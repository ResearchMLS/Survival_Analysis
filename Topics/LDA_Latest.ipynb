{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/admin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run in python console\n",
    "import nltk; nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import string\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# NLTK Stop words\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk import TweetTokenizer\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import Phrases\n",
    "from gensim.models import Word2Vec\n",
    "# Plots\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use','good','be','class','method','function','return','code','fix','add'])\n",
    "\n",
    "#f = open('/Users/admin/Documents/Winter2020/RevicedRelease Eng/dataset10/stopword.txt', 'r')\n",
    "#x = f.readlines()\n",
    "#remove_words = []\n",
    "#for xx in x:\n",
    "#    remove_words.append(xx.replace(\"\\n\",''))\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ztd-jni</td>\n",
       "      <td>Fix all warnings Also add tests to validate th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ztd-jni</td>\n",
       "      <td>Zstd v0.4.4/Fix the 32bit compatibility We nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ztd-jni</td>\n",
       "      <td>Zstd 0.3 add compression using HC variant/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ztd-jni</td>\n",
       "      <td>Concurrency fix/Zstd-0.4.1 and performance tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ztd-jni</td>\n",
       "      <td>Zstd 0.3 add compression using HC variant/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    System                                               Text\n",
       "0  ztd-jni  Fix all warnings Also add tests to validate th...\n",
       "1  ztd-jni  Zstd v0.4.4/Fix the 32bit compatibility We nee...\n",
       "2  ztd-jni         Zstd 0.3 add compression using HC variant/\n",
       "3  ztd-jni  Concurrency fix/Zstd-0.4.1 and performance tes...\n",
       "4  ztd-jni         Zstd 0.3 add compression using HC variant/"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_csv('/Users/admin/Documents/commit-message/cleaned/Ccommitmessages.csv')\n",
    "#print(df.Text.unique())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "data = df.Text.values.tolist()\n",
    "# Remove new line characters\n",
    "#for line in data:\n",
    "    #print(line)\n",
    "#data = [re.sub('\\s+',' ', str(sent)) for sent in data]\n",
    "#data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "#data = [re.sub('<pre>(.*?)</pre>', '', sent) for sent in data]\n",
    "#data = [re.sub('<code>(.*?)</code>', '', sent) for sent in data]\n",
    "#data = [re.sub('<a(.*?)</a>', ' ', sent) for sent in data]\n",
    "#data = [re.sub('<p>', ' ', sent) for sent in data]\n",
    "#data = [re.sub('</p>', ' ', sent) for sent in data]\n",
    "#data = [re.sub('<li>', ' ', sent) for sent in data]\n",
    "#data = [re.sub('</li>', ' ', sent) for sent in data]\n",
    "#data = [re.sub('<ol>', ' ', sent) for sent in data]\n",
    "#data = [re.sub('</ol>', ' ', sent) for sent in data]\n",
    "#data = [re.sub('<em>', ' ', sent) for sent in data]\n",
    "#data = [re.sub('</em>', ' ', sent) for sent in data]\n",
    "#data = [re.sub('<blockquote>', ' ', sent) for sent in data]\n",
    "#data = [re.sub('</blockquote>', ' ', sent) for sent in data]\n",
    "#data = [re.sub('<h1>', ' ', sent) for sent in data]\n",
    "#data = [re.sub('</h1>', ' ', sent) for sent in data]\n",
    "#data = [re.sub('<h2>', ' ', sent) for sent in data]\n",
    "#data = [re.sub('</h2>', ' ', sent) for sent in data]\n",
    "#data = [re.sub('\\'', '', sent) for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "\n",
    "\n",
    "def get_bigrams(myString):\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    tokens = tokenizer.tokenize(myString)\n",
    "    stemmer = PorterStemmer()\n",
    "    bigram_finder = BigramCollocationFinder.from_words(tokens)\n",
    "    bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 500)\n",
    "\n",
    "    for bigram_tuple in bigrams:\n",
    "        x = \"%s_%s\" % bigram_tuple\n",
    "        tokens.append(x)\n",
    "\n",
    "    result = [' '.join([stemmer.stem(w).lower() for w in x.split()]) for x in tokens if x.lower() not in stop_words]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "#print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "data_words_nostops = remove_stopwords(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "bigram = Phrases()\n",
    "for sentence in data_words_nostops:\n",
    "    sentences.append(sentence)\n",
    "    bigram.add_vocab([sentence])\n",
    "#print(list(bigram[sentences])[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for data in \n",
    "# Form Bigrams\n",
    "data_words_bigrams = list(bigram[sentences])\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "#print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('able', 1),\n",
       "  ('also', 1),\n",
       "  ('always', 1),\n",
       "  ('bit', 2),\n",
       "  ('bytestream', 1),\n",
       "  ('cast', 2),\n",
       "  ('compatibility', 1),\n",
       "  ('compiler_warning', 1),\n",
       "  ('double', 1),\n",
       "  ('else', 1),\n",
       "  ('equal', 1),\n",
       "  ('jlong', 1),\n",
       "  ('need', 1),\n",
       "  ('order', 1),\n",
       "  ('pointer', 2),\n",
       "  ('produce', 1),\n",
       "  ('rebase', 1),\n",
       "  ('size', 1),\n",
       "  ('test', 1),\n",
       "  ('top', 1),\n",
       "  ('validate', 1),\n",
       "  ('warning', 1),\n",
       "  ('zstd', 1)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the term frequency\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/Users/admin/Documents/commit-message/Topics/20/'\n",
    "num_topics = 16\n",
    "step_size = 4\n",
    "topic_index = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics, \n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -8.226295097933248\n",
      "\n",
      "Coherence Score:  0.30768447626117534\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', ldamodel.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=ldamodel, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num,topn=num_topics)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=ldamodel, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>test, support, change, version, fix, restructu...</td>\n",
       "      <td>Fix all warnings Also add tests to validate th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>test, support, change, version, fix, restructu...</td>\n",
       "      <td>Zstd v0.4.4/Fix the 32bit compatibility We nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.7645</td>\n",
       "      <td>test, summary, test_plan, make, throwing_excep...</td>\n",
       "      <td>Zstd 0.3 add compression using HC variant/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>summary, test, test_plan, differential_revisio...</td>\n",
       "      <td>Concurrency fix/Zstd-0.4.1 and performance tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.7645</td>\n",
       "      <td>test, summary, test_plan, make, throwing_excep...</td>\n",
       "      <td>Zstd 0.3 add compression using HC variant/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>test, support, also, summary, use, change, cor...</td>\n",
       "      <td>Use JNI_ABORT on releasing the source buffer c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>test, support, also, summary, use, change, cor...</td>\n",
       "      <td>Use JNI_ABORT on releasing the source buffer c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.8791</td>\n",
       "      <td>platform, session, make, sessionsnapshot, acti...</td>\n",
       "      <td>Add support for InputStream.read() FilterInput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.6873</td>\n",
       "      <td>platform, session, make, sessionsnapshot, acti...</td>\n",
       "      <td>Move to the new streaming API/Zstd-0.7.4/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.7285</td>\n",
       "      <td>test, support, change, version, fix, restructu...</td>\n",
       "      <td>Finish the move to the new Zstd streaming API ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0            15.0              0.7039   \n",
       "1            1            15.0              0.9506   \n",
       "2            2             5.0              0.7645   \n",
       "3            3             0.0              0.7201   \n",
       "4            4             5.0              0.7645   \n",
       "5            5             3.0              0.4983   \n",
       "6            6             3.0              0.4988   \n",
       "7            7            13.0              0.8791   \n",
       "8            8            13.0              0.6873   \n",
       "9            9            15.0              0.7285   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  test, support, change, version, fix, restructu...   \n",
       "1  test, support, change, version, fix, restructu...   \n",
       "2  test, summary, test_plan, make, throwing_excep...   \n",
       "3  summary, test, test_plan, differential_revisio...   \n",
       "4  test, summary, test_plan, make, throwing_excep...   \n",
       "5  test, support, also, summary, use, change, cor...   \n",
       "6  test, support, also, summary, use, change, cor...   \n",
       "7  platform, session, make, sessionsnapshot, acti...   \n",
       "8  platform, session, make, sessionsnapshot, acti...   \n",
       "9  test, support, change, version, fix, restructu...   \n",
       "\n",
       "                                                Text  \n",
       "0  Fix all warnings Also add tests to validate th...  \n",
       "1  Zstd v0.4.4/Fix the 32bit compatibility We nee...  \n",
       "2         Zstd 0.3 add compression using HC variant/  \n",
       "3  Concurrency fix/Zstd-0.4.1 and performance tes...  \n",
       "4         Zstd 0.3 add compression using HC variant/  \n",
       "5  Use JNI_ABORT on releasing the source buffer c...  \n",
       "6  Use JNI_ABORT on releasing the source buffer c...  \n",
       "7  Add support for InputStream.read() FilterInput...  \n",
       "8          Move to the new streaming API/Zstd-0.7.4/  \n",
       "9  Finish the move to the new Zstd streaming API ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.to_csv(r'{}Topic_1.csv'.format(output_path))\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(14,\n",
      "  [('support', 0.04161588020198503),\n",
      "   ('key', 0.039874629984328745),\n",
      "   ('implementation', 0.03290962911370364),\n",
      "   ('instance', 0.023506877938359743),\n",
      "   ('implement', 0.02211387776423472),\n",
      "   ('provide', 0.021069127633640956),\n",
      "   ('cipher_suite', 0.019502002437750306),\n",
      "   ('enable', 0.018805502350687793),\n",
      "   ('work', 0.014104126763015845),\n",
      "   ('list', 0.013407626675953334)]),\n",
      " (0,\n",
      "  [('compaction', 0.04824955116696589),\n",
      "   ('level', 0.04757630161579892),\n",
      "   ('file', 0.04207809694793537),\n",
      "   ('summary', 0.03949730700179533),\n",
      "   ('test_plan', 0.030745062836624776),\n",
      "   ('write', 0.022778276481149013),\n",
      "   ('option', 0.020758527827648116),\n",
      "   ('run', 0.020197486535008975),\n",
      "   ('differential_revision', 0.01671903052064632),\n",
      "   ('number', 0.016494614003590664)]),\n",
      " (9,\n",
      "  [('commit', 0.06296769483482387),\n",
      "   ('call', 0.03814564701587881),\n",
      "   ('read', 0.030297499543712355),\n",
      "   ('merge', 0.02701222850885198),\n",
      "   ('change', 0.02646468333637525),\n",
      "   ('buffer', 0.023909472531483848),\n",
      "   ('array', 0.014418689541887205),\n",
      "   ('track', 0.012593538966964775),\n",
      "   ('native', 0.010768388392042343),\n",
      "   ('write', 0.010403358277057857)]),\n",
      " (3,\n",
      "  [('native', 0.026536781995297277),\n",
      "   ('case', 0.024689284514612025),\n",
      "   ('object', 0.021330198186093382),\n",
      "   ('pass', 0.018978837756130334),\n",
      "   ('call', 0.017635203224722874),\n",
      "   ('create', 0.01561975142761169),\n",
      "   ('socket', 0.015283842794759825),\n",
      "   ('load', 0.015115888478333893),\n",
      "   ('free', 0.013604299630500504),\n",
      "   ('fix', 0.013268390997648639)]),\n",
      " (10,\n",
      "  [('file', 0.03438234964721693),\n",
      "   ('test', 0.031470489416508006),\n",
      "   ('summary', 0.028894613058573188),\n",
      "   ('differential_revision', 0.023070892597155338),\n",
      "   ('test_plan', 0.02273490872438123),\n",
      "   ('delete', 0.01971105386941427),\n",
      "   ('add', 0.015007279650576773),\n",
      "   ('make', 0.014111322656512488),\n",
      "   ('release', 0.012879381789674096),\n",
      "   ('time', 0.012767387165416061)]),\n",
      " (15,\n",
      "  [('work', 0.044813598609233146),\n",
      "   ('type', 0.04268881591655399),\n",
      "   ('parameter', 0.01757774773034576),\n",
      "   ('release', 0.01371450647092911),\n",
      "   ('case', 0.013135020282016612),\n",
      "   ('return', 0.012941858219045779),\n",
      "   ('set', 0.012941858219045779),\n",
      "   ('order', 0.012748696156074947),\n",
      "   ('function', 0.012555534093104115),\n",
      "   ('make', 0.01216920996716245)]),\n",
      " (11,\n",
      "  [('log', 0.03664507976622966),\n",
      "   ('issue', 0.03238035065550466),\n",
      "   ('fix', 0.028589480334860213),\n",
      "   ('add', 0.025904280524403727),\n",
      "   ('change', 0.024640657084188913),\n",
      "   ('level', 0.019270257463275944),\n",
      "   ('avoid', 0.018006634023061126),\n",
      "   ('failure', 0.017848681093034276),\n",
      "   ('error', 0.015163481282577792),\n",
      "   ('small', 0.014531669562470383)]),\n",
      " (2,\n",
      "  [('file', 0.056648777579010136),\n",
      "   ('summary', 0.03875968992248062),\n",
      "   ('test_plan', 0.022510435301132975),\n",
      "   ('differential_revision', 0.021765056648777578),\n",
      "   ('version', 0.017889087656529516),\n",
      "   ('create', 0.016398330351818723),\n",
      "   ('read', 0.013714967203339297),\n",
      "   ('datum', 0.012522361359570662),\n",
      "   ('database', 0.012373285629099583),\n",
      "   ('open', 0.011627906976744186)]),\n",
      " (13,\n",
      "  [('test_plan', 0.05216664677092038),\n",
      "   ('summary', 0.04965978273845052),\n",
      "   ('reviewer', 0.03939357765309777),\n",
      "   ('option', 0.037722334964784526),\n",
      "   ('differential_revision', 0.028291751223588398),\n",
      "   ('user', 0.028291751223588398),\n",
      "   ('key', 0.02566551271338188),\n",
      "   ('run', 0.017786797182762326),\n",
      "   ('fail', 0.017428673749552346),\n",
      "   ('size', 0.017309299271815685)]),\n",
      " (4,\n",
      "  [('add', 0.08060556464811784),\n",
      "   ('test', 0.028641571194762683),\n",
      "   ('field', 0.02843698854337152),\n",
      "   ('method', 0.024549918166939442),\n",
      "   ('type', 0.023731587561374796),\n",
      "   ('change', 0.020662847790507366),\n",
      "   ('table', 0.020049099836333878),\n",
      "   ('update', 0.018412438625204582),\n",
      "   ('throw', 0.016571194762684125),\n",
      "   ('check', 0.016571194762684125)])]\n",
      "\n",
      "Coherence Score:  0.41730346499715737\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from pprint import pprint\n",
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "mallet_path = '/Users/admin/Documents/mallet-2.0-2.8/bin/mallet' # update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=step_size, step=step_size):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=step_size, limit=40, step=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "limit=40; start=step_size; step=step_size;\n",
    "x = range(start, limit, step)\n",
    "#plt.plot(x, coherence_values)\n",
    "#plt.xlabel(\"Num Topics\")\n",
    "#plt.ylabel(\"Coherence score\")\n",
    "#plt.legend((\"coherence_values\"), loc='best')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 4  has Coherence Value of 0.3979\n",
      "Num Topics = 8  has Coherence Value of 0.3975\n",
      "Num Topics = 12  has Coherence Value of 0.3818\n",
      "Num Topics = 16  has Coherence Value of 0.4353\n",
      "Num Topics = 20  has Coherence Value of 0.4457\n",
      "Num Topics = 24  has Coherence Value of 0.4312\n",
      "Num Topics = 28  has Coherence Value of 0.4415\n",
      "Num Topics = 32  has Coherence Value of 0.4354\n",
      "Num Topics = 36  has Coherence Value of 0.443\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.033*\"test\" + 0.031*\"summary\" + 0.029*\"test_plan\" + 0.026*\"file\" + '\n",
      "  '0.019*\"differential_revision\" + 0.016*\"unit\" + 0.014*\"reviewer\" + '\n",
      "  '0.014*\"add\" + 0.013*\"case\" + 0.012*\"delete\"'),\n",
      " (1,\n",
      "  '0.048*\"file\" + 0.036*\"summary\" + 0.027*\"test_plan\" + '\n",
      "  '0.025*\"differential_revision\" + 0.024*\"option\" + 0.024*\"test\" + '\n",
      "  '0.019*\"delete\" + 0.019*\"compaction\" + 0.018*\"time\" + 0.014*\"unit_test\"'),\n",
      " (2,\n",
      "  '0.045*\"commit\" + 0.038*\"call\" + 0.029*\"enable\" + 0.022*\"merge\" + '\n",
      "  '0.019*\"cipher_suite\" + 0.017*\"buffer\" + 0.016*\"instance\" + 0.015*\"key\" + '\n",
      "  '0.012*\"array\" + 0.011*\"check\"'),\n",
      " (3,\n",
      "  '0.036*\"type\" + 0.028*\"case\" + 0.016*\"load\" + 0.015*\"order\" + '\n",
      "  '0.014*\"default\" + 0.014*\"main_file\" + 0.014*\"parameter\" + 0.013*\"cacert\" + '\n",
      "  '0.012*\"create\" + 0.011*\"make\"'),\n",
      " (4,\n",
      "  '0.043*\"type\" + 0.026*\"fix\" + 0.025*\"update\" + 0.023*\"support\" + '\n",
      "  '0.020*\"long\" + 0.018*\"exception\" + 0.016*\"remove\" + 0.015*\"field\" + '\n",
      "  '0.012*\"set\" + 0.012*\"java\"'),\n",
      " (5,\n",
      "  '0.036*\"realm\" + 0.029*\"check\" + 0.027*\"thread\" + 0.023*\"test\" + '\n",
      "  '0.021*\"change\" + 0.017*\"object\" + 0.016*\"class\" + 0.015*\"default_value\" + '\n",
      "  '0.015*\"realm_instance\" + 0.014*\"object_store\"'),\n",
      " (6,\n",
      "  '0.047*\"summary\" + 0.044*\"reviewer\" + 0.041*\"revision\" + 0.039*\"test_plan\" + '\n",
      "  '0.027*\"make\" + 0.025*\"leveldb_differential\" + 0.024*\"file\" + 0.023*\"review\" '\n",
      "  '+ 0.019*\"compaction\" + 0.019*\"level\"'),\n",
      " (7,\n",
      "  '0.029*\"fix\" + 0.026*\"find\" + 0.025*\"check\" + 0.023*\"update\" + 0.022*\"issue\" '\n",
      "  '+ 0.021*\"request_resolve\" + 0.021*\"add\" + 0.018*\"block\" + '\n",
      "  '0.017*\"fbshipit_source\" + 0.017*\"snapshot\"'),\n",
      " (8,\n",
      "  '0.030*\"write\" + 0.026*\"summary\" + 0.021*\"base\" + 0.020*\"make\" + '\n",
      "  '0.018*\"unit_test\" + 0.015*\"rocksdb\" + 0.014*\"performance\" + '\n",
      "  '0.014*\"memtable\" + 0.013*\"improve\" + 0.013*\"memory\"'),\n",
      " (9,\n",
      "  '0.059*\"issue\" + 0.036*\"pointer\" + 0.027*\"native\" + 0.021*\"error\" + '\n",
      "  '0.020*\"call\" + 0.020*\"object\" + 0.017*\"parser\" + 0.017*\"generator\" + '\n",
      "  '0.014*\"annotation\" + 0.014*\"failure\"'),\n",
      " (10,\n",
      "  '0.041*\"level\" + 0.037*\"summary\" + 0.036*\"file\" + 0.036*\"compaction\" + '\n",
      "  '0.028*\"test_plan\" + 0.022*\"differential_revision\" + 0.021*\"option\" + '\n",
      "  '0.017*\"run\" + 0.015*\"read\" + 0.015*\"log\"'),\n",
      " (11,\n",
      "  '0.045*\"table\" + 0.044*\"test_plan\" + 0.042*\"summary\" + 0.036*\"reviewer\" + '\n",
      "  '0.026*\"log\" + 0.024*\"user\" + 0.023*\"test\" + 0.021*\"differential_revision\" + '\n",
      "  '0.017*\"option\" + 0.016*\"size\"'),\n",
      " (12,\n",
      "  '0.034*\"summary\" + 0.032*\"test_plan\" + 0.030*\"column_family\" + '\n",
      "  '0.025*\"column_familie\" + 0.023*\"add\" + 0.022*\"change\" + '\n",
      "  '0.020*\"differential_revision\" + 0.018*\"diff\" + 0.017*\"option\" + '\n",
      "  '0.013*\"file\"'),\n",
      " (13,\n",
      "  '0.069*\"support\" + 0.030*\"implementation\" + 0.027*\"implement\" + 0.026*\"work\" '\n",
      "  '+ 0.023*\"key\" + 0.022*\"make\" + 0.022*\"version\" + 0.019*\"build\" + '\n",
      "  '0.016*\"platform\" + 0.015*\"provide\"'),\n",
      " (14,\n",
      "  '0.102*\"add\" + 0.065*\"test\" + 0.039*\"fix\" + 0.032*\"work\" + 0.019*\"throw\" + '\n",
      "  '0.014*\"realm\" + 0.013*\"query\" + 0.013*\"change\" + 0.012*\"method\" + '\n",
      "  '0.012*\"close\"'),\n",
      " (15,\n",
      "  '0.147*\"test\" + 0.033*\"change\" + 0.029*\"support\" + 0.025*\"harmony_xnet\" + '\n",
      "  '0.022*\"remove\" + 0.022*\"main_java\" + 0.022*\"add\" + 0.016*\"instance\" + '\n",
      "  '0.015*\"move\" + 0.013*\"java_libcore\"')]\n"
     ]
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[topic_index]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.1207</td>\n",
       "      <td>issue, pointer, native, error, call, object, p...</td>\n",
       "      <td>Fix all warnings Also add tests to validate th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.1113</td>\n",
       "      <td>issue, pointer, native, error, call, object, p...</td>\n",
       "      <td>Zstd v0.4.4/Fix the 32bit compatibility We nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>table, test_plan, summary, reviewer, log, user...</td>\n",
       "      <td>Zstd 0.3 add compression using HC variant/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1038</td>\n",
       "      <td>fix, find, check, update, issue, request_resol...</td>\n",
       "      <td>Concurrency fix/Zstd-0.4.1 and performance tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>table, test_plan, summary, reviewer, log, user...</td>\n",
       "      <td>Zstd 0.3 add compression using HC variant/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>commit, call, enable, merge, cipher_suite, buf...</td>\n",
       "      <td>Use JNI_ABORT on releasing the source buffer c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>test, summary, test_plan, file, differential_r...</td>\n",
       "      <td>Use JNI_ABORT on releasing the source buffer c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1113</td>\n",
       "      <td>fix, find, check, update, issue, request_resol...</td>\n",
       "      <td>Add support for InputStream.read() FilterInput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>fix, find, check, update, issue, request_resol...</td>\n",
       "      <td>Move to the new streaming API/Zstd-0.7.4/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>fix, find, check, update, issue, request_resol...</td>\n",
       "      <td>Finish the move to the new Zstd streaming API ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             9.0              0.1207   \n",
       "1            1             9.0              0.1113   \n",
       "2            2            11.0              0.0793   \n",
       "3            3             7.0              0.1038   \n",
       "4            4            11.0              0.0793   \n",
       "5            5             2.0              0.0763   \n",
       "6            6             0.0              0.0743   \n",
       "7            7             7.0              0.1113   \n",
       "8            8             7.0              0.0793   \n",
       "9            9             7.0              0.1178   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  issue, pointer, native, error, call, object, p...   \n",
       "1  issue, pointer, native, error, call, object, p...   \n",
       "2  table, test_plan, summary, reviewer, log, user...   \n",
       "3  fix, find, check, update, issue, request_resol...   \n",
       "4  table, test_plan, summary, reviewer, log, user...   \n",
       "5  commit, call, enable, merge, cipher_suite, buf...   \n",
       "6  test, summary, test_plan, file, differential_r...   \n",
       "7  fix, find, check, update, issue, request_resol...   \n",
       "8  fix, find, check, update, issue, request_resol...   \n",
       "9  fix, find, check, update, issue, request_resol...   \n",
       "\n",
       "                                                Text  \n",
       "0  Fix all warnings Also add tests to validate th...  \n",
       "1  Zstd v0.4.4/Fix the 32bit compatibility We nee...  \n",
       "2         Zstd 0.3 add compression using HC variant/  \n",
       "3  Concurrency fix/Zstd-0.4.1 and performance tes...  \n",
       "4         Zstd 0.3 add compression using HC variant/  \n",
       "5  Use JNI_ABORT on releasing the source buffer c...  \n",
       "6  Use JNI_ABORT on releasing the source buffer c...  \n",
       "7  Add support for InputStream.read() FilterInput...  \n",
       "8          Move to the new streaming API/Zstd-0.7.4/  \n",
       "9  Finish the move to the new Zstd streaming API ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=ldamodel, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num,topn=20)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "df_dominant_topic.to_csv(r'{}Topic_2.csv'.format(output_path))\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6479</td>\n",
       "      <td>test, summary, test_plan, file, differential_r...</td>\n",
       "      <td>Fix the string format issue Summary: mac and o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7450</td>\n",
       "      <td>file, summary, test_plan, differential_revisio...</td>\n",
       "      <td>Universal Compaction should keep DeleteMarkers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8779</td>\n",
       "      <td>commit, call, enable, merge, cipher_suite, buf...</td>\n",
       "      <td>Fix OpenSSLSocketImpl.getPort when SNI is used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7049</td>\n",
       "      <td>type, case, load, order, default, main_file, p...</td>\n",
       "      <td>Thanks to Ken Olson reporting MSVC2010 complai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5451</td>\n",
       "      <td>type, fix, update, support, long, exception, r...</td>\n",
       "      <td>Remove Java OpenSSL name mapping. (#227) As of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0              0.6479   \n",
       "1        1.0              0.7450   \n",
       "2        2.0              0.8779   \n",
       "3        3.0              0.7049   \n",
       "4        4.0              0.5451   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  test, summary, test_plan, file, differential_r...   \n",
       "1  file, summary, test_plan, differential_revisio...   \n",
       "2  commit, call, enable, merge, cipher_suite, buf...   \n",
       "3  type, case, load, order, default, main_file, p...   \n",
       "4  type, fix, update, support, long, exception, r...   \n",
       "\n",
       "                                                Text  \n",
       "0  Fix the string format issue Summary: mac and o...  \n",
       "1  Universal Compaction should keep DeleteMarkers...  \n",
       "2  Fix OpenSSLSocketImpl.getPort when SNI is used...  \n",
       "3  Thanks to Ken Olson reporting MSVC2010 complai...  \n",
       "4  Remove Java OpenSSL name mapping. (#227) As of...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "\n",
    "sent_topics_sorteddf_mallet.to_csv(r'{}Topic_3.csv'.format(output_path))\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Num_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>issue, pointer, native, error, call, object, p...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>issue, pointer, native, error, call, object, p...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>table, test_plan, summary, reviewer, log, user...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>fix, find, check, update, issue, request_resol...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>table, test_plan, summary, reviewer, log, user...</td>\n",
       "      <td>249.0</td>\n",
       "      <td>0.1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>test, summary, test_plan, file, differential_r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2174.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>test, change, support, harmony_xnet, remove, m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2175.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>support, implementation, implement, work, key,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>test, summary, test_plan, file, differential_r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>test, summary, test_plan, file, differential_r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2178 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant_Topic                                     Topic_Keywords  \\\n",
       "0.0                9.0  issue, pointer, native, error, call, object, p...   \n",
       "1.0                9.0  issue, pointer, native, error, call, object, p...   \n",
       "2.0               11.0  table, test_plan, summary, reviewer, log, user...   \n",
       "3.0                7.0  fix, find, check, update, issue, request_resol...   \n",
       "4.0               11.0  table, test_plan, summary, reviewer, log, user...   \n",
       "...                ...                                                ...   \n",
       "2173.0             0.0  test, summary, test_plan, file, differential_r...   \n",
       "2174.0            15.0  test, change, support, harmony_xnet, remove, m...   \n",
       "2175.0            13.0  support, implementation, implement, work, key,...   \n",
       "2176.0             0.0  test, summary, test_plan, file, differential_r...   \n",
       "2177.0             0.0  test, summary, test_plan, file, differential_r...   \n",
       "\n",
       "        Num_Documents  Perc_Documents  \n",
       "0.0             150.0          0.0689  \n",
       "1.0              57.0          0.0262  \n",
       "2.0             106.0          0.0487  \n",
       "3.0             109.0          0.0500  \n",
       "4.0             249.0          0.1143  \n",
       "...               ...             ...  \n",
       "2173.0            NaN             NaN  \n",
       "2174.0            NaN             NaN  \n",
       "2175.0            NaN             NaN  \n",
       "2176.0            NaN             NaN  \n",
       "2177.0            NaN             NaN  \n",
       "\n",
       "[2178 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "df_dominant_topics.to_csv(r'{}Topic_4.csv'.format(output_path))\n",
    "# Show\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
