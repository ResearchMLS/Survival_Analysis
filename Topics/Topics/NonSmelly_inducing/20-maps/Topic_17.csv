Topic_no,Keywords,Contrib,System,Text
17,"revision_pulle, summary, closes_differential, pull_request, resolved_differential, fbshipit_source, yiwu_arbug, maysamyabandeh_fbshipit, ajkr_fbshipit, pr, ad, sagar_fbshipit, riversand_fbshipit, call, sst_file, range_tombstone, siying_fbshipit, part, include, rocksdb",0.0763,OpenDDS,return const char* since only dealing with string literals/Remove use of streams when interacting with Guid and GuidConverter. Added header for stream includes allowed/not allowed in SafetyProfile/
,,0.063,pljava,Coersion for getXXX now applies to updateXXX as well/
,,0.0628,pljava,Added BlobValue coersion to the bytea type./
,,0.0648,rocksdb,Remove usage of C runtime API that has file handle limitation/
,,0.166,rocksdb,"Optimize sequential insert into memtable Part 2: Implementation Summary: Implement a insert hint into skip-list to hint insert position. This is to optimize for the write workload where there are multiple stream of sequential writes. For example, there is a stream of keys of a1, a2, a3... but also b1, b2, b2... Each stream are not neccessary strictly sequential, but can get reorder a little bit. User can specify a prefix extractor and the `SkipListRep` can thus maintan a hint for each of the stream for fast insert into memtable. This is the internal implementation part. See for the interface part. See inline comments for details. Closes Differential Revision: D4106781 Pulled By: yiwu-arbug fbshipit-source-id: f4d48c4/"
,,0.1357,rocksdb,"DeleteRange flush support Summary: Changed BuildTable() (used for flush) to (1) add range tombstones to the aggregator, which is used by CompactionIterator to determine which keys can be removed; and (2) add aggregators range tombstones to the table that is output for the flush. Closes Differential Revision: D4100025 Pulled By: ajkr fbshipit-source-id: cb01a70/"
,,0.1194,rocksdb,"DeleteRange flush support Summary: Changed BuildTable() (used for flush) to (1) add range tombstones to the aggregator, which is used by CompactionIterator to determine which keys can be removed; and (2) add aggregators range tombstones to the table that is output for the flush. Closes Differential Revision: D4100025 Pulled By: ajkr fbshipit-source-id: cb01a70/Add TableBuilderOptions::level and relevant changes (#1335)/"
,,0.1647,rocksdb,"Optimize sequential insert into memtable Part 2: Implementation Summary: Implement a insert hint into skip-list to hint insert position. This is to optimize for the write workload where there are multiple stream of sequential writes. For example, there is a stream of keys of a1, a2, a3... but also b1, b2, b2... Each stream are not neccessary strictly sequential, but can get reorder a little bit. User can specify a prefix extractor and the `SkipListRep` can thus maintan a hint for each of the stream for fast insert into memtable. This is the internal implementation part. See for the interface part. See inline comments for details. Closes Differential Revision: D4106781 Pulled By: yiwu-arbug fbshipit-source-id: f4d48c4/"
,,0.1184,rocksdb,"DeleteRange flush support Summary: Changed BuildTable() (used for flush) to (1) add range tombstones to the aggregator, which is used by CompactionIterator to determine which keys can be removed; and (2) add aggregators range tombstones to the table that is output for the flush. Closes Differential Revision: D4100025 Pulled By: ajkr fbshipit-source-id: cb01a70/Split DBOptions into ImmutableDBOptions and MutableDBOptions Summary: Use ImmutableDBOptions/MutableDBOptions internally and DBOptions only for user-facing APIs. MutableDBOptions is barely a placeholder for now. Ill start to move options to MutableDBOptions in following diffs. Test Plan: make all check Reviewers: yhchiang, IslamAbdelRahman, sdong Reviewed By: sdong Subscribers: andrewkr, dhruba, leveldb Differential Revision:"
,,0.0905,rocksdb,Fix rocksdb::Status::getState Summary: This fixes the Java API for Status#getState use in Native code and also simplifies the implementation of rocksdb::Status::getState. Closes Closes Differential Revision: D4364181 Pulled By: yiwu-arbug fbshipit-source-id: 8e073b4/
,,0.1511,rocksdb,disable UBSAN for functions with intentional shift / overflow Summary: disable UBSAN for functions with intentional left shift on number / overflow These functions are rocksdb:: Hash FixedLengthColBufEncoder::Append FaultInjectionTest:: Key Closes Differential Revision: D4240801 Pulled By: IslamAbdelRahman fbshipit-source-id: 3e1caf6/
,,0.0987,rocksdb,Remove sst_file_manager option from LITE Summary: Remove sst_file_manager option from LITE Closes Differential Revision: D4341331 Pulled By: IslamAbdelRahman fbshipit-source-id: 9f9328d/
,,0.1023,rocksdb,Gcc 7 fallthrough Summary: hopefully the last of the gcc-7 compile errors Closes Differential Revision: D4332106 Pulled By: IslamAbdelRahman fbshipit-source-id: 139448c/
,,0.0987,rocksdb,Remove sst_file_manager option from LITE Summary: Remove sst_file_manager option from LITE Closes Differential Revision: D4341331 Pulled By: IslamAbdelRahman fbshipit-source-id: 9f9328d/
,,0.0938,rocksdb,Implement PositionedAppend for PosixWritableFile Summary: This patch clarifies the contract of PositionedAppend with some unit tests and also implements it for PosixWritableFile. (Tasks: 14524071) Closes Differential Revision: D4204907 Pulled By: maysamyabandeh fbshipit-source-id: 06eabd2/
,,0.2278,rocksdb,"[rocksdb][PR] compaction_style and compaction_pri should output their value as a stÖ Summary: Öring Replace the numerical output for compaction_style and compaction_pri with strings Closes Differential Revision: D4482796 Pulled By: highker fbshipit-source-id: 5785768/Optimize sequential insert into memtable Part 1: Interface Summary: Currently our skip-list have an optimization to speedup sequential inserts from a single stream, by remembering the last insert position. We extend the idea to support sequential inserts from multiple streams, and even tolerate small reordering wihtin each stream. This PR is the interface part adding the following: Add `memtable_insert_prefix_extractor` to allow specifying prefix for each key. Add `InsertWithHint()` interface to memtable, to allow underlying implementation to return a hint of insert position, which can be later pass back to optimize inserts. Memtable will maintain a map from prefix to hints and pass the hint via `InsertWithHint()` if `memtable_insert_prefix_extractor` is non-null. Closes Differential Revision: D4079367 Pulled By: yiwu-arbug fbshipit-source-id: 3555326/"
,,0.1088,rocksdb,"Allow incrementing refcount on cache handles Summary: Previously the only way to increment a handles refcount was to invoke Lookup(), which (1) did hash table lookup to get cache handle, (2) incremented that handles refcount. For a future DeleteRange optimization, I added a function, Ref(), for when the caller already has a cache handle and only needs to do (2). Closes Differential Revision: D4397114 Pulled By: ajkr fbshipit-source-id: 9addbe5/"
,,0.1357,rocksdb,"Fix fd leak when using direct IOs Summary: We should close the fd, before overriding it. This bug was introduced by f89caa127baa086cb100976b14da1a531cf0e823 Closes Differential Revision: D4214101 Pulled By: siying fbshipit-source-id: 0d65de0/Implement PositionedAppend for PosixWritableFile Summary: This patch clarifies the contract of PositionedAppend with some unit tests and also implements it for PosixWritableFile. (Tasks: 14524071) Closes Differential Revision: D4204907 Pulled By: maysamyabandeh fbshipit-source-id: 06eabd2/"
,,0.0846,rocksdb,"direct reads refactor Summary: direct IO reads refactoring remove unnecessary classes and unified interfaces tested with db_bench need more change for options and ON/OFF for different files. Since disabled is default, it should be fine now Closes Differential Revision: D4307189 Pulled By: lightmark fbshipit-source-id: 6991e22/"
,,0.1275,rocksdb,"Allow SstFileWriter to Fadvise the file away from page cache Summary: Add `fadvise_trigger` option to `SstFileWriter` If fadvise_trigger is passed with a non-zero value, SstFileWriter will invalidate the os page cache every `fadvise_trigger` bytes for the sst file Closes Differential Revision: D4371246 Pulled By: IslamAbdelRahman fbshipit-source-id: 91caff1/"
,,0.0869,rocksdb,"NewLRUCache() to pick number of shard bits based on capacity if not given Summary: If the users use the NewLRUCache() without passing in the number of shard bits, instead of using hard-coded 6, well determine it based on capacity. Closes Differential Revision: D4242517 Pulled By: siying fbshipit-source-id: 86b0f18/"
,,0.0934,rocksdb,Cleaner default options using C++11 in-class init Summary: C++11 in-class initialization is cleaner and makes it the default more explicit to our users and more visible. Use it for ColumnFamilyOptions and DBOptions Closes Differential Revision: D4490473 Pulled By: IslamAbdelRahman fbshipit-source-id: c493a87/
,,0.2273,rocksdb,"Optimize sequential insert into memtable Part 1: Interface Summary: Currently our skip-list have an optimization to speedup sequential inserts from a single stream, by remembering the last insert position. We extend the idea to support sequential inserts from multiple streams, and even tolerate small reordering wihtin each stream. This PR is the interface part adding the following: Add `memtable_insert_prefix_extractor` to allow specifying prefix for each key. Add `InsertWithHint()` interface to memtable, to allow underlying implementation to return a hint of insert position, which can be later pass back to optimize inserts. Memtable will maintain a map from prefix to hints and pass the hint via `InsertWithHint()` if `memtable_insert_prefix_extractor` is non-null. Closes Differential Revision: D4079367 Pulled By: yiwu-arbug fbshipit-source-id: 3555326/"
,,0.1283,rocksdb,Fixes for MSVC compilation Summary: Closes Differential Revision: D4327421 Pulled By: yiwu-arbug fbshipit-source-id: 661ee0b/
,,0.102,rocksdb,Add support for JNI Library on Linux on PowerPC. Summary: Closes Closes Differential Revision: D4546491 Pulled By: siying fbshipit-source-id: 86190b4/
,,0.1495,rocksdb,disable UBSAN for functions with intentional shift / overflow Summary: disable UBSAN for functions with intentional left shift on number / overflow These functions are rocksdb:: Hash FixedLengthColBufEncoder::Append FaultInjectionTest:: Key Closes Differential Revision: D4240801 Pulled By: IslamAbdelRahman fbshipit-source-id: 3e1caf6/
,,0.1307,rocksdb,Dump persistent cache options Summary: Dump persistent cache options Closes Differential Revision: D4337019 Pulled By: yiwu-arbug fbshipit-source-id: 3812f8a/Persistent Cache: Expose stats to user via public API Summary: Exposing persistent cache stats (counters) to the user via public API. Closes Differential Revision: D4155274 Pulled By: siying fbshipit-source-id: 30a9f50/
,,0.1385,rocksdb,"Allow SstFileWriter to Fadvise the file away from page cache Summary: Add `fadvise_trigger` option to `SstFileWriter` If fadvise_trigger is passed with a non-zero value, SstFileWriter will invalidate the os page cache every `fadvise_trigger` bytes for the sst file Closes Differential Revision: D4371246 Pulled By: IslamAbdelRahman fbshipit-source-id: 91caff1/"
,,0.1062,rocksdb,Disable IngestExternalFile in ReadOnly mode Summary: Disable IngestExternalFile() in read only mode Closes Differential Revision: D4439179 Pulled By: IslamAbdelRahman fbshipit-source-id: b7e46e7/
,,0.0903,rocksdb,"Revert ""PinnableSlice"" Summary: This reverts commit 54d94e9c2cc0bf6eeb2a165ada33fa9c174f0b16. The pull request was landed by mistake. Closes Differential Revision: D4391678 Pulled By: maysamyabandeh fbshipit-source-id: 36d5149/"
,,0.1511,rocksdb,disable UBSAN for functions with intentional shift / overflow Summary: disable UBSAN for functions with intentional left shift on number / overflow These functions are rocksdb:: Hash FixedLengthColBufEncoder::Append FaultInjectionTest:: Key Closes Differential Revision: D4240801 Pulled By: IslamAbdelRahman fbshipit-source-id: 3e1caf6/
,,0.2494,rocksdb,"Fix for 2PC causing WAL to grow too large Summary: Consider the following single column family scenario: prepare in log A commit in log B *WAL is too large, flush all CFs to releast log A* *CFA is on log B so we do not see CFA is depending on log A so no flush is requested* To fix this we must also consider the log containing the prepare section when determining what log a CF is dependent on. Closes Differential Revision: D4403265 Pulled By: reidHoruff fbshipit-source-id: ce800ff/Avoid intentional overflow in GetL0ThresholdSpeedupCompaction Summary: fixes integer overflow in GetL0ThresholdSpeedupCompaction() by checking if int become UBSAN will complain about that since this is still an overflow, we can fix the issue by simply using int64_t Closes Differential Revision: D4241525 Pulled By: IslamAbdelRahman fbshipit-source-id: b3ae21f/Optimize sequential insert into memtable Part 1: Interface Summary: Currently our skip-list have an optimization to speedup sequential inserts from a single stream, by remembering the last insert position. We extend the idea to support sequential inserts from multiple streams, and even tolerate small reordering wihtin each stream. This PR is the interface part adding the following: Add `memtable_insert_prefix_extractor` to allow specifying prefix for each key. Add `InsertWithHint()` interface to memtable, to allow underlying implementation to return a hint of insert position, which can be later pass back to optimize inserts. Memtable will maintain a map from prefix to hints and pass the hint via `InsertWithHint()` if `memtable_insert_prefix_extractor` is non-null. Closes Differential Revision: D4079367 Pulled By: yiwu-arbug fbshipit-source-id: 3555326/"
,,0.0915,rocksdb,"Flush job should release reference current version if sync log failed Summary: Fix the bug when sync log fail, FlushJob::Run() will not be execute and reference to cfd->current() will not be release. Closes Differential Revision: D4441316 Pulled By: yiwu-arbug fbshipit-source-id: 5523e28/"
,,0.0903,rocksdb,"Revert ""PinnableSlice"" Summary: This reverts commit 54d94e9c2cc0bf6eeb2a165ada33fa9c174f0b16. The pull request was landed by mistake. Closes Differential Revision: D4391678 Pulled By: maysamyabandeh fbshipit-source-id: 36d5149/"
,,0.2194,rocksdb,"Optimize sequential insert into memtable Part 1: Interface Summary: Currently our skip-list have an optimization to speedup sequential inserts from a single stream, by remembering the last insert position. We extend the idea to support sequential inserts from multiple streams, and even tolerate small reordering wihtin each stream. This PR is the interface part adding the following: Add `memtable_insert_prefix_extractor` to allow specifying prefix for each key. Add `InsertWithHint()` interface to memtable, to allow underlying implementation to return a hint of insert position, which can be later pass back to optimize inserts. Memtable will maintain a map from prefix to hints and pass the hint via `InsertWithHint()` if `memtable_insert_prefix_extractor` is non-null. Closes Differential Revision: D4079367 Pulled By: yiwu-arbug fbshipit-source-id: 3555326/"
,,0.1062,rocksdb,Disable IngestExternalFile in ReadOnly mode Summary: Disable IngestExternalFile() in read only mode Closes Differential Revision: D4439179 Pulled By: IslamAbdelRahman fbshipit-source-id: b7e46e7/
,,0.1513,rocksdb,"Change DB::GetApproximateSizes for more flexibility needed for MyRocks Summary: Added an option to GetApproximateSizes to exclude file stats, as MyRocks has those counted exactly and we need only stats from memtables. Closes Differential Revision: D4441111 Pulled By: IslamAbdelRahman fbshipit-source-id: c11f4c3/Fix for 2PC causing WAL to grow too large Summary: Consider the following single column family scenario: prepare in log A commit in log B *WAL is too large, flush all CFs to releast log A* *CFA is on log B so we do not see CFA is depending on log A so no flush is requested* To fix this we must also consider the log containing the prepare section when determining what log a CF is dependent on. Closes Differential Revision: D4403265 Pulled By: reidHoruff fbshipit-source-id: ce800ff/Dynamic max_total_wal_size option Summary: Closes Differential Revision: D4176426 Pulled By: yiwu-arbug fbshipit-source-id: b57689d/"
,,0.1173,rocksdb,"Revert ""PinnableSlice"" Summary: This reverts commit 54d94e9c2cc0bf6eeb2a165ada33fa9c174f0b16. The pull request was landed by mistake. Closes Differential Revision: D4391678 Pulled By: maysamyabandeh fbshipit-source-id: 36d5149/Range deletion microoptimizations Summary: Made RangeDelAggregators InternalKeyComparator member a reference-to-const so we dont need to copy-construct it. Also added InternalKeyComparator to ImmutableCFOptions so we dont need to construct one for each DBIter. Made MemTable::NewRangeTombstoneIterator and the table readers NewRangeTombstoneIterator() functions return nullptr instead of NewEmptyInternalIterator to avoid the allocation. Updated callers accordingly. Closes Differential Revision: D4208169 Pulled By: ajkr fbshipit-source-id: 2fd65cf/"
,,0.08800000000000001,rocksdb,"Fix for 2PC causing WAL to grow too large Summary: Consider the following single column family scenario: prepare in log A commit in log B *WAL is too large, flush all CFs to releast log A* *CFA is on log B so we do not see CFA is depending on log A so no flush is requested* To fix this we must also consider the log containing the prepare section when determining what log a CF is dependent on. Closes Differential Revision: D4403265 Pulled By: reidHoruff fbshipit-source-id: ce800ff/"
,,0.1011,rocksdb,Compaction::IsTrivialMove relaxing Summary: IsTrivialMove returns true if no input file overlaps with output_level+1 with more than max_compaction_bytes_ bytes. Closes Differential Revision: D4278338 Pulled By: yiwu-arbug fbshipit-source-id: 994c001/
,,0.0942,rocksdb,"Revert ""PinnableSlice"" Summary: This reverts commit 54d94e9c2cc0bf6eeb2a165ada33fa9c174f0b16. The pull request was landed by mistake. Closes Differential Revision: D4391678 Pulled By: maysamyabandeh fbshipit-source-id: 36d5149/"
,,0.2522,rocksdb,"Test merge op covered by range deletion in memtable Summary: Its a test case for Also got rid of kTypeDeletion in the conditional since we treat it the same as kTypeRangeDeletion. Closes Differential Revision: D4451300 Pulled By: ajkr fbshipit-source-id: b39dda1/Revert ""PinnableSlice"" Summary: This reverts commit 54d94e9c2cc0bf6eeb2a165ada33fa9c174f0b16. The pull request was landed by mistake. Closes Differential Revision: D4391678 Pulled By: maysamyabandeh fbshipit-source-id: 36d5149/Range deletion microoptimizations Summary: Made RangeDelAggregators InternalKeyComparator member a reference-to-const so we dont need to copy-construct it. Also added InternalKeyComparator to ImmutableCFOptions so we dont need to construct one for each DBIter. Made MemTable::NewRangeTombstoneIterator and the table readers NewRangeTombstoneIterator() functions return nullptr instead of NewEmptyInternalIterator to avoid the allocation. Updated callers accordingly. Closes Differential Revision: D4208169 Pulled By: ajkr fbshipit-source-id: 2fd65cf/Remove Arena in RangeDelAggregator Summary: The Arena construction/destruction introduced significant overhead to read-heavy workload just by creating empty vectors for its blocks, so avoid it in RangeDelAggregator. Closes Differential Revision: D4207781 Pulled By: ajkr fbshipit-source-id: 9d1c130/Report memory usage by memtable insert hints map. Summary: It is hard to measure acutal memory usage by std containers. Even providing a custom allocator will miss count some of the usage. Here we only do a wild guess on its memory usage. Closes Differential Revision: D4179945 Pulled By: yiwu-arbug fbshipit-source-id: 32ab929/Optimize sequential insert into memtable Part 1: Interface Summary: Currently our skip-list have an optimization to speedup sequential inserts from a single stream, by remembering the last insert position. We extend the idea to support sequential inserts from multiple streams, and even tolerate small reordering wihtin each stream. This PR is the interface part adding the following: Add `memtable_insert_prefix_extractor` to allow specifying prefix for each key. Add `InsertWithHint()` interface to memtable, to allow underlying implementation to return a hint of insert position, which can be later pass back to optimize inserts. Memtable will maintain a map from prefix to hints and pass the hint via `InsertWithHint()` if `memtable_insert_prefix_extractor` is non-null. Closes Differential Revision: D4079367 Pulled By: yiwu-arbug fbshipit-source-id: 3555326/"
,,0.092,rocksdb,Allow Users to change customized ldb tools header in help printing Summary: Closes Differential Revision: D4748448 Pulled By: siying fbshipit-source-id: a54c2f9/
,,0.1385,rocksdb,Roundup read bytes in ReadaheadRandomAccessFile Summary: Fix alignment in ReadaheadRandomAccessFile Closes Differential Revision: D5012336 Pulled By: lightmark fbshipit-source-id: 10d2c829520cb787227ef653ef63d5d701725778/readahead backwards from sst end Summary: prefetch some data from the end of the file for each compaction to reduce IO. Closes Differential Revision: D4880576 Pulled By: lightmark fbshipit-source-id: aa767cd1afc84c541837fbf1ad6c0d45b34d3932/alignment is on in ReadaheadRandomAccessFile::Read() Summary: Closes Differential Revision: D4534518 Pulled By: wat-ze-hex fbshipit-source-id: b456946/
,,0.11199999999999999,rocksdb,CoreLocalArray class Summary: Moved the logic for core-local array out of ConcurrentArena and into a separate class because I want to reuse it for core-local stats. Closes Differential Revision: D5011518 Pulled By: ajkr fbshipit-source-id: a75a7b8f7b7a42fd6273489ada405f14c6be196a/
,,0.0919,rocksdb,alignment is on in ReadaheadRandomAccessFile::Read() Summary: Closes Differential Revision: D4534518 Pulled By: wat-ze-hex fbshipit-source-id: b456946/
,,0.1173,rocksdb,"Limit maximum memory used in the WriteBatch representation Summary: Extend TransactionOptions to include max_write_batch_size which determines the maximum size of the writebatch representation. If memory limit is exceeded, the operation will abort with subcode kMemoryLimit. Closes Differential Revision: D4861842 Pulled By: lth fbshipit-source-id: 46fd172ea67cc90bbba829bf0d70cfab2261c161/"
,,0.1082,rocksdb,"add max to histogram stats Summary: Domas enlightened me about p100 (i.e., max) stats. Lets add them to our histograms. Closes Differential Revision: D4678716 Pulled By: ajkr fbshipit-source-id: 65e7118/"
,,0.0897,rocksdb,Support SstFileManager::SetDeleteRateBytesPerSecond() Summary: Update DeleteScheduler component to support changing delete rate in runtime by introducing SstFileManager::SetDeleteRateBytesPerSecond() Closes Differential Revision: D4719906 Pulled By: IslamAbdelRahman fbshipit-source-id: e6b8d9e/
,,0.0869,rocksdb,Add a new SstFileWriter constructor without explicit comparator Summary: The comparator param in SstFileWriter constructor is redundant as it already exists as a field in options. So the current SstFileWriter constructor should be deprecated in favor of a new one which does not take a comparator. Note that the jni/java apis have not been touched yet. Closes Differential Revision: D4685629 Pulled By: sagar0 fbshipit-source-id: 372ce96/
,,0.1513,rocksdb,Blob storage helper methods Summary: Split out interfaces needed for blob storage from including * CompactionEventListener and OnFlushBegin listener interfaces. * Blob filename support. Closes Differential Revision: D4905463 Pulled By: yiwu-arbug fbshipit-source-id: 564e73448f1b7a367e5e46216a521e57ea9011b5/
,,0.0821,rocksdb,Object lifetime in cache Summary: Any non-raw-data dependent object must be destructed before the table closes. There was a bug of not doing that for filter object. This patch fixes the bug and adds a unit test to prevent such bugs in future. Closes Differential Revision: D5001318 Pulled By: maysamyabandeh fbshipit-source-id: 6d8772e58765485868094b92964da82ef9730b6d/
,,0.0869,rocksdb,Added SstFileWriter construtor without explicit comparator to JNI api Summary: Adding API missing after adamretter IslamAbdelRahman Tested locally. Closes Differential Revision: D4762817 Pulled By: IslamAbdelRahman fbshipit-source-id: 833f478/
,,0.0869,rocksdb,Added SstFileWriter construtor without explicit comparator to JNI api Summary: Adding API missing after adamretter IslamAbdelRahman Tested locally. Closes Differential Revision: D4762817 Pulled By: IslamAbdelRahman fbshipit-source-id: 833f478/
,,0.1,rocksdb,Expose DB::DeleteRange and WriteBath::DeleteRange in Java Summary: Added JNI wrapper from `DeleteRange` methods Closes Differential Revision: D4657746 Pulled By: yiwu-arbug fbshipit-source-id: 3fc7ab8/
,,0.1,rocksdb,Expose DB::DeleteRange and WriteBath::DeleteRange in Java Summary: Added JNI wrapper from `DeleteRange` methods Closes Differential Revision: D4657746 Pulled By: yiwu-arbug fbshipit-source-id: 3fc7ab8/
,,0.0917,rocksdb,Added missing options to RocksJava Summary: This adds almost all missing options to RocksJava Closes Differential Revision: D4779991 Pulled By: siying fbshipit-source-id: 4a1bf28/
,,0.0954,rocksdb,Added missing options to RocksJava Summary: This adds almost all missing options to RocksJava Closes Differential Revision: D4779991 Pulled By: siying fbshipit-source-id: 4a1bf28/
,,0.0972,rocksdb,Added missing options to RocksJava Summary: This adds almost all missing options to RocksJava Closes Differential Revision: D4779991 Pulled By: siying fbshipit-source-id: 4a1bf28/
,,0.0894,rocksdb,Allow checkpointing without flushing Summary: Add a parameter to Checkpoint::CreateCheckpoint() so that flush can be skipped if total log file size is within a threshold. Closes Differential Revision: D4719842 Pulled By: siying fbshipit-source-id: 4f9d9e1/
,,0.1504,rocksdb,Blob storage pr Summary: The final pull request for Blob Storage. Closes Differential Revision: D5033189 Pulled By: yiwu-arbug fbshipit-source-id: 6356b683ccd58cbf38a1dc55e2ea400feecd5d06/
,,0.1335,rocksdb,"Limit maximum memory used in the WriteBatch representation Summary: Extend TransactionOptions to include max_write_batch_size which determines the maximum size of the writebatch representation. If memory limit is exceeded, the operation will abort with subcode kMemoryLimit. Closes Differential Revision: D4861842 Pulled By: lth fbshipit-source-id: 46fd172ea67cc90bbba829bf0d70cfab2261c161/Make WriteBatchWithIndex moveble Summary: `WriteBatchWithIndex` has an incorrect implicitly-generated move constructor (it will copy the pointer causing a double-free on destruction). Just switch to `unique_ptr` so we get correct move semantics for free. Closes Differential Revision: D4598896 Pulled By: ajkr fbshipit-source-id: 2373d47/"
,,0.0811,rocksdb,Change Build Env to gcc-5 Summary: Default to build using gcc-5. Only apply to Facebook-only environments. Closes Differential Revision: D4887568 Pulled By: siying fbshipit-source-id: 53496c9af3273ccd44441bd0bef9d29beefbc00b/
,,0.1542,rocksdb,Blob storage pr Summary: The final pull request for Blob Storage. Closes Differential Revision: D5033189 Pulled By: yiwu-arbug fbshipit-source-id: 6356b683ccd58cbf38a1dc55e2ea400feecd5d06/
,,0.1561,rocksdb,Blob storage pr Summary: The final pull request for Blob Storage. Closes Differential Revision: D5033189 Pulled By: yiwu-arbug fbshipit-source-id: 6356b683ccd58cbf38a1dc55e2ea400feecd5d06/
,,0.2157,rocksdb,"Readers for partition filter Summary: This is the last split of this pull request: which includes the reader part as well as the tests. Closes Differential Revision: D4672216 Pulled By: maysamyabandeh fbshipit-source-id: 6a2b829/Builders for partition filter Summary: This is the second split of this pull request: which includes only the builder part. The testing will be included in the third split, where the reader is also included. Closes Differential Revision: D4660272 Pulled By: maysamyabandeh fbshipit-source-id: 36b3cf0/"
,,0.2114,rocksdb,"Readers for partition filter Summary: This is the last split of this pull request: which includes the reader part as well as the tests. Closes Differential Revision: D4672216 Pulled By: maysamyabandeh fbshipit-source-id: 6a2b829/Builders for partition filter Summary: This is the second split of this pull request: which includes only the builder part. The testing will be included in the third split, where the reader is also included. Closes Differential Revision: D4660272 Pulled By: maysamyabandeh fbshipit-source-id: 36b3cf0/"
,,0.1513,rocksdb,Blob storage helper methods Summary: Split out interfaces needed for blob storage from including * CompactionEventListener and OnFlushBegin listener interfaces. * Blob filename support. Closes Differential Revision: D4905463 Pulled By: yiwu-arbug fbshipit-source-id: 564e73448f1b7a367e5e46216a521e57ea9011b5/
,,0.1598,rocksdb,"Limit maximum memory used in the WriteBatch representation Summary: Extend TransactionOptions to include max_write_batch_size which determines the maximum size of the writebatch representation. If memory limit is exceeded, the operation will abort with subcode kMemoryLimit. Closes Differential Revision: D4861842 Pulled By: lth fbshipit-source-id: 46fd172ea67cc90bbba829bf0d70cfab2261c161/Adding comments to the write path Summary: also did minor refactoring Closes Differential Revision: D4855818 Pulled By: maysamyabandeh fbshipit-source-id: fbca6ac57e5c6677fffe8354f7291e596a50cb77/Optionally construct Post Processing Info map in MemTableInserter Summary: MemTableInserter default constructs Post processing info std::map. However, on Windows with 2015 STL the default constructed map still dynamically allocates one node which shows up on a profiler and we loose ~40% throughput on fillrandom benchmark. Solution: declare a map as std::aligned storage and optionally construct. This addresses Before: Initializing RocksDB Options from command-line flags DB path: [k:\data\BulkLoadRandom_10M_fillonly] fillrandom : 2.775 micros/op 360334 ops/sec; 280.4 MB/s Microseconds per write: Count: 10000000 Average: 2.7749 StdDev: 39.92 Min: 1 Median: 2.0826 Max: 26051 Percentiles: P50: 2.08 P75: 2.55 P99: 3.55 P99.9: 9.58 P99.99: 51.5**6 After: Initializing RocksDB Options from command-line flags DB path: [k:\data\BulkLoadRandom_10M_fillon Closes Differential Revision: D4740823 Pulled By: siying fbshipit-source-id: 1daaa2c/"
,,0.09,rocksdb,"change use_direct_writes to use_direct_io_for_flush_and_compaction Summary: Replace Options::use_direct_writes with Options::use_direct_io_for_flush_and_compaction Now if Options::use_direct_io_for_flush_and_compaction true, we will enable direct io for both reads and writes for flush and compaction job. Whereas Options::use_direct_reads controls user reads like iterator and Get(). Closes Differential Revision: D4860912 Pulled By: lightmark fbshipit-source-id: d93575a8a5e780cf7e40797287edc425ee648c19/"
,,0.1083,rocksdb,"Fix repair_test on ROCKSDB_LITE Summary: RepairDB isnt included in rocksdb lite, so dont test it. Closes Differential Revision: D4565094 Pulled By: ajkr fbshipit-source-id: 8cc0898/"
,,0.0901,rocksdb,support bulk loading with universal compaction Summary: Support buck load with universal compaction. More test cases to be added. Closes Differential Revision: D4935360 Pulled By: lightmark fbshipit-source-id: cc3ca1b6f42faa503207dab1408d6bcf393ee5b5/
,,0.1011,rocksdb,"Move MergeOperatorPinning tests to be with other merge operator tests Summary: Moved MergeOperatorPinning tests from db_test2.cc to db_merge_operator_test.cc. [This is the same code as PR , which has already been reviewed, but I am creating a new PR as I cannot import from onto phabricator anymore even after rebasing. Ill close and discard Closes Differential Revision: D4863312 Pulled By: sagar0 fbshipit-source-id: 0f71a7690aa09c1d03ee85ce2bc1d2d89e4f4399/"
,,0.0991,rocksdb,dynamic setting of stats_dump_period_sec through SetDBOption() Summary: Resolved the following issue: Closes Differential Revision: D4736764 Pulled By: yiwu-arbug fbshipit-source-id: 64fe0b7/
,,0.1357,rocksdb,Readers for partition filter Summary: This is the last split of this pull request: which includes the reader part as well as the tests. Closes Differential Revision: D4672216 Pulled By: maysamyabandeh fbshipit-source-id: 6a2b829/
,,0.1299,rocksdb,AIX and Solaris Sparc Support Summary: Replacement of The change was squashed due to a lot of conflicts. Closes Differential Revision: D4929799 Pulled By: siying fbshipit-source-id: 5cd49c254737a1d5ac13f3c035f128e86524c581/
,,0.2099,rocksdb,Blob storage pr Summary: The final pull request for Blob Storage. Closes Differential Revision: D5033189 Pulled By: yiwu-arbug fbshipit-source-id: 6356b683ccd58cbf38a1dc55e2ea400feecd5d06/set compaction_iterator earliest_snapshot to max if no snapshot Summary: It is a potential bug that will be triggered if we ingest files before inserting the first key into an empty db. 0 is a special value reserved to indicate the concept of non-existence. But not good for seqno in this case because 0 is a valid seqno for ingestion(bulk loading) Closes Differential Revision: D4919827 Pulled By: lightmark fbshipit-source-id: 237eea40f88bd6487b66806109d90065dc02c362/Blob storage helper methods Summary: Split out interfaces needed for blob storage from including * CompactionEventListener and OnFlushBegin listener interfaces. * Blob filename support. Closes Differential Revision: D4905463 Pulled By: yiwu-arbug fbshipit-source-id: 564e73448f1b7a367e5e46216a521e57ea9011b5/
,,0.1412,rocksdb,add GetRootDB() in DeleteFilesInRange Summary: In case users cast a subclass of db* into dbimpl* Closes Differential Revision: D4964486 Pulled By: lightmark fbshipit-source-id: 0ccdc08ee8e7a193dfbbe0218c3cbfd795662ca1/call GetRootDB() before cast to DBImpl* in CancelAllBackgroundWork Summary: User could call this with wrapper class of DB or DBImpl Closes Differential Revision: D4935530 Pulled By: lightmark fbshipit-source-id: df9cb61d67d0f3bbcf62f714d77523a459a92883/
,,0.0978,rocksdb,"change use_direct_writes to use_direct_io_for_flush_and_compaction Summary: Replace Options::use_direct_writes with Options::use_direct_io_for_flush_and_compaction Now if Options::use_direct_io_for_flush_and_compaction true, we will enable direct io for both reads and writes for flush and compaction job. Whereas Options::use_direct_reads controls user reads like iterator and Get(). Closes Differential Revision: D4860912 Pulled By: lightmark fbshipit-source-id: d93575a8a5e780cf7e40797287edc425ee648c19/"
,,0.1466,rocksdb,Readers for partition filter Summary: This is the last split of this pull request: which includes the reader part as well as the tests. Closes Differential Revision: D4672216 Pulled By: maysamyabandeh fbshipit-source-id: 6a2b829/
,,0.1339,rocksdb,"Fix build with MinGW Summary: There still are many warnings (most of them about invalid printf format for long long), but it builds if FAIL_ON_WARNINGS is disabled. Closes Differential Revision: D4807355 Pulled By: siying fbshipit-source-id: ef03786/"
,,0.1321,rocksdb,"Fix build with MinGW Summary: There still are many warnings (most of them about invalid printf format for long long), but it builds if FAIL_ON_WARNINGS is disabled. Closes Differential Revision: D4807355 Pulled By: siying fbshipit-source-id: ef03786/"
,,0.1062,rocksdb,LRUCacheShard cache line size alignment Summary: combining and Closes Differential Revision: D5464394 Pulled By: IslamAbdelRahman fbshipit-source-id: 9f71d3058dd6adaf02ce3b2de3a81a1228009778/
,,0.1022,rocksdb,LRUCacheShard cache line size alignment Summary: combining and Closes Differential Revision: D5464394 Pulled By: IslamAbdelRahman fbshipit-source-id: 9f71d3058dd6adaf02ce3b2de3a81a1228009778/
,,0.1227,rocksdb,"LRUCacheShard cache line size alignment Summary: combining and Closes Differential Revision: D5464394 Pulled By: IslamAbdelRahman fbshipit-source-id: 9f71d3058dd6adaf02ce3b2de3a81a1228009778/enable PinnableSlice for RowCache Summary: This patch enables using PinnableSlice for RowCache, changes include not releasing the cache handle immediately after lookup in TableCache::Get, instead pass a Cleanble function which does Cache::RleaseHandle. Closes Differential Revision: D5316216 Pulled By: maysamyabandeh fbshipit-source-id: d2a684bd7e4ba73772f762e58a82b5f4fbd5d362/"
,,0.1554,rocksdb,Avoid unsupported attributes when not building with UBSAN Summary: yiwu-arbug see individual commits. Closes Differential Revision: D5141520 Pulled By: yiwu-arbug fbshipit-source-id: 7987c92ab4461eef36afce5a133d3a0ee0c96300/
,,0.09699999999999999,rocksdb,Address MS Visual Studio 2017 issue with autovector Summary: This addresses Closes Differential Revision: D5097941 Pulled By: siying fbshipit-source-id: fb33582bfe7883ecc3f6da028703982522b5f75f/
,,0.0687,rocksdb,gcc-7/i386: markup intentional fallthroughs Summary: Markup i386 code paths resolving compilation failure under i386 with gcc-7. Signed-off-by: James Page Closes Differential Revision: D5583047 Pulled By: maysamyabandeh fbshipit-source-id: fe31bcfeaf7cd2d3f51b55f5ae0b3b0cb3788fbc/
,,0.1035,rocksdb,Limit trash directory to be 25% of total DB Summary: Update DeleteScheduler to delete files immediately if trash directory is >= 25% of DB size Closes Differential Revision: D5230384 Pulled By: IslamAbdelRahman fbshipit-source-id: 5cbda8ac536a3cc72c774641621edc02c8202482/
,,0.126,rocksdb,"Fix UBSAN issue of passing nullptr to memcmp Summary: As explained in the comments, Sometimes we create Slice(nullptr, 0) in our code base which cause us to do calls like ``` memcmp(nullptr, ""abc"", 0); ``` Thats fine since the len is equal 0, but UBSAN is not happy about it so disable UBSAN for this function and add an assert instead Closes Differential Revision: D5458326 Pulled By: IslamAbdelRahman fbshipit-source-id: cfca32abe30f7d8f760c9f77ecd9543dfb1170dd/"
,,0.1214,rocksdb,"fixed wrong type for ""allow_compaction"" parameter Summary: should be boolean, not uint64_t MSVC complains about it during compilation with error `include\rocksdb\advanced_options.h(77): warning C4800: uint64_t: forcing value to bool true or false (performance warning)` Closes Differential Revision: D5310685 Pulled By: siying fbshipit-source-id: 719a33b3dba4f711aa72e3f229013c188015dc86/"
,,0.1104,rocksdb,"Sample number of reads per SST file Summary: We estimate number of reads per SST files, by updating the counter per file in sampled read requests. This information can later be used to trigger compactions to improve read performacne. Closes Differential Revision: D5193528 Pulled By: siying fbshipit-source-id: b4241c5ad0eaf444b61afb53f8e6290d9f5da2df/"
,,0.1214,rocksdb,expose set_skip_stats_update_on_db_open to C bindings Summary: It would be super helpful to not have to recompile rocksdb to get this performance tweak for mechanical disks. I have signed the CLA. Closes Differential Revision: D5606994 Pulled By: yiwu-arbug fbshipit-source-id: c05e92bad0d03bd38211af1e1ced0d0d1e02f634/C API: support pinnable get Summary: Closes Differential Revision: D5053590 Pulled By: yiwu-arbug fbshipit-source-id: 2f365a031b3a2947b4fba21d26d4f8f52af9b9f0/
,,0.0891,rocksdb,Refactor TransactionDBImpl Summary: This opens space for the new implementations of TransactionDBImpl such as WritePreparedTxnDBImpl that has a different policy of how to write to DB. Closes Differential Revision: D5568918 Pulled By: maysamyabandeh fbshipit-source-id: f7eac866e175daf3793ae79da108f65cc7dc7b25/
,,0.1062,rocksdb,"Revert ""comment out unused parameters"" Summary: This reverts the previous commit 1d7048c5985e60be8e356663ec3cb6d020adb44d, which broke the build. Did a `git revert 1d7048c`. Closes Differential Revision: D5476473 Pulled By: sagar0 fbshipit-source-id: 4756ff5c0dfc88c17eceb00e02c36176de728d06/"
,,0.1048,rocksdb,default implementation for InRange Summary: its confusing to implementors of prefix extractor to implement an unused function Closes Differential Revision: D5267408 Pulled By: ajkr fbshipit-source-id: 2f1fe3131efc978f6098ae7a80e52bc7a0b13571/
,,0.1043,rocksdb,"Revert ""comment out unused parameters"" Summary: This reverts the previous commit 1d7048c5985e60be8e356663ec3cb6d020adb44d, which broke the build. Did a `git revert 1d7048c`. Closes Differential Revision: D5476473 Pulled By: sagar0 fbshipit-source-id: 4756ff5c0dfc88c17eceb00e02c36176de728d06/"
,,0.1353,rocksdb,"support merge and delete in file ingestion Summary: Previously sst_file_writer only supports kTypeValue, we need kTypeMerge and kTypeDeletion also as user requested. Closes Differential Revision: D5139402 Pulled By: lightmark fbshipit-source-id: 092a60756d01692539d817a3765ebfd58a8d7f88/"
,,0.1242,rocksdb,"Java APIs for put, merge and delete in file ingestion Summary: Adding SSTFileWriters newly introduced put, merge and delete apis to the Java api. The C++ APIs were first introduced in Add is deprecated in favor of Put. Merge is especially needed to support streaming for Cassandra-on-RocksDB work in Closes Differential Revision: D5165091 Pulled By: sagar0 fbshipit-source-id: 6f0ad396a7cbd2e27ca63e702584784dd72acaab/"
,,0.1053,rocksdb,Improve the error message for I/O related errors. Summary: Force people to write something other than file name while returning status for IOError. Closes Differential Revision: D5321309 Pulled By: siying fbshipit-source-id: 38bcf6c19e80831cd3e300a047e975cbb131d822/
,,0.1053,rocksdb,Improve the error message for I/O related errors. Summary: Force people to write something other than file name while returning status for IOError. Closes Differential Revision: D5321309 Pulled By: siying fbshipit-source-id: 38bcf6c19e80831cd3e300a047e975cbb131d822/
,,0.0879,rocksdb,fixed typo Summary: fixed typo Closes Differential Revision: D5079631 Pulled By: sagar0 fbshipit-source-id: e4c8d1d89b244ee69e9dea1dd013227cc5241026/
,,0.1571,rocksdb,Avoid unsupported attributes when not building with UBSAN Summary: yiwu-arbug see individual commits. Closes Differential Revision: D5141520 Pulled By: yiwu-arbug fbshipit-source-id: 7987c92ab4461eef36afce5a133d3a0ee0c96300/
,,0.2165,rocksdb,"Update all blob db TTL and timestamps to uint64_t Summary: The current blob db implementation use mix of int32_t, uint32_t and uint64_t for TTL and expiration. Update all timestamps to uint64_t for consistency. Closes Differential Revision: D5557103 Pulled By: yiwu-arbug fbshipit-source-id: e4eab2691629a755e614e8cf1eed9c3a681d0c42/Simple blob file dumper Summary: A simple blob file dumper. Closes Differential Revision: D5097553 Pulled By: yiwu-arbug fbshipit-source-id: c6e00d949fcd3658f9f68da9352f06339fac418d/"
,,0.1102,rocksdb,Simple blob file dumper Summary: A simple blob file dumper. Closes Differential Revision: D5097553 Pulled By: yiwu-arbug fbshipit-source-id: c6e00d949fcd3658f9f68da9352f06339fac418d/
,,0.2058,rocksdb,"Update all blob db TTL and timestamps to uint64_t Summary: The current blob db implementation use mix of int32_t, uint32_t and uint64_t for TTL and expiration. Update all timestamps to uint64_t for consistency. Closes Differential Revision: D5557103 Pulled By: yiwu-arbug fbshipit-source-id: e4eab2691629a755e614e8cf1eed9c3a681d0c42/Update blob db to use ROCKS_LOG_* macro Summary: Update blob db to use the newer ROCKS_LOG_* macro. Closes Differential Revision: D5414526 Pulled By: yiwu-arbug fbshipit-source-id: e428753aa5917e8b435cead2db26df586e5d1def/Improve Status message for block checksum mismatches Summary: Weve got some DBs where iterators return Status with message ""Corruption: block checksum mismatch"" all the time. Thats not very informative. It would be much easier to investigate if the error message contained the file name then we would know e.g. how old the corrupted file is, which would be very useful for finding the root cause. This PR adds file name, offset and other stuff to some block corruption-related status messages. It doesnt improve all the error messages, just a few that were easy to improve. Im mostly interested in ""block checksum mismatch"" and ""Bad table magic number"" since theyre the only corruption errors that Ive ever seen in the wild. Closes Differential Revision: D5345702 Pulled By: al13n321 fbshipit-source-id: fc8023d43f1935ad927cef1b9c55481ab3cb1339/s/std::snprintf/snprintf Summary: Looks like std::snprintf is not available on all platforms (e.g. MSVC 2010). Change it back to snprintf, where we have a macro in port.h to workaround compatibility. Closes Differential Revision: D5070988 Pulled By: yiwu-arbug fbshipit-source-id: bedfc1660bab0431c583ad434b7e68265e1211b1/"
,,0.152,rocksdb,"Dump Blob DB options to info log Summary: * Dump blob db options to info log * Remove BlobDBOptionsImpl to disallow dynamic cast *BlobDBOptions into *BlobDBOptionsImpl. Move options there to be constants or into BlobDBOptions. The dynamic cast is broken after * Change some of the default options * Remove blob_db_options.min_blob_size, which is unimplemented. Will implement it soon. Closes Differential Revision: D5529912 Pulled By: yiwu-arbug fbshipit-source-id: dcd58ca981db5bcc7f123b65a0d6f6ae0dc703c7/"
,,0.162,rocksdb,"Update all blob db TTL and timestamps to uint64_t Summary: The current blob db implementation use mix of int32_t, uint32_t and uint64_t for TTL and expiration. Update all timestamps to uint64_t for consistency. Closes Differential Revision: D5557103 Pulled By: yiwu-arbug fbshipit-source-id: e4eab2691629a755e614e8cf1eed9c3a681d0c42/"
,,0.2533,rocksdb,"Update all blob db TTL and timestamps to uint64_t Summary: The current blob db implementation use mix of int32_t, uint32_t and uint64_t for TTL and expiration. Update all timestamps to uint64_t for consistency. Closes Differential Revision: D5557103 Pulled By: yiwu-arbug fbshipit-source-id: e4eab2691629a755e614e8cf1eed9c3a681d0c42/Blob DB TTL extractor Summary: Introducing blob_db::TTLExtractor to replace extract_ttl_fn. The TTL extractor can be use to extract TTL from keys insert with Put or WriteBatch. Change over existing extract_ttl_fn are: * If value is changed, it will be return via std::string* (rather than Slice*). With Slice* the new value has to be part of the existing value. With std::string* the limitation is removed. * It can optionally return TTL or expiration. Other changes in this PR: * replace `std::chrono::system_clock` with `Env::NowMicros` so that I can mock time in tests. * add several TTL tests. * other minor naming change. Closes Differential Revision: D5512627 Pulled By: yiwu-arbug fbshipit-source-id: 0dfcb00d74d060b8534c6130c808e4d5d0a54440/Simple blob file dumper Summary: A simple blob file dumper. Closes Differential Revision: D5097553 Pulled By: yiwu-arbug fbshipit-source-id: c6e00d949fcd3658f9f68da9352f06339fac418d/"
,,0.2069,rocksdb,"Fix blob DB transaction usage while GC Summary: While GC, blob DB use optimistic transaction to delete or replace the index entry in LSM, to guarantee correctness if theres a normal write writing to the same key. However, the previous implementation doesnt call SetSnapshot() nor use GetForUpdate() of transaction API, instead it do its own sequence number checking before beginning the transaction. A normal write can sneak in after the sequence number check and overwrite the key, and the GC will delete or relocate the old version of the key by mistake. Update the code to property use GetForUpdate() to check the existing index entry. After the patch the sequence number store with each blob record is useless, So Im considering remove the sequence number from blob record, in another patch. Closes Differential Revision: D5589178 Pulled By: yiwu-arbug fbshipit-source-id: 8dc960cd5f4e61b36024ba7c32d05584ce149c24/Update all blob db TTL and timestamps to uint64_t Summary: The current blob db implementation use mix of int32_t, uint32_t and uint64_t for TTL and expiration. Update all timestamps to uint64_t for consistency. Closes Differential Revision: D5557103 Pulled By: yiwu-arbug fbshipit-source-id: e4eab2691629a755e614e8cf1eed9c3a681d0c42/Dump Blob DB options to info log Summary: * Dump blob db options to info log * Remove BlobDBOptionsImpl to disallow dynamic cast *BlobDBOptions into *BlobDBOptionsImpl. Move options there to be constants or into BlobDBOptions. The dynamic cast is broken after * Change some of the default options * Remove blob_db_options.min_blob_size, which is unimplemented. Will implement it soon. Closes Differential Revision: D5529912 Pulled By: yiwu-arbug fbshipit-source-id: dcd58ca981db5bcc7f123b65a0d6f6ae0dc703c7/Blob DB TTL extractor Summary: Introducing blob_db::TTLExtractor to replace extract_ttl_fn. The TTL extractor can be use to extract TTL from keys insert with Put or WriteBatch. Change over existing extract_ttl_fn are: * If value is changed, it will be return via std::string* (rather than Slice*). With Slice* the new value has to be part of the existing value. With std::string* the limitation is removed. * It can optionally return TTL or expiration. Other changes in this PR: * replace `std::chrono::system_clock` with `Env::NowMicros` so that I can mock time in tests. * add several TTL tests. * other minor naming change. Closes Differential Revision: D5512627 Pulled By: yiwu-arbug fbshipit-source-id: 0dfcb00d74d060b8534c6130c808e4d5d0a54440/Fixing blob db sequence number handling Summary: Blob db rely on base db returning sequence number through write batch after DB::Write(). However after recent changes to the write path, DB::Writ()e no longer return sequence number in some cases. Fixing it by have WriteBatchInternal::InsertInto() always encode sequence number into write batch. Stacking on Closes Differential Revision: D5148358 Pulled By: yiwu-arbug fbshipit-source-id: 8bda0aa07b9334ed03ed381548b39d167dc20c33/"
,,0.1639,rocksdb,"Update all blob db TTL and timestamps to uint64_t Summary: The current blob db implementation use mix of int32_t, uint32_t and uint64_t for TTL and expiration. Update all timestamps to uint64_t for consistency. Closes Differential Revision: D5557103 Pulled By: yiwu-arbug fbshipit-source-id: e4eab2691629a755e614e8cf1eed9c3a681d0c42/"
,,0.2962,rocksdb,"Update all blob db TTL and timestamps to uint64_t Summary: The current blob db implementation use mix of int32_t, uint32_t and uint64_t for TTL and expiration. Update all timestamps to uint64_t for consistency. Closes Differential Revision: D5557103 Pulled By: yiwu-arbug fbshipit-source-id: e4eab2691629a755e614e8cf1eed9c3a681d0c42/Dump Blob DB options to info log Summary: * Dump blob db options to info log * Remove BlobDBOptionsImpl to disallow dynamic cast *BlobDBOptions into *BlobDBOptionsImpl. Move options there to be constants or into BlobDBOptions. The dynamic cast is broken after * Change some of the default options * Remove blob_db_options.min_blob_size, which is unimplemented. Will implement it soon. Closes Differential Revision: D5529912 Pulled By: yiwu-arbug fbshipit-source-id: dcd58ca981db5bcc7f123b65a0d6f6ae0dc703c7/Move blob_db/ttl_extractor.h into blob_db/blob_db.h Summary: Move blob_db/ttl_extractor.h into blob_db/blob_db.h Also exclude TTLExtractor from LITE build. Closes Differential Revision: D5520009 Pulled By: yiwu-arbug fbshipit-source-id: 4813dcc272c7cc4bf2cdac285256d9a17d78c7b7/Blob DB TTL extractor Summary: Introducing blob_db::TTLExtractor to replace extract_ttl_fn. The TTL extractor can be use to extract TTL from keys insert with Put or WriteBatch. Change over existing extract_ttl_fn are: * If value is changed, it will be return via std::string* (rather than Slice*). With Slice* the new value has to be part of the existing value. With std::string* the limitation is removed. * It can optionally return TTL or expiration. Other changes in this PR: * replace `std::chrono::system_clock` with `Env::NowMicros` so that I can mock time in tests. * add several TTL tests. * other minor naming change. Closes Differential Revision: D5512627 Pulled By: yiwu-arbug fbshipit-source-id: 0dfcb00d74d060b8534c6130c808e4d5d0a54440/Revert ""comment out unused parameters"" Summary: This reverts the previous commit 1d7048c5985e60be8e356663ec3cb6d020adb44d, which broke the build. Did a `git revert 1d7048c`. Closes Differential Revision: D5476473 Pulled By: sagar0 fbshipit-source-id: 4756ff5c0dfc88c17eceb00e02c36176de728d06/"
,,0.1299,rocksdb,"support merge and delete in file ingestion Summary: Previously sst_file_writer only supports kTypeValue, we need kTypeMerge and kTypeDeletion also as user requested. Closes Differential Revision: D5139402 Pulled By: lightmark fbshipit-source-id: 092a60756d01692539d817a3765ebfd58a8d7f88/"
,,0.1335,rocksdb,"support merge and delete in file ingestion Summary: Previously sst_file_writer only supports kTypeValue, we need kTypeMerge and kTypeDeletion also as user requested. Closes Differential Revision: D5139402 Pulled By: lightmark fbshipit-source-id: 092a60756d01692539d817a3765ebfd58a8d7f88/"
,,0.0814,rocksdb,"Unit Tests for sync, range sync and file close failures Summary: Closes Differential Revision: D5255320 Pulled By: siying fbshipit-source-id: 0080830fa8eb5da6de25e17ba68aee91018c7913/"
,,0.1608,rocksdb,disable direct reads for log and manifest and add direct io to tests Summary: Disable direct reads for log and manifest. Direct reads should not affect sequential_file Also add kDirectIO for option_config_ in db_test_util Closes Differential Revision: D5100261 Pulled By: lightmark fbshipit-source-id: 0ebfd13b93fa1b8f9acae514ac44f8125a05868b/
,,0.1519,rocksdb,Avoid unsupported attributes when not building with UBSAN Summary: yiwu-arbug see individual commits. Closes Differential Revision: D5141520 Pulled By: yiwu-arbug fbshipit-source-id: 7987c92ab4461eef36afce5a133d3a0ee0c96300/
,,0.1692,rocksdb,disable direct reads for log and manifest and add direct io to tests Summary: Disable direct reads for log and manifest. Direct reads should not affect sequential_file Also add kDirectIO for option_config_ in db_test_util Closes Differential Revision: D5100261 Pulled By: lightmark fbshipit-source-id: 0ebfd13b93fa1b8f9acae514ac44f8125a05868b/
,,0.2166,rocksdb,"Add Iterator::Refresh() Summary: Add and implement Iterator::Refresh(). When this function is called, if the super version doesnt change, update the sequence number of the iterator to the latest one and invalidate the iterator. If the super version changed, recreated the whole iterator. This can help users reuse the iterator more easily. Closes Differential Revision: D5464500 Pulled By: siying fbshipit-source-id: f548bd35e85c1efca2ea69273802f6704eba6ba9/Make ""make analyze"" happy Summary: ""make analyze"" is reporting some errors. Its complicated to look but it seems to me that they are all false positive. Anyway, I think cleaning them up is a good idea. Some of the changes are hacky but I dont know a better way. Closes Differential Revision: D5341710 Pulled By: siying fbshipit-source-id: 6070e430e0e41a080ef441e05e8ec827d45efab6/Histogram of number of merge operands Summary: Add a histogram in statistics to help users understand how many merge operands they merge. Closes Differential Revision: D5139983 Pulled By: siying fbshipit-source-id: 61b9ba8ca83f358530a4833d68f0103b56a0e182/Suppress clang-analyzer false positive Summary: Fixing two types of clang-analyzer false positives: * db is deleted and then reopen, and clang-analyzer thinks we are reusing the pointer after it has been deleted. Adding asserts to hint clang-analyzer the pointer is recreated. * ParsedInternalKey is (intentionally) uninitialized. Initialize the struct only when clang-analyzer is running. Closes Differential Revision: D5093801 Pulled By: yiwu-arbug fbshipit-source-id: f51355382098eb3da5ab9f64e094c6d03e6bdf7d/"
,,0.2074,rocksdb,"Add Iterator::Refresh() Summary: Add and implement Iterator::Refresh(). When this function is called, if the super version doesnt change, update the sequence number of the iterator to the latest one and invalidate the iterator. If the super version changed, recreated the whole iterator. This can help users reuse the iterator more easily. Closes Differential Revision: D5464500 Pulled By: siying fbshipit-source-id: f548bd35e85c1efca2ea69273802f6704eba6ba9/disable direct reads for log and manifest and add direct io to tests Summary: Disable direct reads for log and manifest. Direct reads should not affect sequential_file Also add kDirectIO for option_config_ in db_test_util Closes Differential Revision: D5100261 Pulled By: lightmark fbshipit-source-id: 0ebfd13b93fa1b8f9acae514ac44f8125a05868b/"
,,0.1022,rocksdb,LRUCacheShard cache line size alignment Summary: combining and Closes Differential Revision: D5464394 Pulled By: IslamAbdelRahman fbshipit-source-id: 9f71d3058dd6adaf02ce3b2de3a81a1228009778/
,,0.0926,rocksdb,"Core-local statistics Summary: This diff changes `StatisticsImpl` from a thread-local approach to a core-local one. The goal is to perform faster aggregations, particularly for applications that have many threads. There should be no behavior change. Closes Differential Revision: D5016258 Pulled By: ajkr fbshipit-source-id: 7d4d165b4a91d8110f0409d113d1be91f22d31a9/"
,,0.1271,rocksdb,WritePrepared Txn: Refactor conf params Summary: Summary of changes: Move seq_per_batch out of Options Rename concurrent_prepare to two_write_queues Add allocate_seq_only_for_data_ Closes Differential Revision: D6304458 Pulled By: maysamyabandeh fbshipit-source-id: 08e685bfa82bbc41b5b1c5eb7040a8ca6e05e58c/
,,0.1059,rocksdb,regression test for missing init options Summary: test the `DBOptions(const Options&)` and `ColumnFamilyOptions(const Options&)` constructors. Actually thisll work better once we refactor `RandomInitDBOptions` / `RandomInitCFOptions` to use the authoritative sources of struct members: `db_options_type_info` / `cf_options_type_info` (internal task T21804189 for this). Closes Differential Revision: D5817141 Pulled By: ajkr fbshipit-source-id: 8567c20feced9d1751fdf1f4383e2af30f7e3591/
,,0.1193,rocksdb,Overload new[] to properly align LRUCacheShard Summary: Also verify it fixes gcc7 compile failure (see also Closes Differential Revision: D5620348 Pulled By: yiwu-arbug fbshipit-source-id: 87db657ab734f23b1bfaaa9db9b9956d10eaef59/
,,0.2021,rocksdb,"Fix coverity uninitialized fields warnings in lru_cache Summary: Coverity uninitialized member variable warnings in lru_cache Closes Differential Revision: D6173062 Pulled By: sagar0 fbshipit-source-id: 7bcfc653457bd362d46045d06527838c9a6adad6/Fix unstable floating point exception Summary: Fix unstable floating point exception, tested on Windows, 64-bit build. The problem appeared in `SetCapacity()` method at line `high_pri_pool_capacity_ capacity_ * high_pri_pool_ratio_;` `high_pri_pool_ratio_` was not initialized at that moment, because `SetHighPriorityPoolRatio()` is called after `SetCapacity()`. So, `high_pri_pool_ratio_` contained garbage, which caused ""Floating point exception"" sometimes. Closes Differential Revision: D6111161 Pulled By: yiwu-arbug fbshipit-source-id: d170329111ad12b4bf9bbcf37bcb6411523438ae/Circumvent ASAN false positive Summary: Changes: * checks if ASAN mode is on, and uses malloc and free in the constructor and destructor Closes Differential Revision: D5671243 Pulled By: armishra fbshipit-source-id: 8e4ad0f7f163400c4effa8617d3b30134119d802/Overload new[] to properly align LRUCacheShard Summary: Also verify it fixes gcc7 compile failure (see also Closes Differential Revision: D5620348 Pulled By: yiwu-arbug fbshipit-source-id: 87db657ab734f23b1bfaaa9db9b9956d10eaef59/"
,,0.1177,rocksdb,"pass key/value samples through zstd compression dictionary generator Summary: Instead of using samples directly, we now support passing the samples through zstds dictionary generator when `CompressionOptions::zstd_max_train_bytes` is set to nonzero. If set to zero, we will use the samples directly as the dictionary same as before. Note this is the first step of extracted into a separate PR per reviewer request. Closes Differential Revision: D6116891 Pulled By: ajkr fbshipit-source-id: 70ab13cc4c734fa02e554180eed0618b75255497/"
,,0.1196,rocksdb,"Fix PinnableSlice move assignment Summary: After move assignment, we need to re-initialized the moved PinnableSlice. Also update blob_db_impl.cc to not reuse the moved PinnableSlice since it is supposed to be in an undefined state after move. Closes Differential Revision: D6238585 Pulled By: yiwu-arbug fbshipit-source-id: bd99f2e37406c4f7de160c7dee6a2e8126bc224e/PinnableSlice move assignment Summary: Allow `std::move(pinnable_slice)`. Closes Differential Revision: D6036782 Pulled By: yiwu-arbug fbshipit-source-id: 583fb0419a97e437ff530f4305822341cd3381fa/"
,,0.2002,rocksdb,"Add DB::Properties::kEstimateOldestKeyTime Summary: With FIFO compaction we would like to get the oldest data time for monitoring. The problem is we dont have timestamp for each key in the DB. As an approximation, we expose the earliest of sst file ""creation_time"" property. My plan is to override the property with a more accurate value with blob db, where we actually have timestamp. Closes Differential Revision: D5770600 Pulled By: yiwu-arbug fbshipit-source-id: 03833c8f10bbfbee62f8ea5c0d03c0cafb5d853a/"
,,0.0915,rocksdb,"add counter for deletion dropping optimization Summary: add this counter stat to track usage of deletion-dropping optimization. if usage is low, we can delete it to prevent bugs like Closes Differential Revision: D5665421 Pulled By: ajkr fbshipit-source-id: 881befa2d199838dac88709e7b376a43d304e3d4/"
,,0.1814,rocksdb,"Added CompactionFilterFactory support to RocksJava Summary: This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support. Closes Differential Revision: D6012778 Pulled By: sagar0 fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/"
,,0.1884,rocksdb,"Added CompactionFilterFactory support to RocksJava Summary: This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support. Closes Differential Revision: D6012778 Pulled By: sagar0 fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/"
,,0.1936,rocksdb,"Added CompactionFilterFactory support to RocksJava Summary: This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support. Closes Differential Revision: D6012778 Pulled By: sagar0 fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/"
,,0.1866,rocksdb,"Added CompactionFilterFactory support to RocksJava Summary: This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support. Closes Differential Revision: D6012778 Pulled By: sagar0 fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/"
,,0.152,rocksdb,"Added CompactionFilterFactory support to RocksJava Summary: This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support. Closes Differential Revision: D6012778 Pulled By: sagar0 fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/Add iterators SeekForPrev functionality to the java-api Summary: As discussed in , this pull-requests brings the iterators [SeekForPrev()]( functionality to the java-api. It affects all locations in the code where previously only Seek() was supported. All code changes are essentially a copy & paste of the already existing implementations for Seek(). **Please Note**: the changes to the C++ code were applied without fully understanding its effect, so please take a closer look. However, since Seek() and SeekForPrev() provide exactly the same signature, I do not expect any mistake here. The java-tests are extended by new tests for the additional functionality. Compilation (`make rocksdbjavastatic`) and test (`java/make test`) run without errors. Closes Differential Revision: D5721011 Pulled By: sagar0 fbshipit-source-id: c1f951cddc321592c70dd2d32bc04892f3f119f8/"
,,0.0865,rocksdb,DestroyDB API Summary: Expose DestroyDB API in RocksJava. Closes Differential Revision: D5914775 Pulled By: sagar0 fbshipit-source-id: 84af6ea0d2bccdcfb9fe8c07b2f87373f0d5bab6/
,,0.1581,rocksdb,"WritePrepared Txn: Compaction/Flush Summary: Update Compaction/Flush to support WritePreparedTxnDB: Add SnapshotChecker which is a proxy to query WritePreparedTxnDB::IsInSnapshot. Pass SnapshotChecker to DBImpl on WritePreparedTxnDB open. CompactionIterator use it to check if a key has been committed and if it is visible to a snapshot. In CompactionIterator: * check if key has been committed. If not, output uncommitted keys AS-IS. * use SnapshotChecker to check if key is visible to a snapshot when in need. * do not output key with seq 0 if the key is not committed. Closes Differential Revision: D5902907 Pulled By: yiwu-arbug fbshipit-source-id: 945e037fdf0aa652dc5ba0ad879461040baa0320/WritePrepared Txn: Recovery Summary: Recover txns from the WAL. Also added some unit tests. Closes Differential Revision: D5859596 Pulled By: maysamyabandeh fbshipit-source-id: 6424967b231388093b4effffe0a3b1b7ec8caeb0/Add more unit test to write_prepared txns Summary: Closes Differential Revision: D5724173 Pulled By: maysamyabandeh fbshipit-source-id: fb6b782d933fb4be315b1a231a6a67a66fdc9c96/Update WritePrepared with the pseudo code Summary: Implement the main body of WritePrepared pseudo code. This includes PrepareInternal and CommitInternal, as well as AddCommitted which updates the commit map. It also provides a IsInSnapshot method that could be later called form the read path to decide if a version is in the read snapshot or it should other be skipped. This patch lacks unit tests and does not attempt to offer an efficient implementation. The idea is that to have the API specified so that we can work on related tasks in parallel. Closes Differential Revision: D5640021 Pulled By: maysamyabandeh fbshipit-source-id: bfa7a05e8d8498811fab714ce4b9c21530514e1c/"
,,0.1733,rocksdb,"Blob DB: Add compaction filter to remove expired blob index entries Summary: After adding expiration to blob index in we are now able to add a compaction filter to cleanup expired blob index entries. Closes Differential Revision: D6183812 Pulled By: yiwu-arbug fbshipit-source-id: 9cb03267a9702975290e758c9c176a2c03530b83/Blob DB: option to enable garbage collection Summary: Add an option to enable/disable auto garbage collection, where we keep counting how many keys have been evicted by either deletion or compaction and decide whether to garbage collect a blob file. Default disable auto garbage collection for now since the whole logic is not fully tested and we plan to make major change to it. Closes Differential Revision: D6224756 Pulled By: yiwu-arbug fbshipit-source-id: cdf53bdccec96a4580a2b3a342110ad9e8864dfe/Fix memory leak on blob db open Summary: Fixes Closes Differential Revision: D5757527 Pulled By: yiwu-arbug fbshipit-source-id: f495b63700495aeaade30a1da5e3675848f3d72f/"
,,0.1234,rocksdb,Enable MSVC W4 with a few exceptions. Fix warnings and bugs Summary: Closes Differential Revision: D6079011 Pulled By: yiwu-arbug fbshipit-source-id: 988a721e7e7617967859dba71d660fc69f4dff57/
,,0.0974,rocksdb,Make it explicit blob db doesnt support CF Summary: Blob db doesnt currently support column families. Return NotSupported status explicitly. Closes Differential Revision: D5757438 Pulled By: yiwu-arbug fbshipit-source-id: 44de9408fd032c98e8ae337d4db4ed37169bd9fa/
,,0.1309,rocksdb,Enable MSVC W4 with a few exceptions. Fix warnings and bugs Summary: Closes Differential Revision: D6079011 Pulled By: yiwu-arbug fbshipit-source-id: 988a721e7e7617967859dba71d660fc69f4dff57/
,,0.2531,rocksdb,"TableProperty::oldest_key_time defaults to 0 Summary: We dont propagate TableProperty::oldest_key_time on compaction and just write the default value to SST files. It is more natural to default the value to 0. Also revert db_sst_test back to before Closes Differential Revision: D6165702 Pulled By: yiwu-arbug fbshipit-source-id: ca3ce5928d96ae79a5beb12bb7d8c640a71478a0/Add DB::Properties::kEstimateOldestKeyTime Summary: With FIFO compaction we would like to get the oldest data time for monitoring. The problem is we dont have timestamp for each key in the DB. As an approximation, we expose the earliest of sst file ""creation_time"" property. My plan is to override the property with a more accurate value with blob db, where we actually have timestamp. Closes Differential Revision: D5770600 Pulled By: yiwu-arbug fbshipit-source-id: 03833c8f10bbfbee62f8ea5c0d03c0cafb5d853a/"
,,0.2586,rocksdb,"TableProperty::oldest_key_time defaults to 0 Summary: We dont propagate TableProperty::oldest_key_time on compaction and just write the default value to SST files. It is more natural to default the value to 0. Also revert db_sst_test back to before Closes Differential Revision: D6165702 Pulled By: yiwu-arbug fbshipit-source-id: ca3ce5928d96ae79a5beb12bb7d8c640a71478a0/Add DB::Properties::kEstimateOldestKeyTime Summary: With FIFO compaction we would like to get the oldest data time for monitoring. The problem is we dont have timestamp for each key in the DB. As an approximation, we expose the earliest of sst file ""creation_time"" property. My plan is to override the property with a more accurate value with blob db, where we actually have timestamp. Closes Differential Revision: D5770600 Pulled By: yiwu-arbug fbshipit-source-id: 03833c8f10bbfbee62f8ea5c0d03c0cafb5d853a/"
,,0.1985,rocksdb,"Add DB::Properties::kEstimateOldestKeyTime Summary: With FIFO compaction we would like to get the oldest data time for monitoring. The problem is we dont have timestamp for each key in the DB. As an approximation, we expose the earliest of sst file ""creation_time"" property. My plan is to override the property with a more accurate value with blob db, where we actually have timestamp. Closes Differential Revision: D5770600 Pulled By: yiwu-arbug fbshipit-source-id: 03833c8f10bbfbee62f8ea5c0d03c0cafb5d853a/"
,,0.159,rocksdb,"WritePrepared Txn: Refactor conf params Summary: Summary of changes: Move seq_per_batch out of Options Rename concurrent_prepare to two_write_queues Add allocate_seq_only_for_data_ Closes Differential Revision: D6304458 Pulled By: maysamyabandeh fbshipit-source-id: 08e685bfa82bbc41b5b1c5eb7040a8ca6e05e58c/WritePrepared Txn: Optimize for recoverable state Summary: GetCommitTimeWriteBatch is currently used to store some state as part of commit in 2PC. In MyRocks it is specifically used to store some data that would be needed only during recovery. So it is not need to be stored in memtable right after each commit. This patch enables an optimization to write the GetCommitTimeWriteBatch only to the WAL. The batch will be written to memtable during recovery when the WAL is replayed. To cover the case when WAL is deleted after memtable flush, the batch is also buffered and written to memtable right before each memtable flush. Closes Differential Revision: D6148023 Pulled By: maysamyabandeh fbshipit-source-id: 2d09bae5565abe2017c0327421010d5c0d55eaa7/Inform caller when rocksdb is stalling writes Summary: Add a new function in Listener to let the caller know when rocksdb is stalling writes. Closes Differential Revision: D5860124 Pulled By: schischi fbshipit-source-id: ee791606169aa64f772c86f817cebf02624e05e1/WritePrepared Txn: Advance seq one per batch Summary: By default the seq number in DB is increased once per written key. WritePrepared txns requires the seq to be increased once per the entire batch so that the seq would be used as the prepare timestamp by which the transaction is identified. Also we need to increase seq for the commit marker since it would give a unique id to the commit timestamp of transactions. Two unit tests are added to verify our understanding of how the seq should be increased. The recovery path requires much more work and is left to another patch. Closes Differential Revision: D5837843 Pulled By: maysamyabandeh fbshipit-source-id: a08960b93d727e1cf438c254d0c2636fb133cc1c/"
,,0.166,rocksdb,"pass key/value samples through zstd compression dictionary generator Summary: Instead of using samples directly, we now support passing the samples through zstds dictionary generator when `CompressionOptions::zstd_max_train_bytes` is set to nonzero. If set to zero, we will use the samples directly as the dictionary same as before. Note this is the first step of extracted into a separate PR per reviewer request. Closes Differential Revision: D6116891 Pulled By: ajkr fbshipit-source-id: 70ab13cc4c734fa02e554180eed0618b75255497/Inform caller when rocksdb is stalling writes Summary: Add a new function in Listener to let the caller know when rocksdb is stalling writes. Closes Differential Revision: D5860124 Pulled By: schischi fbshipit-source-id: ee791606169aa64f772c86f817cebf02624e05e1/"
,,0.183,rocksdb,"Add DB::Properties::kEstimateOldestKeyTime Summary: With FIFO compaction we would like to get the oldest data time for monitoring. The problem is we dont have timestamp for each key in the DB. As an approximation, we expose the earliest of sst file ""creation_time"" property. My plan is to override the property with a more accurate value with blob db, where we actually have timestamp. Closes Differential Revision: D5770600 Pulled By: yiwu-arbug fbshipit-source-id: 03833c8f10bbfbee62f8ea5c0d03c0cafb5d853a/Make bytes_per_sync and wal_bytes_per_sync mutable Summary: SUMMARY Moves the bytes_per_sync and wal_bytes_per_sync options from immutableoptions to mutable options. Also if wal_bytes_per_sync is changed, the wal file and memtables are flushed. TEST PLAN ran make check all passed Two new tests SetBytesPerSync, SetWalBytesPerSync check that after issuing setoptions with a new value for the var, the db options have the new value. Closes Reviewed By: yiwu-arbug Differential Revision: D5845814 Pulled By: TheRushingWookie fbshipit-source-id: 93b52d779ce623691b546679dcd984a06d2ad1bd/"
,,0.1246,rocksdb,test compaction input-level split range tombstone assumption Summary: One of the core assumptions of DeleteRange is that files containing portions of the same range tombstone are treated as a single unit from the perspective of compaction picker. Need better tests for this. This PR adds the tests for manual compaction. Closes Differential Revision: D5676677 Pulled By: ajkr fbshipit-source-id: 1b4b3382b300ff7048b872911405fdf900e4fbec/fix deleterange with memtable prefix bloom Summary: the range delete tombstones in memtable should be added to the aggregator even when the memtables prefix bloom filter tells us the lookup keys not there. This bug could cause data to temporarily reappear until the memtable containing range deletions is flushed. Reported in Closes Differential Revision: D5639007 Pulled By: ajkr fbshipit-source-id: 04fc6facb6f978340a3f639536f4ca7c0d73dfc9/
,,0.0936,rocksdb,Fix false removal of tombstone issue in FIFO and kCompactionStyleNone Summary: Similar to the bug fixed by FIFO with compaction and kCompactionStyleNone during user customized CompactFiles() with output level to be 0 can suffer from the same problem. Fix it by leveraging the bottommost_level_ flag. Closes Differential Revision: D5626906 Pulled By: siying fbshipit-source-id: 2b148d0461c61dbd986d74655e384419ae442158/
,,0.1215,rocksdb,WritePrepared Txn: Refactor conf params Summary: Summary of changes: Move seq_per_batch out of Options Rename concurrent_prepare to two_write_queues Add allocate_seq_only_for_data_ Closes Differential Revision: D6304458 Pulled By: maysamyabandeh fbshipit-source-id: 08e685bfa82bbc41b5b1c5eb7040a8ca6e05e58c/
,,0.1252,rocksdb,Inform caller when rocksdb is stalling writes Summary: Add a new function in Listener to let the caller know when rocksdb is stalling writes. Closes Differential Revision: D5860124 Pulled By: schischi fbshipit-source-id: ee791606169aa64f772c86f817cebf02624e05e1/
,,0.1196,rocksdb,WritePrepared Txn: Refactor conf params Summary: Summary of changes: Move seq_per_batch out of Options Rename concurrent_prepare to two_write_queues Add allocate_seq_only_for_data_ Closes Differential Revision: D6304458 Pulled By: maysamyabandeh fbshipit-source-id: 08e685bfa82bbc41b5b1c5eb7040a8ca6e05e58c/
,,0.1234,rocksdb,Enable MSVC W4 with a few exceptions. Fix warnings and bugs Summary: Closes Differential Revision: D6079011 Pulled By: yiwu-arbug fbshipit-source-id: 988a721e7e7617967859dba71d660fc69f4dff57/
,,0.2572,rocksdb,"TableProperty::oldest_key_time defaults to 0 Summary: We dont propagate TableProperty::oldest_key_time on compaction and just write the default value to SST files. It is more natural to default the value to 0. Also revert db_sst_test back to before Closes Differential Revision: D6165702 Pulled By: yiwu-arbug fbshipit-source-id: ca3ce5928d96ae79a5beb12bb7d8c640a71478a0/Add DB::Properties::kEstimateOldestKeyTime Summary: With FIFO compaction we would like to get the oldest data time for monitoring. The problem is we dont have timestamp for each key in the DB. As an approximation, we expose the earliest of sst file ""creation_time"" property. My plan is to override the property with a more accurate value with blob db, where we actually have timestamp. Closes Differential Revision: D5770600 Pulled By: yiwu-arbug fbshipit-source-id: 03833c8f10bbfbee62f8ea5c0d03c0cafb5d853a/"
,,0.2116,rocksdb,"Add DB::Properties::kEstimateOldestKeyTime Summary: With FIFO compaction we would like to get the oldest data time for monitoring. The problem is we dont have timestamp for each key in the DB. As an approximation, we expose the earliest of sst file ""creation_time"" property. My plan is to override the property with a more accurate value with blob db, where we actually have timestamp. Closes Differential Revision: D5770600 Pulled By: yiwu-arbug fbshipit-source-id: 03833c8f10bbfbee62f8ea5c0d03c0cafb5d853a/"
,,0.2018,rocksdb,"Add DB::Properties::kEstimateOldestKeyTime Summary: With FIFO compaction we would like to get the oldest data time for monitoring. The problem is we dont have timestamp for each key in the DB. As an approximation, we expose the earliest of sst file ""creation_time"" property. My plan is to override the property with a more accurate value with blob db, where we actually have timestamp. Closes Differential Revision: D5770600 Pulled By: yiwu-arbug fbshipit-source-id: 03833c8f10bbfbee62f8ea5c0d03c0cafb5d853a/"
,,0.145,rocksdb,Move static variables out of the header file Summary: Static variables in header files will be instantiated in every file that includes the header file. This patch moves some of them from options_helper.h to its .cc files. It also moves the static variable out of the offset_of since the template function could also lead to multiple instantiation perhaps due to inlining. Fixes Closes Differential Revision: D6363794 Pulled By: maysamyabandeh fbshipit-source-id: d0a07f061b4d992ab4e0de2706e622131d258fdd/Make DBOption compaction_readahead_size dynamic Summary: Closes Differential Revision: D6056141 Pulled By: miasantreble fbshipit-source-id: 56df1630f464fd56b07d25d38161f699e0528b7f/
,,0.1492,rocksdb,Make Universal compaction options dynamic Summary: Let me know if more test coverage is needed Closes Differential Revision: D6457165 Pulled By: miasantreble fbshipit-source-id: 3f944abff28aa7775237f1c4f61c64ccbad4eea9/Move static variables out of the header file Summary: Static variables in header files will be instantiated in every file that includes the header file. This patch moves some of them from options_helper.h to its .cc files. It also moves the static variable out of the offset_of since the template function could also lead to multiple instantiation perhaps due to inlining. Fixes Closes Differential Revision: D6363794 Pulled By: maysamyabandeh fbshipit-source-id: d0a07f061b4d992ab4e0de2706e622131d258fdd/
,,0.1178,rocksdb,Add a BlockBasedTableOption to turn off index block compression. Summary: Add a new bool option index_uncompressed in BlockBasedTableOptions. Closes Differential Revision: D6686161 Pulled By: anand1976 fbshipit-source-id: 748b46993d48a01e5f89b6bd3e41f06a59ec6054/
,,0.2227,rocksdb,"Blob DB: miscellaneous changes Summary: * Expose garbage collection related options * Minor logging and counter name update * Remove unused constants. Closes Differential Revision: D6867077 Pulled By: yiwu-arbug fbshipit-source-id: 6c3272a9c9d78b125a0bd6b2e56d00d087cdd6c8/Add a histogram stat for memtable flush Summary: Add a new histogram stat called rocksdb.db.flush.micros for memtable flush Closes Differential Revision: D6559496 Pulled By: anand1976 fbshipit-source-id: f5c771ba2568630458751795e8c37a493ff9b14d/Blob DB: Add statistics Summary: Adding a list of blob db counters. Also remove WaStats() which doesnt expose the stats and can be substitute by (BLOB_DB_BYTES_WRITTEN / BLOB_DB_BLOB_FILE_BYTES_WRITTEN). Closes Differential Revision: D6394216 Pulled By: yiwu-arbug fbshipit-source-id: 017508c8ff3fcd7ea7403c64d0f9834b24816803/Add a ticker stat for number of keys skipped during iteration Summary: This diff adds a new ticker stat, NUMBER_ITER_SKIP, to count the number of internal keys skipped during iteration. Keys can be skipped due to deletes, or lower sequence number, or higher sequence number than the one requested. Also, fix the issue when StatisticsData is naturally aligned on cacheline boundary, padding becomes a zero size array, which the Windows compiler doesnt like. So add a cacheline worth of padding in that case to keep it happy. We cannot conditionally add padding as gcc doesnt allow using sizeof in preprocessor directives. Closes Differential Revision: D6353897 Pulled By: anand1976 fbshipit-source-id: 441d5a09af9c4e22e7355242dfc0c7b27aa0a6c2/"
,,0.1667,rocksdb,Blob DB: Add statistics Summary: Adding a list of blob db counters. Also remove WaStats() which doesnt expose the stats and can be substitute by (BLOB_DB_BYTES_WRITTEN / BLOB_DB_BLOB_FILE_BYTES_WRITTEN). Closes Differential Revision: D6394216 Pulled By: yiwu-arbug fbshipit-source-id: 017508c8ff3fcd7ea7403c64d0f9834b24816803/
,,0.2071,rocksdb,"Blob DB: fix crash when DB full but no candidate file to evict Summary: When blob_files is empty, std::min_element will return blobfiles.end(), which cannot be dereference. Fixing it. Closes Differential Revision: D6764927 Pulled By: yiwu-arbug fbshipit-source-id: 86f78700132be95760d35ac63480dfd3a8bbe17a/Blob DB: Add statistics Summary: Adding a list of blob db counters. Also remove WaStats() which doesnt expose the stats and can be substitute by (BLOB_DB_BYTES_WRITTEN / BLOB_DB_BLOB_FILE_BYTES_WRITTEN). Closes Differential Revision: D6394216 Pulled By: yiwu-arbug fbshipit-source-id: 017508c8ff3fcd7ea7403c64d0f9834b24816803/"
,,0.2037,rocksdb,Blob DB: dump blob_db_options.min_blob_size Summary: min_blob_size was missing from BlobDBOptions::Dump. Closes Differential Revision: D6781525 Pulled By: yiwu-arbug fbshipit-source-id: 40d9b391578d7f8c91bd89f4ce2eda5064864c25/Blob DB: Add statistics Summary: Adding a list of blob db counters. Also remove WaStats() which doesnt expose the stats and can be substitute by (BLOB_DB_BYTES_WRITTEN / BLOB_DB_BLOB_FILE_BYTES_WRITTEN). Closes Differential Revision: D6394216 Pulled By: yiwu-arbug fbshipit-source-id: 017508c8ff3fcd7ea7403c64d0f9834b24816803/
,,0.1648,rocksdb,Blob DB: Add statistics Summary: Adding a list of blob db counters. Also remove WaStats() which doesnt expose the stats and can be substitute by (BLOB_DB_BYTES_WRITTEN / BLOB_DB_BLOB_FILE_BYTES_WRITTEN). Closes Differential Revision: D6394216 Pulled By: yiwu-arbug fbshipit-source-id: 017508c8ff3fcd7ea7403c64d0f9834b24816803/
,,0.1366,rocksdb,"BlobDB: refactor DB open logic Summary: Refactor BlobDB open logic. List of changes: Major: * On reopen, mark blob files found as immutable, do not use them for writing new keys. * Not to scan the whole file to find file footer. Instead just seek to the end of the file and try to read footer. Minor: * Move most of the real logic from blob_db.cc to blob_db_impl.cc. * Not to hold shared_ptr of event listeners in global maps in blob_db.cc * Some changes to BlobFile interface. * Improve logging and error handling. Closes Differential Revision: D6526147 Pulled By: yiwu-arbug fbshipit-source-id: 9dc4cdd63359a2f9b696af817086949da8d06952/Blob DB: Add statistics Summary: Adding a list of blob db counters. Also remove WaStats() which doesnt expose the stats and can be substitute by (BLOB_DB_BYTES_WRITTEN / BLOB_DB_BLOB_FILE_BYTES_WRITTEN). Closes Differential Revision: D6394216 Pulled By: yiwu-arbug fbshipit-source-id: 017508c8ff3fcd7ea7403c64d0f9834b24816803/"
,,0.1612,rocksdb,Blob DB: Add statistics Summary: Adding a list of blob db counters. Also remove WaStats() which doesnt expose the stats and can be substitute by (BLOB_DB_BYTES_WRITTEN / BLOB_DB_BLOB_FILE_BYTES_WRITTEN). Closes Differential Revision: D6394216 Pulled By: yiwu-arbug fbshipit-source-id: 017508c8ff3fcd7ea7403c64d0f9834b24816803/
,,0.1648,rocksdb,Blob DB: Add statistics Summary: Adding a list of blob db counters. Also remove WaStats() which doesnt expose the stats and can be substitute by (BLOB_DB_BYTES_WRITTEN / BLOB_DB_BLOB_FILE_BYTES_WRITTEN). Closes Differential Revision: D6394216 Pulled By: yiwu-arbug fbshipit-source-id: 017508c8ff3fcd7ea7403c64d0f9834b24816803/
,,0.0712,rocksdb,Refactor ReadBlockContents() Summary: Divide ReadBlockContents() to multiple sub-functions. Maintaining the input and intermediate data in a new class BlockFetcher. I hope in general it makes the code easier to maintain. Another motivation to do it is to clearly divide the logic before file reading and after file reading. The refactor will help us evaluate how can we make I/O async in the future. Closes Differential Revision: D6520983 Pulled By: siying fbshipit-source-id: 338d90bc0338472d46be7a7682028dc9114b12e9/
,,0.1093,rocksdb,"Tests for dynamic universal compaction options Summary: Added a test for three dynamic universal compaction options, in the realm of read amplification: size_ratio min_merge_width max_merge_width Also updated DynamicUniversalCompactionSizeAmplification by adding a check on compaction reason. Found a bug in compaction reason setting while working on this PR, and fixed in . TODO for later: Still to add tests for these options: compression_size_percent, stop_style and trivial_move. Closes Differential Revision: D6822217 Pulled By: sagar0 fbshipit-source-id: 074573fca6389053cbac229891a0163f38bb56c4/Make Universal compaction options dynamic Summary: Let me know if more test coverage is needed Closes Differential Revision: D6457165 Pulled By: miasantreble fbshipit-source-id: 3f944abff28aa7775237f1c4f61c64ccbad4eea9/"
,,0.1004,rocksdb,Make Universal compaction options dynamic Summary: Let me know if more test coverage is needed Closes Differential Revision: D6457165 Pulled By: miasantreble fbshipit-source-id: 3f944abff28aa7775237f1c4f61c64ccbad4eea9/
,,0.1043,rocksdb,Make DBOption compaction_readahead_size dynamic Summary: Closes Differential Revision: D6056141 Pulled By: miasantreble fbshipit-source-id: 56df1630f464fd56b07d25d38161f699e0528b7f/
,,0.114,rocksdb,Make DBOption compaction_readahead_size dynamic Summary: Closes Differential Revision: D6056141 Pulled By: miasantreble fbshipit-source-id: 56df1630f464fd56b07d25d38161f699e0528b7f/
,,0.1983,rocksdb,"WritePrepared Txn: Fix DBIterator and add test Summary: In DBIter, Prev() calls FindValueForCurrentKey() to search the current value backward. If it finds that there are too many stale value being skipped, it falls back to FindValueForCurrentKeyUsingSeek(), seeking directly to the key with snapshot sequence. After introducing read_callback, however, the key it seeks to might not be visible, according to read_callback. It thus needs to keep searching forward until the first visible value. Closes Differential Revision: D6756148 Pulled By: yiwu-arbug fbshipit-source-id: 064e39b1eec5e083af1c10142600f26d1d2697be/Make iterator invalid on Merge error Summary: Since on merge error, iterator will be set to corrupted status, but it doesnt invalidate the iterator. Fixing it. Closes Differential Revision: D6499094 Pulled By: yiwu-arbug fbshipit-source-id: 80222930f949e31f90a6feaa37ddc3529b510d2c/fix Seek with lower_bound Summary: When Seek a key less than `lower_bound`, should return `lower_bound`. ajkr PTAL Closes Differential Revision: D6421126 Pulled By: ajkr fbshipit-source-id: a06c825830573e0040630704f6bcb3f7f48626f7/Add a ticker stat for number of keys skipped during iteration Summary: This diff adds a new ticker stat, NUMBER_ITER_SKIP, to count the number of internal keys skipped during iteration. Keys can be skipped due to deletes, or lower sequence number, or higher sequence number than the one requested. Also, fix the issue when StatisticsData is naturally aligned on cacheline boundary, padding becomes a zero size array, which the Windows compiler doesnt like. So add a cacheline worth of padding in that case to keep it happy. We cannot conditionally add padding as gcc doesnt allow using sizeof in preprocessor directives. Closes Differential Revision: D6353897 Pulled By: anand1976 fbshipit-source-id: 441d5a09af9c4e22e7355242dfc0c7b27aa0a6c2/"
,,0.1599,rocksdb,"WritePrepared Txn: update compaction_iterator_test and db_iterator_test Summary: Update compaction_iterator_test with write-prepared transaction DB related tests. Transaction related tests are group in CompactionIteratorWithSnapshotCheckerTest. The existing test are duplicated to make them also test with dummy SnapshotChecker that will say every key is visible to every snapshot (this is okay, we still compare sequence number to verify visibility). Merge related tests are disabled and will be revisit in another PR. Existing db_iterator_tests are also duplicated to test with dummy read_callback that will say every key is committed. Closes Differential Revision: D6909253 Pulled By: yiwu-arbug fbshipit-source-id: 2ae4656b843a55e2e9ff8beecf21f2832f96cd25/WritePrepared Txn: Fix DBIterator and add test Summary: In DBIter, Prev() calls FindValueForCurrentKey() to search the current value backward. If it finds that there are too many stale value being skipped, it falls back to FindValueForCurrentKeyUsingSeek(), seeking directly to the key with snapshot sequence. After introducing read_callback, however, the key it seeks to might not be visible, according to read_callback. It thus needs to keep searching forward until the first visible value. Closes Differential Revision: D6756148 Pulled By: yiwu-arbug fbshipit-source-id: 064e39b1eec5e083af1c10142600f26d1d2697be/Add a ticker stat for number of keys skipped during iteration Summary: This diff adds a new ticker stat, NUMBER_ITER_SKIP, to count the number of internal keys skipped during iteration. Keys can be skipped due to deletes, or lower sequence number, or higher sequence number than the one requested. Also, fix the issue when StatisticsData is naturally aligned on cacheline boundary, padding becomes a zero size array, which the Windows compiler doesnt like. So add a cacheline worth of padding in that case to keep it happy. We cannot conditionally add padding as gcc doesnt allow using sizeof in preprocessor directives. Closes Differential Revision: D6353897 Pulled By: anand1976 fbshipit-source-id: 441d5a09af9c4e22e7355242dfc0c7b27aa0a6c2/"
,,0.1561,rocksdb,Print out compression type of new SST files in logging Summary: Closes Differential Revision: D6552768 Pulled By: siying fbshipit-source-id: 6303110aff22f341d5cff41f8d2d4f138a53652d/Make DBOption compaction_readahead_size dynamic Summary: Closes Differential Revision: D6056141 Pulled By: miasantreble fbshipit-source-id: 56df1630f464fd56b07d25d38161f699e0528b7f/
,,0.1302,rocksdb,make MockTimeEnv::current_time_ atomic to fix data race Summary: fix a new TSAN failure Closes Differential Revision: D7565310 Pulled By: miasantreble fbshipit-source-id: f672c96e925797b34dec6e20b59527e8eebaa825/Fix up backupable_db stack corruption. Summary: Fix up OACR(Lint) warnings. Closes Differential Revision: D7563869 Pulled By: ajkr fbshipit-source-id: 8c1e5045c8a6a2d85b2933fdbc60fde93bf0c9de/
,,0.19399999999999998,rocksdb,comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/
,,0.2111,rocksdb,comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/Comment out unused variables Summary: Submitting on behalf of another employee. Closes Differential Revision: D7146025 Pulled By: ajkr fbshipit-source-id: 495ca5db5beec3789e671e26f78170957704e77e/
,,0.0977,rocksdb,"Sync parent directory after deleting a file in delete scheduler Summary: sync parent directory after deleting a file in delete scheduler. Otherwise, trim speed may not be as smooth as what we want. Closes Differential Revision: D7760136 Pulled By: siying fbshipit-source-id: ec131d53b61953f09c60d67e901e5eeb2716b05f/"
,,0.1048,rocksdb,"Enable cancelling manual compactions if they hit the sfm size limit Summary: Manual compactions should be cancelled, just like scheduled compactions are cancelled, if sfm->EnoughRoomForCompaction is not true. Closes Differential Revision: D7457683 Pulled By: amytai fbshipit-source-id: 669b02fdb707f75db576d03d2c818fb98d1876f5/"
,,0.1038,rocksdb,Comment out unused variables Summary: Submitting on behalf of another employee. Closes Differential Revision: D7146025 Pulled By: ajkr fbshipit-source-id: 495ca5db5beec3789e671e26f78170957704e77e/
,,0.1038,rocksdb,Comment out unused variables Summary: Submitting on behalf of another employee. Closes Differential Revision: D7146025 Pulled By: ajkr fbshipit-source-id: 495ca5db5beec3789e671e26f78170957704e77e/
,,0.1038,rocksdb,Comment out unused variables Summary: Submitting on behalf of another employee. Closes Differential Revision: D7146025 Pulled By: ajkr fbshipit-source-id: 495ca5db5beec3789e671e26f78170957704e77e/
,,0.1038,rocksdb,Comment out unused variables Summary: Submitting on behalf of another employee. Closes Differential Revision: D7146025 Pulled By: ajkr fbshipit-source-id: 495ca5db5beec3789e671e26f78170957704e77e/
,,0.1038,rocksdb,Comment out unused variables Summary: Submitting on behalf of another employee. Closes Differential Revision: D7146025 Pulled By: ajkr fbshipit-source-id: 495ca5db5beec3789e671e26f78170957704e77e/
,,0.17,rocksdb,"comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/Java wrapper for Native Comparators Summary: This is an abstraction for working with custom Comparators implemented in native C++ code from Java. Native code must directly extend `rocksdb::Comparator`. When the native code comparator is compiled into the RocksDB codebase, you can then create a Java Class, and JNI stub to wrap it. Useful if the C++/JNI barrier overhead is too much for your applications comparator performance. An example is provided in `java/rocksjni/native_comparator_wrapper_test.cc` and `java/src/main/java/org/rocksdb/NativeComparatorWrapperTest.java`. Closes Differential Revision: D7172605 Pulled By: miasantreble fbshipit-source-id: e24b7eb267a3bcb6afa214e0379a1d5e8a2ceabe/"
,,0.1885,rocksdb,comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/
,,0.1687,rocksdb,"comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/Java wrapper for Native Comparators Summary: This is an abstraction for working with custom Comparators implemented in native C++ code from Java. Native code must directly extend `rocksdb::Comparator`. When the native code comparator is compiled into the RocksDB codebase, you can then create a Java Class, and JNI stub to wrap it. Useful if the C++/JNI barrier overhead is too much for your applications comparator performance. An example is provided in `java/rocksjni/native_comparator_wrapper_test.cc` and `java/src/main/java/org/rocksdb/NativeComparatorWrapperTest.java`. Closes Differential Revision: D7172605 Pulled By: miasantreble fbshipit-source-id: e24b7eb267a3bcb6afa214e0379a1d5e8a2ceabe/"
,,0.1792,rocksdb,"comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/Java wrapper for Native Comparators Summary: This is an abstraction for working with custom Comparators implemented in native C++ code from Java. Native code must directly extend `rocksdb::Comparator`. When the native code comparator is compiled into the RocksDB codebase, you can then create a Java Class, and JNI stub to wrap it. Useful if the C++/JNI barrier overhead is too much for your applications comparator performance. An example is provided in `java/rocksjni/native_comparator_wrapper_test.cc` and `java/src/main/java/org/rocksdb/NativeComparatorWrapperTest.java`. Closes Differential Revision: D7172605 Pulled By: miasantreble fbshipit-source-id: e24b7eb267a3bcb6afa214e0379a1d5e8a2ceabe/"
,,0.1831,rocksdb,comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/
,,0.0956,rocksdb,Brings the Java API for WriteBatch inline with the C++ API Summary: * Exposes status * Corrects some method naming * Adds missing functionality Closes Differential Revision: D7140790 Pulled By: sagar0 fbshipit-source-id: cbdab6c5a7ae4f3030fb46739e9060e381b26fa6/
,,0.0822,rocksdb,"Add a stat for MultiGet keys found, update memtable hit/miss stats Summary: 1. Add a new ticker stat rocksdb.number.multiget.keys.found to track the number of keys successfully read 2. Update rocksdb.memtable.hit/miss in DBImpl::MultiGet(). It was being done in DBImpl::GetImpl(), but not MultiGet Closes Differential Revision: D7677364 Pulled By: anand1976 fbshipit-source-id: af22bd0ef8ddc5cf2b4244b0a024e539fe48bca5/"
,,0.1038,rocksdb,Comment out unused variables Summary: Submitting on behalf of another employee. Closes Differential Revision: D7146025 Pulled By: ajkr fbshipit-source-id: 495ca5db5beec3789e671e26f78170957704e77e/
,,0.0992,rocksdb,Fix build with USE_RTTI=0 Summary: utilities/column_aware_encoding_util.cc:61:23: error: cannot use dynamic_cast with table_reader_.reset(dynamic_cast<BlockBasedTable*>(table_reader.release())); ^ 1 error generated. It was added as a [local patch]( on FreeBSD since RocksDB 5.8. It also fixes Closes Differential Revision: D7005571 Pulled By: siying fbshipit-source-id: 351a9055d21d0accdd7a932e8e7bfcd3c8e22068/
,,0.115,rocksdb,Blob DB: blob_dump to show uncompressed values Summary: Make blob_dump tool able to show uncompressed values if the blob file is compressed. Also show total compressed vs. raw size at the end if is provided. Closes Differential Revision: D7348926 Pulled By: yiwu-arbug fbshipit-source-id: ca709cb4ed5cf6a550ff2987df8033df81516f8e/
,,0.08,rocksdb,Ignore empty filter block when data block is empty Summary: Close Closes Differential Revision: D7291706 Pulled By: ajkr fbshipit-source-id: 9dd8f40bd7716588e1e3fd6be0c2bc2766861f8c/
,,0.1903,rocksdb,comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/
,,0.1922,rocksdb,comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/
,,0.1794,rocksdb,comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/
,,0.2179,rocksdb,comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/Comment out unused variables Summary: Submitting on behalf of another employee. Closes Differential Revision: D7146025 Pulled By: ajkr fbshipit-source-id: 495ca5db5beec3789e671e26f78170957704e77e/
,,0.1042,rocksdb,Use nullptr instead of NULL / 0 more consistently. Summary: Closes Differential Revision: D7170968 Pulled By: yiwu-arbug fbshipit-source-id: 308a6b7dd358a04fd9a7de3d927bfd8abd57d348/
,,0.1314,rocksdb,"Improve accuracy of I/O stats collection of external SST ingestion. Summary: RocksDB supports ingestion of external ssts. If ingestion_options.move_files is true, when performing ingestion, RocksDB first tries to link external ssts. If external SST file resides on a different FS, or the underlying FS does not support hard link, then RocksDB performs actual file copy. However, no matter which choice is made, current code increase bytes-written when updating compaction stats, which is inaccurate when RocksDB does NOT copy file. Rename a sync point. Closes Differential Revision: D7604151 Pulled By: riversand963 fbshipit-source-id: dd0c0d9b9a69c7d9ffceafc3d9c23371aa413586/"
,,0.1254,rocksdb,"Add max_subcompactions as a compaction option Summary: Sometimes we want to compact files as fast as possible, but dont want to set a large `max_subcompactions` in the `DBOptions` by default. I add a `max_subcompactions` options to `CompactionOptions` so that we can choose a proper concurrency dynamically. Closes Differential Revision: D7792357 Pulled By: ajkr fbshipit-source-id: 94f54c3784dce69e40a229721a79a97e80cd6a6c/"
,,0.0858,rocksdb,"Avoid adding tombstones of the same file to RangeDelAggregator multiple times Summary: RangeDelAggregator will remember the files whose range tombstones have been added, so the caller can check whether the file has been added before call AddTombstones. Closes Differential Revision: D7354604 Pulled By: ajkr fbshipit-source-id: 9b9f7ec130556028df417e650711554b46d8d107/"
,,0.1038,rocksdb,Comment out unused variables Summary: Submitting on behalf of another employee. Closes Differential Revision: D7146025 Pulled By: ajkr fbshipit-source-id: 495ca5db5beec3789e671e26f78170957704e77e/
,,0.0858,rocksdb,"Avoid adding tombstones of the same file to RangeDelAggregator multiple times Summary: RangeDelAggregator will remember the files whose range tombstones have been added, so the caller can check whether the file has been added before call AddTombstones. Closes Differential Revision: D7354604 Pulled By: ajkr fbshipit-source-id: 9b9f7ec130556028df417e650711554b46d8d107/"
,,0.19399999999999998,rocksdb,comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/
,,0.1752,rocksdb,"Add max_subcompactions as a compaction option Summary: Sometimes we want to compact files as fast as possible, but dont want to set a large `max_subcompactions` in the `DBOptions` by default. I add a `max_subcompactions` options to `CompactionOptions` so that we can choose a proper concurrency dynamically. Closes Differential Revision: D7792357 Pulled By: ajkr fbshipit-source-id: 94f54c3784dce69e40a229721a79a97e80cd6a6c/Comment out unused variables Summary: Submitting on behalf of another employee. Closes Differential Revision: D7146025 Pulled By: ajkr fbshipit-source-id: 495ca5db5beec3789e671e26f78170957704e77e/"
,,0.1038,rocksdb,Comment out unused variables Summary: Submitting on behalf of another employee. Closes Differential Revision: D7146025 Pulled By: ajkr fbshipit-source-id: 495ca5db5beec3789e671e26f78170957704e77e/
,,0.1038,rocksdb,Comment out unused variables Summary: Submitting on behalf of another employee. Closes Differential Revision: D7146025 Pulled By: ajkr fbshipit-source-id: 495ca5db5beec3789e671e26f78170957704e77e/
,,0.1922,rocksdb,comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/
,,0.1508,rocksdb,"MaxFileSizeForLevel: adjust max_file_size for dynamic level compaction Summary: `MutableCFOptions::RefreshDerivedOptions` always assume base level is L1, which is not true when `level_compaction_dynamic_level_bytes=true` and Level based compaction is used. This PR fixes this by recomputing `max_file_size` at query time (in `MaxFileSizeForLevel`) Fixes In master: ``` Level Files Size(MB) 0 14 846 1 0 0 2 0 0 3 0 0 4 0 0 5 15 366 6 11 481 Cumulative compaction: 3.83 GB write, 2.27 GB read ``` In branch: ``` Level Files Size(MB) 0 9 544 1 0 0 2 0 0 3 0 0 4 0 0 5 0 0 6 445 935 Cumulative compaction: 2.91 GB write, 1.46 GB read ``` db_bench command used: ``` ./db_bench ``` Closes Differential Revision: D7721381 Pulled By: miasantreble fbshipit-source-id: 39afb8503190bac3b466adf9bbf2a9b3655789f8/comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/Throw NoSpace instead of IOError when out of space. Summary: Replaces and is updated from feedback. Closes Differential Revision: D7457395 Pulled By: gfosco fbshipit-source-id: 25a21dd8cfa5a6e42e024208b444d9379d920c82/uint64_t and size_t changes to compile for iOS Summary: In attempting to build a static lib for use in iOS, I ran in to lots of type errors between uint64_t and size_t. This PR contains the changes I made to get `TARGET_OS=IOS make static_lib` to succeed while also getting Xcode to build successfully with the resulting `librocksdb.a` library imported. This also compiles for me on macOS and tests fine, but Im really not sure if I made the correct decisions about where to `static_cast` and where to change types. Also up for discussion: is iOS worth supporting? Getting the static lib is just part one, we arent providing any bridging headers or wrappers like the ObjectiveRocks project, it wont be a great experience. Closes Differential Revision: D7106457 Pulled By: gfosco fbshipit-source-id: 82ac2073de7e1f09b91f6b4faea91d18bd311f8e/Blob DB: remove existing garbage collection implementation Summary: Red diff to remove existing implementation of garbage collection. The current approach is reference counting kind of approach and require a lot of effort to get the size counter right on compaction and deletion. Im going to go with a simple mark-sweep kind of approach and will send another PR for that. CompactionEventListener was added solely for blob db and it adds complexity and overhead to compaction iterator. Removing it as well. Closes Differential Revision: D7130190 Pulled By: yiwu-arbug fbshipit-source-id: c3a375ad2639a3f6ed179df6eda602372cc5b8df/"
,,0.0863,rocksdb,"CloseHandle docs says that the return is non-zero, does not say TRUE(1) Summary: say it is TRUE(1). Add assert. Closes Differential Revision: D7346895 Pulled By: ajkr fbshipit-source-id: a46075aa4dd89f32520230606adecccecc874cdf/"
,,0.2296,rocksdb,"Implement Env::NumFileLinks (#4221) Summary: Although delete scheduler implementation allows for the interface not to be supported, the delete_scheduler_test does not allow for that. Address compiler warnings Make sst_dump_test use test directory structure as the current execution directory may not be writiable. Pull Request resolved: Differential Revision: D9210152 Pulled By: siying fbshipit-source-id: 381a74511e969ecb8089d5c4b4df87dc30c8df63/Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.1619,rocksdb,"Add file name info to SequentialFileReader. (#4026) Summary: We potentially need this information for tracing, profiling and diagnosis. Closes Differential Revision: D8555214 Pulled By: riversand963 fbshipit-source-id: 4263e06c00b6d5410b46aa46eb4e358ff2161dd2/"
,,0.1685,rocksdb,"Generalize parameters generation. (#4046) Summary: Making generation of column families and keys virtual function so that subclasses of StressTest can override them to provide custom parameter generation for more flexibility. This will be useful for future tests. Pull Request resolved: Differential Revision: D9073382 Pulled By: riversand963 fbshipit-source-id: 2754f0fdfa5c24d95c1f92d4944bc479552fb665/Reclaim memory allocated to backup_engine. Summary: Closes Differential Revision: D8595609 Pulled By: riversand963 fbshipit-source-id: 5ba5954d804b82b0e7264b2e18e1da4c94103b53/Support file ingestion in stress test (#4018) Summary: Once per `ingest_external_file_one_in` operations, uses SstFileWriter to create a file containing `ingest_external_file_width` consecutive keys. The file is named containing the thread ID to avoid clashes. The file is then added to the DB using `IngestExternalFile`. We cant enable it by default in crash test because `nooverwritepercent` and `test_batches_snapshot` both must be zero for the DBs whole lifetime. Perhaps we should setup a separate test with that config as range deletion also requires it. Closes Differential Revision: D8507698 Pulled By: ajkr fbshipit-source-id: 1437ea26fd989349a9ce8b94117241c65e40f10f/Support backup and checkpoint in db_stress (#4005) Summary: Add the `backup_one_in` and `checkpoint_one_in` options to periodically trigger backups and checkpoints. The directory names contain thread ID to avoid clashing with parallel backups/checkpoints. Enable checkpoint in crash test so our CI runs will use it. Didnt enable backup in crash test since it copies all the files which is too slow. Closes Differential Revision: D8472275 Pulled By: ajkr fbshipit-source-id: ff91bdc37caac4ffd97aea8df96b3983313ac1d5/Run manual compaction in stress/crash tests (#3936) Summary: Add support to `db_stress` for `CompactRange` Enable `CompactRange` and `CompactFiles` in crash tests Closes Differential Revision: D8230953 Pulled By: ajkr fbshipit-source-id: 208f9980b5bc8c204b1fa726e83791ad674e21e8/Refactoring db_stress.cc (#3902) Summary: We use `db_stress.cc` intensively to test and verify the behavior of RocksDB. Sometimes we need to add new tests for recently added features. Original `StressTest` class provides many general functionality that can be leveraged by other tests. Therefore, in this refactoring PR, I try to identify the general operations as well as operations that future tests most likely want to customize. Future tests can inherit `StressTest` and overriding the virtual functions to test custom logic. Closes Differential Revision: D8284607 Pulled By: riversand963 fbshipit-source-id: 019302d04665a2b18334b6d05d04a477168c8ea4/Extend some tests to format_version=3 (#3942) Summary: format_version=3 changes the format of SST index. This is however not being tested currently since tests only work with the default format_version which is currently 2. The patch extends the most related tests to also test for format_version=3. Closes Differential Revision: D8238413 Pulled By: maysamyabandeh fbshipit-source-id: 915725f55753dd8e9188e802bf471c23645ad035/"
,,0.2231,rocksdb,"Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.1321,rocksdb,Remove unused arg which causes compilation failure (#4080) Summary: It seems that compilation has been made stricter about unused args. Closes Differential Revision: D8712049 Pulled By: sagar0 fbshipit-source-id: 984af1982638af3568aac1a167f565f4741badee/
,,0.1197,rocksdb,Per-thread unique test db names (#4135) Summary: The patch makes sure that two parallel test threads will operate on different db paths. This enables using open source tools such as gtest-parallel to run the tests of a file in parallel. Example: ``` ~/gtest-parallel/gtest-parallel ./table_test``` Pull Request resolved: Differential Revision: D8846653 Pulled By: maysamyabandeh fbshipit-source-id: 799bad1abb260e3d346bcb680d2ae207a852ba84/
,,0.1561,rocksdb,"Add file name info to SequentialFileReader. (#4026) Summary: We potentially need this information for tracing, profiling and diagnosis. Closes Differential Revision: D8555214 Pulled By: riversand963 fbshipit-source-id: 4263e06c00b6d5410b46aa46eb4e358ff2161dd2/"
,,0.1839,rocksdb,"Blob DB: enable readahead for garbage collection (#3648) Summary: Enable readahead for blob DB garbage collection, which should improve GC performance a little bit. Closes Differential Revision: D7383791 Pulled By: yiwu-arbug fbshipit-source-id: 642b3327f7105eca85986d3fb2d8f960a3d83cf1/Add file name info to SequentialFileReader. (#4026) Summary: We potentially need this information for tracing, profiling and diagnosis. Closes Differential Revision: D8555214 Pulled By: riversand963 fbshipit-source-id: 4263e06c00b6d5410b46aa46eb4e358ff2161dd2/"
,,0.2266,rocksdb,"Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.2266,rocksdb,"Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.2266,rocksdb,"Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.2266,rocksdb,"Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.2248,rocksdb,"Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.1939,rocksdb,"Pin mmap files in ReadOnlyDB (#4053) Summary: fixed a bug where PinnableSlice pin mmap files which could be deleted with background compaction. This is however a non-issue for ReadOnlyDB when there is no compaction running and max_open_files is This patch reenables the pinning feature for that case. Closes Differential Revision: D8662546 Pulled By: maysamyabandeh fbshipit-source-id: 402962602eb0f644e17822748332999c3af029fd/Fix the bug with duplicate prefix in partition filters (#4024) Summary: introduced an optimization feature to skip duplicate prefix entires in full bloom filters. Unfortunately it also introduces a bug in partitioned full filters, where the duplicate prefix should still be inserted if it is in a new partition. The patch fixes the bug by resetting the duplicate detection logic each time a partition is cut. This bug could result into false negatives, which means that DB could skip an existing key. Closes Differential Revision: D8518866 Pulled By: maysamyabandeh fbshipit-source-id: 044f4d988e606a330ecafd8c79daceb68b8796bf/Extend format 3 to partitioned index/filters (#3958) Summary: format_version 3 changes the format of index blocks by storing user keys instead of the internal keys, which saves 8-bytes per key. This patch extends the format to top-level indexes in partitioned index/filters. Closes Differential Revision: D8294615 Pulled By: maysamyabandeh fbshipit-source-id: 17666cc16b8076c363972e2308e31547e835f0fe/Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.2231,rocksdb,"Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.1181,rocksdb,Extend some tests to format_version=3 (#3942) Summary: format_version=3 changes the format of SST index. This is however not being tested currently since tests only work with the default format_version which is currently 2. The patch extends the most related tests to also test for format_version=3. Closes Differential Revision: D8238413 Pulled By: maysamyabandeh fbshipit-source-id: 915725f55753dd8e9188e802bf471c23645ad035/
,,0.1561,rocksdb,"Add file name info to SequentialFileReader. (#4026) Summary: We potentially need this information for tracing, profiling and diagnosis. Closes Differential Revision: D8555214 Pulled By: riversand963 fbshipit-source-id: 4263e06c00b6d5410b46aa46eb4e358ff2161dd2/"
,,0.2214,rocksdb,"Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.2248,rocksdb,"Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.1842,rocksdb,"Add tracing function of Seek() and SeekForPrev() to trace_replay (#4228) Summary: In the current trace_and replay, Get an WriteBatch are traced. This pull request track down the Seek() and SeekForPrev() to the trace file. timestamp, column_family_id> are write to the file. Replay of Iterator is not supported in the current implementation. Tested with trace_analyzer. Pull Request resolved: Differential Revision: D9201381 Pulled By: zhichao-cao fbshipit-source-id: 6f9cc9cb3c20260af741bee065ec35c5c96354ab/Trace and Replay for RocksDB (#3837) Summary: A framework for tracing and replaying RocksDB operations. A binary trace file is created by capturing the DB operations, and it can be replayed back at the same rate using db_bench. Column-families are supported Multi-threaded tracing is supported. TraceReader and TraceWriter are exposed to the user, so that tracing to various destinations can be enabled (say, to other messaging/logging services). By default, a FileTraceReader and FileTraceWriter are implemented to capture to a file and replay from it. This is not yet ideal to be enabled in production due to large performance overhead, but it can be safely tried out in a shadow setup, say, for analyzing RocksDB operations. Currently supported DB operations: Writes: Put Merge Delete SingleDelete DeleteRange Write Reads: Get (point lookups) Pull Request resolved: Differential Revision: D7974837 Pulled By: sagar0 fbshipit-source-id: 8ec65aaf336504bc1f6ed0feae67f6ed5ef97a72/Remove random writes from SST file ingestion (#4172) Summary: RocksDB used to store global_seqno in external SST files written by SstFileWriter. During file ingestion, RocksDB uses `pwrite` to update the `global_seqno`. Since random write is not supported in some non-POSIX compliant file systems, external SST file ingestion is not supported on these file systems. To address this limitation, we no longer update `global_seqno` during file ingestion. Later RocksDB uses the MANIFEST and other information in table properties to deduce global seqno for externally-ingested SST files. Pull Request resolved: Differential Revision: D8961465 Pulled By: riversand963 fbshipit-source-id: 4382ec85270a96be5bc0cf33758ca2b167b05071/Protect external file when ingesting (#4099) Summary: If crash happen after a hard link established, Recover function may reuse the file number that has already assigned to the internal file, and this will overwrite the external file. To protect the external file, we have to make sure the file number will never being reused. Pull Request resolved: Differential Revision: D9034092 Pulled By: riversand963 fbshipit-source-id: 3f1a737440b86aa2ef01673e5013aacbb7c33e28/Remove managed iterator Summary: Pull Request resolved: Differential Revision: D8829910 Pulled By: siying fbshipit-source-id: f3e952ccf3a631071a5d77c48e327046f8abb560/Allow DB resume after background errors (#3997) Summary: Currently, if RocksDB encounters errors during a write operation (user requested or BG operations), it sets DBImpl::bg_error_ and fails subsequent writes. This PR allows the DB to be resumed for certain classes of errors. It consists of 3 parts 1. Introduce Status::Severity in rocksdb::Status to indicate whether a given error can be recovered from or not 2. Refactor the error handling code so that setting bg_error_ and deciding on severity is in one place 3. Provide an API for the user to clear the error and resume the DB instance This whole change is broken up into multiple PRs. Initially, we only allow clearing the error for Status::NoSpace() errors during background flush/compaction. Subsequent PRs will expand this to include more errors and foreground operations such as Put(), and implement a polling mechanism for out-of-space errors. Closes Differential Revision: D8653831 Pulled By: anand1976 fbshipit-source-id: 6dc835c76122443a7668497c0226b4f072bc6afd/WriteUnPrepared Txn: Disable seek to snapshot optimization (#3955) Summary: This is implemented by extending ReadCallback with another function `MaxUnpreparedSequenceNumber` which returns the largest visible sequence number for the current transaction, if there is uncommitted data written to DB. Otherwise, it returns zero, indicating no uncommitted data. There are the places where reads had to be modified. Get and Seek/Next was just updated to seek to max(snapshot_seq, MaxUnpreparedSequenceNumber()) instead, and iterate until a key was visible. Prev did not need need updates since it did not use the Seek to sequence number optimization. Assuming that locks were held when writing unprepared keys, and ValidateSnapshot runs, there should only be committed keys and unprepared keys of the current transaction, all of which are visible. Prev will simply iterate to get the last visible key. Reseeking to skip keys optimization was also disabled for write unprepared, since its possible to hit the max_skip condition even while reseeking. There needs to be some way to resolve infinite looping in this case. Closes Differential Revision: D8286688 Pulled By: lth fbshipit-source-id: 25e42f47fdeb5f7accea0f4fd350ef35198caafe/Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.2515,rocksdb,"Relax VersionStorageInfo::GetOverlappingInputs check (#4050) Summary: Do not consider the range tombstone sentinel key as causing 2 adjacent sstables in a level to overlap. When a range tombstones end key is the largest key in an sstable, the sstables end key is so to a ""sentinel"" value that is the smallest key in the next sstable with a sequence number of kMaxSequenceNumber. This ""sentinel"" is guaranteed to not overlap in internal-key space with the next sstable. Unfortunately, GetOverlappingFiles uses user-keys to determine overlap and was thus considering 2 adjacent sstables in a level to overlap if they were separated by this sentinel key. This in turn would cause compactions to be larger than necessary. Note that this conflicts with and cases `DBRangeDelTest.CompactionTreatsSplitInputLevelDeletionAtomically` to fail. Pull Request resolved: Differential Revision: D8844423 Pulled By: ajkr fbshipit-source-id: df3f9f1db8f4cff2bff77376b98b83c2ae1d155b/Range deletion performance improvements + cleanup (#4014) Summary: This fixes the same performance issue that fixes but with much more invasive cleanup. Im more excited about this PR because it paves the way for fixing another problem we uncovered at Cockroach where range deletion tombstones can cause massive compactions. For example, suppose L4 contains deletions from [a, c) and [x, z) and no other keys, and L5 is entirely empty. L6, however, is full of data. When compacting L4 L5, well end up with one file that spans, massively, from [a, z). When we go to compact L5 L6, well have to rewrite all of L6 If, instead of range deletions in L4, we had keys a, b, x, y, and z, RocksDB would have been smart enough to create two files in L5: one for a and b and another for x, y, and z. With the changes in this PR, it will be possible to adjust the compaction logic to split tombstones/start new output files when they would span too many files in the grandparent level. ajkr please take a look when you have a minute Pull Request resolved: Differential Revision: D8773253 Pulled By: ajkr fbshipit-source-id: ec62fa85f648fdebe1380b83ed997f9baec35677/"
,,0.1197,rocksdb,Per-thread unique test db names (#4135) Summary: The patch makes sure that two parallel test threads will operate on different db paths. This enables using open source tools such as gtest-parallel to run the tests of a file in parallel. Example: ``` ~/gtest-parallel/gtest-parallel ./table_test``` Pull Request resolved: Differential Revision: D8846653 Pulled By: maysamyabandeh fbshipit-source-id: 799bad1abb260e3d346bcb680d2ae207a852ba84/
,,0.332,rocksdb,"Relax VersionStorageInfo::GetOverlappingInputs check (#4050) Summary: Do not consider the range tombstone sentinel key as causing 2 adjacent sstables in a level to overlap. When a range tombstones end key is the largest key in an sstable, the sstables end key is so to a ""sentinel"" value that is the smallest key in the next sstable with a sequence number of kMaxSequenceNumber. This ""sentinel"" is guaranteed to not overlap in internal-key space with the next sstable. Unfortunately, GetOverlappingFiles uses user-keys to determine overlap and was thus considering 2 adjacent sstables in a level to overlap if they were separated by this sentinel key. This in turn would cause compactions to be larger than necessary. Note that this conflicts with and cases `DBRangeDelTest.CompactionTreatsSplitInputLevelDeletionAtomically` to fail. Pull Request resolved: Differential Revision: D8844423 Pulled By: ajkr fbshipit-source-id: df3f9f1db8f4cff2bff77376b98b83c2ae1d155b/Pin mmap files in ReadOnlyDB (#4053) Summary: fixed a bug where PinnableSlice pin mmap files which could be deleted with background compaction. This is however a non-issue for ReadOnlyDB when there is no compaction running and max_open_files is This patch reenables the pinning feature for that case. Closes Differential Revision: D8662546 Pulled By: maysamyabandeh fbshipit-source-id: 402962602eb0f644e17822748332999c3af029fd/Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.1213,rocksdb,Per-thread unique test db names (#4135) Summary: The patch makes sure that two parallel test threads will operate on different db paths. This enables using open source tools such as gtest-parallel to run the tests of a file in parallel. Example: ``` ~/gtest-parallel/gtest-parallel ./table_test``` Pull Request resolved: Differential Revision: D8846653 Pulled By: maysamyabandeh fbshipit-source-id: 799bad1abb260e3d346bcb680d2ae207a852ba84/
,,0.0992,rocksdb,Fix test for rocksdb_lite: hide incompatible option kDirectIO Summary: Previous commit unhide a few test options which includes kDirectIO. However its not supported by RocksDB lite. Need to hide this option from the lite build. Closes Differential Revision: D8242757 Pulled By: miasantreble fbshipit-source-id: 1edfad3a5d01a46bfb7eedee765981ebe02c500a/
,,0.2046,rocksdb,"Relax VersionStorageInfo::GetOverlappingInputs check (#4050) Summary: Do not consider the range tombstone sentinel key as causing 2 adjacent sstables in a level to overlap. When a range tombstones end key is the largest key in an sstable, the sstables end key is so to a ""sentinel"" value that is the smallest key in the next sstable with a sequence number of kMaxSequenceNumber. This ""sentinel"" is guaranteed to not overlap in internal-key space with the next sstable. Unfortunately, GetOverlappingFiles uses user-keys to determine overlap and was thus considering 2 adjacent sstables in a level to overlap if they were separated by this sentinel key. This in turn would cause compactions to be larger than necessary. Note that this conflicts with and cases `DBRangeDelTest.CompactionTreatsSplitInputLevelDeletionAtomically` to fail. Pull Request resolved: Differential Revision: D8844423 Pulled By: ajkr fbshipit-source-id: df3f9f1db8f4cff2bff77376b98b83c2ae1d155b/Test range deletions with more configurations (#4021) Summary: Run the basic range deletion tests against the standard set of configurations. This testing exposed that files with hash indexes and partitioned indexes were not handling the case where the file contained only range deletions--i.e., where the index was empty. Additionally file a TODO about the fact that range deletions are broken when allow_mmap_reads true is set. /cc ajkr nvanbenschoten Best viewed with ?w=1: Pull Request resolved: Differential Revision: D8811860 Pulled By: ajkr fbshipit-source-id: 3cc07e6d6210a2a00b932866481b3d5c59775343/"
,,0.3226,rocksdb,"Relax VersionStorageInfo::GetOverlappingInputs check (#4050) Summary: Do not consider the range tombstone sentinel key as causing 2 adjacent sstables in a level to overlap. When a range tombstones end key is the largest key in an sstable, the sstables end key is so to a ""sentinel"" value that is the smallest key in the next sstable with a sequence number of kMaxSequenceNumber. This ""sentinel"" is guaranteed to not overlap in internal-key space with the next sstable. Unfortunately, GetOverlappingFiles uses user-keys to determine overlap and was thus considering 2 adjacent sstables in a level to overlap if they were separated by this sentinel key. This in turn would cause compactions to be larger than necessary. Note that this conflicts with and cases `DBRangeDelTest.CompactionTreatsSplitInputLevelDeletionAtomically` to fail. Pull Request resolved: Differential Revision: D8844423 Pulled By: ajkr fbshipit-source-id: df3f9f1db8f4cff2bff77376b98b83c2ae1d155b/Dont generate a notification for a 0 size SST (#4003) Summary: Dont call the OnTableFileCreated listener callback when a 0 size SST file gets created by Flush. Doing so causes an assertion failure in db_stress. It is also not correct behavior as we call env->DeleteFile() for such files right before the notification. Closes Differential Revision: D8461385 Pulled By: anand1976 fbshipit-source-id: ae92d4f921c2e2cff981ad58f4929ed8b609f35d/Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.2608,rocksdb,"Remove random writes from SST file ingestion (#4172) Summary: RocksDB used to store global_seqno in external SST files written by SstFileWriter. During file ingestion, RocksDB uses `pwrite` to update the `global_seqno`. Since random write is not supported in some non-POSIX compliant file systems, external SST file ingestion is not supported on these file systems. To address this limitation, we no longer update `global_seqno` during file ingestion. Later RocksDB uses the MANIFEST and other information in table properties to deduce global seqno for externally-ingested SST files. Pull Request resolved: Differential Revision: D8961465 Pulled By: riversand963 fbshipit-source-id: 4382ec85270a96be5bc0cf33758ca2b167b05071/Specify the underlying type of enums. Summary: Explicitly specify the underlying type of enums help developers understand the physical storage. Closes Differential Revision: D8107027 Pulled By: riversand963 fbshipit-source-id: a00efecbba46df4a3c8eed0994a2d4972ad1a1d3/"
,,0.1228,rocksdb,Per-thread unique test db names (#4135) Summary: The patch makes sure that two parallel test threads will operate on different db paths. This enables using open source tools such as gtest-parallel to run the tests of a file in parallel. Example: ``` ~/gtest-parallel/gtest-parallel ./table_test``` Pull Request resolved: Differential Revision: D8846653 Pulled By: maysamyabandeh fbshipit-source-id: 799bad1abb260e3d346bcb680d2ae207a852ba84/
,,0.1196,rocksdb,Extend some tests to format_version=3 (#3942) Summary: format_version=3 changes the format of SST index. This is however not being tested currently since tests only work with the default format_version which is currently 2. The patch extends the most related tests to also test for format_version=3. Closes Differential Revision: D8238413 Pulled By: maysamyabandeh fbshipit-source-id: 915725f55753dd8e9188e802bf471c23645ad035/
,,0.0884,rocksdb,"Remove tests from ROCKSDB_VALGRIND_RUN Summary: In order to make valgrind check test to pass in a day, remove some tests that run prohibitively slow under valgrind. Closes Differential Revision: D8210184 Pulled By: siying fbshipit-source-id: 5b06fb08f3cf57571d422d05a0dbddc9f9376f7a/"
,,0.2248,rocksdb,"Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.2248,rocksdb,"Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.2443,rocksdb,"Support range deletion tombstones in IngestExternalFile SSTs (#3778) Summary: Fixes This change adds a `DeleteRange` method to `SstFileWriter` and adds support for ingesting SSTs with range deletion tombstones. This is important for applications that need to atomically ingest SSTs while clearing out any existing keys in a given key range. Pull Request resolved: Differential Revision: D8821836 Pulled By: anand1976 fbshipit-source-id: ca7786c1947ff129afa703dab011d524c7883844/Fix a map lookup that may throw exception. (#4098) Summary: `std::map::at(key)` throws std::out_of_range if key does not exist. Current code does not handle this. Although this case is unlikely, I feel its safe to use `std::map::find`. Pull Request resolved: Differential Revision: D8753865 Pulled By: riversand963 fbshipit-source-id: 9a9ba43badb0fb5e0d24cd87903931fd12f3f8ec/Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.2296,rocksdb,"Support group commits of version edits (#3944) Summary: This PR supports the group commit of multiple version edit entries corresponding to different column families. Column family drop/creation still cannot be grouped. This PR is a subset of [PR 3752]( Closes Differential Revision: D8432536 Pulled By: riversand963 fbshipit-source-id: 8f11bd05193b6c0d9272d82e44b676abfac113cb/Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.1619,rocksdb,"Add file name info to SequentialFileReader. (#4026) Summary: We potentially need this information for tracing, profiling and diagnosis. Closes Differential Revision: D8555214 Pulled By: riversand963 fbshipit-source-id: 4263e06c00b6d5410b46aa46eb4e358ff2161dd2/"
,,0.11900000000000001,rocksdb,"SetOptions Backup Race Condition (#4108) Summary: Prior to this PR, there was a race condition between `DBImpl::SetOptions` and `BackupEngine::CreateNewBackup`, as illustrated below. ``` Time thread 1 thread 2 | CreateNewBackup GetLiveFiles | SetOptions RenameTempFileToOptionsFile | SetOptions RenameTempFileToOptionsFile | SetOptions RenameTempFileToOptionsFile // unlink oldest OPTIONS file | copy the oldest OPTIONS // IO error V ``` Proposed fix is to check the value of `DBImpl::disable_obsolete_files_deletion_` before calling `DeleteObsoleteOptionsFiles`. Pull Request resolved: Differential Revision: D8796360 Pulled By: riversand963 fbshipit-source-id: 02045317f793ea4c7d4400a5bf333b8502fa3e82/"
,,0.2145,rocksdb,"Avoid sleep in DBTest.GroupCommitTest to fix flakiness Summary: DBTest.GroupCommitTest would often fail when run under valgrind because its sleeps were insufficient to guarantee a group commit had multiple entries. Instead we can use sync point to force a leader to wait until a non-leader thread has enqueued its work, thus guaranteeing a leader can do group commit work for multiple threads. Closes Differential Revision: D8079429 Pulled By: ajkr fbshipit-source-id: 61dc50fad29d2c85547842f681288de60fa29049/Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.3994,rocksdb,"Remove random writes from SST file ingestion (#4172) Summary: RocksDB used to store global_seqno in external SST files written by SstFileWriter. During file ingestion, RocksDB uses `pwrite` to update the `global_seqno`. Since random write is not supported in some non-POSIX compliant file systems, external SST file ingestion is not supported on these file systems. To address this limitation, we no longer update `global_seqno` during file ingestion. Later RocksDB uses the MANIFEST and other information in table properties to deduce global seqno for externally-ingested SST files. Pull Request resolved: Differential Revision: D8961465 Pulled By: riversand963 fbshipit-source-id: 4382ec85270a96be5bc0cf33758ca2b167b05071/Allow ttl to be changed dynamically (#4133) Summary: Allow ttl to be changed dynamically. Pull Request resolved: Differential Revision: D8845440 Pulled By: sagar0 fbshipit-source-id: c8c87ae643b3a8c4123e4c037c4645efc094a2d3/Relax VersionStorageInfo::GetOverlappingInputs check (#4050) Summary: Do not consider the range tombstone sentinel key as causing 2 adjacent sstables in a level to overlap. When a range tombstones end key is the largest key in an sstable, the sstables end key is so to a ""sentinel"" value that is the smallest key in the next sstable with a sequence number of kMaxSequenceNumber. This ""sentinel"" is guaranteed to not overlap in internal-key space with the next sstable. Unfortunately, GetOverlappingFiles uses user-keys to determine overlap and was thus considering 2 adjacent sstables in a level to overlap if they were separated by this sentinel key. This in turn would cause compactions to be larger than necessary. Note that this conflicts with and cases `DBRangeDelTest.CompactionTreatsSplitInputLevelDeletionAtomically` to fail. Pull Request resolved: Differential Revision: D8844423 Pulled By: ajkr fbshipit-source-id: df3f9f1db8f4cff2bff77376b98b83c2ae1d155b/Support group commits of version edits (#3944) Summary: This PR supports the group commit of multiple version edit entries corresponding to different column families. Column family drop/creation still cannot be grouped. This PR is a subset of [PR 3752]( Closes Differential Revision: D8432536 Pulled By: riversand963 fbshipit-source-id: 8f11bd05193b6c0d9272d82e44b676abfac113cb/Add file name info to SequentialFileReader. (#4026) Summary: We potentially need this information for tracing, profiling and diagnosis. Closes Differential Revision: D8555214 Pulled By: riversand963 fbshipit-source-id: 4263e06c00b6d5410b46aa46eb4e358ff2161dd2/Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.1244,rocksdb,Per-thread unique test db names (#4135) Summary: The patch makes sure that two parallel test threads will operate on different db paths. This enables using open source tools such as gtest-parallel to run the tests of a file in parallel. Example: ``` ~/gtest-parallel/gtest-parallel ./table_test``` Pull Request resolved: Differential Revision: D8846653 Pulled By: maysamyabandeh fbshipit-source-id: 799bad1abb260e3d346bcb680d2ae207a852ba84/
,,0.2214,rocksdb,"Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.1638,rocksdb,"Add file name info to SequentialFileReader. (#4026) Summary: We potentially need this information for tracing, profiling and diagnosis. Closes Differential Revision: D8555214 Pulled By: riversand963 fbshipit-source-id: 4263e06c00b6d5410b46aa46eb4e358ff2161dd2/"
,,0.1213,rocksdb,Per-thread unique test db names (#4135) Summary: The patch makes sure that two parallel test threads will operate on different db paths. This enables using open source tools such as gtest-parallel to run the tests of a file in parallel. Example: ``` ~/gtest-parallel/gtest-parallel ./table_test``` Pull Request resolved: Differential Revision: D8846653 Pulled By: maysamyabandeh fbshipit-source-id: 799bad1abb260e3d346bcb680d2ae207a852ba84/
,,0.1567,rocksdb,"Range deletion performance improvements + cleanup (#4014) Summary: This fixes the same performance issue that fixes but with much more invasive cleanup. Im more excited about this PR because it paves the way for fixing another problem we uncovered at Cockroach where range deletion tombstones can cause massive compactions. For example, suppose L4 contains deletions from [a, c) and [x, z) and no other keys, and L5 is entirely empty. L6, however, is full of data. When compacting L4 L5, well end up with one file that spans, massively, from [a, z). When we go to compact L5 L6, well have to rewrite all of L6 If, instead of range deletions in L4, we had keys a, b, x, y, and z, RocksDB would have been smart enough to create two files in L5: one for a and b and another for x, y, and z. With the changes in this PR, it will be possible to adjust the compaction logic to split tombstones/start new output files when they would span too many files in the grandparent level. ajkr please take a look when you have a minute Pull Request resolved: Differential Revision: D8773253 Pulled By: ajkr fbshipit-source-id: ec62fa85f648fdebe1380b83ed997f9baec35677/Add bottommost_compression_opts to for bottommost_compression (#3985) Summary: Öression For `CompressionType` we have options `compression` and `bottommost_compression`. Thus, to make the compression options consitent with the compression type when bottommost_compression is enabled, we add the bottommost_compression_opts Closes Reviewed By: riversand963 Differential Revision: D8385911 Pulled By: zhichao-cao fbshipit-source-id: 07bc533dd61bcf1cef5927d8d62901c13d38d5fc/Delay verify compaction output table (#3979) Summary: Verify table will load SST into `TableCache` it occupy memory & `TableCache`ës capacity ... but no logic use them its unnecessary ... so , we verify them after all sub compact finished Closes Differential Revision: D8389946 Pulled By: ajkr fbshipit-source-id: 54bd4f474f9e7b3accf39c3068b1f36a27ec4c49/"
,,0.1047,rocksdb,Align StatisticsImpl / StatisticsData (#4036) Summary: Pinned the alignment of StatisticsData to the cacheline size rather than just extending its size (which could go over two cache lines)if unaligned in allocation. Avoid compile errors in the process as per individual commit messages. strengthen static_assert to CACHELINE rather than the highest common multiple. Closes Differential Revision: D8582844 Pulled By: yiwu-arbug fbshipit-source-id: 363c37029f28e6093e06c60b987bca9aa204bc71/
,,0.1302,rocksdb,Enable atomic flush (#4023) Summary: Adds a DB option `atomic_flush` to control whether to enable this feature. This PR is a subset of [PR 3752]( Pull Request resolved: Differential Revision: D8518381 Pulled By: riversand963 fbshipit-source-id: 1e3bb33e99bb102876a31b378d93b0138ff6634f/
,,0.1284,rocksdb,Enable atomic flush (#4023) Summary: Adds a DB option `atomic_flush` to control whether to enable this feature. This PR is a subset of [PR 3752]( Pull Request resolved: Differential Revision: D8518381 Pulled By: riversand963 fbshipit-source-id: 1e3bb33e99bb102876a31b378d93b0138ff6634f/
,,0.2125,rocksdb,Add path to WritableFileWriter. (#4039) Summary: We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise its hard to tell what has been going on. Pull Request resolved: Differential Revision: D8670178 Pulled By: riversand963 fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/
,,0.2324,rocksdb,"Add read retry support to log reader (#4394) Summary: Current `log::Reader` does not perform retry after encountering `EOF`. In the future, we need the log reader to be able to retry tailing the log even after `EOF`. Current implementation is simple. It does not provide more advanced retry policies. Will address this in the future. Pull Request resolved: Differential Revision: D9926508 Pulled By: riversand963 fbshipit-source-id: d86d145792a41bd64a72f642a2a08c7b7b5201e1/"
,,0.1836,rocksdb,"Verify restore from backup in db_stress (#4655) Summary: We already exercised backup functionality in `db_stress` according to the `-backup_one_in` flag. This PR verifies the backup can be restored/opened and sanity checks a few keys. Changes in this PR: Extracted existing backup-related logic to a helper function, `TestBackupRestore` Added restore logic, which targets a hidden directory named ""./.restore\<thread number\>"", similar to how backups target hidden directories named ""./.backup\<thread number\>"". After restore, check the existence/non-existence of a few keys. With this PR, backup is no longer compatible with clearing column families. Also included unrelated fixes to set `ReadOptions::total_order_seek=true` when using `-compare_full_db_state_snapshot` Pull Request resolved: Differential Revision: D12972496 Pulled By: ajkr fbshipit-source-id: 481a40052d9a38d1bd5c5159aa4d7c5a4b546b80/Update manual flush stress test (#4608) Summary: Originally, the manual flush calls in db_stress flushes only a single column family, which is not sufficient when atomic flush is enabled. With atomic flush, we should call `Flush(flush_opts, cfhs)` to better test this new feature. Specifically, we manuall flush all column families so that database verification is easier. Pull Request resolved: Differential Revision: D12849160 Pulled By: riversand963 fbshipit-source-id: ae1f0dd825247b42c0aba520a5c967335102c876/Fix a warning against implicit type conversion (#4593) Summary: Test plan ``` $USE_CLANG=1 make all check ``` Pull Request resolved: Differential Revision: D12811159 Pulled By: riversand963 fbshipit-source-id: 5e3bbe058c5a8d5a286a19d7643593fc154a2d6d/Enable atomic flush (#4023) Summary: Adds a DB option `atomic_flush` to control whether to enable this feature. This PR is a subset of [PR 3752]( Pull Request resolved: Differential Revision: D8518381 Pulled By: riversand963 fbshipit-source-id: 1e3bb33e99bb102876a31b378d93b0138ff6634f/Support manual flush in stress/crash tests (#4368) Summary: Made stress test call `Flush()` periodically according to `--flush_one_in` flag. Enabled by default in crash test. Pull Request resolved: Differential Revision: D9838593 Pulled By: ajkr fbshipit-source-id: fe5a6e49b36e5ea752acc3aa8be364f8ef34d9cc/Drop unnecessary deletion markers during compaction (issue 3842) (#4289) Summary: This PR fixes issue 3842. We drop deletion markers iff 1. We are the bottom most level AND 2. All other occurrences of the key are in the same snapshot range as the delete Ive also enhanced db_stress_test to add an option that does a full compare of the keys. This is done by a single thread (thread 0). For tests Ive run (so far) make check db_stress db_stress /* to verify that new code doesnt break existing tests */ ./db_stress /* to verify new test code */ Pull Request resolved: Differential Revision: D9491165 Pulled By: shrikanthshankar fbshipit-source-id: ce144834f31736c189aaca81bed356ba990331e2/Invoke OnTableFileCreated for empty SSTs (#4307) Summary: The API comment on `OnTableFileCreationStarted` ( led users to believe a call to `OnTableFileCreationStarted` will always be matched with a call to `OnTableFileCreated`. However, we were skipping the `OnTableFileCreated` call in one case: no error happens but also no file is generated since theres no data. This PR adds the call to `OnTableFileCreated` for that case. The filename will be ""(nil)"" and the size will be zero. Pull Request resolved: Differential Revision: D9485201 Pulled By: ajkr fbshipit-source-id: 2f077ec7913f128487aae2624c69a50762394df6/"
,,0.2821,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/Add path to WritableFileWriter. (#4039) Summary: We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise its hard to tell what has been going on. Pull Request resolved: Differential Revision: D8670178 Pulled By: riversand963 fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/"
,,0.3383,rocksdb,"s/CacheAllocator/MemoryAllocator/g (#4590) Summary: Rename the interface, as it is mean to be a generic interface for memory allocation. Pull Request resolved: Differential Revision: D10866340 Pulled By: yiwu-arbug fbshipit-source-id: 85cb753351a40cb856c046aeaa3f3b369eef3d16/Introduce CacheAllocator, a custom allocator for cache blocks (#4437) Summary: This is a conceptually simple change, but it touches many files to pass the allocator through function calls. We introduce CacheAllocator, which can be used by clients to configure custom allocator for cache blocks. Our motivation is to hook this up with follys `JemallocNodumpAllocator` ( but there are many other possible use cases. Additionally, this commit cleans up memory allocation in `util/compression.h`, making sure that all allocations are wrapped in a unique_ptr as soon as possible. Pull Request resolved: Differential Revision: D10132814 Pulled By: yiwu-arbug fbshipit-source-id: be1343a4b69f6048df127939fea9bbc96969f564/"
,,0.3411,rocksdb,"s/CacheAllocator/MemoryAllocator/g (#4590) Summary: Rename the interface, as it is mean to be a generic interface for memory allocation. Pull Request resolved: Differential Revision: D10866340 Pulled By: yiwu-arbug fbshipit-source-id: 85cb753351a40cb856c046aeaa3f3b369eef3d16/Introduce CacheAllocator, a custom allocator for cache blocks (#4437) Summary: This is a conceptually simple change, but it touches many files to pass the allocator through function calls. We introduce CacheAllocator, which can be used by clients to configure custom allocator for cache blocks. Our motivation is to hook this up with follys `JemallocNodumpAllocator` ( but there are many other possible use cases. Additionally, this commit cleans up memory allocation in `util/compression.h`, making sure that all allocations are wrapped in a unique_ptr as soon as possible. Pull Request resolved: Differential Revision: D10132814 Pulled By: yiwu-arbug fbshipit-source-id: be1343a4b69f6048df127939fea9bbc96969f564/"
,,0.3397,rocksdb,"s/CacheAllocator/MemoryAllocator/g (#4590) Summary: Rename the interface, as it is mean to be a generic interface for memory allocation. Pull Request resolved: Differential Revision: D10866340 Pulled By: yiwu-arbug fbshipit-source-id: 85cb753351a40cb856c046aeaa3f3b369eef3d16/Introduce CacheAllocator, a custom allocator for cache blocks (#4437) Summary: This is a conceptually simple change, but it touches many files to pass the allocator through function calls. We introduce CacheAllocator, which can be used by clients to configure custom allocator for cache blocks. Our motivation is to hook this up with follys `JemallocNodumpAllocator` ( but there are many other possible use cases. Additionally, this commit cleans up memory allocation in `util/compression.h`, making sure that all allocations are wrapped in a unique_ptr as soon as possible. Pull Request resolved: Differential Revision: D10132814 Pulled By: yiwu-arbug fbshipit-source-id: be1343a4b69f6048df127939fea9bbc96969f564/"
,,0.3439,rocksdb,"s/CacheAllocator/MemoryAllocator/g (#4590) Summary: Rename the interface, as it is mean to be a generic interface for memory allocation. Pull Request resolved: Differential Revision: D10866340 Pulled By: yiwu-arbug fbshipit-source-id: 85cb753351a40cb856c046aeaa3f3b369eef3d16/Introduce CacheAllocator, a custom allocator for cache blocks (#4437) Summary: This is a conceptually simple change, but it touches many files to pass the allocator through function calls. We introduce CacheAllocator, which can be used by clients to configure custom allocator for cache blocks. Our motivation is to hook this up with follys `JemallocNodumpAllocator` ( but there are many other possible use cases. Additionally, this commit cleans up memory allocation in `util/compression.h`, making sure that all allocations are wrapped in a unique_ptr as soon as possible. Pull Request resolved: Differential Revision: D10132814 Pulled By: yiwu-arbug fbshipit-source-id: be1343a4b69f6048df127939fea9bbc96969f564/"
,,0.0653,rocksdb,xxhash 64 support Summary: Pull Request resolved: Reviewed By: siying Differential Revision: D12836696 Pulled By: jsjhoubo fbshipit-source-id: 7122ccb712d0b0f1cd998aa4477e0da1401bd870/
,,0.1042,rocksdb,Move `#include` outside of namespace (#4629) Summary: clang modules warns about `#include`s inside of namespaces. Pull Request resolved: Reviewed By: ajkr Differential Revision: D12927333 Pulled By: andrewjcg fbshipit-source-id: a9e0b069e63d8224f78b7c3be1c3acf09bb83d3f/xxhash 64 support Summary: Pull Request resolved: Reviewed By: siying Differential Revision: D12836696 Pulled By: jsjhoubo fbshipit-source-id: 7122ccb712d0b0f1cd998aa4477e0da1401bd870/
,,0.1159,rocksdb,"Add listener to sample file io (#3933) Summary: We would like to collect file-system-level statistics including file name, offset, length, return code, latency, etc., which requires to add callbacks to intercept file IO function calls when RocksDB is running. To collect file-system-level statistics, users can inherit the class `EventListener`, as in `TestFileOperationListener `. Note that `TestFileOperationListener::ShouldBeNotifiedOnFileIO()` returns true. Pull Request resolved: Differential Revision: D10219571 Pulled By: riversand963 fbshipit-source-id: 7acc577a2d31097766a27adb6f78eaf8b1e8ff15/"
,,0.2821,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/Add path to WritableFileWriter. (#4039) Summary: We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise its hard to tell what has been going on. Pull Request resolved: Differential Revision: D8670178 Pulled By: riversand963 fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/"
,,0.4691,rocksdb,"s/CacheAllocator/MemoryAllocator/g (#4590) Summary: Rename the interface, as it is mean to be a generic interface for memory allocation. Pull Request resolved: Differential Revision: D10866340 Pulled By: yiwu-arbug fbshipit-source-id: 85cb753351a40cb856c046aeaa3f3b369eef3d16/Adapt three unit tests with newer compiler/libraries (#4562) Summary: This fixes three tests that fail with relatively recent tools and libraries: The tests are: * `spatial_db_test` * `table_test` * `db_universal_compaction_test` Im using: * `gcc` 7.3.0 * `glibc` 2.27 * `snappy` 1.1.7 * `gflags` 2.2.1 * `zlib` 1.2.11 * `bzip2` 1.0.6.0.1 * `lz4` 1.8.2 * `jemalloc` 5.0.1 The versions used in the Travis environment (which is two Ubuntu LTS versions behind the current one and doesnt use `lz4` or `jemalloc`) dont seem to have a problem. However, to be safe, I verified that these tests pass with and without my changes in a trusty Docker container without `lz4` and `jemalloc`. However, I do get an unrelated set of other failures when using a trusty Docker container that uses `lz4` and `jemalloc`: ``` db/db_universal_compaction_test.cc:506: Failure Value of: num + 1 Actual: 3 Expected: NumSortedRuns(1) Which is: 4 [ FAILED ] UniversalCompactionNumLevels/DBTestUniversalCompaction.DynamicUniversalCompactionReadAmplification/0, where GetParam() (1, false) (1189 ms) [ RUN ] UniversalCompactionNumLevels/DBTestUniversalCompaction.DynamicUniversalCompactionReadAmplification/1 db/db_universal_compaction_test.cc:506: Failure Value of: num + 1 Actual: 3 Expected: NumSortedRuns(1) Which is: 4 [ FAILED ] UniversalCompactionNumLevels/DBTestUniversalCompaction.DynamicUniversalCompactionReadAmplification/1, where GetParam() (1, true) (1246 ms) [ RUN ] UniversalCompactionNumLevels/DBTestUniversalCompaction.DynamicUniversalCompactionReadAmplification/2 db/db_universal_compaction_test.cc:506: Failure Value of: num + 1 Actual: 3 Expected: NumSortedRuns(1) Which is: 4 [ FAILED ] UniversalCompactionNumLevels/DBTestUniversalCompaction.DynamicUniversalCompactionReadAmplification/2, where GetParam() (3, false) (1237 ms) [ RUN ] UniversalCompactionNumLevels/DBTestUniversalCompaction.DynamicUniversalCompactionReadAmplification/3 db/db_universal_compaction_test.cc:506: Failure Value of: num + 1 Actual: 3 Expected: NumSortedRuns(1) Which is: 4 [ FAILED ] UniversalCompactionNumLevels/DBTestUniversalCompaction.DynamicUniversalCompactionReadAmplification/3, where GetParam() (3, true) (1195 ms) [ RUN ] UniversalCompactionNumLevels/DBTestUniversalCompaction.DynamicUniversalCompactionReadAmplification/4 db/db_universal_compaction_test.cc:506: Failure Value of: num + 1 Actual: 3 Expected: NumSortedRuns(1) Which is: 4 [ FAILED ] UniversalCompactionNumLevels/DBTestUniversalCompaction.DynamicUniversalCompactionReadAmplification/4, where GetParam() (5, false) (1161 ms) [ RUN ] UniversalCompactionNumLevels/DBTestUniversalCompaction.DynamicUniversalCompactionReadAmplification/5 db/db_universal_compaction_test.cc:506: Failure Value of: num + 1 Actual: 3 Expected: NumSortedRuns(1) Which is: 4 [ FAILED ] UniversalCompactionNumLevels/DBTestUniversalCompaction.DynamicUniversalCompactionReadAmplification/5, where GetParam() (5, true) (1229 ms) ``` I havent attempted to fix these since Im not using trusty and Travis doesnt use `lz4` and `jemalloc`. However, the final commit in this PR does at least fix the compilation errors that occur when using trustys version of `lz4`. Pull Request resolved: Differential Revision: D10510917 Pulled By: maysamyabandeh fbshipit-source-id: 59534042015ec339270e5fc2f6ac4d859370d189/Introduce CacheAllocator, a custom allocator for cache blocks (#4437) Summary: This is a conceptually simple change, but it touches many files to pass the allocator through function calls. We introduce CacheAllocator, which can be used by clients to configure custom allocator for cache blocks. Our motivation is to hook this up with follys `JemallocNodumpAllocator` ( but there are many other possible use cases. Additionally, this commit cleans up memory allocation in `util/compression.h`, making sure that all allocations are wrapped in a unique_ptr as soon as possible. Pull Request resolved: Differential Revision: D10132814 Pulled By: yiwu-arbug fbshipit-source-id: be1343a4b69f6048df127939fea9bbc96969f564/Revert ""Digest ZSTD compression dictionary once per SST file (#4251)"" (#4347) Summary: Reverting is needed to unblock a user building against master, who is blocked for multiple days due to a thread-safety issue in `GetEmptyDict`. We havent been able to fix it quickly, so reverting. Simply ran `git revert 6c40806e51a89386d2b066fddf73d3fd03a36f65`. There were no merge conflicts. Pull Request resolved: Differential Revision: D9668365 Pulled By: ajkr fbshipit-source-id: 0c56334f0a23cf5ee0233d4e4679eae6709739cd/Digest ZSTD compression dictionary once per SST file (#4251) Summary: In RocksDB, for a given SST file, all data blocks are compressed with the same dictionary. When we compress a block using the dictionarys raw bytes, the compression library first has to digest the dictionary to get it into a usable form. This digestion work is redundant and ideally should be done once per file. ZSTD offers APIs for the caller to create and reuse a digested dictionary object (`ZSTD_CDict`). In this PR, we call `ZSTD_createCDict` once per file to digest the raw bytes. Then we use `ZSTD_compress_usingCDict` to compress each data block using the pre-digested dictionary. Once the files created `ZSTD_freeCDict` releases the resources held by the digested dictionary. There are a couple other changes included in this PR: Changed the parameter object for (un)compression functions from `CompressionContext`/`UncompressionContext` to `CompressionInfo`/`UncompressionInfo`. This avoids the previous pattern, where `CompressionContext`/`UncompressionContext` had to be mutated before calling a (un)compression function depending on whether dictionary should be used. I felt that mutation was error-prone so eliminated it. Added support for digested uncompression dictionaries (`ZSTD_DDict`) as well. However, this PR does not support reusing them across uncompression calls for the same file. That work is deferred to a later PR when we will store the `ZSTD_DDict` objects in block cache. Pull Request resolved: Differential Revision: D9257078 Pulled By: ajkr fbshipit-source-id: 21b8cb6bbdd48e459f1c62343780ab66c0a64438/"
,,0.1401,rocksdb,"Two code changes to make ""clang analyze"" happy (#4292) Summary: Clang analyze is not happy in two pieces of code, with ""Potential memory leak"". No idea what the problem but slightly changing the code makes clang happy. Pull Request resolved: Differential Revision: D9413555 Pulled By: siying fbshipit-source-id: 9428c9d3664530c72129feefd135ee63d8386137/"
,,0.1821,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/"
,,0.1132,rocksdb,"Add listener to sample file io (#3933) Summary: We would like to collect file-system-level statistics including file name, offset, length, return code, latency, etc., which requires to add callbacks to intercept file IO function calls when RocksDB is running. To collect file-system-level statistics, users can inherit the class `EventListener`, as in `TestFileOperationListener `. Note that `TestFileOperationListener::ShouldBeNotifiedOnFileIO()` returns true. Pull Request resolved: Differential Revision: D10219571 Pulled By: riversand963 fbshipit-source-id: 7acc577a2d31097766a27adb6f78eaf8b1e8ff15/"
,,0.3411,rocksdb,"s/CacheAllocator/MemoryAllocator/g (#4590) Summary: Rename the interface, as it is mean to be a generic interface for memory allocation. Pull Request resolved: Differential Revision: D10866340 Pulled By: yiwu-arbug fbshipit-source-id: 85cb753351a40cb856c046aeaa3f3b369eef3d16/Introduce CacheAllocator, a custom allocator for cache blocks (#4437) Summary: This is a conceptually simple change, but it touches many files to pass the allocator through function calls. We introduce CacheAllocator, which can be used by clients to configure custom allocator for cache blocks. Our motivation is to hook this up with follys `JemallocNodumpAllocator` ( but there are many other possible use cases. Additionally, this commit cleans up memory allocation in `util/compression.h`, making sure that all allocations are wrapped in a unique_ptr as soon as possible. Pull Request resolved: Differential Revision: D10132814 Pulled By: yiwu-arbug fbshipit-source-id: be1343a4b69f6048df127939fea9bbc96969f564/"
,,0.2746,rocksdb,"Support pragma once in all header files and cleanup some warnings (#4339) Summary: As you know, almost all compilers support ""pragma once"" keyword instead of using include guards. To be keep consistency between header files, all header files are edited. Besides this, try to fix some warnings about loss of data. Pull Request resolved: Differential Revision: D9654990 Pulled By: ajkr fbshipit-source-id: c2cf3d2d03a599847684bed81378c401920ca848/"
,,0.1182,rocksdb,Add UInt64AddOperator to rocksjava (#4448) Summary: Closes Pull Request resolved: Differential Revision: D10351852 Pulled By: ajkr fbshipit-source-id: 18287b5190ae0b8153ce425da9a0bdfe1af88c34/
,,0.1361,rocksdb,Plumb WriteBufferManager through JNI (#4492) Summary: Allow rocks java to explicitly create WriteBufferManager by plumbing it to the native code through JNI. Pull Request resolved: Differential Revision: D10428506 Pulled By: sagar0 fbshipit-source-id: cd9dd8c2ef745a0303416b44e2080547bdcca1fd/
,,0.1803,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/"
,,0.2055,rocksdb,Add path to WritableFileWriter. (#4039) Summary: We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise its hard to tell what has been going on. Pull Request resolved: Differential Revision: D8670178 Pulled By: riversand963 fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/
,,0.209,rocksdb,Add path to WritableFileWriter. (#4039) Summary: We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise its hard to tell what has been going on. Pull Request resolved: Differential Revision: D8670178 Pulled By: riversand963 fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/
,,0.1855,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/"
,,0.1969,rocksdb,fix compilation with g++ option `-Wsuggest-override` (#4272) Summary: Fixes compilation warnings (which are turned into compilation errors by default) when compiling with g++ option `-Wsuggest-override`. Pull Request resolved: Differential Revision: D9322556 Pulled By: siying fbshipit-source-id: abd57a29ec8f544bee77c0bb438f31be830b7244/
,,0.1604,rocksdb,Suppress clang analyzer error (#4299) Summary: Suppress multiple clang-analyzer error. All of them are clang false-positive. Pull Request resolved: Differential Revision: D9430740 Pulled By: yiwu-arbug fbshipit-source-id: fbdd575bdc214d124826d61d35a117995c509279/
,,0.3894,rocksdb,"Digest ZSTD compression dictionary once per SST file (#4251) Summary: In RocksDB, for a given SST file, all data blocks are compressed with the same dictionary. When we compress a block using the dictionarys raw bytes, the compression library first has to digest the dictionary to get it into a usable form. This digestion work is redundant and ideally should be done once per file. ZSTD offers APIs for the caller to create and reuse a digested dictionary object (`ZSTD_CDict`). In this PR, we call `ZSTD_createCDict` once per file to digest the raw bytes. Then we use `ZSTD_compress_usingCDict` to compress each data block using the pre-digested dictionary. Once the files created `ZSTD_freeCDict` releases the resources held by the digested dictionary. There are a couple other changes included in this PR: Changed the parameter object for (un)compression functions from `CompressionContext`/`UncompressionContext` to `CompressionInfo`/`UncompressionInfo`. This avoids the previous pattern, where `CompressionContext`/`UncompressionContext` had to be mutated before calling a (un)compression function depending on whether dictionary should be used. I felt that mutation was error-prone so eliminated it. Added support for digested uncompression dictionaries (`ZSTD_DDict`) as well. However, this PR does not support reusing them across uncompression calls for the same file. That work is deferred to a later PR when we will store the `ZSTD_DDict` objects in block cache. Pull Request resolved: Differential Revision: D9257078 Pulled By: ajkr fbshipit-source-id: 21b8cb6bbdd48e459f1c62343780ab66c0a64438/"
,,0.5431,rocksdb,"Revert ""Digest ZSTD compression dictionary once per SST file (#4251)"" (#4347) Summary: Reverting is needed to unblock a user building against master, who is blocked for multiple days due to a thread-safety issue in `GetEmptyDict`. We havent been able to fix it quickly, so reverting. Simply ran `git revert 6c40806e51a89386d2b066fddf73d3fd03a36f65`. There were no merge conflicts. Pull Request resolved: Differential Revision: D9668365 Pulled By: ajkr fbshipit-source-id: 0c56334f0a23cf5ee0233d4e4679eae6709739cd/Support pragma once in all header files and cleanup some warnings (#4339) Summary: As you know, almost all compilers support ""pragma once"" keyword instead of using include guards. To be keep consistency between header files, all header files are edited. Besides this, try to fix some warnings about loss of data. Pull Request resolved: Differential Revision: D9654990 Pulled By: ajkr fbshipit-source-id: c2cf3d2d03a599847684bed81378c401920ca848/Digest ZSTD compression dictionary once per SST file (#4251) Summary: In RocksDB, for a given SST file, all data blocks are compressed with the same dictionary. When we compress a block using the dictionarys raw bytes, the compression library first has to digest the dictionary to get it into a usable form. This digestion work is redundant and ideally should be done once per file. ZSTD offers APIs for the caller to create and reuse a digested dictionary object (`ZSTD_CDict`). In this PR, we call `ZSTD_createCDict` once per file to digest the raw bytes. Then we use `ZSTD_compress_usingCDict` to compress each data block using the pre-digested dictionary. Once the files created `ZSTD_freeCDict` releases the resources held by the digested dictionary. There are a couple other changes included in this PR: Changed the parameter object for (un)compression functions from `CompressionContext`/`UncompressionContext` to `CompressionInfo`/`UncompressionInfo`. This avoids the previous pattern, where `CompressionContext`/`UncompressionContext` had to be mutated before calling a (un)compression function depending on whether dictionary should be used. I felt that mutation was error-prone so eliminated it. Added support for digested uncompression dictionaries (`ZSTD_DDict`) as well. However, this PR does not support reusing them across uncompression calls for the same file. That work is deferred to a later PR when we will store the `ZSTD_DDict` objects in block cache. Pull Request resolved: Differential Revision: D9257078 Pulled By: ajkr fbshipit-source-id: 21b8cb6bbdd48e459f1c62343780ab66c0a64438/"
,,0.281,rocksdb,"Support pragma once in all header files and cleanup some warnings (#4339) Summary: As you know, almost all compilers support ""pragma once"" keyword instead of using include guards. To be keep consistency between header files, all header files are edited. Besides this, try to fix some warnings about loss of data. Pull Request resolved: Differential Revision: D9654990 Pulled By: ajkr fbshipit-source-id: c2cf3d2d03a599847684bed81378c401920ca848/"
,,0.4771,rocksdb,"BlobDB: handle IO error on write (#4580) Summary: A fix similar to but on the write path. On IO error on `SelectBlobFile()` we didnt return error code properly, but simply a nullptr of `BlobFile`. The `AppendBlob()` method didnt have null check for the pointer and caused crash. The fix make sure we properly return error code in this case. Pull Request resolved: Differential Revision: D10513849 Pulled By: yiwu-arbug fbshipit-source-id: 80bca920d1d7a3541149de981015ad83e0aa14b5/BlobDB: handle IO error on read (#4410) Summary: Fix IO error on read not being handle and crashing the DB. With the fix we properly return the error. Pull Request resolved: Differential Revision: D9979246 Pulled By: yiwu-arbug fbshipit-source-id: 111a85675067a29c03cb60e9a34103f4ff636694/Revert ""Digest ZSTD compression dictionary once per SST file (#4251)"" (#4347) Summary: Reverting is needed to unblock a user building against master, who is blocked for multiple days due to a thread-safety issue in `GetEmptyDict`. We havent been able to fix it quickly, so reverting. Simply ran `git revert 6c40806e51a89386d2b066fddf73d3fd03a36f65`. There were no merge conflicts. Pull Request resolved: Differential Revision: D9668365 Pulled By: ajkr fbshipit-source-id: 0c56334f0a23cf5ee0233d4e4679eae6709739cd/Support pragma once in all header files and cleanup some warnings (#4339) Summary: As you know, almost all compilers support ""pragma once"" keyword instead of using include guards. To be keep consistency between header files, all header files are edited. Besides this, try to fix some warnings about loss of data. Pull Request resolved: Differential Revision: D9654990 Pulled By: ajkr fbshipit-source-id: c2cf3d2d03a599847684bed81378c401920ca848/BlobDB: Improve info log (#4324) Summary: Improve BlobDB info logs. Pull Request resolved: Differential Revision: D9545074 Pulled By: yiwu-arbug fbshipit-source-id: 678ab8820a78758fee451be3b123b0680c1081df/BlobDB: Avoid returning garbage value on key not found (#4321) Summary: When reading an expired key using `Get(..., std::string* value)` API, BlobDB first read the index entry and decode expiration from it. In this case, although BlobDB reset the PinnableSlice, the index entry is stored in user provided string `value`. The value will be returned as a garbage value, despite status being NotFound. Fixing it by use a different PinnableSlice to read the index entry. Pull Request resolved: Differential Revision: D9519042 Pulled By: yiwu-arbug fbshipit-source-id: f054c951a1fa98265228be94f931904ed7056677/Digest ZSTD compression dictionary once per SST file (#4251) Summary: In RocksDB, for a given SST file, all data blocks are compressed with the same dictionary. When we compress a block using the dictionarys raw bytes, the compression library first has to digest the dictionary to get it into a usable form. This digestion work is redundant and ideally should be done once per file. ZSTD offers APIs for the caller to create and reuse a digested dictionary object (`ZSTD_CDict`). In this PR, we call `ZSTD_createCDict` once per file to digest the raw bytes. Then we use `ZSTD_compress_usingCDict` to compress each data block using the pre-digested dictionary. Once the files created `ZSTD_freeCDict` releases the resources held by the digested dictionary. There are a couple other changes included in this PR: Changed the parameter object for (un)compression functions from `CompressionContext`/`UncompressionContext` to `CompressionInfo`/`UncompressionInfo`. This avoids the previous pattern, where `CompressionContext`/`UncompressionContext` had to be mutated before calling a (un)compression function depending on whether dictionary should be used. I felt that mutation was error-prone so eliminated it. Added support for digested uncompression dictionaries (`ZSTD_DDict`) as well. However, this PR does not support reusing them across uncompression calls for the same file. That work is deferred to a later PR when we will store the `ZSTD_DDict` objects in block cache. Pull Request resolved: Differential Revision: D9257078 Pulled By: ajkr fbshipit-source-id: 21b8cb6bbdd48e459f1c62343780ab66c0a64438/Add path to WritableFileWriter. (#4039) Summary: We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise its hard to tell what has been going on. Pull Request resolved: Differential Revision: D8670178 Pulled By: riversand963 fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/BlobDB: Fix expired file not being evicted (#4294) Summary: Fix expired file not being evicted from the DB. We have a background task (previously called `CheckSeqFiles` and I rename it to `EvictExpiredFiles`) to scan and remove expired files, but it only close the files, not marking them as expired. Pull Request resolved: Differential Revision: D9415984 Pulled By: yiwu-arbug fbshipit-source-id: eff7bf0331c52a7ccdb02318602bff7f64f3ef3d/"
,,0.3762,rocksdb,"s/CacheAllocator/MemoryAllocator/g (#4590) Summary: Rename the interface, as it is mean to be a generic interface for memory allocation. Pull Request resolved: Differential Revision: D10866340 Pulled By: yiwu-arbug fbshipit-source-id: 85cb753351a40cb856c046aeaa3f3b369eef3d16/Cache fragmented range tombstones in BlockBasedTableReader (#4493) Summary: This allows tombstone fragmenting to only be performed when the table is opened, and cached for subsequent accesses. On the same DB used in running `readrandom` results in the following: ``` readrandom : 0.983 micros/op 1017076 ops/sec; 78.3 MB/s (63103 of 100000 found) ``` Now that Get performance in the presence of range tombstones is reasonable, I also compared the performance between a DB with range tombstones, ""expanded"" range tombstones (several point tombstones that cover the same keys the equivalent range tombstone would cover, a common workaround for DeleteRange), and no range tombstones. The created DBs had 5 million keys each, and DeleteRange was called at regular intervals (depending on the total number of range tombstones being written) after 4.5 million Puts. The table below summarizes the results of a `readwhilewriting` benchmark (in order to provide somewhat more realistic results): ``` Tombstones? | avg micros/op | stddev micros/op | avg ops/s | stddev ops/s | | | | None | 0.6186 | 0.04637 | 1,625,252.90 | 124,679.41 500 Expanded | 0.6019 | 0.03628 | 1,666,670.40 | 101,142.65 500 Unexpanded | 0.6435 | 0.03994 | 1,559,979.40 | 104,090.52 1k Expanded | 0.6034 | 0.04349 | 1,665,128.10 | 125,144.57 1k Unexpanded | 0.6261 | 0.03093 | 1,600,457.50 | 79,024.94 5k Expanded | 0.6163 | 0.05926 | 1,636,668.80 | 154,888.85 5k Unexpanded | 0.6402 | 0.04002 | 1,567,804.70 | 100,965.55 10k Expanded | 0.6036 | 0.05105 | 1,667,237.70 | 142,830.36 10k Unexpanded | 0.6128 | 0.02598 | 1,634,633.40 | 72,161.82 25k Expanded | 0.6198 | 0.04542 | 1,620,980.50 | 116,662.93 25k Unexpanded | 0.5478 | 0.0362 | 1,833,059.10 | 121,233.81 50k Expanded | 0.5104 | 0.04347 | 1,973,107.90 | 184,073.49 50k Unexpanded | 0.4528 | 0.03387 | 2,219,034.50 | 170,984.32 ``` After a large enough quantity of range tombstones are written, range tombstone Gets can become faster than reading from an equivalent DB with several point tombstones. Pull Request resolved: Differential Revision: D10842844 Pulled By: abhimadan fbshipit-source-id: a7d44534f8120e6aabb65779d26c6b9df954c509/Introduce CacheAllocator, a custom allocator for cache blocks (#4437) Summary: This is a conceptually simple change, but it touches many files to pass the allocator through function calls. We introduce CacheAllocator, which can be used by clients to configure custom allocator for cache blocks. Our motivation is to hook this up with follys `JemallocNodumpAllocator` ( but there are many other possible use cases. Additionally, this commit cleans up memory allocation in `util/compression.h`, making sure that all allocations are wrapped in a unique_ptr as soon as possible. Pull Request resolved: Differential Revision: D10132814 Pulled By: yiwu-arbug fbshipit-source-id: be1343a4b69f6048df127939fea9bbc96969f564/"
,,0.3383,rocksdb,"s/CacheAllocator/MemoryAllocator/g (#4590) Summary: Rename the interface, as it is mean to be a generic interface for memory allocation. Pull Request resolved: Differential Revision: D10866340 Pulled By: yiwu-arbug fbshipit-source-id: 85cb753351a40cb856c046aeaa3f3b369eef3d16/Introduce CacheAllocator, a custom allocator for cache blocks (#4437) Summary: This is a conceptually simple change, but it touches many files to pass the allocator through function calls. We introduce CacheAllocator, which can be used by clients to configure custom allocator for cache blocks. Our motivation is to hook this up with follys `JemallocNodumpAllocator` ( but there are many other possible use cases. Additionally, this commit cleans up memory allocation in `util/compression.h`, making sure that all allocations are wrapped in a unique_ptr as soon as possible. Pull Request resolved: Differential Revision: D10132814 Pulled By: yiwu-arbug fbshipit-source-id: be1343a4b69f6048df127939fea9bbc96969f564/"
,,0.4379,rocksdb,"xxhash 64 support Summary: Pull Request resolved: Reviewed By: siying Differential Revision: D12836696 Pulled By: jsjhoubo fbshipit-source-id: 7122ccb712d0b0f1cd998aa4477e0da1401bd870/Promote rocksdb.{deleted.keys,merge.operands} to main table properties (#4594) Summary: Since the number of range deletions are reported in TableProperties, it is confusing to not report the number of merge operands and point deletions as top-level properties; they are accessible through the public API, but since they are not the ""main"" properties, they do not appear in aggregated table properties, or the string representation of table properties. This change promotes those two property keys to `rocksdb/table_properties.h`, adds corresponding uint64 members for them, deprecates the old access methods `GetDeletedKeys()` and `GetMergeOperands()` (though they are still usable for now), and removes `InternalKeyPropertiesCollector`. The property key strings are the same as before this change, so this should be able to read DBs written from older versions (though I havent tested this yet). Pull Request resolved: Differential Revision: D12826893 Pulled By: abhimadan fbshipit-source-id: 9e4e4fbdc5b0da161c89582566d184101ba8eb68/s/CacheAllocator/MemoryAllocator/g (#4590) Summary: Rename the interface, as it is mean to be a generic interface for memory allocation. Pull Request resolved: Differential Revision: D10866340 Pulled By: yiwu-arbug fbshipit-source-id: 85cb753351a40cb856c046aeaa3f3b369eef3d16/Introduce CacheAllocator, a custom allocator for cache blocks (#4437) Summary: This is a conceptually simple change, but it touches many files to pass the allocator through function calls. We introduce CacheAllocator, which can be used by clients to configure custom allocator for cache blocks. Our motivation is to hook this up with follys `JemallocNodumpAllocator` ( but there are many other possible use cases. Additionally, this commit cleans up memory allocation in `util/compression.h`, making sure that all allocations are wrapped in a unique_ptr as soon as possible. Pull Request resolved: Differential Revision: D10132814 Pulled By: yiwu-arbug fbshipit-source-id: be1343a4b69f6048df127939fea9bbc96969f564/Revert ""Digest ZSTD compression dictionary once per SST file (#4251)"" (#4347) Summary: Reverting is needed to unblock a user building against master, who is blocked for multiple days due to a thread-safety issue in `GetEmptyDict`. We havent been able to fix it quickly, so reverting. Simply ran `git revert 6c40806e51a89386d2b066fddf73d3fd03a36f65`. There were no merge conflicts. Pull Request resolved: Differential Revision: D9668365 Pulled By: ajkr fbshipit-source-id: 0c56334f0a23cf5ee0233d4e4679eae6709739cd/Digest ZSTD compression dictionary once per SST file (#4251) Summary: In RocksDB, for a given SST file, all data blocks are compressed with the same dictionary. When we compress a block using the dictionarys raw bytes, the compression library first has to digest the dictionary to get it into a usable form. This digestion work is redundant and ideally should be done once per file. ZSTD offers APIs for the caller to create and reuse a digested dictionary object (`ZSTD_CDict`). In this PR, we call `ZSTD_createCDict` once per file to digest the raw bytes. Then we use `ZSTD_compress_usingCDict` to compress each data block using the pre-digested dictionary. Once the files created `ZSTD_freeCDict` releases the resources held by the digested dictionary. There are a couple other changes included in this PR: Changed the parameter object for (un)compression functions from `CompressionContext`/`UncompressionContext` to `CompressionInfo`/`UncompressionInfo`. This avoids the previous pattern, where `CompressionContext`/`UncompressionContext` had to be mutated before calling a (un)compression function depending on whether dictionary should be used. I felt that mutation was error-prone so eliminated it. Added support for digested uncompression dictionaries (`ZSTD_DDict`) as well. However, this PR does not support reusing them across uncompression calls for the same file. That work is deferred to a later PR when we will store the `ZSTD_DDict` objects in block cache. Pull Request resolved: Differential Revision: D9257078 Pulled By: ajkr fbshipit-source-id: 21b8cb6bbdd48e459f1c62343780ab66c0a64438/"
,,0.1132,rocksdb,"Add listener to sample file io (#3933) Summary: We would like to collect file-system-level statistics including file name, offset, length, return code, latency, etc., which requires to add callbacks to intercept file IO function calls when RocksDB is running. To collect file-system-level statistics, users can inherit the class `EventListener`, as in `TestFileOperationListener `. Note that `TestFileOperationListener::ShouldBeNotifiedOnFileIO()` returns true. Pull Request resolved: Differential Revision: D10219571 Pulled By: riversand963 fbshipit-source-id: 7acc577a2d31097766a27adb6f78eaf8b1e8ff15/"
,,0.2002,rocksdb,Add path to WritableFileWriter. (#4039) Summary: We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise its hard to tell what has been going on. Pull Request resolved: Differential Revision: D8670178 Pulled By: riversand963 fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/
,,0.5765,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/s/CacheAllocator/MemoryAllocator/g (#4590) Summary: Rename the interface, as it is mean to be a generic interface for memory allocation. Pull Request resolved: Differential Revision: D10866340 Pulled By: yiwu-arbug fbshipit-source-id: 85cb753351a40cb856c046aeaa3f3b369eef3d16/Cache fragmented range tombstones in BlockBasedTableReader (#4493) Summary: This allows tombstone fragmenting to only be performed when the table is opened, and cached for subsequent accesses. On the same DB used in running `readrandom` results in the following: ``` readrandom : 0.983 micros/op 1017076 ops/sec; 78.3 MB/s (63103 of 100000 found) ``` Now that Get performance in the presence of range tombstones is reasonable, I also compared the performance between a DB with range tombstones, ""expanded"" range tombstones (several point tombstones that cover the same keys the equivalent range tombstone would cover, a common workaround for DeleteRange), and no range tombstones. The created DBs had 5 million keys each, and DeleteRange was called at regular intervals (depending on the total number of range tombstones being written) after 4.5 million Puts. The table below summarizes the results of a `readwhilewriting` benchmark (in order to provide somewhat more realistic results): ``` Tombstones? | avg micros/op | stddev micros/op | avg ops/s | stddev ops/s | | | | None | 0.6186 | 0.04637 | 1,625,252.90 | 124,679.41 500 Expanded | 0.6019 | 0.03628 | 1,666,670.40 | 101,142.65 500 Unexpanded | 0.6435 | 0.03994 | 1,559,979.40 | 104,090.52 1k Expanded | 0.6034 | 0.04349 | 1,665,128.10 | 125,144.57 1k Unexpanded | 0.6261 | 0.03093 | 1,600,457.50 | 79,024.94 5k Expanded | 0.6163 | 0.05926 | 1,636,668.80 | 154,888.85 5k Unexpanded | 0.6402 | 0.04002 | 1,567,804.70 | 100,965.55 10k Expanded | 0.6036 | 0.05105 | 1,667,237.70 | 142,830.36 10k Unexpanded | 0.6128 | 0.02598 | 1,634,633.40 | 72,161.82 25k Expanded | 0.6198 | 0.04542 | 1,620,980.50 | 116,662.93 25k Unexpanded | 0.5478 | 0.0362 | 1,833,059.10 | 121,233.81 50k Expanded | 0.5104 | 0.04347 | 1,973,107.90 | 184,073.49 50k Unexpanded | 0.4528 | 0.03387 | 2,219,034.50 | 170,984.32 ``` After a large enough quantity of range tombstones are written, range tombstone Gets can become faster than reading from an equivalent DB with several point tombstones. Pull Request resolved: Differential Revision: D10842844 Pulled By: abhimadan fbshipit-source-id: a7d44534f8120e6aabb65779d26c6b9df954c509/fix unused param `allocator` in compression.h (#4453) Summary: this should fix currently failing contrun test: rocksdb-contrun-no_compression, rocksdb-contrun-tsan, rocksdb-contrun-tsan_crash Pull Request resolved: Differential Revision: D10202626 Pulled By: miasantreble fbshipit-source-id: 850b07f14f671b5998c22d8239e2a55b2fc1e355/Introduce CacheAllocator, a custom allocator for cache blocks (#4437) Summary: This is a conceptually simple change, but it touches many files to pass the allocator through function calls. We introduce CacheAllocator, which can be used by clients to configure custom allocator for cache blocks. Our motivation is to hook this up with follys `JemallocNodumpAllocator` ( but there are many other possible use cases. Additionally, this commit cleans up memory allocation in `util/compression.h`, making sure that all allocations are wrapped in a unique_ptr as soon as possible. Pull Request resolved: Differential Revision: D10132814 Pulled By: yiwu-arbug fbshipit-source-id: be1343a4b69f6048df127939fea9bbc96969f564/Revert ""Digest ZSTD compression dictionary once per SST file (#4251)"" (#4347) Summary: Reverting is needed to unblock a user building against master, who is blocked for multiple days due to a thread-safety issue in `GetEmptyDict`. We havent been able to fix it quickly, so reverting. Simply ran `git revert 6c40806e51a89386d2b066fddf73d3fd03a36f65`. There were no merge conflicts. Pull Request resolved: Differential Revision: D9668365 Pulled By: ajkr fbshipit-source-id: 0c56334f0a23cf5ee0233d4e4679eae6709739cd/Support pragma once in all header files and cleanup some warnings (#4339) Summary: As you know, almost all compilers support ""pragma once"" keyword instead of using include guards. To be keep consistency between header files, all header files are edited. Besides this, try to fix some warnings about loss of data. Pull Request resolved: Differential Revision: D9654990 Pulled By: ajkr fbshipit-source-id: c2cf3d2d03a599847684bed81378c401920ca848/Digest ZSTD compression dictionary once per SST file (#4251) Summary: In RocksDB, for a given SST file, all data blocks are compressed with the same dictionary. When we compress a block using the dictionarys raw bytes, the compression library first has to digest the dictionary to get it into a usable form. This digestion work is redundant and ideally should be done once per file. ZSTD offers APIs for the caller to create and reuse a digested dictionary object (`ZSTD_CDict`). In this PR, we call `ZSTD_createCDict` once per file to digest the raw bytes. Then we use `ZSTD_compress_usingCDict` to compress each data block using the pre-digested dictionary. Once the files created `ZSTD_freeCDict` releases the resources held by the digested dictionary. There are a couple other changes included in this PR: Changed the parameter object for (un)compression functions from `CompressionContext`/`UncompressionContext` to `CompressionInfo`/`UncompressionInfo`. This avoids the previous pattern, where `CompressionContext`/`UncompressionContext` had to be mutated before calling a (un)compression function depending on whether dictionary should be used. I felt that mutation was error-prone so eliminated it. Added support for digested uncompression dictionaries (`ZSTD_DDict`) as well. However, this PR does not support reusing them across uncompression calls for the same file. That work is deferred to a later PR when we will store the `ZSTD_DDict` objects in block cache. Pull Request resolved: Differential Revision: D9257078 Pulled By: ajkr fbshipit-source-id: 21b8cb6bbdd48e459f1c62343780ab66c0a64438/Suppress two CLANG Analyze warning (#4291) Summary: Suppress two CLANG analyze warnings. They dont seem to be real bugs Pull Request resolved: Differential Revision: D9407333 Pulled By: siying fbshipit-source-id: 2ed63d88fa0b217fdccb1572d7508467c2203dc8/"
,,0.4767,rocksdb,"Revert ""Digest ZSTD compression dictionary once per SST file (#4251)"" (#4347) Summary: Reverting is needed to unblock a user building against master, who is blocked for multiple days due to a thread-safety issue in `GetEmptyDict`. We havent been able to fix it quickly, so reverting. Simply ran `git revert 6c40806e51a89386d2b066fddf73d3fd03a36f65`. There were no merge conflicts. Pull Request resolved: Differential Revision: D9668365 Pulled By: ajkr fbshipit-source-id: 0c56334f0a23cf5ee0233d4e4679eae6709739cd/Digest ZSTD compression dictionary once per SST file (#4251) Summary: In RocksDB, for a given SST file, all data blocks are compressed with the same dictionary. When we compress a block using the dictionarys raw bytes, the compression library first has to digest the dictionary to get it into a usable form. This digestion work is redundant and ideally should be done once per file. ZSTD offers APIs for the caller to create and reuse a digested dictionary object (`ZSTD_CDict`). In this PR, we call `ZSTD_createCDict` once per file to digest the raw bytes. Then we use `ZSTD_compress_usingCDict` to compress each data block using the pre-digested dictionary. Once the files created `ZSTD_freeCDict` releases the resources held by the digested dictionary. There are a couple other changes included in this PR: Changed the parameter object for (un)compression functions from `CompressionContext`/`UncompressionContext` to `CompressionInfo`/`UncompressionInfo`. This avoids the previous pattern, where `CompressionContext`/`UncompressionContext` had to be mutated before calling a (un)compression function depending on whether dictionary should be used. I felt that mutation was error-prone so eliminated it. Added support for digested uncompression dictionaries (`ZSTD_DDict`) as well. However, this PR does not support reusing them across uncompression calls for the same file. That work is deferred to a later PR when we will store the `ZSTD_DDict` objects in block cache. Pull Request resolved: Differential Revision: D9257078 Pulled By: ajkr fbshipit-source-id: 21b8cb6bbdd48e459f1c62343780ab66c0a64438/"
,,0.5567,rocksdb,"fix unused param `allocator` in compression.h (#4453) Summary: this should fix currently failing contrun test: rocksdb-contrun-no_compression, rocksdb-contrun-tsan, rocksdb-contrun-tsan_crash Pull Request resolved: Differential Revision: D10202626 Pulled By: miasantreble fbshipit-source-id: 850b07f14f671b5998c22d8239e2a55b2fc1e355/Introduce CacheAllocator, a custom allocator for cache blocks (#4437) Summary: This is a conceptually simple change, but it touches many files to pass the allocator through function calls. We introduce CacheAllocator, which can be used by clients to configure custom allocator for cache blocks. Our motivation is to hook this up with follys `JemallocNodumpAllocator` ( but there are many other possible use cases. Additionally, this commit cleans up memory allocation in `util/compression.h`, making sure that all allocations are wrapped in a unique_ptr as soon as possible. Pull Request resolved: Differential Revision: D10132814 Pulled By: yiwu-arbug fbshipit-source-id: be1343a4b69f6048df127939fea9bbc96969f564/Revert ""Digest ZSTD compression dictionary once per SST file (#4251)"" (#4347) Summary: Reverting is needed to unblock a user building against master, who is blocked for multiple days due to a thread-safety issue in `GetEmptyDict`. We havent been able to fix it quickly, so reverting. Simply ran `git revert 6c40806e51a89386d2b066fddf73d3fd03a36f65`. There were no merge conflicts. Pull Request resolved: Differential Revision: D9668365 Pulled By: ajkr fbshipit-source-id: 0c56334f0a23cf5ee0233d4e4679eae6709739cd/Digest ZSTD compression dictionary once per SST file (#4251) Summary: In RocksDB, for a given SST file, all data blocks are compressed with the same dictionary. When we compress a block using the dictionarys raw bytes, the compression library first has to digest the dictionary to get it into a usable form. This digestion work is redundant and ideally should be done once per file. ZSTD offers APIs for the caller to create and reuse a digested dictionary object (`ZSTD_CDict`). In this PR, we call `ZSTD_createCDict` once per file to digest the raw bytes. Then we use `ZSTD_compress_usingCDict` to compress each data block using the pre-digested dictionary. Once the files created `ZSTD_freeCDict` releases the resources held by the digested dictionary. There are a couple other changes included in this PR: Changed the parameter object for (un)compression functions from `CompressionContext`/`UncompressionContext` to `CompressionInfo`/`UncompressionInfo`. This avoids the previous pattern, where `CompressionContext`/`UncompressionContext` had to be mutated before calling a (un)compression function depending on whether dictionary should be used. I felt that mutation was error-prone so eliminated it. Added support for digested uncompression dictionaries (`ZSTD_DDict`) as well. However, this PR does not support reusing them across uncompression calls for the same file. That work is deferred to a later PR when we will store the `ZSTD_DDict` objects in block cache. Pull Request resolved: Differential Revision: D9257078 Pulled By: ajkr fbshipit-source-id: 21b8cb6bbdd48e459f1c62343780ab66c0a64438/"
,,0.5552,rocksdb,"s/CacheAllocator/MemoryAllocator/g (#4590) Summary: Rename the interface, as it is mean to be a generic interface for memory allocation. Pull Request resolved: Differential Revision: D10866340 Pulled By: yiwu-arbug fbshipit-source-id: 85cb753351a40cb856c046aeaa3f3b369eef3d16/Introduce CacheAllocator, a custom allocator for cache blocks (#4437) Summary: This is a conceptually simple change, but it touches many files to pass the allocator through function calls. We introduce CacheAllocator, which can be used by clients to configure custom allocator for cache blocks. Our motivation is to hook this up with follys `JemallocNodumpAllocator` ( but there are many other possible use cases. Additionally, this commit cleans up memory allocation in `util/compression.h`, making sure that all allocations are wrapped in a unique_ptr as soon as possible. Pull Request resolved: Differential Revision: D10132814 Pulled By: yiwu-arbug fbshipit-source-id: be1343a4b69f6048df127939fea9bbc96969f564/Revert ""Digest ZSTD compression dictionary once per SST file (#4251)"" (#4347) Summary: Reverting is needed to unblock a user building against master, who is blocked for multiple days due to a thread-safety issue in `GetEmptyDict`. We havent been able to fix it quickly, so reverting. Simply ran `git revert 6c40806e51a89386d2b066fddf73d3fd03a36f65`. There were no merge conflicts. Pull Request resolved: Differential Revision: D9668365 Pulled By: ajkr fbshipit-source-id: 0c56334f0a23cf5ee0233d4e4679eae6709739cd/Digest ZSTD compression dictionary once per SST file (#4251) Summary: In RocksDB, for a given SST file, all data blocks are compressed with the same dictionary. When we compress a block using the dictionarys raw bytes, the compression library first has to digest the dictionary to get it into a usable form. This digestion work is redundant and ideally should be done once per file. ZSTD offers APIs for the caller to create and reuse a digested dictionary object (`ZSTD_CDict`). In this PR, we call `ZSTD_createCDict` once per file to digest the raw bytes. Then we use `ZSTD_compress_usingCDict` to compress each data block using the pre-digested dictionary. Once the files created `ZSTD_freeCDict` releases the resources held by the digested dictionary. There are a couple other changes included in this PR: Changed the parameter object for (un)compression functions from `CompressionContext`/`UncompressionContext` to `CompressionInfo`/`UncompressionInfo`. This avoids the previous pattern, where `CompressionContext`/`UncompressionContext` had to be mutated before calling a (un)compression function depending on whether dictionary should be used. I felt that mutation was error-prone so eliminated it. Added support for digested uncompression dictionaries (`ZSTD_DDict`) as well. However, this PR does not support reusing them across uncompression calls for the same file. That work is deferred to a later PR when we will store the `ZSTD_DDict` objects in block cache. Pull Request resolved: Differential Revision: D9257078 Pulled By: ajkr fbshipit-source-id: 21b8cb6bbdd48e459f1c62343780ab66c0a64438/"
,,0.2762,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/s/CacheAllocator/MemoryAllocator/g (#4590) Summary: Rename the interface, as it is mean to be a generic interface for memory allocation. Pull Request resolved: Differential Revision: D10866340 Pulled By: yiwu-arbug fbshipit-source-id: 85cb753351a40cb856c046aeaa3f3b369eef3d16/Introduce CacheAllocator, a custom allocator for cache blocks (#4437) Summary: This is a conceptually simple change, but it touches many files to pass the allocator through function calls. We introduce CacheAllocator, which can be used by clients to configure custom allocator for cache blocks. Our motivation is to hook this up with follys `JemallocNodumpAllocator` ( but there are many other possible use cases. Additionally, this commit cleans up memory allocation in `util/compression.h`, making sure that all allocations are wrapped in a unique_ptr as soon as possible. Pull Request resolved: Differential Revision: D10132814 Pulled By: yiwu-arbug fbshipit-source-id: be1343a4b69f6048df127939fea9bbc96969f564/Improve point-lookup performance using a data block hash index (#4174) Summary: Add hash index support to data blocks, which helps to reduce the CPU utilization of point-lookup operations. This feature is backward compatible with the data block created without the hash index. It is disabled by default unless `BlockBasedTableOptions::data_block_index_type` is set to `data_block_index_type kDataBlockBinaryAndHash.` The DB size would be bigger with the hash index option as a hash table is added at the end of each data block. If the hash utilization ratio is 1:1, the space overhead is one byte per key. The hash table utilization ratio is adjustable using `BlockBasedTableOptions::data_block_hash_table_util_ratio`. A lower utilization ratio will improve more on the point-lookup efficiency, but take more space too. Pull Request resolved: Differential Revision: D8965914 Pulled By: fgwu fbshipit-source-id: 1c6bae5d1fc39c80282d8890a72e9e67bc247198/"
,,0.1119,rocksdb,followup for fix performance degression introduced by switching order of operands (#4284) Summary: Followup for There is one more place in **get_context.cc** where **MergeOperator::ShouldMerge** should be called with reversed list of operands. Pull Request resolved: Differential Revision: D9380008 Pulled By: sagar0 fbshipit-source-id: 70ec26e607e5b88465e1acbdcd6c6171bd76b9f2/
,,0.5373,rocksdb,"xxhash 64 support Summary: Pull Request resolved: Reviewed By: siying Differential Revision: D12836696 Pulled By: jsjhoubo fbshipit-source-id: 7122ccb712d0b0f1cd998aa4477e0da1401bd870/Introduce CacheAllocator, a custom allocator for cache blocks (#4437) Summary: This is a conceptually simple change, but it touches many files to pass the allocator through function calls. We introduce CacheAllocator, which can be used by clients to configure custom allocator for cache blocks. Our motivation is to hook this up with follys `JemallocNodumpAllocator` ( but there are many other possible use cases. Additionally, this commit cleans up memory allocation in `util/compression.h`, making sure that all allocations are wrapped in a unique_ptr as soon as possible. Pull Request resolved: Differential Revision: D10132814 Pulled By: yiwu-arbug fbshipit-source-id: be1343a4b69f6048df127939fea9bbc96969f564/Revert ""Digest ZSTD compression dictionary once per SST file (#4251)"" (#4347) Summary: Reverting is needed to unblock a user building against master, who is blocked for multiple days due to a thread-safety issue in `GetEmptyDict`. We havent been able to fix it quickly, so reverting. Simply ran `git revert 6c40806e51a89386d2b066fddf73d3fd03a36f65`. There were no merge conflicts. Pull Request resolved: Differential Revision: D9668365 Pulled By: ajkr fbshipit-source-id: 0c56334f0a23cf5ee0233d4e4679eae6709739cd/Digest ZSTD compression dictionary once per SST file (#4251) Summary: In RocksDB, for a given SST file, all data blocks are compressed with the same dictionary. When we compress a block using the dictionarys raw bytes, the compression library first has to digest the dictionary to get it into a usable form. This digestion work is redundant and ideally should be done once per file. ZSTD offers APIs for the caller to create and reuse a digested dictionary object (`ZSTD_CDict`). In this PR, we call `ZSTD_createCDict` once per file to digest the raw bytes. Then we use `ZSTD_compress_usingCDict` to compress each data block using the pre-digested dictionary. Once the files created `ZSTD_freeCDict` releases the resources held by the digested dictionary. There are a couple other changes included in this PR: Changed the parameter object for (un)compression functions from `CompressionContext`/`UncompressionContext` to `CompressionInfo`/`UncompressionInfo`. This avoids the previous pattern, where `CompressionContext`/`UncompressionContext` had to be mutated before calling a (un)compression function depending on whether dictionary should be used. I felt that mutation was error-prone so eliminated it. Added support for digested uncompression dictionaries (`ZSTD_DDict`) as well. However, this PR does not support reusing them across uncompression calls for the same file. That work is deferred to a later PR when we will store the `ZSTD_DDict` objects in block cache. Pull Request resolved: Differential Revision: D9257078 Pulled By: ajkr fbshipit-source-id: 21b8cb6bbdd48e459f1c62343780ab66c0a64438/Suppress two CLANG Analyze warning (#4291) Summary: Suppress two CLANG analyze warnings. They dont seem to be real bugs Pull Request resolved: Differential Revision: D9407333 Pulled By: siying fbshipit-source-id: 2ed63d88fa0b217fdccb1572d7508467c2203dc8/"
,,0.2247,rocksdb,Add support to flush multiple CFs atomically (#4262) Summary: Leverage existing `FlushJob` to implement atomic flush of multiple column families. This PR depends on other PRs and is a subset of . This PR itself is not sufficient in fulfilling atomic flush. Pull Request resolved: Differential Revision: D9283109 Pulled By: riversand963 fbshipit-source-id: 65401f913e4160b0a61c0be6cd02adc15dad28ed/
,,0.4292,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/Add read retry support to log reader (#4394) Summary: Current `log::Reader` does not perform retry after encountering `EOF`. In the future, we need the log reader to be able to retry tailing the log even after `EOF`. Current implementation is simple. It does not provide more advanced retry policies. Will address this in the future. Pull Request resolved: Differential Revision: D9926508 Pulled By: riversand963 fbshipit-source-id: d86d145792a41bd64a72f642a2a08c7b7b5201e1/Delete code for WAL reader to start at nonzero offset (#4362) Summary: The code is dead in RocksDB as `log::Reader::initial_offset_` is always zero. We should delete it so we dont have to maintain it like in Pull Request resolved: Differential Revision: D9817829 Pulled By: ajkr fbshipit-source-id: 474a2c679e5bd273b40608f3a5332931d9eefe6d/Support pragma once in all header files and cleanup some warnings (#4339) Summary: As you know, almost all compilers support ""pragma once"" keyword instead of using include guards. To be keep consistency between header files, all header files are edited. Besides this, try to fix some warnings about loss of data. Pull Request resolved: Differential Revision: D9654990 Pulled By: ajkr fbshipit-source-id: c2cf3d2d03a599847684bed81378c401920ca848/"
,,0.1162,rocksdb,"Fix CompactFiles support for kDisableCompressionOption (#4438) Summary: Previously `CompactFiles` with `CompressionType::kDisableCompressionOption` caused program to crash on assertion failure. This PR fixes the crash by adding support for that setting. Now, that setting will cause RocksDB to choose compression according to the column familys options. Pull Request resolved: Differential Revision: D10115761 Pulled By: ajkr fbshipit-source-id: a553c6fa76fa5b6f73b0d165d95640da6f454122/"
,,0.2019,rocksdb,Add path to WritableFileWriter. (#4039) Summary: We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise its hard to tell what has been going on. Pull Request resolved: Differential Revision: D8670178 Pulled By: riversand963 fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/
,,0.0634,rocksdb,xxhash 64 support Summary: Pull Request resolved: Reviewed By: siying Differential Revision: D12836696 Pulled By: jsjhoubo fbshipit-source-id: 7122ccb712d0b0f1cd998aa4477e0da1401bd870/
,,0.136,rocksdb,"Fix DBImpl::GetColumnFamilyHandleUnlocked race condition (#4391) Summary: Fix DBImpl API race condition The timeline of execution flow is as follow: ``` timeline user_thread1 user_thread2 t1 | cfh GetColumnFamilyHandleUnlocked(0) t2 | id1 cfh->GetID() t3 | GetColumnFamilyHandleUnlocked(1) t4 | id2 cfh->GetID() V ``` The original implementation return a pointer to a stateful variable, so that the return `ColumnFamilyHandle` will be changed when another thread calls `GetColumnFamilyHandleUnlocked` with different `column family id` Expose ColumnFamily ID to compaction event listener Fix the return status of `DBImpl::GetLatestSequenceForKey` Pull Request resolved: Differential Revision: D10221243 Pulled By: yiwu-arbug fbshipit-source-id: dec60ee9ff0c8261a2f2413a8506ec1063991993/Add a unit test to verify iterators release data blocks after using them (#4170) Summary: Add a unit test to check that iterators release data blocks after it has moved away from it. Verify the same for compaction input iterators. Pull Request resolved: Differential Revision: D8962513 Pulled By: siying fbshipit-source-id: 05a5b604d7d29887fb488f2cda7286f554a14407/"
,,0.3774,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/Add support to flush multiple CFs atomically (#4262) Summary: Leverage existing `FlushJob` to implement atomic flush of multiple column families. This PR depends on other PRs and is a subset of . This PR itself is not sufficient in fulfilling atomic flush. Pull Request resolved: Differential Revision: D9283109 Pulled By: riversand963 fbshipit-source-id: 65401f913e4160b0a61c0be6cd02adc15dad28ed/Add path to WritableFileWriter. (#4039) Summary: We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise its hard to tell what has been going on. Pull Request resolved: Differential Revision: D8670178 Pulled By: riversand963 fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/"
,,0.285,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/Add path to WritableFileWriter. (#4039) Summary: We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise its hard to tell what has been going on. Pull Request resolved: Differential Revision: D8670178 Pulled By: riversand963 fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/"
,,0.3248,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/fix clang analyzer error (#4583) Summary: clang analyzer currently fails with the following warnings: > db/log_reader.cc:323:9: warning: Undefined or garbage value returned to caller return r; ^~~~~~~~ db/log_reader.cc:344:11: warning: Undefined or garbage value returned to caller return r; ^~~~~~~~ db/log_reader.cc:369:11: warning: Undefined or garbage value returned to caller return r; Pull Request resolved: Differential Revision: D10523517 Pulled By: miasantreble fbshipit-source-id: 0cc8b8f27657b202bead148bbe7c4aa84fed095b/Add read retry support to log reader (#4394) Summary: Current `log::Reader` does not perform retry after encountering `EOF`. In the future, we need the log reader to be able to retry tailing the log even after `EOF`. Current implementation is simple. It does not provide more advanced retry policies. Will address this in the future. Pull Request resolved: Differential Revision: D9926508 Pulled By: riversand963 fbshipit-source-id: d86d145792a41bd64a72f642a2a08c7b7b5201e1/"
,,0.1838,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/"
,,0.2418,rocksdb,"Add read retry support to log reader (#4394) Summary: Current `log::Reader` does not perform retry after encountering `EOF`. In the future, we need the log reader to be able to retry tailing the log even after `EOF`. Current implementation is simple. It does not provide more advanced retry policies. Will address this in the future. Pull Request resolved: Differential Revision: D9926508 Pulled By: riversand963 fbshipit-source-id: d86d145792a41bd64a72f642a2a08c7b7b5201e1/"
,,0.2247,rocksdb,Add support to flush multiple CFs atomically (#4262) Summary: Leverage existing `FlushJob` to implement atomic flush of multiple column families. This PR depends on other PRs and is a subset of . This PR itself is not sufficient in fulfilling atomic flush. Pull Request resolved: Differential Revision: D9283109 Pulled By: riversand963 fbshipit-source-id: 65401f913e4160b0a61c0be6cd02adc15dad28ed/
,,0.1786,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/"
,,0.335,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/Add read retry support to log reader (#4394) Summary: Current `log::Reader` does not perform retry after encountering `EOF`. In the future, we need the log reader to be able to retry tailing the log even after `EOF`. Current implementation is simple. It does not provide more advanced retry policies. Will address this in the future. Pull Request resolved: Differential Revision: D9926508 Pulled By: riversand963 fbshipit-source-id: d86d145792a41bd64a72f642a2a08c7b7b5201e1/Delete code for WAL reader to start at nonzero offset (#4362) Summary: The code is dead in RocksDB as `log::Reader::initial_offset_` is always zero. We should delete it so we dont have to maintain it like in Pull Request resolved: Differential Revision: D9817829 Pulled By: ajkr fbshipit-source-id: 474a2c679e5bd273b40608f3a5332931d9eefe6d/"
,,0.221,rocksdb,"Truncate range tombstones by leveraging InternalKeys (#4432) Summary: To more accurately truncate range tombstones at SST boundaries, we now represent them in RangeDelAggregator using InternalKeys, which are end-key-exclusive as they were before this change. During compaction, ""atomic compaction unit boundaries"" (the range of keys contained in neighbouring and overlaping SSTs) are propagated down to RangeDelAggregator to truncate range tombstones at those boundariies instead. See and for motivating examples. Pull Request resolved: Differential Revision: D10263952 Pulled By: abhimadan fbshipit-source-id: 2fe85ff8a02b3a6a2de2edfe708012797a7bd579/use specified comparator in CollapsedRangeDelMap (#4386) Summary: The Comparator passed to CollapsedRangeDelMap was not used for operator less of the std::map `rep_` object contained in CollapsedRangeDelMap. So the map was always sorted using the default ByteWiseComparator, which seems wrong. Passing the specified Comparator through for usage in that map object fixes actual problems we were seeing with RangeDelete operations that do not delete keys as expected when using a custom Comparator. I found that the tests in current master crash when I run them locally, both with and without my patch, at the very same location. I therefore dont know if the patch breaks something else, but it seems to fix RangeDeletion issues in our product that uses RocksDB. Pull Request resolved: Differential Revision: D9916506 Pulled By: ajkr fbshipit-source-id: 27bff8c775831f089dde8c5289df7343d88b2d66/fix compilation with g++ option `-Wsuggest-override` (#4272) Summary: Fixes compilation warnings (which are turned into compilation errors by default) when compiling with g++ option `-Wsuggest-override`. Pull Request resolved: Differential Revision: D9322556 Pulled By: siying fbshipit-source-id: abd57a29ec8f544bee77c0bb438f31be830b7244/"
,,0.2807,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/Add path to WritableFileWriter. (#4039) Summary: We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise its hard to tell what has been going on. Pull Request resolved: Differential Revision: D8670178 Pulled By: riversand963 fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/"
,,0.3464,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/Cache fragmented range tombstones in BlockBasedTableReader (#4493) Summary: This allows tombstone fragmenting to only be performed when the table is opened, and cached for subsequent accesses. On the same DB used in running `readrandom` results in the following: ``` readrandom : 0.983 micros/op 1017076 ops/sec; 78.3 MB/s (63103 of 100000 found) ``` Now that Get performance in the presence of range tombstones is reasonable, I also compared the performance between a DB with range tombstones, ""expanded"" range tombstones (several point tombstones that cover the same keys the equivalent range tombstone would cover, a common workaround for DeleteRange), and no range tombstones. The created DBs had 5 million keys each, and DeleteRange was called at regular intervals (depending on the total number of range tombstones being written) after 4.5 million Puts. The table below summarizes the results of a `readwhilewriting` benchmark (in order to provide somewhat more realistic results): ``` Tombstones? | avg micros/op | stddev micros/op | avg ops/s | stddev ops/s | | | | None | 0.6186 | 0.04637 | 1,625,252.90 | 124,679.41 500 Expanded | 0.6019 | 0.03628 | 1,666,670.40 | 101,142.65 500 Unexpanded | 0.6435 | 0.03994 | 1,559,979.40 | 104,090.52 1k Expanded | 0.6034 | 0.04349 | 1,665,128.10 | 125,144.57 1k Unexpanded | 0.6261 | 0.03093 | 1,600,457.50 | 79,024.94 5k Expanded | 0.6163 | 0.05926 | 1,636,668.80 | 154,888.85 5k Unexpanded | 0.6402 | 0.04002 | 1,567,804.70 | 100,965.55 10k Expanded | 0.6036 | 0.05105 | 1,667,237.70 | 142,830.36 10k Unexpanded | 0.6128 | 0.02598 | 1,634,633.40 | 72,161.82 25k Expanded | 0.6198 | 0.04542 | 1,620,980.50 | 116,662.93 25k Unexpanded | 0.5478 | 0.0362 | 1,833,059.10 | 121,233.81 50k Expanded | 0.5104 | 0.04347 | 1,973,107.90 | 184,073.49 50k Unexpanded | 0.4528 | 0.03387 | 2,219,034.50 | 170,984.32 ``` After a large enough quantity of range tombstones are written, range tombstone Gets can become faster than reading from an equivalent DB with several point tombstones. Pull Request resolved: Differential Revision: D10842844 Pulled By: abhimadan fbshipit-source-id: a7d44534f8120e6aabb65779d26c6b9df954c509/Use only ""local"" range tombstones during Get (#4449) Summary: Previously, range tombstones were accumulated from every level, which was necessary if a range tombstone in a higher level covered a key in a lower level. However, RangeDelAggregator::AddTombstoness complexity is based on the number of tombstones that are currently stored in it, which is wasteful in the Get case, where we only need to know the highest sequence number of range tombstones that cover the key from higher levels, and compute the highest covering sequence number at the current level. This change introduces this optimization, and removes the use of RangeDelAggregator from the Get path. In the benchmark results, the following command was used to initialize the database: ``` ./db_bench ``` ...and the following command was used to measure read throughput: ``` ./db_bench ``` The filluniquerandom command was only run once, and the resulting database was used to measure read performance before and after the PR. Both binaries were compiled with `DEBUG_LEVEL=0`. Readrandom results before PR: ``` readrandom : 4.544 micros/op 220090 ops/sec; 16.9 MB/s (63103 of 100000 found) ``` Readrandom results after PR: ``` readrandom : 11.147 micros/op 89707 ops/sec; 6.9 MB/s (63103 of 100000 found) ``` So its actually slower right now, but this PR paves the way for future optimizations (see Pull Request resolved: Differential Revision: D10370575 Pulled By: abhimadan fbshipit-source-id: 9a2e152be1ef36969055c0e9eb4beb0d96c11f4d/Add read retry support to log reader (#4394) Summary: Current `log::Reader` does not perform retry after encountering `EOF`. In the future, we need the log reader to be able to retry tailing the log even after `EOF`. Current implementation is simple. It does not provide more advanced retry policies. Will address this in the future. Pull Request resolved: Differential Revision: D9926508 Pulled By: riversand963 fbshipit-source-id: d86d145792a41bd64a72f642a2a08c7b7b5201e1/Properly determine a truncated CompactRange stop key (#4496) Summary: When a CompactRange() call for a level is truncated before the end key is reached, because it exceeds max_compaction_bytes, we need to properly set the compaction_end parameter to indicate the stop key. The next CompactRange will use that as the begin key. We set it to the smallest key of the next file in the level after expanding inputs to get a clean cut. Previously, we were setting it before expanding inputs. So we could end up recompacting some files. In a pathological case, where a single key has many entries spanning all the files in the level (possibly due to merge operands without a partial merge operator, thus resulting in compaction output identical to the input), this would result in an endless loop over the same set of files. Pull Request resolved: Differential Revision: D10395026 Pulled By: anand1976 fbshipit-source-id: f0c2f89fee29b4b3be53b6467b53abba8e9146a9/fix unused param `allocator` in compression.h (#4453) Summary: this should fix currently failing contrun test: rocksdb-contrun-no_compression, rocksdb-contrun-tsan, rocksdb-contrun-tsan_crash Pull Request resolved: Differential Revision: D10202626 Pulled By: miasantreble fbshipit-source-id: 850b07f14f671b5998c22d8239e2a55b2fc1e355/VersionSet: GetOverlappingInputs() fix overflow and optimize. (#4385) Summary: This fix is for `level 0` in `GetOverlappingInputs()`: In `GetOverlappingInputs()`, if `level 0`, it has potential risk of overflow if `i 0`. Optmize process when `expand true`, the expected complexity can be reduced to O(n). Signed-off-by: JiYou Pull Request resolved: Differential Revision: D10181001 Pulled By: riversand963 fbshipit-source-id: 46eef8a1d1605c9329c164e6471cd5c5b6de16b5/Support pragma once in all header files and cleanup some warnings (#4339) Summary: As you know, almost all compilers support ""pragma once"" keyword instead of using include guards. To be keep consistency between header files, all header files are edited. Besides this, try to fix some warnings about loss of data. Pull Request resolved: Differential Revision: D9654990 Pulled By: ajkr fbshipit-source-id: c2cf3d2d03a599847684bed81378c401920ca848/Add path to WritableFileWriter. (#4039) Summary: We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise its hard to tell what has been going on. Pull Request resolved: Differential Revision: D8670178 Pulled By: riversand963 fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/Update recovery code for version edits group commit. (#3945) Summary: During recovery, RocksDB is able to handle version edits that belong to group commits. This PR is a subset of [PR 3752]( Pull Request resolved: Differential Revision: D8529122 Pulled By: riversand963 fbshipit-source-id: 57cb0f9cc55ecca684a837742d6626dc9c07f37e/"
,,0.2277,rocksdb,"Add read retry support to log reader (#4394) Summary: Current `log::Reader` does not perform retry after encountering `EOF`. In the future, we need the log reader to be able to retry tailing the log even after `EOF`. Current implementation is simple. It does not provide more advanced retry policies. Will address this in the future. Pull Request resolved: Differential Revision: D9926508 Pulled By: riversand963 fbshipit-source-id: d86d145792a41bd64a72f642a2a08c7b7b5201e1/"
,,0.2763,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/Add path to WritableFileWriter. (#4039) Summary: We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise its hard to tell what has been going on. Pull Request resolved: Differential Revision: D8670178 Pulled By: riversand963 fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/"
,,0.1821,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/"
,,0.2995,rocksdb,"Update all unique/shared_ptr instances to be qualified with namespace std (#4638) Summary: Ran the following commands to recursively change all the files under RocksDB: ``` find . f ""*.cc"" sed s/ unique_ptr/ std::unique_ptr/g {} + find . f ""*.cc"" sed s/<unique_ptr/<std::unique_ptr/g {} + find . f ""*.cc"" sed s/ shared_ptr/ std::shared_ptr/g {} + find . f ""*.cc"" sed s/<shared_ptr/<std::shared_ptr/g {} + ``` Running `make format` updated some formatting on the files touched. Pull Request resolved: Differential Revision: D12934992 Pulled By: sagar0 fbshipit-source-id: 45a15d23c230cdd64c08f9c0243e5183934338a8/Add read retry support to log reader (#4394) Summary: Current `log::Reader` does not perform retry after encountering `EOF`. In the future, we need the log reader to be able to retry tailing the log even after `EOF`. Current implementation is simple. It does not provide more advanced retry policies. Will address this in the future. Pull Request resolved: Differential Revision: D9926508 Pulled By: riversand963 fbshipit-source-id: d86d145792a41bd64a72f642a2a08c7b7b5201e1/"
,,0.2277,rocksdb,"Add read retry support to log reader (#4394) Summary: Current `log::Reader` does not perform retry after encountering `EOF`. In the future, we need the log reader to be able to retry tailing the log even after `EOF`. Current implementation is simple. It does not provide more advanced retry policies. Will address this in the future. Pull Request resolved: Differential Revision: D9926508 Pulled By: riversand963 fbshipit-source-id: d86d145792a41bd64a72f642a2a08c7b7b5201e1/"
,,0.3066,rocksdb,Add path to WritableFileWriter. (#4039) Summary: We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise its hard to tell what has been going on. Pull Request resolved: Differential Revision: D8670178 Pulled By: riversand963 fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/fix compilation with g++ option `-Wsuggest-override` (#4272) Summary: Fixes compilation warnings (which are turned into compilation errors by default) when compiling with g++ option `-Wsuggest-override`. Pull Request resolved: Differential Revision: D9322556 Pulled By: siying fbshipit-source-id: abd57a29ec8f544bee77c0bb438f31be830b7244/
,,0.2749,rocksdb,"Cache fragmented range tombstones in BlockBasedTableReader (#4493) Summary: This allows tombstone fragmenting to only be performed when the table is opened, and cached for subsequent accesses. On the same DB used in running `readrandom` results in the following: ``` readrandom : 0.983 micros/op 1017076 ops/sec; 78.3 MB/s (63103 of 100000 found) ``` Now that Get performance in the presence of range tombstones is reasonable, I also compared the performance between a DB with range tombstones, ""expanded"" range tombstones (several point tombstones that cover the same keys the equivalent range tombstone would cover, a common workaround for DeleteRange), and no range tombstones. The created DBs had 5 million keys each, and DeleteRange was called at regular intervals (depending on the total number of range tombstones being written) after 4.5 million Puts. The table below summarizes the results of a `readwhilewriting` benchmark (in order to provide somewhat more realistic results): ``` Tombstones? | avg micros/op | stddev micros/op | avg ops/s | stddev ops/s | | | | None | 0.6186 | 0.04637 | 1,625,252.90 | 124,679.41 500 Expanded | 0.6019 | 0.03628 | 1,666,670.40 | 101,142.65 500 Unexpanded | 0.6435 | 0.03994 | 1,559,979.40 | 104,090.52 1k Expanded | 0.6034 | 0.04349 | 1,665,128.10 | 125,144.57 1k Unexpanded | 0.6261 | 0.03093 | 1,600,457.50 | 79,024.94 5k Expanded | 0.6163 | 0.05926 | 1,636,668.80 | 154,888.85 5k Unexpanded | 0.6402 | 0.04002 | 1,567,804.70 | 100,965.55 10k Expanded | 0.6036 | 0.05105 | 1,667,237.70 | 142,830.36 10k Unexpanded | 0.6128 | 0.02598 | 1,634,633.40 | 72,161.82 25k Expanded | 0.6198 | 0.04542 | 1,620,980.50 | 116,662.93 25k Unexpanded | 0.5478 | 0.0362 | 1,833,059.10 | 121,233.81 50k Expanded | 0.5104 | 0.04347 | 1,973,107.90 | 184,073.49 50k Unexpanded | 0.4528 | 0.03387 | 2,219,034.50 | 170,984.32 ``` After a large enough quantity of range tombstones are written, range tombstone Gets can become faster than reading from an equivalent DB with several point tombstones. Pull Request resolved: Differential Revision: D10842844 Pulled By: abhimadan fbshipit-source-id: a7d44534f8120e6aabb65779d26c6b9df954c509/Use only ""local"" range tombstones during Get (#4449) Summary: Previously, range tombstones were accumulated from every level, which was necessary if a range tombstone in a higher level covered a key in a lower level. However, RangeDelAggregator::AddTombstoness complexity is based on the number of tombstones that are currently stored in it, which is wasteful in the Get case, where we only need to know the highest sequence number of range tombstones that cover the key from higher levels, and compute the highest covering sequence number at the current level. This change introduces this optimization, and removes the use of RangeDelAggregator from the Get path. In the benchmark results, the following command was used to initialize the database: ``` ./db_bench ``` ...and the following command was used to measure read throughput: ``` ./db_bench ``` The filluniquerandom command was only run once, and the resulting database was used to measure read performance before and after the PR. Both binaries were compiled with `DEBUG_LEVEL=0`. Readrandom results before PR: ``` readrandom : 4.544 micros/op 220090 ops/sec; 16.9 MB/s (63103 of 100000 found) ``` Readrandom results after PR: ``` readrandom : 11.147 micros/op 89707 ops/sec; 6.9 MB/s (63103 of 100000 found) ``` So its actually slower right now, but this PR paves the way for future optimizations (see Pull Request resolved: Differential Revision: D10370575 Pulled By: abhimadan fbshipit-source-id: 9a2e152be1ef36969055c0e9eb4beb0d96c11f4d/Add support to flush multiple CFs atomically (#4262) Summary: Leverage existing `FlushJob` to implement atomic flush of multiple column families. This PR depends on other PRs and is a subset of . This PR itself is not sufficient in fulfilling atomic flush. Pull Request resolved: Differential Revision: D9283109 Pulled By: riversand963 fbshipit-source-id: 65401f913e4160b0a61c0be6cd02adc15dad28ed/#3865 fix performance regression introduced by MergeOperator.ShouldMerge (#4266) Summary: This PR addresses issue and implements the following approach to fix it: adds `MergeContext::GetOperandsDirectionForward` and `MergeContext::GetOperandsDirectionBackward` to query merge operands in a specific order `MergeContext::GetOperands` becomes a shortcut for `MergeContext::GetOperandsDirectionForward` pass `MergeContext::GetOperandsDirectionBackward` to `MergeOperator::ShouldMerge` and document the order Pull Request resolved: Differential Revision: D9360750 Pulled By: sagar0 fbshipit-source-id: 20cb73ff017760b062ecdcf4382560767086e092/"
,,0.1284,rocksdb,Enable atomic flush (#4023) Summary: Adds a DB option `atomic_flush` to control whether to enable this feature. This PR is a subset of [PR 3752]( Pull Request resolved: Differential Revision: D8518381 Pulled By: riversand963 fbshipit-source-id: 1e3bb33e99bb102876a31b378d93b0138ff6634f/
,,0.2765,rocksdb,"Add compile time option to work with utf8 filename strings (#4469) Summary: The default behaviour of rocksdb is to use the `*A(` windows API functions. These accept filenames in the currently configured system encoding, be it Latin 1, utf8 or whatever. If the Application intends to completely work with utf8 strings internally, converting these to that codepage properly isnt even always possible. Thus this patch adds a switch to use the `*W(` functions, which accept UTF-16 filenames, and uses C++11 features to translate the UTF8 containing std::string to an UTF16 containing std::wstring. This feature is a compile time options, that can be enabled by setting `WITH_WINDOWS_UTF8_FILENAMES` to true. Pull Request resolved: Differential Revision: D10356011 Pulled By: yiwu-arbug fbshipit-source-id: 27b6ae9171f209085894cdf80069e8a896642044/Support pragma once in all header files and cleanup some warnings (#4339) Summary: As you know, almost all compilers support ""pragma once"" keyword instead of using include guards. To be keep consistency between header files, all header files are edited. Besides this, try to fix some warnings about loss of data. Pull Request resolved: Differential Revision: D9654990 Pulled By: ajkr fbshipit-source-id: c2cf3d2d03a599847684bed81378c401920ca848/Add path to WritableFileWriter. (#4039) Summary: We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise its hard to tell what has been going on. Pull Request resolved: Differential Revision: D8670178 Pulled By: riversand963 fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/"
,,0.1306,rocksdb,"Remove redundant member var and set options (#4631) Summary: In the past, both `DBImpl::atomic_flush_` and `DBImpl::immutable_db_options_.atomic_flush` exist. However, we fail to set `immutable_db_options_.atomic_flush`, but use `DBImpl::atomic_flush_` which is set correctly. This does not lead to incorrect behavior, but is a duplicate of information. Since `immutable_db_options_` is always there and has `atomic_flush`, we should use it as source of truth and remove `DBImpl::atomic_flush_`. Pull Request resolved: Differential Revision: D12928371 Pulled By: riversand963 fbshipit-source-id: f85a811959d3828aad4a3a1b05f71facf19c636d/"
,,0.2231,rocksdb,"Move MemoryAllocator option from Cache to BlockBasedTableOptions (#4676) Summary: Per offline discussion with siying, `MemoryAllocator` and `Cache` should be decouple. The idea is that memory allocator handles memory allocation, while cache handle cache policy. It is normal that external cache libraries pack couple the two components for better optimization. If we want to integrate with such library in the future, we can make a wrapper of the library implementing both `Cache` and `MemoryAllocator` interface. Pull Request resolved: Differential Revision: D13047662 Pulled By: yiwu-arbug fbshipit-source-id: cd42e246d80ab600b4de47d073f7d2db308ce6dd/"
,,0.175,rocksdb,"Add support for read-only db chkpt stress (#4690) Summary: Updated stress test will support testing of db in read-only mode. The user has to make sure that only read/scan operations are enabled. This PR relies on Pull Request resolved: Differential Revision: D13102741 Pulled By: riversand963 fbshipit-source-id: f5a36b34db187fe12dd355f7eda161f99d6c75e4/Refine db_stress params for atomic flush (#4781) Summary: Separate flag for enabling option from flag for enabling dedicated atomic stress test. I have found setting the former without setting the latter can detect different problems. Pull Request resolved: Differential Revision: D13463211 Pulled By: ajkr fbshipit-source-id: 054f777885b2dc7d5ea99faafa21d6537eee45fd/Improve result report of scan (#4648) Summary: When iterator becomes invalid, there are two possibilities. First, all data in the column family have been scanned and there is nothing more to scan. Second, an underlying error has occurred, causing `status()` to be ok. Therefore, we need to check for both cases when `iter->Valid()`. Pull Request resolved: Differential Revision: D12959601 Pulled By: riversand963 fbshipit-source-id: 49c9382c9ea9e78f2e2b6f3708f0670b822ca8dd/"
,,0.228,rocksdb,"Move MemoryAllocator option from Cache to BlockBasedTableOptions (#4676) Summary: Per offline discussion with siying, `MemoryAllocator` and `Cache` should be decouple. The idea is that memory allocator handles memory allocation, while cache handle cache policy. It is normal that external cache libraries pack couple the two components for better optimization. If we want to integrate with such library in the future, we can make a wrapper of the library implementing both `Cache` and `MemoryAllocator` interface. Pull Request resolved: Differential Revision: D13047662 Pulled By: yiwu-arbug fbshipit-source-id: cd42e246d80ab600b4de47d073f7d2db308ce6dd/"
,,0.228,rocksdb,"Move MemoryAllocator option from Cache to BlockBasedTableOptions (#4676) Summary: Per offline discussion with siying, `MemoryAllocator` and `Cache` should be decouple. The idea is that memory allocator handles memory allocation, while cache handle cache policy. It is normal that external cache libraries pack couple the two components for better optimization. If we want to integrate with such library in the future, we can make a wrapper of the library implementing both `Cache` and `MemoryAllocator` interface. Pull Request resolved: Differential Revision: D13047662 Pulled By: yiwu-arbug fbshipit-source-id: cd42e246d80ab600b4de47d073f7d2db308ce6dd/"
,,0.2264,rocksdb,"Move MemoryAllocator option from Cache to BlockBasedTableOptions (#4676) Summary: Per offline discussion with siying, `MemoryAllocator` and `Cache` should be decouple. The idea is that memory allocator handles memory allocation, while cache handle cache policy. It is normal that external cache libraries pack couple the two components for better optimization. If we want to integrate with such library in the future, we can make a wrapper of the library implementing both `Cache` and `MemoryAllocator` interface. Pull Request resolved: Differential Revision: D13047662 Pulled By: yiwu-arbug fbshipit-source-id: cd42e246d80ab600b4de47d073f7d2db308ce6dd/"
,,0.228,rocksdb,"Move MemoryAllocator option from Cache to BlockBasedTableOptions (#4676) Summary: Per offline discussion with siying, `MemoryAllocator` and `Cache` should be decouple. The idea is that memory allocator handles memory allocation, while cache handle cache policy. It is normal that external cache libraries pack couple the two components for better optimization. If we want to integrate with such library in the future, we can make a wrapper of the library implementing both `Cache` and `MemoryAllocator` interface. Pull Request resolved: Differential Revision: D13047662 Pulled By: yiwu-arbug fbshipit-source-id: cd42e246d80ab600b4de47d073f7d2db308ce6dd/"
,,0.1305,rocksdb,"Always delete Blob DB files in the background (#4928) Summary: Blob DB files are not tracked by the SFM, so they currently dont get deleted in the background. Force them to be deleted in background so rate limiting can be applied Pull Request resolved: Differential Revision: D13854649 Pulled By: anand1976 fbshipit-source-id: 8031ce66842ff0af440c715d886b377983dad7d8/"
,,0.1536,rocksdb,"Cache dictionary used for decompressing data blocks (#4881) Summary: If block cache disabled or not used for meta-blocks, `BlockBasedTableReader::Rep::uncompression_dict` owns the `UncompressionDict`. It is preloaded during `PrefetchIndexAndFilterBlocks`. If block cache is enabled and used for meta-blocks, block cache owns the `UncompressionDict`, which holds dictionary and digested dictionary when needed. It is never prefetched though there is a TODO for this in the code. The cache key is simply the compression dictionary block handle. New stats for compression dictionary accesses in block cache: ""BLOCK_CACHE_COMPRESSION_DICT_*"" and ""compression_dict_block_read_count"" Pull Request resolved: Differential Revision: D13663801 Pulled By: ajkr fbshipit-source-id: bdcc54044e180855cdcc57639b493b0e016c9a3f/Digest ZSTD compression dictionary once when writing SST file (#4849) Summary: This is essentially a re-submission of with a few improvements: Split `CompressionDict` into two separate classes: `CompressionDict` and `UncompressionDict` Eliminated `Init` functions. Instead do all initialization work in constructors. Added test case for parallel DB open, which is the scenario where failed under TSAN. Pull Request resolved: Differential Revision: D13606039 Pulled By: ajkr fbshipit-source-id: 08c236059798c710db9cbf545fce0f371232d447/"
,,0.1322,rocksdb,"Always delete Blob DB files in the background (#4928) Summary: Blob DB files are not tracked by the SFM, so they currently dont get deleted in the background. Force them to be deleted in background so rate limiting can be applied Pull Request resolved: Differential Revision: D13854649 Pulled By: anand1976 fbshipit-source-id: 8031ce66842ff0af440c715d886b377983dad7d8/"
,,0.1379,rocksdb,"fix unused param ""options"" error in jemalloc_nodump_allocator.cc (#4738) Summary: Currently tests are failing on master with the following message: > util/jemalloc_nodump_allocator.cc:132:8: error: unused parameter ëoptionsí [-Werror=unused-parameter] Status NewJemallocNodumpAllocator( This PR attempts to fix the issue Pull Request resolved: Differential Revision: D13278804 Pulled By: miasantreble fbshipit-source-id: 64a6204aa685bd85d8b5080655cafef9980fac2f/JemallocAllocator: thread-local tcache (#4603) Summary: Add option to support thread-local tcache to reduce mutex contention inside Jemalloc arena. Pull Request resolved: Differential Revision: D12830738 Pulled By: yiwu-arbug fbshipit-source-id: 59bd25b165b903f23a6a8531b18d72e140d69f65/"
,,0.2655,rocksdb,"Revert ""Move MemoryAllocator option from Cache to BlockBasedTableOptiÖ (#4697) Summary: Öons (#4676)"" This reverts commit b32d087dbb3b9d9f2c9597caa650d0ca9d2e2d7f. `MemoryAllocator` needs to be with `Cache`, since cache entry can outlive DB and block based table. The cache needs to hold reference to memory allocator when deleting cache entry. Pull Request resolved: Differential Revision: D13133490 Pulled By: yiwu-arbug fbshipit-source-id: 8ef7e8a51263bfd929f892fd062665ff4ce9ce5a/Move MemoryAllocator option from Cache to BlockBasedTableOptions (#4676) Summary: Per offline discussion with siying, `MemoryAllocator` and `Cache` should be decouple. The idea is that memory allocator handles memory allocation, while cache handle cache policy. It is normal that external cache libraries pack couple the two components for better optimization. If we want to integrate with such library in the future, we can make a wrapper of the library implementing both `Cache` and `MemoryAllocator` interface. Pull Request resolved: Differential Revision: D13047662 Pulled By: yiwu-arbug fbshipit-source-id: cd42e246d80ab600b4de47d073f7d2db308ce6dd/"
,,0.0946,rocksdb,Fix uninitialized fields in file metadata (#4693) Summary: This is a quick fix for the uninitialized bugs in `LiveFileMetaData` and `SstFileMetaData` that were uncovered in Pull Request resolved: Differential Revision: D13113189 Pulled By: ajkr fbshipit-source-id: 18e798d031d2a59d0b55fc010c135e0126f4042d/
,,0.228,rocksdb,"Move MemoryAllocator option from Cache to BlockBasedTableOptions (#4676) Summary: Per offline discussion with siying, `MemoryAllocator` and `Cache` should be decouple. The idea is that memory allocator handles memory allocation, while cache handle cache policy. It is normal that external cache libraries pack couple the two components for better optimization. If we want to integrate with such library in the future, we can make a wrapper of the library implementing both `Cache` and `MemoryAllocator` interface. Pull Request resolved: Differential Revision: D13047662 Pulled By: yiwu-arbug fbshipit-source-id: cd42e246d80ab600b4de47d073f7d2db308ce6dd/"
,,0.1159,rocksdb,"Revert ""apply ReadOptions.iterate_upper_bound to transaction iteratorÖ (#4705) Summary: Ö (#4656)"" This reverts commit b76398a82bde58bfcfa3ed5ba3dbfb6168c241de. Will add test coverage for iterate_upper_bound before re-commit b76398 Pull Request resolved: Differential Revision: D13148592 Pulled By: miasantreble fbshipit-source-id: 4d1ce0bfd9f7a5359a7688bd780eb06a66f45b1f/"
,,0.1079,rocksdb,"Backup engine support for direct I/O reads (#4640) Summary: Use the `DBOptions` that the backup engine already holds to figure out the right `EnvOptions` to use when reading the DB files. This means that, if a user opened a DB instance with `use_direct_reads=true`, then using `BackupEngine` to back up that DB instance will use direct I/O to read files when calculating checksums and copying. Currently the WALs and manifests would still be read using buffered I/O to prevent mixing direct I/O reads with concurrent buffered I/O writes. Pull Request resolved: Differential Revision: D13015268 Pulled By: ajkr fbshipit-source-id: 77006ad6f3e00ce58374ca4793b785eea0db6269/"
,,0.114,rocksdb,"Revert ""apply ReadOptions.iterate_upper_bound to transaction iteratorÖ (#4705) Summary: Ö (#4656)"" This reverts commit b76398a82bde58bfcfa3ed5ba3dbfb6168c241de. Will add test coverage for iterate_upper_bound before re-commit b76398 Pull Request resolved: Differential Revision: D13148592 Pulled By: miasantreble fbshipit-source-id: 4d1ce0bfd9f7a5359a7688bd780eb06a66f45b1f/"
,,0.1197,rocksdb,"Revert ""apply ReadOptions.iterate_upper_bound to transaction iteratorÖ (#4705) Summary: Ö (#4656)"" This reverts commit b76398a82bde58bfcfa3ed5ba3dbfb6168c241de. Will add test coverage for iterate_upper_bound before re-commit b76398 Pull Request resolved: Differential Revision: D13148592 Pulled By: miasantreble fbshipit-source-id: 4d1ce0bfd9f7a5359a7688bd780eb06a66f45b1f/"
,,0.1159,rocksdb,"Revert ""apply ReadOptions.iterate_upper_bound to transaction iteratorÖ (#4705) Summary: Ö (#4656)"" This reverts commit b76398a82bde58bfcfa3ed5ba3dbfb6168c241de. Will add test coverage for iterate_upper_bound before re-commit b76398 Pull Request resolved: Differential Revision: D13148592 Pulled By: miasantreble fbshipit-source-id: 4d1ce0bfd9f7a5359a7688bd780eb06a66f45b1f/"
,,0.1781,rocksdb,"Always delete Blob DB files in the background (#4928) Summary: Blob DB files are not tracked by the SFM, so they currently dont get deleted in the background. Force them to be deleted in background so rate limiting can be applied Pull Request resolved: Differential Revision: D13854649 Pulled By: anand1976 fbshipit-source-id: 8031ce66842ff0af440c715d886b377983dad7d8/Digest ZSTD compression dictionary once when writing SST file (#4849) Summary: This is essentially a re-submission of with a few improvements: Split `CompressionDict` into two separate classes: `CompressionDict` and `UncompressionDict` Eliminated `Init` functions. Instead do all initialization work in constructors. Added test case for parallel DB open, which is the scenario where failed under TSAN. Pull Request resolved: Differential Revision: D13606039 Pulled By: ajkr fbshipit-source-id: 08c236059798c710db9cbf545fce0f371232d447/"
,,0.2517,rocksdb,"Cache dictionary used for decompressing data blocks (#4881) Summary: If block cache disabled or not used for meta-blocks, `BlockBasedTableReader::Rep::uncompression_dict` owns the `UncompressionDict`. It is preloaded during `PrefetchIndexAndFilterBlocks`. If block cache is enabled and used for meta-blocks, block cache owns the `UncompressionDict`, which holds dictionary and digested dictionary when needed. It is never prefetched though there is a TODO for this in the code. The cache key is simply the compression dictionary block handle. New stats for compression dictionary accesses in block cache: ""BLOCK_CACHE_COMPRESSION_DICT_*"" and ""compression_dict_block_read_count"" Pull Request resolved: Differential Revision: D13663801 Pulled By: ajkr fbshipit-source-id: bdcc54044e180855cdcc57639b493b0e016c9a3f/Digest ZSTD compression dictionary once when writing SST file (#4849) Summary: This is essentially a re-submission of with a few improvements: Split `CompressionDict` into two separate classes: `CompressionDict` and `UncompressionDict` Eliminated `Init` functions. Instead do all initialization work in constructors. Added test case for parallel DB open, which is the scenario where failed under TSAN. Pull Request resolved: Differential Revision: D13606039 Pulled By: ajkr fbshipit-source-id: 08c236059798c710db9cbf545fce0f371232d447/Move MemoryAllocator option from Cache to BlockBasedTableOptions (#4676) Summary: Per offline discussion with siying, `MemoryAllocator` and `Cache` should be decouple. The idea is that memory allocator handles memory allocation, while cache handle cache policy. It is normal that external cache libraries pack couple the two components for better optimization. If we want to integrate with such library in the future, we can make a wrapper of the library implementing both `Cache` and `MemoryAllocator` interface. Pull Request resolved: Differential Revision: D13047662 Pulled By: yiwu-arbug fbshipit-source-id: cd42e246d80ab600b4de47d073f7d2db308ce6dd/"
,,0.2214,rocksdb,"Move MemoryAllocator option from Cache to BlockBasedTableOptions (#4676) Summary: Per offline discussion with siying, `MemoryAllocator` and `Cache` should be decouple. The idea is that memory allocator handles memory allocation, while cache handle cache policy. It is normal that external cache libraries pack couple the two components for better optimization. If we want to integrate with such library in the future, we can make a wrapper of the library implementing both `Cache` and `MemoryAllocator` interface. Pull Request resolved: Differential Revision: D13047662 Pulled By: yiwu-arbug fbshipit-source-id: cd42e246d80ab600b4de47d073f7d2db308ce6dd/"
,,0.2313,rocksdb,"Move MemoryAllocator option from Cache to BlockBasedTableOptions (#4676) Summary: Per offline discussion with siying, `MemoryAllocator` and `Cache` should be decouple. The idea is that memory allocator handles memory allocation, while cache handle cache policy. It is normal that external cache libraries pack couple the two components for better optimization. If we want to integrate with such library in the future, we can make a wrapper of the library implementing both `Cache` and `MemoryAllocator` interface. Pull Request resolved: Differential Revision: D13047662 Pulled By: yiwu-arbug fbshipit-source-id: cd42e246d80ab600b4de47d073f7d2db308ce6dd/"
,,0.2316,rocksdb,"Cache dictionary used for decompressing data blocks (#4881) Summary: If block cache disabled or not used for meta-blocks, `BlockBasedTableReader::Rep::uncompression_dict` owns the `UncompressionDict`. It is preloaded during `PrefetchIndexAndFilterBlocks`. If block cache is enabled and used for meta-blocks, block cache owns the `UncompressionDict`, which holds dictionary and digested dictionary when needed. It is never prefetched though there is a TODO for this in the code. The cache key is simply the compression dictionary block handle. New stats for compression dictionary accesses in block cache: ""BLOCK_CACHE_COMPRESSION_DICT_*"" and ""compression_dict_block_read_count"" Pull Request resolved: Differential Revision: D13663801 Pulled By: ajkr fbshipit-source-id: bdcc54044e180855cdcc57639b493b0e016c9a3f/Move MemoryAllocator option from Cache to BlockBasedTableOptions (#4676) Summary: Per offline discussion with siying, `MemoryAllocator` and `Cache` should be decouple. The idea is that memory allocator handles memory allocation, while cache handle cache policy. It is normal that external cache libraries pack couple the two components for better optimization. If we want to integrate with such library in the future, we can make a wrapper of the library implementing both `Cache` and `MemoryAllocator` interface. Pull Request resolved: Differential Revision: D13047662 Pulled By: yiwu-arbug fbshipit-source-id: cd42e246d80ab600b4de47d073f7d2db308ce6dd/"
,,0.1366,rocksdb,"PlainTable should avoid copying Get() results from immortal source. (#4924) Summary: avoids memcopy for Get() results if files are immortable (read-only DB, max_open_files=-1) and the file is ammaped. The same optimization is being applied to PlainTable here. Pull Request resolved: Differential Revision: D13827749 Pulled By: siying fbshipit-source-id: 1f2cbfc530b40ce08ccd53f95f6e78de4d1c2f96/"
,,0.0944,rocksdb,Fix only `SyncClosedLogs` for multiple CFs (#4460) Summary: Call `SyncClosedLogs()` only if there are more than one column families. Update several unit tests (in `fault_injection_test` and `db_flush_test`) correspondingly. See for more info. Pull Request resolved: Differential Revision: D12896377 Pulled By: riversand963 fbshipit-source-id: f49afdaec32568f12f001219a3aec1dfde3b32bf/
,,0.1888,rocksdb,"Remove an unused parameter (#4816) Summary: The `flush_reason` parameter in `DBImpl::InstallSuperVersionAndScheduleWork` is not used. Remove it. Pull Request resolved: Differential Revision: D13543218 Pulled By: riversand963 fbshipit-source-id: 8fc75d49462ce092e85aef0fe0c50936140db153/Fix building RocksDB for iOS (#4687) Summary: This PR contains the following fixes: 1. Fixing Makefile to support non-default locations of developer tools 2. Fixing compile error using a patch from Pull Request resolved: Differential Revision: D13287263 Pulled By: riversand963 fbshipit-source-id: 4525eb42ba7b6f82af5f9bfb8e52fa4024e27ccc/Allow file-ingest-triggered flush to skip waiting for write-stall clear (#4751) Summary: When write stall has already been triggered due to number of L0 files reaching threshold, file ingestion must proceed with its flush without waiting for the write stall condition to cleared by the compaction because compaction can wait for ingestion to finish (circular wait). In order to avoid this wait, we can set `FlushOptions.allow_write_stall` to be true (default is false). Setting it to false can cause deadlock. This can happen when the number of compaction threads is low. Considere the following ``` Time compaction_thread ingestion_thread | num_running_ingest_file_++ | while(num_running_ingest_file_>0){wait} | flush V ``` Pull Request resolved: Differential Revision: D13343037 Pulled By: riversand963 fbshipit-source-id: d3b95938814af46ec4c463feff0b50c70bd8b23f/Move a function to critical section (#4752) Summary: Test plan ``` $make clean && make all check ``` Pull Request resolved: Differential Revision: D13344705 Pulled By: riversand963 fbshipit-source-id: fc3a43174d09d70ccc2b09decd78e1da1b6ba9d1/Remove redundant member var and set options (#4631) Summary: In the past, both `DBImpl::atomic_flush_` and `DBImpl::immutable_db_options_.atomic_flush` exist. However, we fail to set `immutable_db_options_.atomic_flush`, but use `DBImpl::atomic_flush_` which is set correctly. This does not lead to incorrect behavior, but is a duplicate of information. Since `immutable_db_options_` is always there and has `atomic_flush`, we should use it as source of truth and remove `DBImpl::atomic_flush_`. Pull Request resolved: Differential Revision: D12928371 Pulled By: riversand963 fbshipit-source-id: f85a811959d3828aad4a3a1b05f71facf19c636d/"
,,0.1996,rocksdb,"Preload some files even if options.max_open_files (#3340) Summary: Choose to preload some files if options.max_open_files This can slightly narrow the gap of performance between options.max_open_files is and a large number. To avoid a significant regression to DB reopen speed if options.max_open_files Limit the files to preload in DB open time to 16. Pull Request resolved: Differential Revision: D6686945 Pulled By: siying fbshipit-source-id: 8ec11bbdb46e3d0cdee7b6ad5897a09c5a07869f/Introduce a CPU time counter in perf_context (#4741) Summary: Introduce the first CPU timing counter, perf_context.get_cpu_nanos. This opens a door to more CPU counters in the future. Only Posix Env has it implemented using clock_gettime() with CLOCK_THREAD_CPUTIME_ID. How accurate the counter is depends on the platform. Make PerfStepTimer to take an Env as an argument, and sometimes pass it in. The direct reason is to make the unit tests to use SpecialEnv where we can ingest logic there. But in long term, this is a good change. Pull Request resolved: Differential Revision: D13287798 Pulled By: siying fbshipit-source-id: 090361049d9d5095d1d1a369fe1338d2e2e1c73f/Fix `CompactFiles` bug (#4665) Summary: `CompactFiles` gets `SuperVersion` before `WaitForIngestFile`, while `IngestExternalFile` may add files that overlap with `input_file_names` The timeline of execution flow is as follow: Lets say that level N has two file [1,2] and [5,6] ``` timeline user_thread1 user_thread2 t0 | CompactFiles([1, 2], [5, 6]) begin t1 | GetReferencedSuperVersion() t2 | IngestExternalFile([3,4]) to level N begin t3 | CompactFiles resume V ``` Pull Request resolved: Differential Revision: D13030674 Pulled By: ajkr fbshipit-source-id: 8be19477fd6e505032267a979d32f3097cc3be51/"
,,0.18,rocksdb,"Remove v1 RangeDelAggregator (#4778) Summary: Now that v2 is fully functional, the v1 aggregator is removed. The v2 aggregator has been renamed. Pull Request resolved: Differential Revision: D13495930 Pulled By: abhimadan fbshipit-source-id: 9d69500a60a283e79b6c4fa938fc68a8aa4d40d6/Prepare FragmentedRangeTombstoneIterator for use in compaction (#4740) Summary: To support the flush/compaction use cases of RangeDelAggregator in v2, FragmentedRangeTombstoneIterator now supports dropping tombstones that cannot be read in the compaction output file. Furthermore, FragmentedRangeTombstoneIterator supports the ""snapshot striping"" use case by allowing an iterator to be split by a list of snapshots. RangeDelAggregatorV2 will use these changes in a follow-up change. In the process of making these changes, other miscellaneous cleanups were also done in these files. Pull Request resolved: Differential Revision: D13287382 Pulled By: abhimadan fbshipit-source-id: f5aeb03e1b3058049b80c02a558ee48f723fa48c/Clean up FragmentedRangeTombstoneList (#4692) Summary: Removed `one_time_use` flag, which removed the need for some tests, and changed all `NewRangeTombstoneIterator` methods to return `FragmentedRangeTombstoneIterators`. These changes also led to removing `RangeDelAggregatorV2::AddUnfragmentedTombstones` and one of the `MemTableListVersion::AddRangeTombstoneIterators` methods. Pull Request resolved: Differential Revision: D13106570 Pulled By: abhimadan fbshipit-source-id: cbab5432d7fc2d9cdfd8d9d40361a1bffaa8f845/Introduce RangeDelAggregatorV2 (#4649) Summary: The old RangeDelAggregator did expensive pre-processing work to create a collapsed, binary-searchable representation of range tombstones. With FragmentedRangeTombstoneIterator, much of this work is now unnecessary. RangeDelAggregatorV2 takes advantage of this by seeking in each iterator to find a covering tombstone in ShouldDelete, while doing minimal work in AddTombstones. The old RangeDelAggregator is still used during flush/compaction for now, though RangeDelAggregatorV2 will support those uses in a future PR. Pull Request resolved: Differential Revision: D13146964 Pulled By: abhimadan fbshipit-source-id: be29a4c020fc440500c137216fcc1cf529571eb3/"
,,0.1661,rocksdb,"Refactor atomic flush result installation to MANIFEST (#4791) Summary: as titled. Since different bg flush threads can flush different sets of column families (due to column family creation and drop), we decide not to let one thread perform atomic flush result installation for other threads. Bg flush threads will install their atomic flush results sequentially to MANIFEST, using a conditional variable, i.e. atomic_flush_install_cv_ to coordinate. Pull Request resolved: Differential Revision: D13498930 Pulled By: riversand963 fbshipit-source-id: dd7482fc41f4bd22dad1e1ef7d4764ef424688d7/Clean up FragmentedRangeTombstoneList (#4692) Summary: Removed `one_time_use` flag, which removed the need for some tests, and changed all `NewRangeTombstoneIterator` methods to return `FragmentedRangeTombstoneIterators`. These changes also led to removing `RangeDelAggregatorV2::AddUnfragmentedTombstones` and one of the `MemTableListVersion::AddRangeTombstoneIterators` methods. Pull Request resolved: Differential Revision: D13106570 Pulled By: abhimadan fbshipit-source-id: cbab5432d7fc2d9cdfd8d9d40361a1bffaa8f845/"
,,0.1526,rocksdb,"Remove v1 RangeDelAggregator (#4778) Summary: Now that v2 is fully functional, the v1 aggregator is removed. The v2 aggregator has been renamed. Pull Request resolved: Differential Revision: D13495930 Pulled By: abhimadan fbshipit-source-id: 9d69500a60a283e79b6c4fa938fc68a8aa4d40d6/"
,,0.0869,rocksdb,Add a new CPU time counter to compaction report (#4889) Summary: Measure CPU time consumed for a compaction and report it in the stats report Enable NowCPUNanos() to work for MacOS Pull Request resolved: Differential Revision: D13701276 Pulled By: zinoale fbshipit-source-id: 5024e5bbccd4dd10fd90d947870237f436445055/
,,0.1232,rocksdb,Add a placeholder in manifest indicating ignorable record (#4960) Summary: We want to reserve some right that some extra information added manifest in the future can be forward compatible by previous versions. Now we create a place holder for that. A bit in tag is added to indicate that a field can be safely ignored. Pull Request resolved: Differential Revision: D14000484 Pulled By: siying fbshipit-source-id: cbf5bad3f9d5ec798f789806f244d1c20d3b66d6/
,,0.1396,rocksdb,Preload some files even if options.max_open_files (#3340) Summary: Choose to preload some files if options.max_open_files This can slightly narrow the gap of performance between options.max_open_files is and a large number. To avoid a significant regression to DB reopen speed if options.max_open_files Limit the files to preload in DB open time to 16. Pull Request resolved: Differential Revision: D6686945 Pulled By: siying fbshipit-source-id: 8ec11bbdb46e3d0cdee7b6ad5897a09c5a07869f/
,,0.1396,rocksdb,Preload some files even if options.max_open_files (#3340) Summary: Choose to preload some files if options.max_open_files This can slightly narrow the gap of performance between options.max_open_files is and a large number. To avoid a significant regression to DB reopen speed if options.max_open_files Limit the files to preload in DB open time to 16. Pull Request resolved: Differential Revision: D6686945 Pulled By: siying fbshipit-source-id: 8ec11bbdb46e3d0cdee7b6ad5897a09c5a07869f/
,,0.1437,rocksdb,"Remove v1 RangeDelAggregator (#4778) Summary: Now that v2 is fully functional, the v1 aggregator is removed. The v2 aggregator has been renamed. Pull Request resolved: Differential Revision: D13495930 Pulled By: abhimadan fbshipit-source-id: 9d69500a60a283e79b6c4fa938fc68a8aa4d40d6/"
,,0.1382,rocksdb,Preload some files even if options.max_open_files (#3340) Summary: Choose to preload some files if options.max_open_files This can slightly narrow the gap of performance between options.max_open_files is and a large number. To avoid a significant regression to DB reopen speed if options.max_open_files Limit the files to preload in DB open time to 16. Pull Request resolved: Differential Revision: D6686945 Pulled By: siying fbshipit-source-id: 8ec11bbdb46e3d0cdee7b6ad5897a09c5a07869f/
,,0.1035,rocksdb,Fix potential DB hang while using CompactFiles (#4940) Summary: CompactFiles() may block auto compaction which could cuase DB hang when it reachs level0_stop_writes_trigger. Pull Request resolved: Differential Revision: D13929648 Pulled By: cooldoger fbshipit-source-id: 10842df38df3bebf862cd1a120a88ce961fdd381/
,,0.2612,rocksdb,"Add a new CPU time counter to compaction report (#4889) Summary: Measure CPU time consumed for a compaction and report it in the stats report Enable NowCPUNanos() to work for MacOS Pull Request resolved: Differential Revision: D13701276 Pulled By: zinoale fbshipit-source-id: 5024e5bbccd4dd10fd90d947870237f436445055/Revert ""Move MemoryAllocator option from Cache to BlockBasedTableOptiÖ (#4697) Summary: Öons (#4676)"" This reverts commit b32d087dbb3b9d9f2c9597caa650d0ca9d2e2d7f. `MemoryAllocator` needs to be with `Cache`, since cache entry can outlive DB and block based table. The cache needs to hold reference to memory allocator when deleting cache entry. Pull Request resolved: Differential Revision: D13133490 Pulled By: yiwu-arbug fbshipit-source-id: 8ef7e8a51263bfd929f892fd062665ff4ce9ce5a/Move MemoryAllocator option from Cache to BlockBasedTableOptions (#4676) Summary: Per offline discussion with siying, `MemoryAllocator` and `Cache` should be decouple. The idea is that memory allocator handles memory allocation, while cache handle cache policy. It is normal that external cache libraries pack couple the two components for better optimization. If we want to integrate with such library in the future, we can make a wrapper of the library implementing both `Cache` and `MemoryAllocator` interface. Pull Request resolved: Differential Revision: D13047662 Pulled By: yiwu-arbug fbshipit-source-id: cd42e246d80ab600b4de47d073f7d2db308ce6dd/use per-level perfcontext for DB::Get calls (#4617) Summary: this PR adds two more per-level perf context counters to track * number of keys returned in Get call, break down by levels * total processing time at each level during Get call Pull Request resolved: Differential Revision: D12898024 Pulled By: miasantreble fbshipit-source-id: 6b84ef1c8097c0d9e97bee1a774958f56ab4a6c4/"
,,0.14400000000000002,rocksdb,Preload some files even if options.max_open_files (#3340) Summary: Choose to preload some files if options.max_open_files This can slightly narrow the gap of performance between options.max_open_files is and a large number. To avoid a significant regression to DB reopen speed if options.max_open_files Limit the files to preload in DB open time to 16. Pull Request resolved: Differential Revision: D6686945 Pulled By: siying fbshipit-source-id: 8ec11bbdb46e3d0cdee7b6ad5897a09c5a07869f/
,,0.1329,rocksdb,"Refactor atomic flush result installation to MANIFEST (#4791) Summary: as titled. Since different bg flush threads can flush different sets of column families (due to column family creation and drop), we decide not to let one thread perform atomic flush result installation for other threads. Bg flush threads will install their atomic flush results sequentially to MANIFEST, using a conditional variable, i.e. atomic_flush_install_cv_ to coordinate. Pull Request resolved: Differential Revision: D13498930 Pulled By: riversand963 fbshipit-source-id: dd7482fc41f4bd22dad1e1ef7d4764ef424688d7/"
,,0.1068,rocksdb,"Add compaction logic to RangeDelAggregatorV2 (#4758) Summary: RangeDelAggregatorV2 now supports ShouldDelete calls on snapshot stripes and creation of range tombstone compaction iterators. RangeDelAggregator is no longer used on any non-test code path, and will be removed in a future commit. Pull Request resolved: Differential Revision: D13439254 Pulled By: abhimadan fbshipit-source-id: fe105bcf8e3d4a2df37a622d5510843cd71b0401/"
,,0.1489,rocksdb,Fix ticker stat for number files closed (#4703) Summary: We havent been populating `NO_FILE_CLOSES` since v1.5.8 even though it was never marked as deprecated. Start populating it again. Conveniently `DeleteTableReader` has an unused `void*` argument that we can use... Blame: 63f216ee0a2a6e28f9dfe24913d134d3a7fa3aca Closes Pull Request resolved: Differential Revision: D13146769 Pulled By: ajkr fbshipit-source-id: ad8d6fb0493e701f60a165a3bca1787d255be008/
,,0.1335,rocksdb,"PlainTable should avoid copying Get() results from immortal source. (#4924) Summary: avoids memcopy for Get() results if files are immortable (read-only DB, max_open_files=-1) and the file is ammaped. The same optimization is being applied to PlainTable here. Pull Request resolved: Differential Revision: D13827749 Pulled By: siying fbshipit-source-id: 1f2cbfc530b40ce08ccd53f95f6e78de4d1c2f96/"
,,0.1121,rocksdb,"Revert ""apply ReadOptions.iterate_upper_bound to transaction iteratorÖ (#4705) Summary: Ö (#4656)"" This reverts commit b76398a82bde58bfcfa3ed5ba3dbfb6168c241de. Will add test coverage for iterate_upper_bound before re-commit b76398 Pull Request resolved: Differential Revision: D13148592 Pulled By: miasantreble fbshipit-source-id: 4d1ce0bfd9f7a5359a7688bd780eb06a66f45b1f/"
,,0.1279,rocksdb,"Add a new CPU time counter to compaction report (#4889) Summary: Measure CPU time consumed for a compaction and report it in the stats report Enable NowCPUNanos() to work for MacOS Pull Request resolved: Differential Revision: D13701276 Pulled By: zinoale fbshipit-source-id: 5024e5bbccd4dd10fd90d947870237f436445055/Add compaction logic to RangeDelAggregatorV2 (#4758) Summary: RangeDelAggregatorV2 now supports ShouldDelete calls on snapshot stripes and creation of range tombstone compaction iterators. RangeDelAggregator is no longer used on any non-test code path, and will be removed in a future commit. Pull Request resolved: Differential Revision: D13439254 Pulled By: abhimadan fbshipit-source-id: fe105bcf8e3d4a2df37a622d5510843cd71b0401/"
,,0.1964,rocksdb,"add GetStatsHistory to retrieve stats snapshots (#4748) Summary: This PR adds public `GetStatsHistory` API to retrieve stats history in the form of an std map. The key of the map is the timestamp in microseconds when the stats snapshot is taken, the value is another std map from stats name to stats value (stored in std string). Two DBOptions are introduced: `stats_persist_period_sec` (default 10 minutes) controls the intervals between two snapshots are taken; `max_stats_history_count` (default 10) controls the max number of history snapshots to keep in memory. RocksDB will stop collecting stats snapshots if `stats_persist_period_sec` is set to 0. (This PR is the in-memory part of Pull Request resolved: Differential Revision: D13961471 Pulled By: miasantreble fbshipit-source-id: ac836d401ecb84ea92216bf9966f969dedf4ad04/"
,,0.1453,rocksdb,"Add missing methods to EnvWrapper, and more wrappers in Env.h (#5131) Summary: Some newer methods of Env werent wrapped in EnvWrapper. Fixed. Added more wrapper classes similar to WritableFileWrapper: SequentialFileWrapper, RandomAccessFileWrapper, RandomRWFileWrapper, DirectoryWrapper, LoggerWrapper. Moved the code around a bit, removed some unused friendships, added some comments. Pull Request resolved: Differential Revision: D14738932 Pulled By: al13n321 fbshipit-source-id: 99a9b1af28f2c629e7b7501389fa920b5ce30218/Run automatic formatter against public header files (#5115) Summary: Automatically format public headers so it looks more consistent. Pull Request resolved: Differential Revision: D14632854 Pulled By: siying fbshipit-source-id: ce9929ea62f9dcd65c69660b23eed1931cb0ae84/"
,,0.209,rocksdb,"add GetStatsHistory to retrieve stats snapshots (#4748) Summary: This PR adds public `GetStatsHistory` API to retrieve stats history in the form of an std map. The key of the map is the timestamp in microseconds when the stats snapshot is taken, the value is another std map from stats name to stats value (stored in std string). Two DBOptions are introduced: `stats_persist_period_sec` (default 10 minutes) controls the intervals between two snapshots are taken; `max_stats_history_count` (default 10) controls the max number of history snapshots to keep in memory. RocksDB will stop collecting stats snapshots if `stats_persist_period_sec` is set to 0. (This PR is the in-memory part of Pull Request resolved: Differential Revision: D13961471 Pulled By: miasantreble fbshipit-source-id: ac836d401ecb84ea92216bf9966f969dedf4ad04/"
,,0.11199999999999999,rocksdb,Add missing functionality to RocksJava (#4833) Summary: This is my latest round of changes to add missing items to RocksJava. More to come in future PRs. Pull Request resolved: Differential Revision: D14152266 Pulled By: sagar0 fbshipit-source-id: d6cff67e26da06c131491b5cf6911a8cd0db0775/
,,0.11199999999999999,rocksdb,Add missing functionality to RocksJava (#4833) Summary: This is my latest round of changes to add missing items to RocksJava. More to come in future PRs. Pull Request resolved: Differential Revision: D14152266 Pulled By: sagar0 fbshipit-source-id: d6cff67e26da06c131491b5cf6911a8cd0db0775/
,,0.1528,rocksdb,"BlobDB::Open() should put all existing trash files to delete scheduler (#5103) Summary: Right now, BlobDB::Open() fails to put all trash files to delete scheduler, which causes some trash files permanently untracked. Pull Request resolved: Differential Revision: D14606095 Pulled By: siying fbshipit-source-id: 41a9437a2948abb235c0ed85f9a04612d0e50183/"
,,0.1633,rocksdb,"Reduce scope of compression dictionary to single SST (#4952) Summary: Our previous approach was to train one compression dictionary per compaction, using the first output SST to train a dictionary, and then applying it on subsequent SSTs in the same compaction. While this was great for minimizing CPU/memory/I/O overhead, it did not achieve good compression ratios in practice. In our most promising potential use case, moderate reductions in a dictionarys scope make a major difference on compression ratio. So, this PR changes compression dictionary to be scoped per-SST. It accepts the tradeoff during table building to use more memory and CPU. Important changes include: The `BlockBasedTableBuilder` has a new state when dictionary compression is in-use: `kBuffered`. In that state it accumulates uncompressed data in-memory whenever `Add` is called. After accumulating target file size bytes or calling `BlockBasedTableBuilder::Finish`, a `BlockBasedTableBuilder` moves to the `kUnbuffered` state. The transition (`EnterUnbuffered()`) involves sampling the buffered data, training a dictionary, and compressing/writing out all buffered data. In the `kUnbuffered` state, a `BlockBasedTableBuilder` behaves the same as before blocks are compressed/written out as soon as they fill up. Samples are now whole uncompressed data blocks, except the final sample may be a partial data block so we dont breach the users configured `max_dict_bytes` or `zstd_max_train_bytes`. The dictionary trainer is supposed to work better when we pass it real units of compression. Previously we were passing 64-byte KV samples which was not realistic. Pull Request resolved: Differential Revision: D13967980 Pulled By: ajkr fbshipit-source-id: 82bea6f7537e1529c7a1a4cdee84585f5949300f/"
,,0.1671,rocksdb,"Still implement StatisticsImpl::measureTime() (#5181) Summary: Since Statistics::measureTime() is deprecated, StatisticsImpl::measureTime() is not implemented. We realized that users might have a wrapped Statistics implementation in which measureTime() is implemented as forwarded to StatisticsImpl, and causes assert failure. In order to make the change less intrusive, we implement StatisticsImpl::measureTime(). We will revisit whether we need to remove it after several releases. Also, add a test to make sure that a Statistics implementation using the old interface still works. Pull Request resolved: Differential Revision: D14907089 Pulled By: siying fbshipit-source-id: 29b6202fd04e30ed6f6adcaeb1000e87f10d1e1a/Introduce CPU timers for iterator seek and next (#5076) Summary: Introduce CPU timers for iterator seek and next operations. Seek counter includes SeekToFirst, SeekToLast and SeekForPrev, w/ the caveat that SeekToLast timer doesnt include some post processing time if upper bound is defined. Pull Request resolved: Differential Revision: D14525218 Pulled By: fredfsh fbshipit-source-id: 03ba25df3b22b06c072621e4de0eacfa1445f0d9/Temporarily Disable DBTest2.PresetCompressionDict (#5003) Summary: DBTest2.PresetCompressionDict is flaky. Temparily disable it for now. Pull Request resolved: Differential Revision: D14139505 Pulled By: siying fbshipit-source-id: ebf1872d364b76b2cb021b489ea2f17ee997116a/Apply modernize-use-override (2nd iteration) Summary: Use C++11ís override and remove virtual where applicable. Change are automatically generated. Reviewed By: Orvid Differential Revision: D14090024 fbshipit-source-id: 1e9432e87d2657e1ff0028e15370a85d1739ba2a/Reduce scope of compression dictionary to single SST (#4952) Summary: Our previous approach was to train one compression dictionary per compaction, using the first output SST to train a dictionary, and then applying it on subsequent SSTs in the same compaction. While this was great for minimizing CPU/memory/I/O overhead, it did not achieve good compression ratios in practice. In our most promising potential use case, moderate reductions in a dictionarys scope make a major difference on compression ratio. So, this PR changes compression dictionary to be scoped per-SST. It accepts the tradeoff during table building to use more memory and CPU. Important changes include: The `BlockBasedTableBuilder` has a new state when dictionary compression is in-use: `kBuffered`. In that state it accumulates uncompressed data in-memory whenever `Add` is called. After accumulating target file size bytes or calling `BlockBasedTableBuilder::Finish`, a `BlockBasedTableBuilder` moves to the `kUnbuffered` state. The transition (`EnterUnbuffered()`) involves sampling the buffered data, training a dictionary, and compressing/writing out all buffered data. In the `kUnbuffered` state, a `BlockBasedTableBuilder` behaves the same as before blocks are compressed/written out as soon as they fill up. Samples are now whole uncompressed data blocks, except the final sample may be a partial data block so we dont breach the users configured `max_dict_bytes` or `zstd_max_train_bytes`. The dictionary trainer is supposed to work better when we pass it real units of compression. Previously we were passing 64-byte KV samples which was not realistic. Pull Request resolved: Differential Revision: D13967980 Pulled By: ajkr fbshipit-source-id: 82bea6f7537e1529c7a1a4cdee84585f5949300f/"
,,0.1026,rocksdb,"Added missing table properties in log (#5168) Summary: When a new SST file is created via flush or compaction, we dump out the table properties, however only a few table properties are logged. The change here is to log all the table properties Pull Request resolved: Differential Revision: D14876928 Pulled By: vjnadimpalli fbshipit-source-id: 1aca42ad00f9f650761d39e187f8beeb8700149b/"
,,0.156,rocksdb,"Atomic ingest (#4895) Summary: Make file ingestion atomic. as title. Ingesting external SST files into multiple column families should be atomic. If a crash occurs and db reopens, either all column families have successfully ingested the files before the crash, or non of the ingestions have any effect on the state of the db. Also add unit tests for atomic ingestion. Note that the unit test here does not cover the case of incomplete atomic group in the MANIFEST, which is covered in VersionSetTest already. Pull Request resolved: Differential Revision: D13718245 Pulled By: riversand963 fbshipit-source-id: 7df97cc483af73ad44dd6993008f99b083852198/"
,,0.1506,rocksdb,"Atomic ingest (#4895) Summary: Make file ingestion atomic. as title. Ingesting external SST files into multiple column families should be atomic. If a crash occurs and db reopens, either all column families have successfully ingested the files before the crash, or non of the ingestions have any effect on the state of the db. Also add unit tests for atomic ingestion. Note that the unit test here does not cover the case of incomplete atomic group in the MANIFEST, which is covered in VersionSetTest already. Pull Request resolved: Differential Revision: D13718245 Pulled By: riversand963 fbshipit-source-id: 7df97cc483af73ad44dd6993008f99b083852198/"
,,0.201,rocksdb,"add GetStatsHistory to retrieve stats snapshots (#4748) Summary: This PR adds public `GetStatsHistory` API to retrieve stats history in the form of an std map. The key of the map is the timestamp in microseconds when the stats snapshot is taken, the value is another std map from stats name to stats value (stored in std string). Two DBOptions are introduced: `stats_persist_period_sec` (default 10 minutes) controls the intervals between two snapshots are taken; `max_stats_history_count` (default 10) controls the max number of history snapshots to keep in memory. RocksDB will stop collecting stats snapshots if `stats_persist_period_sec` is set to 0. (This PR is the in-memory part of Pull Request resolved: Differential Revision: D13961471 Pulled By: miasantreble fbshipit-source-id: ac836d401ecb84ea92216bf9966f969dedf4ad04/"
,,0.1237,rocksdb,Add a unit test to Ignorable manfiest record (#4964) Summary: introduced ignorable manfiest record. Adding a test to it. Pull Request resolved: Differential Revision: D14012667 Pulled By: siying fbshipit-source-id: e5f10ecc68dec2716e178d44f0fe2b76c3d857ef/
,,0.1164,rocksdb,"fix NowNanos overflow (#5062) Summary: The original implementation of WinEnvIO::NowNanos() has a constant data overflow by: li.QuadPart *= std::nano::den; As a result, the api provides a incorrect result. e.g.: li.QuadPart=13477844301545 std::nano::den=1e9 The fix uses pre-computed nano_seconds_per_period_ to present the nano seconds per performance counter period, in the case if nano::den is divisible by perf_counter_frequency_. Otherwise it falls back to use high_resolution_clock. siying ajkr Pull Request resolved: Differential Revision: D14426842 Pulled By: anand1976 fbshipit-source-id: 127f1daf423dd4b30edd0dcf8ea0466f468bec12/"
,,0.1149,rocksdb,"fix NowNanos overflow (#5062) Summary: The original implementation of WinEnvIO::NowNanos() has a constant data overflow by: li.QuadPart *= std::nano::den; As a result, the api provides a incorrect result. e.g.: li.QuadPart=13477844301545 std::nano::den=1e9 The fix uses pre-computed nano_seconds_per_period_ to present the nano seconds per performance counter period, in the case if nano::den is divisible by perf_counter_frequency_. Otherwise it falls back to use high_resolution_clock. siying ajkr Pull Request resolved: Differential Revision: D14426842 Pulled By: anand1976 fbshipit-source-id: 127f1daf423dd4b30edd0dcf8ea0466f468bec12/"
,,0.1239,rocksdb,"Added log_readahead_size option to control prefetching for Log::Reader (#5592) Summary: Added log_readahead_size option to control prefetching for Log::Reader. This is mostly useful for reading a remotely located log, as it can save the number of round-trips when reading it. Pull Request resolved: Differential Revision: D16362989 Pulled By: elipoz fbshipit-source-id: c5d4d5245a44008cd59879640efff70c091ad3e8/"
,,0.2299,rocksdb,"Fix from some C-style casting (#5524) Summary: Fix from some C-style casting in bloom.cc and ./tools/db_bench_tool.cc Pull Request resolved: Differential Revision: D16075626 Pulled By: elipoz fbshipit-source-id: 352948885efb64a7ef865942c75c3c727a914207/Unordered Writes (#5218) Summary: Performing unordered writes in rocksdb when unordered_write option is set to true. When enabled the writes to memtable are done without joining any write thread. This offers much higher write throughput since the upcoming writes would not have to wait for the slowest memtable write to finish. The tradeoff is that the writes visible to a snapshot might change over time. If the application cannot tolerate that, it should implement its own mechanisms to work around that. Using TransactionDB with WRITE_PREPARED write policy is one way to achieve that. Doing so increases the max throughput by 2.2x without however compromising the snapshot guarantees. The patch is prepared based on an original by siying Existing unit tests are extended to include unordered_write option. Benchmark Results: ``` TEST_TMPDIR=/dev/shm/ ./db_bench_unordered ``` With WAL Vanilla RocksDB: 78.6 MB/s WRITER_PREPARED with unordered_write: 177.8 MB/s (2.2x) unordered_write: 368.9 MB/s (4.7x with relaxed snapshot guarantees) Without WAL Vanilla RocksDB: 111.3 MB/s WRITER_PREPARED with unordered_write: 259.3 MB/s MB/s (2.3x) unordered_write: 645.6 MB/s (5.8x with relaxed snapshot guarantees) WRITER_PREPARED with unordered_write disable concurrency control: 185.3 MB/s MB/s (2.35x) Limitations: The feature is not yet extended to `max_successive_merges` > 0. The feature is also incompatible with `enable_pipelined_write` true as well as with `allow_concurrent_memtable_write` false. Pull Request resolved: Differential Revision: D15219029 Pulled By: maysamyabandeh fbshipit-source-id: 38f2abc4af8780148c6128acdba2b3227bc81759/"
,,0.0947,rocksdb,Add a MultiRead() method to Env (#5311) Summary: Define the Env:: MultiRead() method to allow callers to request multiple block reads in one shot. The underlying Env implementation can parallelize it if it chooses to in order to reduce the overall IO latency. Pull Request resolved: Differential Revision: D15502172 Pulled By: anand1976 fbshipit-source-id: 2b228269c2e11b5f54694d6b2bb3119c8a8ce2b9/
,,0.0833,rocksdb,Implemented a file logger that uses WritableFileWriter (#5491) Summary: Current PosixLogger performs IO operations using posix calls. Thus the current implementation will not work for non-posix env. Created a new logger class EnvLogger that uses env specific WritableFileWriter for IO operations. Pull Request resolved: Test Plan: make check Differential Revision: D15909002 Pulled By: ggaurav28 fbshipit-source-id: 13a8105176e8e42db0c59798d48cb6a0dbccc965/
,,0.1087,rocksdb,Remove passing const variable to thread (#5443) Summary: CLANG complains that passing const to thread is not necessary. The patch removes it form PreparedHeap::Concurrent test. Pull Request resolved: Differential Revision: D15781598 Pulled By: maysamyabandeh fbshipit-source-id: 3aceb05d96182fa4726d6d37eed45fd3aac4c016/
,,0.203,rocksdb,"Unordered Writes (#5218) Summary: Performing unordered writes in rocksdb when unordered_write option is set to true. When enabled the writes to memtable are done without joining any write thread. This offers much higher write throughput since the upcoming writes would not have to wait for the slowest memtable write to finish. The tradeoff is that the writes visible to a snapshot might change over time. If the application cannot tolerate that, it should implement its own mechanisms to work around that. Using TransactionDB with WRITE_PREPARED write policy is one way to achieve that. Doing so increases the max throughput by 2.2x without however compromising the snapshot guarantees. The patch is prepared based on an original by siying Existing unit tests are extended to include unordered_write option. Benchmark Results: ``` TEST_TMPDIR=/dev/shm/ ./db_bench_unordered ``` With WAL Vanilla RocksDB: 78.6 MB/s WRITER_PREPARED with unordered_write: 177.8 MB/s (2.2x) unordered_write: 368.9 MB/s (4.7x with relaxed snapshot guarantees) Without WAL Vanilla RocksDB: 111.3 MB/s WRITER_PREPARED with unordered_write: 259.3 MB/s MB/s (2.3x) unordered_write: 645.6 MB/s (5.8x with relaxed snapshot guarantees) WRITER_PREPARED with unordered_write disable concurrency control: 185.3 MB/s MB/s (2.35x) Limitations: The feature is not yet extended to `max_successive_merges` > 0. The feature is also incompatible with `enable_pipelined_write` true as well as with `allow_concurrent_memtable_write` false. Pull Request resolved: Differential Revision: D15219029 Pulled By: maysamyabandeh fbshipit-source-id: 38f2abc4af8780148c6128acdba2b3227bc81759/"
,,0.0838,rocksdb,"Revert ""Reduce iterator key comparison for upper/lower bound check (#5111)"" (#5440) Summary: This reverts commit f3a7847598d89ef8f9f531b10fabb7ce044a38f8. Pull Request resolved: Differential Revision: D15765967 Pulled By: ltamasi fbshipit-source-id: d027fe24132e3729289cd7c01857a7eb449d9dd0/"
,,0.08,rocksdb,"Revert ""Reduce iterator key comparison for upper/lower bound check (#5111)"" (#5440) Summary: This reverts commit f3a7847598d89ef8f9f531b10fabb7ce044a38f8. Pull Request resolved: Differential Revision: D15765967 Pulled By: ltamasi fbshipit-source-id: d027fe24132e3729289cd7c01857a7eb449d9dd0/"
,,0.1045,rocksdb,"Support loading custom objects in unit tests (#5676) Summary: Most existing RocksDB unit tests run on `Env::Default()`. It will be useful to port the unit tests to non-default environments, e.g. `HdfsEnv`, etc. This pull request is one step towards this goal. If RocksDB unit tests are built with a static library exposing a function `RegisterCustomObjects()`, then it is possible to implement custom object registrar logic in the library. RocksDB unit test can call `RegisterCustomObjects()` at the beginning. By default, `ROCKSDB_UNITTESTS_WITH_CUSTOM_OBJECTS_FROM_STATIC_LIBS` is not defined, thus this PR has no impact on existing RocksDB because `RegisterCustomObjects()` is a noop. Test plan (on devserver): ``` $make clean && COMPILE_WITH_ASAN=1 make all $make check ``` All unit tests must pass. Pull Request resolved: Differential Revision: D16679157 Pulled By: riversand963 fbshipit-source-id: aca571af3fd0525277cdc674248d0fe06e060f9d/"
,,0.2379,rocksdb,"Fix tsan complaint in ConcurrentMergeWrite test (#5308) Summary: The test was not using separate MemTablePostProcessInfo per memetable insert thread and thus tsan was complaining about data race. Pull Request resolved: Differential Revision: D15356420 Pulled By: maysamyabandeh fbshipit-source-id: 46c2f2d19fb02c3c775b587aa09ca9c0dae6ed04/Unordered Writes (#5218) Summary: Performing unordered writes in rocksdb when unordered_write option is set to true. When enabled the writes to memtable are done without joining any write thread. This offers much higher write throughput since the upcoming writes would not have to wait for the slowest memtable write to finish. The tradeoff is that the writes visible to a snapshot might change over time. If the application cannot tolerate that, it should implement its own mechanisms to work around that. Using TransactionDB with WRITE_PREPARED write policy is one way to achieve that. Doing so increases the max throughput by 2.2x without however compromising the snapshot guarantees. The patch is prepared based on an original by siying Existing unit tests are extended to include unordered_write option. Benchmark Results: ``` TEST_TMPDIR=/dev/shm/ ./db_bench_unordered ``` With WAL Vanilla RocksDB: 78.6 MB/s WRITER_PREPARED with unordered_write: 177.8 MB/s (2.2x) unordered_write: 368.9 MB/s (4.7x with relaxed snapshot guarantees) Without WAL Vanilla RocksDB: 111.3 MB/s WRITER_PREPARED with unordered_write: 259.3 MB/s MB/s (2.3x) unordered_write: 645.6 MB/s (5.8x with relaxed snapshot guarantees) WRITER_PREPARED with unordered_write disable concurrency control: 185.3 MB/s MB/s (2.35x) Limitations: The feature is not yet extended to `max_successive_merges` > 0. The feature is also incompatible with `enable_pipelined_write` true as well as with `allow_concurrent_memtable_write` false. Pull Request resolved: Differential Revision: D15219029 Pulled By: maysamyabandeh fbshipit-source-id: 38f2abc4af8780148c6128acdba2b3227bc81759/"
,,0.0819,rocksdb,"Revert ""Reduce iterator key comparison for upper/lower bound check (#5111)"" (#5440) Summary: This reverts commit f3a7847598d89ef8f9f531b10fabb7ce044a38f8. Pull Request resolved: Differential Revision: D15765967 Pulled By: ltamasi fbshipit-source-id: d027fe24132e3729289cd7c01857a7eb449d9dd0/"
,,0.1541,rocksdb,"Fix a compile error (#5864) Summary: ``` tools/block_cache_analyzer/block_cache_trace_analyzer.cc:653:48: error: implicit conversion loses integer precision: uint64_t (aka unsigned long long) to std::__1::linear_congruential_engine<unsigned int, 48271, 0, 2147483647>::result_type (aka unsigned int) [-Werror,-Wshorten-64-to-32] std::default_random_engine rand_engine(env_->NowMicros()); ``` Pull Request resolved: Differential Revision: D17668962 fbshipit-source-id: e08fa58b2a78a8dd8b334862b5714208f696b8ab/Fix RocksDB bug in block_cache_trace_analyzer.cc on Windows (#5786) Summary: This is required to compile on Windows with Visual Studio 2015. Pull Request resolved: Differential Revision: D17335994 fbshipit-source-id: 8f9568310bc6f697e312b5e24ad465e9084f0011/"
,,0.2731,rocksdb,sst_dump recompress show compressed and not compressed (#5791) Summary: Closes Helps show when the 12.5% threshold for GoodCompressionRatio (originally from ldb) is hit. Example output: ``` > ./sst_dump from [] to [] Process /tmp/test.sst Sst file format: block-based Block Size: 16384 Compression: kNoCompression Size: 122579836 Blocks: 2300 Compressed: 0 ( 0.0%) Not compressed (ratio): 2300 (100.0%) Not compressed (abort): 0 ( 0.0%) Compression: kSnappyCompression Size: 46289962 Blocks: 2300 Compressed: 2119 ( 92.1%) Not compressed (ratio): 181 ( 7.9%) Not compressed (abort): 0 ( 0.0%) Compression: kZlibCompression Size: 29689825 Blocks: 2300 Compressed: 2301 (100.0%) Not compressed (ratio): 0 ( 0.0%) Not compressed (abort): 0 ( 0.0%) Unsupported compression type: kBZip2Compression. Compression: kLZ4Compression Size: 44785490 Blocks: 2300 Compressed: 1950 ( 84.8%) Not compressed (ratio): 350 ( 15.2%) Not compressed (abort): 0 ( 0.0%) Compression: kLZ4HCCompression Size: 37498895 Blocks: 2300 Compressed: 2301 (100.0%) Not compressed (ratio): 0 ( 0.0%) Not compressed (abort): 0 ( 0.0%) Unsupported compression type: kXpressCompression. Compression: kZSTD Size: 32208707 Blocks: 2300 Compressed: 2301 (100.0%) Not compressed (ratio): 0 ( 0.0%) Not compressed (abort): 0 ( 0.0%) ``` Pull Request resolved: Differential Revision: D17347870 fbshipit-source-id: af10849c010b46b20e54162b70123c2805ffe526/
,,0.0937,rocksdb,"arm64 crc prefetch optimise (#5773) Summary: prefetch data for following block?avoid cache miss when doing crc caculate I do performance test at kunpeng-920 server(arm-v8, ./db_bench before optimise : 587313.500 micros/op 1 ops/sec; 811.9 MB/s (500000000 per op) after optimise : 289248.500 micros/op 3 ops/sec; 1648.5 MB/s (500000000 per op) Pull Request resolved: Differential Revision: D17347339 fbshipit-source-id: bfcd74f0f0eb4b322b959be68019ddcaae1e3341/"
,,0.0899,rocksdb,"Use delete to disable automatic generated methods. (#5009) Summary: Use delete to disable automatic generated methods instead of private, and put the constructor together for more clear.This modification cause the unused field warning, so add unused attribute to disable this warning. Pull Request resolved: Differential Revision: D17288733 fbshipit-source-id: 8a767ce096f185f1db01bd28fc88fef1cdd921f3/"
,,0.092,rocksdb,"WriteUnPrepared: increase test coverage in transaction_test (#5658) Summary: The changes transaction_test to set `txn_db_options.default_write_batch_flush_threshold 1` in order to give better test coverage for WriteUnprepared. As part of the change, some tests had to be updated. Pull Request resolved: Differential Revision: D16740468 Pulled By: lth fbshipit-source-id: 3821eec20baf13917c8c1fab444332f75a509de9/"
,,0.1116,rocksdb,"Fix PlainTableReader not to crash sst_dump (#5940) Summary: Plain table SSTs could crash sst_dump because of a bug in PlainTableReader that can leave table_properties_ as null. Even if it was intended not to keep the table properties in some cases, they were leaked on the offending code path. Steps to reproduce: $ db_bench $ sst_dump from [] to [] Process /dev/shm/dbbench/000014.sst Sst file format: plain table Raw user collected properties Segmentation fault (core dumped) Also added missing unit testing of plain table full_scan_mode, and an assertion in NewIterator to check for regression. Pull Request resolved: Test Plan: new unit test, manual, make check Differential Revision: D18018145 Pulled By: pdillinger fbshipit-source-id: 4310c755e824c4cd6f3f86a3abc20dfa417c5e07/Revert changes from PR#5784 accidentally in PR#5780 (#5810) Summary: This will allow us to fix history by having the code changes for PR#5784 properly attributed to it. Pull Request resolved: Differential Revision: D17400231 Pulled By: pdillinger fbshipit-source-id: 2da8b1cdf2533cfedb35b5526eadefb38c291f09/Refactor some confusing logic in PlainTableReader Summary: Pull Request resolved: Test Plan: existing plain table unit test Differential Revision: D17368629 Pulled By: pdillinger fbshipit-source-id: f25409cdc2f39ebe8d5cbb599cf820270e6b5d26/"
,,0.1601,rocksdb,Revert changes from PR#5784 accidentally in PR#5780 (#5810) Summary: This will allow us to fix history by having the code changes for PR#5784 properly attributed to it. Pull Request resolved: Differential Revision: D17400231 Pulled By: pdillinger fbshipit-source-id: 2da8b1cdf2533cfedb35b5526eadefb38c291f09/Refactor some confusing logic in PlainTableReader Summary: Pull Request resolved: Test Plan: existing plain table unit test Differential Revision: D17368629 Pulled By: pdillinger fbshipit-source-id: f25409cdc2f39ebe8d5cbb599cf820270e6b5d26/
,,0.1521,rocksdb,Refactor ObsoleteFilesTest to inherit from DBTestBase (#5820) Summary: Make class ObsoleteFilesTest inherit from DBTestBase. Test plan (on devserver): ``` $COMPILE_WITH_ASAN=1 make obsolete_files_test $./obsolete_files_test ``` Pull Request resolved: Differential Revision: D17452348 Pulled By: riversand963 fbshipit-source-id: b09f4581a18022ca2bfd79f2836c0bf7083f5f25/
,,0.1557,rocksdb,Revert changes from PR#5784 accidentally in PR#5780 (#5810) Summary: This will allow us to fix history by having the code changes for PR#5784 properly attributed to it. Pull Request resolved: Differential Revision: D17400231 Pulled By: pdillinger fbshipit-source-id: 2da8b1cdf2533cfedb35b5526eadefb38c291f09/Refactor some confusing logic in PlainTableReader Summary: Pull Request resolved: Test Plan: existing plain table unit test Differential Revision: D17368629 Pulled By: pdillinger fbshipit-source-id: f25409cdc2f39ebe8d5cbb599cf820270e6b5d26/
,,0.1239,rocksdb,Refactor deletefile_test.cc (#5822) Summary: Make DeleteFileTest inherit DBTestBase to avoid code duplication. Test Plan (on devserver) ``` $make deletefile_test $./deletefile_test ``` Pull Request resolved: Differential Revision: D17456750 Pulled By: riversand963 fbshipit-source-id: 224e97967da7b98838a98981cd5095d3230a814f/
,,0.0789,rocksdb,"Add range delete function to C-API (#6259) Summary: It seems that the C-API doesnt expose the range delete functionality at the moment, so add the API. Pull Request resolved: Differential Revision: D19290320 Pulled By: pdillinger fbshipit-source-id: 3f403a4c3446d2042d55f1ece7cdc9c040f40c27/"
,,0.1213,rocksdb,Cleanup deprecation warnings and javadoc (#6218) Summary: There are no API changes ;-) Pull Request resolved: Differential Revision: D19200373 Pulled By: pdillinger fbshipit-source-id: 58d34b01ea53b75a1eccbd72f8b14d6256a7380f/
,,0.1157,rocksdb,Cleanup deprecation warnings and javadoc (#6218) Summary: There are no API changes ;-) Pull Request resolved: Differential Revision: D19200373 Pulled By: pdillinger fbshipit-source-id: 58d34b01ea53b75a1eccbd72f8b14d6256a7380f/
,,0.1157,rocksdb,Cleanup deprecation warnings and javadoc (#6218) Summary: There are no API changes ;-) Pull Request resolved: Differential Revision: D19200373 Pulled By: pdillinger fbshipit-source-id: 58d34b01ea53b75a1eccbd72f8b14d6256a7380f/
,,0.094,rocksdb,"Add kHashSearch to stress tests (#6210) Summary: Beside extending index_type to kHashSearch, it clarifies in the code base that this feature is incompatible with index_block_restart_interval > 1. Pull Request resolved: Test Plan: ``` make crash_test Differential Revision: D19166567 Pulled By: maysamyabandeh fbshipit-source-id: 3aaf75a70a8b462d372d43aac69dbd10df303ec7/"
,,0.0907,rocksdb,"Add kHashSearch to stress tests (#6210) Summary: Beside extending index_type to kHashSearch, it clarifies in the code base that this feature is incompatible with index_block_restart_interval > 1. Pull Request resolved: Test Plan: ``` make crash_test Differential Revision: D19166567 Pulled By: maysamyabandeh fbshipit-source-id: 3aaf75a70a8b462d372d43aac69dbd10df303ec7/"
,,0.2271,rocksdb,"Check KeyContext status in MultiGet (#6387) Summary: Currently, any IO errors and checksum mismatches while reading data blocks, are being ignored by the batched MultiGet. Its only looking at the GetContext state. Fix that. Pull Request resolved: Test Plan: Add unit tests Differential Revision: D19799819 Pulled By: anand1976 fbshipit-source-id: 46133dccbb04e64067b9fe6cda73e282203db969/Fix compilation under LITE (#6277) Summary: Fix compilation under LITE by putting `#ifndef ROCKSDB_LITE` around a code block. Pull Request resolved: Differential Revision: D19334157 Pulled By: riversand963 fbshipit-source-id: 947111ed68aa550f5ea424b216c1442a8af9e32b/Update file indexer to take timestamp into consideration (#6205) Summary: Exclude timestamp in key comparison during boundary calculation to avoid key versions being excluded. Pull Request resolved: Differential Revision: D19166765 Pulled By: riversand963 fbshipit-source-id: bbe08816fef8de349a83ebd59a595ad844021f24/"
,,0.1586,rocksdb,"Add a unit test for prefix extractor changes (#6323) Summary: Add a unit test for prefix extractor change, including a check that fails due to a bug. Also comment out the partitioned filter case which will fail the test too. Pull Request resolved: Test Plan: Run the test and it passes (and fails if the SeekForPrev() part is uncommented) Differential Revision: D19509744 fbshipit-source-id: 678202ca97b5503e9de73b54b90de9e5ba822b72/Fix a data race for cfd->log_number_ (#6249) Summary: A thread calling LogAndApply may release db mutex when calling WriteCurrentStateToManifest() which reads cfd->log_number_. Another thread can call SwitchMemtable() and writes to cfd->log_number_. Solution is to cache the cfd->log_number_ before releasing mutex in LogAndApply. Test Plan (on devserver): ``` $COMPILE_WITH_TSAN=1 make db_stress $./db_stress ``` Then repeat the following multiple times, e.g. 100 after compiling with tsan. ``` $./db_test2 ``` Pull Request resolved: Differential Revision: D19235077 Pulled By: riversand963 fbshipit-source-id: 79467b52f48739ce7c27e440caa2447a40653173/Prevent an incompatible combination of options (#6254) Summary: allow_concurrent_memtable_write is incompatible with non-zero max_successive_merges. Although we check this at runtime, we currently dont prevent the user from setting this combination in options. This has led to stress tests to fail with this combination is tried in ::SetOptions. The patch fixes that. Pull Request resolved: Differential Revision: D19265819 Pulled By: maysamyabandeh fbshipit-source-id: 47f2e2dc26fe0972c7152f4da15dadb9703f1179/delete superversions in BackgroundCallPurge (#6146) Summary: I found that CleanupSuperVersion() may block Get() for 30ms+ ?per MemTable is 256MB?. Then I found ""delete sv"" in ~SuperVersion() takes the time. The backtrace looks like this DBImpl::GetImpl() DBImpl::ReturnAndCleanupSuperVersion() DBImpl::CleanupSuperVersion() : delete sv; ~SuperVersion() I think its better to delete in a background thread, please review it? Pull Request resolved: Differential Revision: D18972066 fbshipit-source-id: 0f7b0b70b9bb1e27ad6fc1c8a408fbbf237ae08c/"
,,0.1386,rocksdb,"Fix IngestExternalFiles bug with two_write_queue (#5976) Summary: When two_write_queue enable, IngestExternalFile performs EnterUnbatched on both write queues. SwitchMemtable also EnterUnbatched on 2nd write queue when this option is enabled. When the call stack includes IngestExternalFile FlushMemTable SwitchMemtable, this results into a deadlock. The implemented solution is to pass on the existing writes_stopped argument in FlushMemTable to skip EnterUnbatched in SwitchMemtable. Fixes Pull Request resolved: Differential Revision: D18535943 Pulled By: maysamyabandeh fbshipit-source-id: a4f9d4964c10d4a7ca06b1e0102ca2ec395512bc/"
