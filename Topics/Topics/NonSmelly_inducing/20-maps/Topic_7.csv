Topic_no,Keywords,Contrib,System,Text
7,"add, fix, change, type, check, field, realm, update, support, exception, remove, throw, internal, null, string, object, core, realmresult, annotation_processor, empty",0.0755,conscrypt,Invert pinning API name The pinning API used a negative name for the API which made it difficult to reason about logically. Change them to positive names so the returned booleans dont need to be inverted in my head. Change-Id: Iad89d9cec33b3ef27e80a3344a5b23dec023d636/
,,0.0859,conscrypt,Invert pinning API name The pinning API used a negative name for the API which made it difficult to reason about logically. Change them to positive names so the returned booleans dont need to be inverted in my head. Change-Id: Iad89d9cec33b3ef27e80a3344a5b23dec023d636/
,,0.0842,conscrypt,Invert pinning API name The pinning API used a negative name for the API which made it difficult to reason about logically. Change them to positive names so the returned booleans dont need to be inverted in my head. Change-Id: Iad89d9cec33b3ef27e80a3344a5b23dec023d636/
,,0.0726,conscrypt,"Use a serialization proxy for DH keys Since DHPrivateKey and DHPublicKey uses a lock to determine when to fetch the key parameters, we need to have some way for the field to be final. Using a serialization proxy makes that safe. Change-Id: Ifac7330fa35f0dc13313c806efacffbd293c6f85/"
,,0.1595,conscrypt,"OpenSSLX509Certificate: use OID if alg name unavailable If we cannot map the signature OID type to a canonical name, then we should try to get an instance of the signature type using the OID. Additionally, we should return the OID for the instead of null. Bug: 22365511 Change-Id: I1ebf48667cf720ee5c7751667601eec2f6f8ec91/Revert ""OpenSSLX509Certificate: mark mContext as transient"" This reverts commit 998fbfcd4729ee2e196ed17106f76de93f33d7f0. Missing the test class. Change-Id: I426680f74c4f3ebeb42abd80ebfdba469247c348/"
,,0.12,conscrypt,"Locking down public APIs (#157) Tried to be as aggressive as I could, so this probably deserves a fairly thorough review. I left most of OpenSSLSocketImpl public, because I think its needed by a few external projects. I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated. Fixes"
,,0.1181,conscrypt,"Locking down public APIs (#157) Tried to be as aggressive as I could, so this probably deserves a fairly thorough review. I left most of OpenSSLSocketImpl public, because I think its needed by a few external projects. I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated. Fixes"
,,0.2032,conscrypt,"Locking down public APIs (#157) Tried to be as aggressive as I could, so this probably deserves a fairly thorough review. I left most of OpenSSLSocketImpl public, because I think its needed by a few external projects. I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated. Fixes top-level Conscrypt class (#152) This is a one-stop-shop for creating and configuring Conscrypt types. It allows a standard way for configuring extended settings that are not currently supported by the standard Java APIs./Add error-prone and fix all the errors (#146)/"
,,0.2111,conscrypt,"Locking down public APIs (#157) Tried to be as aggressive as I could, so this probably deserves a fairly thorough review. I left most of OpenSSLSocketImpl public, because I think its needed by a few external projects. I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated. Fixes top-level Conscrypt class (#152) This is a one-stop-shop for creating and configuring Conscrypt types. It allows a standard way for configuring extended settings that are not currently supported by the standard Java APIs./"
,,0.2111,conscrypt,"Locking down public APIs (#157) Tried to be as aggressive as I could, so this probably deserves a fairly thorough review. I left most of OpenSSLSocketImpl public, because I think its needed by a few external projects. I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated. Fixes top-level Conscrypt class (#152) This is a one-stop-shop for creating and configuring Conscrypt types. It allows a standard way for configuring extended settings that are not currently supported by the standard Java APIs./"
,,0.1161,conscrypt,"Locking down public APIs (#157) Tried to be as aggressive as I could, so this probably deserves a fairly thorough review. I left most of OpenSSLSocketImpl public, because I think its needed by a few external projects. I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated. Fixes"
,,0.2128,conscrypt,"Locking down public APIs (#157) Tried to be as aggressive as I could, so this probably deserves a fairly thorough review. I left most of OpenSSLSocketImpl public, because I think its needed by a few external projects. I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated. Fixes top-level Conscrypt class (#152) This is a one-stop-shop for creating and configuring Conscrypt types. It allows a standard way for configuring extended settings that are not currently supported by the standard Java APIs./"
,,0.2094,conscrypt,"Locking down public APIs (#157) Tried to be as aggressive as I could, so this probably deserves a fairly thorough review. I left most of OpenSSLSocketImpl public, because I think its needed by a few external projects. I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated. Fixes top-level Conscrypt class (#152) This is a one-stop-shop for creating and configuring Conscrypt types. It allows a standard way for configuring extended settings that are not currently supported by the standard Java APIs./"
,,0.2151,conscrypt,"Locking down public APIs (#157) Tried to be as aggressive as I could, so this probably deserves a fairly thorough review. I left most of OpenSSLSocketImpl public, because I think its needed by a few external projects. I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated. Fixes top-level Conscrypt class (#152) This is a one-stop-shop for creating and configuring Conscrypt types. It allows a standard way for configuring extended settings that are not currently supported by the standard Java APIs./Create Doclet for public API docs This allows us to use to prevent a class from showing up in the public API documentation./"
,,0.1806,conscrypt,Adding all factory methods for engine socket. (#192) Also properly throwing SSLHandshakeException in some cases. Fixes top-level Conscrypt class (#152) This is a one-stop-shop for creating and configuring Conscrypt types. It allows a standard way for configuring extended settings that are not currently supported by the standard Java APIs./
,,0.1254,conscrypt,"Add additional aliases. These aliases are provided by Bouncy Castle for these algorithms, so were adding them as well so that anyone using them can get the Conscrypt versions without having to change their code./Locking down public APIs (#157) Tried to be as aggressive as I could, so this probably deserves a fairly thorough review. I left most of OpenSSLSocketImpl public, because I think its needed by a few external projects. I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated. Fixes"
,,0.2264,conscrypt,"Allow localhost as an SNI hostname. (#475) As an exception to the normal rule that you cant have an SNI hostname without dots, localhost is a fine hostname for SNI./Disallow invalid SNI hostnames in setHostname(). (#470) The code that sets the SNI value on the connection checks for impl.getUseSni() && AddressUtils.isValidSniHostname(hostname) which is good for hostnames that were supplied as the hostname to connect to, since they may or may not be valid for SNI, but means that if you set an invalid hostname with setHostname() it will just silently be omitted from the connection and no SNI extension will be included in the handshake. Better to reject the hostname immediately. Also disallow hostnames with trailing dots, which arent legal SNI hostnames per RFC 6066. Also disallow null bytes./"
,,0.0643,frostwire,"[desktop] Using new API for sc, no more recursion/"
,,0.0639,frostwire,[android] MusicViewHolder optional mParentId field. list_item_image refactor/
,,0.1228,frostwire,[android] fix infinite recursion in Debug#hasContext due to self reference field/[android] Debug log output Not having this is time consuming as many exceptions are ignored and it might just be the context verifier throwing an exception that doesnt get printed by anybody/[android] dont check Boolean/[android] avoid infinite recursion checking enums for Context Leaks/[android] added method to detect all activities that should not be done in the main thread/
,,0.0673,frostwire,[android] FileListAdapter.initCheckableGridImageView throws cleanup/
,,0.0818,javacpp,* Provide `BytePointer` with value getters and setters for primitive types other than `byte` to facilitate unaligned memory accesses/
,,0.0713,javacpp,"* Let users bundle arbitrary resources, have them extracted in cache, and used as `include` or `link` paths (pull"
,,0.071,javacpp,"* Add `Parser` support for `_Bool`, `_Complex`, `_Imaginary`, `complex`, `imaginary` types from C99/"
,,0.0933,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0975,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0933,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.1017,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0912,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0566,jna,Many many updates. Merge from gcc and then some./
,,0.0912,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0954,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0954,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0954,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0954,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0933,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0975,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0954,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0912,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0933,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0912,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0933,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0954,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0954,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0933,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0975,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0975,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.1017,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0954,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0975,jna,Pulled in libffi from gcc trunk. Fixed build and install for standalone use./
,,0.0665,jna,fix struct layout cacheing in Union/cache structure layout results/fix JIRA issue 188/
,,0.114,jna,"updated ""Promote float varargs to double"" bug fix/Promote float varargs to double/"
,,0.0756,jna,structure alignment fixes for ARM/fixed tests related to 64-bit alignment/down to 24 failures (4 crashes) on w32ce-arm/w32ce-arm library load on wince 5 (WM6.1)/
,,0.1157,jna,"updated ""Promote float varargs to double"" bug fix/Promote float varargs to double/Apply generic definitions wherever applicable/"
,,0.066,jna,Add GetDriveType() to Kernerl32 examples. Patch by Marc Strapetz. git-svn-id: 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/
,,0.0776,jna,More changes based on feedback * Converted char to byte for UCHAR * Made Privilege implement Closeable/
,,0.0621,jna,GetLogicalProcessorInformation and associated structs/
,,0.0618,jna,Added Shell32.SHGetKnownFolderPath and corresponding constants/
,,0.0883,jna,Fixing the DOMAIN_CONTROLLER_INFO structure. It was missing a field declaration. This should fix the getDC method and unit test/Fixing null values in first domain trust array entry/address issue
,,0.0786,jna,Fixed bug in WinspoolUtil.getPrinterInfo1() and WinspoolUtil.getPrinterInfo4() where the first elements fields was never populated/
,,0.0599,jna,some changes for typelib/some changes/
,,0.0731,jna,"Fix variant constructors, add a test that makes sure they now longer throw immediately/"
,,0.0577,jna,some changes to find issue with JNA 4/
,,0.0664,OpenDDS,ChangeLogTag:Mon Dec 19 09:43:03 MST 2005 Trevor Fields
,,0.0686,OpenDDS,Tue Oct 25 17:26:38 MST 2005 Trevor Fields
,,0.063,OpenDDS,Thu Nov 17 06:23:48 MST 2005 Scott Harris
,,0.0686,OpenDDS,ChangeLogTag:Fri Dec 16 01:03:41 MST 2005 Trevor Fields Dec 9 16:57:17 USMST 2005 Yan Dai
,,0.0686,OpenDDS,Thu Dec 15 10:08:28 USMST 2005 Yan Dai Dec 09 15:22:38 MST 2005 Trevor Fields
,,0.0686,OpenDDS,Thu Dec 15 10:08:28 USMST 2005 Yan Dai Dec 09 15:22:38 MST 2005 Trevor Fields
,,0.0838,OpenDDS,Thu Dec 15 10:08:28 USMST 2005 Yan Dai Dec 09 15:22:38 MST 2005 Trevor Fields Nov 30 10:00:19 MST 2005 Trevor Fields Oct 25 15:22:28 MST 2005 Trevor Fields Sun Oct 23 16:19:14 MST 2005 Trevor Fields
,,0.2253,OpenDDS,"Tue Jul 26 19:06:14 UTC 2011 Phil Mesnier * dds/idl/be_global.h: * dds/idl/be_global.cpp: * dds/idl/be_produce.cpp: * dds/idl/dds_visitor.cpp: * dds/idl/wireshark_generator.h: * dds/idl/wireshark_generator.cpp: Added generator of wireshark dissector configuration files. To run, add ""-Gws"" to the opendds_idl command line. Running on yields in the local directory. This *_ws.ini file can then be used by the wireshark dissector to process sample data messages. * tools/dissector/giop_base.h: * tools/dissector/giop_base.cpp: * tools/dissector/packet-datawriter.h: * tools/dissector/packet-datawriter.cpp: * tools/dissector/packet-opendds.h: * tools/dissector/packet-opendds.cpp: * tools/dissector/packet-repo.h: * tools/dissector/packet-repo.cpp: Fixed a couple of compiler warnings. Added decomposition of content filter ID values, enabled the parsing of inforepo messages without first storing the inforepo ior in ""IOR.txt"" for wireshark. * tools/dissector/sample_dissector.h: * tools/dissector/sample_dissector.cpp: * tools/dissector/sample_manager.h: * tools/dissector/sample_manager.cpp: Added ""CORBA::<typename>"" as an alternative basic type id for parsing. The idl compiler emits C++ mapped types rather than the original CORBA IDL type name for predefined types. User specified types are used as-is. Also, translations between string types were simplified, favoring std::string where ever posible./"
,,0.066,OpenDDS,Fri Aug 9 22:04:45 UTC 2013 Phillip LaBanca
,,0.0686,OpenDDS,ChangeLogTag: Thu Dec 18 17:18:55 UTC 2014 Justin Wilson
,,0.0677,OpenDDS,"Added option to opendds_idl, renamed to to distinguish/"
,,0.0783,OpenDDS,"opendds_idl: rename existing ""FACE"" functionality to ""FACE TS"", continued adding support for specialized language mappings (with FACE C++ being the first one)./Added option to opendds_idl, renamed to to distinguish/"
,,0.0865,OpenDDS,ChangeLogTag: Fri Feb 6 21:12:24 UTC 2015 Adam Mitz Jan 20 19:11:12 UTC 2015 Justin Wilson Jan 19 15:54:56 UTC 2015 Justin Wilson
,,0.0686,OpenDDS,ChangeLogTag: Fri Feb 6 18:51:05 UTC 2015 Adam Mitz Jan 22 23:11:40 UTC 2015 Justin Wilson
,,0.0833,OpenDDS,Initial pass at converting all std::set to OPENDDS_SET(_CMP)/ChangeLogTag: Wed Feb 25 23:20:10 UTC 2015 Adam Mitz Jan 22 23:15:46 UTC 2015 Justin Wilson Jan 5 18:55:31 UTC 2015 Justin Wilson
,,0.0891,OpenDDS,Added support for write ITL in opendds_idl. Added support for reading ITL in Wireshark dissector./
,,0.0872,OpenDDS,Added support for write ITL in opendds_idl. Added support for reading ITL in Wireshark dissector./
,,0.0987,OpenDDS,Added support for write ITL in opendds_idl. Added support for reading ITL in Wireshark dissector./
,,0.0872,OpenDDS,Added support for write ITL in opendds_idl. Added support for reading ITL in Wireshark dissector./
,,0.0929,OpenDDS,Added support for write ITL in opendds_idl. Added support for reading ITL in Wireshark dissector./
,,0.071,OpenDDS,Consolidated traits. Moved impl templates to OpenDDS::DCPS. Removed HTemplate.txt./
,,0.1044,OpenDDS,opendds_idl: with generate better code for operator== of structs with nested/multidim array members (avoids warnings in generated code)/
,,0.0719,OpenDDS,In passive_connection remove the do/while loop and replace with a copy of the vector of callbacks to iterate over and check each with current list since the lock is released and reacquired./
,,0.0744,OpenDDS,Fixed dissector bugs./
,,0.073,OpenDDS,"Addressing Coverity Scan CIDs: 1392433, 1392432, 1392430, 1392429, 1392427, 1392424, 1392421. Fix handling of uncaught exceptions./"
,,0.0833,OpenDDS,"Addressing Coverity Scan CIDs: 1392433, 1392432, 1392430, 1392429, 1392427, 1392424, 1392421. Fix handling of uncaught exceptions./"
,,0.0818,OpenDDS,"Addressing Coverity Scan CIDs: 1392433, 1392432, 1392430, 1392429, 1392427, 1392424, 1392421. Fix handling of uncaught exceptions./Added make_rch() template functions/"
,,0.0772,OpenDDS,"Addressing Coverity Scan CIDs: 1392433, 1392432, 1392430, 1392429, 1392427, 1392424, 1392421. Fix handling of uncaught exceptions./"
,,0.0665,OpenDDS,"Initial support for Wireshark 2.x, see TODO comments proto_tree_add* still needs to be handled as this has a large breaking change in wireshark/"
,,0.0833,OpenDDS,"dissector: updated handling of use_index for arrays/sequences/Initial support for Wireshark 2.x, see TODO comments proto_tree_add* still needs to be handled as this has a large breaking change in wireshark/"
,,0.063,OpenDDS,Add try/catch for CORBA::BAD_PARAM exceptions at the FaceTSS API boundary./
,,0.063,OpenDDS,Add try/catch for CORBA::BAD_PARAM exceptions at the FaceTSS API boundary./
,,0.375,OpenDDS,"Dissector: Create WS namespace properly (printed)/Dissector: Leaks dyn. field names and array/Dissector: Basic Payload Dissection in WS2 This is the basic framework for payload dissection in wireshark2. Involves adding a hf vector to the Sample_Manager Singleton, adding fields as they encountered in Sample_Dissector, and merging them with the constant DCPS fields and passing the result to wireshark when DCPS is registered. Sample Fields are left with a int that is the wireshark field id (hf_). During packet dissect, Sample_Fields are passed the wireshark field id and using that they can add data corresponding to their field. Payload type is now set on opendds.sample.payload and payload contents are added in a tree under that. Work left as of writing this is: to fix/complete registration of non string fields, involve composite types (seq, union, etc), clean up Sample_Manager usage, check/stop possible leak of dynamically generated field names and get working with tests other than Messenger./"
,,0.3836,OpenDDS,"Dissector: Create WS namespace properly (printed)/Dissector: Leaks dyn. field names and array/Dissector: Basic Payload Dissection in WS2 This is the basic framework for payload dissection in wireshark2. Involves adding a hf vector to the Sample_Manager Singleton, adding fields as they encountered in Sample_Dissector, and merging them with the constant DCPS fields and passing the result to wireshark when DCPS is registered. Sample Fields are left with a int that is the wireshark field id (hf_). During packet dissect, Sample_Fields are passed the wireshark field id and using that they can add data corresponding to their field. Payload type is now set on opendds.sample.payload and payload contents are added in a tree under that. Work left as of writing this is: to fix/complete registration of non string fields, involve composite types (seq, union, etc), clean up Sample_Manager usage, check/stop possible leak of dynamically generated field names and get working with tests other than Messenger./"
,,0.3757,OpenDDS,"Dissector: Create WS namespace properly (printed)/Dissector: Basic Payload Dissection in WS2 This is the basic framework for payload dissection in wireshark2. Involves adding a hf vector to the Sample_Manager Singleton, adding fields as they encountered in Sample_Dissector, and merging them with the constant DCPS fields and passing the result to wireshark when DCPS is registered. Sample Fields are left with a int that is the wireshark field id (hf_). During packet dissect, Sample_Fields are passed the wireshark field id and using that they can add data corresponding to their field. Payload type is now set on opendds.sample.payload and payload contents are added in a tree under that. Work left as of writing this is: to fix/complete registration of non string fields, involve composite types (seq, union, etc), clean up Sample_Manager usage, check/stop possible leak of dynamically generated field names and get working with tests other than Messenger./"
,,0.4206,OpenDDS,"Dissector: Create WS namespace properly (printed)/Dissector: Namespace passing to Sample_Field/Dissector: Added more types/Dissector: Added Support for all integer types/Dissector: Basic Payload Dissection in WS2 This is the basic framework for payload dissection in wireshark2. Involves adding a hf vector to the Sample_Manager Singleton, adding fields as they encountered in Sample_Dissector, and merging them with the constant DCPS fields and passing the result to wireshark when DCPS is registered. Sample Fields are left with a int that is the wireshark field id (hf_). During packet dissect, Sample_Fields are passed the wireshark field id and using that they can add data corresponding to their field. Payload type is now set on opendds.sample.payload and payload contents are added in a tree under that. Work left as of writing this is: to fix/complete registration of non string fields, involve composite types (seq, union, etc), clean up Sample_Manager usage, check/stop possible leak of dynamically generated field names and get working with tests other than Messenger./DCPS Dissector now running on Wireshark 2.4.1 Added ""ws"" prefix to remaining calls to proto_tree_add and tvb_length./"
,,0.1284,OpenDDS,"Mark struct as Primary DCPS Data Type in ITL file IDL compiler will add a note ""is_dcps_data_type"" to ITL types that are a struct delcared as the primary datatype with the DCPS_DATA_TYPE pragma. This is intended to help in the generation of a proper namespace for the Wireshark 2 dissector as the primary data types will be the roots of the sample payload namespaces./"
,,0.0556,OpenDDS,Remove the reference cycle in RequestDeadlineWatchdog/
,,0.0833,OpenDDS,Coverity Scan updates: Address 1454919 and 1454912 having to do with further exceptions not being caught from the bind_config call./Catch exception thrown in bind_config. Addresses Coverity Defects: 1446126 & 1446125./
,,0.4247,OpenDDS,"dissector: Fixed Type Support and expert changes Added support for dissection for OpenDDS fixed-point numbers which are converted to doubles for numerical functions. If ACE_CDR::Fixed is missing, a message will be displayed that this is so. Also started marking some packets with a warning instead of marking it as malformed. For example, when an individual field fails for some reason or non essential information is unavailable, like the dissector ITL file./Access Fixed Type Attributes/Dissector: Changes for Scoreboard, and others Also: Print ITL files and types found Fixed Bug where every field was a struct/Dissector: Various Changes for PR Comments Removed Some Manual Memory Management: String and WString code rewritten to use TAO::String_Manager_T utf16_to_utf8 rewritten to use std::vector Various Other Small Changes/Dissector: More Codacy Changes/Dissector: Fixs for PR Addressing Adams inital comments, Codacy, the Merge Conflict and a few things I found along the way./Dissector: Nexted Structs/Dissector: Namespace Resolution and Union Bug Added Sample_Base as a Parent Class to Sample_Field and Sample_Dissector. Sample_Base holds wireshark namespace and field for every context that its child class is used in. Tweaked Array and Sequence Labels and Namespace. For now using ""_e"" (for element) to access an element of the sequence or array. Removed namespace debug messages. Fixed bug in Union length calculation that caused String Key Test to hang on dissection./Dissector: Now working on String Key Test/"
,,0.1538,OpenDDS,"Dissector: Changes for Scoreboard, and others Also: Print ITL files and types found Fixed Bug where every field was a struct/Dissector: Adjustments for WS compatibility Made some changes to README Sample Dissection enabled for Wireshark 1.x. Attempted to make compatible with the next release, 2.5/2.6, but it has an assertion error on start up. 1.10 and before segfaults. Tested successfully with 1.12, 2.0, 2.2, and 2.4 on Linux./Dissector: Now working on String Key Test/"
,,0.4016,OpenDDS,"dissector: Fixed Type Support and expert changes Added support for dissection for OpenDDS fixed-point numbers which are converted to doubles for numerical functions. If ACE_CDR::Fixed is missing, a message will be displayed that this is so. Also started marking some packets with a warning instead of marking it as malformed. For example, when an individual field fails for some reason or non essential information is unavailable, like the dissector ITL file./Access Fixed Type Attributes/Dissector: Various Changes for PR Comments Removed Some Manual Memory Management: String and WString code rewritten to use TAO::String_Manager_T utf16_to_utf8 rewritten to use std::vector Various Other Small Changes/Dissector: Various Smaller Tasks Completely Removed ws_proto_tree_add_text(). Mark Packet if a determinable error occurs during sample dissection./Dissector: Serializer Refactor: Compiles, but broken/Dissector: Nexted Structs/Dissector: Namespace Resolution and Union Bug Added Sample_Base as a Parent Class to Sample_Field and Sample_Dissector. Sample_Base holds wireshark namespace and field for every context that its child class is used in. Tweaked Array and Sequence Labels and Namespace. For now using ""_e"" (for element) to access an element of the sequence or array. Removed namespace debug messages. Fixed bug in Union length calculation that caused String Key Test to hang on dissection./Dissector: Now working on String Key Test/"
,,0.4085,OpenDDS,"dissector: Fixed Type Support and expert changes Added support for dissection for OpenDDS fixed-point numbers which are converted to doubles for numerical functions. If ACE_CDR::Fixed is missing, a message will be displayed that this is so. Also started marking some packets with a warning instead of marking it as malformed. For example, when an individual field fails for some reason or non essential information is unavailable, like the dissector ITL file./Dissector: Changes for Scoreboard, and others Also: Print ITL files and types found Fixed Bug where every field was a struct/Dissector: String_Mangers remove .in()/Dissector: Various Changes for PR Comments Removed Some Manual Memory Management: String and WString code rewritten to use TAO::String_Manager_T utf16_to_utf8 rewritten to use std::vector Various Other Small Changes/Dissector: Adjustments for WS compatibility Made some changes to README Sample Dissection enabled for Wireshark 1.x. Attempted to make compatible with the next release, 2.5/2.6, but it has an assertion error on start up. 1.10 and before segfaults. Tested successfully with 1.12, 2.0, 2.2, and 2.4 on Linux./Dissector: Fixs for PR Addressing Adams inital comments, Codacy, the Merge Conflict and a few things I found along the way./Dissector: Various Smaller Tasks Completely Removed ws_proto_tree_add_text(). Mark Packet if a determinable error occurs during sample dissection./Dissector: Adjust Labels and WChar/WString WChar and WString now are more properly handled by both the DCPS Seriliazer and g_convert./Dissector: Serializer on Payload, WChar/WStrings/Dissector: Serializer Refactor: Compiles, but broken/Dissector: Nexted Structs/Dissector: Namespace Resolution and Union Bug Added Sample_Base as a Parent Class to Sample_Field and Sample_Dissector. Sample_Base holds wireshark namespace and field for every context that its child class is used in. Tweaked Array and Sequence Labels and Namespace. For now using ""_e"" (for element) to access an element of the sequence or array. Removed namespace debug messages. Fixed bug in Union length calculation that caused String Key Test to hang on dissection./Dissector: Now working on String Key Test/"
,,0.2681,OpenDDS,"dissector: Fixed Type Support and expert changes Added support for dissection for OpenDDS fixed-point numbers which are converted to doubles for numerical functions. If ACE_CDR::Fixed is missing, a message will be displayed that this is so. Also started marking some packets with a warning instead of marking it as malformed. For example, when an individual field fails for some reason or non essential information is unavailable, like the dissector ITL file./"
,,0.1237,OpenDDS,"Dissector: Refctr SD with RCH (Compiles but broken)/Dissector: corrections/Dissector: Move Field Info into Field_Context Put the Wireshark field struct into Field_Context to be collected after the entire tree has been evaluated. Refactored almost all the code to account for this change, which consists of initializing the protocol tree in two passes. Dissectors now need to be able to be deleted if the first pass fails./dissector: renamed variable that clashed with another/"
,,0.0849,OpenDDS,Javascript support for IDL types: added unions/
,,0.0884,OpenDDS,opendds_idl: set error state for invalid argument/Starting C++11 mapping support in opendds_idl Use (similar to Not done yet: unions bounded string/sequence some details of enums IDL traits disambiguation for multiple arrays/sequences that have the same types/
,,0.1071,OpenDDS,IDL-to-C++11 support in opendds_idl/Starting C++11 mapping support in opendds_idl Use (similar to Not done yet: unions bounded string/sequence some details of enums IDL traits disambiguation for multiple arrays/sequences that have the same types/
,,0.0621,OpenDDS,fixing debug typo/
,,0.0673,OpenDDS,Merge remote-tracking branch origin/master into cmake-pkg/
,,0.107,OpenDDS,More Support for Standalone Unions in opendds_idl Now at the point where a simple example appilcation can be compiled and run./opendds_idl: Make macro blocks neater/opendds_idl: Rename Sample Type Annotation/Infrastructure For Support Also Added
,,0.0991,OpenDDS,More Support for Standalone Unions in opendds_idl Now at the point where a simple example appilcation can be compiled and run./Infrastructure For Support Also Added
,,0.1281,OpenDDS,More Support for Standalone Unions in opendds_idl Now at the point where a simple example appilcation can be compiled and run./Merge branch master into igtd/sample_annotations/opendds_idl: WIP Support on Union Discrim Also add example of key union nested in struct to topic_annotations_test.idl TODO: Add generated code for KeyLessThan in keys_generator and support standalone unions./opendds_idl: Rename Sample Type Annotation/Some fixes but not enough.../Fixed issues with compiling C++11 Messenger IDL; Added export file./Initial IDL-Generator changes migrated from issue-994-cpp11-mapping./
,,0.0681,OpenDDS,Security: Misc Changes/
,,0.0648,OpenDDS,Refactor Hex Data Printing/Security: Misc Changes/
,,0.0865,OpenDDS,Changes for Review/No DCPS_DATA_TYPE Warnings for OpenDDS itself/Refactor Topic Type Code/opendds_idl: Update dcps_data_type warning/Refactored to have the topic\nested situation be more clear. is properly implemented and tested. Default to things being hidden./Temp push for review/Properly using the error logger for throwing errors/Throw an error and fail if we see both a and a
,,0.0776,OpenDDS,No DCPS_DATA_TYPE Warnings for OpenDDS itself/opendds_idl: Misc Fixes/opendds_idl: Update dcps_data_type warning/Modified to throw a warning when DCPS_DATA_TYPE is used/
,,0.0865,OpenDDS,Attempt to Normalize opendds_idl args Rename to Rename to Rename to Add as an alias of Add to Clean up output on opendds_idl Update changed flags in other places in OpenDDS/
,,0.2832,OpenDDS,"Problem: TopicDetails not scoped correctly Solution: Scope it./removing poorly-scaling vendor-specific extension for datareader announcement by adding new vendor-specific extension to participant announcement, indicating that incoming datareader annoucements are not expected to contain associated datawriters. This should allow us to remove datareader announcement of associated writers without breaking backwards compatibility with previous versions of OpenDDS/Problem: Inconsistent topic only discovered with local reader/writer A participant can only get inconconsistent topic when it has a local reader or writer on that topic. While usual, a participant should be able to create a topic and then get inconsistent topic on it without creating readers and writers. This also lead to a race condition in earlier versions of the InconsistentTopic test which made it fail sporadically. Solution: Track local and remote topics and link the local topic to its impl through callbacks so that inconsistent topic can be reported without a reader or writer./Problem: Creating inconsistent topic in same participant succeeds This is only an issue in RTPS. Solution: Check for inconsistent topic when asserting topic with RTPS./Incorporate changes from review/Problem: Create topic fails for multiple participants in same process When using RTPS, multiple participants in different processes can create inconsistent topics. However, when the participants are in the same process, an inconsistent topic cannot be created. Solution: Force all knowledge of topics to the endpoint manager of discovery./Problem: Participants cannot communicate directly when behing NATs Participants that are behind NATs cannot communicate directly. The RtpsRelay solves the problem of enabling communication. However, all of the data transferred between the participants must pass through the relay. This solution provides an optimization where participants can communicate directly after bootstrapping discovery with the RtpsRelay. Solution: Implement ICE for RTPS. ICE involves exchanging candidate information and then performing connectivity checks to determine a pair of candidates that can be used to exchange data. Candidate information is exchange via SPDP; presumably by using the RtpsRelay. ICE is then attempted for SEDP. Similarly, SEDP is used to exchange candidate information for the data transport. ICE is then attempted for the data transports./"
,,0.4203,OpenDDS,"Problem: Participants cannot communicate directly when behing NATs Participants that are behind NATs cannot communicate directly. The RtpsRelay solves the problem of enabling communication. However, all of the data transferred between the participants must pass through the relay. This solution provides an optimization where participants can communicate directly after bootstrapping discovery with the RtpsRelay. Solution: Implement ICE for RTPS. ICE involves exchanging candidate information and then performing connectivity checks to determine a pair of candidates that can be used to exchange data. Candidate information is exchange via SPDP; presumably by using the RtpsRelay. ICE is then attempted for SEDP. Similarly, SEDP is used to exchange candidate information for the data transport. ICE is then attempted for the data transports./"
,,0.4242,OpenDDS,"Problem: Participants cannot communicate directly when behing NATs Participants that are behind NATs cannot communicate directly. The RtpsRelay solves the problem of enabling communication. However, all of the data transferred between the participants must pass through the relay. This solution provides an optimization where participants can communicate directly after bootstrapping discovery with the RtpsRelay. Solution: Implement ICE for RTPS. ICE involves exchanging candidate information and then performing connectivity checks to determine a pair of candidates that can be used to exchange data. Candidate information is exchange via SPDP; presumably by using the RtpsRelay. ICE is then attempted for SEDP. Similarly, SEDP is used to exchange candidate information for the data transport. ICE is then attempted for the data transports./"
,,0.419,OpenDDS,"Problem: Participants cannot communicate directly when behing NATs Participants that are behind NATs cannot communicate directly. The RtpsRelay solves the problem of enabling communication. However, all of the data transferred between the participants must pass through the relay. This solution provides an optimization where participants can communicate directly after bootstrapping discovery with the RtpsRelay. Solution: Implement ICE for RTPS. ICE involves exchanging candidate information and then performing connectivity checks to determine a pair of candidates that can be used to exchange data. Candidate information is exchange via SPDP; presumably by using the RtpsRelay. ICE is then attempted for SEDP. Similarly, SEDP is used to exchange candidate information for the data transport. ICE is then attempted for the data transports./"
,,0.419,OpenDDS,"Problem: Participants cannot communicate directly when behing NATs Participants that are behind NATs cannot communicate directly. The RtpsRelay solves the problem of enabling communication. However, all of the data transferred between the participants must pass through the relay. This solution provides an optimization where participants can communicate directly after bootstrapping discovery with the RtpsRelay. Solution: Implement ICE for RTPS. ICE involves exchanging candidate information and then performing connectivity checks to determine a pair of candidates that can be used to exchange data. Candidate information is exchange via SPDP; presumably by using the RtpsRelay. ICE is then attempted for SEDP. Similarly, SEDP is used to exchange candidate information for the data transport. ICE is then attempted for the data transports./"
,,0.419,OpenDDS,"Problem: Participants cannot communicate directly when behing NATs Participants that are behind NATs cannot communicate directly. The RtpsRelay solves the problem of enabling communication. However, all of the data transferred between the participants must pass through the relay. This solution provides an optimization where participants can communicate directly after bootstrapping discovery with the RtpsRelay. Solution: Implement ICE for RTPS. ICE involves exchanging candidate information and then performing connectivity checks to determine a pair of candidates that can be used to exchange data. Candidate information is exchange via SPDP; presumably by using the RtpsRelay. ICE is then attempted for SEDP. Similarly, SEDP is used to exchange candidate information for the data transport. ICE is then attempted for the data transports./"
,,0.419,OpenDDS,"Problem: Participants cannot communicate directly when behing NATs Participants that are behind NATs cannot communicate directly. The RtpsRelay solves the problem of enabling communication. However, all of the data transferred between the participants must pass through the relay. This solution provides an optimization where participants can communicate directly after bootstrapping discovery with the RtpsRelay. Solution: Implement ICE for RTPS. ICE involves exchanging candidate information and then performing connectivity checks to determine a pair of candidates that can be used to exchange data. Candidate information is exchange via SPDP; presumably by using the RtpsRelay. ICE is then attempted for SEDP. Similarly, SEDP is used to exchange candidate information for the data transport. ICE is then attempted for the data transports./"
,,0.4676,OpenDDS,"removing poorly-scaling vendor-specific extension for datareader announcement by adding new vendor-specific extension to participant announcement, indicating that incoming datareader annoucements are not expected to contain associated datawriters. This should allow us to remove datareader announcement of associated writers without breaking backwards compatibility with previous versions of OpenDDS/Problem: Participants cannot communicate directly when behing NATs Participants that are behind NATs cannot communicate directly. The RtpsRelay solves the problem of enabling communication. However, all of the data transferred between the participants must pass through the relay. This solution provides an optimization where participants can communicate directly after bootstrapping discovery with the RtpsRelay. Solution: Implement ICE for RTPS. ICE involves exchanging candidate information and then performing connectivity checks to determine a pair of candidates that can be used to exchange data. Candidate information is exchange via SPDP; presumably by using the RtpsRelay. ICE is then attempted for SEDP. Similarly, SEDP is used to exchange candidate information for the data transport. ICE is then attempted for the data transports./"
,,0.2002,OpenDDS,"removing poorly-scaling vendor-specific extension for datareader announcement by adding new vendor-specific extension to participant announcement, indicating that incoming datareader annoucements are not expected to contain associated datawriters. This should allow us to remove datareader announcement of associated writers without breaking backwards compatibility with previous versions of OpenDDS/"
,,0.4203,OpenDDS,"Problem: Participants cannot communicate directly when behing NATs Participants that are behind NATs cannot communicate directly. The RtpsRelay solves the problem of enabling communication. However, all of the data transferred between the participants must pass through the relay. This solution provides an optimization where participants can communicate directly after bootstrapping discovery with the RtpsRelay. Solution: Implement ICE for RTPS. ICE involves exchanging candidate information and then performing connectivity checks to determine a pair of candidates that can be used to exchange data. Candidate information is exchange via SPDP; presumably by using the RtpsRelay. ICE is then attempted for SEDP. Similarly, SEDP is used to exchange candidate information for the data transport. ICE is then attempted for the data transports./"
,,0.3693,OpenDDS,"delete_contained_entities hangs when Service Participant thread is interrupted (#1206) An interrupt delievered to the Service Participant thread causes the run_reactor_event_loop function to return with an ""interrupted system call"" error. An attempt to shutdown will notify the now stopped reactor. Since the reactor isnt running, DomainParticipantImpl::handle_exception is never called. Since handle_exception is never called, the condition variable is not released and shutdown hangs. The solution is to block signals in the Service Participant thread (and other threads that are running the reactor event loop). This was already being done in the transport reactor task so it was promoted and similar classes were consolidated./Problem: Participants cannot communicate directly when behing NATs Participants that are behind NATs cannot communicate directly. The RtpsRelay solves the problem of enabling communication. However, all of the data transferred between the participants must pass through the relay. This solution provides an optimization where participants can communicate directly after bootstrapping discovery with the RtpsRelay. Solution: Implement ICE for RTPS. ICE involves exchanging candidate information and then performing connectivity checks to determine a pair of candidates that can be used to exchange data. Candidate information is exchange via SPDP; presumably by using the RtpsRelay. ICE is then attempted for SEDP. Similarly, SEDP is used to exchange candidate information for the data transport. ICE is then attempted for the data transports./"
,,0.419,OpenDDS,"Problem: Participants cannot communicate directly when behing NATs Participants that are behind NATs cannot communicate directly. The RtpsRelay solves the problem of enabling communication. However, all of the data transferred between the participants must pass through the relay. This solution provides an optimization where participants can communicate directly after bootstrapping discovery with the RtpsRelay. Solution: Implement ICE for RTPS. ICE involves exchanging candidate information and then performing connectivity checks to determine a pair of candidates that can be used to exchange data. Candidate information is exchange via SPDP; presumably by using the RtpsRelay. ICE is then attempted for SEDP. Similarly, SEDP is used to exchange candidate information for the data transport. ICE is then attempted for the data transports./"
,,0.3683,OpenDDS,"removing first_acknowledged_by_reader/protect / isolate on_start_callbacks to make transport_assoc_done accurately reflect acknack status for reliable writers, use delayed association inside sedp for durable builtin data, allow heartbeats without final flag and zero last SN to prompt initial acknacks, respond to all non-final heartbeats if they are valid according to the spec/Problem: Builtin topics not updated when inconsistent topic When the logic in SEDP detects an inconsistent topic, it returns before updating the builtin topics. Solution: Continue processing when an inconsistent topic is discovered./Problem: Participants cannot communicate directly when behing NATs Participants that are behind NATs cannot communicate directly. The RtpsRelay solves the problem of enabling communication. However, all of the data transferred between the participants must pass through the relay. This solution provides an optimization where participants can communicate directly after bootstrapping discovery with the RtpsRelay. Solution: Implement ICE for RTPS. ICE involves exchanging candidate information and then performing connectivity checks to determine a pair of candidates that can be used to exchange data. Candidate information is exchange via SPDP; presumably by using the RtpsRelay. ICE is then attempted for SEDP. Similarly, SEDP is used to exchange candidate information for the data transport. ICE is then attempted for the data transports./"
,,0.4216,OpenDDS,"Problem: Participants cannot communicate directly when behing NATs Participants that are behind NATs cannot communicate directly. The RtpsRelay solves the problem of enabling communication. However, all of the data transferred between the participants must pass through the relay. This solution provides an optimization where participants can communicate directly after bootstrapping discovery with the RtpsRelay. Solution: Implement ICE for RTPS. ICE involves exchanging candidate information and then performing connectivity checks to determine a pair of candidates that can be used to exchange data. Candidate information is exchange via SPDP; presumably by using the RtpsRelay. ICE is then attempted for SEDP. Similarly, SEDP is used to exchange candidate information for the data transport. ICE is then attempted for the data transports./"
,,0.3735,OpenDDS,"InfoRepo does not start correctly on Windows InfoRepo has a static initializer which results in the construction of a reactor. This must be preceded by a call to ACE::init(). To fix this, we delay the creation of the reactor to the open method of the ReactorTask./delete_contained_entities hangs when Service Participant thread is interrupted (#1206) An interrupt delievered to the Service Participant thread causes the run_reactor_event_loop function to return with an ""interrupted system call"" error. An attempt to shutdown will notify the now stopped reactor. Since the reactor isnt running, DomainParticipantImpl::handle_exception is never called. Since handle_exception is never called, the condition variable is not released and shutdown hangs. The solution is to block signals in the Service Participant thread (and other threads that are running the reactor event loop). This was already being done in the transport reactor task so it was promoted and similar classes were consolidated./removing poorly-scaling vendor-specific extension for datareader announcement by adding new vendor-specific extension to participant announcement, indicating that incoming datareader annoucements are not expected to contain associated datawriters. This should allow us to remove datareader announcement of associated writers without breaking backwards compatibility with previous versions of OpenDDS/Change type or use static_cast where necessary to address 64-bit build warnings. Additional changes include replacing std::auto_ptr with std::unique_ptr./Problem: Participants cannot communicate directly when behing NATs Participants that are behind NATs cannot communicate directly. The RtpsRelay solves the problem of enabling communication. However, all of the data transferred between the participants must pass through the relay. This solution provides an optimization where participants can communicate directly after bootstrapping discovery with the RtpsRelay. Solution: Implement ICE for RTPS. ICE involves exchanging candidate information and then performing connectivity checks to determine a pair of candidates that can be used to exchange data. Candidate information is exchange via SPDP; presumably by using the RtpsRelay. ICE is then attempted for SEDP. Similarly, SEDP is used to exchange candidate information for the data transport. ICE is then attempted for the data transports./"
,,0.4154,OpenDDS,"Coverity 1481717 and 1481688/Problem: Participants cannot communicate directly when behing NATs Participants that are behind NATs cannot communicate directly. The RtpsRelay solves the problem of enabling communication. However, all of the data transferred between the participants must pass through the relay. This solution provides an optimization where participants can communicate directly after bootstrapping discovery with the RtpsRelay. Solution: Implement ICE for RTPS. ICE involves exchanging candidate information and then performing connectivity checks to determine a pair of candidates that can be used to exchange data. Candidate information is exchange via SPDP; presumably by using the RtpsRelay. ICE is then attempted for SEDP. Similarly, SEDP is used to exchange candidate information for the data transport. ICE is then attempted for the data transports./"
,,0.0763,OpenDDS,Sort Out assert Removed Unsed assert includes Include cassert when defining OPENDDS_ASSERT Replace some uses of ACE or C assert with OPENDDS_ASSERT/
,,0.11900000000000001,OpenDDS,"Amid Implied Keys If there are fields that are marked with and none marked with or then keys can still be implied, but it excludes the fields that are marked with Changes Requested/Replace DCPS_D"
,,0.0639,OpenDDS,opendds_idl: Replace local function with tao_idl one/
,,0.1103,OpenDDS,updating v8 & rapidjson deserialization to correctly support unions with struct / sequence members/updating v8 & rapidjson deserialization to correctly support unions with struct / sequence members/
,,0.1305,OpenDDS,updating v8 & rapidjson deserialization to correctly support unions with struct / sequence members/updating v8 & rapidjson deserialization to correctly support unions with struct / sequence members/
,,0.0556,OpenDDS,ParameterListConverter return types fix/WIP/
,,0.0556,OpenDDS,"add MultiTask for an adjustable timer in the vein of Sporadic/PeriodicTask, update SPDPs send_listener_ and RTPSs heartbeat_ to use it/"
,,0.0645,pljava,Added missing FlushErrorState after CopyError/Added BlobValue coersion to the bytea type./Fix for bug
,,0.1067,pljava,More forgiving getXXX methods on ResultSet with respect to types. Made use of Oid more strict. The Oid class is used instead of int. Moved TypeMap functionality into the Oid class./Changes needed for PostgreSQL 8.1.x/Added getOid method (needed for ResultSetMetaData)/
,,0.0884,pljava,Added column jarManifest to sqlj.jar_repository and logic that makes sure the manifest ends up there when a jar is installed or replaced./Working draft of scalar UDTs/Fixed bug Jar owner in the sqlj.jar_repository table changed type from oid to name./
,,0.0758,pljava,Fixed bug Jar owner in the sqlj.jar_repository table changed type from oid to name./
,,0.0609,pljava,Added boolean array type/
,,0.0772,pljava,Rewrite of the type mapping system/
,,0.1502,pljava,"Check for base UDT if no other type mapping found. Addresses issue The strategy of registering base UDTs on the first call to their input/output/send/recv functions breaks down if the first reference in a session to such a type is one that doesnt involve calling those functions (for example, an existing table has a column of that type, and a query wants to pass it to a Java function accepting that type; PostgreSQL has no reason to think it should call an I/O function in that case). This change adds one more step to the rules in Type_fromOid. If no previous step succeeded, and just before punting to String, take a close look at the type to see if it could be a Base UDT. Thats a tedious check that involves following the types input/ output/receive/send Oids via prolang back to their language Oids, and (one could stop here by assuming the language will always be named java or javaU, but if not) from there to the languages call handler C function and its dynamic library path, which should match PL/Javas. A future optimization could cache language Oids that are found to refer to PL/Java, but it might not be needed often enough to matter./Make DEBUG1 quieter. Move a bunch of DEBUG1s to DEBUG2, leaving DEBUG1 for the initial load message that identifies PL/Java and JVM versions. (This is NOTICE if PL/Java is explicitly LOADed, so its seen by default, but in other cases you can now see it by enabling DEBUG1, and not mixed in with a lot of other stuff.)/"
,,0.0534,realm-java,Updated tutorial/
,,0.1365,realm-java,"Introduced separate model for the tests (issue "".generated"" suffix in generated sources packages (issue (joined) base for table and view tests./"
,,0.1152,realm-java,"Added tests and examples for the ""average"" method (issue separate model for the tests (issue "".generated"" suffix in generated sources packages (issue (joined) base for table and view tests./Resolved a compilation error./Various changes in relation to building on Linux/"
,,0.1384,realm-java,"Introduced separate model for the tests (issue "".generated"" suffix in generated sources packages (issue (joined) base for table and view tests./"
,,0.1119,realm-java,"Disabled a few unit tests that were failing for known reasons/Added tests and examples for the ""average"" method (issue separate model for the tests (issue "".generated"" suffix in generated sources packages (issue (joined) base for table and view tests./"
,,0.138,realm-java,"Introduced separate model for the tests completed (issue separate model for the tests (issue "".generated"" suffix in generated sources packages (issue (joined) base for table and view tests./"
,,0.1296,realm-java,"Enable some tests. released dll for B13/Added TableBase::nativeToJson() currently disabled in JNI/Removed limit parameter in aggregate methods. Added TableBase::average(). Added index checks in TableQuery(). Compiles to relative h-files/Enabled some unit tests they work now./Introduced separate model for the tests (issue "".generated"" suffix in generated sources packages (issue the query-based statistics with high-level methods (#53)./Refactored (joined) base for table and view tests./Covered the case-sensitive query methods./"
,,0.1403,realm-java,"Introduced separate model for the tests (issue "".generated"" suffix in generated sources packages (issue (joined) base for table and view tests./"
,,0.1582,realm-java,"Added wrapper and tests for mixed type retrieval method (issue separate model for the tests (issue "".generated"" suffix in generated sources packages (issue column operations tests to exercise the view columns, too./Refactored (joined) base for table and view tests./"
,,0.0825,realm-java,"Improved (and fixed) the ""field sorting"" mechanism./Improved field sorter to support multiple source folders (issue from errors to warnings for non-critical problems(issue"
,,0.1204,realm-java,Fix for: Order of items in enum ColumnType updated to mach recent changes in the core library/Order of items in enum ColumnType updated to mach recent changes in the core library/
,,0.0972,realm-java,"float: updated floats sum, average to return double instead of float./WIP: Updated with float, double support. Still a crash./"
,,0.147,realm-java,"String conversion in both directions is complete except for an important FIXME in to_jstring() in util.h/String conversion from C++ to Java done, opposite order remains/Tracking changes in core library: Renaming of column type enumeration/float: updated floats sum, average to return double instead of float./WIP: Updated with float, double support. Still a crash./"
,,0.0588,realm-java,REnamed Group::getTableCount() to size()/
,,0.12300000000000001,realm-java,Merge remote-tracking branch nikuco/master Conflicts: tightdb-java-core/src/main/java/com/tightdb/typed/TableCursorColumn.java Set on typed tables does not yet fully support subtables (can only set to null)/
,,0.0879,realm-java,Supported float and double types in code generator and typed API./
,,0.11199999999999999,realm-java,"Added experimental method to Table: findSortedLong(). NOTICE it does not return if the value was actually found or not you have to check that through a get() afterwards for now./float: updated floats sum, average to return double instead of float./WIP: Updated with float, double support. Still a crash./"
,,0.0891,realm-java,Added experimental method to Table: findSortedLong(). NOTICE it does not return if the value was actually found or not you have to check that through a get() afterwards for now./Added experimental method: table.moveLastOver() method/Supported float and double types in code generator and typed API./
,,0.073,realm-java,"WIP: Updated with float, double support. Still a crash./"
,,0.0902,realm-java,"Added Table::addColumn(), renameColumn(), removeColumn()/Added testcases for Mixed float and double/WIP: Updated with float, double support. Still a crash./"
,,0.0818,realm-java,Supported float and double types in code generator and typed API./
,,0.2022,realm-java,"support new Query.find() method/Table.close() now private (added private_debug_close() instead. Added better support for detecting valid View and Query after close of table. Still not completely tested, also missing core-support./Added last validity checks in Query./Added column type check/"
,,0.0784,realm-java,Added test cases for all Exceptions that native interface can throw./
,,0.31,realm-java,"debugging datebug fixed one/Renamed to reflect c++ renames/Fixed merge bug./Added TableDefinition, to allow dynamic operations on subtable columns/Exception handling for Table (not tested)/Table.close() now private (added private_debug_close() instead. Added better support for detecting valid View and Query after close of table. Still not completely tested, also missing core-support./Added ref-doc of *to_string(). Added TableView.rowToString()/+ Added Table.toString(), Table.toString(maxRows) + Added TableView.toString(), TableView.toString(maxRows), + Added Mixed.getReadableValue() + Remove TightDB.print methods Lacking update of ref-doc/Added column type check/Updates due to changes in core library: Table::is_valid() Table::is_attached()/Added parameter checks to all Table methods. (lacking testcases) Changed Exception for invalid Table form IllegalArgumentException to InvalidStateException./"
,,0.336,realm-java,"Renamed to reflect c++ renames/Added column information methods to views/Added exception handling to TableView (no tests)/Table.close() now private (added private_debug_close() instead. Added better support for detecting valid View and Query after close of table. Still not completely tested, also missing core-support./Added ref-doc of *to_string(). Added TableView.rowToString()/+ Added Table.toString(), Table.toString(maxRows) + Added TableView.toString(), TableView.toString(maxRows), + Added Mixed.getReadableValue() + Remove TightDB.print methods Lacking update of ref-doc/Added column type check/Added parameter checks in tableview./"
,,0.2228,realm-java,"Added exception handling for Group (untested)/Table.close() now private (added private_debug_close() instead. Added better support for detecting valid View and Query after close of table. Still not completely tested, also missing core-support./Added column type check/Updates due to changes in core library: Table::is_valid() Table::is_attached()/Added parameter checks in tableview./Added parameter checks to all Table methods. (lacking testcases) Changed Exception for invalid Table form IllegalArgumentException to InvalidStateException./"
,,0.1574,realm-java,"resolved clonflict when merging from brians code/Updated test of TableView and Query close() test. + other minor updates/Table.close() now private (added private_debug_close() instead. Added better support for detecting valid View and Query after close of table. Still not completely tested, also missing core-support./hack for renaming/"
,,0.1882,realm-java,"test case added/test case column name in subtables/Fixed type errors/Added TableDefinition, to allow dynamic operations on subtable columns/Table.close() now private (added private_debug_close() instead. Added better support for detecting valid View and Query after close of table. Still not completely tested, also missing core-support./"
,,0.1101,realm-java,Changed syntax for Typed Rows. now only traditional getters & setters are allowed/
,,0.1155,realm-java,Query on views/support new Query.find() method/Test for thrown exception in queri on wrong column types/More comprehensive tests for Aggregates on a Query/
,,0.0645,realm-java,BREAKING CHANGE: Column type enum have been renamed. Is now less verbose and more java like e.g. ColumnType.ColumnTypeString is now ColumnType.STRING etc/
,,0.066,realm-java,Added findFrom() method to typed query/
,,0.0597,realm-java,Added addEmptyRow() method to typed table/
,,0.066,realm-java,Outcommented lookup in table and tableview/
,,0.146,realm-java,renamed exception/add exception. Throw it when wrong type is acessed from Mixed type/
,,0.1042,realm-java,Changed syntax for Typed Rows. now only traditional getters & setters are allowed/
,,0.0945,realm-java,added no exception note/added jni bridge to getColumnIndex/simple pivot on TableView/
,,0.0823,realm-java,Renamed some aggregating methods in Table and TableView (averageInt() to averageLong() etc. )/
,,0.1362,realm-java,"Modified code generation to use static column indices. Since the Java VM keeps the fields in a different order than the java compiler, I had to introduce proxy based table generation. removed setter/getter method for row no RealmObject. row is now accessed directly. Proxy class suffix has been changed to _PROXY* has been changed to RealmProxy./performance test runs without fail./"
,,0.1362,realm-java,"New code generation is ""working"". Stills needs to fix the column indices./Modified code generation to use static column indices. Since the Java VM keeps the fields in a different order than the java compiler, I had to introduce proxy based table generation. removed setter/getter method for row no RealmObject. row is now accessed directly. Proxy class suffix has been changed to _PROXY* has been changed to RealmProxy./Cleanup and extra test conditions in performanceTest. Maintain realmRowIndex./performance test runs without fail./"
,,0.2798,realm-java,"Refactored json methods to support standalone objects. Added stub methods + begun work on unit tests./Added copyToRealmOrUpdate method./RealmObject.toString() method now uses isValid()/Add test for empty model classes/Better handling of empty model classes in the code generator/copyToRealm method implemented + unit tests. Style fixes to unit tests./Import only minimum number of packages./copyToRealm method added to proxy classes./Using getGenericType() is not always a good idea./Import statements must be in alphabetic order. Using getGenericType to simplify code./Only import required classes in the proxy classes in order to avoid ambiguous references./Update RealmProxyClassGenerator.java Setting relationship to null throws NullPointerException, because setter method does not exit where it should, trying to access null value instead./PR comment fixes: Cleanup example, method comments has been made better. Regexp for checking date syntax./Fixed annotation processor unit test./Fixed bug in RealmObject.equals()/Remove rowIndex from RealmObject.toString()/Mitigate the file size growing problem This change does the following: * disables the caching of Realm instances in threads without an event loop * makes the Realm class implement Closable * does reference counting for closing Realm instances * checks if the Realm instance has not been closed before any operation/More consistent toString output./toString, equals and hashcode now work properly with cyclic model structures. Refactored proxy class generator to be more readable./Cleanup + fixed merge mistake./Merge branch master into cm-primary-keys Conflicts: changelog.txt realm-annotations-processor/src/main/java/io/realm/processor/RealmProcessor.java realm-annotations-processor/src/main/java/io/realm/processor/RealmProxyClassGenerator.java settings.gradle/Preliminary support for primary keys in the binding + Unit tests./Adding thread check on RealmObject. Refactoring unit tests. Updating changelog./"
,,0.0716,realm-java,Renamed ConcurrencyExample to ServiceExample. Added threadExample to distribution examples./
,,0.0737,realm-java,Renamed ConcurrencyExample to ServiceExample. Added threadExample to distribution examples./
,,0.0716,realm-java,Renamed ConcurrencyExample to ServiceExample. Added threadExample to distribution examples./
,,0.0737,realm-java,Renamed ConcurrencyExample to ServiceExample. Added threadExample to distribution examples./
,,0.0716,realm-java,Renamed ConcurrencyExample to ServiceExample. Added threadExample to distribution examples./
,,0.0759,realm-java,Renamed ConcurrencyExample to ServiceExample. Added threadExample to distribution examples./
,,0.0887,realm-java,Moving checks to C++./Optimizing Realm.allObjectSorted() and refactoring for code reuse./Using variadic macros instead./Using to_jstring for better conversion between core and java strings./
,,0.182,realm-java,"Moving checks to C++./Changing signatures of Realm.allObjects(), RealmQuery.findAll(), and RealmResults.sort()./Realm.allObjects(), RealmResults.sort() and RealmQuery.findAll() extended with multi-field sorting./Move sync_if_needed() to macro/Iterating a RealmResult now correctly identifies any changes to the underlying query result./Use to_jstring() everywhere at the JNI layer./"
,,0.0948,realm-java,Moved error checking to JNI./Adding where() to RealmList/Adding where() to RealmList/
,,0.0926,realm-java,"Added missing header file update./Update encryption functionality for the latest core changes/Revert ""Revert ""Merge pull request from realm/kg-core-0.87.0"""" This reverts commit 6be8edca486f53273f28553584d28bc17c5a0ddf./"
,,0.10400000000000001,realm-java,"Realm.allObjects(), RealmResults.sort() and RealmQuery.findAll() extended with multi-field sorting./Added test for sorting by child properties./Modify the unit tests to comply to Realm.close()/Sort with characters/maxDate was not correct./"
,,0.0833,realm-java,bug fixed and test added/Support for case sensitive searches in equalTo and notEqualTo/
,,0.2556,realm-java,Adding copyOrUpdate(iterable) + unit test./Refactored json methods to support standalone objects. Added stub methods + begun work on unit tests./minor fix to error message/Fail when instantiating a Realm with the wrong key/Throw an exception if deleting an open Realm file/Error handling now uses exception thrown from core where it makes sense./Added check for read only files./Better error reporting for error cases when creating a Realm using the File constructors./Added support for executing transactions in a closure./copyToRealm method implemented + unit tests. Style fixes to unit tests./Removed some code/Fixed bug in equalTo() for date. Updated testcases/Rename compacting related methods/Change writeCopy signature and improve tests/Using the transaction (Group) to write a copy/Added unit test for testing all unicode chars./Fix RealmTest for Realm.close()/Add a unit test for reference counting/using RealmQuery boolean/broke long lines/test contains in query/Catching null pointer in queries with wrong field/Updated and fixed test/Made separate model for non latin field names/Guarding JStringAccessor in a try block./Removed some text in asserts/Non latin column name and tests/updated/Fixed Realm cache not working./Updates due to PR feedback/
,,0.1184,realm-java,"Fix merge mistake + style fixes./Fixed broken unit tests in RealmAnnotationsTest./It is no longer possible to set the primary key to a column that already contains duplicate values./It is no longer possible to manually set 0 or """" in primary key fields. Refactored error checking so it is more maintainable./Primary keys are now indexed. Refactored Table/Row for missing cases + cleaner code. Additional unit tests./Preliminary support for primary keys in the binding + Unit tests./"
,,0.212,realm-java,"Refactored json methods to support standalone objects. Added stub methods + begun work on unit tests./Added unit tests for RealmList. Throw better errors if not used correctly./Added managed/non-managed mode to RealmList + a no arg constructor./Added checks to RealmList.move() + added unit tests./More consistent toString output./toString, equals and hashcode now work properly with cyclic model structures. Refactored proxy class generator to be more readable./Adding where() to RealmList/"
,,0.2027,realm-java,Remove deprecated sorting methods/Rename the sorting find methods and deprecate the old ones/Rename internal parameter to a better name./Fix subquery scope not working properly./Fixed bug when querying a RealmList. Added unit test. Improved error message for wrong query types./Adding sort functionality to findAll()./Update due to PR feedback/Catching null pointer in queries with wrong field/Adding where() to RealmList/
,,0.2568,realm-java,Refactored json methods to support standalone objects. Added stub methods + begun work on unit tests./Remove deprecated sorting methods/Added tests for reading iOS realms. Added option for custom schemas./Added copyToRealmOrUpdate method./Throw an exception if deleting an open Realm file/Added check for read only files./Better error reporting for error cases when creating a Realm using the File constructors./Call to close() replaced by warning in Realm finalizer./Optimized getHandler() method./Thread handler no longer gets removed too soon./Using id to compare Realms will also support in-memory Realms./Fixed reference counting bug./Added support for executing transactions in a closure./copyToRealm method implemented + unit tests. Style fixes to unit tests./copyToRealm method added to proxy classes./Handlers are now properly removed when a Realm is closed./Allow to add/remove RealmChangeListeners in RealmChangeListeners We create a defensive copy of the list before iterating it/Moved methods/Make the reference counter depend on the realm path/Only commit if needed during instantiation and re-enable caching/Mitigate the file size growing problem This change does the following: * disables the caching of Realm instances in threads without an event loop * makes the Realm class implement Closable * does reference counting for closing Realm instances * checks if the Realm instance has not been closed before any operation/Fixed Realm cache not working./Fixed build warnings + Realm cache lookup./Updates due to PR feedback/Adding distinct() to Realm/Adding thread check on RealmObject. Refactoring unit tests. Updating changelog./
,,0.2976,realm-java,Adds RealmPath to RealmMigrationNeedException/Reverted getCanonicalPath to getPath/Fixed annotation processor unit tests./Fixed annotation processor unit test./copyToRealm now correctly handles nested objects already part of the Realm./Proxy classes now uses constants for column indexes for getters/setters./Column indices moved to proxy classes to minimise number of lookups./Updated annotation processor unit tests./Encapsulates columnIndicies in its own class. The internal map now uses Class as key instead of Strings/Fixed annotation processor unit tests./Fix annotation-processor unit tests./Fixed annotation processor unit test./Fixed annotation processor unit tests./
,,0.2766,realm-java,Update BooleansRealmProxy.java/Adds RealmPath to RealmMigrationNeedException/Reverted getCanonicalPath to getPath/Fixed annotation processor unit tests./Fixed annotation processor unit test./copyToRealm now correctly handles nested objects already part of the Realm./Proxy classes now uses constants for column indexes for getters/setters./Column indices moved to proxy classes to minimise number of lookups./Updated annotation processor unit tests./Encapsulates columnIndicies in its own class. The internal map now uses Class as key instead of Strings/Fix annotation-processor unit tests./Fixed annotation processor unit test./Fixed annotation processor unit tests./
,,0.3585,realm-java,Adds RealmPath to RealmMigrationNeedException/Reverted getCanonicalPath to getPath/Using copyToRealmOrUpdate with a Null primary key now throws a proper exception instead of crashing./Fixing expected output/Renaming hasIndex() to hasSearchIndex() and setIndex() to addSearchIndex()./Fixed annotation processor unit tests./Fixed annotation processor unit test./copyToRealm now correctly handles nested objects already part of the Realm./validateTable now also verifies that primary key and index is set correctly./Proxy classes now uses constants for column indexes for getters/setters./Column indices moved to proxy classes to minimise number of lookups./Updated annotation processor unit tests./Encapsulates columnIndicies in its own class. The internal map now uses Class as key instead of Strings/Fixed annotation processor unit tests./Added RealmObject and RealmList to annotation processor all types unit test./Fix annotation-processor unit tests./Fixed annotation processor unit test./Fixed annotation processor unit tests./
,,0.3641,realm-java,Adds RealmPath to RealmMigrationNeedException/Reverted getCanonicalPath to getPath/Using copyToRealmOrUpdate with a Null primary key now throws a proper exception instead of crashing./Renaming hasIndex() to hasSearchIndex() and setIndex() to addSearchIndex()./Fix wrong String comparison/Merge branch master into cm-realm-modules Conflicts: realm/src/main/java/io/realm/Realm.java/Jason streams now only update fields actually present./copyToRealm now correctly handles nested objects already part of the Realm./validateTable now also verifies that primary key and index is set correctly./Merge branch master into cm-realm-modules Conflicts: realm-annotations-processor/src/main/java/io/realm/processor/RealmJSonImplGenerator.java realm-annotations-processor/src/main/java/io/realm/processor/RealmProcessor.java realm-annotations-processor/src/main/java/io/realm/processor/RealmProxyClassGenerator.java realm-annotations-processor/src/main/java/io/realm/processor/RealmValidationListGenerator.java realm/src/main/java/io/realm/Realm.java/Proxy classes now uses constants for column indexes for getters/setters./Column indices moved to proxy classes to minimise number of lookups./Added support for RealmModules + Reintroduced RealmProxyMediator/Encapsulates columnIndicies in its own class. The internal map now uses Class as key instead of Strings/Refactored RealmProcessor to make it easier to add changes./Fixed issues with object references in copy/update methods./Fix merge mistake./Merge branch master into cm-cyclic-copy Conflicts: changelog.txt realm-annotations-processor/src/main/java/io/realm/processor/RealmProxyClassGenerator.java realm-annotations-processor/src/test/resources/io/realm/AllTypesRealmProxy.java realm-annotations-processor/src/test/resources/io/realm/BooleansRealmProxy.java realm-annotations-processor/src/test/resources/io/realm/SimpleRealmProxy.java realm/src/androidTest/java/io/realm/RealmTest.java/Only lookup in hash map once. Fixed generics./Cyclic data structures no longer crash copyToRealm/Donít use String.join() since itís Java8 only/Now properly propagates update or copy flag + fixed unit tests./
,,0.1087,realm-java,Primary key table migration added./Adding Table.unsetIndex() to remove search index./Annotation processor now fails if a RealmObject contains no fields./Changing formatting to support both 32 and 64 bit systems when logging./Moved setPrimaryKey to JNI./
,,0.0987,realm-java,Moving parameter checking to C++. Adding tracing to LinkView and Row C++ methods./
,,0.0891,realm-java,Realm Core has change namespace from tightdb to realm./Fixed unit test./Adding RealmQuery.isNull() and RealmQuery.isNotNull()./
,,0.0859,realm-java,Added compact() method from core also for encrypted Realms./
,,0.1082,realm-java,Renaming hasIndex() to hasSearchIndex() and setIndex() to addSearchIndex()./validateTable now also verifies that primary key and index is set correctly./
,,0.0737,realm-java,Jason streams now only update fields actually present./Added unit tests./
,,0.1353,realm-java,Disable breaking unit test./copyToRealm now correctly handles nested objects already part of the Realm./Potential tmp fix for unit test./Realms are now only cached if correctly opened./Add a couple of unit tests/Fixed unit test./Added compact() method from core also for encrypted Realms./Properly check for key equality while using a cached Realm instance/Removed warnings./
,,0.1557,realm-java,Remove columnIndices getter./Merge branch master into cm-bug-migration Conflicts: realm-annotations-processor/src/main/java/io/realm/processor/RealmProxyClassGenerator.java realm-annotations-processor/src/test/resources/io/realm/AllTypesRealmProxy.java realm-annotations-processor/src/test/resources/io/realm/BooleansRealmProxy.java realm-annotations-processor/src/test/resources/io/realm/SimpleRealmProxy.java realm/src/main/java/io/realm/Realm.java realm/src/main/java/io/realm/RealmQuery.java/
,,0.2398,realm-java,"Merge branch master into cm-realm-modules Conflicts: realm-annotations-processor/src/main/java/io/realm/processor/RealmProxyClassGenerator.java realm-annotations-processor/src/test/resources/io/realm/AllTypesRealmProxy.java/Use canonicalPath instead of absolutePath/Realm IDs are now strings to avoid hash collisions./Compacting encrypted Realms fail on some devices, and it is disabled temporarily./Merge branch master into cm-realm-modules Conflicts: realm/src/main/java/io/realm/Realm.java/ColumnIndices are now cached pr. Realm instead of globally./Cleaned up the API. Updated documentation./Merge branch master into cm-column-indicies Conflicts: realm/src/main/java/io/realm/Realm.java/Added test cases for RealmConfiguration + minor refactoring./Streamline new constructors and deprecate old constructors + other utility methods that now uses RealmConfiguration./Added compact() method from core also for encrypted Realms./Column indices moved to proxy classes to minimise number of lookups./Added support for RealmModules + Reintroduced RealmProxyMediator/Cyclic data structures no longer crash copyToRealm/Removed warnings./"
,,0.1427,realm-java,"Handle null value for String in Json when updating Fix Update the objects String field to empty string when the corresponding field in Json is null./add support for findFirst & findAllSorted*, update UnitTests/Readdded AllTypesRealmProxy unit test./Updates due to PR feedback/Merge branch master of github.com:realm/realm-java into kg-bug-migrate-linkview/Tighter check on table validation involving RealmList<> fields./"
,,0.1722,realm-java,"Handle null value for String in Json when updating Fix Update the objects String field to empty string when the corresponding field in Json is null./Support search indexing for column int, bool, date 1. Enable the search index annotation on byte, short, int, long, boolean, and Date. 2. Enable add/remove search index in java. 3. Annotation processor test to support better detailed test cases. 4. Modify JNI test cases. 5. Update doc. 6. Add AnnotationIndexTypes to avoid polluting other test cases. This is the first PR for Implicit index to int primary keys will be handled in another PR./add support for findFirst & findAllSorted*, update UnitTests/Add support for Findbugs and fix the issues found/Better error messages/Updates due to PR feedback/Tighter check on table validation involving RealmList<> fields./"
,,0.1737,realm-java,Handle null value for String in Json when updating Fix Update the objects String field to empty string when the corresponding field in Json is null./Add analytics on annotation/Add check on fields of type RealmList/
,,0.0599,realm-java,Updated examples with RealmConfiguration/
,,0.0813,realm-java,Split row into checked and unchecked variant./
,,0.0744,realm-java,Realm will now throw a RealmError when Realm Core enters an unrecoverable error condition./
,,0.1538,realm-java,"using std::unique_ptr for handover + remove unnecessary begin_read in a spearate JNI call + latest fixes from fsa_handover_demo (untyped query etc.)/Changing logic to handover the query from caller to background thread, handle different failure points (begin_read, import_handover), update UnitTests/Support UnreachableVersionException from Core/"
,,0.1138,realm-java,LinkView mutable methods now correctly require a write transaction + added unit tests for all mutable public methods./
,,0.11199999999999999,realm-java,LinkView mutable methods now correctly require a write transaction + added unit tests for all mutable public methods./
,,0.0813,realm-java,Split row into checked and unchecked variant./
,,0.0987,realm-java,"Added a check for null values in io.realm.internal.Table.findFirst{String,Date}()./"
,,0.087,realm-java,"add support for findFirst & findAllSorted*, update UnitTests/"
,,0.0887,realm-java,PR comment fixes./Split row into checked and unchecked variant./
,,0.1338,realm-java,"add support for findFirst & findAllSorted*, update UnitTests/Changing logic to handover the query from caller to background thread, handle different failure points (begin_read, import_handover), update UnitTests/update PR as per feedback/POC async query, using Core fsa_handover_demo branch/"
,,0.1701,realm-java,"Removed deprecated methods from Realm. Bumped dev version to 0.83.0/add support for findFirst & findAllSorted*, update UnitTests/add retry policy + concurrency tests + perf improvement to the query/Split row into checked and unchecked variant./POC async query, using Core fsa_handover_demo branch/RealmConfiguration now used as cache key/Do remove the RealmChangeListener weak reference Weak references on a same object are not same./Merge branch master into cm-configuration-builder Conflicts: realm/src/main/java/io/realm/Realm.java/Fix a memory leak in RealmBaseAdapter Fixes We now use WeakReferences to store the change listeners. This allows the Garbage Collector to clean up the adapters./"
,,0.3397,realm-java,"Suppress useless cast and raw type warnings in generated proxy classes. This warnings are reported when `-Xlint:all` is added to the compilar args. Example configuration of `build.gradle` is: ``` allprojects { gradle.projectsEvaluated { tasks.withType(JavaCompile) { options.compilerArgs options.compilerArgs } } } ```/reorder parameters of ColumnInfo class/fix for Problem: The Proxy class of each model holds column indices in static fields. These indices are good only when all Realm databases have the same column index in every column of the model class. If Realm databases have different column indices, the getter/setter of Proxy class reads/writes wrong column. Solution: This commit introduces `ColumnInfo` object that holds column indices information per Realm instance which shares the same database file./Added missing thread confinement checks/Reference equality for empty RealmLists, fix Async tests/fix javadoc, revert getByIndex to Realm.get, remove ArgumentsHolder fron public package/Add Nullable suport * Add boxed type support. * Add annotation. * isNull and isNotNull support all nullable types now. * equalTo query can take null as input param for nullable fields. * Add functions for nullable related migration. * JSON converter behavior changes for null value. * Update test cases./update branch as per PR feedback/Milestone 2: findAllAsync & findFirst working with retries sratetgies/"
,,0.3396,realm-java,"Suppress useless cast and raw type warnings in generated proxy classes. This warnings are reported when `-Xlint:all` is added to the compilar args. Example configuration of `build.gradle` is: ``` allprojects { gradle.projectsEvaluated { tasks.withType(JavaCompile) { options.compilerArgs options.compilerArgs } } } ```/reorder parameters of ColumnInfo class/fix for Problem: The Proxy class of each model holds column indices in static fields. These indices are good only when all Realm databases have the same column index in every column of the model class. If Realm databases have different column indices, the getter/setter of Proxy class reads/writes wrong column. Solution: This commit introduces `ColumnInfo` object that holds column indices information per Realm instance which shares the same database file./Added missing thread confinement checks/Reference equality for empty RealmLists, fix Async tests/typo, fix style, & remove layout header for threadExample/fix javadoc, revert getByIndex to Realm.get, remove ArgumentsHolder fron public package/Add Nullable suport * Add boxed type support. * Add annotation. * isNull and isNotNull support all nullable types now. * equalTo query can take null as input param for nullable fields. * Add functions for nullable related migration. * JSON converter behavior changes for null value. * Update test cases./update branch as per PR feedback/Milestone 2: findAllAsync & findFirst working with retries sratetgies/"
,,0.1737,realm-java,Add Nullable suport * Add boxed type support. * Add annotation. * isNull and isNotNull support all nullable types now. * equalTo query can take null as input param for nullable fields. * Add functions for nullable related migration. * JSON converter behavior changes for null value. * Update test cases./
,,0.2272,realm-java,Primary keys now compatible with primary keys from the Object Store/Adding Realm.distinct() method. Closes Nullable suport * Add boxed type support. * Add annotation. * isNull and isNotNull support all nullable types now. * equalTo query can take null as input param for nullable fields. * Add functions for nullable related migration. * JSON converter behavior changes for null value. * Update test cases./Milestone 2: findAllAsync & findFirst working with retries sratetgies/
,,0.1631,realm-java,Add Nullable suport * Add boxed type support. * Add annotation. * isNull and isNotNull support all nullable types now. * equalTo query can take null as input param for nullable fields. * Add functions for nullable related migration. * JSON converter behavior changes for null value. * Update test cases./
,,0.0865,realm-java,Milestone 2: findAllAsync & findFirst working with retries sratetgies/
,,0.1299,realm-java,"Added missing thread confinement checks/Add Realm.isInWriteTransaction() to indicate if it is in a write transaction. See also: Closes equality for empty RealmLists, fix Async tests/update branch as per PR feedback/add fix for are now only validated once across threads./"
,,0.1532,realm-java,Add Nullable suport * Add boxed type support. * Add annotation. * isNull and isNotNull support all nullable types now. * equalTo query can take null as input param for nullable fields. * Add functions for nullable related migration. * JSON converter behavior changes for null value. * Update test cases./Simply unit test/Unit test to expose timeout in finalizer/
,,0.0717,realm-java,Merge remote-tracking branch origin/master into nh-async-query/update branch as per PR feedback/
,,0.1762,realm-java,now throwing Exception if we try to add/remove listener for unmanaged RealmObject/RealmResults/update as per round 2 feedback/Milestone 4: before merging origin/master/Milestone 2: findAllAsync & findFirst working with retries sratetgies/
,,0.2473,realm-java,"Add Nullable suport * Add boxed type support. * Add annotation. * isNull and isNotNull support all nullable types now. * equalTo query can take null as input param for nullable fields. * Add functions for nullable related migration. * JSON converter behavior changes for null value. * Update test cases./Merge branch master into nh-async-query Conflicts: realm/src/androidTest/java/io/realm/NotificationsTest.java realm/src/main/java/io/realm/Realm.java realm/src/main/java/io/realm/internal/SharedGroup.java/Milestone 4: before merging origin/master/Milestone 3: findAllSorted, findFirst & asyncTransaction working/Milestone 2: findAllAsync & findFirst working with retries sratetgies/Milesonte1/"
,,0.2301,realm-java,"fix for Problem: The Proxy class of each model holds column indices in static fields. These indices are good only when all Realm databases have the same column index in every column of the model class. If Realm databases have different column indices, the getter/setter of Proxy class reads/writes wrong column. Solution: This commit introduces `ColumnInfo` object that holds column indices information per Realm instance which shares the same database file./change the return type of RealmProxyMediator#getModelClasses() to Set in order to guarantee its contents unordered and unique./Added fix for column indices/Introduced RealmBase and SharedGroupManager/fix for 4: before merging origin/master/Removed ConcurrentSet/Fixed unit tests./Use Set instead of Map/Schemas are now only validated once across threads./"
,,0.0686,realm-java,New Migration and Dynamic API. New Sort/Case enums. New RealmCache/
,,0.2229,realm-java,More fixes for the AP/Fix the AP unit tests/Fix the unit tests of the annotations processor. Also remove one unit test which makes no sense now that users can write model classes in any way they like./update unit tests for annotation-processor/Added Realm.copyFromRealm()/Realm.createOrUpdateObjectFromJson() now works correctly if the RealmObject class contains a primary key/New Migration and Dynamic API. New Sort/Case enums. New RealmCache/Add a same origin check/fix typo/Now setters for RealmObject and RealmList have a check if the value is a valid object or not (#1749)./
,,0.1719,realm-java,More fixes for the AP/Fix the AP unit tests/Fix the unit tests of the annotations processor. Also remove one unit test which makes no sense now that users can write model classes in any way they like./update unit tests for annotation-processor/Added Realm.copyFromRealm()/New Migration and Dynamic API. New Sort/Case enums. New RealmCache/Add a same origin check/Now setters for RealmObject and RealmList have a check if the value is a valid object or not (#1749)./
,,0.1082,realm-java,Disallow transient and volatile fields/Disallow final fields/
,,0.2183,realm-java,Remove reflection from the generated proxy code./Make the examples build again/Added Realm.copyFromRealm()/Realm.createOrUpdateObjectFromJson() now works correctly if the RealmObject class contains a primary key/New Migration and Dynamic API. New Sort/Case enums. New RealmCache/Add a same origin check/fix typo/Now setters for RealmObject and RealmList have a check if the value is a valid object or not (#1749)./
,,0.1757,realm-java,Remove reflection from the generated proxy code./Disallow transient and volatile fields/Disallow final fields/Donít override equals/hashCode/toString if already implemented/Fix support for ignored fields/First working version. TODO: * Make the kotlin example work with the plugin (and re-enable it in the settings.grade file) * Make the plugin make sure itís applied after the android plugin (app or library) * Modify the model classes in the unit tests of the realm-library project * Write unit tests for the Gradle plugin/New Migration and Dynamic API. New Sort/Case enums. New RealmCache/
,,0.0792,realm-java,Add support for detached objects/New Migration and Dynamic API. New Sort/Case enums. New RealmCache/
,,0.1689,realm-java,"Access to RealmResults based on deleted RealmList * When the original RealmList is deleted, for most methods of RealmResults should just work without crash by just treat it like an empty RealmResults. * RealmResults.where() throws IllegalStateExecption in this case. * RealmResults.isValid() returns false in this case. This is a temp fix, check for more details. Close"
,,0.0686,realm-java,New Migration and Dynamic API. New Sort/Case enums. New RealmCache/
,,0.0686,realm-java,New Migration and Dynamic API. New Sort/Case enums. New RealmCache/
,,0.0686,realm-java,New Migration and Dynamic API. New Sort/Case enums. New RealmCache/
,,0.0673,realm-java,Convert IOSRealmTests and JNITransaction tests/New Migration and Dynamic API. New Sort/Case enums. New RealmCache/
,,0.0664,realm-java,New Migration and Dynamic API. New Sort/Case enums. New RealmCache/
,,0.0664,realm-java,New Migration and Dynamic API. New Sort/Case enums. New RealmCache/
,,0.0686,realm-java,New Migration and Dynamic API. New Sort/Case enums. New RealmCache/
,,0.0686,realm-java,New Migration and Dynamic API. New Sort/Case enums. New RealmCache/
,,0.0643,realm-java,switch to JUnit4/New Migration and Dynamic API. New Sort/Case enums. New RealmCache/
,,0.0849,realm-java,Realm.createOrUpdateObjectFromJson() now works correctly if the RealmObject class contains a primary key/
,,0.0686,realm-java,New Migration and Dynamic API. New Sort/Case enums. New RealmCache/
,,0.0686,realm-java,New Migration and Dynamic API. New Sort/Case enums. New RealmCache/
,,0.1085,realm-java,Use JUNIT4 for RealmQueryTest * Clean up RealmQueryTest. * No NP_NULL_PARAM_DEREF_ALL_TARGETS_DANGEROUS and DM_GC for tests./Support for RealmQuery.isNotEmpty() added/Add tests of aggregation methods in ReqlmQuery for nullable column/
,,0.1263,realm-java,"Added RealmQuery.distinct(), RealmResults.distinct()/"
,,0.0534,realm-java,Added Realm.copyFromRealm()/
,,0.0643,realm-java,New Migration and Dynamic API. New Sort/Case enums. New RealmCache/
,,0.0757,realm-java,"Allow byte code weaving during unit testing/NotificationTests converted to use TestRealmConfigurationFactory/switch to JUnit4/enhancing notifications, adding Async queries for DynamicRealmObject/"
,,0.2011,realm-java,"Fix flaky tests related with async transaction * Background realm needs to be closed before notifying other threads in async transaction. * Latch needs to be called after Realm closed./Add RealmList.removeAllFromRealm and Realm.clear * Add LinkView.removeAllTargetRows. * Add Realm.clear to remove all objects from Realm. * Add RealmList.removeAllFromRealm(). * Javadoc & test case update. Close basic PMD rules/Converted DynamicRealmTests to JUnit4. Added JUnit test guidelines./Revert ""Merge pull request from realm/ez/pmd"" This reverts commit d6d351f7e55a5598e6abbceda92f0a5bba33156a, reversing changes made to a73cb7969185ea10649ccf2bc73241d6908b861d./Add a check to prevent removing a RealmChangeListener from a non-Looper thread/fix 1884 listener trigger/enhancing notifications, adding Async queries for DynamicRealmObject/New Migration and Dynamic API. New Sort/Case enums. New RealmCache/Listeners are strong reference now/Checking for transaction in Realm.refresh and throwing if inside of Transaction as the Realm is always kept up to date. Fixes per code reviews. Adding update to changelog Fixing indentation. Updating change log to show correct exception/"
,,0.0848,realm-java,Add RxJava support/Deprecate RealmConfiguration.getSchemaMediator() and add RealmConfiguration.getRealmObjectClasses() which returns the unmodifiable set of model classes that make up the schema./
,,0.0995,realm-java,Release LinkView native pointers Fix * Add abstract method to NativeObjectReference for native resource releasing. * Implement NativeObjectReference.cleanup for UncheckRow and LinkView/
,,0.0874,realm-java,"enhancing notifications, adding Async queries for DynamicRealmObject/New Migration and Dynamic API. New Sort/Case enums. New RealmCache/"
,,0.0923,realm-java,Release LinkView native pointers Fix * Add abstract method to NativeObjectReference for native resource releasing. * Implement NativeObjectReference.cleanup for UncheckRow and LinkView/
,,0.0577,realm-java,Added Realm.copyFromRealm()/
,,0.1025,realm-java,Added Realm.copyFromRealm()/Deprecate RealmConfiguration.getSchemaMediator() and add RealmConfiguration.getRealmObjectClasses() which returns the unmodifiable set of model classes that make up the schema./
,,0.1044,realm-java,Added Realm.copyFromRealm()/Deprecate RealmConfiguration.getSchemaMediator() and add RealmConfiguration.getRealmObjectClasses() which returns the unmodifiable set of model classes that make up the schema./
,,0.1302,realm-java,"Notify listeners of async RealmObject even if the result is empty/Add RxJava support/fix 1894 changelistener not called/enhancing notifications, adding Async queries for DynamicRealmObject/New Migration and Dynamic API. New Sort/Case enums. New RealmCache/"
,,0.1675,realm-java,"Better exception message when sort on sub object Close RealmQuery.isNotEmpty(). It is fix for Fix the native method + Renaming./Support for RealmQuery.isNotEmpty() added/Always close shared group first before async msg/fix 1884 listener trigger/enhancing notifications, adding Async queries for DynamicRealmObject/New Migration and Dynamic API. New Sort/Case enums. New RealmCache/"
,,0.1157,realm-java,"Revert ""Merge pull request from realm/ez/pmd"" This reverts commit d6d351f7e55a5598e6abbceda92f0a5bba33156a, reversing changes made to a73cb7969185ea10649ccf2bc73241d6908b861d./enhancing notifications, adding Async queries for DynamicRealmObject/"
,,0.0664,realm-java,New Migration and Dynamic API. New Sort/Case enums. New RealmCache/
,,0.0702,realm-java,"enhancing notifications, adding Async queries for DynamicRealmObject/"
,,0.166,realm-java,"Access to RealmResults based on deleted RealmList * When the original RealmList is deleted, for most methods of RealmResults should just work without crash by just treat it like an empty RealmResults. * RealmResults.where() throws IllegalStateExecption in this case. * RealmResults.isValid() returns false in this case. This is a temp fix, check for more details. Close notifications, adding Async queries for DynamicRealmObject/"
,,0.0926,realm-java,Add RealmList.removeAllFromRealm and Realm.clear * Add LinkView.removeAllTargetRows. * Add Realm.clear to remove all objects from Realm. * Add RealmList.removeAllFromRealm(). * Javadoc & test case update. Close
,,0.1735,realm-java,"Access to RealmResults based on deleted RealmList * When the original RealmList is deleted, for most methods of RealmResults should just work without crash by just treat it like an empty RealmResults. * RealmResults.where() throws IllegalStateExecption in this case. * RealmResults.isValid() returns false in this case. This is a temp fix, check for more details. Close Migration and Dynamic API. New Sort/Case enums. New RealmCache/fix potential memory leak in jni code and skip copying back to java array if native array is not modified./"
,,0.0765,realm-java,Fixed lint warnings in RxJava example/
,,0.0758,realm-java,Fix warnings in AdapterExample (#2580) * Fix warnings * Add missing newline * Add missing newline * Update AndroidManifest.xml/Added RealmCollection APIs/
,,0.0737,realm-java,Fix warnings in AdapterExample (#2580) * Fix warnings * Add missing newline * Add missing newline * Update AndroidManifest.xml/Added RealmCollection APIs/
,,0.5321,realm-java,"RealmChangeListener should provide the changes object/realm/collection as well (#2705) RealmChangeListener should provide the changes object/realm/collection as in String, Byte, Short, Integer, and Long types can be null. (#2634) is allowed to be null for String and Boxed primitive types. Features part of this commit are 1. A annotated field in java.lang.String/Byte/Short/Integer/Long type can be null. 2. The object with nil primary key can be updated. 3. Migration checks if existing nullable type is set to be nullable in existing file. If not, throws RealmMigrationNeeded. 4. Duplicated null as PrimaryKey throws RealmPrimaryKeyConstraintException. 5. When a new empty row is added, the default value checked for duplicated is still the same empty string ("""") at Table.addEmptyRow() 6. Since there isnt equivalent term for Optional in Java 7 yet, nullable PK types are configured as following in this PR. | String PK | Number PK | Primitive PK | Table Column | Nullable | Nullable | Not Nullable |/Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/Thread check for copyToRealm/copyToRealmOrUpdate/Fix the cast in proxy generator for CacheData Close realm and row as a field name of model class. This fixes"
,,0.3788,realm-java,"RealmChangeListener should provide the changes object/realm/collection as well (#2705) RealmChangeListener should provide the changes object/realm/collection as well/Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/Thread check for copyToRealm/copyToRealmOrUpdate/Fix the cast in proxy generator for CacheData Close realm and row as a field name of model class. This fixes"
,,0.28,realm-java,"Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/"
,,0.3614,realm-java,"Fix using RealmModel as a field (#2666) * Modify and rename isRealmObject to isRealmModel. * Modify annotation processor to allow RealmModel as a field. Fix as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/allow realm and row as a field name of model class. This fixes"
,,0.5334,realm-java,"RealmChangeListener should provide the changes object/realm/collection as well (#2705) RealmChangeListener should provide the changes object/realm/collection as well/Fix using RealmModel as a field (#2666) * Modify and rename isRealmObject to isRealmModel. * Modify annotation processor to allow RealmModel as a field. Fix combination of and annotation now generates appropriate type cast when a primary key field type is String When RealmProxyClassGenerator.emitCopyOrUpdateMethod() is generating code for checking value for not-nullable types (i.e. primitive types or marked with it now generates appropriate type casts according to the field types. * Required PrimaryKey tests are in String, Byte, Short, Integer, and Long types can be null. (#2634) is allowed to be null for String and Boxed primitive types. Features part of this commit are 1. A annotated field in java.lang.String/Byte/Short/Integer/Long type can be null. 2. The object with nil primary key can be updated. 3. Migration checks if existing nullable type is set to be nullable in existing file. If not, throws RealmMigrationNeeded. 4. Duplicated null as PrimaryKey throws RealmPrimaryKeyConstraintException. 5. When a new empty row is added, the default value checked for duplicated is still the same empty string ("""") at Table.addEmptyRow() 6. Since there isnt equivalent term for Optional in Java 7 yet, nullable PK types are configured as following in this PR. | String PK | Number PK | Primitive PK | Table Column | Nullable | Nullable | Not Nullable |/Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/Thread check for copyToRealm/copyToRealmOrUpdate/Fix the cast in proxy generator for CacheData Close realm and row as a field name of model class. This fixes"
,,0.3354,realm-java,"Fix using RealmModel as a field (#2666) * Modify and rename isRealmObject to isRealmModel. * Modify annotation processor to allow RealmModel as a field. Fix as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/"
,,0.2875,realm-java,"Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/"
,,0.3434,realm-java,"RealmChangeListener should provide the changes object/realm/collection as well (#2705) RealmChangeListener should provide the changes object/realm/collection as well/Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/Thread local notifactions are now triggered using the Looper instead of immediately/Simplify ReamAsyncQueryTests + added new test util classes/"
,,0.1931,realm-java,"in String, Byte, Short, Integer, and Long types can be null. (#2634) is allowed to be null for String and Boxed primitive types. Features part of this commit are 1. A annotated field in java.lang.String/Byte/Short/"
,,0.1102,realm-java,Handle PK when calling RealmSchemas remove/rename (#2663) * Handle PK when calling RealmSchemas remove/rename * RealmSchema.remove() should remove the field from PK table. * RealmSchema.rename() should change the corresponding row in the PK table. Fix
,,0.1641,realm-java,"Add to realmObjects when addChangeListener called (#2723) * Only add the RealmObject to HandlerController.realmObjects when addChangeListener called. This will avoid we have too many objects in the map. * addToRealmObjects missed reference queue which would lead to the map grows always without cleaning. Close potentially a fix to ./Increased RealmObjectTests coverage with testing on unmanaged objects and removing null listener./Custom equals(), toString() and hashCode() work correctly./Added RealmCollection APIs/allow realm and row as a field name of model class. This fixes"
,,0.1845,realm-java,Give async related vars better names asyncQueryExecutor and pendingQuery seem to be very confusing since they are used for async transaction as well./#1594 RealmChangeListener should provide the changes object/realm/collection as well (#2705) RealmChangeListener should provide the changes object/realm/collection as well/Added RealmCollection APIs/Fixed race condition causing BadVersionException/Merge remote-tracking branch origin/release/0.87 into mc/merge/0.87_e5bd0080 Conflicts: changelog.txt realm/realm-library/src/androidTest/java/io/realm/RealmAsyncQueryTests.java/fixes IllegalStateException Caller thread behind the worker thread/Thread local notifactions are now triggered using the Looper instead of immediately/Simplify ReamAsyncQueryTests + added new test util classes/
,,0.1949,realm-java,"in String, Byte, Short, Integer, and Long types can be null. (#2634) is allowed to be null for String and Boxed primitive types. Features part of this commit are 1. A annotated field in java.lang.String/Byte/Short/"
,,0.1917,realm-java,"fix the String from DynamicRealmObject.toString(). Now DynamicRealmObject.toString() shows null value as ""null"". ""class_"" prefix is removed from type name in that String. Align the format to the String from typed RealmObject./Correct checking in DynamicRealmObject.setList * Fix * Check equality of Realm in DynamicRealmObject setters to avoid risks mentioned 2) in"
,,0.2297,realm-java,RealmResults and RealmObjects are no longer accidentally GCed while their Observable is still alive./Added RealmCollection APIs/Realm Observables now holds a Realm instance until unsubscribed/Thread local notifactions are now triggered using the Looper instead of immediately/
,,0.0954,realm-java,Thread local notifactions are now triggered using the Looper instead of immediately/
,,0.0772,realm-java,Added RealmCollection APIs/optimize imports/
,,0.0686,realm-java,Added RealmCollection APIs/
,,0.4962,realm-java,"Implementation of SharedGroup::wait_for_change() method. (#2386) Goal 1. Add BaseRealm.waitForChange() which blocks until a change is available, then advance the Realm and continue without triggering RealmChangeListeners. 2. Add BaseRealm.stopWaitForChange() that makes any current waitForChange() return false immediately. 3. Deprecated BaseRealm.refresh(). Behaviors 1. waitForChange() will throw IllegalStateException within a transaction. 2. BaseRealm cannot wait in a thread with Looper. IllegalStateException will be thrown. 3. Once stopWaitForChange is called, all future calls to waitForChange will immediately return false. For detailed discussions, please refer RealmChangeListener should provide the changes object/realm/collection as well (#2705) RealmChangeListener should provide the changes object/realm/collection as well/Make Realm.createObject(Class,PrimaryKey) public (#2622) This method is a way to solve the problem that people might have data with a primary key that is is the default value for that type, e.g a long primary key with the value 0. Once this object is saved in Realm any calls to the normal Realm.createObject() would throw an exception as it would try to assign the default value (zero) to the object before the user could set it to something else. With this method that is no longer a problem. Internally we already use this method and it is already public in the Dynamic API. The reason for not making this public earlier was due to fear of mis-use since there is no type-safe guarantee at compile time. However since it is already public in the Dynamic API and we havent seen any indication of that being misused we feel it should be safe to make this public. Also our Query API is also semi-threadsafe so there is precedence there as well./Only throw RealmException if absolutely necessary (#2618) We should avoid wrapping lower level exceptions in RealmExceptions unless there is a good reason for it. We had multiple support issues where people were confused about the RealmException and didnt understand they had to dig through the stack trace for the original exception. This change alters the behaviour of all our JSON methods so they now only convert JSONException to RealmException in order to prevent checked exceptions to reach the user. All other exceptions should be thrown directly./RealmCollection iterators are now stable (#2124) This commit changes the semantics of how live RealmResults really are. Before this commit RealmResults where live _all the time_, which meant that code like the below didnt work as expected (only half the elements would be deleted): ``` for (int i 0; i results.size(); i++) { results.get(i).deleteFromRealm(); } ``` The rather unintuitive work-around was counting backwards: ``` for (int i results.size() i >=0; i--) { results.get(i).deleteFromRealm(); } ``` This commit changes the behaviour of RealmResults, so they no longer are automatically up to date. They are instead refreshed using Looper events just like changes from other threads. RealmList iterators are not live in the same way that RealmResults are but act more like standard ArrayLists, so they dont suffer from the same liveness issues. The high-level arguments for doing this change was: Pros: * All iterators now work as you would normally expect (ease of use). * The liveness of Realm objects are now all controlled through the Looper (simpler internal code / easier to document Realm behaviour). Cons: * There is a small chance that people can accidentally reference a deleted RealmObject in a RealmResult. (Can be checked through use of in String, Byte, Short, Integer, and Long types can be null. (#2634) is allowed to be null for String and Boxed primitive types. Features part of this commit are 1. A annotated field in java.lang.String/Byte/Short/Integer/Long type can be null. 2. The object with nil primary key can be updated. 3. Migration checks if existing nullable type is set to be nullable in existing file. If not, throws RealmMigrationNeeded. 4. Duplicated null as PrimaryKey throws RealmPrimaryKeyConstraintException. 5. When a new empty row is added, the default value checked for duplicated is still the same empty string ("""") at Table.addEmptyRow() 6. Since there isnt equivalent term for Optional in Java 7 yet, nullable PK types are configured as following in this PR. | String PK | Number PK | Primitive PK | Table Column | Nullable | Nullable | Not Nullable |/Added RealmCollection APIs/Thread check for copyToRealm/copyToRealmOrUpdate/Rename clear and removeAllFromRealm to conform to new RealmCollection API/Add test case for getInstance(Context)/"
,,0.4567,realm-java,"RealmCollection iterators are now stable (#2124) This commit changes the semantics of how live RealmResults really are. Before this commit RealmResults where live _all the time_, which meant that code like the below didnt work as expected (only half the elements would be deleted): ``` for (int i 0; i results.size(); i++) { results.get(i).deleteFromRealm(); } ``` The rather unintuitive work-around was counting backwards: ``` for (int i results.size() i >=0; i--) { results.get(i).deleteFromRealm(); } ``` This commit changes the behaviour of RealmResults, so they no longer are automatically up to date. They are instead refreshed using Looper events just like changes from other threads. RealmList iterators are not live in the same way that RealmResults are but act more like standard ArrayLists, so they dont suffer from the same liveness issues. The high-level arguments for doing this change was: Pros: * All iterators now work as you would normally expect (ease of use). * The liveness of Realm objects are now all controlled through the Looper (simpler internal code / easier to document Realm behaviour). Cons: * There is a small chance that people can accidentally reference a deleted RealmObject in a RealmResult. (Can be checked through use of `RealmObject.isValid()`)/Added RealmCollection APIs/Merge remote-tracking branch origin/release/0.87 into mc/merge/0.87_4c218573 Conflicts: changelog.txt realm/realm-jni/src/util.cpp realm/realm-library/src/androidTest/java/io/realm/RealmResultsTest.java realm/realm-library/src/androidTest/java/io/realm/TypeBasedNotificationsTest.java realm/realm-library/src/main/java/io/realm/RealmResults.java/RealmQuery.distinctAsync(), RealmResults.distinctAsync() support./"
,,0.2436,realm-java,Added RealmCollection APIs/More checkings when modify RealmList Fix * New method LinkView.getTargetTable(). * Proper checking to add DynamicRealmObject to RealmList. * Disallow modifying with RealmObject belongs to another Realm instance./
,,0.0751,realm-java,optimize imports/Added RealmCollection APIs/
,,0.0895,realm-java,"Multi-arguments distinct(...) for Realm, DynamicRealm, RealmQuery, and RealmResults/"
,,0.4599,realm-java,"RealmChangeListener should provide the changes object/realm/collection as well (#2705) RealmChangeListener should provide the changes object/realm/collection as well/RealmCollection iterators are now stable (#2124) This commit changes the semantics of how live RealmResults really are. Before this commit RealmResults where live _all the time_, which meant that code like the below didnt work as expected (only half the elements would be deleted): ``` for (int i 0; i results.size(); i++) { results.get(i).deleteFromRealm(); } ``` The rather unintuitive work-around was counting backwards: ``` for (int i results.size() i >=0; i--) { results.get(i).deleteFromRealm(); } ``` This commit changes the behaviour of RealmResults, so they no longer are automatically up to date. They are instead refreshed using Looper events just like changes from other threads. RealmList iterators are not live in the same way that RealmResults are but act more like standard ArrayLists, so they dont suffer from the same liveness issues. The high-level arguments for doing this change was: Pros: * All iterators now work as you would normally expect (ease of use). * The liveness of Realm objects are now all controlled through the Looper (simpler internal code / easier to document Realm behaviour). Cons: * There is a small chance that people can accidentally reference a deleted RealmObject in a RealmResult. (Can be checked through use of `RealmObject.isValid()`)/One more flaky test/Thread local notifactions are now triggered using the Looper instead of immediately/"
,,0.5201,realm-java,"Implementation of SharedGroup::wait_for_change() method. (#2386) Goal 1. Add BaseRealm.waitForChange() which blocks until a change is available, then advance the Realm and continue without triggering RealmChangeListeners. 2. Add BaseRealm.stopWaitForChange() that makes any current waitForChange() return false immediately. 3. Deprecated BaseRealm.refresh(). Behaviors 1. waitForChange() will throw IllegalStateException within a transaction. 2. BaseRealm cannot wait in a thread with Looper. IllegalStateException will be thrown. 3. Once stopWaitForChange is called, all future calls to waitForChange will immediately return false. For detailed discussions, please refer RealmChangeListener should provide the changes object/realm/collection as well (#2705) RealmChangeListener should provide the changes object/realm/collection as well/RealmCollection iterators are now stable (#2124) This commit changes the semantics of how live RealmResults really are. Before this commit RealmResults where live _all the time_, which meant that code like the below didnt work as expected (only half the elements would be deleted): ``` for (int i 0; i results.size(); i++) { results.get(i).deleteFromRealm(); } ``` The rather unintuitive work-around was counting backwards: ``` for (int i results.size() i >=0; i--) { results.get(i).deleteFromRealm(); } ``` This commit changes the behaviour of RealmResults, so they no longer are automatically up to date. They are instead refreshed using Looper events just like changes from other threads. RealmList iterators are not live in the same way that RealmResults are but act more like standard ArrayLists, so they dont suffer from the same liveness issues. The high-level arguments for doing this change was: Pros: * All iterators now work as you would normally expect (ease of use). * The liveness of Realm objects are now all controlled through the Looper (simpler internal code / easier to document Realm behaviour). Cons: * There is a small chance that people can accidentally reference a deleted RealmObject in a RealmResult. (Can be checked through use of `RealmObject.isValid()`)/Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/migrateRealm throws when db doesnt exsit Close ./Thread local notifactions are now triggered using the Looper instead of immediately/"
,,0.5628,realm-java,"RealmCollection iterators are now stable (#2124) This commit changes the semantics of how live RealmResults really are. Before this commit RealmResults where live _all the time_, which meant that code like the below didnt work as expected (only half the elements would be deleted): ``` for (int i 0; i results.size(); i++) { results.get(i).deleteFromRealm(); } ``` The rather unintuitive work-around was counting backwards: ``` for (int i results.size() i >=0; i--) { results.get(i).deleteFromRealm(); } ``` This commit changes the behaviour of RealmResults, so they no longer are automatically up to date. They are instead refreshed using Looper events just like changes from other threads. RealmList iterators are not live in the same way that RealmResults are but act more like standard ArrayLists, so they dont suffer from the same liveness issues. The high-level arguments for doing this change was: Pros: * All iterators now work as you would normally expect (ease of use). * The liveness of Realm objects are now all controlled through the Looper (simpler internal code / easier to document Realm behaviour). Cons: * There is a small chance that people can accidentally reference a deleted RealmObject in a RealmResult. (Can be checked through use of `RealmObject.isValid()`)/Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/Added RealmCollection APIs/More checkings when modify RealmList Fix * New method LinkView.getTargetTable(). * Proper checking to add DynamicRealmObject to RealmList. * Disallow modifying with RealmObject belongs to another Realm instance./"
,,0.2506,realm-java,"Replace setModules() with modules() (#2621) This commit deprecates RealmConfiguration.setModules() in favour of RealmConfiguration.modules(). The reason being using the setter terminology is not common in builders. See Effective Java item 2./Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/move RealmConfiguration.getSchemaMediator() to package private./"
,,0.4297,realm-java,"Handle PK when calling RealmSchemas remove/rename (#2663) * Handle PK when calling RealmSchemas remove/rename * RealmSchema.remove() should remove the field from PK table. * RealmSchema.rename() should change the corresponding row in the PK table. Fix as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/More checkings when modify RealmList Fix * New method LinkView.getTargetTable(). * Proper checking to add DynamicRealmObject to RealmList. * Disallow modifying with RealmObject belongs to another Realm instance./"
,,0.2845,realm-java,"Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/"
,,0.292,realm-java,"Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/"
,,0.2815,realm-java,"Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/"
,,0.2899,realm-java,"Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/Add a check whether transformer was applied or not. This commit adds default implementation of `transformerApplied()` to `RealmProxyMediator` class which returns `false`. And then Realm transformer adds overriding method to its subclasses and those methods returns `true`. If Transformer was applied, `RealmProxyMediator.transformerApplied()` returns `true` and if not, `RealmProxyMediator.transformerApplied()` returns `false`. That enable us to detect Realm transformer was applied or not at runtime./"
,,0.3461,realm-java,"RealmChangeListener should provide the changes object/realm/collection as well (#2705) RealmChangeListener should provide the changes object/realm/collection as well/Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/Added RealmCollection APIs/Only load RealmObservableFactory when RxJava exist Close * Check RxJava existence only once. * Dont load RealmObservableFactory if RxJava doesnt exist. NOTE: When reflection called on the RealmObject/RealmResults, crash will still happen because of Observable doesnt exist in the class path. In such a case, a dummy rx.Observable is still needed as a workaround./allow realm and row as a field name of model class. This fixes lint warnings/"
,,0.1872,realm-java,"Implementation of SharedGroup::wait_for_change() method. (#2386) Goal 1. Add BaseRealm.waitForChange() which blocks until a change is available, then advance the Realm and continue without triggering RealmChangeListeners. 2. Add BaseRealm.stopWaitForChange() that makes any current waitForChange() return false immediately. 3. Deprecated BaseRealm.refresh(). Behaviors 1. waitForChange() will throw IllegalStateException within a transaction. 2. BaseRealm cannot wait in a thread with Looper. IllegalStateException will be thrown. 3. Once stopWaitForChange is called, all future calls to waitForChange will immediately return false. For detailed discussions, please refer"
,,0.1032,realm-java,Make all methods on RealmObject and all classes in public API final (#2675) We should mark all methods that should not be overridden final. We should mark all classes that should not be inherited final./
,,0.5319,realm-java,"Give async related vars better names asyncQueryExecutor and pendingQuery seem to be very confusing since they are used for async transaction as well./Deprecated 3 field sort in Realm and RealmQuery (#2619)/RealmCollection iterators are now stable (#2124) This commit changes the semantics of how live RealmResults really are. Before this commit RealmResults where live _all the time_, which meant that code like the below didnt work as expected (only half the elements would be deleted): ``` for (int i 0; i results.size(); i++) { results.get(i).deleteFromRealm(); } ``` The rather unintuitive work-around was counting backwards: ``` for (int i results.size() i >=0; i--) { results.get(i).deleteFromRealm(); } ``` This commit changes the behaviour of RealmResults, so they no longer are automatically up to date. They are instead refreshed using Looper events just like changes from other threads. RealmList iterators are not live in the same way that RealmResults are but act more like standard ArrayLists, so they dont suffer from the same liveness issues. The high-level arguments for doing this change was: Pros: * All iterators now work as you would normally expect (ease of use). * The liveness of Realm objects are now all controlled through the Looper (simpler internal code / easier to document Realm behaviour). Cons: * There is a small chance that people can accidentally reference a deleted RealmObject in a RealmResult. (Can be checked through use of `RealmObject.isValid()`)/Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/RealmQuery.distinctAsync(), RealmResults.distinctAsync() support./"
,,0.2487,realm-java,"Move all query methods to RealmQuery (#2620) Currently we have the following helper query methods on Realm/DynamicRealm: allObjects() and distinct() However we have to be mindful about the number of methods in our API and from the projects we have seen so far, these methods does not seem to have been used much. Moving all query methods to RealmQuery has two advantages: 1) It helps us to reduce our overall method count and 2) It makes our API more consistent as now all RealmQuery methods are only found on RealmQuery./Added RealmCollection APIs/Multi-arguments distinct(...) for Realm, DynamicRealm, RealmQuery, and RealmResults/RealmQuery.distinctAsync(), RealmResults.distinctAsync() support./"
,,0.4458,realm-java,"RealmChangeListener should provide the changes object/realm/collection as well (#2705) RealmChangeListener should provide the changes object/realm/collection as well/Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/fix the String from DynamicRealmObject.toString(). Now DynamicRealmObject.toString() shows null value as ""null"". ""class_"" prefix is removed from type name in that String. Align the format to the String from typed RealmObject./More checkings when modify RealmList Fix * New method LinkView.getTargetTable(). * Proper checking to add DynamicRealmObject to RealmList. * Disallow modifying with RealmObject belongs to another Realm instance./Correct checking in DynamicRealmObject.setList * Fix * Check equality of Realm in DynamicRealmObject setters to avoid risks mentioned 2) in lint warnings/"
,,0.3066,realm-java,"Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/Added RealmCollection APIs/"
,,0.5176,realm-java,"Give async related vars better names asyncQueryExecutor and pendingQuery seem to be very confusing since they are used for async transaction as well./RealmCollection iterators are now stable (#2124) This commit changes the semantics of how live RealmResults really are. Before this commit RealmResults where live _all the time_, which meant that code like the below didnt work as expected (only half the elements would be deleted): ``` for (int i 0; i results.size(); i++) { results.get(i).deleteFromRealm(); } ``` The rather unintuitive work-around was counting backwards: ``` for (int i results.size() i >=0; i--) { results.get(i).deleteFromRealm(); } ``` This commit changes the behaviour of RealmResults, so they no longer are automatically up to date. They are instead refreshed using Looper events just like changes from other threads. RealmList iterators are not live in the same way that RealmResults are but act more like standard ArrayLists, so they dont suffer from the same liveness issues. The high-level arguments for doing this change was: Pros: * All iterators now work as you would normally expect (ease of use). * The liveness of Realm objects are now all controlled through the Looper (simpler internal code / easier to document Realm behaviour). Cons: * There is a small chance that people can accidentally reference a deleted RealmObject in a RealmResult. (Can be checked through use of `RealmObject.isValid()`)/Interface as supplement to extending RealmObject (#2599) * Backup * Add RealmModel * Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests * fixing examples * WIP * fix Annotation processor * clean up * fix javadoc * add transformer tests & fix DynamicRealm tests * fixing tests * adding tests * adding tests * fixing tests for the realm-annotations-processor * add tests to cover more UC for RealmList * renamed POJO to RealmModel * reduce method count by using proxyState only in RealmObjectProxy * fix examples, no need to exclude RealmObject using Gson * making RealmList final, remove unused method & fixing APT test/Fixed race condition causing BadVersionException/Thread local notifactions are now triggered using the Looper instead of immediately/"
,,0.2487,realm-java,Added RealmCollection APIs/More checkings when modify RealmList Fix * New method LinkView.getTargetTable(). * Proper checking to add DynamicRealmObject to RealmList. * Disallow modifying with RealmObject belongs to another Realm instance./
,,0.4704,realm-java,"Expanding time resolution into millisecs (#2679) Expanding time resolution into milliseconds but using cores new column type Timestamp. An upgrade to core version 0.100.0 is required, and some minor updates are coming from some changes in the core API./RealmCollection iterators are now stable (#2124) This commit changes the semantics of how live RealmResults really are. Before this commit RealmResults where live _all the time_, which meant that code like the below didnt work as expected (only half the elements would be deleted): ``` for (int i 0; i results.size(); i++) { results.get(i).deleteFromRealm(); } ``` The rather unintuitive work-around was counting backwards: ``` for (int i results.size() i >=0; i--) { results.get(i).deleteFromRealm(); } ``` This commit changes the behaviour of RealmResults, so they no longer are automatically up to date. They are instead refreshed using Looper events just like changes from other threads. RealmList iterators are not live in the same way that RealmResults are but act more like standard ArrayLists, so they dont suffer from the same liveness issues. The high-level arguments for doing this change was: Pros: * All iterators now work as you would normally expect (ease of use). * The liveness of Realm objects are now all controlled through the Looper (simpler internal code / easier to document Realm behaviour). Cons: * There is a small chance that people can accidentally reference a deleted RealmObject in a RealmResult. (Can be checked through use of `RealmObject.isValid()`)/Multi-arguments distinct(...) for Realm, DynamicRealm, RealmQuery, and RealmResults/"
,,0.1102,realm-java,"Expanding time resolution into millisecs (#2679) Expanding time resolution into milliseconds but using cores new column type Timestamp. An upgrade to core version 0.100.0 is required, and some minor updates are coming from some changes in the core API./"
,,0.19,realm-java,"Implementation of SharedGroup::wait_for_change() method. (#2386) Goal 1. Add BaseRealm.waitForChange() which blocks until a change is available, then advance the Realm and continue without triggering RealmChangeListeners. 2. Add BaseRealm.stopWaitForChange() that makes any current waitForChange() return false immediately. 3. Deprecated BaseRealm.refresh(). Behaviors 1. waitForChange() will throw IllegalStateException within a transaction. 2. BaseRealm cannot wait in a thread with Looper. IllegalStateException will be thrown. 3. Once stopWaitForChange is called, all future calls to waitForChange will immediately return false. For detailed discussions, please refer"
,,0.4289,realm-java,"Expanding time resolution into millisecs (#2679) Expanding time resolution into milliseconds but using cores new column type Timestamp. An upgrade to core version 0.100.0 is required, and some minor updates are coming from some changes in the core in String, Byte, Short, Integer, and Long types can be null. (#2634) is allowed to be null for String and Boxed primitive types. Features part of this commit are 1. A annotated field in java.lang.String/Byte/Short/Integer/Long type can be null. 2. The object with nil primary key can be updated. 3. Migration checks if existing nullable type is set to be nullable in existing file. If not, throws RealmMigrationNeeded. 4. Duplicated null as PrimaryKey throws RealmPrimaryKeyConstraintException. 5. When a new empty row is added, the default value checked for duplicated is still the same empty string ("""") at Table.addEmptyRow() 6. Since there isnt equivalent term for Optional in Java 7 yet, nullable PK types are configured as following in this PR. | String PK | Number PK | Primitive PK | Table Column | Nullable | Nullable | Not Nullable |/"
,,0.1002,realm-java,Fixed race condition causing BadVersionException/Upgrading to Realm Core 0.97.0/fixes IllegalStateException Caller thread behind the worker thread/
,,0.1261,realm-java,"Expanding time resolution into millisecs (#2679) Expanding time resolution into milliseconds but using cores new column type Timestamp. An upgrade to core version 0.100.0 is required, and some minor updates are coming from some changes in the core API./Upgrading to Realm Core 0.97.0/"
,,0.1649,realm-java,"Adapt core fix for the delete RealmList Update core to 0.96.1. No more exception will be thrown when access RealmResults if the base RealmList has be deleted. Instead, it will be treated as an empty RealmResults forever./"
,,0.1102,realm-java,"Expanding time resolution into millisecs (#2679) Expanding time resolution into milliseconds but using cores new column type Timestamp. An upgrade to core version 0.100.0 is required, and some minor updates are coming from some changes in the core API./"
,,0.1972,realm-java,"Implementation of SharedGroup::wait_for_change() method. (#2386) Goal 1. Add BaseRealm.waitForChange() which blocks until a change is available, then advance the Realm and continue without triggering RealmChangeListeners. 2. Add BaseRealm.stopWaitForChange() that makes any current waitForChange() return false immediately. 3. Deprecated BaseRealm.refresh(). Behaviors 1. waitForChange() will throw IllegalStateException within a transaction. 2. BaseRealm cannot wait in a thread with Looper. IllegalStateException will be thrown. 3. Once stopWaitForChange is called, all future calls to waitForChange will immediately return false. For detailed discussions, please refer to Realm Core 0.97.0/"
,,0.0813,realm-java,Removed all deprecated methods and fixed examples./
,,0.0779,realm-java,Removed all deprecated methods and fixed examples./Examples should use transaction blocks (#2800) * Moving examples over to execute transaction * Updating comments to use executeTransaction * Use partial mocks for Realm#executeTransaction(...) and create additional tests to illustrate mock verification of Realm#executeTransaction(...). Had to do this because of a problem with Powermock:
,,0.1026,realm-java,"Improved detection when using interfaces in Realm classes (#2821) This commits adds check to the annotation processor so we detects if people try to use interfaces that extends RealmModel as a Generic to RealmList or a single object reference. Until we support polymorphism, you can only reference concrete types./"
,,0.1196,realm-java,"Improved detection when using interfaces in Realm classes (#2821) This commits adds check to the annotation processor so we detects if people try to use interfaces that extends RealmModel as a Generic to RealmList or a single object reference. Until we support polymorphism, you can only reference concrete types./"
,,0.1364,realm-java,More GCed ref for flaky test (#3135)/Objects not in Realm are now called unmananged everywhere. (#2828)/add a null check to addChangeListener and removeChangeListener (#2805) * add a null check to addChangeListener and removeChangeListener in Realm and DynamicRealm (fixes * reflect review comments/Fixed unit tests./thread safe HandlerController#emptyAsyncRealmObject & realmObjects (#2761) * making HandlerController#emptyAsyncRealmObject & HandlerController#realmObjects thread safe/
,,0.1042,realm-java,Remove unused mixed type (#3041) * Remove unused mixed type/
,,0.1002,realm-java,Remove unused mixed type (#3041) * Remove unused mixed type/
,,0.2554,realm-java,"RealmObjectSchema.setClassName() transfers primary key for new class name (#3149) RealmObjectSchema.setClassName() transfers a primary key for a new class name that the renamed class can maintain the old primary key./Unit tests for PrimaryKey field type change (#3076) Unit tests for checking proper migration of PrimaryKey field type change from String to Integer/int./ PrimaryKey index rearrangement in migration revisited (#2920) This PR fixes two issues; 1) When a column with a smaller index than that of a primary key field gets removed, the primary key field index decrements, which causes a cached primary key index to point a wrong field. 2) When a primary key field is renamed, the primary key meta table is not updated accordingly./addPrimaryKey() on RealmObjectSchema misses Index addition. (#2832) RealmObjectSchema.addPrimaryKey() is supposed to add a search index to its primary key field but it is currently missing. This is to fix the addition and removal of a search index related to primary key methods in RealmObjectSchema./"
,,0.1389,realm-java,"Unit test cleanup and parameterization for PrimaryKey (#2815) The issue is addressed with adding more coverage and cleanup for PrimaryKey related unit tests. 1. With an exception, all the null primarykey tests in RealmTests are now parameterized. 2. Parameters in RealmJsonNullPrimaryKeyTests are cleaned up. 3. Realm.createObject(class, primaryKeyValue) is tested with null in positive and negative manner. 4. NullPrimaryKey interface is expanded to setters as well./"
,,0.0713,realm-java,Wrong JNI function declaration caused test timeout (#2995) The worst thing is async query wont throw those exceptions in the background. * Rephrase changelog/
,,0.1066,realm-java,"Nh/fixing 3105 (#3306) * Fixing issue with Cyclic dependency insert or the existing copyToRealm, adding support for managed RealmObject/"
,,0.1597,realm-java,"Use createObject(class, primaryKey) in test (#3377) Since Realm.createObject(class) will be deprecated on master for Classes with primary key defined, fix the test cases which use it first to avoid more conflicts when merging./Typed getters on DynamicRealmObject now throws a proper exception instead of creating a seg fault when called with a field name of the wrong type. (#3312)/"
,,0.0765,realm-java,Fixed leaking unit tests./
,,0.0648,realm-java,getFieldIndex returns null for non-existing field (#3295) Close
,,0.10300000000000001,realm-java,"Use createObject(class, primaryKey) in test (#3377) Since Realm.createObject(class) will be deprecated on master for Classes with primary key defined, fix the test cases which use it first to avoid more conflicts when merging./"
,,0.0787,realm-java,Add RealmFileException to replace RealmIOException and IncompatibleLockFileException. Also it is mapped to the same name exception in ObjectStore to give user a detailed kind of file exception./
,,0.1234,realm-java,Typed getters on DynamicRealmObject now throws a proper exception instead of creating a seg fault when called with a field name of the wrong type. (#3312)/
,,0.08,realm-java,Expose listeners list size from RealmNotifier And enable related RxJava tests./
,,0.2751,realm-java,"Fix tests/Get findAllAsync and findFirstAsync back the findAllAsync got deprecated since from OS Results point of view, the query updating will run in the background by default, then there would be no difference between findAll and findAsync. Apparently the isLoad() and load() should be deprecated as well. So like cocoa, the Query will be executed immediately if user tries to access the element in the Results. But ... That was wrong because of those use cases: 1) RxJava support, in the subscription, it needs to check isLoaded() to determine the next step. And it will be fired once after the Observable created. By always returning true from isLoaded(), that means for RxJava will always run sync query at the first time. 2) Create a RealmResults and pass it to a list adapter. Since UI will always call size() which will run the query immediately and the first time query becomes synced. So, we get all async related APIs back and keep them having the same functionality like before. The behavior wont be exact the same, but from users perspective, they are the same as before./Fix LinkView based RealmResultss tests behaviour The original tests for deleted LinkView based RealmResults are incorrect. Before the next event loop, even if the LinkView is not valid anymore, for the purpose of maintaining the stable iterator, the RealmResults has to stay the same without calling sync_if_needed. The results becomes empty only if the we enter into the next event loop and reattach to the original TableView. Also, a core bug was found during changing the tests, see"
,,0.08800000000000001,realm-java,"Fix wrong thread test When call the RealmResults.contains(), the given object must be a managed RealmObject, otherwise it will just return false./"
,,0.142,realm-java,"Wire the ""like"" predicate into RealmQuery (#3992) * Wire the ""like"" predicate into RealmQuery Fixes distinctAsync tests distinct is async by default, and distinctAsync is deprecated./Fix links field query tests/Remove TableView and TableOrView YEAH/"
,,0.1068,realm-java,PermissionOffer/PermissionOfferResponse support (#4005) Added support for PermissionOffer and PermissionOfferResponse/Throw correct exception for multiple logged in users (#3921)/Add support for the management-Realm (#3627) Add preliminary support for the management-Realm/
,,0.2554,realm-java,"Get findAllAsync and findFirstAsync back the findAllAsync got deprecated since from OS Results point of view, the query updating will run in the background by default, then there would be no difference between findAll and findAsync. Apparently the isLoad() and load() should be deprecated as well. So like cocoa, the Query will be executed immediately if user tries to access the element in the Results. But ... That was wrong because of those use cases: 1) RxJava support, in the subscription, it needs to check isLoaded() to determine the next step. And it will be fired once after the Observable created. By always returning true from isLoaded(), that means for RxJava will always run sync query at the first time. 2) Create a RealmResults and pass it to a list adapter. Since UI will always call size() which will run the query immediately and the first time query becomes synced. So, we get all async related APIs back and keep them having the same functionality like before. The behavior wont be exact the same, but from users perspective, they are the same as before./Use RealmNotifier for RealmObject listener Ideally we should use the object notifications from object store, but since it is still in progress and the KVO notifications is not generic enough for us to use (there are some logic issues), we simply use the RealmNotifier to trigger the RealmObject listeners. There will be false positive notifications with this implementation since we are only checking the Rows table version. But this problem exists even before this commit./Generalize the ObserverPairList Since RowNotifier, CollectioNotifier and RealmNotifier have the similar requirements control the life cycle of the anonymous listener, create a ObserverPairList class for it. Also tests for the ObserverPairList. Then we can remove weak ref related tests from others./Realm should be validated always before callback/Accessor of PendingRow should throw Explicitly to let the front end run the pending query./Clear the memory ownership for RowNotifier/Use OS notification for RealmObject this makes the fine grained notifications for RealmObject possible./Add PendingRow to suport findFirst/"
,,0.2808,realm-java,"Wire the ""like"" predicate into RealmQuery (#3992) * Wire the ""like"" predicate into RealmQuery Fixes calling findAllAsync on non-looper thread/Get findAllAsync and findFirstAsync back the findAllAsync got deprecated since from OS Results point of view, the query updating will run in the background by default, then there would be no difference between findAll and findAsync. Apparently the isLoad() and load() should be deprecated as well. So like cocoa, the Query will be executed immediately if user tries to access the element in the Results. But ... That was wrong because of those use cases: 1) RxJava support, in the subscription, it needs to check isLoaded() to determine the next step. And it will be fired once after the Observable created. By always returning true from isLoaded(), that means for RxJava will always run sync query at the first time. 2) Create a RealmResults and pass it to a list adapter. Since UI will always call size() which will run the query immediately and the first time query becomes synced. So, we get all async related APIs back and keep them having the same functionality like before. The behavior wont be exact the same, but from users perspective, they are the same as before./We cannot deprecate the findFirstAsync findFirst() may return null before which has a differnt API behavior./PendingRow can return a CheckedRow for DynamicRealmObject. Also some code cleanup./Move TableOrView.NO_MATCH to Table/Remove useless code and fix one missed findAllxxx function./Distinct support/Wrap SortDescriptor/"
,,0.0917,realm-java,reattach when BindingContext::before_notify/Clear the memory ownership for RowNotifier/Use OS notification for RealmObject this makes the fine grained notifications for RealmObject possible./
,,0.198,realm-java,Refactor Schemas into separate native and realm-based implementations (#4382) * Refactor Schemas into separate native and realm-based implementations * Fix all tests * Respond to PR comments * Temporary (git add .) kludge to fix visiblity problem/
,,0.1137,realm-java,Clear pending collection first for findFirstAsync (#4497) Otherwise the pending query will be executed again if there is a local transaction in the listener. That would cause a infinite recursion or NPE (like Fix distinct on unindexed fields (#4390) Fix
,,0.0833,realm-java,RealmList.asObservable() (#4233)/Deleted RealmObjects are now emitted as well. (#4236)/
,,0.1998,realm-java,Refactor Schemas into separate native and realm-based implementations (#4382) * Refactor Schemas into separate native and realm-based implementations * Fix all tests * Respond to PR comments * Temporary (git add .) kludge to fix visiblity problem/
,,0.1885,realm-java,Re-add Realm.refresh() (#4515)/refactor internal method name in RealmSchema (#4429)/Refactor Schemas into separate native and realm-based implementations (#4382) * Refactor Schemas into separate native and realm-based implementations * Fix all tests * Respond to PR comments * Temporary (git add .) kludge to fix visiblity problem/
,,0.0891,realm-java,Update Object Store and test cases (#4507) Update OS to 7a1924b4cf Fix distinct on unindexed fields (#4390) Fix
,,0.1324,realm-java,"Add OrderedRealmCollectionSnapshot (#4172) Introduce OrderedRealmCollectionSnapshot as another type of OrderedRealmCollection. A snapshot can be created from RealmResults or RealmList. A snapshot is backed by a snapshot of OS Results. So the snapshot itself wont be updated. The size and order stay the same forever (elements inside are still live objects.). Since the RealmResults is auto-updated all the time, snapshot will be usefull when changing the results in a simple loops. This commit also moves the common code from RealmResults to OrderedRealmCollectionImpl since those can be shared with snapshot implementation. Implement"
,,0.1678,realm-java,"Use target table to create snapshot from LinkView (#4556) Fix . Remove useless confusing `LinkView.getTable()`./Enable listeners on RealmList (#4216) The RealmList holds a Collection which is used for listeners. Other RealmList APIs are still calling from LinkView./Add OrderedRealmCollectionSnapshot (#4172) Introduce OrderedRealmCollectionSnapshot as another type of OrderedRealmCollection. A snapshot can be created from RealmResults or RealmList. A snapshot is backed by a snapshot of OS Results. So the snapshot itself wont be updated. The size and order stay the same forever (elements inside are still live objects.). Since the RealmResults is auto-updated all the time, snapshot will be usefull when changing the results in a simple loops. This commit also moves the common code from RealmResults to OrderedRealmCollectionImpl since those can be shared with snapshot implementation. Implement"
,,0.066,realm-java,Add support for changing a users password. (#4538)/
,,0.2411,realm-java,"Refactor Schemas into separate native and realm-based implementations (#4382) * Refactor Schemas into separate native and realm-based implementations * Fix all tests * Respond to PR comments * Temporary (git add .) kludge to fix visiblity problem/Enable listeners on RealmList (#4216) The RealmList holds a Collection which is used for listeners. Other RealmList APIs are still calling from LinkView./Add OrderedRealmCollectionSnapshot (#4172) Introduce OrderedRealmCollectionSnapshot as another type of OrderedRealmCollection. A snapshot can be created from RealmResults or RealmList. A snapshot is backed by a snapshot of OS Results. So the snapshot itself wont be updated. The size and order stay the same forever (elements inside are still live objects.). Since the RealmResults is auto-updated all the time, snapshot will be usefull when changing the results in a simple loops. This commit also moves the common code from RealmResults to OrderedRealmCollectionImpl since those can be shared with snapshot implementation. Implement"
,,0.1615,realm-java,Add detailed notification for RealmObject (#4331) See Add ObjectChangeSet & RealmObjectChangeListener. Add OsObject to wrap ObjectStores Object for notifications. No more false positive notifications for RealmObject. Use ObserverPairList in ProxyState instead of normal list to solve the potential listener removal problems which is handled well by the ObserverPairList. Fix tests./findFirstAsync returns invalid row if no object Fix The findFirstAsync()s behavior doesnt match the javadoc from the first day the API was introduced. It kept running the query until it could find a row match the query condition. This behavior create difficulties if user want to check if there is no object in the db. Also it was not consistent with the behavior of findFirst() which will return an invalid row in the same condition./
,,0.1791,realm-java,"Remove some useless code for Table There are more could be removed if we remove JNITableTest./Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/Refactor Schemas into separate native and realm-based implementations (#4382) * Refactor Schemas into separate native and realm-based implementations * Fix all tests * Respond to PR comments * Temporary (git add .) kludge to fix visiblity problem/Add thread check to methods in RealmQuery. (#4257) * Throw IllegalStateException instead of process crash when any of thread confined methods in RealmQuery is called from wrong thread (#4228). * fix some bugs in test and remove methodParams * no need to add realm.checkIfValid(); to RealmQuery.isValid() * PR fixes * removed section header comments/"
,,0.0913,realm-java,Fine grained locks for RealmCache (#4551) Separated lock for different RealmConfiguration instead of one lock on the RealmCache class. So Opening Realm instances from different configurations wont block each other. DynamicRealm which is created during opening type Realm will not be associated to any RealmCache to avoid recursive locks and multiple times initial block. (Also make the code easier.) This is for and part of implementation of ./
,,0.2905,realm-java,"Introduce DynamicRealmObject#linkingObjects(String srcClassName, String srcFieldName) (#4492)/Refactor Schemas into separate native and realm-based implementations (#4382) * Refactor Schemas into separate native and realm-based implementations * Fix all tests * Respond to PR comments * Temporary (git add .) kludge to fix visiblity problem/Fixed element type checking in DynamicRealmOject#setList(). (#4254) * Fixed element type checking in DynamicRealmOject#setList() (#4252). * Update CHANGELOG.md * PR fixes * PR fixes/"
,,0.1317,realm-java,Add RealmObject.getRealm() and DynamicRealmObject.getDynamicRealm(). (#4778) * Add RealmObject.getConfiguration(RealmModel) (#4720). * revert a change in Realm.java * check exception message * Now RealmObject.getConfiguration(RealmModel) returns null if the model is unmanaged * add RealmObject.getConfiguration() * implement RealmObject#getRealm() and DynamicRealmObject#getDynamicRealm() * fix markup * remove empty tests * fix tests/
,,0.1263,realm-java,Add RealmObject.getRealm() and DynamicRealmObject.getDynamicRealm(). (#4778) * Add RealmObject.getConfiguration(RealmModel) (#4720). * revert a change in Realm.java * check exception message * Now RealmObject.getConfiguration(RealmModel) returns null if the model is unmanaged * add RealmObject.getConfiguration() * implement RealmObject#getRealm() and DynamicRealmObject#getDynamicRealm() * fix markup * remove empty tests * fix tests/
,,0.2275,realm-java,"Immutable RealmSchema and RealmObjectSchema (#5003) Before this change, Realm.getSchema() and DynamicRealm.getSchema() both return a mutable version RealmSchema object. That would cause issue when changing the typed Realms schema then continue to use typed inferface to access the Realm where the column indices might be changed already and had not been refreshed before the transaction commited. After this change: Realm.getSchema() returns an immutable RealmSchema object. And all RealmObjectSchema objects retrieved from that will be immutable as well./Converting nullable PK fields with null values (#4798) RealmObjectSchema.setRequired() will throw if the PK field has null values stored. Call set_xxx_unique when converting nullability on a PK field. Remove useless check in the proxy generator which caused inconsistency exception. Add relevant test cases./BLOBs default value when convert to not-nullable (#4794) """" is a char* type takes 1 byte of memory./"
,,0.0837,realm-java,"Refactor object creation into OsObject (#4632) Hide the addEmptyRow from java to support future stable ID. Add bulk insertion benchmark. This wont be the final design of internal object creation API, when integration of OS object accessor, the internal API might be changed a bit since it doesnt look nice at all 5 params for the JNI call to create an object with integer primary key/"
,,0.0634,realm-java,[Sync] Adding user account lookup (#4882)/Exponential Back Off now retry query in case of `ConnectionException` (#4805) * fixes
,,0.195,realm-java,More minor fixes to pave the way for fixing UTs/Add CompactOnLaunch. (#4857) * Implement CompactOnLaunch. This commit adds RealmConfiguration.compactOnLaunch and RealmConfiguration.Builder.compactOnLaunch(CompactOnLaunchCallback). It makes a Realm determines if it should be compacted. * Throw an exception if it is read-only Realm. * Add readOnly_compactOnLaunch_throws * Fix a wrong signature. * Add tests to check compactOnLaunch. * Fix tests. * Add Javadoc. * Updated CHANGELOG>md * Fix a typo * PR feedback. * PR feedback: Improve tests. * PR feedback. * Improve Javadocs sentences. * Support Proguard. * Rename more accurate. * PR feedback. * Fix Proguard. * Fix JNI code. * PR feedback: Remove 2 createConfiguration. * PR feedback * Add RealmConfiguration.Builder.compactOnLaunch(). * Fix a bug of JNI code. * Add more tests. * Improve Javadoc. * PR feedback: Add a test to check a bug. * add a test to check a bug where compactOnLaunch is called each time a Realm is opened on a new thread. * PR feedback * Imporve Javadoc. * Fix a test (Thread). * PR: fix a test./Support readOnly() on Configurations (#4575)/
,,0.0556,realm-java,Update to use MutableRealmIntegers (#5158)/
,,0.0697,realm-java,Support internal names for types in other compilation units (#5764)/
,,0.0818,realm-java,Better exception message if non model class is provided as function argument/
,,0.063,realm-java,Align Sync APIs with Cocoa (#5835)/
,,0.0849,realm-java,Fix extension check/Remove reliance on groovy in realm-transformer (#6025)/
,,0.0669,realm-java,Add support for custom headers for improved proxy support. (#6131)/
,,0.0689,realm-java,Add support for custom headers for improved proxy support. (#6131)/
,,0.2247,rocksdb,"Bugfix for issue 33; reduce lock contention in Get(), parallel benchmarks. Fix for issue 33 (non-null-terminated result from leveldb_property_value()) Support for running multiple instances of a benchmark in parallel. Reduce lock contention on Get(): (1) Do not hold the lock while searching memtables. (2) Shard block and table caches 16-ways. Benchmark for evaluating this change: $ db_bench (fillseq1 is a small hack to make sure fillseq runs once regardless of number of threads specified on the command line). git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/Speed up Snappy uncompression, new Logger interface. Removed one copy of an uncompressed block contents changing the signature of Snappy_Uncompress() so it uncompresses into a flat array instead of a std::string. Speeds up readrandom ~10%. Instead of a combination of Env/WritableFile, we now have a Logger interface that can be easily overridden applications that want to supply their own logging. Separated out the gcc and Sun Studio parts of atomic_pointer.h so we can use asm, volatile keywords for Sun Studio. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/A number of smaller fixes and performance improvements: Implemented Get() directly instead of building on top of a full merging iterator stack. This speeds up the ""readrandom"" benchmark by up to 15-30%. Fixed an opensource compilation problem. Added flag to control where the database is placed. Automatically compact a file when we have done enough overlapping seeks to that file. Fixed a performance bug where we would read from at least one file in a level even if none of the files overlapped the key being read. Makefile fix for Mac OSX installations that have XCode 4 without XCode 3. Unified the two occurrences of binary search in a file-list into one routine. Found and fixed a bug where we would unnecessarily search the last file when looking for a key larger than all data in the level. A fix to avoid the need for trivial move compactions and therefore gets rid of two out of five syncs in ""fillseq"". Removed the MANIFEST file write when switching to a new memtable/log-file for a 10-20% improvement on fill speed on ext4. Adding a SNAPPY setting in the Makefile for folks who have Snappy installed. Snappy compresses values and speeds up writes. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/"
,,0.2758,rocksdb,"A number of smaller fixes and performance improvements: Implemented Get() directly instead of building on top of a full merging iterator stack. This speeds up the ""readrandom"" benchmark by up to 15-30%. Fixed an opensource compilation problem. Added flag to control where the database is placed. Automatically compact a file when we have done enough overlapping seeks to that file. Fixed a performance bug where we would read from at least one file in a level even if none of the files overlapped the key being read. Makefile fix for Mac OSX installations that have XCode 4 without XCode 3. Unified the two occurrences of binary search in a file-list into one routine. Found and fixed a bug where we would unnecessarily search the last file when looking for a key larger than all data in the level. A fix to avoid the need for trivial move compactions and therefore gets rid of two out of five syncs in ""fillseq"". Removed the MANIFEST file write when switching to a new memtable/log-file for a 10-20% improvement on fill speed on ext4. Adding a SNAPPY setting in the Makefile for folks who have Snappy installed. Snappy compresses values and speeds up writes. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/"
,,0.24600000000000002,rocksdb,"A number of smaller fixes and performance improvements: Implemented Get() directly instead of building on top of a full merging iterator stack. This speeds up the ""readrandom"" benchmark by up to 15-30%. Fixed an opensource compilation problem. Added flag to control where the database is placed. Automatically compact a file when we have done enough overlapping seeks to that file. Fixed a performance bug where we would read from at least one file in a level even if none of the files overlapped the key being read. Makefile fix for Mac OSX installations that have XCode 4 without XCode 3. Unified the two occurrences of binary search in a file-list into one routine. Found and fixed a bug where we would unnecessarily search the last file when looking for a key larger than all data in the level. A fix to avoid the need for trivial move compactions and therefore gets rid of two out of five syncs in ""fillseq"". Removed the MANIFEST file write when switching to a new memtable/log-file for a 10-20% improvement on fill speed on ext4. Adding a SNAPPY setting in the Makefile for folks who have Snappy installed. Snappy compresses values and speeds up writes. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/sync with upstream Fixed race condition reported by Dave Smit on the leveldb mailing list. We were not signalling waiters after a trivial move from level-0. The result was that in some cases (hard to reproduce), a write would get stuck forever waiting for the number of level-0 files to drop below its hard limit. The new code is simpler: there is just one condition variable instead of two, and the condition variable is signalled after every piece of background work finishes. Also, all compaction work (including for manual compactions) is done in the background thread, and therefore we can remove the ""compacting_"" variable. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/"
,,0.2878,rocksdb,"A number of smaller fixes and performance improvements: Implemented Get() directly instead of building on top of a full merging iterator stack. This speeds up the ""readrandom"" benchmark by up to 15-30%. Fixed an opensource compilation problem. Added flag to control where the database is placed. Automatically compact a file when we have done enough overlapping seeks to that file. Fixed a performance bug where we would read from at least one file in a level even if none of the files overlapped the key being read. Makefile fix for Mac OSX installations that have XCode 4 without XCode 3. Unified the two occurrences of binary search in a file-list into one routine. Found and fixed a bug where we would unnecessarily search the last file when looking for a key larger than all data in the level. A fix to avoid the need for trivial move compactions and therefore gets rid of two out of five syncs in ""fillseq"". Removed the MANIFEST file write when switching to a new memtable/log-file for a 10-20% improvement on fill speed on ext4. Adding a SNAPPY setting in the Makefile for folks who have Snappy installed. Snappy compresses values and speeds up writes. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/"
,,0.2868,rocksdb,"A number of smaller fixes and performance improvements: Implemented Get() directly instead of building on top of a full merging iterator stack. This speeds up the ""readrandom"" benchmark by up to 15-30%. Fixed an opensource compilation problem. Added flag to control where the database is placed. Automatically compact a file when we have done enough overlapping seeks to that file. Fixed a performance bug where we would read from at least one file in a level even if none of the files overlapped the key being read. Makefile fix for Mac OSX installations that have XCode 4 without XCode 3. Unified the two occurrences of binary search in a file-list into one routine. Found and fixed a bug where we would unnecessarily search the last file when looking for a key larger than all data in the level. A fix to avoid the need for trivial move compactions and therefore gets rid of two out of five syncs in ""fillseq"". Removed the MANIFEST file write when switching to a new memtable/log-file for a 10-20% improvement on fill speed on ext4. Adding a SNAPPY setting in the Makefile for folks who have Snappy installed. Snappy compresses values and speeds up writes. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/"
,,0.2878,rocksdb,"A number of smaller fixes and performance improvements: Implemented Get() directly instead of building on top of a full merging iterator stack. This speeds up the ""readrandom"" benchmark by up to 15-30%. Fixed an opensource compilation problem. Added flag to control where the database is placed. Automatically compact a file when we have done enough overlapping seeks to that file. Fixed a performance bug where we would read from at least one file in a level even if none of the files overlapped the key being read. Makefile fix for Mac OSX installations that have XCode 4 without XCode 3. Unified the two occurrences of binary search in a file-list into one routine. Found and fixed a bug where we would unnecessarily search the last file when looking for a key larger than all data in the level. A fix to avoid the need for trivial move compactions and therefore gets rid of two out of five syncs in ""fillseq"". Removed the MANIFEST file write when switching to a new memtable/log-file for a 10-20% improvement on fill speed on ext4. Adding a SNAPPY setting in the Makefile for folks who have Snappy installed. Snappy compresses values and speeds up writes. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/"
,,0.2046,rocksdb,"Small tweaks and bugfixes for Issue 18 and 19. Slight tweak to the no-overlap optimization: only push to level 2 to reduce the amount of wasted space when the same small key range is being repeatedly overwritten. Fix for Issue 18: Avoid failure on Windows by avoiding deletion of lock file until the end of DestroyDB(). Fix for Issue 19: Disregard sequence numbers when checking for overlap in sstable ranges. This fixes issue 19: when writing the same key over and over again, we would generate a sequence of sstables that were never merged together since their sequence numbers were disjoint. Dont ignore map/unmap error checks. Miscellaneous fixes for small problems Sanjay found while diagnosing issue/9 and issue/16 (corruption_testr failures). log::Reader reports the record type when it finds an unexpected type. log::Reader no longer reports an error when it encounters an expected zero record regardless of the setting of the ""checksum"" flag. Added a missing forward declaration. Documented a side-effects of larger write buffer sizes (longer recovery time). git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/A number of smaller fixes and performance improvements: Implemented Get() directly instead of building on top of a full merging iterator stack. This speeds up the ""readrandom"" benchmark by up to 15-30%. Fixed an opensource compilation problem. Added flag to control where the database is placed. Automatically compact a file when we have done enough overlapping seeks to that file. Fixed a performance bug where we would read from at least one file in a level even if none of the files overlapped the key being read. Makefile fix for Mac OSX installations that have XCode 4 without XCode 3. Unified the two occurrences of binary search in a file-list into one routine. Found and fixed a bug where we would unnecessarily search the last file when looking for a key larger than all data in the level. A fix to avoid the need for trivial move compactions and therefore gets rid of two out of five syncs in ""fillseq"". Removed the MANIFEST file write when switching to a new memtable/log-file for a 10-20% improvement on fill speed on ext4. Adding a SNAPPY setting in the Makefile for folks who have Snappy installed. Snappy compresses values and speeds up writes. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/"
,,0.2868,rocksdb,"A number of smaller fixes and performance improvements: Implemented Get() directly instead of building on top of a full merging iterator stack. This speeds up the ""readrandom"" benchmark by up to 15-30%. Fixed an opensource compilation problem. Added flag to control where the database is placed. Automatically compact a file when we have done enough overlapping seeks to that file. Fixed a performance bug where we would read from at least one file in a level even if none of the files overlapped the key being read. Makefile fix for Mac OSX installations that have XCode 4 without XCode 3. Unified the two occurrences of binary search in a file-list into one routine. Found and fixed a bug where we would unnecessarily search the last file when looking for a key larger than all data in the level. A fix to avoid the need for trivial move compactions and therefore gets rid of two out of five syncs in ""fillseq"". Removed the MANIFEST file write when switching to a new memtable/log-file for a 10-20% improvement on fill speed on ext4. Adding a SNAPPY setting in the Makefile for folks who have Snappy installed. Snappy compresses values and speeds up writes. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/"
,,0.2858,rocksdb,"A number of smaller fixes and performance improvements: Implemented Get() directly instead of building on top of a full merging iterator stack. This speeds up the ""readrandom"" benchmark by up to 15-30%. Fixed an opensource compilation problem. Added flag to control where the database is placed. Automatically compact a file when we have done enough overlapping seeks to that file. Fixed a performance bug where we would read from at least one file in a level even if none of the files overlapped the key being read. Makefile fix for Mac OSX installations that have XCode 4 without XCode 3. Unified the two occurrences of binary search in a file-list into one routine. Found and fixed a bug where we would unnecessarily search the last file when looking for a key larger than all data in the level. A fix to avoid the need for trivial move compactions and therefore gets rid of two out of five syncs in ""fillseq"". Removed the MANIFEST file write when switching to a new memtable/log-file for a 10-20% improvement on fill speed on ext4. Adding a SNAPPY setting in the Makefile for folks who have Snappy installed. Snappy compresses values and speeds up writes. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/"
,,0.0597,rocksdb,Commit both PR and internal code review changes/
,,0.0618,rocksdb,Commit both PR and internal code review changes/
,,0.0577,rocksdb,Commit both PR and internal code review changes/
,,0.0577,rocksdb,Commit both PR and internal code review changes/
,,0.3001,rocksdb,"Fixed compile warning in rocksdbjava Summary: Fixed the following compile warning in rocksdbjava: java/rocksjni/comparatorjnicallback.cc:20:14: warning: unused variable ërsí [-Wunused-variable] const jint rs env->GetJavaVM(&m_jvm); ^ java/rocksjni/comparatorjnicallback.cc: In member function ëJNIEnv* rocksdb::BaseComparatorJniCallback::getJniEnv() constí: java/rocksjni/comparatorjnicallback.cc:45:8: warning: unused variable ërsí [-Wunused-variable] jint rs m_jvm->AttachCurrentThread(reinterpret_cast<void **>(&env), NULL); ^ java/rocksjni/loggerjnicallback.cc: In constructor ërocksdb::LoggerJniCallback::LoggerJniCallback(JNIEnv*, jobject)í: java/rocksjni/loggerjnicallback.cc:19:14: warning: unused variable ërsí [-Wunused-variable] const jint rs env->GetJavaVM(&m_jvm); ^ java/rocksjni/loggerjnicallback.cc: In member function ëJNIEnv* rocksdb::LoggerJniCallback::getJniEnv() constí: java/rocksjni/loggerjnicallback.cc:33:8: warning: unused variable ërsí [-Wunused-variable] jint rs m_jvm->AttachCurrentThread(reinterpret_cast<void **>(&env), NULL); ^ Test Plan: make rocksdbjava Reviewers: sdong, anthony, IslamAbdelRahman, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision:"
,,0.3143,rocksdb,"Fixed a compile warning in rocksjni/loggerjnicallback.cc Summary: This patch fixes the following compile warning. java/rocksjni/loggerjnicallback.cc: In constructor ërocksdb::LoggerJniCallback::LoggerJniCallback(JNIEnv*, jobject)í: java/rocksjni/loggerjnicallback.cc:19:14: warning: unused variable ërsí [-Wunused-variable] const jint rs env->GetJavaVM(&m_jvm); ^ Test Plan: make rocksdbjavastaticrelease Reviewers: sdong, anthony, IslamAbdelRahman, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision: compile warning in rocksdbjava Summary: Fixed the following compile warning in rocksdbjava: java/rocksjni/comparatorjnicallback.cc:20:14: warning: unused variable ërsí [-Wunused-variable] const jint rs env->GetJavaVM(&m_jvm); ^ java/rocksjni/comparatorjnicallback.cc: In member function ëJNIEnv* rocksdb::BaseComparatorJniCallback::getJniEnv() constí: java/rocksjni/comparatorjnicallback.cc:45:8: warning: unused variable ërsí [-Wunused-variable] jint rs m_jvm->AttachCurrentThread(reinterpret_cast<void **>(&env), NULL); ^ java/rocksjni/loggerjnicallback.cc: In constructor ërocksdb::LoggerJniCallback::LoggerJniCallback(JNIEnv*, jobject)í: java/rocksjni/loggerjnicallback.cc:19:14: warning: unused variable ërsí [-Wunused-variable] const jint rs env->GetJavaVM(&m_jvm); ^ java/rocksjni/loggerjnicallback.cc: In member function ëJNIEnv* rocksdb::LoggerJniCallback::getJniEnv() constí: java/rocksjni/loggerjnicallback.cc:33:8: warning: unused variable ërsí [-Wunused-variable] jint rs m_jvm->AttachCurrentThread(reinterpret_cast<void **>(&env), NULL); ^ Test Plan: make rocksdbjava Reviewers: sdong, anthony, IslamAbdelRahman, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision:"
,,0.3636,rocksdb,"WritePrepared Txn: Refactor conf params Summary: Summary of changes: Move seq_per_batch out of Options Rename concurrent_prepare to two_write_queues Add allocate_seq_only_for_data_ Closes Differential Revision: D6304458 Pulled By: maysamyabandeh fbshipit-source-id: 08e685bfa82bbc41b5b1c5eb7040a8ca6e05e58c/Added support for differential snapshots Summary: The motivation for this PR is to add to RocksDB support for differential (incremental) snapshots, as snapshot of the DB changes between two points in time (one can think of it as diff between to sequence numbers, or the diff D which can be thought of as an SST file or just set of KVs that can be applied to sequence number S1 to get the database to the state at sequence number S2). This feature would be useful for various distributed storages layers built on top of RocksDB, as it should help reduce resources (time and network bandwidth) needed to recover and rebuilt DB instances as replicas in the context of distributed storages. From the API standpoint that would like client app requesting iterator between (start seqnum) and current DB state, and reading the ""diff"". This is a very draft PR for initial review in the discussion on the approach, im going to rework some parts and keep updating the PR. For now, whats done here according to initial discussions: Preserving deletes: We want to be able to optionally preserve recent deletes for some defined period of time, so that if a delete came in recently and might need to be included in the next incremental snapshot it wouldt get dropped by a compaction. This is done by adding new param to Options (preserve deletes flag) and new variable to DB Impl where we keep track of the sequence number after which we dont want to drop tombstones, even if they are otherwise eligible for deletion. I also added a new API call for clients to be able to advance this cutoff seqnum after which we drop deletes; i assume its more flexible to let clients control this, since otherwise wed need to keep some kind of timestamp > seqnum mapping inside the DB, which sounds messy and painful to support. Clients could make use of it by periodically calling GetLatestSequenceNumber(), noting the timestamp, doing some calculation and figuring out by how much we need to advance the cutoff seqnum. Compaction codepath in compaction_iterator.cc has been modified to avoid dropping tombstones with seqnum > cutoff seqnum. Iterator changes: couple params added to ReadOptions, to optionally allow client to request internal keys instead of user keys (so that client can get the latest value of a key, be it delete marker or a put), as well as min timestamp and min seqnum. TableCache changes: I modified table_cache code to be able to quickly exclude SST files from iterators heep if creation_time on the file is less then iter_start_ts as passed in ReadOptions. That would help a lot in some DB settings (like reading very recent data only or using FIFO compactions), but not so much for universal compaction with more or less long iterator time span. Whats left: Still looking at how to best plug that inside DBIter codepath. So far it seems that FindNextUserKeyInternal only parses values as UserKeys, and iter->key() call generally returns user key. Can we add new API to DBIter as internal_key(), and modify this internal method to optionally set saved_key_ to point to the full internal key? I dont need to store actual seqnum there, but I do need to store type. Closes Differential Revision: D6175602 Pulled By: mikhail-antonov fbshipit-source-id: c779a6696ee2d574d86c69cec866a3ae095aa900/Make writable_file_max_buffer_size dynamic Summary: The DBOptions::writable_file_max_buffer_size can be changed dynamically. Closes Differential Revision: D6152720 Pulled By: shligit fbshipit-source-id: aa0c0cfcfae6a54eb17faadb148d904797c68681/Make FIFO compaction options dynamically configurable Summary: ColumnFamilyOptions::compaction_options_fifo and all its sub-fields can be set dynamically now. Some of the ways in which the fifo compaction options can be set are: `SetOptions({{""compaction_options_fifo"", ""{max_table_files_size=1024}""}})` `SetOptions({{""compaction_options_fifo"", ""{ttl=600;}""}})` `SetOptions({{""compaction_options_fifo"", ""{max_table_files_size=1024;ttl=600;}""}})` `SetOptions({{""compaction_options_fifo"", ""{max_table_files_size=51;ttl=49;allow_compaction=true;}""}})` Most of the code has been made generic enough so that it could be reused later to make universal options (and other such nested defined-types) dynamic with very few lines of parsing/serializing code changes. Introduced a few new functions like `ParseStruct`, `SerializeStruct` and `GetStringFromStruct`. The duplicate code in `GetStringFromDBOptions` and `GetStringFromColumnFamilyOptions` has been moved into `GetStringFromStruct`. So they become just simple wrappers now. Closes Differential Revision: D6058619 Pulled By: sagar0 fbshipit-source-id: 1e8f78b3374ca5249bb4f3be8a6d3bb4cbc52f92/fix lite build Summary: * make `checksum_type_string_map` available for lite * comment out `FilesPerLevel` in lite mode. * travis and legocastle lite build also build `all` target and run tests Closes Differential Revision: D6069822 Pulled By: yiwu-arbug fbshipit-source-id: 9fe92ac220e711e9e6ed4e921bd25ef4314796a0/Allow upgrades from nullptr to some merge operator Summary: Currently, RocksDB does not allow reopening a preexisting DB with no merge operator defined, with a merge operator defined. This means that if a DB ever want to add a merge operator, theres no way to do so currently. Fix this by adding a new verification type `kByNameAllowFromNull` which will allow old values to be nullptr, and new values to be non-nullptr. Closes Differential Revision: D5961131 Pulled By: lth fbshipit-source-id: 06179bebd0d90db3d43690b5eb7345e2d5bab1eb/Make bytes_per_sync and wal_bytes_per_sync mutable Summary: SUMMARY Moves the bytes_per_sync and wal_bytes_per_sync options from immutableoptions to mutable options. Also if wal_bytes_per_sync is changed, the wal file and memtables are flushed. TEST PLAN ran make check all passed Two new tests SetBytesPerSync, SetWalBytesPerSync check that after issuing setoptions with a new value for the var, the db options have the new value. Closes Reviewed By: yiwu-arbug Differential Revision: D5845814 Pulled By: TheRushingWookie fbshipit-source-id: 93b52d779ce623691b546679dcd984a06d2ad1bd/WritePrepared Txn: Advance seq one per batch Summary: By default the seq number in DB is increased once per written key. WritePrepared txns requires the seq to be increased once per the entire batch so that the seq would be used as the prepare timestamp by which the transaction is identified. Also we need to increase seq for the commit marker since it would give a unique id to the commit timestamp of transactions. Two unit tests are added to verify our understanding of how the seq should be increased. The recovery path requires much more work and is left to another patch. Closes Differential Revision: D5837843 Pulled By: maysamyabandeh fbshipit-source-id: a08960b93d727e1cf438c254d0c2636fb133cc1c/regression test for missing init options Summary: test the `DBOptions(const Options&)` and `ColumnFamilyOptions(const Options&)` constructors. Actually thisll work better once we refactor `RandomInitDBOptions` / `RandomInitCFOptions` to use the authoritative sources of struct members: `db_options_type_info` / `cf_options_type_info` (internal task T21804189 for this). Closes Differential Revision: D5817141 Pulled By: ajkr fbshipit-source-id: 8567c20feced9d1751fdf1f4383e2af30f7e3591/"
,,0.5328,rocksdb,"Added support for differential snapshots Summary: The motivation for this PR is to add to RocksDB support for differential (incremental) snapshots, as snapshot of the DB changes between two points in time (one can think of it as diff between to sequence numbers, or the diff D which can be thought of as an SST file or just set of KVs that can be applied to sequence number S1 to get the database to the state at sequence number S2). This feature would be useful for various distributed storages layers built on top of RocksDB, as it should help reduce resources (time and network bandwidth) needed to recover and rebuilt DB instances as replicas in the context of distributed storages. From the API standpoint that would like client app requesting iterator between (start seqnum) and current DB state, and reading the ""diff"". This is a very draft PR for initial review in the discussion on the approach, im going to rework some parts and keep updating the PR. For now, whats done here according to initial discussions: Preserving deletes: We want to be able to optionally preserve recent deletes for some defined period of time, so that if a delete came in recently and might need to be included in the next incremental snapshot it wouldt get dropped by a compaction. This is done by adding new param to Options (preserve deletes flag) and new variable to DB Impl where we keep track of the sequence number after which we dont want to drop tombstones, even if they are otherwise eligible for deletion. I also added a new API call for clients to be able to advance this cutoff seqnum after which we drop deletes; i assume its more flexible to let clients control this, since otherwise wed need to keep some kind of timestamp > seqnum mapping inside the DB, which sounds messy and painful to support. Clients could make use of it by periodically calling GetLatestSequenceNumber(), noting the timestamp, doing some calculation and figuring out by how much we need to advance the cutoff seqnum. Compaction codepath in compaction_iterator.cc has been modified to avoid dropping tombstones with seqnum > cutoff seqnum. Iterator changes: couple params added to ReadOptions, to optionally allow client to request internal keys instead of user keys (so that client can get the latest value of a key, be it delete marker or a put), as well as min timestamp and min seqnum. TableCache changes: I modified table_cache code to be able to quickly exclude SST files from iterators heep if creation_time on the file is less then iter_start_ts as passed in ReadOptions. That would help a lot in some DB settings (like reading very recent data only or using FIFO compactions), but not so much for universal compaction with more or less long iterator time span. Whats left: Still looking at how to best plug that inside DBIter codepath. So far it seems that FindNextUserKeyInternal only parses values as UserKeys, and iter->key() call generally returns user key. Can we add new API to DBIter as internal_key(), and modify this internal method to optionally set saved_key_ to point to the full internal key? I dont need to store actual seqnum there, but I do need to store type. Closes Differential Revision: D6175602 Pulled By: mikhail-antonov fbshipit-source-id: c779a6696ee2d574d86c69cec866a3ae095aa900/"
,,0.1359,rocksdb,"Make bytes_per_sync and wal_bytes_per_sync mutable Summary: SUMMARY Moves the bytes_per_sync and wal_bytes_per_sync options from immutableoptions to mutable options. Also if wal_bytes_per_sync is changed, the wal file and memtables are flushed. TEST PLAN ran make check all passed Two new tests SetBytesPerSync, SetWalBytesPerSync check that after issuing setoptions with a new value for the var, the db options have the new value. Closes Reviewed By: yiwu-arbug Differential Revision: D5845814 Pulled By: TheRushingWookie fbshipit-source-id: 93b52d779ce623691b546679dcd984a06d2ad1bd/"
,,0.5423,rocksdb,"Added support for differential snapshots Summary: The motivation for this PR is to add to RocksDB support for differential (incremental) snapshots, as snapshot of the DB changes between two points in time (one can think of it as diff between to sequence numbers, or the diff D which can be thought of as an SST file or just set of KVs that can be applied to sequence number S1 to get the database to the state at sequence number S2). This feature would be useful for various distributed storages layers built on top of RocksDB, as it should help reduce resources (time and network bandwidth) needed to recover and rebuilt DB instances as replicas in the context of distributed storages. From the API standpoint that would like client app requesting iterator between (start seqnum) and current DB state, and reading the ""diff"". This is a very draft PR for initial review in the discussion on the approach, im going to rework some parts and keep updating the PR. For now, whats done here according to initial discussions: Preserving deletes: We want to be able to optionally preserve recent deletes for some defined period of time, so that if a delete came in recently and might need to be included in the next incremental snapshot it wouldt get dropped by a compaction. This is done by adding new param to Options (preserve deletes flag) and new variable to DB Impl where we keep track of the sequence number after which we dont want to drop tombstones, even if they are otherwise eligible for deletion. I also added a new API call for clients to be able to advance this cutoff seqnum after which we drop deletes; i assume its more flexible to let clients control this, since otherwise wed need to keep some kind of timestamp > seqnum mapping inside the DB, which sounds messy and painful to support. Clients could make use of it by periodically calling GetLatestSequenceNumber(), noting the timestamp, doing some calculation and figuring out by how much we need to advance the cutoff seqnum. Compaction codepath in compaction_iterator.cc has been modified to avoid dropping tombstones with seqnum > cutoff seqnum. Iterator changes: couple params added to ReadOptions, to optionally allow client to request internal keys instead of user keys (so that client can get the latest value of a key, be it delete marker or a put), as well as min timestamp and min seqnum. TableCache changes: I modified table_cache code to be able to quickly exclude SST files from iterators heep if creation_time on the file is less then iter_start_ts as passed in ReadOptions. That would help a lot in some DB settings (like reading very recent data only or using FIFO compactions), but not so much for universal compaction with more or less long iterator time span. Whats left: Still looking at how to best plug that inside DBIter codepath. So far it seems that FindNextUserKeyInternal only parses values as UserKeys, and iter->key() call generally returns user key. Can we add new API to DBIter as internal_key(), and modify this internal method to optionally set saved_key_ to point to the full internal key? I dont need to store actual seqnum there, but I do need to store type. Closes Differential Revision: D6175602 Pulled By: mikhail-antonov fbshipit-source-id: c779a6696ee2d574d86c69cec866a3ae095aa900/"
,,0.3444,rocksdb,"Added support for differential snapshots Summary: The motivation for this PR is to add to RocksDB support for differential (incremental) snapshots, as snapshot of the DB changes between two points in time (one can think of it as diff between to sequence numbers, or the diff D which can be thought of as an SST file or just set of KVs that can be applied to sequence number S1 to get the database to the state at sequence number S2). This feature would be useful for various distributed storages layers built on top of RocksDB, as it should help reduce resources (time and network bandwidth) needed to recover and rebuilt DB instances as replicas in the context of distributed storages. From the API standpoint that would like client app requesting iterator between (start seqnum) and current DB state, and reading the ""diff"". This is a very draft PR for initial review in the discussion on the approach, im going to rework some parts and keep updating the PR. For now, whats done here according to initial discussions: Preserving deletes: We want to be able to optionally preserve recent deletes for some defined period of time, so that if a delete came in recently and might need to be included in the next incremental snapshot it wouldt get dropped by a compaction. This is done by adding new param to Options (preserve deletes flag) and new variable to DB Impl where we keep track of the sequence number after which we dont want to drop tombstones, even if they are otherwise eligible for deletion. I also added a new API call for clients to be able to advance this cutoff seqnum after which we drop deletes; i assume its more flexible to let clients control this, since otherwise wed need to keep some kind of timestamp > seqnum mapping inside the DB, which sounds messy and painful to support. Clients could make use of it by periodically calling GetLatestSequenceNumber(), noting the timestamp, doing some calculation and figuring out by how much we need to advance the cutoff seqnum. Compaction codepath in compaction_iterator.cc has been modified to avoid dropping tombstones with seqnum > cutoff seqnum. Iterator changes: couple params added to ReadOptions, to optionally allow client to request internal keys instead of user keys (so that client can get the latest value of a key, be it delete marker or a put), as well as min timestamp and min seqnum. TableCache changes: I modified table_cache code to be able to quickly exclude SST files from iterators heep if creation_time on the file is less then iter_start_ts as passed in ReadOptions. That would help a lot in some DB settings (like reading very recent data only or using FIFO compactions), but not so much for universal compaction with more or less long iterator time span. Whats left: Still looking at how to best plug that inside DBIter codepath. So far it seems that FindNextUserKeyInternal only parses values as UserKeys, and iter->key() call generally returns user key. Can we add new API to DBIter as internal_key(), and modify this internal method to optionally set saved_key_ to point to the full internal key? I dont need to store actual seqnum there, but I do need to store type. Closes Differential Revision: D6175602 Pulled By: mikhail-antonov fbshipit-source-id: c779a6696ee2d574d86c69cec866a3ae095aa900/single-file bottom-level compaction when snapshot released Summary: When snapshots are held for a long time, files may reach the bottom level containing overwritten/deleted keys. We previously had no mechanism to trigger compaction on such files. This particularly impacted DBs that write to different parts of the keyspace over time, as such files would never be naturally compacted due to second-last level files moving down. This PR introduces a mechanism for bottommost files to be recompacted upon releasing all snapshots that prevent them from dropping their deleted/overwritten keys. Changed `CompactionPicker` to compact files in `BottommostFilesMarkedForCompaction()`. These are the last choice when picking. Each file will be compacted alone and output to the same level in which it originated. The goal of this type of compaction is to rewrite the data excluding deleted/overwritten keys. Changed `ReleaseSnapshot()` to recompute the bottom files marked for compaction when the oldest existing snapshot changes, and schedule a compaction if needed. We cache the value that oldest existing snapshot needs to exceed in order for another file to be marked in `bottommost_files_mark_threshold_`, which allows us to avoid recomputing marked files for most snapshot releases. Changed `VersionStorageInfo` to track the list of bottommost files, which is recomputed every time the version changes by `UpdateBottommostFiles()`. The list of marked bottommost files is first computed in `ComputeBottommostFilesMarkedForCompaction()` when the version changes, but may also be recomputed when `ReleaseSnapshot()` is called. Extracted core logic of `Compaction::IsBottommostLevel()` into `VersionStorageInfo::RangeMightExistAfterSortedRun()` since logic to check whether a file is bottommost is now necessary outside of compaction. Closes Differential Revision: D6062044 Pulled By: ajkr fbshipit-source-id: 123d201cf140715a7d5928e8b3cb4f9cd9f7ad21/fix hanging after CompactFiles with L0 overlap Summary: Bug report: Non-empty `level0_compactions_in_progress_` was aborting `CompactFiles` after incrementing `bg_compaction_scheduled_`, and in that case we never decremented it. This blocked future compactions and prevented DB close as we wait for scheduled compactions to finish/abort during close. I eliminated `CompactFiles`s dependency on `level0_compactions_in_progress_`. Since it takes a contiguous span of L0 files through the last L0 file if any L1+ files are included its fine to run in parallel with other compactions involving L0. We make the same assumption in intra-L0 compaction. Closes Differential Revision: D5780440 Pulled By: ajkr fbshipit-source-id: 15b15d3faf5a699aed4b82a58352d4a7bb23e027/add counter for deletion dropping optimization Summary: add this counter stat to track usage of deletion-dropping optimization. if usage is low, we can delete it to prevent bugs like Closes Differential Revision: D5665421 Pulled By: ajkr fbshipit-source-id: 881befa2d199838dac88709e7b376a43d304e3d4/"
,,0.1359,rocksdb,"Make bytes_per_sync and wal_bytes_per_sync mutable Summary: SUMMARY Moves the bytes_per_sync and wal_bytes_per_sync options from immutableoptions to mutable options. Also if wal_bytes_per_sync is changed, the wal file and memtables are flushed. TEST PLAN ran make check all passed Two new tests SetBytesPerSync, SetWalBytesPerSync check that after issuing setoptions with a new value for the var, the db options have the new value. Closes Reviewed By: yiwu-arbug Differential Revision: D5845814 Pulled By: TheRushingWookie fbshipit-source-id: 93b52d779ce623691b546679dcd984a06d2ad1bd/"
,,0.1888,rocksdb,"WritePrepared Txn: Disable GC during recovery Summary: Disables GC during recovery of a WritePrepared txn db to avoid GCing uncommitted key values. Closes Differential Revision: D6000191 Pulled By: maysamyabandeh fbshipit-source-id: fc4d522c643d24ebf043f811fe4ecd0dd0294675/WritePrepared Txn: Compaction/Flush Summary: Update Compaction/Flush to support WritePreparedTxnDB: Add SnapshotChecker which is a proxy to query WritePreparedTxnDB::IsInSnapshot. Pass SnapshotChecker to DBImpl on WritePreparedTxnDB open. CompactionIterator use it to check if a key has been committed and if it is visible to a snapshot. In CompactionIterator: * check if key has been committed. If not, output uncommitted keys AS-IS. * use SnapshotChecker to check if key is visible to a snapshot when in need. * do not output key with seq 0 if the key is not committed. Closes Differential Revision: D5902907 Pulled By: yiwu-arbug fbshipit-source-id: 945e037fdf0aa652dc5ba0ad879461040baa0320/Inform caller when rocksdb is stalling writes Summary: Add a new function in Listener to let the caller know when rocksdb is stalling writes. Closes Differential Revision: D5860124 Pulled By: schischi fbshipit-source-id: ee791606169aa64f772c86f817cebf02624e05e1/Make bytes_per_sync and wal_bytes_per_sync mutable Summary: SUMMARY Moves the bytes_per_sync and wal_bytes_per_sync options from immutableoptions to mutable options. Also if wal_bytes_per_sync is changed, the wal file and memtables are flushed. TEST PLAN ran make check all passed Two new tests SetBytesPerSync, SetWalBytesPerSync check that after issuing setoptions with a new value for the var, the db options have the new value. Closes Reviewed By: yiwu-arbug Differential Revision: D5845814 Pulled By: TheRushingWookie fbshipit-source-id: 93b52d779ce623691b546679dcd984a06d2ad1bd/"
,,0.5206,rocksdb,"Added support for differential snapshots Summary: The motivation for this PR is to add to RocksDB support for differential (incremental) snapshots, as snapshot of the DB changes between two points in time (one can think of it as diff between to sequence numbers, or the diff D which can be thought of as an SST file or just set of KVs that can be applied to sequence number S1 to get the database to the state at sequence number S2). This feature would be useful for various distributed storages layers built on top of RocksDB, as it should help reduce resources (time and network bandwidth) needed to recover and rebuilt DB instances as replicas in the context of distributed storages. From the API standpoint that would like client app requesting iterator between (start seqnum) and current DB state, and reading the ""diff"". This is a very draft PR for initial review in the discussion on the approach, im going to rework some parts and keep updating the PR. For now, whats done here according to initial discussions: Preserving deletes: We want to be able to optionally preserve recent deletes for some defined period of time, so that if a delete came in recently and might need to be included in the next incremental snapshot it wouldt get dropped by a compaction. This is done by adding new param to Options (preserve deletes flag) and new variable to DB Impl where we keep track of the sequence number after which we dont want to drop tombstones, even if they are otherwise eligible for deletion. I also added a new API call for clients to be able to advance this cutoff seqnum after which we drop deletes; i assume its more flexible to let clients control this, since otherwise wed need to keep some kind of timestamp > seqnum mapping inside the DB, which sounds messy and painful to support. Clients could make use of it by periodically calling GetLatestSequenceNumber(), noting the timestamp, doing some calculation and figuring out by how much we need to advance the cutoff seqnum. Compaction codepath in compaction_iterator.cc has been modified to avoid dropping tombstones with seqnum > cutoff seqnum. Iterator changes: couple params added to ReadOptions, to optionally allow client to request internal keys instead of user keys (so that client can get the latest value of a key, be it delete marker or a put), as well as min timestamp and min seqnum. TableCache changes: I modified table_cache code to be able to quickly exclude SST files from iterators heep if creation_time on the file is less then iter_start_ts as passed in ReadOptions. That would help a lot in some DB settings (like reading very recent data only or using FIFO compactions), but not so much for universal compaction with more or less long iterator time span. Whats left: Still looking at how to best plug that inside DBIter codepath. So far it seems that FindNextUserKeyInternal only parses values as UserKeys, and iter->key() call generally returns user key. Can we add new API to DBIter as internal_key(), and modify this internal method to optionally set saved_key_ to point to the full internal key? I dont need to store actual seqnum there, but I do need to store type. Closes Differential Revision: D6175602 Pulled By: mikhail-antonov fbshipit-source-id: c779a6696ee2d574d86c69cec866a3ae095aa900/WritePrepared Txn: Compaction/Flush Summary: Update Compaction/Flush to support WritePreparedTxnDB: Add SnapshotChecker which is a proxy to query WritePreparedTxnDB::IsInSnapshot. Pass SnapshotChecker to DBImpl on WritePreparedTxnDB open. CompactionIterator use it to check if a key has been committed and if it is visible to a snapshot. In CompactionIterator: * check if key has been committed. If not, output uncommitted keys AS-IS. * use SnapshotChecker to check if key is visible to a snapshot when in need. * do not output key with seq 0 if the key is not committed. Closes Differential Revision: D5902907 Pulled By: yiwu-arbug fbshipit-source-id: 945e037fdf0aa652dc5ba0ad879461040baa0320/Make bytes_per_sync and wal_bytes_per_sync mutable Summary: SUMMARY Moves the bytes_per_sync and wal_bytes_per_sync options from immutableoptions to mutable options. Also if wal_bytes_per_sync is changed, the wal file and memtables are flushed. TEST PLAN ran make check all passed Two new tests SetBytesPerSync, SetWalBytesPerSync check that after issuing setoptions with a new value for the var, the db options have the new value. Closes Reviewed By: yiwu-arbug Differential Revision: D5845814 Pulled By: TheRushingWookie fbshipit-source-id: 93b52d779ce623691b546679dcd984a06d2ad1bd/"
,,0.1332,rocksdb,"Make writable_file_max_buffer_size dynamic Summary: The DBOptions::writable_file_max_buffer_size can be changed dynamically. Closes Differential Revision: D6152720 Pulled By: shligit fbshipit-source-id: aa0c0cfcfae6a54eb17faadb148d904797c68681/Make bytes_per_sync and wal_bytes_per_sync mutable Summary: SUMMARY Moves the bytes_per_sync and wal_bytes_per_sync options from immutableoptions to mutable options. Also if wal_bytes_per_sync is changed, the wal file and memtables are flushed. TEST PLAN ran make check all passed Two new tests SetBytesPerSync, SetWalBytesPerSync check that after issuing setoptions with a new value for the var, the db options have the new value. Closes Reviewed By: yiwu-arbug Differential Revision: D5845814 Pulled By: TheRushingWookie fbshipit-source-id: 93b52d779ce623691b546679dcd984a06d2ad1bd/"
,,0.4209,rocksdb,"Blob DB: Add compaction filter to remove expired blob index entries Summary: After adding expiration to blob index in we are now able to add a compaction filter to cleanup expired blob index entries. Closes Differential Revision: D6183812 Pulled By: yiwu-arbug fbshipit-source-id: 9cb03267a9702975290e758c9c176a2c03530b83/Added support for differential snapshots Summary: The motivation for this PR is to add to RocksDB support for differential (incremental) snapshots, as snapshot of the DB changes between two points in time (one can think of it as diff between to sequence numbers, or the diff D which can be thought of as an SST file or just set of KVs that can be applied to sequence number S1 to get the database to the state at sequence number S2). This feature would be useful for various distributed storages layers built on top of RocksDB, as it should help reduce resources (time and network bandwidth) needed to recover and rebuilt DB instances as replicas in the context of distributed storages. From the API standpoint that would like client app requesting iterator between (start seqnum) and current DB state, and reading the ""diff"". This is a very draft PR for initial review in the discussion on the approach, im going to rework some parts and keep updating the PR. For now, whats done here according to initial discussions: Preserving deletes: We want to be able to optionally preserve recent deletes for some defined period of time, so that if a delete came in recently and might need to be included in the next incremental snapshot it wouldt get dropped by a compaction. This is done by adding new param to Options (preserve deletes flag) and new variable to DB Impl where we keep track of the sequence number after which we dont want to drop tombstones, even if they are otherwise eligible for deletion. I also added a new API call for clients to be able to advance this cutoff seqnum after which we drop deletes; i assume its more flexible to let clients control this, since otherwise wed need to keep some kind of timestamp > seqnum mapping inside the DB, which sounds messy and painful to support. Clients could make use of it by periodically calling GetLatestSequenceNumber(), noting the timestamp, doing some calculation and figuring out by how much we need to advance the cutoff seqnum. Compaction codepath in compaction_iterator.cc has been modified to avoid dropping tombstones with seqnum > cutoff seqnum. Iterator changes: couple params added to ReadOptions, to optionally allow client to request internal keys instead of user keys (so that client can get the latest value of a key, be it delete marker or a put), as well as min timestamp and min seqnum. TableCache changes: I modified table_cache code to be able to quickly exclude SST files from iterators heep if creation_time on the file is less then iter_start_ts as passed in ReadOptions. That would help a lot in some DB settings (like reading very recent data only or using FIFO compactions), but not so much for universal compaction with more or less long iterator time span. Whats left: Still looking at how to best plug that inside DBIter codepath. So far it seems that FindNextUserKeyInternal only parses values as UserKeys, and iter->key() call generally returns user key. Can we add new API to DBIter as internal_key(), and modify this internal method to optionally set saved_key_ to point to the full internal key? I dont need to store actual seqnum there, but I do need to store type. Closes Differential Revision: D6175602 Pulled By: mikhail-antonov fbshipit-source-id: c779a6696ee2d574d86c69cec866a3ae095aa900/WritePrepared Txn: Compaction/Flush Summary: Update Compaction/Flush to support WritePreparedTxnDB: Add SnapshotChecker which is a proxy to query WritePreparedTxnDB::IsInSnapshot. Pass SnapshotChecker to DBImpl on WritePreparedTxnDB open. CompactionIterator use it to check if a key has been committed and if it is visible to a snapshot. In CompactionIterator: * check if key has been committed. If not, output uncommitted keys AS-IS. * use SnapshotChecker to check if key is visible to a snapshot when in need. * do not output key with seq 0 if the key is not committed. Closes Differential Revision: D5902907 Pulled By: yiwu-arbug fbshipit-source-id: 945e037fdf0aa652dc5ba0ad879461040baa0320/Add ValueType::kTypeBlobIndex Summary: Add kTypeBlobIndex value type, which will be used by blob db only, to insert a (key, blob_offset) KV pair. The purpose is to 1. Make it possible to open existing rocksdb instance as blob db. Existing value will be of kTypeIndex type, while value inserted by blob db will be of kTypeBlobIndex. 2. Make rocksdb able to detect if the db contains value written by blob db, if so return error. 3. Make it possible to have blob db optionally store value in SST file (with kTypeValue type) or as a blob value (with kTypeBlobIndex type). The root db (DBImpl) basically pretended kTypeBlobIndex are normal value on write. On Get if is_blob is provided, return whether the value read is of kTypeBlobIndex type, or return Status::NotSupported() status if is_blob is not provided. On scan allow_blob flag is pass and if the flag is true, return wether the value is of kTypeBlobIndex type via iter->IsBlob(). Changes on blob db side will be in a separate patch. Closes Differential Revision: D5838431 Pulled By: yiwu-arbug fbshipit-source-id: 3c5306c62bc13bb11abc03422ec5cbcea1203cca/"
,,0.3079,rocksdb,"Added support for differential snapshots Summary: The motivation for this PR is to add to RocksDB support for differential (incremental) snapshots, as snapshot of the DB changes between two points in time (one can think of it as diff between to sequence numbers, or the diff D which can be thought of as an SST file or just set of KVs that can be applied to sequence number S1 to get the database to the state at sequence number S2). This feature would be useful for various distributed storages layers built on top of RocksDB, as it should help reduce resources (time and network bandwidth) needed to recover and rebuilt DB instances as replicas in the context of distributed storages. From the API standpoint that would like client app requesting iterator between (start seqnum) and current DB state, and reading the ""diff"". This is a very draft PR for initial review in the discussion on the approach, im going to rework some parts and keep updating the PR. For now, whats done here according to initial discussions: Preserving deletes: We want to be able to optionally preserve recent deletes for some defined period of time, so that if a delete came in recently and might need to be included in the next incremental snapshot it wouldt get dropped by a compaction. This is done by adding new param to Options (preserve deletes flag) and new variable to DB Impl where we keep track of the sequence number after which we dont want to drop tombstones, even if they are otherwise eligible for deletion. I also added a new API call for clients to be able to advance this cutoff seqnum after which we drop deletes; i assume its more flexible to let clients control this, since otherwise wed need to keep some kind of timestamp > seqnum mapping inside the DB, which sounds messy and painful to support. Clients could make use of it by periodically calling GetLatestSequenceNumber(), noting the timestamp, doing some calculation and figuring out by how much we need to advance the cutoff seqnum. Compaction codepath in compaction_iterator.cc has been modified to avoid dropping tombstones with seqnum > cutoff seqnum. Iterator changes: couple params added to ReadOptions, to optionally allow client to request internal keys instead of user keys (so that client can get the latest value of a key, be it delete marker or a put), as well as min timestamp and min seqnum. TableCache changes: I modified table_cache code to be able to quickly exclude SST files from iterators heep if creation_time on the file is less then iter_start_ts as passed in ReadOptions. That would help a lot in some DB settings (like reading very recent data only or using FIFO compactions), but not so much for universal compaction with more or less long iterator time span. Whats left: Still looking at how to best plug that inside DBIter codepath. So far it seems that FindNextUserKeyInternal only parses values as UserKeys, and iter->key() call generally returns user key. Can we add new API to DBIter as internal_key(), and modify this internal method to optionally set saved_key_ to point to the full internal key? I dont need to store actual seqnum there, but I do need to store type. Closes Differential Revision: D6175602 Pulled By: mikhail-antonov fbshipit-source-id: c779a6696ee2d574d86c69cec866a3ae095aa900/Fix coverity uninitialized fields warnings Pulled By: ajkr Differential Revision: D6170448 fbshipit-source-id: 5fd6d1608fc0df27c94d9f5059315ce7f79b8f5c/implement lower bound for iterators Summary: for `SeekToFirst()`, just convert it to a regular `Seek()` if lower bound is specified for operations that iterate backwards over user keys (`SeekForPrev`, `SeekToLast`, `Prev`), change `PrevInternal` to check whether user key went below lower bound every time the user key changes same approach we use to ensure we stay within a prefix when `prefix_same_as_start=true`. Closes Differential Revision: D6158654 Pulled By: ajkr fbshipit-source-id: cb0e3a922e2650d2cd4d1c6e1c0f1e8b729ff518/Fix tombstone scans in SeekForPrev outside prefix Summary: When doing a Seek() or SeekForPrev() we should stop the moment we see a key with a different prefix as start if ReadOptions:: prefix_same_as_start was set to true Right now we dont stop if we encounter a tombstone outside the prefix while executing SeekForPrev() Closes Differential Revision: D6149638 Pulled By: IslamAbdelRahman fbshipit-source-id: 7f659862d2bf552d3c9104a360c79439ceba2f18/Enable MSVC W4 with a few exceptions. Fix warnings and bugs Summary: Closes Differential Revision: D6079011 Pulled By: yiwu-arbug fbshipit-source-id: 988a721e7e7617967859dba71d660fc69f4dff57/WritePrepared Txn: Iterator Summary: On iterator create, take a snapshot, create a ReadCallback and pass the ReadCallback to the underlying DBIter to check if key is committed. Closes Differential Revision: D6001471 Pulled By: yiwu-arbug fbshipit-source-id: 3565c4cdaf25370ba47008b0e0cb65b31dfe79fe/Add ValueType::kTypeBlobIndex Summary: Add kTypeBlobIndex value type, which will be used by blob db only, to insert a (key, blob_offset) KV pair. The purpose is to 1. Make it possible to open existing rocksdb instance as blob db. Existing value will be of kTypeIndex type, while value inserted by blob db will be of kTypeBlobIndex. 2. Make rocksdb able to detect if the db contains value written by blob db, if so return error. 3. Make it possible to have blob db optionally store value in SST file (with kTypeValue type) or as a blob value (with kTypeBlobIndex type). The root db (DBImpl) basically pretended kTypeBlobIndex are normal value on write. On Get if is_blob is provided, return whether the value read is of kTypeBlobIndex type, or return Status::NotSupported() status if is_blob is not provided. On scan allow_blob flag is pass and if the flag is true, return wether the value is of kTypeBlobIndex type via iter->IsBlob(). Changes on blob db side will be in a separate patch. Closes Differential Revision: D5838431 Pulled By: yiwu-arbug fbshipit-source-id: 3c5306c62bc13bb11abc03422ec5cbcea1203cca/Three code-level optimization to Iterator::Next() Summary: Three small optimizations: (1) iter_->IsKeyPinned() shouldnt be called if read_options.pin_data is not true. This may trigger function call all the way down the iterator tree. (2) reuse the iterator key object in DBIter::FindNextUserEntryInternal(). The constructor of the class has some overheads. (3) Move the switching direction logic in MergingIterator::Next() to a separate function. These three in total improves readseq performance by about 3% in my benchmark setting. Closes Differential Revision: D5829252 Pulled By: siying fbshipit-source-id: 991aea10c6d6c3b43769cb4db168db62954ad1e3/perf_context measure user bytes read Summary: With this PR, we can measure read-amp for queries where perf_context is enabled as follows: ``` SetPerfLevel(kEnableCount); Get(1, ""foo""); double read_amp static_cast<double>(get_perf_context()->block_read_byte / get_perf_context()->get_read_bytes); SetPerfLevel(kDisable); ``` Our internal infra enables perf_context for a sampling of queries. So well be able to compute the read-amp for the sample set, which can give us a good estimate of read-amp. Closes Differential Revision: D5647240 Pulled By: ajkr fbshipit-source-id: ad73550b06990cf040cc4528fa885360f308ec12/"
,,0.1719,rocksdb,"WritePrepared Txn: Compaction/Flush Summary: Update Compaction/Flush to support WritePreparedTxnDB: Add SnapshotChecker which is a proxy to query WritePreparedTxnDB::IsInSnapshot. Pass SnapshotChecker to DBImpl on WritePreparedTxnDB open. CompactionIterator use it to check if a key has been committed and if it is visible to a snapshot. In CompactionIterator: * check if key has been committed. If not, output uncommitted keys AS-IS. * use SnapshotChecker to check if key is visible to a snapshot when in need. * do not output key with seq 0 if the key is not committed. Closes Differential Revision: D5902907 Pulled By: yiwu-arbug fbshipit-source-id: 945e037fdf0aa652dc5ba0ad879461040baa0320/"
,,0.1567,rocksdb,"WritePrepared Txn: Refactor conf params Summary: Summary of changes: Move seq_per_batch out of Options Rename concurrent_prepare to two_write_queues Add allocate_seq_only_for_data_ Closes Differential Revision: D6304458 Pulled By: maysamyabandeh fbshipit-source-id: 08e685bfa82bbc41b5b1c5eb7040a8ca6e05e58c/WritePrepared Txn: Compaction/Flush Summary: Update Compaction/Flush to support WritePreparedTxnDB: Add SnapshotChecker which is a proxy to query WritePreparedTxnDB::IsInSnapshot. Pass SnapshotChecker to DBImpl on WritePreparedTxnDB open. CompactionIterator use it to check if a key has been committed and if it is visible to a snapshot. In CompactionIterator: * check if key has been committed. If not, output uncommitted keys AS-IS. * use SnapshotChecker to check if key is visible to a snapshot when in need. * do not output key with seq 0 if the key is not committed. Closes Differential Revision: D5902907 Pulled By: yiwu-arbug fbshipit-source-id: 945e037fdf0aa652dc5ba0ad879461040baa0320/"
,,0.5355,rocksdb,"Added support for differential snapshots Summary: The motivation for this PR is to add to RocksDB support for differential (incremental) snapshots, as snapshot of the DB changes between two points in time (one can think of it as diff between to sequence numbers, or the diff D which can be thought of as an SST file or just set of KVs that can be applied to sequence number S1 to get the database to the state at sequence number S2). This feature would be useful for various distributed storages layers built on top of RocksDB, as it should help reduce resources (time and network bandwidth) needed to recover and rebuilt DB instances as replicas in the context of distributed storages. From the API standpoint that would like client app requesting iterator between (start seqnum) and current DB state, and reading the ""diff"". This is a very draft PR for initial review in the discussion on the approach, im going to rework some parts and keep updating the PR. For now, whats done here according to initial discussions: Preserving deletes: We want to be able to optionally preserve recent deletes for some defined period of time, so that if a delete came in recently and might need to be included in the next incremental snapshot it wouldt get dropped by a compaction. This is done by adding new param to Options (preserve deletes flag) and new variable to DB Impl where we keep track of the sequence number after which we dont want to drop tombstones, even if they are otherwise eligible for deletion. I also added a new API call for clients to be able to advance this cutoff seqnum after which we drop deletes; i assume its more flexible to let clients control this, since otherwise wed need to keep some kind of timestamp > seqnum mapping inside the DB, which sounds messy and painful to support. Clients could make use of it by periodically calling GetLatestSequenceNumber(), noting the timestamp, doing some calculation and figuring out by how much we need to advance the cutoff seqnum. Compaction codepath in compaction_iterator.cc has been modified to avoid dropping tombstones with seqnum > cutoff seqnum. Iterator changes: couple params added to ReadOptions, to optionally allow client to request internal keys instead of user keys (so that client can get the latest value of a key, be it delete marker or a put), as well as min timestamp and min seqnum. TableCache changes: I modified table_cache code to be able to quickly exclude SST files from iterators heep if creation_time on the file is less then iter_start_ts as passed in ReadOptions. That would help a lot in some DB settings (like reading very recent data only or using FIFO compactions), but not so much for universal compaction with more or less long iterator time span. Whats left: Still looking at how to best plug that inside DBIter codepath. So far it seems that FindNextUserKeyInternal only parses values as UserKeys, and iter->key() call generally returns user key. Can we add new API to DBIter as internal_key(), and modify this internal method to optionally set saved_key_ to point to the full internal key? I dont need to store actual seqnum there, but I do need to store type. Closes Differential Revision: D6175602 Pulled By: mikhail-antonov fbshipit-source-id: c779a6696ee2d574d86c69cec866a3ae095aa900/WritePrepared Txn: Compaction/Flush Summary: Update Compaction/Flush to support WritePreparedTxnDB: Add SnapshotChecker which is a proxy to query WritePreparedTxnDB::IsInSnapshot. Pass SnapshotChecker to DBImpl on WritePreparedTxnDB open. CompactionIterator use it to check if a key has been committed and if it is visible to a snapshot. In CompactionIterator: * check if key has been committed. If not, output uncommitted keys AS-IS. * use SnapshotChecker to check if key is visible to a snapshot when in need. * do not output key with seq 0 if the key is not committed. Closes Differential Revision: D5902907 Pulled By: yiwu-arbug fbshipit-source-id: 945e037fdf0aa652dc5ba0ad879461040baa0320/"
,,0.5084,rocksdb,"pass key/value samples through zstd compression dictionary generator Summary: Instead of using samples directly, we now support passing the samples through zstds dictionary generator when `CompressionOptions::zstd_max_train_bytes` is set to nonzero. If set to zero, we will use the samples directly as the dictionary same as before. Note this is the first step of extracted into a separate PR per reviewer request. Closes Differential Revision: D6116891 Pulled By: ajkr fbshipit-source-id: 70ab13cc4c734fa02e554180eed0618b75255497/Added support for differential snapshots Summary: The motivation for this PR is to add to RocksDB support for differential (incremental) snapshots, as snapshot of the DB changes between two points in time (one can think of it as diff between to sequence numbers, or the diff D which can be thought of as an SST file or just set of KVs that can be applied to sequence number S1 to get the database to the state at sequence number S2). This feature would be useful for various distributed storages layers built on top of RocksDB, as it should help reduce resources (time and network bandwidth) needed to recover and rebuilt DB instances as replicas in the context of distributed storages. From the API standpoint that would like client app requesting iterator between (start seqnum) and current DB state, and reading the ""diff"". This is a very draft PR for initial review in the discussion on the approach, im going to rework some parts and keep updating the PR. For now, whats done here according to initial discussions: Preserving deletes: We want to be able to optionally preserve recent deletes for some defined period of time, so that if a delete came in recently and might need to be included in the next incremental snapshot it wouldt get dropped by a compaction. This is done by adding new param to Options (preserve deletes flag) and new variable to DB Impl where we keep track of the sequence number after which we dont want to drop tombstones, even if they are otherwise eligible for deletion. I also added a new API call for clients to be able to advance this cutoff seqnum after which we drop deletes; i assume its more flexible to let clients control this, since otherwise wed need to keep some kind of timestamp > seqnum mapping inside the DB, which sounds messy and painful to support. Clients could make use of it by periodically calling GetLatestSequenceNumber(), noting the timestamp, doing some calculation and figuring out by how much we need to advance the cutoff seqnum. Compaction codepath in compaction_iterator.cc has been modified to avoid dropping tombstones with seqnum > cutoff seqnum. Iterator changes: couple params added to ReadOptions, to optionally allow client to request internal keys instead of user keys (so that client can get the latest value of a key, be it delete marker or a put), as well as min timestamp and min seqnum. TableCache changes: I modified table_cache code to be able to quickly exclude SST files from iterators heep if creation_time on the file is less then iter_start_ts as passed in ReadOptions. That would help a lot in some DB settings (like reading very recent data only or using FIFO compactions), but not so much for universal compaction with more or less long iterator time span. Whats left: Still looking at how to best plug that inside DBIter codepath. So far it seems that FindNextUserKeyInternal only parses values as UserKeys, and iter->key() call generally returns user key. Can we add new API to DBIter as internal_key(), and modify this internal method to optionally set saved_key_ to point to the full internal key? I dont need to store actual seqnum there, but I do need to store type. Closes Differential Revision: D6175602 Pulled By: mikhail-antonov fbshipit-source-id: c779a6696ee2d574d86c69cec866a3ae095aa900/WritePrepared Txn: Compaction/Flush Summary: Update Compaction/Flush to support WritePreparedTxnDB: Add SnapshotChecker which is a proxy to query WritePreparedTxnDB::IsInSnapshot. Pass SnapshotChecker to DBImpl on WritePreparedTxnDB open. CompactionIterator use it to check if a key has been committed and if it is visible to a snapshot. In CompactionIterator: * check if key has been committed. If not, output uncommitted keys AS-IS. * use SnapshotChecker to check if key is visible to a snapshot when in need. * do not output key with seq 0 if the key is not committed. Closes Differential Revision: D5902907 Pulled By: yiwu-arbug fbshipit-source-id: 945e037fdf0aa652dc5ba0ad879461040baa0320/"
,,0.0935,rocksdb,refactor constructor of LRUCacheShard Summary: Update LRUCacheShard constructor so that adding new params to it dont need to add extra SetXXX() methods. Closes Differential Revision: D8128618 Pulled By: yiwu-arbug fbshipit-source-id: 6afa715de1493a50de413678761a765e3af9b83b/
,,0.0898,rocksdb,refactor constructor of LRUCacheShard Summary: Update LRUCacheShard constructor so that adding new params to it dont need to add extra SetXXX() methods. Closes Differential Revision: D8128618 Pulled By: yiwu-arbug fbshipit-source-id: 6afa715de1493a50de413678761a765e3af9b83b/
,,0.0917,rocksdb,refactor constructor of LRUCacheShard Summary: Update LRUCacheShard constructor so that adding new params to it dont need to add extra SetXXX() methods. Closes Differential Revision: D8128618 Pulled By: yiwu-arbug fbshipit-source-id: 6afa715de1493a50de413678761a765e3af9b83b/
,,0.0887,rocksdb,PrefixMayMatch: remove unnecessary check for prefix_extractor_ (#4067) Summary: with and `prefix_extractor_` is not really being used in block based filter and full filters version of `PrefixMayMatch` because now `prefix_extractor` is passed as an argument. Also it is now possible that prefix_extractor_ may be initialized to nullptr when a non-standard prefix_extractor is used and also for ROCKSDB_LITE. Removing these checks should not break any existing tests. Closes Differential Revision: D8669002 Pulled By: miasantreble fbshipit-source-id: 0e701ba912b8a26734fadb72d15bb1b266b6176a/
