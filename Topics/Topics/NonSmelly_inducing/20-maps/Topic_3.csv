Topic_no,Keywords,Contrib,System,Text
3,"commit, transaction, call, snapshot, create, check, update, object, close, process, cache, handle, release, crash, bug, failure, set, maysamyabandeh_fbshipit, patch, optimization",0.1264,conscrypt,"Allow beginHandshake() when a handshake is in process. (#293) The documentation for beginHandshake() says that IllegalStateException is thrown if the client/server mode hasnt been set, and its reported that the OpenJDK implementation and previous Android releases both allowed calling beginHandshake() when a handshake is in progress. Since beginHandshake() is documented as being non-blocking, this should be safe. This fixes"
,,0.0818,frostwire,[android] long running Finger was causing way too many ANRs. build 395/
,,0.0804,frostwire,[android] added try-catch in Peer#finger/[android] long running Finger was causing way too many ANRs. build 395/
,,0.0798,frostwire,[android] long running Finger was causing way too many ANRs. build 395/
,,0.08,frostwire,[common] dont create StringBuilder unless you need it Thanks Logger methods now support optional parameter to display thread and caller method stack trace info/
,,0.0652,frostwire,[android] NPE issue with FWVibrator/
,,0.0588,javacpp,Initial commit/
,,0.0673,javacpp,Initial commit/
,,0.063,javacpp,Initial commit/
,,0.0673,javacpp,Initial commit/
,,0.0673,jna,fulfill hashCode contract for Function git-svn-id: 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/
,,0.0586,jna,[#384] Make jna.nosys=true default Closes:
,,0.0764,jna,Ensure inherited structure fields are properly ordered git-svn-id: 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/
,,0.0738,jna,Fix issue# 68 File monitor thread terminates on any removeWatch call. git-svn-id: 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/
,,0.0636,jna,"Check entire linux version, not just last digit git-svn-id: 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
,,0.0689,jna,fix struct layout cacheing in Union/cache structure layout results/
,,0.066,jna,Add encryption and decryption functions to Advapi32/
,,0.079,jna,Third attempt at fixing Netapi32Util.getDomainTrusts()./Second attempt at fixing the crash in Netapi32Util. This time we change the definition of Netapi32.DsEnumerateDomainTrusts. Crash is still not happening and this fix is more likely to be correct./
,,0.063,jna,Revert further duplicated changes./
,,0.0652,jna,Add encryption and decryption helpers to Advapi32Util/
,,0.0673,jna,Add encryption and decryption helpers to Advapi32Util/
,,0.066,jna,Add encryption and decryption functions to Advapi32/
,,0.0681,jna,manual handling of wchar vs char/
,,0.066,OpenDDS,Merged from trunk r6013 through r6048 to get OpenDDS-3.5 release update/Wed Jan 8 19:54:37 UTC 2014 Mike Martinez Jan 8 02:59:39 UTC 2014 Mike Martinez Jan 2 23:29:23 UTC 2014 Mike Martinez Dec 20 00:25:35 UTC 2013 Mike Martinez
,,0.063,OpenDDS,First commit of changes for wait_for_ack to branch/
,,0.0652,OpenDDS,First commit of changes for wait_for_ack to branch/
,,0.0652,OpenDDS,First commit of changes for wait_for_ack to branch/
,,0.063,OpenDDS,First commit of changes for wait_for_ack to branch/
,,0.0697,OpenDDS,"First commit of changes for wait_for_ack to branch/Changes to send_links, pending_data, and get_unsent_data with add_sending_data/Creating Branch/"
,,0.0609,OpenDDS,First commit of changes for wait_for_ack to branch/
,,0.063,OpenDDS,First commit of changes for wait_for_ack to branch/
,,0.0673,OpenDDS,First commit of changes for wait_for_ack to branch/
,,0.0673,OpenDDS,First commit of changes for wait_for_ack to branch/Thu Jan 8 23:03:23 UTC 2015 Paul Calabrese
,,0.0588,OpenDDS,First commit of changes for wait_for_ack to branch/
,,0.0636,OpenDDS,Fixed warnings in FACE/safety code/ChangeLogTag: Fri Feb 27 22:55:08 UTC 2015 Adam Mitz Thu Jan 15 20:30:23 UTC 2015 Jeff Schmitz
,,0.0556,OpenDDS,Initialize last_liveliness_check_time_ before liveliness timer is enabled./
,,0.0681,OpenDDS,One more fix to DataLink ref counting when interacting with Reactor/
,,0.0648,OpenDDS,Make sure we dont have any notifications in the reactor after a wait()./
,,0.1758,OpenDDS,"Using reference counting to manage TransportClient::PendingAssoc objects. The manual managnement for the lifetime of TransportClient::PendingAssoc objects fails occasionally because thereís no guarantee a PendingAssoc object is no longer referenced by another thread when it is about to be deleted. TransportClient::initiate_connect_i() had some logic to detect whether a PendingAssoc object was deleted or not before it returned to the caller (TransportClient::PendingAssoc::initiate_connect). However, it made the return value ìfalseî from TransportClient::initiate_connect_i() ambiguous because it could mean connection failure or successfully connected but the PendingAssoc object is deleted already. This made it hard for the caller to avoid accessing the deleted object./TransportClient allow fallback to next transport impl when active side fails to connect on the first/"
,,0.1916,OpenDDS,"Using reference counting to manage TransportClient::PendingAssoc objects. The manual managnement for the lifetime of TransportClient::PendingAssoc objects fails occasionally because thereís no guarantee a PendingAssoc object is no longer referenced by another thread when it is about to be deleted. TransportClient::initiate_connect_i() had some logic to detect whether a PendingAssoc object was deleted or not before it returned to the caller (TransportClient::PendingAssoc::initiate_connect). However, it made the return value ìfalseî from TransportClient::initiate_connect_i() ambiguous because it could mean connection failure or successfully connected but the PendingAssoc object is deleted already. This made it hard for the caller to avoid accessing the deleted object./"
,,0.0833,OpenDDS,Use ACE_Event_Handler reference counting policy for ReactorInterceptor to manage its object lifetime./
,,0.0677,OpenDDS,Using publication status to decide when to finish program/
,,0.0577,OpenDDS,Fix TCP wait_for_acknowledgements() bug/
,,0.0556,OpenDDS,Handle thrown exception BAD_PARAM./
,,0.0652,OpenDDS,Fix leaks in TransportQueuedElement derived classes/Rename scope_ptr to unique_ptr/
,,0.066,OpenDDS,Modifications from code review process./
,,0.0605,OpenDDS,fixing compiler warnings/Temporary commit for merge resolution/
,,0.0731,OpenDDS,DataReaderImpl changes to avoid linking error when compiling with clr/
,,0.0577,OpenDDS,s/retcode_to_dds_string/retcode_to_string/g/Created retcode_to_dds_string/
,,0.0639,pljava,Named an anonymous struct in the Ptr2Long union/Initial revision/
,,0.0942,pljava,Added test of transaction recovery using an anonymous savepoint/
,,0.0642,pljava,"Keep making DEBUG1 quieter. These sites were missed in commit 1eb3bd8, trying to get the PL/Java-loaded-versions announcement to be the only thing at DEBUG1./"
,,0.0673,realm-java,Added experimental method: table.moveLastOver() method/
,,0.0673,realm-java,Added experimental method: table.moveLastOver() method/
,,0.0673,realm-java,Added experimental method: table.moveLastOver() method/
,,0.0652,realm-java,Added experimental method: table.moveLastOver() method/
,,0.0939,realm-java,Fixed automatic transaction rollback on close./
,,0.0792,realm-java,"implementation of context in Table, View, Group, SharedGroup, ReadTrans and Query/"
,,0.0738,realm-java,A cleaner solution/Thread handler no longer gets removed too soon./Fixed bug causing refresh on closed Realms on background threads with loopers./Modify the unit tests to comply to Realm.close()/
,,0.1021,realm-java,"Changing logic to handover the query from caller to background thread, handle different failure points (begin_read, import_handover), update UnitTests/add retry policy + concurrency tests + perf improvement to the query/"
,,0.09699999999999999,realm-java,Add support for in-memory Realm 1. Add durability to createNativeWithImplicitTransactions. 2. Add inMemory to RealmConfiguration. 3. Support passing durability to SharedGroup constructor. 4. Add new static method getInMemoryRealm to Realm class. 5. Add test cases./add retry policy + concurrency tests + perf improvement to the query/Add support for Findbugs and fix the issues found/
,,0.1236,realm-java,"Ignore dup entries when addChangeListener Since there should not have lots of listeners in on realm instance, looping should be an acceptable way to do this./"
,,0.1421,realm-java,write transaction transaction to avoid confusing users. write transaction transaction. Some write transactions with read transactinos remain. Realm.isInWriteTransaction Realm.isInTrasaction./Add Realm.isInWriteTransaction() to indicate if it is in a write transaction. See also: Closes
,,0.1661,realm-java,"Using separate interfaces for async transaction also fixes unit test naming and looper thread usage./switch to JUnit4/Fix crash when closing a Realm in listener batch update for async queries to fix notifications, adding Async queries for DynamicRealmObject/New Migration and Dynamic API. New Sort/Case enums. New RealmCache/Checking to see if a transaction is currently in progress for sync and async transaction pathways. Also adding logging. Added a test helper to assist with log assertion. Fixes Fixing typo. Removing logger after testing Removing extra line Fixing tests and adding change log message. Adding breaking change message Small cosmetic changes Adding punctuation formatting Fixing unit test./"
,,0.1218,realm-java,"Removed explicit GC call when Realm changes/fix 1884 listener trigger/Fix crash when closing a Realm in listener notifications, adding Async queries for DynamicRealmObject/"
,,0.0993,realm-java,Buffer overwritten caused PK migration failure Close A String or Binary pointer retrieved from Realm is invalidated when set_string called./
,,0.0843,realm-java,Support for RealmQuery.isNotEmpty() added/add batch update for async queries to fix potential memory leak in jni code and skip copying back to java array if native array is not modified./
,,0.0724,realm-java,Support for RealmQuery.isNotEmpty() added/Add RxJava support/add batch update for async queries to fix
,,0.0858,realm-java,Examples should use transaction blocks (#2800) * Moving examples over to execute transaction * Updating comments to use executeTransaction * Use partial mocks for Realm#executeTransaction(...) and create additional tests to illustrate mock verification of Realm#executeTransaction(...). Had to do this because of a problem with Powermock:
,,0.3138,realm-java,"More GCed ref for flaky test (#3135)/Forward all throwables but not only excpetions (#3126) For example the UnsatisfiedLinkError should cause the process terminated. This is the reason of all the time out issues we found for CI./Fix async transaction problem when async query already exist. (#2780) I have rewritten how async transactions works. Before they did this: 1) commitOnBackgroundThread() post REALM_CHANGED post onSuccess runnable The problem with that approach was that the REALM_CHANGED would be swallowed if async queries existed which meant that the async transaction would call onSuccess on an old version of the Realm (making it look like it didnt work). Instead we now do this: 2) commitOnBackgroundThread post runnable that calls HandlerController.handleAsyncTransactionCompleted(runnable) The special runnable is treated as a combined REALM_CHANGED + Callback, which makes it possible for us to queue up callbacks until we are finally able to trigger all of them. Unfortunately the Handler has poor support for this so it means that we no longer can detect if such a message is in the queue. This means that it introduces a slight chance of such a event plus a real REALM_CHANGED event to be in the message queue at the same time. I considered that acceptable (since it can already happen today), and since preventing this will introduce more complexity to something that is already entirely to complex./Fixed unit tests./thread safe HandlerController#emptyAsyncRealmObject & realmObjects (#2761) * making HandlerController#emptyAsyncRealmObject & HandlerController#realmObjects thread safe/"
,,0.353,realm-java,Disable change listeners on IntentService threads (#3232)/Race condition between Realm change notifications and UI events (#2990) This commit fixes a bug surfaced by our Realm Android Adapter example. Before this commit we posted all REALM_CHANGED events to the looper queue as normal. This meant that potential touch input events could get in front which in turn could cause a relayout of a ListView which would then crash because it detected a difference between its cached adapter size and the actual one. This commit now forces all local commits to be placed at the front of the queue eliminating that risk./
,,0.4393,realm-java,"Disable change listeners on IntentService threads (#3232)/More GCed ref for flaky test (#3135)/Race condition between Realm change notifications and UI events (#2990) This commit fixes a bug surfaced by our Realm Android Adapter example. Before this commit we posted all REALM_CHANGED events to the looper queue as normal. This meant that potential touch input events could get in front which in turn could cause a relayout of a ListView which would then crash because it detected a difference between its cached adapter size and the actual one. This commit now forces all local commits to be placed at the front of the queue eliminating that risk./Fix listeners can exposing unsynchronized RealmResults (Async queries) (#2951) When async queries are updated, they call listeners in a specific order. Before this commit this had a very subtle bug, so accessing synchronous RealmResults from inside a async RealmResult listener might hit a detached row accessor. Reason being is that the Realm is advanced, then all listeners called in order, but RealmResults are not synchronised until just before listener is called. This commit fixes this so all RealmResults are now synced before the listener is called./RealmResults is not synced in global listener (#2926) Close RealmResults are synced when calling its listener, since we need to check the table version before calling the listener. So sync it just after advance read wont be an option in that way, the results listener wont be triggered. So we notify the global listeners as the last thing to do, at that point, result will be synced already. Also a test case is added to ensure the calling sequence of synced listeners./Fixed unit tests./"
,,0.4523,realm-java,"Disable change listeners on IntentService threads (#3232)/Forward all throwables but not only excpetions (#3126) For example the UnsatisfiedLinkError should cause the process terminated. This is the reason of all the time out issues we found for CI./Fix async transaction problem when async query already exist. (#2780) I have rewritten how async transactions works. Before they did this: 1) commitOnBackgroundThread() post REALM_CHANGED post onSuccess runnable The problem with that approach was that the REALM_CHANGED would be swallowed if async queries existed which meant that the async transaction would call onSuccess on an old version of the Realm (making it look like it didnt work). Instead we now do this: 2) commitOnBackgroundThread post runnable that calls HandlerController.handleAsyncTransactionCompleted(runnable) The special runnable is treated as a combined REALM_CHANGED + Callback, which makes it possible for us to queue up callbacks until we are finally able to trigger all of them. Unfortunately the Handler has poor support for this so it means that we no longer can detect if such a message is in the queue. This means that it introduces a slight chance of such a event plus a real REALM_CHANGED event to be in the message queue at the same time. I considered that acceptable (since it can already happen today), and since preventing this will introduce more complexity to something that is already entirely to complex./Race condition between Realm change notifications and UI events (#2990) This commit fixes a bug surfaced by our Realm Android Adapter example. Before this commit we posted all REALM_CHANGED events to the looper queue as normal. This meant that potential touch input events could get in front which in turn could cause a relayout of a ListView which would then crash because it detected a difference between its cached adapter size and the actual one. This commit now forces all local commits to be placed at the front of the queue eliminating that risk./"
,,0.1025,realm-java,Forward all throwables but not only excpetions (#3126) For example the UnsatisfiedLinkError should cause the process terminated. This is the reason of all the time out issues we found for CI./
,,0.326,realm-java,"Fix async transaction problem when async query already exist. (#2780) I have rewritten how async transactions works. Before they did this: 1) commitOnBackgroundThread() post REALM_CHANGED post onSuccess runnable The problem with that approach was that the REALM_CHANGED would be swallowed if async queries existed which meant that the async transaction would call onSuccess on an old version of the Realm (making it look like it didnt work). Instead we now do this: 2) commitOnBackgroundThread post runnable that calls HandlerController.handleAsyncTransactionCompleted(runnable) The special runnable is treated as a combined REALM_CHANGED + Callback, which makes it possible for us to queue up callbacks until we are finally able to trigger all of them. Unfortunately the Handler has poor support for this so it means that we no longer can detect if such a message is in the queue. This means that it introduces a slight chance of such a event plus a real REALM_CHANGED event to be in the message queue at the same time. I considered that acceptable (since it can already happen today), and since preventing this will introduce more complexity to something that is already entirely to complex./"
,,0.0838,realm-java,Disable change listeners on IntentService threads (#3232)/
,,0.4274,realm-java,"Forward all throwables but not only excpetions (#3126) For example the UnsatisfiedLinkError should cause the process terminated. This is the reason of all the time out issues we found for CI./Race condition between Realm change notifications and UI events (#2990) This commit fixes a bug surfaced by our Realm Android Adapter example. Before this commit we posted all REALM_CHANGED events to the looper queue as normal. This meant that potential touch input events could get in front which in turn could cause a relayout of a ListView which would then crash because it detected a difference between its cached adapter size and the actual one. This commit now forces all local commits to be placed at the front of the queue eliminating that risk./Fix listeners can exposing unsynchronized RealmResults (Async queries) (#2951) When async queries are updated, they call listeners in a specific order. Before this commit this had a very subtle bug, so accessing synchronous RealmResults from inside a async RealmResult listener might hit a detached row accessor. Reason being is that the Realm is advanced, then all listeners called in order, but RealmResults are not synchronised until just before listener is called. This commit fixes this so all RealmResults are now synced before the listener is called./"
,,0.5923,realm-java,"add default value instruction support (#3462) * add default value support to Table class * Table#isNull() and TableView#isNull() * use default value feature * added a test to check if nullified link can be overwritten by default value * removed duplicate thread check when constructing proxy objects (and small bugfix in setter of the list). * added thread check * reflect review comments * reflect comment in JNI code/Allow to specify default value of the field in models constructor (#3397) * Allow to call its accessors, and replace its field accesses with accessor calls in models constructor. fixes fixes * use field instead of checking transaction * fix a bug that acceptDefaultValue is not set correctly * reject default values when the getter of a model creates other model object * add simple test for default value * supports default value of model field * supports default value of RealmList fields * add tests for assignment in constructor and setter in constructor * update javadoc comments of createObject * always ignores the default value of primary key if the object is managed * update javadoc * add a test for default values handling in copyToRealm(). the last assertion of RealmTests.copyToRealm_defaultValuesAreIgnored() is failing now. * refactor tests * use isPrimaryKey() * fix a bug that unexpected realm object is created by default value of RealmModel/RealmList fields * remove extra ; from generated code * add more tests for default value * fix tests * fix a bug that creates unexpected objects * rename internal methods * update changelog * update CHANGELOG * review comments * update CHANGELOG * added a description of how proxy object should be created in the Javadoc comment of RealmProcessor/Supporting both additive and manual schema modes (#91) * Adding very thin wrappers for Object Stores ObjectSchema and Property. * Adding method for building object schema is proxy classes * Adding rudimentary support for Object Store schemas. Using ObjectStore::update_schema() to update schema for the additive mode. * Disallowing destructive schema changes in additive mode./Invalidate schema cache when the schema version of Realm is changed by other process (#3409). invalidate schema cache when the schema version of Realm is changed by other process. Now schema cache referred by Realm instance is not shared and global schema cache is introduced instead./Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./Add isManaged() to RealmObject/RealmCollection (#3341) * isValid() returns true for unmanaged object and collection. * Add isManaged() to RealmObject and RealmCollection/"
,,0.5899,realm-java,"add default value instruction support (#3462) * add default value support to Table class * Table#isNull() and TableView#isNull() * use default value feature * added a test to check if nullified link can be overwritten by default value * removed duplicate thread check when constructing proxy objects (and small bugfix in setter of the list). * added thread check * reflect review comments * reflect comment in JNI code/Allow to specify default value of the field in models constructor (#3397) * Allow to call its accessors, and replace its field accesses with accessor calls in models constructor. fixes fixes * use field instead of checking transaction * fix a bug that acceptDefaultValue is not set correctly * reject default values when the getter of a model creates other model object * add simple test for default value * supports default value of model field * supports default value of RealmList fields * add tests for assignment in constructor and setter in constructor * update javadoc comments of createObject * always ignores the default value of primary key if the object is managed * update javadoc * add a test for default values handling in copyToRealm(). the last assertion of RealmTests.copyToRealm_defaultValuesAreIgnored() is failing now. * refactor tests * use isPrimaryKey() * fix a bug that unexpected realm object is created by default value of RealmModel/RealmList fields * remove extra ; from generated code * add more tests for default value * fix tests * fix a bug that creates unexpected objects * rename internal methods * update changelog * update CHANGELOG * review comments * update CHANGELOG * added a description of how proxy object should be created in the Javadoc comment of RealmProcessor/Supporting both additive and manual schema modes (#91) * Adding very thin wrappers for Object Stores ObjectSchema and Property. * Adding method for building object schema is proxy classes * Adding rudimentary support for Object Store schemas. Using ObjectStore::update_schema() to update schema for the additive mode. * Disallowing destructive schema changes in additive mode./Invalidate schema cache when the schema version of Realm is changed by other process (#3409). invalidate schema cache when the schema version of Realm is changed by other process. Now schema cache referred by Realm instance is not shared and global schema cache is introduced instead./Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./Add isManaged() to RealmObject/RealmCollection (#3341) * isValid() returns true for unmanaged object and collection. * Add isManaged() to RealmObject and RealmCollection/"
,,0.4888,realm-java,"Supporting both additive and manual schema modes (#91) * Adding very thin wrappers for Object Stores ObjectSchema and Property. * Adding method for building object schema is proxy classes * Adding rudimentary support for Object Store schemas. Using ObjectStore::update_schema() to update schema for the additive mode. * Disallowing destructive schema changes in additive mode./Invalidate schema cache when the schema version of Realm is changed by other process (#3409). invalidate schema cache when the schema version of Realm is changed by other process. Now schema cache referred by Realm instance is not shared and global schema cache is introduced instead./Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./"
,,0.5639,realm-java,"add default value instruction support (#3462) * add default value support to Table class * Table#isNull() and TableView#isNull() * use default value feature * added a test to check if nullified link can be overwritten by default value * removed duplicate thread check when constructing proxy objects (and small bugfix in setter of the list). * added thread check * reflect review comments * reflect comment in JNI code/Allow to specify default value of the field in models constructor (#3397) * Allow to call its accessors, and replace its field accesses with accessor calls in models constructor. fixes fixes * use field instead of checking transaction * fix a bug that acceptDefaultValue is not set correctly * reject default values when the getter of a model creates other model object * add simple test for default value * supports default value of model field * supports default value of RealmList fields * add tests for assignment in constructor and setter in constructor * update javadoc comments of createObject * always ignores the default value of primary key if the object is managed * update javadoc * add a test for default values handling in copyToRealm(). the last assertion of RealmTests.copyToRealm_defaultValuesAreIgnored() is failing now. * refactor tests * use isPrimaryKey() * fix a bug that unexpected realm object is created by default value of RealmModel/RealmList fields * remove extra ; from generated code * add more tests for default value * fix tests * fix a bug that creates unexpected objects * rename internal methods * update changelog * update CHANGELOG * review comments * update CHANGELOG * added a description of how proxy object should be created in the Javadoc comment of RealmProcessor/Supporting both additive and manual schema modes (#91) * Adding very thin wrappers for Object Stores ObjectSchema and Property. * Adding method for building object schema is proxy classes * Adding rudimentary support for Object Store schemas. Using ObjectStore::update_schema() to update schema for the additive mode. * Disallowing destructive schema changes in additive mode./Disallow changing PK after object created (#3418) Thrown an exception if changing the pk after the object creation./Upgrade to beta-33 / 2.0.0-rc4 (#90)/Invalidate schema cache when the schema version of Realm is changed by other process (#3409). invalidate schema cache when the schema version of Realm is changed by other process. Now schema cache referred by Realm instance is not shared and global schema cache is introduced instead./Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./Add isManaged() to RealmObject/RealmCollection (#3341) * isValid() returns true for unmanaged object and collection. * Add isManaged() to RealmObject and RealmCollection/Nh/fixing 3105 (#3306) * Fixing issue with Cyclic dependency insert or the existing copyToRealm, adding support for managed RealmObject/"
,,0.1988,realm-java,Supporting both additive and manual schema modes (#91) * Adding very thin wrappers for Object Stores ObjectSchema and Property. * Adding method for building object schema is proxy classes * Adding rudimentary support for Object Store schemas. Using ObjectStore::update_schema() to update schema for the additive mode. * Disallowing destructive schema changes in additive mode./
,,0.4877,realm-java,"Supporting both additive and manual schema modes (#91) * Adding very thin wrappers for Object Stores ObjectSchema and Property. * Adding method for building object schema is proxy classes * Adding rudimentary support for Object Store schemas. Using ObjectStore::update_schema() to update schema for the additive mode. * Disallowing destructive schema changes in additive mode./Invalidate schema cache when the schema version of Realm is changed by other process (#3409). invalidate schema cache when the schema version of Realm is changed by other process. Now schema cache referred by Realm instance is not shared and global schema cache is introduced instead./Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./"
,,0.1342,realm-java,"allow to put Realm database file on external storage. (#3591) * set the path of the directory of named pipes to fix * update CHANGELOG * add a test for issue3140 * update test * follow the chenges in object-store * skip an external storage test on the device where SELinux is not enforced * rename test * rename variable * update object-store * make SharedRealm#temporaryDirectory volatile * address findbugs error/RealmLog (#3368) Moved RealmLog to the public API. Routes all log events through it, also from native code./"
,,0.4697,realm-java,"fix flaky test (#3626)/distinctAsync now respects other query parameters. (#3539)/DeleteLocalRef when the ref is created in loop (#3366) Add wrapper class for JNI local reference to delete the local ref after using it. This is reported by user on helpscout: And some useful explanation can be found: Normally the local ref doesnt have to be deleted since they will be cleaned up when program returns to Java from native code. Using it in a loop is obvious a corner case: the size of local ref table is relatively small (512 on Android). To avoid it, the local ref should be deleted when using it in a loop./Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./Wait all async tasks done before next test (#3319) This is highly related with Below things are still guaranteed by this change after commit async transaction: * When callback function called (onSuccess/onError), the background Realm is closed. * When any change listeners called, the background Realm is closed. What is true now but it is not guaranteed in the future: * Background Realm might not be closed before REALM_CHANGED sent (not received). Due to this, to avoid the flaky tests, we have to ensure all async tasks quit peacefully before start the next test. This is implemented by wait and check in the TestRealmConfigurationFactory. NOTE: Any test, if the async tasks cannot be finished peacefully in a certain time, it has to be considered as a problem and fixed. This would be needed by OS notifications since Java wont have a precise control of sending REALM_CHANGED anymore./"
,,0.3907,realm-java,"add default value instruction support (#3462) * add default value support to Table class * Table#isNull() and TableView#isNull() * use default value feature * added a test to check if nullified link can be overwritten by default value * removed duplicate thread check when constructing proxy objects (and small bugfix in setter of the list). * added thread check * reflect review comments * reflect comment in JNI code/Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./"
,,0.3966,realm-java,"add default value instruction support (#3462) * add default value support to Table class * Table#isNull() and TableView#isNull() * use default value feature * added a test to check if nullified link can be overwritten by default value * removed duplicate thread check when constructing proxy objects (and small bugfix in setter of the list). * added thread check * reflect review comments * reflect comment in JNI code/Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./"
,,0.1887,realm-java,Fix unstable test (#3495)/add default value instruction support (#3462) * add default value support to Table class * Table#isNull() and TableView#isNull() * use default value feature * added a test to check if nullified link can be overwritten by default value * removed duplicate thread check when constructing proxy objects (and small bugfix in setter of the list). * added thread check * reflect review comments * reflect comment in JNI code/getFieldIndex returns null for non-existing field (#3295) Close
,,0.3495,realm-java,"Add RealmFileException to replace RealmIOException and IncompatibleLockFileException. Also it is mapped to the same name exception in ObjectStore to give user a detailed kind of file exception./Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./"
,,0.526,realm-java,"Logout and Userstore (#104)/Allow to specify default value of the field in models constructor (#3397) * Allow to call its accessors, and replace its field accesses with accessor calls in models constructor. fixes fixes * use field instead of checking transaction * fix a bug that acceptDefaultValue is not set correctly * reject default values when the getter of a model creates other model object * add simple test for default value * supports default value of model field * supports default value of RealmList fields * add tests for assignment in constructor and setter in constructor * update javadoc comments of createObject * always ignores the default value of primary key if the object is managed * update javadoc * add a test for default values handling in copyToRealm(). the last assertion of RealmTests.copyToRealm_defaultValuesAreIgnored() is failing now. * refactor tests * use isPrimaryKey() * fix a bug that unexpected realm object is created by default value of RealmModel/RealmList fields * remove extra ; from generated code * add more tests for default value * fix tests * fix a bug that creates unexpected objects * rename internal methods * update changelog * update CHANGELOG * review comments * update CHANGELOG * added a description of how proxy object should be created in the Javadoc comment of RealmProcessor/Invalidate schema cache when the schema version of Realm is changed by other process (#3409). invalidate schema cache when the schema version of Realm is changed by other process. Now schema cache referred by Realm instance is not shared and global schema cache is introduced instead./Add RealmFileException to replace RealmIOException and IncompatibleLockFileException. Also it is mapped to the same name exception in ObjectStore to give user a detailed kind of file exception./Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./"
,,0.3614,realm-java,"Allow to specify default value of the field in models constructor (#3397) * Allow to call its accessors, and replace its field accesses with accessor calls in models constructor. fixes fixes * use field instead of checking transaction * fix a bug that acceptDefaultValue is not set correctly * reject default values when the getter of a model creates other model object * add simple test for default value * supports default value of model field * supports default value of RealmList fields * add tests for assignment in constructor and setter in constructor * update javadoc comments of createObject * always ignores the default value of primary key if the object is managed * update javadoc * add a test for default values handling in copyToRealm(). the last assertion of RealmTests.copyToRealm_defaultValuesAreIgnored() is failing now. * refactor tests * use isPrimaryKey() * fix a bug that unexpected realm object is created by default value of RealmModel/RealmList fields * remove extra ; from generated code * add more tests for default value * fix tests * fix a bug that creates unexpected objects * rename internal methods * update changelog * update CHANGELOG * review comments * update CHANGELOG * added a description of how proxy object should be created in the Javadoc comment of RealmProcessor/"
,,0.0929,realm-java,Disallow changing PK after object created (#3418) Thrown an exception if changing the pk after the object creation./Add methods to RealmQuery to support byte arrays (#3285)/
,,0.1121,realm-java,Disallow changing PK after object created (#3418) Thrown an exception if changing the pk after the object creation./
,,0.17800000000000002,realm-java,Add isManaged() to RealmObject/RealmCollection (#3341) * isValid() returns true for unmanaged object and collection. * Add isManaged() to RealmObject and RealmCollection/
,,0.1939,realm-java,"Upgrade to beta-33 / 2.0.0-rc4 (#90)/RealmLog (#3368) Moved RealmLog to the public API. Routes all log events through it, also from native code./Fix notification tests for following changes (#3301) * Fix notification tests for following changes To support multiprocess & OS notifications, a dedicated thread will monitor the Realm changes and send notifications to other thread. This means our tests cannot assume notifications will be sent for every transaction commit. Also, the Realm.handler will moved to a lower layer, its better to not rely on it in the test as well. To avoid a massive PR, tests changes are made separately first./"
,,0.5365,realm-java,"Use CheckedRow when creating a DynamicRealm Object. (#3551) And this removes a check of UncheckedRow in some constructors of DynamicRealmObject since CheckedRow is never passed to it./Add cause to RealmMigrationNeededException (#3482)/Make BaseRealm package protected again (#143) and move SyncObjectServerFacade to internal/objectserver./Merge branch master into cm/merge-globalinit-from-master Conflicts: realm/realm-library/src/main/java/io/realm/BaseRealm.java realm/realm-library/src/main/java/io/realm/RealmConfiguration.java/Allow to specify default value of the field in models constructor (#3397) * Allow to call its accessors, and replace its field accesses with accessor calls in models constructor. fixes fixes * use field instead of checking transaction * fix a bug that acceptDefaultValue is not set correctly * reject default values when the getter of a model creates other model object * add simple test for default value * supports default value of model field * supports default value of RealmList fields * add tests for assignment in constructor and setter in constructor * update javadoc comments of createObject * always ignores the default value of primary key if the object is managed * update javadoc * add a test for default values handling in copyToRealm(). the last assertion of RealmTests.copyToRealm_defaultValuesAreIgnored() is failing now. * refactor tests * use isPrimaryKey() * fix a bug that unexpected realm object is created by default value of RealmModel/RealmList fields * remove extra ; from generated code * add more tests for default value * fix tests * fix a bug that creates unexpected objects * rename internal methods * update changelog * update CHANGELOG * review comments * update CHANGELOG * added a description of how proxy object should be created in the Javadoc comment of RealmProcessor/Supporting both additive and manual schema modes (#91) * Adding very thin wrappers for Object Stores ObjectSchema and Property. * Adding method for building object schema is proxy classes * Adding rudimentary support for Object Store schemas. Using ObjectStore::update_schema() to update schema for the additive mode. * Disallowing destructive schema changes in additive mode./Invalidate schema cache when the schema version of Realm is changed by other process (#3409). invalidate schema cache when the schema version of Realm is changed by other process. Now schema cache referred by Realm instance is not shared and global schema cache is introduced instead./Integrate Object Store [PART4] OS notifications (#3370) * Use OSs notification mechanism to notify threads. * Create RealmNotificer interface for decouple Android related handler logic. * Create AndroidNotifier for the handler notifications. The major change of this PR is about the timing. The notifications are not sent immediately after transaction committed. Instead, there is a dedicated thread monitoring changes and notify others when changes happen. The known problem is for every RealmConfiguration, a monitor thread will be created which is not ideal for app which is using multiple RealmConfiguration. There are different implementations for the monitoring thread in OS. For Android, we can choose from generic which is based on the cores wait_for_change() and android which is used by dotnet based on the named pipe. To align with dotnet, we are using the named pipe for now which also enables notifications between realm-java and realm-dotnet./Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./Wait all async tasks done before next test (#3319) This is highly related with Below things are still guaranteed by this change after commit async transaction: * When callback function called (onSuccess/onError), the background Realm is closed. * When any change listeners called, the background Realm is closed. What is true now but it is not guaranteed in the future: * Background Realm might not be closed before REALM_CHANGED sent (not received). Due to this, to avoid the flaky tests, we have to ensure all async tasks quit peacefully before start the next test. This is implemented by wait and check in the TestRealmConfigurationFactory. NOTE: Any test, if the async tasks cannot be finished peacefully in a certain time, it has to be considered as a problem and fixed. This would be needed by OS notifications since Java wont have a precise control of sending REALM_CHANGED anymore./"
,,0.2788,realm-java,"SyncConfiguration Builder now only contains allowed options (#87)/Remove deprecated constructor + add directory() (#3357) This commit simplifies the RealmConfiguration constructors and also ensures that we always have an Android context. It does so by now only having the`RealmConfiguration.Builder(context)` constructor. Custom file locations are now supported through the `directory()` builder method. This also made it possible to simply `assetFile(Context, location)` to only `assetFile(location)`. Having the Context means that we are now able to access system services and other framework classes without exposing any Android functionality in any potential interface (which will be needed to support Realm on the JVM)./Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./"
,,0.4061,realm-java,"Fix unit tests./fix merge mistakes/Supporting both additive and manual schema modes (#91) * Adding very thin wrappers for Object Stores ObjectSchema and Property. * Adding method for building object schema is proxy classes * Adding rudimentary support for Object Store schemas. Using ObjectStore::update_schema() to update schema for the additive mode. * Disallowing destructive schema changes in additive mode./Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./improve `Table` and schema cache. (#3315) * improve `Table` and schema cache./"
,,0.4888,realm-java,"Supporting both additive and manual schema modes (#91) * Adding very thin wrappers for Object Stores ObjectSchema and Property. * Adding method for building object schema is proxy classes * Adding rudimentary support for Object Store schemas. Using ObjectStore::update_schema() to update schema for the additive mode. * Disallowing destructive schema changes in additive mode./Invalidate schema cache when the schema version of Realm is changed by other process (#3409). invalidate schema cache when the schema version of Realm is changed by other process. Now schema cache referred by Realm instance is not shared and global schema cache is introduced instead./Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./"
,,0.1954,realm-java,Invalidate schema cache when the schema version of Realm is changed by other process (#3409). invalidate schema cache when the schema version of Realm is changed by other process. Now schema cache referred by Realm instance is not shared and global schema cache is introduced instead./
,,0.2009,realm-java,Invalidate schema cache when the schema version of Realm is changed by other process (#3409). invalidate schema cache when the schema version of Realm is changed by other process. Now schema cache referred by Realm instance is not shared and global schema cache is introduced instead./
,,0.4944,realm-java,"Supporting both additive and manual schema modes (#91) * Adding very thin wrappers for Object Stores ObjectSchema and Property. * Adding method for building object schema is proxy classes * Adding rudimentary support for Object Store schemas. Using ObjectStore::update_schema() to update schema for the additive mode. * Disallowing destructive schema changes in additive mode./Invalidate schema cache when the schema version of Realm is changed by other process (#3409). invalidate schema cache when the schema version of Realm is changed by other process. Now schema cache referred by Realm instance is not shared and global schema cache is introduced instead./Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./"
,,0.4933,realm-java,"Supporting both additive and manual schema modes (#91) * Adding very thin wrappers for Object Stores ObjectSchema and Property. * Adding method for building object schema is proxy classes * Adding rudimentary support for Object Store schemas. Using ObjectStore::update_schema() to update schema for the additive mode. * Disallowing destructive schema changes in additive mode./Invalidate schema cache when the schema version of Realm is changed by other process (#3409). invalidate schema cache when the schema version of Realm is changed by other process. Now schema cache referred by Realm instance is not shared and global schema cache is introduced instead./Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./"
,,0.1667,realm-java,Add isManaged() to RealmObject/RealmCollection (#3341) * isValid() returns true for unmanaged object and collection. * Add isManaged() to RealmObject and RealmCollection/
,,0.3115,realm-java,"Use set_string_unique to set primary key (#3488) * Migrate PK table when get 1st Realm instance * migratePrimaryKeyTableIfNeeded will be called when the first time Realm instance gets opened. * Get miss-deleted tests case for pk table back. * Update Object Store/Logout and Userstore (#104)/Invalidate schema cache when the schema version of Realm is changed by other process (#3409). invalidate schema cache when the schema version of Realm is changed by other process. Now schema cache referred by Realm instance is not shared and global schema cache is introduced instead./RealmLog (#3368) Moved RealmLog to the public API. Routes all log events through it, also from native code./"
,,0.3394,realm-java,"Update core to 2.0.0-rc4 (#3384) * And with some code cleanup. * Throw an runtime exception when input java bytes array cannot be read. * Update Object Store to solve the breaking change caused failure. See * Use instead since it seems a gcc bug hangs encryption releated tests with enabled in JNI build./Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./Add methods to RealmQuery to support byte arrays (#3285)/"
,,0.3936,realm-java,"Disallow changing PK after object created (#3418) Thrown an exception if changing the pk after the object creation./Integrate Object Store [PART2] SharedRealm (#3031) This simplified our code base a lot. Basically all APIs we need from SharedGroup/Group are wrapped in the SharedRealm. So we can just remove those classes. But we do need a few APIs from SharedGroup which is not supplied by SharedRealm because of async queries. Currently we expose those in a friend class of ShareRealm, see realm/realm-object-store#141 We are still managing Realm caches in Java although there are mechanism in OS to do the same thing. The major reason is we have method like deleteRealm needs information from cache to check if all Realm instances are closed. The ShareRealm is actually a std::shared_ptr. We hold the pointer to the std::shared_ptr in Java. Another fundamental change is that we used to have separated SharedGroups for DynamicRealm and typed Realm in the same thread. But now they are using different SharedRealm but actually the different SharedRealms are point to the same SharedGroup. And some other code cleanup./"
,,0.0669,realm-java,Updated changelog; combined duplicate implementations for both .first and .last/
,,0.0991,realm-java,"Nh/fix 3966 (#3979) Realm migration is triggered, when the primary key definition is altered (#3966)/Fixed a bug that caused unexpected MigrationNeededException in very rare case. (#3768) In sync mode, `validateTable()` must get all fields in the tabla./"
,,0.1016,realm-java,"Merge remote-tracking branch origin/master into kneth/object-store/results/Nh/fix 3966 (#3979) Realm migration is triggered, when the primary key definition is altered (#3966)/Java lint warnings with proxy class (#3948) Fix TableOrView.NO_MATCH to Table/Fixed a bug that caused unexpected MigrationNeededException in very rare case. (#3768) In sync mode, `validateTable()` must get all fields in the tabla./"
,,0.1174,realm-java,Fix various minor issues/Nh/objectstore userstore (#3838) * Add a UserStore based on ObjectStore implementation/Wrap SortDescriptor/WiP start using Object Stores Results class/
,,0.2118,realm-java,"Free the SharedRealm in phantom daemon (#4096) Treat the SharedRealm the same as other native objects. SharedRealm.close will only call Object Store Realm::close without deleting the ShareRealm pointer. Then we dont need the finalizer anymore. Fix . This is related with as well. It is possible that java close the Realm in any of the Object Stores callbacks. To avoid Object Store operating on a invalid SharedRealm pointer, binding should try to make sure after callbacks. However, it cannot be totally avoided since user could set the Realm instance to null and the instance can be GCed at any time. It is still something should be considered in the Object Store implementation./Expose schemaVersion in SyncConfig (#4058)/Call OS set_auto_refresh() & auto_refresh()/"
,,0.2589,realm-java,"Update Object Store and test cases (#4507) Update OS to 7a1924b4cf Fix detailed notification for RealmObject (#4331) See Add ObjectChangeSet & RealmObjectChangeListener. Add OsObject to wrap ObjectStores Object for notifications. No more false positive notifications for RealmObject. Use ObserverPairList in ProxyState instead of normal list to solve the potential listener removal problems which is handled well by the ObserverPairList. Fix tests./Deleted RealmObjects are now emitted as well. (#4236)/RealmResults is always live-to-updated This is the precondition of fine grained notifications. OS will trigger the collection notification immediately when transaction begins on the local thread to compute the change set if there is any. This conflicts with Javas original RealmResults behavior the original RealmResults would only be synced in the next event loop. Also, there are some edge cases dont work well with the original RealmResults behavior, see details in So: RealmResults becomes always up-to-date again which means it will never contains a invalid row. Behavior of iteration on a RealmResults still just works, it will just iterate on snapshot of collection. This means user can still delete elements from a RealmResults inside iteration. Deletion & Modification on RealmResults in simple-for-loop wont work as expected if the changes will impact the order/elements of the results. This could be solved by the future new Collection type RealmCollectionSnapshot. Add Collection.load() and Collection.isLoaded() to support java sync queries. Test fix. wont be an issue anymore since the RealmResults is always up to date and it wont contain any invalid rows. So remove the related tests. Failure tests caused by listener being triggred with beginTransaction() Remove realmResultsListenerAddedAfterCommit. when add listener to the OS Results after commit transaction, the OS CollectionNotifier will be created at the SharedGroup version of transaction committed. So the listener wont be called anymore since the all changes already exist in current SharedGroup./"
,,0.215,realm-java,"Add support for SyncConfiguration.waitForServerChanges() (#4536)/Implement getInstanceAsync (#4570) Fix Add APIs to get Realm instance asynchronously. Remove some useless methods. There some work need to be done before create the first Realm instance in the process, like creating schema table, doing migration, etc.. Those could block the UI thread quite badly. This commit tries to do those initialization work in the background and hold a Realm instance in the background until the 2nd instance created in the caller thread. A better solution than this would be do initialization in the background and only deliver a column indices cache to caller thread without holding a Realm instance in the background. But that is not possible since from the current database design, we cannot know if the schema changes compared with the last time it was opened. Also create a SharedGroup in the background and handover it to the caller thread is not ideal as well. That not only requires some design changes in the Object Store RealmCoordinator, but also is a very special use case of SharedGroup which core is not designed for. SharedGroup Leaking during the handover is another flaw for this solution we can only rely on the GC to collect the leaked SharedGroup during handover then./Fine grained locks for RealmCache (#4551) Separated lock for different RealmConfiguration instead of one lock on the RealmCache class. So Opening Realm instances from different configurations wont block each other. DynamicRealm which is created during opening type Realm will not be associated to any RealmCache to avoid recursive locks and multiple times initial block. (Also make the code easier.) This is for and part of implementation of ./refactor internal method name in RealmSchema (#4429)/Refactor Schemas into separate native and realm-based implementations (#4382) * Refactor Schemas into separate native and realm-based implementations * Fix all tests * Respond to PR comments * Temporary (git add .) kludge to fix visiblity problem/"
,,0.2651,realm-java,"Let Object Store handle table creations (#4674) This tries to progressively move more things about schemas to Object Store. First the concept of Schema in Object Store is not the same as what we have in Java. It is very much just a schema information holder and wont take care of the schema modifications. That says it is more like the ColumnIndices cache in the Java binding. So this commit try to: Instead of inheriting from the RealmSchema, change the OsRealmSchema/OsRealmObjectSchema to OsSchemaInfo/OsObjectSchemaInfo. They behave as a simple Java wrapper to the relevant OS objects. Add functions to Proxy classes which will create its own OsObjectSchemaInfo and those info can be used to create a OsSchemaInfo through the mediator. Call `SharedRealm.updateSchema` with the OsSchemaInfo which is got from the proxy interface to do table initialization. This will also fix a minor bug we have before, All tables are created even if the class is not in the module. Migration is still handled in the old way, and it will be solved in the future, to let Object Store handle it. ColumnIndices are still kept for now, but it should be computed from the OsSchemaInfo/OsObjectSchemaInfo in the future./"
,,0.2772,realm-java,"Let Object Store handle table creations (#4674) This tries to progressively move more things about schemas to Object Store. First the concept of Schema in Object Store is not the same as what we have in Java. It is very much just a schema information holder and wont take care of the schema modifications. That says it is more like the ColumnIndices cache in the Java binding. So this commit try to: Instead of inheriting from the RealmSchema, change the OsRealmSchema/OsRealmObjectSchema to OsSchemaInfo/OsObjectSchemaInfo. They behave as a simple Java wrapper to the relevant OS objects. Add functions to Proxy classes which will create its own OsObjectSchemaInfo and those info can be used to create a OsSchemaInfo through the mediator. Call `SharedRealm.updateSchema` with the OsSchemaInfo which is got from the proxy interface to do table initialization. This will also fix a minor bug we have before, All tables are created even if the class is not in the module. Migration is still handled in the old way, and it will be solved in the future, to let Object Store handle it. ColumnIndices are still kept for now, but it should be computed from the OsSchemaInfo/OsObjectSchemaInfo in the future./"
,,0.1052,realm-java,Support stable IDs for sync (#4693) * Support stable IDs for sync A special column to store stable IDs are added by sync. See for details. Calling sync::create_object instead of add_empty_row to create new object. Calling sync::create_table/sync::create_table_with_primary_key instead of add_table to create a new object schema. addPrimaryKey() is not allowed for synced Realm anymore. New API RealmSchema.createWithPrimaryKeyField is added./
,,0.2053,realm-java,"Use Object Store to handle schema migration Use Object Store to handle migration. This is for non-synced Realm. Object Store will compare the expected OsSchemaInfo with the current on on the disc. if they dont match, the migration callback supplied by java will called to do manual migration. Update Object Store to 0d0aef97b8/"
,,0.1703,realm-java,"Fix admin users not connection correctly to ROS (#4760)/Get more integration test to work (#4066) Add a new TestRule RunWithRemoteService to allow a test case create a service running in a remote process. This is very much like what we have for the RealmInterProcessTests but with more flexibility, eg.: Separate service for separate test case. Enabled sync interaction tests: notify by simple commit, notify by lots of commits. Deprecate RemoteProcessService. Since we have troubles to peacefully reseting sync server and client, just use a different user for every test. This is achieved by storing a user name inside a UserFactoryStore Realm file and retrieve it from different processes./"
,,0.1581,realm-java,"Get more integration test to work (#4066) Add a new TestRule RunWithRemoteService to allow a test case create a service running in a remote process. This is very much like what we have for the RealmInterProcessTests but with more flexibility, eg.: Separate service for separate test case. Enabled sync interaction tests: notify by simple commit, notify by lots of commits. Deprecate RemoteProcessService. Since we have troubles to peacefully reseting sync server and client, just use a different user for every test. This is achieved by storing a user name inside a UserFactoryStore Realm file and retrieve it from different processes./"
,,0.0717,realm-java,Add support for SyncSession.uploadAllLocalChanges() (#4985)/Re-add Sync Progress Notifications (#4415)/
,,0.1086,realm-java,Support stable IDs for sync (#4693) * Support stable IDs for sync A special column to store stable IDs are added by sync. See for details. Calling sync::create_object instead of add_empty_row to create new object. Calling sync::create_table/sync::create_table_with_primary_key instead of add_table to create a new object schema. addPrimaryKey() is not allowed for synced Realm anymore. New API RealmSchema.createWithPrimaryKeyField is added./
,,0.1542,realm-java,Support stable IDs for sync (#4693) * Support stable IDs for sync A special column to store stable IDs are added by sync. See for details. Calling sync::create_object instead of add_empty_row to create new object. Calling sync::create_table/sync::create_table_with_primary_key instead of add_table to create a new object schema. addPrimaryKey() is not allowed for synced Realm anymore. New API RealmSchema.createWithPrimaryKeyField is added./Turn off the column check for synced realms (#4706)/SchemaVersion for synced Realms where required by mistake (#4666)/
,,0.1075,realm-java,"Update Object Store (#5058) to 50cf5ee583 Breaking changes from Object Store: To identify a user, Object Store needs both user ID and auth URL. Thus API has been changed in UserStore. Property::PropertyType has been changed which is not the same with field types in the core anymore./[Sync] Adding user account lookup (#4882)/fixes (#4862) * fixes code in SyncUser.java (#4846)/Change password using Admin user (#4694) add the ability to change a users password from an admin user/"
,,0.0673,realm-java,Fix admin users not connection correctly to ROS (#4760)/
,,0.2784,realm-java,"Let Object Store handle table creations (#4674) This tries to progressively move more things about schemas to Object Store. First the concept of Schema in Object Store is not the same as what we have in Java. It is very much just a schema information holder and wont take care of the schema modifications. That says it is more like the ColumnIndices cache in the Java binding. So this commit try to: Instead of inheriting from the RealmSchema, change the OsRealmSchema/OsRealmObjectSchema to OsSchemaInfo/OsObjectSchemaInfo. They behave as a simple Java wrapper to the relevant OS objects. Add functions to Proxy classes which will create its own OsObjectSchemaInfo and those info can be used to create a OsSchemaInfo through the mediator. Call `SharedRealm.updateSchema` with the OsSchemaInfo which is got from the proxy interface to do table initialization. This will also fix a minor bug we have before, All tables are created even if the class is not in the module. Migration is still handled in the old way, and it will be solved in the future, to let Object Store handle it. ColumnIndices are still kept for now, but it should be computed from the OsSchemaInfo/OsObjectSchemaInfo in the future./"
,,0.359,realm-java,"Work around jmethod bug with Android cherry-pick to enabled debug in menifest which caused a crash described in Removed API to create JavaMethod from jobject/class name string. There seems to be a bug in Android JVM when getting the method by: jclass cls env->GetObjectClass(obj); jmethodID method env->GetMethodID(cls, ""xxx"", ""xxx"") The methodID retrieved by the above way triggers a strange bug in JVM, it reports the method cannot be found on a non-relevant object. Like: "" cant call boolean io.realm.DefaultCompactOnLaunchCallback.shouldCompact(long, long) on instance of io.realm.RealmTests$6 "" Where RealmTest$6 has nothing to do with that JNI call. It is not because of the local ref of cls has been deleted Even if it is deleted, the methodID should still be valid according to the doc: The class references, field IDs, and method IDs are guaranteed valid until the class is unloaded. Classes are only unloaded if all classes associated with a ClassLoader can be garbage collected, which is rare but will not be impossible in Android. The class should never be unload in this case For safety reasons, the JavaMethod should only be created from a JavaClass right now to avoid future surprise. Close object creation into OsObject (#4632) Hide the addEmptyRow from java to support future stable ID. Add bulk insertion benchmark. This wont be the final design of internal object creation API, when integration of OS object accessor, the internal API might be changed a bit since it doesnt look nice at all 5 params for the JNI call to create an object with integer primary key/"
,,0.3606,realm-java,"Work around jmethod bug with Android cherry-pick to enabled debug in menifest which caused a crash described in Removed API to create JavaMethod from jobject/class name string. There seems to be a bug in Android JVM when getting the method by: jclass cls env->GetObjectClass(obj); jmethodID method env->GetMethodID(cls, ""xxx"", ""xxx"") The methodID retrieved by the above way triggers a strange bug in JVM, it reports the method cannot be found on a non-relevant object. Like: "" cant call boolean io.realm.DefaultCompactOnLaunchCallback.shouldCompact(long, long) on instance of io.realm.RealmTests$6 "" Where RealmTest$6 has nothing to do with that JNI call. It is not because of the local ref of cls has been deleted Even if it is deleted, the methodID should still be valid according to the doc: The class references, field IDs, and method IDs are guaranteed valid until the class is unloaded. Classes are only unloaded if all classes associated with a ClassLoader can be garbage collected, which is rare but will not be impossible in Android. The class should never be unload in this case For safety reasons, the JavaMethod should only be created from a JavaClass right now to avoid future surprise. Close"
,,0.0932,realm-java,"Upgrade Realm Core to 2.8.6 (#4934) Upgrade Realm Core to 2.8.6, sync to 1.10.5. Add test case to Expose bug when querying an indexed field with Case.INSENSITIVE. Adapt DescriptorOdering changes from Object Store. See Update Object Store to 7c12b340e0/"
,,0.0863,realm-java,"Upgrade Realm Core to 2.8.6 (#4934) Upgrade Realm Core to 2.8.6, sync to 1.10.5. Add test case to Expose bug when querying an indexed field with Case.INSENSITIVE. Adapt DescriptorOdering changes from Object Store. See Update Object Store to 7c12b340e0/"
,,0.0673,realm-java,Re-add Sync Progress Notifications (#4415)/
,,0.3244,realm-java,"Merge remote-tracking branch origin/master into mc/os-schema-migration/Update Object Store (#5058) to 50cf5ee583 Breaking changes from Object Store: To identify a user, Object Store needs both user ID and auth URL. Thus API has been changed in UserStore. Property::PropertyType has been changed which is not the same with field types in the core anymore./Work around jmethod bug with Android cherry-pick to enabled debug in menifest which caused a crash described in Removed API to create JavaMethod from jobject/class name string. There seems to be a bug in Android JVM when getting the method by: jclass cls env->GetObjectClass(obj); jmethodID method env->GetMethodID(cls, ""xxx"", ""xxx"") The methodID retrieved by the above way triggers a strange bug in JVM, it reports the method cannot be found on a non-relevant object. Like: "" cant call boolean io.realm.DefaultCompactOnLaunchCallback.shouldCompact(long, long) on instance of io.realm.RealmTests$6 "" Where RealmTest$6 has nothing to do with that JNI call. It is not because of the local ref of cls has been deleted Even if it is deleted, the methodID should still be valid according to the doc: The class references, field IDs, and method IDs are guaranteed valid until the class is unloaded. Classes are only unloaded if all classes associated with a ClassLoader can be garbage collected, which is rare but will not be impossible in Android. The class should never be unload in this case For safety reasons, the JavaMethod should only be created from a JavaClass right now to avoid future surprise. Close remote-tracking branch origin/master into mc/os-schema-migration/Add CompactOnLaunch. (#4857) * Implement CompactOnLaunch. This commit adds RealmConfiguration.compactOnLaunch and RealmConfiguration.Builder.compactOnLaunch(CompactOnLaunchCallback). It makes a Realm determines if it should be compacted. * Throw an exception if it is read-only Realm. * Add readOnly_compactOnLaunch_throws * Fix a wrong signature. * Add tests to check compactOnLaunch. * Fix tests. * Add Javadoc. * Updated CHANGELOG>md * Fix a typo * PR feedback. * PR feedback: Improve tests. * PR feedback. * Improve Javadocs sentences. * Support Proguard. * Rename more accurate. * PR feedback. * Fix Proguard. * Fix JNI code. * PR feedback: Remove 2 createConfiguration. * PR feedback * Add RealmConfiguration.Builder.compactOnLaunch(). * Fix a bug of JNI code. * Add more tests. * Improve Javadoc. * PR feedback: Add a test to check a bug. * add a test to check a bug where compactOnLaunch is called each time a Realm is opened on a new thread. * PR feedback * Imporve Javadoc. * Fix a test (Thread). * PR: fix a test./Exception def/Use Object Store to handle schema migration Use Object Store to handle migration. This is for non-synced Realm. Object Store will compare the expected OsSchemaInfo with the current on on the disc. if they dont match, the migration callback supplied by java will called to do manual migration. Update Object Store to 0d0aef97b8/Enable encryption with Sync (#4746)/Nh/android support ssl (#4591) * Expose two new SyncConfiguration options to 1: Disable TLS verification. 2: provide the trusted root CA to validate the RealmObjectServer TLS connection (since OpenSSL doesnt have access to Android keystore) fixes"
,,0.3839,realm-java,"Work around jmethod bug with Android cherry-pick to enabled debug in menifest which caused a crash described in Removed API to create JavaMethod from jobject/class name string. There seems to be a bug in Android JVM when getting the method by: jclass cls env->GetObjectClass(obj); jmethodID method env->GetMethodID(cls, ""xxx"", ""xxx"") The methodID retrieved by the above way triggers a strange bug in JVM, it reports the method cannot be found on a non-relevant object. Like: "" cant call boolean io.realm.DefaultCompactOnLaunchCallback.shouldCompact(long, long) on instance of io.realm.RealmTests$6 "" Where RealmTest$6 has nothing to do with that JNI call. It is not because of the local ref of cls has been deleted Even if it is deleted, the methodID should still be valid according to the doc: The class references, field IDs, and method IDs are guaranteed valid until the class is unloaded. Classes are only unloaded if all classes associated with a ClassLoader can be garbage collected, which is rare but will not be impossible in Android. The class should never be unload in this case For safety reasons, the JavaMethod should only be created from a JavaClass right now to avoid future surprise. Close"
,,0.0806,realm-java,"Expose SyncSessionStopPolicy in SyncConfiguration (#5356) Expose SyncSessionStopPolicy as an option on SyncConfiguration. This makes it possible to make integration tests more deterministic./Unclosed realm & SyncManager::reset_for_testing See When assertion enabled, those will fail earlier. Without the assertion, all different kind of native crash will happen. Update Object Store to d1a101fda6/"
,,0.1412,realm-java,"Always use object store to create PK table (#5284) Add OsObjectStore class to wrap methods in ObjectStore.hpp. Use ObjectStore to create meta tables. Use ObjectStore to get/set primary key. Always create meta tables when open a non-exist, non-readonly Dynamic Realm. Clean code./"
,,0.0899,realm-java,getColumnInfo was checking obfuscated class name It should check the table name instead. Close
,,0.0945,realm-java,Ensure stable classes order in generated mediators (#5567) Fixes
,,0.0965,realm-java,Ensure stable classes order in generated mediators (#5567) Fixes
,,0.0989,realm-java,logout logging not resuming sync (#5820) * Fixes logout/login resume syncing/
,,0.066,rocksdb,Abstractions for common iterator behaviour/
,,0.09,rocksdb,"Fix leak when create_missing_column_families=true on ThreadStatus Summary: An entry of ConstantColumnFamilyInfo is created when: 1. DB::Open 2. CreateColumnFamily. However, there are cases that DB::Open could also call CreateColumnFamily when create_missing_column_families=true. As a result, it will create duplicate ConstantColumnFamilyInfo and one of them would be leaked. Test Plan: ./deletefile_test Reviewers: igor, sdong, ljin Reviewed By: ljin Subscribers: dhruba, leveldb Differential Revision:"
,,0.1047,rocksdb,"Add missing hashCode() implementation Summary: Whenever a Java class implements equals(), it has to implement hashCode(), otherwise there might be weird behavior when inserting instances of the class in a hash map for example. This adds two missing hashCode() implementations and extends tests to test the hashCode() implementations. Test Plan: make jtest Reviewers: rven, igor, sdong, yhchiang Reviewed By: yhchiang Subscribers: anthony, dhruba, leveldb Differential Revision: Fixed test failures Summary: The option bottommost_level_compaction was introduced lately. This option breaks the Java API behavior. To prevent the library from doing so we set that option to a fixed value in Java. In future we are going to remove that portion and replace the hardcoded options using a more flexible way. Fixed bug introduced by WriteBatchWithIndex Patch Lately icanadi changed the behavior of WriteBatchWithIndex. See commit: 821cff114e57efa67711c1c1c105aa02831a0d23 This commit solves problems introduced by above mentioned commit. Test Plan: make rocksdbjava make jtest Reviewers: adamretter, ankgup87, yhchiang Reviewed By: yhchiang Subscribers: igor, dhruba Differential Revision:"
,,0.1545,rocksdb,"Transactions: Release Locks when rolling back to a savepoint Summary: Transaction::RollbackToSavePoint() will now release any locks that were taken since the previous SavePoint. To do this cleanly, I moved tracked_keys_ management into TransactionBase. Test Plan: New Transaction test. Reviewers: igor, rven, sdong Reviewed By: sdong Subscribers: dhruba, spetrunia, leveldb Differential Revision:"
,,0.1545,rocksdb,"Transactions: Release Locks when rolling back to a savepoint Summary: Transaction::RollbackToSavePoint() will now release any locks that were taken since the previous SavePoint. To do this cleanly, I moved tracked_keys_ management into TransactionBase. Test Plan: New Transaction test. Reviewers: igor, rven, sdong Reviewed By: sdong Subscribers: dhruba, spetrunia, leveldb Differential Revision:"
,,0.1484,rocksdb,"Transactions: Release Locks when rolling back to a savepoint Summary: Transaction::RollbackToSavePoint() will now release any locks that were taken since the previous SavePoint. To do this cleanly, I moved tracked_keys_ management into TransactionBase. Test Plan: New Transaction test. Reviewers: igor, rven, sdong Reviewed By: sdong Subscribers: dhruba, spetrunia, leveldb Differential Revision:"
,,0.0793,rocksdb,"TransactionDB Custom Locking API Summary: Prototype of API to allow MyRocks to override default Mutex/CondVar used by transactions with their own implementations. They would simply need to pass their own implementations of Mutex/CondVar to the templated TransactionDB::Open(). Default implementation of TransactionDBMutex/TransactionDBCondVar provided (but the code is not currently changed to use this). Let me know if this API makes sense or if it should be changed Test Plan: n/a Reviewers: yhchiang, rven, igor, sdong, spetrunia Reviewed By: spetrunia Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.0852,rocksdb,"Have a way for compaction filter to ignore snapshots Summary: Provide an API for compaction filter to specify that it needs to be applied even if there are snapshots. Test Plan: DBTestCompactionFilter.CompactionFilterIgnoreSnapshot Reviewers: yhchiang, IslamAbdelRahman, sdong, anthony Reviewed By: anthony Subscribers: yoshinorim, dhruba, leveldb Differential Revision:"
,,0.0609,rocksdb,Fix a memory leak of Slice objects from org.rocksdb.WBWIRocksIterator#entry1/
,,0.1068,rocksdb,"Temporarily disable unstable tests in memory_test.cc Summary: memory_test.cc has some tests that are not unstable but hard to reproduce, and the cause is the test itself not the code. Temporarily disable the tests until we have a good fix. Test Plan: memory_test Reviewers: sdong, anthony, IslamAbdelRahman, rven, kradhakrishnan Subscribers: dhruba, leveldb Differential Revision:"
,,0.1051,rocksdb,"Removing data race from expirable transactions Summary: Doing inline checking of transaction expiration instead of using a callback. Test Plan: To be added Reviewers: anthony Reviewed By: anthony Subscribers: leveldb, dhruba Differential Revision:"
,,0.0661,rocksdb,"Enable MS compiler warning c4244. Mostly due to the fact that there are differences in sizes of int,long on 64 bit systems vs GNU./"
,,0.1596,rocksdb,"Modification of WriteBatch to support two phase commit Summary: Adds three new WriteBatch data types: Prepare(xid), Commit(xid), Rollback(xid). Prepare(xid) should precede the (single) operation to which is applies. There can obviously be multiple Prepare(xid) markers. There should only be one Rollback(xid) or Commit(xid) marker yet not both. None of this logic is currently enforced and will most likely be implemented further up such as in the memtableinserter. All three markers are similar to PutLogData in that they are writebatch meta-data, ie stored but not counted. All three markers differ from PutLogData in that they will actually be written to disk. As for WriteBatchWithIndex, Prepare, Commit, Rollback are all implemented just as PutLogData and none are tested just as PutLogData. Test Plan: single unit test in write_batch_test. Reviewers: hermanlee4, sdong, anthony Subscribers: leveldb, dhruba, vasilep, andrewkr Differential Revision:"
,,0.2589,rocksdb,"[rocksdb] 2PC double recovery bug fix Summary: 1. prepare() 2. crash 3. recover 4. commit() 5. crash 6. data is lost This is due to the transaction data still only residing in the WAL but because the logs were flushed on the first recovery the data is ignored on the second recovery. We must scan all logs found on recovery and only ignore redundant data at the time of replay. It is not possible to know which logs still contain relevant data at time of recovery. We cannot simply ignore a log because all of the non-2pc data it contains has already been written to L0. The changes made to MemTableInserter are to ensure that prepared sections are still recovered even if all of the non-2pc data in that log has already been flushed to L0. Test Plan: Provided test. Reviewers: sdong Subscribers: andrewkr, hermanlee4, dhruba, leveldb Differential Revision: Recovery path sequence miscount fix Summary: Consider the following WAL with 4 batch entries prefixed with their sequence at time of memtable insert. [1: BEGIN_PREPARE, PUT, PUT, PUT, PUT, END_PREPARE(a)] [1: BEGIN_PREPARE, PUT, PUT, PUT, PUT, END_PREPARE(b)] [4: COMMIT(a)] [7: COMMIT(b)] The first two batches do not consume any sequence numbers so are both prefixed with seq=1. For 2pc commit, memtable insertion takes place before COMMIT batch is written to WAL. We can see that sequence number consumption takes place between WAL entries giving us the seemingly sparse sequence prefix for WAL entries. This is a valid WAL. Because with 2PC markers one WriteBatch points to another batch containing its inserts a writebatch can consume more or less sequence numbers than the number of sequence consuming entries that it contains. We can see that, given the entries in the WAL, 6 sequence ids were consumed. Yet on recovery the maximum sequence consumed would be 7 + 3 (the number of sequence numbers consumed by COMMIT(b)) So, now upon recovery we must track the actual consumption of sequence numbers. In the provided scenario there will be no sequence gaps, but it is possible to produce a sequence gap. This should not be a problem though. correct? Test Plan: provided test. Reviewers: sdong Subscribers: andrewkr, leveldb, dhruba, hermanlee4 Differential Revision: Two Phase Transaction Summary: Two Phase Commit addition to RocksDB. See wiki: Quip: Depends on: WriteBatch modification: Memtable Log Referencing and Prepared Batch Recovery: Test Plan: SimpleTwoPhaseTransactionTest PersistentTwoPhaseTransactionTest. TwoPhaseRollbackTest TwoPhaseMultiThreadTest TwoPhaseLogRollingTest TwoPhaseEmptyWriteTest TwoPhaseExpirationTest Reviewers: IslamAbdelRahman, sdong Reviewed By: sdong Subscribers: leveldb, hermanlee4, andrewkr, vasilep, dhruba, santoshb Differential Revision: multithreaded transaction test Summary: Refactored db_bench transaction stress tests so that they can be called from unit tests as well. Test Plan: run new unit test as well as db_bench Reviewers: yhchiang, IslamAbdelRahman, sdong Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba, leveldb Differential Revision: Summary: Add function to reinitialize a transaction object so that it can be reused. This is an optimization so users can potentially avoid reallocating transaction objects. Test Plan: added tests Reviewers: yhchiang, kradhakrishnan, IslamAbdelRahman, sdong Reviewed By: sdong Subscribers: jkedgar, dhruba, leveldb Differential Revision:"
,,0.08800000000000001,rocksdb,"Add multithreaded transaction test Summary: Refactored db_bench transaction stress tests so that they can be called from unit tests as well. Test Plan: run new unit test as well as db_bench Reviewers: yhchiang, IslamAbdelRahman, sdong Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba, leveldb Differential Revision:"
,,0.2083,rocksdb,"[rocksdb] Recovery path sequence miscount fix Summary: Consider the following WAL with 4 batch entries prefixed with their sequence at time of memtable insert. [1: BEGIN_PREPARE, PUT, PUT, PUT, PUT, END_PREPARE(a)] [1: BEGIN_PREPARE, PUT, PUT, PUT, PUT, END_PREPARE(b)] [4: COMMIT(a)] [7: COMMIT(b)] The first two batches do not consume any sequence numbers so are both prefixed with seq=1. For 2pc commit, memtable insertion takes place before COMMIT batch is written to WAL. We can see that sequence number consumption takes place between WAL entries giving us the seemingly sparse sequence prefix for WAL entries. This is a valid WAL. Because with 2PC markers one WriteBatch points to another batch containing its inserts a writebatch can consume more or less sequence numbers than the number of sequence consuming entries that it contains. We can see that, given the entries in the WAL, 6 sequence ids were consumed. Yet on recovery the maximum sequence consumed would be 7 + 3 (the number of sequence numbers consumed by COMMIT(b)) So, now upon recovery we must track the actual consumption of sequence numbers. In the provided scenario there will be no sequence gaps, but it is possible to produce a sequence gap. This should not be a problem though. correct? Test Plan: provided test. Reviewers: sdong Subscribers: andrewkr, leveldb, dhruba, hermanlee4 Differential Revision: Memtable Log Referencing and Prepared Batch Recovery Summary: This diff is built on top of WriteBatch modification: and adds the required functionality to rocksdb core necessary for rocksdb to support 2PC. modfication of DBImpl::WriteImpl() added two arguments *uint64_t log_used nullptr, uint64_t log_ref 0; *log_used is an output argument which will return the log number which the incoming batch was inserted into, 0 if no WAL insert took place. log_ref is a supplied log_number which all memtables inserted into will reference after the batch insert takes place. This number will reside in FindMinPrepLogReferencedByMemTable() until all Memtables insertinto have flushed. Recovery/writepath is now aware of prepared batches and commit and rollback markers. Test Plan: There is currently no test on this diff. All testing of this functionality takes place in the Transaction layer/diff but I will add some testing. Reviewers: IslamAbdelRahman, sdong Subscribers: leveldb, santoshb, andrewkr, vasilep, dhruba, hermanlee4 Differential Revision:"
,,0.1058,rocksdb,"Use correct sequence number when creating memtable Summary: copied from: Opening existing RocksDB attempts recovery from log files, which uses wrong sequence number to create the memtable. This is a regression introduced in change a400336. This change includes a test demonstrating the problem, without the fix the test fails with ""Operation failed. Try again.: Transaction could not check for conflicts for operation at SequenceNumber 1 as the MemTable only contains changes newer than SequenceNumber 2. Increasing the value of the max_write_buffer_number_to_maintain option could reduce the frequency of this error"" This change is a joint effort by Peter Stig Edwards thatsafunnyname and me. Closes Differential Revision: D4143791 Pulled By: reidHoruff fbshipit-source-id: 5a25033/"
,,0.066,rocksdb,Add TableBuilderOptions::level and relevant changes (#1335)/
,,0.1056,rocksdb,"Fix bug of Checkpoint loses recent transactions with 2PC Summary: If 2PC is enabled, checkpoint may not copy previous log files that contain uncommitted prepare records. In this diff we keep those files. Closes Differential Revision: D4368319 Pulled By: siying fbshipit-source-id: cc2c746/"
,,0.1354,rocksdb,"Fixing Solaris Sparc crash due to cached TLS Summary: Workaround for Solaris gcc binary. Program is crashing, because when TLS of perf context that is used twice on same frame, it is damaged thus Segmentation fault. Issue: Closes Differential Revision: D4922274 Pulled By: siying fbshipit-source-id: 549105ebce9a8ce08a737f4d6b9f2312ebcde9a8/"
,,0.1042,rocksdb,Improved transactions support in C API Summary: Solves Added OptimisticTransactionDB to the C API. Added missing merge operations to Transaction. Added missing get_for_update operation to transaction If required I will create tests for this another day. Closes Differential Revision: D5600906 Pulled By: yiwu-arbug fbshipit-source-id: da23e4484433d8f59d471f778ff2ae210e3fe4eb/
,,0.1307,rocksdb,"Use PinnableSlice in Transactions Summary: The ::Get from DB is not augmented with an overload method that takes a PinnableSlice instead of a string. Transactions however are not yet upgraded to use the new API. As a result, transaction users such as MyRocks cannot benefit from it. This patch updates the transactional API with a PinnableSlice overload. Closes Differential Revision: D5645770 Pulled By: maysamyabandeh fbshipit-source-id: f6af520df902f842de1bcf99bed3e8dfc43ad96d/"
,,0.1147,rocksdb,"Make writable_file_max_buffer_size dynamic Summary: The DBOptions::writable_file_max_buffer_size can be changed dynamically. Closes Differential Revision: D6152720 Pulled By: shligit fbshipit-source-id: aa0c0cfcfae6a54eb17faadb148d904797c68681/Repair DBs with trailing slash in name Summary: Problem: `DB::SanitizeOptions` strips trailing slash from `wal_dir` but not `dbname` We check whether `wal_dir` and `dbname` refer to the same directory using string equality: Providing `dbname` with trailing slash causes default `wal_dir` to be misidentified as a separate directory. Then the repair tries to add all SST files to the `VersionEdit` twice (once for `dbname` dir, once for `wal_dir`) and fails with coredump. Solution: Add a new `Env` function, `AreFilesSame`, which uses device and inode number to check whether files are the same. Its currently only implemented in `PosixEnv`. Migrate repair to use `AreFilesSame` to check whether `dbname` and `wal_dir` are same. If unsupported, falls back to string comparison. Closes Differential Revision: D5761349 Pulled By: ajkr fbshipit-source-id: c839d548678b742af1166d60b09abd94e5476238/"
,,0.242,rocksdb,"WritePrepared Txn: Refactoring TrackKeys Summary: This patch clarifies and refactors the logic around tracked keys in transactions. Closes Differential Revision: D6290258 Pulled By: maysamyabandeh fbshipit-source-id: 03b50646264cbcc550813c060b180fc7451a55c1/WritePrepared Txn: ValidateSnapshot Summary: Implements ValidateSnapshot for WritePrepared txns and also adds a unit test to clarify the contract of this function. Closes Differential Revision: D6199405 Pulled By: maysamyabandeh fbshipit-source-id: ace509934c307ea5d26f4bbac5f836d7c80fd240/Enable two write queues for transactions Summary: Enable concurrent_prepare flag for WritePrepared transactions and extend the existing transaction tests with this config. Closes Differential Revision: D6106534 Pulled By: maysamyabandeh fbshipit-source-id: 88c8d21d45bc492beb0a131caea84a2ac5e7d38c/WritePrepared Txn: Iterator Summary: On iterator create, take a snapshot, create a ReadCallback and pass the ReadCallback to the underlying DBIter to check if key is committed. Closes Differential Revision: D6001471 Pulled By: yiwu-arbug fbshipit-source-id: 3565c4cdaf25370ba47008b0e0cb65b31dfe79fe/WritePrepared Txn: end-to-end tests Summary: Enable WritePrepared policy for existing transaction tests. Closes Differential Revision: D5993614 Pulled By: maysamyabandeh fbshipit-source-id: d1eb53e2920c4e2a56434bb001231c98426f3509/WritePrepared Txn: Rollback Summary: Implement the rollback of WritePrepared txns. For each modified value, it reads the value before the txn and write it back. This would cancel out the effect of transaction. It also remove the rolled back txn from prepared heap. Closes Differential Revision: D5937575 Pulled By: maysamyabandeh fbshipit-source-id: a6d3c47f44db3729f44b287a80f97d08dc4e888d/WritePrepared Txn: Recovery Summary: Recover txns from the WAL. Also added some unit tests. Closes Differential Revision: D5859596 Pulled By: maysamyabandeh fbshipit-source-id: 6424967b231388093b4effffe0a3b1b7ec8caeb0/WritePrepared Txn: Advance seq one per batch Summary: By default the seq number in DB is increased once per written key. WritePrepared txns requires the seq to be increased once per the entire batch so that the seq would be used as the prepare timestamp by which the transaction is identified. Also we need to increase seq for the commit marker since it would give a unique id to the commit timestamp of transactions. Two unit tests are added to verify our understanding of how the seq should be increased. The recovery path requires much more work and is left to another patch. Closes Differential Revision: D5837843 Pulled By: maysamyabandeh fbshipit-source-id: a08960b93d727e1cf438c254d0c2636fb133cc1c/write-prepared txn: call IsInSnapshot Summary: This patch instruments the read path to verify each read value against an optional ReadCallback class. If the value is rejected, the reader moves on to the next value. The WritePreparedTxn makes use of this feature to skip sequence numbers that are not in the read snapshot. Closes Differential Revision: D5787375 Pulled By: maysamyabandeh fbshipit-source-id: 49d808b3062ab35e7ae98ad388f659757794184c/Update WritePrepared with the pseudo code Summary: Implement the main body of WritePrepared pseudo code. This includes PrepareInternal and CommitInternal, as well as AddCommitted which updates the commit map. It also provides a IsInSnapshot method that could be later called form the read path to decide if a version is in the read snapshot or it should other be skipped. This patch lacks unit tests and does not attempt to offer an efficient implementation. The idea is that to have the API specified so that we can work on related tasks in parallel. Closes Differential Revision: D5640021 Pulled By: maysamyabandeh fbshipit-source-id: bfa7a05e8d8498811fab714ce4b9c21530514e1c/"
,,0.1984,rocksdb,"WritePrepared Txn: Lock-free CommitMap Summary: We had two proposals for lock-free commit maps. This patch implements the latter one that was simpler. We can later experiment with both proposals. In this impl each entry is an std::atomic of uint64_t, which are accessed via memory_order_acquire/release. In x86_64 arch this is compiled to simple reads and writes from memory. Closes Differential Revision: D5800724 Pulled By: maysamyabandeh fbshipit-source-id: 41abae9a4a5df050a8eb696c43de11c2770afdda/Advance max evicted seq in coarser granularity Summary: This patch advances the max_evicted_seq_ is larger granularities to reduce the overhead of updating the relevant data structures. It also refactor the related code and adds testing to that. As part of this patch some of the TODOs for removing usage of non-static const members are also addressed. Closes Differential Revision: D5772928 Pulled By: maysamyabandeh fbshipit-source-id: f4fcc2948be69c034f10812cf922ce5ab82ef98c/WriteAtPrepare: Efficient read from snapshot list Summary: Divide the old snapshots to two lists: a few that fit into a cached array and the rest in a vector, which is expected to be empty in normal cases. The former is to optimize concurrent reads from snapshots without requiring locks. It is done by an array of std::atomic, from which std::memory_order_acquire reads are compiled to simple read instructions in most of the x86_64 architectures. Closes Differential Revision: D5660504 Pulled By: maysamyabandeh fbshipit-source-id: 524fcf9a8e7f90a92324536456912a99aaa6740c/Add unit test for WritePrepared skeleton Summary: Closes Differential Revision: D5660516 Pulled By: maysamyabandeh fbshipit-source-id: f3f3d3b5f544007a7fbdd78e49e4738b4437c7ee/Update WritePrepared with the pseudo code Summary: Implement the main body of WritePrepared pseudo code. This includes PrepareInternal and CommitInternal, as well as AddCommitted which updates the commit map. It also provides a IsInSnapshot method that could be later called form the read path to decide if a version is in the read snapshot or it should other be skipped. This patch lacks unit tests and does not attempt to offer an efficient implementation. The idea is that to have the API specified so that we can work on related tasks in parallel. Closes Differential Revision: D5640021 Pulled By: maysamyabandeh fbshipit-source-id: bfa7a05e8d8498811fab714ce4b9c21530514e1c/"
,,0.1539,rocksdb,"WritePrepared Txn: Refactoring TrackKeys Summary: This patch clarifies and refactors the logic around tracked keys in transactions. Closes Differential Revision: D6290258 Pulled By: maysamyabandeh fbshipit-source-id: 03b50646264cbcc550813c060b180fc7451a55c1/WritePrepared Txn: ValidateSnapshot Summary: Implements ValidateSnapshot for WritePrepared txns and also adds a unit test to clarify the contract of this function. Closes Differential Revision: D6199405 Pulled By: maysamyabandeh fbshipit-source-id: ace509934c307ea5d26f4bbac5f836d7c80fd240/WritePrepared Txn: Optimize for recoverable state Summary: GetCommitTimeWriteBatch is currently used to store some state as part of commit in 2PC. In MyRocks it is specifically used to store some data that would be needed only during recovery. So it is not need to be stored in memtable right after each commit. This patch enables an optimization to write the GetCommitTimeWriteBatch only to the WAL. The batch will be written to memtable during recovery when the WAL is replayed. To cover the case when WAL is deleted after memtable flush, the batch is also buffered and written to memtable right before each memtable flush. Closes Differential Revision: D6148023 Pulled By: maysamyabandeh fbshipit-source-id: 2d09bae5565abe2017c0327421010d5c0d55eaa7/Enable two write queues for transactions Summary: Enable concurrent_prepare flag for WritePrepared transactions and extend the existing transaction tests with this config. Closes Differential Revision: D6106534 Pulled By: maysamyabandeh fbshipit-source-id: 88c8d21d45bc492beb0a131caea84a2ac5e7d38c/WritePrepared Txn: Recovery Summary: Recover txns from the WAL. Also added some unit tests. Closes Differential Revision: D5859596 Pulled By: maysamyabandeh fbshipit-source-id: 6424967b231388093b4effffe0a3b1b7ec8caeb0/"
,,0.2753,rocksdb,"WritePrepared Txn: cross-compatibility test Summary: Add tests to ensure that WritePrepared and WriteCommitted policies are cross compatible when the db WAL is empty. This is important when the admin want to switch between the policies. In such case, before the switch the admin needs to empty the WAL by i) committing/rollbacking all the pending transactions, ii) FlushMemTables Closes Differential Revision: D6227247 Pulled By: maysamyabandeh fbshipit-source-id: bcde3d92c1e89cda3b9cfa69f6a20af5d8993db7/WritePrepared Txn: duplicate keys Summary: With WriteCommitted, when the write batch has duplicate keys, the txn db simply inserts them to the db with different seq numbers and let the db ignore/merge the duplicate values at the read time. With WritePrepared all the entries of the batch are inserted with the same seq number which prevents us from benefiting from this simple solution. This patch applies a hackish solution to unblock the end-to-end testing. The hack is to be replaced with a proper solution soon. The patch simply detects the duplicate key insertions, and mark the previous one as obsolete. Then before writing to the db it rewrites the batch eliminating the obsolete keys. This would incur a memcpy cost. Furthermore handing duplicate merge would require to do FullMerge instead of simply ignoring the previous value, which is not handled by this patch. Closes Differential Revision: D5976337 Pulled By: maysamyabandeh fbshipit-source-id: 114e65b66f137d8454ff2d1d782b8c05da95f989/Fix WriteBatchWithIndex::GetFromBatchAndDB not allowing StackableDB Summary: Closes Differential Revision: D5829682 Pulled By: yiwu-arbug fbshipit-source-id: abb8fa14b58cea7c416282f9be19e8b1a7961c6e/write-prepared txn: call IsInSnapshot Summary: This patch instruments the read path to verify each read value against an optional ReadCallback class. If the value is rejected, the reader moves on to the next value. The WritePreparedTxn makes use of this feature to skip sequence numbers that are not in the read snapshot. Closes Differential Revision: D5787375 Pulled By: maysamyabandeh fbshipit-source-id: 49d808b3062ab35e7ae98ad388f659757794184c/Use PinnableSlice in Transactions Summary: The ::Get from DB is not augmented with an overload method that takes a PinnableSlice instead of a string. Transactions however are not yet upgraded to use the new API. As a result, transaction users such as MyRocks cannot benefit from it. This patch updates the transactional API with a PinnableSlice overload. Closes Differential Revision: D5645770 Pulled By: maysamyabandeh fbshipit-source-id: f6af520df902f842de1bcf99bed3e8dfc43ad96d/"
,,0.1119,rocksdb,WritePrepared Txn: Refactor conf params Summary: Summary of changes: Move seq_per_batch out of Options Rename concurrent_prepare to two_write_queues Add allocate_seq_only_for_data_ Closes Differential Revision: D6304458 Pulled By: maysamyabandeh fbshipit-source-id: 08e685bfa82bbc41b5b1c5eb7040a8ca6e05e58c/Enable two write queues for transactions Summary: Enable concurrent_prepare flag for WritePrepared transactions and extend the existing transaction tests with this config. Closes Differential Revision: D6106534 Pulled By: maysamyabandeh fbshipit-source-id: 88c8d21d45bc492beb0a131caea84a2ac5e7d38c/
,,0.1865,rocksdb,WritePrepared Txn: Recovery Summary: Recover txns from the WAL. Also added some unit tests. Closes Differential Revision: D5859596 Pulled By: maysamyabandeh fbshipit-source-id: 6424967b231388093b4effffe0a3b1b7ec8caeb0/WritePrepared Txn: Advance seq one per batch Summary: By default the seq number in DB is increased once per written key. WritePrepared txns requires the seq to be increased once per the entire batch so that the seq would be used as the prepare timestamp by which the transaction is identified. Also we need to increase seq for the commit marker since it would give a unique id to the commit timestamp of transactions. Two unit tests are added to verify our understanding of how the seq should be increased. The recovery path requires much more work and is left to another patch. Closes Differential Revision: D5837843 Pulled By: maysamyabandeh fbshipit-source-id: a08960b93d727e1cf438c254d0c2636fb133cc1c/
,,0.3083,rocksdb,"Add a Close() method to DB to return status when closing a db Summary: Currently, the only way to close an open DB is to destroy the DB object. There is no way for the caller to know the status. In one instance, the destructor encountered an error due to failure to close a log file on HDFS. In order to prevent silent failures, we add DB::Close() that calls CloseImpl() which must be implemented by its descendants. The main failure point in the destructor is closing the log file. This patch also adds a Close() entry point to Logger in order to get status. When DBOptions::info_log is allocated and owned by the DBImpl, it is explicitly closed by DBImpl::CloseImpl(). Closes Differential Revision: D6698158 Pulled By: anand1976 fbshipit-source-id: 9468e2892553eb09c4c41b8723f590c0dbd8ab7d/"
,,0.1053,rocksdb,WritePrepared Txn: stress test Summary: Augment the existing MySQLStyleTransactionTest to check for more core case scenarios. The changes showed effective in revealing the bugs reported in and Closes Differential Revision: D6476862 Pulled By: maysamyabandeh fbshipit-source-id: 5068497702d67ffc206a58ed96f8578fbb510137/
,,0.1533,rocksdb,"WritePrepared Txn: Duplicate Keys, Memtable part Summary: Currently DB does not accept duplicate keys (keys with the same user key and the same sequence number). If Memtable returns false when receiving such keys, we can benefit from this signal to properly increase the sequence number in the rare cases when we have a duplicate key in the write batch written to DB under WritePrepared transactions. Closes Differential Revision: D6822412 Pulled By: maysamyabandeh fbshipit-source-id: adea3ce5073131cd38ed52b16bea0673b1a19e77/"
,,0.1415,rocksdb,"WritePrepared Txn: Duplicate Keys, Memtable part Summary: Currently DB does not accept duplicate keys (keys with the same user key and the same sequence number). If Memtable returns false when receiving such keys, we can benefit from this signal to properly increase the sequence number in the rare cases when we have a duplicate key in the write batch written to DB under WritePrepared transactions. Closes Differential Revision: D6822412 Pulled By: maysamyabandeh fbshipit-source-id: adea3ce5073131cd38ed52b16bea0673b1a19e77/"
,,0.3039,rocksdb,"Add a Close() method to DB to return status when closing a db Summary: Currently, the only way to close an open DB is to destroy the DB object. There is no way for the caller to know the status. In one instance, the destructor encountered an error due to failure to close a log file on HDFS. In order to prevent silent failures, we add DB::Close() that calls CloseImpl() which must be implemented by its descendants. The main failure point in the destructor is closing the log file. This patch also adds a Close() entry point to Logger in order to get status. When DBOptions::info_log is allocated and owned by the DBImpl, it is explicitly closed by DBImpl::CloseImpl(). Closes Differential Revision: D6698158 Pulled By: anand1976 fbshipit-source-id: 9468e2892553eb09c4c41b8723f590c0dbd8ab7d/"
,,0.3039,rocksdb,"Add a Close() method to DB to return status when closing a db Summary: Currently, the only way to close an open DB is to destroy the DB object. There is no way for the caller to know the status. In one instance, the destructor encountered an error due to failure to close a log file on HDFS. In order to prevent silent failures, we add DB::Close() that calls CloseImpl() which must be implemented by its descendants. The main failure point in the destructor is closing the log file. This patch also adds a Close() entry point to Logger in order to get status. When DBOptions::info_log is allocated and owned by the DBImpl, it is explicitly closed by DBImpl::CloseImpl(). Closes Differential Revision: D6698158 Pulled By: anand1976 fbshipit-source-id: 9468e2892553eb09c4c41b8723f590c0dbd8ab7d/"
,,0.1879,rocksdb,"fix for checkpoint directory with trailing slash(es) Summary: previously if `checkpoint_dir` contained a trailing slash, wed attempt to create the `.tmp` directory under `checkpoint_dir` due to simply concatenating `checkpoint_dir + "".tmp""`. This failed because `checkpoint_dir` hadnt been created yet and our directory creation is non-recursive. This PR fixes the issue by always creating the `.tmp` directory in the same parent as `checkpoint_dir` by stripping trailing slashes before concatenating. Closes Differential Revision: D6574952 Pulled By: ajkr fbshipit-source-id: a6daa6777a901eac2460cd0140c9515f7241aefc/"
,,0.3667,rocksdb,"WritePrepared Txn: address some pending TODOs Summary: This patch addresses a couple of minor TODOs for WritePrepared Txn such as double checking some assert statements at runtime as well, skip extra AddPrepared in non-2pc transactions, and safety check for infinite loops. Closes Differential Revision: D6617002 Pulled By: maysamyabandeh fbshipit-source-id: ef6673c139cb49f64c0879508d2f573b78609aca/WritePrepared Txn: GC old_commit_map_ Summary: Garbage collect entries from old_commit_map_ when the corresponding snapshots are released. Closes Differential Revision: D6528478 Pulled By: maysamyabandeh fbshipit-source-id: 15d1566d85d4ac07036bc0dc47418f6c3228d4bf/WritePrepared Txn: stress test Summary: Augment the existing MySQLStyleTransactionTest to check for more core case scenarios. The changes showed effective in revealing the bugs reported in and Closes Differential Revision: D6476862 Pulled By: maysamyabandeh fbshipit-source-id: 5068497702d67ffc206a58ed96f8578fbb510137/WritePrepared Txn: PreReleaseCallback Summary: Add PreReleaseCallback to be called at the end of WriteImpl but before publishing the sequence number. The callback is used in WritePrepareTxn to i) update the commit map, ii) update the last published sequence number in the 2nd write queue. It also ensures that all the commits will go to the 2nd queue. These changes will ensure that the commit map is updated before the sequence number is published and used by reading snapshots. If we use two write queues, the snapshots will use the seq number published by the 2nd queue. If we use one write queue (the default, the snapshots will use the last seq number in the memtable, which also indicates the last published seq number. Closes Differential Revision: D6438959 Pulled By: maysamyabandeh fbshipit-source-id: f8b6c434e94bc5f5ab9cb696879d4c23e2577ab9/"
,,0.3237,rocksdb,"WritePrepared Txn: Duplicate Keys, Txn Part Summary: This patch takes advantage of memtable being able to detect duplicate and returning TryAgain to handle duplicate keys in WritePrepared Txns. Through WriteBatchWithIndexs index it detects existence of at least a duplicate key in the write batch. If duplicate key was reported, it then pays the cost of counting the number of sub-patches by iterating over the write batch and pass it to DBImpl::Write. DB will make use of the provided batch_count to assign proper sequence numbers before sending them to the WAL. When later inserting the batch to the memtable, it increases the seq each time memtbale reports a duplicate (a sub-patch in our counting) and tries again. Closes Differential Revision: D6873699 Pulled By: maysamyabandeh fbshipit-source-id: db8487526c3a5dc1ddda0ea49f0f979b26ae648d/Split SnapshotConcurrentAccessTest into 20 sub tests Summary: SnapshotConcurrentAccessTest sometimes times out when running on the test infra. This patch splits the test into smaller sub-tests to avoid the timeout. It also benefits from lower run-time of each sub-test and increases the coverage of the test. The overall run-time of each final sub-test is at most half of the original test so we should no longer see a timeout. Closes Differential Revision: D6839427 Pulled By: maysamyabandeh fbshipit-source-id: d53fdb157109e2438ca7fe447d0cf4b71f304bd8/WritePrepared Txn: address some pending TODOs Summary: This patch addresses a couple of minor TODOs for WritePrepared Txn such as double checking some assert statements at runtime as well, skip extra AddPrepared in non-2pc transactions, and safety check for infinite loops. Closes Differential Revision: D6617002 Pulled By: maysamyabandeh fbshipit-source-id: ef6673c139cb49f64c0879508d2f573b78609aca/WritePrepared Txn: non-2pc write in one round Summary: Currently non-2pc writes do the 2nd dummy write to actually commit the transaction. This was necessary to ensure that publishing the commit sequence number will be done only from one queue (the queue that does not write to memtable). This is however not necessary when we have only one write queue, which is actually the setup that would be used by non-2pc writes. This patch eliminates the 2nd write when two_write_queues are disabled by updating the commit map in the 1st write. Closes Differential Revision: D6575392 Pulled By: maysamyabandeh fbshipit-source-id: 8ab458f7ca506905962f9166026b2ec81e749c46/WritePrepared Txn: GC old_commit_map_ Summary: Garbage collect entries from old_commit_map_ when the corresponding snapshots are released. Closes Differential Revision: D6528478 Pulled By: maysamyabandeh fbshipit-source-id: 15d1566d85d4ac07036bc0dc47418f6c3228d4bf/"
,,0.3157,rocksdb,"WritePrepared Txn: Duplicate Keys, Txn Part Summary: This patch takes advantage of memtable being able to detect duplicate and returning TryAgain to handle duplicate keys in WritePrepared Txns. Through WriteBatchWithIndexs index it detects existence of at least a duplicate key in the write batch. If duplicate key was reported, it then pays the cost of counting the number of sub-patches by iterating over the write batch and pass it to DBImpl::Write. DB will make use of the provided batch_count to assign proper sequence numbers before sending them to the WAL. When later inserting the batch to the memtable, it increases the seq each time memtbale reports a duplicate (a sub-patch in our counting) and tries again. Closes Differential Revision: D6873699 Pulled By: maysamyabandeh fbshipit-source-id: db8487526c3a5dc1ddda0ea49f0f979b26ae648d/WritePrepared Txn: stress test Summary: Augment the existing MySQLStyleTransactionTest to check for more core case scenarios. The changes showed effective in revealing the bugs reported in and Closes Differential Revision: D6476862 Pulled By: maysamyabandeh fbshipit-source-id: 5068497702d67ffc206a58ed96f8578fbb510137/WritePrepared Txn: fix bug with Rollback seq Summary: The sequence number was not properly advanced after a rollback marker. The patch extends the existing unit tests to detect the bug and also fixes it. Closes Differential Revision: D6304291 Pulled By: maysamyabandeh fbshipit-source-id: 1b519c44a5371b802da49c9e32bd00087a8da401/"
,,0.2807,rocksdb,"WritePrepared Txn: Duplicate Keys, Txn Part Summary: This patch takes advantage of memtable being able to detect duplicate and returning TryAgain to handle duplicate keys in WritePrepared Txns. Through WriteBatchWithIndexs index it detects existence of at least a duplicate key in the write batch. If duplicate key was reported, it then pays the cost of counting the number of sub-patches by iterating over the write batch and pass it to DBImpl::Write. DB will make use of the provided batch_count to assign proper sequence numbers before sending them to the WAL. When later inserting the batch to the memtable, it increases the seq each time memtbale reports a duplicate (a sub-patch in our counting) and tries again. Closes Differential Revision: D6873699 Pulled By: maysamyabandeh fbshipit-source-id: db8487526c3a5dc1ddda0ea49f0f979b26ae648d/"
,,0.3061,rocksdb,"Add a Close() method to DB to return status when closing a db Summary: Currently, the only way to close an open DB is to destroy the DB object. There is no way for the caller to know the status. In one instance, the destructor encountered an error due to failure to close a log file on HDFS. In order to prevent silent failures, we add DB::Close() that calls CloseImpl() which must be implemented by its descendants. The main failure point in the destructor is closing the log file. This patch also adds a Close() entry point to Logger in order to get status. When DBOptions::info_log is allocated and owned by the DBImpl, it is explicitly closed by DBImpl::CloseImpl(). Closes Differential Revision: D6698158 Pulled By: anand1976 fbshipit-source-id: 9468e2892553eb09c4c41b8723f590c0dbd8ab7d/"
,,0.2874,rocksdb,"Handle error return from WriteBuffer() Summary: There are a couple of places where we swallow any error from WriteBuffer() in SwitchMemtable() and DBImpl::CloseImpl(). Propagate the error up in those cases rather than ignoring it. Closes Differential Revision: D6879954 Pulled By: anand1976 fbshipit-source-id: 2ef88b554be5286b0a8bad7384ba17a105395bdb/Disable need_log_sync on bg err Summary: When there is a background error PreprocessWrite returns without marking the logs synced. If we keep need_log_sync to true, it would try to sync them at the end, which would break the logic. The patch would unset need_log_sync if the logs end up not being marked for sync in PreprocessWrite. Closes Differential Revision: D6602347 Pulled By: maysamyabandeh fbshipit-source-id: 37ee04209e8dcfd78de891654ce50d0954abeb38/WritePrepared Txn: PreReleaseCallback Summary: Add PreReleaseCallback to be called at the end of WriteImpl but before publishing the sequence number. The callback is used in WritePrepareTxn to i) update the commit map, ii) update the last published sequence number in the 2nd write queue. It also ensures that all the commits will go to the 2nd queue. These changes will ensure that the commit map is updated before the sequence number is published and used by reading snapshots. If we use two write queues, the snapshots will use the seq number published by the 2nd queue. If we use one write queue (the default, the snapshots will use the last seq number in the memtable, which also indicates the last published seq number. Closes Differential Revision: D6438959 Pulled By: maysamyabandeh fbshipit-source-id: f8b6c434e94bc5f5ab9cb696879d4c23e2577ab9/"
,,0.2375,rocksdb,"WritePrepared Txn: Duplicate Keys, Txn Part Summary: This patch takes advantage of memtable being able to detect duplicate and returning TryAgain to handle duplicate keys in WritePrepared Txns. Through WriteBatchWithIndexs index it detects existence of at least a duplicate key in the write batch. If duplicate key was reported, it then pays the cost of counting the number of sub-patches by iterating over the write batch and pass it to DBImpl::Write. DB will make use of the provided batch_count to assign proper sequence numbers before sending them to the WAL. When later inserting the batch to the memtable, it increases the seq each time memtbale reports a duplicate (a sub-patch in our counting) and tries again. Closes Differential Revision: D6873699 Pulled By: maysamyabandeh fbshipit-source-id: db8487526c3a5dc1ddda0ea49f0f979b26ae648d/add WriteBatch::WriteBatch(std::string&&) Summary: to save a string copy for some use cases. The change is pretty straightforward, please feel free to let me know if you want to suggest any tests for it. Closes Differential Revision: D6706828 Pulled By: yiwu-arbug fbshipit-source-id: 873ce4442937bdc030b395c7f99228eda7f59eb7/"
,,0.1311,rocksdb,"WritePrepared Txn: Duplicate Keys, Memtable part Summary: Currently DB does not accept duplicate keys (keys with the same user key and the same sequence number). If Memtable returns false when receiving such keys, we can benefit from this signal to properly increase the sequence number in the rare cases when we have a duplicate key in the write batch written to DB under WritePrepared transactions. Closes Differential Revision: D6822412 Pulled By: maysamyabandeh fbshipit-source-id: adea3ce5073131cd38ed52b16bea0673b1a19e77/"
,,0.295,rocksdb,"Add a Close() method to DB to return status when closing a db Summary: Currently, the only way to close an open DB is to destroy the DB object. There is no way for the caller to know the status. In one instance, the destructor encountered an error due to failure to close a log file on HDFS. In order to prevent silent failures, we add DB::Close() that calls CloseImpl() which must be implemented by its descendants. The main failure point in the destructor is closing the log file. This patch also adds a Close() entry point to Logger in order to get status. When DBOptions::info_log is allocated and owned by the DBImpl, it is explicitly closed by DBImpl::CloseImpl(). Closes Differential Revision: D6698158 Pulled By: anand1976 fbshipit-source-id: 9468e2892553eb09c4c41b8723f590c0dbd8ab7d/"
,,0.2536,rocksdb,"WritePrepared Txn: PreReleaseCallback Summary: Add PreReleaseCallback to be called at the end of WriteImpl but before publishing the sequence number. The callback is used in WritePrepareTxn to i) update the commit map, ii) update the last published sequence number in the 2nd write queue. It also ensures that all the commits will go to the 2nd queue. These changes will ensure that the commit map is updated before the sequence number is published and used by reading snapshots. If we use two write queues, the snapshots will use the seq number published by the 2nd queue. If we use one write queue (the default, the snapshots will use the last seq number in the memtable, which also indicates the last published seq number. Closes Differential Revision: D6438959 Pulled By: maysamyabandeh fbshipit-source-id: f8b6c434e94bc5f5ab9cb696879d4c23e2577ab9/optimize file ingestion checks for range deletion overlap Summary: Before we were checking every file in the level which was unnecessary. We can piggyback onto the code for checking point-key overlap, which already opens all the files that could possibly contain overlapping range deletions. This PR makes us check just the range deletions from those files, so no extra ones will be opened. Closes Differential Revision: D6358125 Pulled By: ajkr fbshipit-source-id: 00e200770fdb8f3cc6b1b2da232b755e4ba36279/"
,,0.1444,rocksdb,"WritePrepared Txn: Duplicate Keys, Memtable part Summary: Currently DB does not accept duplicate keys (keys with the same user key and the same sequence number). If Memtable returns false when receiving such keys, we can benefit from this signal to properly increase the sequence number in the rare cases when we have a duplicate key in the write batch written to DB under WritePrepared transactions. Closes Differential Revision: D6822412 Pulled By: maysamyabandeh fbshipit-source-id: adea3ce5073131cd38ed52b16bea0673b1a19e77/"
,,0.124,rocksdb,"WritePrepared Txn: Duplicate Keys, Memtable part Summary: Currently DB does not accept duplicate keys (keys with the same user key and the same sequence number). If Memtable returns false when receiving such keys, we can benefit from this signal to properly increase the sequence number in the rare cases when we have a duplicate key in the write batch written to DB under WritePrepared transactions. Closes Differential Revision: D6822412 Pulled By: maysamyabandeh fbshipit-source-id: adea3ce5073131cd38ed52b16bea0673b1a19e77/Make DBOption compaction_readahead_size dynamic Summary: Closes Differential Revision: D6056141 Pulled By: miasantreble fbshipit-source-id: 56df1630f464fd56b07d25d38161f699e0528b7f/"
,,0.3049,rocksdb,"WritePrepared Txn: PreReleaseCallback Summary: Add PreReleaseCallback to be called at the end of WriteImpl but before publishing the sequence number. The callback is used in WritePrepareTxn to i) update the commit map, ii) update the last published sequence number in the 2nd write queue. It also ensures that all the commits will go to the 2nd queue. These changes will ensure that the commit map is updated before the sequence number is published and used by reading snapshots. If we use two write queues, the snapshots will use the seq number published by the 2nd queue. If we use one write queue (the default, the snapshots will use the last seq number in the memtable, which also indicates the last published seq number. Closes Differential Revision: D6438959 Pulled By: maysamyabandeh fbshipit-source-id: f8b6c434e94bc5f5ab9cb696879d4c23e2577ab9/"
,,0.3441,rocksdb,"WritePrepared Txn: disable rollback in stress test Summary: WritePrepared rollback implementation is not ready to be invoked in the middle of workload. This is due the lack of synchronization to obtain the cf handle from db. Temporarily disabling this until the problem with rollback is fixed. Closes Differential Revision: D7769041 Pulled By: maysamyabandeh fbshipit-source-id: 0e3b0ce679bc2afba82e653a40afa3f045722754/WritePrepared Txn: rollback via commit Summary: Currently WritePrepared rolls back a transaction with prepare sequence number prepare_seq by i) write a single rollback batch with rollback_seq, ii) add rollback_seq> to commit cache, iii) remove prepare_seq from PrepareHeap. This is correct assuming that there is no snapshot taken when a transaction is rolled back. This is the case the way MySQL does rollback which is after recovery. Otherwise if max_evicted_seq advances the prepare_seq, the live snapshot might assume data as committed since it does not find them in CommitCache. The change is to simply add rollback_seq> to commit cache before removing prepare_seq from PrepareHeap. In this way if max_evicted_seq advances prpeare_seq, the existing mechanism that we have to check evicted entries against live snapshots will make sure that the live snapshot will not see the data of rolled back transaction. Closes Differential Revision: D7696193 Pulled By: maysamyabandeh fbshipit-source-id: c9a2d46341ddc03554dded1303520a1cab74ef9c/"
,,0.0878,rocksdb,"WritePrepared Txn: add write_committed option to dump_wal Summary: Currently dump_wal cannot print the prepared records from the WAL that is generated by WRITE_PREPARED write policy since the default reaction of the handler is to return NotSupported if markers of WRITE_PREPARED are encountered. This patch enables the admin to pass option, which will be accordingly passed to the handler. Note that DBFileDumperCommand and DBDumperCommand are still not updated by this patch but firstly they are not urgent and secondly we need to revise this approach later when we also add WRITE_UNPREPARED markers so I leave it for future work. Tested by running it on a WAL generated by WRITE_PREPARED: $ ./ldb dump_wal | grep BEGIN_PREARE | head 1,2,70,0,BEGIN_PREARE $ ./ldb dump_wal | grep BEGIN_PREARE | head 1,2,70,0,BEGIN_PREARE PUT(0) : 0x30303031313330313938 PUT(0) : 0x30303032353732313935 END_PREPARE(0x74786E31313535383434323738303738363938313335312D30) Closes Differential Revision: D7522090 Pulled By: maysamyabandeh fbshipit-source-id: a0332207261c61e18b2f9dfbe9feecd9a1339aca/"
,,0.2412,rocksdb,"Add crash-recovery correctness check to db_stress Summary: Previously, our `db_stress` tool held the expected state of the DB in-memory, so after crash-recovery, there was no way to verify data correctness. This PR adds an option, `--expected_values_file`, which specifies a file holding the expected values. In black-box testing, the `db_stress` process can be killed arbitrarily, so updates to the `--expected_values_file` must be atomic. We achieve this by `mmap`ing the file and relying on `std::atomic<uint32_t>` for atomicity. Actually this doesnt provide a total guarantee on what we want as `std::atomic<uint32_t>` could, in theory, be translated into multiple stores surrounded by a mutex. We can verify our assumption by looking at `std::atomic::is_always_lock_free`. For the `mmap`d file, we didnt have an existing way to expose its contents as a raw memory buffer. This PR adds it in the `Env::NewMemoryMappedFileBuffer` function, and `MemoryMappedFileBuffer` class. `db_crashtest.py` is updated to use an expected values file for black-box testing. On the first iteration (when the DB is created), an empty file is provided as `db_stress` will populate it when it runs. On subsequent iterations, that same filename is provided so `db_stress` can check the data is as expected on startup. Closes Differential Revision: D7463144 Pulled By: ajkr fbshipit-source-id: c8f3e82c93e045a90055e2468316be155633bd8b/Comment out unused variables Summary: Submitting on behalf of another employee. Closes Differential Revision: D7146025 Pulled By: ajkr fbshipit-source-id: 495ca5db5beec3789e671e26f78170957704e77e/"
,,0.1859,rocksdb,"Fix the Logger::Close() and DBImpl::Close() design pattern Summary: The recent Logger::Close() and DBImpl::Close() implementation rely on calling the CloseImpl() virtual function from the destructor, which will not work. Refactor the implementation to have a private close helper function in derived classes that can be called by both CloseImpl() and the destructor. Closes Reviewed By: gfosco Differential Revision: D7049303 Pulled By: anand1976 fbshipit-source-id: 76a64cbf403209216dfe4864ecf96b5d7f3db9f4/"
,,0.308,rocksdb,"Second attempt at db_stress crash-recovery verification Summary: Original commit: a4fb1f8c049ee9d61a9da8cf23b64d2c7d36a33f Revert commit (we reverted as a quick fix to get crash tests passing): 6afe22db2e667799d8c903db61750d676bffe152 This PR includes the contents of the original commit plus two bug fixes, which are: In whitebox crash test, only set `--expected_values_path` for `db_stress` runs in the first half of the crash tests duration. In the second half, a fresh DB is created for each `db_stress` run, so we cannot maintain expected state across `db_stress` runs. Made `Exists()` return true for `UNKNOWN_SENTINEL` values. I previously had an assert in `Exists()` that value was not `UNKNOWN_SENTINEL`. But it is possible for post-crash-recovery expected values to be `UNKNOWN_SENTINEL` (i.e., if the crash happens in the middle of an update), in which case this assertion would be tripped. The effect of returning true in this case is there may be cases where a `SingleDelete` deletes no data. But if we had returned false, the effect would be calling `SingleDelete` on a key with multiple older versions, which is not supported. Closes Differential Revision: D7811671 Pulled By: ajkr fbshipit-source-id: 67e0295bfb1695ff9674837f2e05bb29c50efc30/Add crash-recovery correctness check to db_stress Summary: Previously, our `db_stress` tool held the expected state of the DB in-memory, so after crash-recovery, there was no way to verify data correctness. This PR adds an option, `--expected_values_file`, which specifies a file holding the expected values. In black-box testing, the `db_stress` process can be killed arbitrarily, so updates to the `--expected_values_file` must be atomic. We achieve this by `mmap`ing the file and relying on `std::atomic<uint32_t>` for atomicity. Actually this doesnt provide a total guarantee on what we want as `std::atomic<uint32_t>` could, in theory, be translated into multiple stores surrounded by a mutex. We can verify our assumption by looking at `std::atomic::is_always_lock_free`. For the `mmap`d file, we didnt have an existing way to expose its contents as a raw memory buffer. This PR adds it in the `Env::NewMemoryMappedFileBuffer` function, and `MemoryMappedFileBuffer` class. `db_crashtest.py` is updated to use an expected values file for black-box testing. On the first iteration (when the DB is created), an empty file is provided as `db_stress` will populate it when it runs. On subsequent iterations, that same filename is provided so `db_stress` can check the data is as expected on startup. Closes Differential Revision: D7463144 Pulled By: ajkr fbshipit-source-id: c8f3e82c93e045a90055e2468316be155633bd8b/Make database files permissions configurable Summary: Closes Differential Revision: D7610227 Pulled By: xiaofeidu008 fbshipit-source-id: 88a52f0f9f96e2195fccde995cf9760b785e9f07/Comment out unused variables Summary: Submitting on behalf of another employee. Closes Differential Revision: D7146025 Pulled By: ajkr fbshipit-source-id: 495ca5db5beec3789e671e26f78170957704e77e/Fix the Logger::Close() and DBImpl::Close() design pattern Summary: The recent Logger::Close() and DBImpl::Close() implementation rely on calling the CloseImpl() virtual function from the destructor, which will not work. Refactor the implementation to have a private close helper function in derived classes that can be called by both CloseImpl() and the destructor. Closes Reviewed By: gfosco Differential Revision: D7049303 Pulled By: anand1976 fbshipit-source-id: 76a64cbf403209216dfe4864ecf96b5d7f3db9f4/"
,,0.2296,rocksdb,"Disallow to open RandomRW file if the file doesnt exist Summary: The only use of RandomRW is to change seqno when bulkloading, and in this use case, the file should exist. We should fail the file opening in this case. Closes Differential Revision: D7913719 Pulled By: siying fbshipit-source-id: 62cf6734f1a6acb9e14f715b927da388131c3492/initialize local variable for UBSAN in PosixEnv function Summary: this is a repeat commit of a8a28da2159648a2f72c35ea507371df8a97a2a9, which got reverted together with 6afe22db2e667799d8c903db61750d676bffe152, but forgotten about when that commit was un-reverted in 46152d53bf58748fc3ed0681d8970c342bcfc47a. Closes Differential Revision: D7826077 Pulled By: ajkr fbshipit-source-id: edb22375da56e2feda50c5b35f942f4d2d52b19c/Second attempt at db_stress crash-recovery verification Summary: Original commit: a4fb1f8c049ee9d61a9da8cf23b64d2c7d36a33f Revert commit (we reverted as a quick fix to get crash tests passing): 6afe22db2e667799d8c903db61750d676bffe152 This PR includes the contents of the original commit plus two bug fixes, which are: In whitebox crash test, only set `--expected_values_path` for `db_stress` runs in the first half of the crash tests duration. In the second half, a fresh DB is created for each `db_stress` run, so we cannot maintain expected state across `db_stress` runs. Made `Exists()` return true for `UNKNOWN_SENTINEL` values. I previously had an assert in `Exists()` that value was not `UNKNOWN_SENTINEL`. But it is possible for post-crash-recovery expected values to be `UNKNOWN_SENTINEL` (i.e., if the crash happens in the middle of an update), in which case this assertion would be tripped. The effect of returning true in this case is there may be cases where a `SingleDelete` deletes no data. But if we had returned false, the effect would be calling `SingleDelete` on a key with multiple older versions, which is not supported. Closes Differential Revision: D7811671 Pulled By: ajkr fbshipit-source-id: 67e0295bfb1695ff9674837f2e05bb29c50efc30/initialize local variable for UBSAN in PosixEnv function Summary: It seems clear to me that the variable is initialized before line 492, but it wasnt clear to UBSAN. The failure was: ``` In file included from ./env/io_posix.h:14:0, from env/env_posix.cc:44: ./include/rocksdb/env.h: In member function ëvirtual rocksdb::Status rocksdb::{anonymous}::PosixEnv::NewMemoryMappedFileBuffer(const string&, std::unique_ptr<rocksdb::MemoryMappedFileBuffer>*)í: ./include/rocksdb/env.h:822:36: error: ëbaseí may be used uninitialized in this function [-Werror=maybe-uninitialized] : base(_base), length(_length) {} ^ env/env_posix.cc:482:11: note: ëbaseí was declared here void* base; ``` We can just initialize to nullptr to keep UBSAN happy. Closes Differential Revision: D7756287 Pulled By: ajkr fbshipit-source-id: 0f2efb9594e2d3a30706a4ca7e1d4a6328031bf2/Add crash-recovery correctness check to db_stress Summary: Previously, our `db_stress` tool held the expected state of the DB in-memory, so after crash-recovery, there was no way to verify data correctness. This PR adds an option, `--expected_values_file`, which specifies a file holding the expected values. In black-box testing, the `db_stress` process can be killed arbitrarily, so updates to the `--expected_values_file` must be atomic. We achieve this by `mmap`ing the file and relying on `std::atomic<uint32_t>` for atomicity. Actually this doesnt provide a total guarantee on what we want as `std::atomic<uint32_t>` could, in theory, be translated into multiple stores surrounded by a mutex. We can verify our assumption by looking at `std::atomic::is_always_lock_free`. For the `mmap`d file, we didnt have an existing way to expose its contents as a raw memory buffer. This PR adds it in the `Env::NewMemoryMappedFileBuffer` function, and `MemoryMappedFileBuffer` class. `db_crashtest.py` is updated to use an expected values file for black-box testing. On the first iteration (when the DB is created), an empty file is provided as `db_stress` will populate it when it runs. On subsequent iterations, that same filename is provided so `db_stress` can check the data is as expected on startup. Closes Differential Revision: D7463144 Pulled By: ajkr fbshipit-source-id: c8f3e82c93e045a90055e2468316be155633bd8b/Make database files permissions configurable Summary: Closes Differential Revision: D7610227 Pulled By: xiaofeidu008 fbshipit-source-id: 88a52f0f9f96e2195fccde995cf9760b785e9f07/comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/Several small ""fixes"" Summary: removed a few unneeded variables fused some variable declarations and their assignments fixed right-trimming code in string_util.cc to not underflow simplifed an assertion move non-nullptr check assertion before dereferencing of that pointer pass an std::string function parameter by const reference instead of by value (avoiding potential copy) Closes Differential Revision: D7004679 Pulled By: sagar0 fbshipit-source-id: 52944952d9b56dfcac3bea3cd7878e315bb563c4/"
,,0.3018,rocksdb,"Add crash-recovery correctness check to db_stress Summary: Previously, our `db_stress` tool held the expected state of the DB in-memory, so after crash-recovery, there was no way to verify data correctness. This PR adds an option, `--expected_values_file`, which specifies a file holding the expected values. In black-box testing, the `db_stress` process can be killed arbitrarily, so updates to the `--expected_values_file` must be atomic. We achieve this by `mmap`ing the file and relying on `std::atomic<uint32_t>` for atomicity. Actually this doesnt provide a total guarantee on what we want as `std::atomic<uint32_t>` could, in theory, be translated into multiple stores surrounded by a mutex. We can verify our assumption by looking at `std::atomic::is_always_lock_free`. For the `mmap`d file, we didnt have an existing way to expose its contents as a raw memory buffer. This PR adds it in the `Env::NewMemoryMappedFileBuffer` function, and `MemoryMappedFileBuffer` class. `db_crashtest.py` is updated to use an expected values file for black-box testing. On the first iteration (when the DB is created), an empty file is provided as `db_stress` will populate it when it runs. On subsequent iterations, that same filename is provided so `db_stress` can check the data is as expected on startup. Closes Differential Revision: D7463144 Pulled By: ajkr fbshipit-source-id: c8f3e82c93e045a90055e2468316be155633bd8b/Fix the Logger::Close() and DBImpl::Close() design pattern Summary: The recent Logger::Close() and DBImpl::Close() implementation rely on calling the CloseImpl() virtual function from the destructor, which will not work. Refactor the implementation to have a private close helper function in derived classes that can be called by both CloseImpl() and the destructor. Closes Reviewed By: gfosco Differential Revision: D7049303 Pulled By: anand1976 fbshipit-source-id: 76a64cbf403209216dfe4864ecf96b5d7f3db9f4/"
,,0.1819,rocksdb,WritePrepared Txn: split SeqAdvanceConcurrentTest Summary: The tsan flavor of SeqAdvanceConcurrentTest times out in our test infra. The patch splits it into 10 tests. On my vm before: [ OK ] WritePreparedTransactionTest/WritePreparedTransactionTest.SeqAdvanceConcurrentTest/0 (5194 ms) after: [ OK ] OneWriteQueue/SeqAdvanceConcurrentTest.SeqAdvanceConcurrentTest/0 (1906 ms) Closes Differential Revision: D7854515 Pulled By: maysamyabandeh fbshipit-source-id: 4fbac42a1f974326cbc237f8cb9d6232d379c431/WritePrepared Txn: AddPrepared for all sub-batches Summary: Currently AddPrepared is performed only on the first sub-batch if there are duplicate keys in the write batch. This could cause a problem if the transaction takes too long to commit and the seq number of the first sub-patch moved to old_prepared_ but not the seq of the later ones. The patch fixes this by calling AddPrepared for all sub-patches. Closes Differential Revision: D7388635 Pulled By: maysamyabandeh fbshipit-source-id: 0ccd80c150d9bc42fe955e49ddb9d7ca353067b4/
,,0.2543,rocksdb,"comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/WritePrepared Txn: smallest_prepare optimization Summary: The is an optimization to reduce lookup in the CommitCache when querying IsInSnapshot. The optimization takes the smallest uncommitted data at the time that the snapshot was taken and if the sequence number of the read data is lower than that number it assumes the data as committed. To implement this optimization two changes are required: i) The AddPrepared function must be called sequentially to avoid out of order insertion in the PrepareHeap (otherwise the top of the heap does not indicate the smallest prepare in future too), ii) non-2PC transactions also call AddPrepared if they do not commit in one step. Closes Differential Revision: D7388630 Pulled By: maysamyabandeh fbshipit-source-id: b79506238c17467d590763582960d4d90181c600/WritePrepared Txn: make recoverable state visible after flush Summary: Currently if the CommitTimeWriteBatch is set to be used only as a state that is required only for recovery , the user cannot see that in DB until it is restarted. This while the state is already inserted into the DB after the memtable flush. It would be useful for debugging if make this state visible to the user after the flush by committing it. The patch does it by a invoking a callback that does the commit on the recoverable state. Closes Differential Revision: D7424577 Pulled By: maysamyabandeh fbshipit-source-id: 137f9408662f0853938b33fa440f27f04c1bbf5c/WritePrepared Txn: fix non-emptied PreparedHeap bug Summary: Under a certain sequence of accessing PreparedHeap, there was a bug that would not successfully empty the heap. This would result in performance issues when the heap content is moved to old_prepared_ after max_evicted_seq_ advances the orphan prepared sequence numbers. The patch fixed the bug and add more unit tests. It also does more logging when the unlikely scenarios are faced Closes Differential Revision: D7038486 Pulled By: maysamyabandeh fbshipit-source-id: f1e40bea558f67b03d2a29131fcb8734c65fce97/WritePrepared Txn: optimizations for sysbench update_noindex Summary: These are optimization that we applied to improve sysbechs update_noindex performance. 1. Make use of LIKELY compiler hint 2. Move std::atomic so the subclass 3. Make use of skip_prepared in non-2pc transactions. Closes Differential Revision: D7000075 Pulled By: maysamyabandeh fbshipit-source-id: 1ab8292584df1f6305a4992973fb1b7933632181/WritePrepared Txn: use TransactionDBWriteOptimizations (2nd attempt) Summary: TransactionDB::Write can receive some optimization hints from the user. One is to skip the concurrency control mechanism. WritePreparedTxnDB is currently ignoring such hints. This patch optimizes WritePreparedTxnDB::Write for skip_concurrency_control and skip_duplicate_key_check hints. Closes Differential Revision: D6971784 Pulled By: maysamyabandeh fbshipit-source-id: cbab10ad538fa2b8bcb47e37c77724afe6e30f03/"
,,0.2363,rocksdb,"Clarify the ownership of root db after TransactionDB::Open Summary: The patch clarifies the ownership of the root db after TransactionDB::Open. If it is a success the ownership if with the TransactionDB, and the root db will be deleted when the destructor of the base class, StackableDB, is called. If it is failure, the temporarily created root db will also be deleted properly. The patch also includes lots of useful formatting changes. Closes upon which this patch is built. Closes Differential Revision: D7878010 Pulled By: maysamyabandeh fbshipit-source-id: f54f3942e29434143ae5a2423ceec9c7072cd4c2/WritePrepared Txn: Fix bug with duplicate keys during recovery Summary: Fix the following bugs: During recovery a duplicate key was inserted twice into the write batch of the recovery transaction, once when the memtable returns false (because it was duplicates) and once for the 2nd attempt. This would result into different SubBatch count measured when the recovered transactions is committing. If a cf is flushed during recovery the memtable is not available to assist in detecting the duplicate key. This could result into not advancing the sequence number when iterating over duplicate keys of a flushed cf and hence inserting the next key with the wrong sequence number. SubBacthCounter would reset the comparator to default comparator after the first duplicate key. The 2nd duplicate key hence would have gone through a wrong comparator and not being detected. Closes Differential Revision: D7149440 Pulled By: maysamyabandeh fbshipit-source-id: 91ec317b165f363f5d11ff8b8c47c81cebb8ed77/"
,,0.1246,rocksdb,WritePrepared Txn: optimizations for sysbench update_noindex Summary: These are optimization that we applied to improve sysbechs update_noindex performance. 1. Make use of LIKELY compiler hint 2. Move std::atomic so the subclass 3. Make use of skip_prepared in non-2pc transactions. Closes Differential Revision: D7000075 Pulled By: maysamyabandeh fbshipit-source-id: 1ab8292584df1f6305a4992973fb1b7933632181/
,,0.4094,rocksdb,"comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/WritePrepared Txn: fix smallest_prep atomicity issue Summary: We introduced smallest_prep optimization in this commit b225de7e10f02be6d00e96b9fb86dfef880babdf, which enables storing the smallest uncommitted sequence number along with the snapshot. This enables the readers that read from the snapshot to skip further checks and safely assumed the data is committed if its sequence number is less than smallest uncommitted when the snapshot was taken. The problem was that smallest uncommitted and the snapshot must be taken atomically, and the lack of atomicity had led to readers using a smallest uncommitted after the snapshot was taken and hence mistakenly skipping some data. This patch fixes the problem by i) separating the process of removing of prepare entries from the AddCommitted function, ii) removing the prepare entires AFTER the committed sequence number is published, iii) getting smallest uncommitted (from the prepare list) BEFORE taking a snapshot. This guarantees that the smallest uncommitted that is accompanied with a snapshot is less than or equal of such number if it was obtained atomically. Tested by running MySQLStyleTransactionTest/MySQLStyleTransactionTest.TransactionStressTest that was failing sporadically. Closes Differential Revision: D7581934 Pulled By: maysamyabandeh fbshipit-source-id: dc9d6f4fb477eba75d4d5927326905b548a96a32/WritePrepared Txn: smallest_prepare optimization Summary: The is an optimization to reduce lookup in the CommitCache when querying IsInSnapshot. The optimization takes the smallest uncommitted data at the time that the snapshot was taken and if the sequence number of the read data is lower than that number it assumes the data as committed. To implement this optimization two changes are required: i) The AddPrepared function must be called sequentially to avoid out of order insertion in the PrepareHeap (otherwise the top of the heap does not indicate the smallest prepare in future too), ii) non-2PC transactions also call AddPrepared if they do not commit in one step. Closes Differential Revision: D7388630 Pulled By: maysamyabandeh fbshipit-source-id: b79506238c17467d590763582960d4d90181c600/WritePrepared Txn: Increase commit cache size to 2^23 Summary: Current commit cache size is 2^21. This was due to a type. With 2^23 commit entries we can have transactions as long as 64s without incurring the cost of having them evicted from the commit cache before their commit. Here is the math: 2^23 / 2 (one out of two seq numbers are for commit) / 2^16 TPS 2^6 64s Closes Differential Revision: D7411211 Pulled By: maysamyabandeh fbshipit-source-id: e7cacf40579f3acf940643d8a1cfe5dd201caa35/WritePrepared Txn: AddPrepared for all sub-batches Summary: Currently AddPrepared is performed only on the first sub-batch if there are duplicate keys in the write batch. This could cause a problem if the transaction takes too long to commit and the seq number of the first sub-patch moved to old_prepared_ but not the seq of the later ones. The patch fixes this by calling AddPrepared for all sub-patches. Closes Differential Revision: D7388635 Pulled By: maysamyabandeh fbshipit-source-id: 0ccd80c150d9bc42fe955e49ddb9d7ca353067b4/WritePrepared Txn: fix race condition on publishing seq Summary: This commit fixes a race condition on calling SetLastPublishedSequence. The function must be called only from the 2nd write queue when two_write_queues is enabled. However there was a bug that would also call it from the main write queue if CommitTimeWriteBatch is provided to the commit request and yet use_only_the_last_commit_time_batch_for_recovery optimization is not enabled. To fix that we penalize the commit request in such cases by doing an additional write solely to publish the seq number from the 2nd queue. Closes Differential Revision: D7361508 Pulled By: maysamyabandeh fbshipit-source-id: bf8f7a27e5cccf5425dccbce25eb0032e8e5a4d7/WritePrepared Txn: fix non-emptied PreparedHeap bug Summary: Under a certain sequence of accessing PreparedHeap, there was a bug that would not successfully empty the heap. This would result in performance issues when the heap content is moved to old_prepared_ after max_evicted_seq_ advances the orphan prepared sequence numbers. The patch fixed the bug and add more unit tests. It also does more logging when the unlikely scenarios are faced Closes Differential Revision: D7038486 Pulled By: maysamyabandeh fbshipit-source-id: f1e40bea558f67b03d2a29131fcb8734c65fce97/WritePrepared Txn: optimizations for sysbench update_noindex Summary: These are optimization that we applied to improve sysbechs update_noindex performance. 1. Make use of LIKELY compiler hint 2. Move std::atomic so the subclass 3. Make use of skip_prepared in non-2pc transactions. Closes Differential Revision: D7000075 Pulled By: maysamyabandeh fbshipit-source-id: 1ab8292584df1f6305a4992973fb1b7933632181/"
,,0.2891,rocksdb,"Clarify the ownership of root db after TransactionDB::Open Summary: The patch clarifies the ownership of the root db after TransactionDB::Open. If it is a success the ownership if with the TransactionDB, and the root db will be deleted when the destructor of the base class, StackableDB, is called. If it is failure, the temporarily created root db will also be deleted properly. The patch also includes lots of useful formatting changes. Closes upon which this patch is built. Closes Differential Revision: D7878010 Pulled By: maysamyabandeh fbshipit-source-id: f54f3942e29434143ae5a2423ceec9c7072cd4c2/WritePrepared Txn: Fix bug with duplicate keys during recovery Summary: Fix the following bugs: During recovery a duplicate key was inserted twice into the write batch of the recovery transaction, once when the memtable returns false (because it was duplicates) and once for the 2nd attempt. This would result into different SubBatch count measured when the recovered transactions is committing. If a cf is flushed during recovery the memtable is not available to assist in detecting the duplicate key. This could result into not advancing the sequence number when iterating over duplicate keys of a flushed cf and hence inserting the next key with the wrong sequence number. SubBacthCounter would reset the comparator to default comparator after the first duplicate key. The 2nd duplicate key hence would have gone through a wrong comparator and not being detected. Closes Differential Revision: D7149440 Pulled By: maysamyabandeh fbshipit-source-id: 91ec317b165f363f5d11ff8b8c47c81cebb8ed77/Fix a leak in prepared_section_completed_ Summary: The zeroed entries were not removed from prepared_section_completed_ map. This patch adds a unit test to show the problem and fixes that by refactoring the code. The new code is more efficient since i) it uses two separate mutex to avoid contention between commit and prepare threads, ii) it uses a sorted vector for maintaining uniq log entires with prepare which avoids a very large heap with many duplicate entries. Closes Differential Revision: D7106071 Pulled By: maysamyabandeh fbshipit-source-id: b3ae17cb6cd37ef10b6b35e0086c15c758768a48/WritePrepared Txn: use TransactionDBWriteOptimizations (2nd attempt) Summary: TransactionDB::Write can receive some optimization hints from the user. One is to skip the concurrency control mechanism. WritePreparedTxnDB is currently ignoring such hints. This patch optimizes WritePreparedTxnDB::Write for skip_concurrency_control and skip_duplicate_key_check hints. Closes Differential Revision: D6971784 Pulled By: maysamyabandeh fbshipit-source-id: cbab10ad538fa2b8bcb47e37c77724afe6e30f03/"
,,0.193,rocksdb,"Fix the Logger::Close() and DBImpl::Close() design pattern Summary: The recent Logger::Close() and DBImpl::Close() implementation rely on calling the CloseImpl() virtual function from the destructor, which will not work. Refactor the implementation to have a private close helper function in derived classes that can be called by both CloseImpl() and the destructor. Closes Reviewed By: gfosco Differential Revision: D7049303 Pulled By: anand1976 fbshipit-source-id: 76a64cbf403209216dfe4864ecf96b5d7f3db9f4/"
,,0.2456,rocksdb,"Add max_subcompactions as a compaction option Summary: Sometimes we want to compact files as fast as possible, but dont want to set a large `max_subcompactions` in the `DBOptions` by default. I add a `max_subcompactions` options to `CompactionOptions` so that we can choose a proper concurrency dynamically. Closes Differential Revision: D7792357 Pulled By: ajkr fbshipit-source-id: 94f54c3784dce69e40a229721a79a97e80cd6a6c/WritePrepared Txn: smallest_prepare optimization Summary: The is an optimization to reduce lookup in the CommitCache when querying IsInSnapshot. The optimization takes the smallest uncommitted data at the time that the snapshot was taken and if the sequence number of the read data is lower than that number it assumes the data as committed. To implement this optimization two changes are required: i) The AddPrepared function must be called sequentially to avoid out of order insertion in the PrepareHeap (otherwise the top of the heap does not indicate the smallest prepare in future too), ii) non-2PC transactions also call AddPrepared if they do not commit in one step. Closes Differential Revision: D7388630 Pulled By: maysamyabandeh fbshipit-source-id: b79506238c17467d590763582960d4d90181c600/Enable cancelling manual compactions if they hit the sfm size limit Summary: Manual compactions should be cancelled, just like scheduled compactions are cancelled, if sfm->EnoughRoomForCompaction is not true. Closes Differential Revision: D7457683 Pulled By: amytai fbshipit-source-id: 669b02fdb707f75db576d03d2c818fb98d1876f5/Fix a leak in prepared_section_completed_ Summary: The zeroed entries were not removed from prepared_section_completed_ map. This patch adds a unit test to show the problem and fixes that by refactoring the code. The new code is more efficient since i) it uses two separate mutex to avoid contention between commit and prepare threads, ii) it uses a sorted vector for maintaining uniq log entires with prepare which avoids a very large heap with many duplicate entries. Closes Differential Revision: D7106071 Pulled By: maysamyabandeh fbshipit-source-id: b3ae17cb6cd37ef10b6b35e0086c15c758768a48/"
,,0.1894,rocksdb,"Fix pre_release callback argument list. Summary: Primitive types constness does not affect the signature of the method and has no influence on whether the overriding method would actually have that const bool instead of just bool. In addition, it is rarely useful but does produce a compatibility warnings in VS 2015 compiler. Closes Differential Revision: D7475739 Pulled By: ajkr fbshipit-source-id: fb275378b5acc397399420ae6abb4b6bfe5bd32f/WritePrepared Txn: fix race condition on publishing seq Summary: This commit fixes a race condition on calling SetLastPublishedSequence. The function must be called only from the 2nd write queue when two_write_queues is enabled. However there was a bug that would also call it from the main write queue if CommitTimeWriteBatch is provided to the commit request and yet use_only_the_last_commit_time_batch_for_recovery optimization is not enabled. To fix that we penalize the commit request in such cases by doing an additional write solely to publish the seq number from the 2nd queue. Closes Differential Revision: D7361508 Pulled By: maysamyabandeh fbshipit-source-id: bf8f7a27e5cccf5425dccbce25eb0032e8e5a4d7/"
,,0.1426,rocksdb,"Add max_subcompactions as a compaction option Summary: Sometimes we want to compact files as fast as possible, but dont want to set a large `max_subcompactions` in the `DBOptions` by default. I add a `max_subcompactions` options to `CompactionOptions` so that we can choose a proper concurrency dynamically. Closes Differential Revision: D7792357 Pulled By: ajkr fbshipit-source-id: 94f54c3784dce69e40a229721a79a97e80cd6a6c/Fix a leak in prepared_section_completed_ Summary: The zeroed entries were not removed from prepared_section_completed_ map. This patch adds a unit test to show the problem and fixes that by refactoring the code. The new code is more efficient since i) it uses two separate mutex to avoid contention between commit and prepare threads, ii) it uses a sorted vector for maintaining uniq log entires with prepare which avoids a very large heap with many duplicate entries. Closes Differential Revision: D7106071 Pulled By: maysamyabandeh fbshipit-source-id: b3ae17cb6cd37ef10b6b35e0086c15c758768a48/"
,,0.2484,rocksdb,"WritePrepared Txn: smallest_prepare optimization Summary: The is an optimization to reduce lookup in the CommitCache when querying IsInSnapshot. The optimization takes the smallest uncommitted data at the time that the snapshot was taken and if the sequence number of the read data is lower than that number it assumes the data as committed. To implement this optimization two changes are required: i) The AddPrepared function must be called sequentially to avoid out of order insertion in the PrepareHeap (otherwise the top of the heap does not indicate the smallest prepare in future too), ii) non-2PC transactions also call AddPrepared if they do not commit in one step. Closes Differential Revision: D7388630 Pulled By: maysamyabandeh fbshipit-source-id: b79506238c17467d590763582960d4d90181c600/"
,,0.2017,rocksdb,"Fix pre_release callback argument list. Summary: Primitive types constness does not affect the signature of the method and has no influence on whether the overriding method would actually have that const bool instead of just bool. In addition, it is rarely useful but does produce a compatibility warnings in VS 2015 compiler. Closes Differential Revision: D7475739 Pulled By: ajkr fbshipit-source-id: fb275378b5acc397399420ae6abb4b6bfe5bd32f/WritePrepared Txn: fix race condition on publishing seq Summary: This commit fixes a race condition on calling SetLastPublishedSequence. The function must be called only from the 2nd write queue when two_write_queues is enabled. However there was a bug that would also call it from the main write queue if CommitTimeWriteBatch is provided to the commit request and yet use_only_the_last_commit_time_batch_for_recovery optimization is not enabled. To fix that we penalize the commit request in such cases by doing an additional write solely to publish the seq number from the 2nd queue. Closes Differential Revision: D7361508 Pulled By: maysamyabandeh fbshipit-source-id: bf8f7a27e5cccf5425dccbce25eb0032e8e5a4d7/"
,,0.1043,rocksdb,"Exclude StackableDB from transaction stress tests (#4132) Summary: The transactions are currently tested with and without using StackableDB. This is mostly to check that the code path is consistent with stackable db as well. Slow, stress tests however do not benefit from being run again with StackableDB. The patch excludes StackableDB from such tests. On a single core it reduced the runtime of transaction_test from 199s to 135s. Pull Request resolved: Differential Revision: D8841655 Pulled By: maysamyabandeh fbshipit-source-id: 7b9aaba2673b542b195439dfb306cef26bd63b19/"
,,0.2265,rocksdb,"WriteUnPrepared: Implement unprepared batches for transactions (#4104) Summary: This adds support for writing unprepared batches based on size defined in `TransactionOptions::max_write_batch_size`. This is done by overriding methods that modify data (Put/Delete/SingleDelete/Merge) and checking first if write batch size has exceeded threshold. If so, the write batch is written to DB as an unprepared batch. Support for Commit/Rollback for unprepared batch is added as well. This has been done by simply extending the WritePrepared Commit/Rollback logic to take care of all unprep_seq numbers either when updating prepare heap, or adding to commit map. For updating the commit map, this logic exists inside `WriteUnpreparedCommitEntryPreReleaseCallback`. A test change was also made to have transactions unregister themselves when committing without prepare. This is because with write unprepared, there may be unprepared entries (which act similarly to prepared entries) already when a commit is done without prepare. Pull Request resolved: Differential Revision: D8785717 Pulled By: lth fbshipit-source-id: c02006e281ec1ce00f628e2a7beec0ee73096a91/"
,,0.0665,rocksdb,Fix clang analyze Summary: This fixes the errors as reported here: Closes Differential Revision: D8263086 Pulled By: lth fbshipit-source-id: 5e148d489cab2153e5846d16979a0a1f2d677d57/
,,0.171,rocksdb,"adds missing PopSavePoint method to Transaction (#4256) Summary: Transaction has had methods to deal with SavePoints already, but was missing the PopSavePoint method provided by WriteBatch and WriteBatchWithIndex. This PR adds PopSavePoint to Transaction as well. Having the method on Transaction-level too is useful for applications that repeatedly execute a sequence of operations that normally succeed, but infrequently need to get rolled back. Using SavePoints here is sensible, but as operations normally succeed the application may pile up a lot of useless SavePoints inside a Transaction, leading to slightly increased memory usage for managing the unneeded SavePoints. Pull Request resolved: Differential Revision: D9326932 Pulled By: yiwu-arbug fbshipit-source-id: 53a0af18a6c7e87feff8a56f1f3eab9df7f371d6/"
,,0.1698,rocksdb,"adds missing PopSavePoint method to Transaction (#4256) Summary: Transaction has had methods to deal with SavePoints already, but was missing the PopSavePoint method provided by WriteBatch and WriteBatchWithIndex. This PR adds PopSavePoint to Transaction as well. Having the method on Transaction-level too is useful for applications that repeatedly execute a sequence of operations that normally succeed, but infrequently need to get rolled back. Using SavePoints here is sensible, but as operations normally succeed the application may pile up a lot of useless SavePoints inside a Transaction, leading to slightly increased memory usage for managing the unneeded SavePoints. Pull Request resolved: Differential Revision: D9326932 Pulled By: yiwu-arbug fbshipit-source-id: 53a0af18a6c7e87feff8a56f1f3eab9df7f371d6/"
,,0.2154,rocksdb,"Extend Transaction::GetForUpdate with do_validate (#4680) Summary: Transaction::GetForUpdate is extended with a do_validate parameter with default value of true. If false it skips validating the snapshot (if there is any) before doing the read. After the read it also returns the latest value (expects the ReadOptions::snapshot to be nullptr). This allows RocksDB applications to use GetForUpdate similarly to how InnoDB does. Similarly ::Merge, ::Put, ::Delete, and ::SingleDelete are extended with assume_exclusive_tracked with default value of false. It true it indicates that call is assumed to be after a ::GetForUpdate(do_validate=false). The Java APIs are accordingly updated. Pull Request resolved: Differential Revision: D13068508 Pulled By: maysamyabandeh fbshipit-source-id: f0b59db28f7f6a078b60844d902057140765e67d/"
,,0.5453,rocksdb,"WritePrepared: non-atomic commit of delayed prepared (#4947) Summary: Commit of delayed prepared has two non-atomic steps: add to commit cache, remove from delayed_prepared_. Similarly in ::IsInSnapshot we read from commit cache first and then look into delayed_prepared_. Due to non-atomicity thus the reader might not find the prep_seq that is just committed neither in commit cache nor in delayed_prepared_. To fix that i) we check if there was any delayed prepared BEFORE looking into commit cache, ii) if there was, we complete the search steps to be these: i) commit cache, ii) delayed prepared, commit cache again. In this way if the first query to commit cache missed the commit, the 2nd will catch it. The cost of the redundant read from commit cache is paid only if delayed_prepared_ is nonempty which should be a very rare scenario. Pull Request resolved: Differential Revision: D13952754 Pulled By: maysamyabandeh fbshipit-source-id: 8f47826b13f8ce154398d842028342423f4ca2b2/WritePrepared: release snapshot equal to max (#4944) Summary: WritePrepared maintains a list of snapshots that are max_evicted_seq_. Based on this list, old_commit_map_ is updated if an evicted commit entry overlaps with such snapshot. Such lists are garbage collected when the release of snapshot is reported to WritePreparedTxnDB, which is the next time max_evicted_seq_ is updated and yet the snapshot is not found is the list returned from DB. This logic was broken since ReleaseSnapshotInternal was using ""< max_evicted_seq_"" to cleanup old_commit_map_, which would leave a snapshot uncleaned if it ""= max_evicted_seq_"". The patch fixes that and adds a unit test to check for the bug. Pull Request resolved: Differential Revision: D13945000 Pulled By: maysamyabandeh fbshipit-source-id: 0c904294f735911f52348a148bf1f945282fc17c/WritePrepared: fix two versions in compaction see different status for released snapshots (#4890) Summary: Fix how CompactionIterator::findEarliestVisibleSnapshots handles released snapshot. It fixing the two scenarios: Scenario 1: key1 has two values v1 and v2. Therere two snapshots s1 and s2 taken after v1 and v2 are committed. Right after compaction output v2, s1 is released. Now findEarliestVisibleSnapshot may see s1 being released, and return the next snapshot, which is s2. Thats larger than v2s earliest visible snapshot, which was s1. The fix: the only place we check against last snapshot and current key snapshot is when we decide whether to compact out a value if it is hidden by a later value. In the check if we see current snapshot is even larger than last snapshot, we know last snapshot is released, and we are safe to compact out current key. Scenario 2: key1 has two values v1 and v2. there are two snapshots s1 and s2 taken after v1 and v2 are committed. During compaction before we process the key, s1 is released. When compaction process v2, snapshot checker may return kSnapshotReleased, and the earliest visible snapshot for v2 become s2. When compaction process v1, snapshot checker may return kIsInSnapshot (for WritePrepared transaction, it could be because v1 is still in commit cache). The result will become inconsistent here. The fix: remember the set of released snapshots ever reported by snapshot checker, and ignore them when finding result for findEarliestVisibleSnapshot. Pull Request resolved: Differential Revision: D13705538 Pulled By: maysamyabandeh fbshipit-source-id: e577f0d9ee1ff5a6035f26859e56902ecc85a5a4/WritePrepared: commit of delayed prepared entries (#4894) Summary: Here is the order of ops in a commit: 1) update commit cache 2) publish seq, 3) RemovePrepared. In case of a delayed prepared, there will be a gap between when the commit is visible to snapshots until delayed_prepared_ is cleaned up. To tell apart this case from a delayed uncommitted txn from, the commit entry of a delayed prepared is also stored in delayed_prepared_commits_, which is updated before publishing the commit. Also logic in GetSnapshotInternal that ensures that each new snapshot is always larger than max_evicted_seq_ is updated to check against the upcoming value of max_evicted_seq_ rather than its current one. This is because AdvanceMaxEvictedSeq gets the list of snapshots lower than the new max, before updating max_evicted_seq_. Pull Request resolved: Differential Revision: D13726988 Pulled By: maysamyabandeh fbshipit-source-id: 1e70d78061b50c944c9816bf4b6dac405ab4ccd3/WritePrepared: fix issue with snapshot released during compaction (#4858) Summary: Compaction iterator keep a copy of list of live snapshots at the beginning of compaction, and then query snapshot checker to verify if values of a sequence number is visible to these snapshots. However when the snapshot is released in the middle of compaction, the snapshot checker implementation (i.e. WritePreparedSnapshotChecker) may remove info with the snapshot and may report incorrect result, which lead to values being compacted out when it shouldnt. This patch conservatively keep the values if snapshot checker determines that the snapshots is released. Pull Request resolved: Differential Revision: D13617146 Pulled By: maysamyabandeh fbshipit-source-id: cf18a94f6f61a94bcff73c280f117b224af5fbc3/WritePrepared: snapshot should be larger than max_evicted_seq_ (#4886) Summary: The AdvanceMaxEvictedSeq algorithm assumes that new snapshots always have sequence number larger than the last max_evicted_seq_. To enforce this assumption we make two changes: i) max is not advanced beyond the last published seq, with the exception that the evicted commit entry itself is not published yet, which is quite rare. ii) When obtaining the snapshot if the max_evicted_seq_ is not published yet, commit a dummy entry so that it waits for it to be published and also increased the latest published seq by one above the max. To test these non-realistic corner cases we create a commit cache with size 1 so that every single commit results into eviction. Pull Request resolved: Differential Revision: D13685270 Pulled By: maysamyabandeh fbshipit-source-id: 5461bc09c2a9b75798bfcb9853a256c81cdac0b0/WritePrepared: Fix SmallestUnCommittedSeq() doesnt check delayed_prepared (#4867) Summary: When prepared_txns_ heap is empty, SmallestUnCommittedSeq() should check delayed_prepared_ set as well. Pull Request resolved: Differential Revision: D13632134 Pulled By: maysamyabandeh fbshipit-source-id: b0423bb0a58dc95f1e636d5ed3f6e619df801fb7/WritePrepared: Report released snapshots in IsInSnapshot (#4856) Summary: Previously IsInSnapshot assumed that the snapshot is valid at the time that the function is called. However there are cases where that might not be valid. Example is background compactions where the compaction algorithm operates with a list of snapshots some of which might be released by the time they are being passed to IsInSnapshot. The patch make two changes to enable the caller to tell difference: i) any live snapshot below max is added to max_committed_seq_, which allows IsInSnapshot to confidently tell whether the passed snapshot is invalid if it below max, ii) extends IsInSnapshot API with a ""released"" variable that is set true when IsInSnapshot find no such snapshot below max and also find no other way to give a certain return value. In such cases the return value is true but the caller should also check the ""released"" boolean after the call. In short here is the changes in the API: i) If the snapshot is valid, no change is required. ii) If the snapshot might be invalid, a reference to ""released"" boolean must be passed to IsInSnapshot. ii-a) If snapshot is above max, IsInSnapshot can figure the return valid using the commit cache. ii-b) otherwise if snapshot is in old_commit_map_, IsInSnapshot can use that to tell if value was visible to the snapshot. ii-c) otherwise it sets ""released"" to true and returns true as well. Pull Request resolved: Differential Revision: D13599847 Pulled By: maysamyabandeh fbshipit-source-id: 1752be28667f886a1efec8cae5714b9b7a8f1e0f/"
,,0.3798,rocksdb,"WritePrepared: commit of delayed prepared entries (#4894) Summary: Here is the order of ops in a commit: 1) update commit cache 2) publish seq, 3) RemovePrepared. In case of a delayed prepared, there will be a gap between when the commit is visible to snapshots until delayed_prepared_ is cleaned up. To tell apart this case from a delayed uncommitted txn from, the commit entry of a delayed prepared is also stored in delayed_prepared_commits_, which is updated before publishing the commit. Also logic in GetSnapshotInternal that ensures that each new snapshot is always larger than max_evicted_seq_ is updated to check against the upcoming value of max_evicted_seq_ rather than its current one. This is because AdvanceMaxEvictedSeq gets the list of snapshots lower than the new max, before updating max_evicted_seq_. Pull Request resolved: Differential Revision: D13726988 Pulled By: maysamyabandeh fbshipit-source-id: 1e70d78061b50c944c9816bf4b6dac405ab4ccd3/WritePrepared: Fix double snapshot release issue (#4727) Summary: Currently the garbage collection of items in old_commit_map_ was done upon ::ReleaseSnapshot. The assumption behind this method was that the sequence number of snapshots are unique, which is incorrect. In the very rare cases that two consecutive snapshot have the same sequence number this could lead the release of the first snapshot affect the old_commit_map_ that is necessary to service the reads of the second snapshot. The bug would be triggered only if i) two snapshot have the same seq, ii) both of them are very old (older than the last ~4m transactions), and iii) there is commit entry overlapping with the snapshot seq number. It is fixed by doing the cleanup of old_commit_map_ in UpdateSnapshot: the new list of snapshots are compared with the old one and the missing sequence numbers are concluded released. If two snapshots have the same seq number, after the release of one of them, the seq number still appears in the snapshot least and thus not cleaned up prematurely. Pull Request resolved: Differential Revision: D13246495 Pulled By: maysamyabandeh fbshipit-source-id: 93b87a5042afd8060889df245526d3f5d29de9fe/"
,,0.2203,rocksdb,"WritePrepared: fix issue with snapshot released during compaction (#4858) Summary: Compaction iterator keep a copy of list of live snapshots at the beginning of compaction, and then query snapshot checker to verify if values of a sequence number is visible to these snapshots. However when the snapshot is released in the middle of compaction, the snapshot checker implementation (i.e. WritePreparedSnapshotChecker) may remove info with the snapshot and may report incorrect result, which lead to values being compacted out when it shouldnt. This patch conservatively keep the values if snapshot checker determines that the snapshots is released. Pull Request resolved: Differential Revision: D13617146 Pulled By: maysamyabandeh fbshipit-source-id: cf18a94f6f61a94bcff73c280f117b224af5fbc3/"
,,0.4317,rocksdb,"WritePrepared: fix two versions in compaction see different status for released snapshots (#4890) Summary: Fix how CompactionIterator::findEarliestVisibleSnapshots handles released snapshot. It fixing the two scenarios: Scenario 1: key1 has two values v1 and v2. Therere two snapshots s1 and s2 taken after v1 and v2 are committed. Right after compaction output v2, s1 is released. Now findEarliestVisibleSnapshot may see s1 being released, and return the next snapshot, which is s2. Thats larger than v2s earliest visible snapshot, which was s1. The fix: the only place we check against last snapshot and current key snapshot is when we decide whether to compact out a value if it is hidden by a later value. In the check if we see current snapshot is even larger than last snapshot, we know last snapshot is released, and we are safe to compact out current key. Scenario 2: key1 has two values v1 and v2. there are two snapshots s1 and s2 taken after v1 and v2 are committed. During compaction before we process the key, s1 is released. When compaction process v2, snapshot checker may return kSnapshotReleased, and the earliest visible snapshot for v2 become s2. When compaction process v1, snapshot checker may return kIsInSnapshot (for WritePrepared transaction, it could be because v1 is still in commit cache). The result will become inconsistent here. The fix: remember the set of released snapshots ever reported by snapshot checker, and ignore them when finding result for findEarliestVisibleSnapshot. Pull Request resolved: Differential Revision: D13705538 Pulled By: maysamyabandeh fbshipit-source-id: e577f0d9ee1ff5a6035f26859e56902ecc85a5a4/"
,,0.5662,rocksdb,"WritePrepared: fix two versions in compaction see different status for released snapshots (#4890) Summary: Fix how CompactionIterator::findEarliestVisibleSnapshots handles released snapshot. It fixing the two scenarios: Scenario 1: key1 has two values v1 and v2. Therere two snapshots s1 and s2 taken after v1 and v2 are committed. Right after compaction output v2, s1 is released. Now findEarliestVisibleSnapshot may see s1 being released, and return the next snapshot, which is s2. Thats larger than v2s earliest visible snapshot, which was s1. The fix: the only place we check against last snapshot and current key snapshot is when we decide whether to compact out a value if it is hidden by a later value. In the check if we see current snapshot is even larger than last snapshot, we know last snapshot is released, and we are safe to compact out current key. Scenario 2: key1 has two values v1 and v2. there are two snapshots s1 and s2 taken after v1 and v2 are committed. During compaction before we process the key, s1 is released. When compaction process v2, snapshot checker may return kSnapshotReleased, and the earliest visible snapshot for v2 become s2. When compaction process v1, snapshot checker may return kIsInSnapshot (for WritePrepared transaction, it could be because v1 is still in commit cache). The result will become inconsistent here. The fix: remember the set of released snapshots ever reported by snapshot checker, and ignore them when finding result for findEarliestVisibleSnapshot. Pull Request resolved: Differential Revision: D13705538 Pulled By: maysamyabandeh fbshipit-source-id: e577f0d9ee1ff5a6035f26859e56902ecc85a5a4/WritePrepared: commit of delayed prepared entries (#4894) Summary: Here is the order of ops in a commit: 1) update commit cache 2) publish seq, 3) RemovePrepared. In case of a delayed prepared, there will be a gap between when the commit is visible to snapshots until delayed_prepared_ is cleaned up. To tell apart this case from a delayed uncommitted txn from, the commit entry of a delayed prepared is also stored in delayed_prepared_commits_, which is updated before publishing the commit. Also logic in GetSnapshotInternal that ensures that each new snapshot is always larger than max_evicted_seq_ is updated to check against the upcoming value of max_evicted_seq_ rather than its current one. This is because AdvanceMaxEvictedSeq gets the list of snapshots lower than the new max, before updating max_evicted_seq_. Pull Request resolved: Differential Revision: D13726988 Pulled By: maysamyabandeh fbshipit-source-id: 1e70d78061b50c944c9816bf4b6dac405ab4ccd3/WritePrepared: Report released snapshots in IsInSnapshot (#4856) Summary: Previously IsInSnapshot assumed that the snapshot is valid at the time that the function is called. However there are cases where that might not be valid. Example is background compactions where the compaction algorithm operates with a list of snapshots some of which might be released by the time they are being passed to IsInSnapshot. The patch make two changes to enable the caller to tell difference: i) any live snapshot below max is added to max_committed_seq_, which allows IsInSnapshot to confidently tell whether the passed snapshot is invalid if it below max, ii) extends IsInSnapshot API with a ""released"" variable that is set true when IsInSnapshot find no such snapshot below max and also find no other way to give a certain return value. In such cases the return value is true but the caller should also check the ""released"" boolean after the call. In short here is the changes in the API: i) If the snapshot is valid, no change is required. ii) If the snapshot might be invalid, a reference to ""released"" boolean must be passed to IsInSnapshot. ii-a) If snapshot is above max, IsInSnapshot can figure the return valid using the commit cache. ii-b) otherwise if snapshot is in old_commit_map_, IsInSnapshot can use that to tell if value was visible to the snapshot. ii-c) otherwise it sets ""released"" to true and returns true as well. Pull Request resolved: Differential Revision: D13599847 Pulled By: maysamyabandeh fbshipit-source-id: 1752be28667f886a1efec8cae5714b9b7a8f1e0f/"
,,0.2111,rocksdb,"WritePrepared: fix ValidateSnapshot with long-running txn (#4961) Summary: ValidateSnapshot checks if another txn has committed a value to about-to-be-locked key since a particular snapshot. It applies an optimization of looking into only the memtable if snapshot seq is larger than the earliest seq in the memtables. With a long-running txn in WritePrepared, the prepared value might be flushed out to the disk and yet it commits after the snapshot, which breaks this optimization. The patch fixes that by disabling this optimization when the min_uncomitted seq at the time the snapshot was taken is lower than earliest seq in the memtables. Pull Request resolved: Differential Revision: D14009947 Pulled By: maysamyabandeh fbshipit-source-id: 1d11679950326f7c4094b433e6b821b729f08850/"
,,0.3827,rocksdb,"WritePrepared: Report released snapshots in IsInSnapshot (#4856) Summary: Previously IsInSnapshot assumed that the snapshot is valid at the time that the function is called. However there are cases where that might not be valid. Example is background compactions where the compaction algorithm operates with a list of snapshots some of which might be released by the time they are being passed to IsInSnapshot. The patch make two changes to enable the caller to tell difference: i) any live snapshot below max is added to max_committed_seq_, which allows IsInSnapshot to confidently tell whether the passed snapshot is invalid if it below max, ii) extends IsInSnapshot API with a ""released"" variable that is set true when IsInSnapshot find no such snapshot below max and also find no other way to give a certain return value. In such cases the return value is true but the caller should also check the ""released"" boolean after the call. In short here is the changes in the API: i) If the snapshot is valid, no change is required. ii) If the snapshot might be invalid, a reference to ""released"" boolean must be passed to IsInSnapshot. ii-a) If snapshot is above max, IsInSnapshot can figure the return valid using the commit cache. ii-b) otherwise if snapshot is in old_commit_map_, IsInSnapshot can use that to tell if value was visible to the snapshot. ii-c) otherwise it sets ""released"" to true and returns true as well. Pull Request resolved: Differential Revision: D13599847 Pulled By: maysamyabandeh fbshipit-source-id: 1752be28667f886a1efec8cae5714b9b7a8f1e0f/"
,,0.5075,rocksdb,"WritePrepared: fix two versions in compaction see different status for released snapshots (#4890) Summary: Fix how CompactionIterator::findEarliestVisibleSnapshots handles released snapshot. It fixing the two scenarios: Scenario 1: key1 has two values v1 and v2. Therere two snapshots s1 and s2 taken after v1 and v2 are committed. Right after compaction output v2, s1 is released. Now findEarliestVisibleSnapshot may see s1 being released, and return the next snapshot, which is s2. Thats larger than v2s earliest visible snapshot, which was s1. The fix: the only place we check against last snapshot and current key snapshot is when we decide whether to compact out a value if it is hidden by a later value. In the check if we see current snapshot is even larger than last snapshot, we know last snapshot is released, and we are safe to compact out current key. Scenario 2: key1 has two values v1 and v2. there are two snapshots s1 and s2 taken after v1 and v2 are committed. During compaction before we process the key, s1 is released. When compaction process v2, snapshot checker may return kSnapshotReleased, and the earliest visible snapshot for v2 become s2. When compaction process v1, snapshot checker may return kIsInSnapshot (for WritePrepared transaction, it could be because v1 is still in commit cache). The result will become inconsistent here. The fix: remember the set of released snapshots ever reported by snapshot checker, and ignore them when finding result for findEarliestVisibleSnapshot. Pull Request resolved: Differential Revision: D13705538 Pulled By: maysamyabandeh fbshipit-source-id: e577f0d9ee1ff5a6035f26859e56902ecc85a5a4/WritePrepared: Report released snapshots in IsInSnapshot (#4856) Summary: Previously IsInSnapshot assumed that the snapshot is valid at the time that the function is called. However there are cases where that might not be valid. Example is background compactions where the compaction algorithm operates with a list of snapshots some of which might be released by the time they are being passed to IsInSnapshot. The patch make two changes to enable the caller to tell difference: i) any live snapshot below max is added to max_committed_seq_, which allows IsInSnapshot to confidently tell whether the passed snapshot is invalid if it below max, ii) extends IsInSnapshot API with a ""released"" variable that is set true when IsInSnapshot find no such snapshot below max and also find no other way to give a certain return value. In such cases the return value is true but the caller should also check the ""released"" boolean after the call. In short here is the changes in the API: i) If the snapshot is valid, no change is required. ii) If the snapshot might be invalid, a reference to ""released"" boolean must be passed to IsInSnapshot. ii-a) If snapshot is above max, IsInSnapshot can figure the return valid using the commit cache. ii-b) otherwise if snapshot is in old_commit_map_, IsInSnapshot can use that to tell if value was visible to the snapshot. ii-c) otherwise it sets ""released"" to true and returns true as well. Pull Request resolved: Differential Revision: D13599847 Pulled By: maysamyabandeh fbshipit-source-id: 1752be28667f886a1efec8cae5714b9b7a8f1e0f/Extend Transaction::GetForUpdate with do_validate (#4680) Summary: Transaction::GetForUpdate is extended with a do_validate parameter with default value of true. If false it skips validating the snapshot (if there is any) before doing the read. After the read it also returns the latest value (expects the ReadOptions::snapshot to be nullptr). This allows RocksDB applications to use GetForUpdate similarly to how InnoDB does. Similarly ::Merge, ::Put, ::Delete, and ::SingleDelete are extended with assume_exclusive_tracked with default value of false. It true it indicates that call is assumed to be after a ::GetForUpdate(do_validate=false). The Java APIs are accordingly updated. Pull Request resolved: Differential Revision: D13068508 Pulled By: maysamyabandeh fbshipit-source-id: f0b59db28f7f6a078b60844d902057140765e67d/Revert ""BaseDeltaIterator: always check valid() before accessing key(Ö (#4744) Summary: Ö) (#4702)"" This reverts commit 3a18bb3e15e67067d111302d711ae9ac9dc45816. Pull Request resolved: Differential Revision: D13311869 Pulled By: miasantreble fbshipit-source-id: 6300b12cc34828d8b9274e907a3aef1506d5d553/Revert ""apply ReadOptions.iterate_upper_bound to transaction iteratorÖ (#4705) Summary: Ö (#4656)"" This reverts commit b76398a82bde58bfcfa3ed5ba3dbfb6168c241de. Will add test coverage for iterate_upper_bound before re-commit b76398 Pull Request resolved: Differential Revision: D13148592 Pulled By: miasantreble fbshipit-source-id: 4d1ce0bfd9f7a5359a7688bd780eb06a66f45b1f/"
,,0.4523,rocksdb,"WritePrepared: fix two versions in compaction see different status for released snapshots (#4890) Summary: Fix how CompactionIterator::findEarliestVisibleSnapshots handles released snapshot. It fixing the two scenarios: Scenario 1: key1 has two values v1 and v2. Therere two snapshots s1 and s2 taken after v1 and v2 are committed. Right after compaction output v2, s1 is released. Now findEarliestVisibleSnapshot may see s1 being released, and return the next snapshot, which is s2. Thats larger than v2s earliest visible snapshot, which was s1. The fix: the only place we check against last snapshot and current key snapshot is when we decide whether to compact out a value if it is hidden by a later value. In the check if we see current snapshot is even larger than last snapshot, we know last snapshot is released, and we are safe to compact out current key. Scenario 2: key1 has two values v1 and v2. there are two snapshots s1 and s2 taken after v1 and v2 are committed. During compaction before we process the key, s1 is released. When compaction process v2, snapshot checker may return kSnapshotReleased, and the earliest visible snapshot for v2 become s2. When compaction process v1, snapshot checker may return kIsInSnapshot (for WritePrepared transaction, it could be because v1 is still in commit cache). The result will become inconsistent here. The fix: remember the set of released snapshots ever reported by snapshot checker, and ignore them when finding result for findEarliestVisibleSnapshot. Pull Request resolved: Differential Revision: D13705538 Pulled By: maysamyabandeh fbshipit-source-id: e577f0d9ee1ff5a6035f26859e56902ecc85a5a4/WritePrepared: fix issue with snapshot released during compaction (#4858) Summary: Compaction iterator keep a copy of list of live snapshots at the beginning of compaction, and then query snapshot checker to verify if values of a sequence number is visible to these snapshots. However when the snapshot is released in the middle of compaction, the snapshot checker implementation (i.e. WritePreparedSnapshotChecker) may remove info with the snapshot and may report incorrect result, which lead to values being compacted out when it shouldnt. This patch conservatively keep the values if snapshot checker determines that the snapshots is released. Pull Request resolved: Differential Revision: D13617146 Pulled By: maysamyabandeh fbshipit-source-id: cf18a94f6f61a94bcff73c280f117b224af5fbc3/"
,,0.1557,rocksdb,"Enhance transaction_test_util with delays (#4970) Summary: Enhance ::Insert and ::Verify test functions to add artificial delay between prepare and commit, and take snapshot and reads respectively. A future PR will make use of these to improve stress tests to test against long-running transactions as well as long-running backup jobs. Also randomly sets set_snapshot to false for inserters to skip setting the snapshot in the initialization phase and let the snapshot be taken later explicitly. Pull Request resolved: Differential Revision: D14031342 Pulled By: maysamyabandeh fbshipit-source-id: b52b453751f0b25b81b23c48892bc1d152464cab/"
,,0.3656,rocksdb,"Support for single-primary, multi-secondary instances (#4899) Summary: This PR allows RocksDB to run in single-primary, multi-secondary process mode. The writer is a regular RocksDB (e.g. an `DBImpl`) instance playing the role of a primary. Multiple `DBImplSecondary` processes (secondaries) share the same set of SST files, MANIFEST, WAL files with the primary. Secondaries tail the MANIFEST of the primary and apply updates to their own in-memory state of the file system, e.g. `VersionStorageInfo`. This PR has several components: 1. (Originally in Add a `PathNotFound` subcode to `IOError` to denote the failure when a secondary tries to open a file which has been deleted by the primary. 2. (Similar to Add `FragmentBufferedReader` to handle partially-read, trailing record at the end of a log from where future read can continue. 3. (Originally in and Add implementation of the secondary, i.e. `DBImplSecondary`. 3.1 Tail the primarys MANIFEST during recovery. 3.2 Tail the primarys MANIFEST during normal processing by calling `ReadAndApply`. 3.3 Tailing WAL will be in a future PR. 4. Add an example in examples/multi_processes_example.cc to demonstrate the usage of secondary RocksDB instance in a multi-process setting. Instructions to run the example can be found at the beginning of the source code. Pull Request resolved: Differential Revision: D14510945 Pulled By: riversand963 fbshipit-source-id: 4ac1c5693e6012ad23f7b4b42d3c374fecbe8886/"
,,0.3002,rocksdb,"WritePrepared: handle adding prepare before max_evicted_seq_ (#5025) Summary: The patch fixes an improbable race condition between AddPrepared from one write queue and AdvanceMaxEvictedSeq from another queue. In this scenario AddPrepared finds prepare_seq lower than max and adding to PrepareHeap as usual while AdvanceMaxEvictedSeq has finished checking PrepareHeap against the future max. Thus when AdvanceMaxEvictedSeq finishes off by updating the max_evicted_seq_, PrepareHeap ends up with a prepared_seq lower than it which breaks the PrepareHeap contract. The fix is that in AddPrepared we check against the future_max_evicted_seq_ instead, which is update before AdvanceMaxEvictedSeq acquire prepare_mutex_ and looks into PrepareHeap. A unit test added to test for the failure scenario. The code is also refactored a bit to remove the duplicate code between AdvanceMaxEvictedSeq and AddPrepared. Pull Request resolved: Differential Revision: D14249028 Pulled By: maysamyabandeh fbshipit-source-id: 072ea56663f40359662c05fafa6ac524417b0622/"
,,0.3628,rocksdb,"WritePrepared: fix race condition in reading batch with duplicate keys (#5147) Summary: When ReadOption doesnt specify a snapshot, WritePrepared::Get used kMaxSequenceNumber to avoid the cost of creating a new snapshot object (that requires sync over db_mutex). This creates a race condition if it is reading from the writes of a transaction that had duplicate keys: each instance of duplicate key is inserted with a different sequence number and depending on the ordering the ::Get might skip the newer one and read the older one that is obsolete. The patch fixes that by using last published seq as the snapshot sequence number. It also adds a check after the read is done to ensure that the max_evicted_seq has not advanced the aforementioned seq, which is a very unlikely event. If it did, then the read is not valid since the seq is not backed by an actually snapshot to let IsInSnapshot handle that properly when an overlapping commit is evicted from commit cache. A unit test is added to reproduce the race condition with duplicate keys. Pull Request resolved: Differential Revision: D14758815 Pulled By: maysamyabandeh fbshipit-source-id: a56915657132cf6ba5e3f5ea1b5d78c803407719/WritePrepared: handle adding prepare before max_evicted_seq_ (#5025) Summary: The patch fixes an improbable race condition between AddPrepared from one write queue and AdvanceMaxEvictedSeq from another queue. In this scenario AddPrepared finds prepare_seq lower than max and adding to PrepareHeap as usual while AdvanceMaxEvictedSeq has finished checking PrepareHeap against the future max. Thus when AdvanceMaxEvictedSeq finishes off by updating the max_evicted_seq_, PrepareHeap ends up with a prepared_seq lower than it which breaks the PrepareHeap contract. The fix is that in AddPrepared we check against the future_max_evicted_seq_ instead, which is update before AdvanceMaxEvictedSeq acquire prepare_mutex_ and looks into PrepareHeap. A unit test added to test for the failure scenario. The code is also refactored a bit to remove the duplicate code between AdvanceMaxEvictedSeq and AddPrepared. Pull Request resolved: Differential Revision: D14249028 Pulled By: maysamyabandeh fbshipit-source-id: 072ea56663f40359662c05fafa6ac524417b0622/Apply modernize-use-override (2nd iteration) Summary: Use C++11ís override and remove virtual where applicable. Change are automatically generated. Reviewed By: Orvid Differential Revision: D14090024 fbshipit-source-id: 1e9432e87d2657e1ff0028e15370a85d1739ba2a/"
,,0.2684,rocksdb,"WritePrepared: fix race condition in reading batch with duplicate keys (#5147) Summary: When ReadOption doesnt specify a snapshot, WritePrepared::Get used kMaxSequenceNumber to avoid the cost of creating a new snapshot object (that requires sync over db_mutex). This creates a race condition if it is reading from the writes of a transaction that had duplicate keys: each instance of duplicate key is inserted with a different sequence number and depending on the ordering the ::Get might skip the newer one and read the older one that is obsolete. The patch fixes that by using last published seq as the snapshot sequence number. It also adds a check after the read is done to ensure that the max_evicted_seq has not advanced the aforementioned seq, which is a very unlikely event. If it did, then the read is not valid since the seq is not backed by an actually snapshot to let IsInSnapshot handle that properly when an overlapping commit is evicted from commit cache. A unit test is added to reproduce the race condition with duplicate keys. Pull Request resolved: Differential Revision: D14758815 Pulled By: maysamyabandeh fbshipit-source-id: a56915657132cf6ba5e3f5ea1b5d78c803407719/WriteUnPrepared: less virtual in iterator callback (#5049) Summary: WriteUnPrepared adds a virtual function, MaxUnpreparedSequenceNumber, to ReadCallback, which returns 0 unless WriteUnPrepared is enabled and the transaction has uncommitted data written to the DB. Together with snapshot sequence number, this determines the last sequence that is visible to reads. The patch clarifies the guarantees of the GetIterator API in WriteUnPrepared transactions and make use of that to statically initialize the read callback and thus avoid the virtual call. Furthermore it increases the minimum value for min_uncommitted from 0 to 1 as seq 0 is used only for last level keys that are committed in all snapshots. The following benchmark shows +0.26% higher throughput in seekrandom benchmark. Benchmark: ./db_bench ./db_bench seekrandom [AVG 10 runs] : 20355 ops/sec; 225.2 MB/sec seekrandom [MEDIAN 10 runs] : 20425 ops/sec; 225.9 MB/sec ./db_bench_lessvirtual3 seekrandom [AVG 10 runs] : 20409 ops/sec; 225.8 MB/sec seekrandom [MEDIAN 10 runs] : 20487 ops/sec; 226.6 MB/sec Pull Request resolved: Differential Revision: D14366459 Pulled By: maysamyabandeh fbshipit-source-id: ebaff8908332a5ae9af7defeadabcb624be660ef/WritePrepared: Add rollback batch to PreparedHeap (#5026) Summary: The patch adds the sequence number of the rollback patch to the PrepareHeap when two_write_queues is enabled. Although the current behavior is still correct, the change simplifies reasoning about the code, by having all uncommitted batches registered with the PreparedHeap. Pull Request resolved: Differential Revision: D14249401 Pulled By: maysamyabandeh fbshipit-source-id: 1e3424edee5cd14e56ee35931ad3c93ed997cd5a/WritePrepared: commit only from the 2nd queue (#5014) Summary: When two_write_queues is enabled we call ::AddPrepared only from the main queue, which writes to both WAL and memtable, and call ::AddCommitted from the 2nd queue, which writes only to WAL. This simplifies the logic by avoiding concurrency between AddPrepared and also between AddCommitted. The patch fixes one case that did not conform with the rule above. This would allow future refactoring. For example AdvaneMaxEvictedSeq, which is invoked by AddCommitted, can be simplified by assuming lack of concurrent calls to it. Pull Request resolved: Differential Revision: D14210493 Pulled By: maysamyabandeh fbshipit-source-id: 6db5ba372a294a568a14caa010576460917a4eab/Apply modernize-use-override (2nd iteration) Summary: Use C++11ís override and remove virtual where applicable. Change are automatically generated. Reviewed By: Orvid Differential Revision: D14090024 fbshipit-source-id: 1e9432e87d2657e1ff0028e15370a85d1739ba2a/"
,,0.1691,rocksdb,"Mark logs with prepare in PreReleaseCallback (#5121) Summary: In prepare phase of 2PC, the db promises to remember the prepared data, for possible future commits. To fulfill the promise the prepared data must be persisted in the WAL so that they could be recovered after a crash. The log that contains a prepare batch that is not committed yet, is marked so that it is not garbage collected before the transaction commits/rollbacks. The bug was that the write to the log file and the mark of the file was not atomic, and WAL gc could have happened before the WAL log is actually marked. This patch moves the marking logic to PreReleaseCallback so that the WAL gc logic that joins both write threads would see the WAL write and WAL mark atomically. Pull Request resolved: Differential Revision: D14665210 Pulled By: maysamyabandeh fbshipit-source-id: 1d66aeb1c66a296cb4899a5a20c4d40c59e4b534/"
,,0.2938,rocksdb,"WritePrepared: fix race condition in reading batch with duplicate keys (#5147) Summary: When ReadOption doesnt specify a snapshot, WritePrepared::Get used kMaxSequenceNumber to avoid the cost of creating a new snapshot object (that requires sync over db_mutex). This creates a race condition if it is reading from the writes of a transaction that had duplicate keys: each instance of duplicate key is inserted with a different sequence number and depending on the ordering the ::Get might skip the newer one and read the older one that is obsolete. The patch fixes that by using last published seq as the snapshot sequence number. It also adds a check after the read is done to ensure that the max_evicted_seq has not advanced the aforementioned seq, which is a very unlikely event. If it did, then the read is not valid since the seq is not backed by an actually snapshot to let IsInSnapshot handle that properly when an overlapping commit is evicted from commit cache. A unit test is added to reproduce the race condition with duplicate keys. Pull Request resolved: Differential Revision: D14758815 Pulled By: maysamyabandeh fbshipit-source-id: a56915657132cf6ba5e3f5ea1b5d78c803407719/WriteUnPrepared: less virtual in iterator callback (#5049) Summary: WriteUnPrepared adds a virtual function, MaxUnpreparedSequenceNumber, to ReadCallback, which returns 0 unless WriteUnPrepared is enabled and the transaction has uncommitted data written to the DB. Together with snapshot sequence number, this determines the last sequence that is visible to reads. The patch clarifies the guarantees of the GetIterator API in WriteUnPrepared transactions and make use of that to statically initialize the read callback and thus avoid the virtual call. Furthermore it increases the minimum value for min_uncommitted from 0 to 1 as seq 0 is used only for last level keys that are committed in all snapshots. The following benchmark shows +0.26% higher throughput in seekrandom benchmark. Benchmark: ./db_bench ./db_bench seekrandom [AVG 10 runs] : 20355 ops/sec; 225.2 MB/sec seekrandom [MEDIAN 10 runs] : 20425 ops/sec; 225.9 MB/sec ./db_bench_lessvirtual3 seekrandom [AVG 10 runs] : 20409 ops/sec; 225.8 MB/sec seekrandom [MEDIAN 10 runs] : 20487 ops/sec; 226.6 MB/sec Pull Request resolved: Differential Revision: D14366459 Pulled By: maysamyabandeh fbshipit-source-id: ebaff8908332a5ae9af7defeadabcb624be660ef/WritePrepared: handle adding prepare before max_evicted_seq_ (#5025) Summary: The patch fixes an improbable race condition between AddPrepared from one write queue and AdvanceMaxEvictedSeq from another queue. In this scenario AddPrepared finds prepare_seq lower than max and adding to PrepareHeap as usual while AdvanceMaxEvictedSeq has finished checking PrepareHeap against the future max. Thus when AdvanceMaxEvictedSeq finishes off by updating the max_evicted_seq_, PrepareHeap ends up with a prepared_seq lower than it which breaks the PrepareHeap contract. The fix is that in AddPrepared we check against the future_max_evicted_seq_ instead, which is update before AdvanceMaxEvictedSeq acquire prepare_mutex_ and looks into PrepareHeap. A unit test added to test for the failure scenario. The code is also refactored a bit to remove the duplicate code between AdvanceMaxEvictedSeq and AddPrepared. Pull Request resolved: Differential Revision: D14249028 Pulled By: maysamyabandeh fbshipit-source-id: 072ea56663f40359662c05fafa6ac524417b0622/WritePrepared: optimize read path by avoiding virtual (#5018) Summary: The read path includes a callback function, ReadCallback, which would eventually calls IsInSnapshot to figure if a particular seq is in the reading snapshot or not. This callback is virtual, which adds the cost of multiple virtual function call to each read. The first few checks in IsInSnapshot, however, are quite trivial and take care of majority of the cases. The patch moves those to a non-virtual function in the the parent class, ReadCallback, to lower the virtual callback cost. Pull Request resolved: Differential Revision: D14226562 Pulled By: maysamyabandeh fbshipit-source-id: 6feed5b34f3b082e52092c5ef143e29b49c46b44/"
,,0.2528,rocksdb,"WritePrepared: Improve stress tests with slow threads (#4974) Summary: The transaction stress tests, stress a high concurrency scenario. In WritePrepared/WriteUnPrepared we need to also stress the scenarios where an inserting/reading transaction is very slow. This would stress the corner cases that the caching is not sufficient and other slower data structures are engaged. To emulate such cases we make use of slow inserter/verifier threads and also reduce the size of cache data structures. Pull Request resolved: Differential Revision: D14143070 Pulled By: maysamyabandeh fbshipit-source-id: 81eb674678faf9fae0f654cd60ebcc74e26aeee7/Enhance transaction_test_util with delays (#4970) Summary: Enhance ::Insert and ::Verify test functions to add artificial delay between prepare and commit, and take snapshot and reads respectively. A future PR will make use of these to improve stress tests to test against long-running transactions as well as long-running backup jobs. Also randomly sets set_snapshot to false for inserters to skip setting the snapshot in the initialization phase and let the snapshot be taken later explicitly. Pull Request resolved: Differential Revision: D14031342 Pulled By: maysamyabandeh fbshipit-source-id: b52b453751f0b25b81b23c48892bc1d152464cab/"
,,0.3337,rocksdb,"Fix some variable naming in db/transaction_log_impl.* (#5112) Summary: We follow Google C++ Style which indicates variable names should be all underscore: Fix some variable names under db/transaction_log_impl.* Pull Request resolved: Differential Revision: D14631157 Pulled By: siying fbshipit-source-id: 9525c9b0976b843bca377b03897700d87cc60af8/Support for single-primary, multi-secondary instances (#4899) Summary: This PR allows RocksDB to run in single-primary, multi-secondary process mode. The writer is a regular RocksDB (e.g. an `DBImpl`) instance playing the role of a primary. Multiple `DBImplSecondary` processes (secondaries) share the same set of SST files, MANIFEST, WAL files with the primary. Secondaries tail the MANIFEST of the primary and apply updates to their own in-memory state of the file system, e.g. `VersionStorageInfo`. This PR has several components: 1. (Originally in Add a `PathNotFound` subcode to `IOError` to denote the failure when a secondary tries to open a file which has been deleted by the primary. 2. (Similar to Add `FragmentBufferedReader` to handle partially-read, trailing record at the end of a log from where future read can continue. 3. (Originally in and Add implementation of the secondary, i.e. `DBImplSecondary`. 3.1 Tail the primarys MANIFEST during recovery. 3.2 Tail the primarys MANIFEST during normal processing by calling `ReadAndApply`. 3.3 Tailing WAL will be in a future PR. 4. Add an example in examples/multi_processes_example.cc to demonstrate the usage of secondary RocksDB instance in a multi-process setting. Instructions to run the example can be found at the beginning of the source code. Pull Request resolved: Differential Revision: D14510945 Pulled By: riversand963 fbshipit-source-id: 4ac1c5693e6012ad23f7b4b42d3c374fecbe8886/"
,,0.3689,rocksdb,"Support for single-primary, multi-secondary instances (#4899) Summary: This PR allows RocksDB to run in single-primary, multi-secondary process mode. The writer is a regular RocksDB (e.g. an `DBImpl`) instance playing the role of a primary. Multiple `DBImplSecondary` processes (secondaries) share the same set of SST files, MANIFEST, WAL files with the primary. Secondaries tail the MANIFEST of the primary and apply updates to their own in-memory state of the file system, e.g. `VersionStorageInfo`. This PR has several components: 1. (Originally in Add a `PathNotFound` subcode to `IOError` to denote the failure when a secondary tries to open a file which has been deleted by the primary. 2. (Similar to Add `FragmentBufferedReader` to handle partially-read, trailing record at the end of a log from where future read can continue. 3. (Originally in and Add implementation of the secondary, i.e. `DBImplSecondary`. 3.1 Tail the primarys MANIFEST during recovery. 3.2 Tail the primarys MANIFEST during normal processing by calling `ReadAndApply`. 3.3 Tailing WAL will be in a future PR. 4. Add an example in examples/multi_processes_example.cc to demonstrate the usage of secondary RocksDB instance in a multi-process setting. Instructions to run the example can be found at the beginning of the source code. Pull Request resolved: Differential Revision: D14510945 Pulled By: riversand963 fbshipit-source-id: 4ac1c5693e6012ad23f7b4b42d3c374fecbe8886/"
,,0.3591,rocksdb,"Support for single-primary, multi-secondary instances (#4899) Summary: This PR allows RocksDB to run in single-primary, multi-secondary process mode. The writer is a regular RocksDB (e.g. an `DBImpl`) instance playing the role of a primary. Multiple `DBImplSecondary` processes (secondaries) share the same set of SST files, MANIFEST, WAL files with the primary. Secondaries tail the MANIFEST of the primary and apply updates to their own in-memory state of the file system, e.g. `VersionStorageInfo`. This PR has several components: 1. (Originally in Add a `PathNotFound` subcode to `IOError` to denote the failure when a secondary tries to open a file which has been deleted by the primary. 2. (Similar to Add `FragmentBufferedReader` to handle partially-read, trailing record at the end of a log from where future read can continue. 3. (Originally in and Add implementation of the secondary, i.e. `DBImplSecondary`. 3.1 Tail the primarys MANIFEST during recovery. 3.2 Tail the primarys MANIFEST during normal processing by calling `ReadAndApply`. 3.3 Tailing WAL will be in a future PR. 4. Add an example in examples/multi_processes_example.cc to demonstrate the usage of secondary RocksDB instance in a multi-process setting. Instructions to run the example can be found at the beginning of the source code. Pull Request resolved: Differential Revision: D14510945 Pulled By: riversand963 fbshipit-source-id: 4ac1c5693e6012ad23f7b4b42d3c374fecbe8886/"
,,0.18600000000000003,rocksdb,"Export Import sst files (#5495) Summary: Refresh of the earlier change here This is a review request for code change needed for ""Add support for taking snapshot of a column family and creating column family from a given CF snapshot"" We have an implementation for this that we have been testing internally. We have two new APIs that together provide this functionality. (1) ExportColumnFamily() This API is modelled after CreateCheckpoint() as below. // Exports all live SST files of a specified Column Family onto export_dir, // returning SST files information in metadata. // SST files will be created as hard links when the directory specified // is in the same partition as the db directory, copied otherwise. // export_dir should not already exist and will be created by this API. // Always triggers a flush. virtual Status ExportColumnFamily(ColumnFamilyHandle* handle, const std::string& export_dir, ExportImportFilesMetaData** metadata); Internally, the API will DisableFileDeletions(), GetColumnFamilyMetaData(), Parse through metadata, creating links/copies of all the sst files, EnableFileDeletions() and complete the call by returning the list of file metadata. (2) CreateColumnFamilyWithImport() This API is modeled after IngestExternalFile(), but invoked only during a CF creation as below. // CreateColumnFamilyWithImport() will create a new column family with // column_family_name and import external SST files specified in metadata into // this column family. // (1) External SST files can be created using SstFileWriter. // (2) External SST files can be exported from a particular column family in // an existing DB. // Option in import_options specifies whether the external files are copied or // moved (default is copy). When option specifies copy, managing files at // external_file_path is callers responsibility. When option specifies a // move, the call ensures that the specified files at external_file_path are // deleted on successful return and files are not modified on any error // return. // On error return, column family handle returned will be nullptr. // ColumnFamily will be present on successful return and will not be present // on error return. ColumnFamily may be present on any crash during this call. virtual Status CreateColumnFamilyWithImport( const ColumnFamilyOptions& options, const std::string& column_family_name, const ImportColumnFamilyOptions& import_options, const ExportImportFilesMetaData& metadata, ColumnFamilyHandle** handle); Internally, this API creates a new CF, parses all the sst files and adds it to the specified column family, at the same level and with same sequence number as in the metadata. Also performs safety checks with respect to overlaps between the sst files being imported. If incoming sequence number is higher than current local sequence number, local sequence number is updated to reflect this. Note, as the sst files is are being moved across Column Families, Column Family name in sst file will no longer match the actual column family on destination DB. The API does not modify Column Family name or id in the sst files being imported. Pull Request resolved: Differential Revision: D16018881 fbshipit-source-id: 9ae2251025d5916d35a9fc4ea4d6707f6be16ff9/"
,,0.1667,rocksdb,"WriteUnPrepared: Use WriteUnpreparedTxnReadCallback for MultiGet (#5634) Summary: The `TransactionTest.MultiGetBatchedTest` were failing with unprepared batches because we were not using the correct callbacks. Override MultiGet to pass down the correct ReadCallback. A similar problem is also fixed in WritePrepared. This PR also fixes an issue similar to ( but for MultiGet instead of Get. Pull Request resolved: Differential Revision: D16552674 Pulled By: lth fbshipit-source-id: 736eaf8e919c6b13d5f5655b1c0d36b57ad04804/Simplify WriteUnpreparedTxnReadCallback and fix some comments (#5621) Summary: Simplify WriteUnpreparedTxnReadCallback so we just have one function `CalcMaxVisibleSeq`. Also, theres no need for the read callback to hold onto the transaction any more, so just hold the set of unprep_seqs, reducing about of indirection in `IsVisibleFullCheck`. Also, some comments about using transaction snapshot were out of date, so remove them. Pull Request resolved: Differential Revision: D16459883 Pulled By: lth fbshipit-source-id: cd581323fd18982e817d99af57b6eaba59e599bb/"
,,0.2348,rocksdb,"WritePrepared: disableWAL in commit without prepare (#5327) Summary: When committing a transaction without prepare, WritePrepared simply writes the batch to db and add the commit entry to CommitCache. When two_write_queues=true, following the rule of committing only from 2nd write queue, the first write, writes the batch and the only thing the 2nd write does is to write the commit entry to CommitCache. Currently the write batch in 2nd write is set to an empty LogData entry, while the write to the WAL could simply be entirely disabled. Pull Request resolved: Differential Revision: D15424546 Pulled By: maysamyabandeh fbshipit-source-id: 3d9ea3922d5196984c584d62a3ed57e1f7ca7b9f/"
,,0.1751,rocksdb,"WritePrepared: fix Get without snapshot (#5664) Summary: if read_options.snapshot is not set, ::Get will take the last sequence number after taking a super-version and uses that as the sequence number. Theoretically max_eviceted_seq_ could advance this sequence number. This could lead ::IsInSnapshot that will be invoked by the ReadCallback to notice the absence of the snapshot. In this case, the ReadCallback should have passed a non-value to snap_released so that it could be set by the ::IsInSnapshot. The patch does that, and adds a unit test to verify it. Pull Request resolved: Differential Revision: D16614033 Pulled By: maysamyabandeh fbshipit-source-id: 06fb3fd4aacd75806ed1a1acec7961f5d02486f2/WriteUnPrepared: Use WriteUnpreparedTxnReadCallback for MultiGet (#5634) Summary: The `TransactionTest.MultiGetBatchedTest` were failing with unprepared batches because we were not using the correct callbacks. Override MultiGet to pass down the correct ReadCallback. A similar problem is also fixed in WritePrepared. This PR also fixes an issue similar to ( but for MultiGet instead of Get. Pull Request resolved: Differential Revision: D16552674 Pulled By: lth fbshipit-source-id: 736eaf8e919c6b13d5f5655b1c0d36b57ad04804/"
,,0.2838,rocksdb,"WritePrepared: reduce prepared_mutex_ overhead (#5420) Summary: The patch reduces the contention over prepared_mutex_ using these techniques: 1) Move ::RemovePrepared() to be called from the commit callback when we have two write queues. 2) Use two separate mutex for PreparedHeap, one prepared_mutex_ needed for ::RemovePrepared, and one ::push_pop_mutex() needed for ::AddPrepared(). Given that we call ::AddPrepared only from the first write queue and ::RemovePrepared mostly from the 2nd, this will result into each the two write queues not competing with each other over a single mutex. ::RemovePrepared might occasionally need to acquire ::push_pop_mutex() if ::erase() ends up with calling ::pop() 3) Acquire ::push_pop_mutex() on the first callback of the write queue and release it on the last. Pull Request resolved: Differential Revision: D15741985 Pulled By: maysamyabandeh fbshipit-source-id: 84ce8016007e88bb6e10da5760ba1f0d26347735/"
,,0.2742,rocksdb,"WritePrepared: reduce prepared_mutex_ overhead (#5420) Summary: The patch reduces the contention over prepared_mutex_ using these techniques: 1) Move ::RemovePrepared() to be called from the commit callback when we have two write queues. 2) Use two separate mutex for PreparedHeap, one prepared_mutex_ needed for ::RemovePrepared, and one ::push_pop_mutex() needed for ::AddPrepared(). Given that we call ::AddPrepared only from the first write queue and ::RemovePrepared mostly from the 2nd, this will result into each the two write queues not competing with each other over a single mutex. ::RemovePrepared might occasionally need to acquire ::push_pop_mutex() if ::erase() ends up with calling ::pop() 3) Acquire ::push_pop_mutex() on the first callback of the write queue and release it on the last. Pull Request resolved: Differential Revision: D15741985 Pulled By: maysamyabandeh fbshipit-source-id: 84ce8016007e88bb6e10da5760ba1f0d26347735/"
,,0.1345,rocksdb,"Simplify WriteUnpreparedTxnReadCallback and fix some comments (#5621) Summary: Simplify WriteUnpreparedTxnReadCallback so we just have one function `CalcMaxVisibleSeq`. Also, theres no need for the read callback to hold onto the transaction any more, so just hold the set of unprep_seqs, reducing about of indirection in `IsVisibleFullCheck`. Also, some comments about using transaction snapshot were out of date, so remove them. Pull Request resolved: Differential Revision: D16459883 Pulled By: lth fbshipit-source-id: cd581323fd18982e817d99af57b6eaba59e599bb/"
,,0.2044,rocksdb,"New API to get all merge operands for a Key (#5604) Summary: This is a new API added to db.h to allow for fetching all merge operands associated with a Key. The main motivation for this API is to support use cases where doing a full online merge is not necessary as it is performance sensitive. Example use-cases: 1. Update subset of columns and read subset of columns Imagine a SQL Table, a row is encoded as a K/V pair (as it is done in MyRocks). If there are many columns and users only updated one of them, we can use merge operator to reduce write amplification. While users only read one or two columns in the read query, this feature can avoid a full merging of the whole row, and save some CPU. 2. Updating very few attributes in a value which is a JSON-like document Updating one attribute can be done efficiently using merge operator, while reading back one attribute can be done more efficiently if we dont need to do a full merge. API : Status GetMergeOperands( const ReadOptions& options, ColumnFamilyHandle* column_family, const Slice& key, PinnableSlice* merge_operands, GetMergeOperandsOptions* get_merge_operands_options, int* number_of_operands) Example usage : int size 100; int number_of_operands 0; std::vector<PinnableSlice> values(size); GetMergeOperandsOptions merge_operands_info; db_->GetMergeOperands(ReadOptions(), db_->DefaultColumnFamily(), ""k1"", values.data(), merge_operands_info, &number_of_operands); Description : Returns all the merge operands corresponding to the key. If the number of merge operands in DB is greater than merge_operands_options.expected_max_number_of_operands no merge operands are returned and status is Incomplete. Merge operands returned are in the order of insertion. merge_operands-> Points to an array of at-least merge_operands_options.expected_max_number_of_operands and the caller is responsible for allocating it. If the status returned is Incomplete then number_of_operands will contain the total number of merge operands found in DB for key. Pull Request resolved: Test Plan: Added unit test and perf test in db_bench that can be run using the command: ./db_bench Differential Revision: D16657366 Pulled By: vjnadimpalli fbshipit-source-id: 0faadd752351745224ee12d4ae9ef3cb529951bf/WritePrepared: fix Get without snapshot (#5664) Summary: if read_options.snapshot is not set, ::Get will take the last sequence number after taking a super-version and uses that as the sequence number. Theoretically max_eviceted_seq_ could advance this sequence number. This could lead ::IsInSnapshot that will be invoked by the ReadCallback to notice the absence of the snapshot. In this case, the ReadCallback should have passed a non-value to snap_released so that it could be set by the ::IsInSnapshot. The patch does that, and adds a unit test to verify it. Pull Request resolved: Differential Revision: D16614033 Pulled By: maysamyabandeh fbshipit-source-id: 06fb3fd4aacd75806ed1a1acec7961f5d02486f2/WriteUnPrepared: savepoint support (#5627) Summary: Add savepoint support when the current transaction has flushed unprepared batches. Rolling back to savepoint is similar to rolling back a transaction. It requires the set of keys that have changed since the savepoint, re-reading the keys at the snapshot at that savepoint, and the restoring the old keys by writing out another unprepared batch. For this strategy to work though, we must be capable of reading keys at a savepoint. This does not work if keys were written out using the same sequence number before and after a savepoint. Therefore, when we flush out unprepared batches, we must split the batch by savepoint if any savepoints exist. eg. If we have the following: ``` Put(A) Put(B) Put(C) SetSavePoint() Put(D) Put(E) SetSavePoint() Put(F) ``` Then we will write out 3 separate unprepared batches: ``` Put(A) 1 Put(B) 1 Put(C) 1 Put(D) 2 Put(E) 2 Put(F) 3 ``` This is so that when we rollback to eg. the first savepoint, we can just read keys at snapshot_seq 1. Pull Request resolved: Differential Revision: D16584130 Pulled By: lth fbshipit-source-id: 6d100dd548fb20c4b76661bd0f8a2647e64477fa/WriteUnPrepared: use WriteUnpreparedTxnReadCallback for ValidateSnapshot (#5657) Summary: In DeferSnapshotSavePointTest, writes were failing with snapshot validation error because the key with the latest sequence number was an unprepared key from the current transaction. Fix this by passing down the correct read callback. Pull Request resolved: Differential Revision: D16582466 Pulled By: lth fbshipit-source-id: 11645dac0e7c1374d917ef5fdf757d13c1d1108d/WriteUnPrepared: Use WriteUnpreparedTxnReadCallback for MultiGet (#5634) Summary: The `TransactionTest.MultiGetBatchedTest` were failing with unprepared batches because we were not using the correct callbacks. Override MultiGet to pass down the correct ReadCallback. A similar problem is also fixed in WritePrepared. This PR also fixes an issue similar to ( but for MultiGet instead of Get. Pull Request resolved: Differential Revision: D16552674 Pulled By: lth fbshipit-source-id: 736eaf8e919c6b13d5f5655b1c0d36b57ad04804/Simplify WriteUnpreparedTxnReadCallback and fix some comments (#5621) Summary: Simplify WriteUnpreparedTxnReadCallback so we just have one function `CalcMaxVisibleSeq`. Also, theres no need for the read callback to hold onto the transaction any more, so just hold the set of unprep_seqs, reducing about of indirection in `IsVisibleFullCheck`. Also, some comments about using transaction snapshot were out of date, so remove them. Pull Request resolved: Differential Revision: D16459883 Pulled By: lth fbshipit-source-id: cd581323fd18982e817d99af57b6eaba59e599bb/WriteUnPrepared: improve read your own write functionality (#5573) Summary: There are a number of fixes in this PR (with most bugs found via the added stress tests): 1. Re-enable reseek optimization. This was initially disabled to avoid infinite loops in but this can be resolved by remembering not to reseek after a reseek has already been done. This problem only affects forward iteration in `DBIter::FindNextUserEntryInternal`, as we already disable reseeking in `DBIter::FindValueForCurrentKeyUsingSeek`. 2. Verify that ReadOption.snapshot can be safely used for iterator creation. Some snapshots would not give correct results because snaphsot validation would not be enforced, breaking some assumptions in Prev() iteration. 3. In the non-snapshot Get() case, reads done at `LastPublishedSequence` may not be enough, because unprepared sequence numbers are not published. Use `std::max(published_seq, max_visible_seq)` to do lookups instead. 4. Add stress test to test reading own writes. 5. Minor bug in the allow_concurrent_memtable_write case where we forgot to pass in batch_per_txn_. 6. Minor performance optimization in `CalcMaxUnpreparedSequenceNumber` by assigning by reference instead of value. 7. Add some more comments everywhere. Pull Request resolved: Differential Revision: D16276089 Pulled By: lth fbshipit-source-id: 18029c944eb427a90a87dee76ac1b23f37ec1ccb/WriteUnPrepared: use tracked_keys_ to track keys needed for rollback (#5562) Summary: Currently, we are tracking keys we need to rollback via a separate structure specific to WriteUnprepared in write_set_keys_. We already have a data structure called tracked_keys_ used to track which keys to unlock on transaction termination. This is exactly what we want, since we should only rollback keys that we have locked anyway. Save some memory by reusing that data structure instead of making our own. Pull Request resolved: Differential Revision: D16206484 Pulled By: lth fbshipit-source-id: 5894d2b824a4b19062d84adbd6e6e86f00047488/WriteUnprepared: commit only from the 2nd queue (#5439) Summary: This is a port of this PR into WriteUnprepared: This also reverts this test change to restore some flaky write unprepared tests: Tested with: $ gtest-parallel ./transaction_test [128/128] MySQLStyleTransactionTest/MySQLStyleTransactionTest.TransactionStressTest/9 (18250 ms) Pull Request resolved: Differential Revision: D15761405 Pulled By: lth fbshipit-source-id: ae2581fd942d8a5b3f9278fd6bc3c1ac0b2c964c/"
,,0.1103,rocksdb,WriteUnPrepared: Use WriteUnpreparedTxnReadCallback for MultiGet (#5634) Summary: The `TransactionTest.MultiGetBatchedTest` were failing with unprepared batches because we were not using the correct callbacks. Override MultiGet to pass down the correct ReadCallback. A similar problem is also fixed in WritePrepared. This PR also fixes an issue similar to ( but for MultiGet instead of Get. Pull Request resolved: Differential Revision: D16552674 Pulled By: lth fbshipit-source-id: 736eaf8e919c6b13d5f5655b1c0d36b57ad04804/
,,0.1595,rocksdb,"row_cache to share entry for recent snapshots (#5600) Summary: Right now, users cannot take advantage of row cache, unless no snapshot is used, or Get() is repeated for the same snapshots. This limits the usage of row cache. This change eliminate this restriction in some cases. If the snapshot used is newer than the largest sequence number in the file, and write callback function is not registered, the same row cache key is used as no snapshot is given. We still need the callback function restriction for now because the callback function may filter out different keys for different snapshots even if the snapshots are new. Pull Request resolved: Test Plan: Add a unit test. Differential Revision: D16386616 fbshipit-source-id: 6b7d214bd215d191b03ccf55926ad4b703ec2e53/"
,,0.3064,rocksdb,"Introduce a new storage specific Env API (#5761) Summary: The current Env API encompasses both storage/file operations, as well as OS related operations. Most of the APIs return a Status, which does not have enough metadata about an error, such as whether its retry-able or not, scope (i.e fault domain) of the error etc., that may be required in order to properly handle a storage error. The file APIs also do not provide enough control over the IO SLA, such as timeout, prioritization, hinting about placement and redundancy etc. This PR separates out the file/storage APIs from Env into a new FileSystem class. The APIs are updated to return an IOStatus with metadata about the error, as well as to take an IOOptions structure as input in order to allow more control over the IO. The user can set both ```options.env``` and ```options.file_system``` to specify that RocksDB should use the former for OS related operations and the latter for storage operations. Internally, a ```CompositeEnvWrapper``` has been introduced that inherits from ```Env``` and redirects individual methods to either an ```Env``` implementation or the ```FileSystem``` as appropriate. When options are sanitized during ```DB::Open```, ```options.env``` is replaced with a newly allocated ```CompositeEnvWrapper``` instance if both env and file_system have been specified. This way, the rest of the RocksDB code can continue to function as before. This PR also ports PosixEnv to the new API by splitting it into two PosixEnv and PosixFileSystem. PosixEnv is defined as a sub-class of CompositeEnvWrapper, and threading/time functions are overridden with Posix specific implementations in order to avoid an extra level of indirection. The ```CompositeEnvWrapper``` translates ```IOStatus``` return code to ```Status```, and sets the severity to ```kSoftError``` if the io_status is retryable. The error handling code in RocksDB can then recover the DB automatically. Pull Request resolved: Differential Revision: D18868376 Pulled By: anand1976 fbshipit-source-id: 39efe18a162ea746fabac6360ff529baba48486f/PosixRandomAccessFile::MultiRead() to use I/O uring if supported (#5881) Summary: Right now, PosixRandomAccessFile::MultiRead() executes read requests in parallel. In this PR, it leverages I/O Uring library to run it in parallel, even when page cache is enabled. This function will fall back if the kernel version doesnt support it. Pull Request resolved: Test Plan: Run the unit test on a kernel version supporting it and make sure all tests pass, and run a unit test on kernel version supporting it and see it pass. Before merging, will also run stress test and see it passes. Differential Revision: D17742266 fbshipit-source-id: e05699c925ac04fdb42379456a4e23e4ebcb803a/"
,,0.142,rocksdb,"Double Crash in kPointInTimeRecovery with TransactionDB (#6313) Summary: In WritePrepared there could be gap in sequence numbers. This breaks the trick we use in kPointInTimeRecovery which assume the first seq in the log right after the corrupted log is one larger than the last seq we read from the logs. To let this trick keep working, we add a dummy entry with the expected sequence to the first log right after recovery. Also in WriteCommitted, if the log right after the corrupted log is empty, since it has no sequence number to let the sequential trick work, it is assumed as unexpected behavior. This is however expected to happen if we close the db after recovering from a corruption and before writing anything new to it. To remedy that, we apply the same technique by writing a dummy entry to the log that is created after the corrupted log. Pull Request resolved: Differential Revision: D19458291 Pulled By: maysamyabandeh fbshipit-source-id: 09bc49e574690085df45b034ca863ff315937e2d/Prevent an incompatible combination of options (#6254) Summary: allow_concurrent_memtable_write is incompatible with non-zero max_successive_merges. Although we check this at runtime, we currently dont prevent the user from setting this combination in options. This has led to stress tests to fail with this combination is tried in ::SetOptions. The patch fixes that. Pull Request resolved: Differential Revision: D19265819 Pulled By: maysamyabandeh fbshipit-source-id: 47f2e2dc26fe0972c7152f4da15dadb9703f1179/"
,,0.2761,rocksdb,"Check KeyContext status in MultiGet (#6387) Summary: Currently, any IO errors and checksum mismatches while reading data blocks, are being ignored by the batched MultiGet. Its only looking at the GetContext state. Fix that. Pull Request resolved: Test Plan: Add unit tests Differential Revision: D19799819 Pulled By: anand1976 fbshipit-source-id: 46133dccbb04e64067b9fe6cda73e282203db969/Fix regression bug of hash index with iterator total order seek (#6328) Summary: introduces a bug for hash index in SST files. If a table reader is created when total order seek is used, prefix_extractor might be passed into table reader as null. While later when prefix seek is used, the same table reader used, hash index is checked but prefix extractor is null and the program would crash. Fix the issue by fixing in the way that prefix_extractor is preserved but ReadOptions.total_order_seek is checked Also, a null pointer check is added so that a bug like this wont cause segfault in the future. Pull Request resolved: Test Plan: Add a unit test that would fail without the fix. Stress test that reproduces the crash would pass. Differential Revision: D19586751 fbshipit-source-id: 8de77690167ddf5a77a01e167cf89430b1bfba42/Introduce a new storage specific Env API (#5761) Summary: The current Env API encompasses both storage/file operations, as well as OS related operations. Most of the APIs return a Status, which does not have enough metadata about an error, such as whether its retry-able or not, scope (i.e fault domain) of the error etc., that may be required in order to properly handle a storage error. The file APIs also do not provide enough control over the IO SLA, such as timeout, prioritization, hinting about placement and redundancy etc. This PR separates out the file/storage APIs from Env into a new FileSystem class. The APIs are updated to return an IOStatus with metadata about the error, as well as to take an IOOptions structure as input in order to allow more control over the IO. The user can set both ```options.env``` and ```options.file_system``` to specify that RocksDB should use the former for OS related operations and the latter for storage operations. Internally, a ```CompositeEnvWrapper``` has been introduced that inherits from ```Env``` and redirects individual methods to either an ```Env``` implementation or the ```FileSystem``` as appropriate. When options are sanitized during ```DB::Open```, ```options.env``` is replaced with a newly allocated ```CompositeEnvWrapper``` instance if both env and file_system have been specified. This way, the rest of the RocksDB code can continue to function as before. This PR also ports PosixEnv to the new API by splitting it into two PosixEnv and PosixFileSystem. PosixEnv is defined as a sub-class of CompositeEnvWrapper, and threading/time functions are overridden with Posix specific implementations in order to avoid an extra level of indirection. The ```CompositeEnvWrapper``` translates ```IOStatus``` return code to ```Status```, and sets the severity to ```kSoftError``` if the io_status is retryable. The error handling code in RocksDB can then recover the DB automatically. Pull Request resolved: Differential Revision: D18868376 Pulled By: anand1976 fbshipit-source-id: 39efe18a162ea746fabac6360ff529baba48486f/Fix a regression bug on total order seek with prefix enabled and range delete (#6028) Summary: Recent change mistakely use ""prefix_extractor_ nullptr"" as the condition to determine whehter prefix bloom filter isused. It fails to consider read_options.total_order_seek, so it is wrong. The result is that an optimization for non-total-order seek is mistakely applied to total order seek, and introduces a bug in following corner case: Because of RangeDelete(), a files largest key is extended. Seek key falls into the range deleted file, so level iterator seeks into the previous file without getting any key. The correct behavior is to place the iterator to the first key of the next file. However, an optimization is triggered and invalidates the iterator because it is out of the prefix range, causing wrong results. This behavior is reproduced in the unit test added. Fix the bug by setting prefix_extractor to be null if total order seek is used. Pull Request resolved: Test Plan: Add a unit test which fails without the fix. Differential Revision: D18479063 fbshipit-source-id: ac075f013029fcf69eb3a598f14c98cce3e810b3/"
,,0.3916,rocksdb,"Introduce a new storage specific Env API (#5761) Summary: The current Env API encompasses both storage/file operations, as well as OS related operations. Most of the APIs return a Status, which does not have enough metadata about an error, such as whether its retry-able or not, scope (i.e fault domain) of the error etc., that may be required in order to properly handle a storage error. The file APIs also do not provide enough control over the IO SLA, such as timeout, prioritization, hinting about placement and redundancy etc. This PR separates out the file/storage APIs from Env into a new FileSystem class. The APIs are updated to return an IOStatus with metadata about the error, as well as to take an IOOptions structure as input in order to allow more control over the IO. The user can set both ```options.env``` and ```options.file_system``` to specify that RocksDB should use the former for OS related operations and the latter for storage operations. Internally, a ```CompositeEnvWrapper``` has been introduced that inherits from ```Env``` and redirects individual methods to either an ```Env``` implementation or the ```FileSystem``` as appropriate. When options are sanitized during ```DB::Open```, ```options.env``` is replaced with a newly allocated ```CompositeEnvWrapper``` instance if both env and file_system have been specified. This way, the rest of the RocksDB code can continue to function as before. This PR also ports PosixEnv to the new API by splitting it into two PosixEnv and PosixFileSystem. PosixEnv is defined as a sub-class of CompositeEnvWrapper, and threading/time functions are overridden with Posix specific implementations in order to avoid an extra level of indirection. The ```CompositeEnvWrapper``` translates ```IOStatus``` return code to ```Status```, and sets the severity to ```kSoftError``` if the io_status is retryable. The error handling code in RocksDB can then recover the DB automatically. Pull Request resolved: Differential Revision: D18868376 Pulled By: anand1976 fbshipit-source-id: 39efe18a162ea746fabac6360ff529baba48486f/"
,,0.1118,rocksdb,"Let DBSecondary close files after catch up (#6114) Summary: After secondary instance replays the logs from primary, certain files become obsolete. The secondary should find these files, evict their table readers from table cache and close them. If this is not done, the secondary will hold on to these files and prevent their space from being freed. Test plan (devserver): ``` $./db_secondary_test $make check $./db_stress ``` Pull Request resolved: Differential Revision: D18769998 Pulled By: riversand963 fbshipit-source-id: 5d1f151567247196164e1b79d8402fa2045b9120/"
,,0.3835,rocksdb,"Introduce a new storage specific Env API (#5761) Summary: The current Env API encompasses both storage/file operations, as well as OS related operations. Most of the APIs return a Status, which does not have enough metadata about an error, such as whether its retry-able or not, scope (i.e fault domain) of the error etc., that may be required in order to properly handle a storage error. The file APIs also do not provide enough control over the IO SLA, such as timeout, prioritization, hinting about placement and redundancy etc. This PR separates out the file/storage APIs from Env into a new FileSystem class. The APIs are updated to return an IOStatus with metadata about the error, as well as to take an IOOptions structure as input in order to allow more control over the IO. The user can set both ```options.env``` and ```options.file_system``` to specify that RocksDB should use the former for OS related operations and the latter for storage operations. Internally, a ```CompositeEnvWrapper``` has been introduced that inherits from ```Env``` and redirects individual methods to either an ```Env``` implementation or the ```FileSystem``` as appropriate. When options are sanitized during ```DB::Open```, ```options.env``` is replaced with a newly allocated ```CompositeEnvWrapper``` instance if both env and file_system have been specified. This way, the rest of the RocksDB code can continue to function as before. This PR also ports PosixEnv to the new API by splitting it into two PosixEnv and PosixFileSystem. PosixEnv is defined as a sub-class of CompositeEnvWrapper, and threading/time functions are overridden with Posix specific implementations in order to avoid an extra level of indirection. The ```CompositeEnvWrapper``` translates ```IOStatus``` return code to ```Status```, and sets the severity to ```kSoftError``` if the io_status is retryable. The error handling code in RocksDB can then recover the DB automatically. Pull Request resolved: Differential Revision: D18868376 Pulled By: anand1976 fbshipit-source-id: 39efe18a162ea746fabac6360ff529baba48486f/"
,,0.1522,rocksdb,"WriteUnPrepared: Untracked keys (#6404) Summary: For write unprepared, some applications may bypass the transaction api, and write keys directly into the write batch. However, since they are not tracked, rollbacks (both for savepoint and transaction) are not aware that these keys have to be rolled back. The fix is to track them in `WriteUnpreparedTxn::untracked_keys_`. This is populated whenever we flush unprepared batches into the DB. Pull Request resolved: Differential Revision: D19842023 Pulled By: lth fbshipit-source-id: a9edfc643d5c905fc89da9a9a9094d30c9b70108/"
