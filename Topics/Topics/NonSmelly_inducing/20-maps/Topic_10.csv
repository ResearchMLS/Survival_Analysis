Topic_no,Keywords,Contrib,System,Text
10,"make, change, log, unit_test, read, number, sequence, dai, patch, break, error, record, correct, env, remove, run, avoid, creation, order, build",0.1327,conscrypt,"Fix unwrap bug for large messages. (#189) If you write a record and dont have enough destination buffer space to read all the plaintext, the plaintext gets left in the plaintext buffer and the next record you write ends up in the ciphertext buffer (and you read the leftover plaintext from the last record), and you continue to have a record sitting in the ciphertext buffer until you get two records that dont fit in the buffer together, at which point you get the short write and subsequent exception. Also added a test to verify the bug./"
,,0.0733,conscrypt,"Add logging macros that work on all platforms. (#462) This adds CONSCRYPT_LOG_X macros that redirect to either ALOG on Android or fprintf(stderr) on non-Android. In the future, we could use these to allow users to register a logging callback and send the logs to a destination of their choice (via java.util.Logger or log4j or what have you), but for now well keep it simple. Fixes"
,,0.0712,frostwire,"[all] after so much time, it does not make sense to have a dedicated package for the single class Logger/"
,,0.0653,frostwire,"[all] after so much time, it does not make sense to have a dedicated package for the single class Logger/"
,,0.0556,frostwire,[all] removed MagnetUriBuilder/
,,0.066,frostwire,[desktop] removed GuiCoreMediator class/[desktop] code formatting of LocalClientInfo/
,,0.0673,frostwire,[android] InHouseBanner offering fix/
,,0.0718,frostwire,[android] using execute instead of submit to avoid unused creation of Future objects/
,,0.0838,frostwire,"[desktop] deprecation fixes, unboxing, labmda refactors/"
,,0.0818,frostwire,"[desktop] deprecation fixes, unboxing, labmda refactors/"
,,0.0879,frostwire,"[desktop] deprecation fixes, unboxing, labmda refactors/"
,,0.0818,frostwire,"[desktop] deprecation fixes, unboxing, labmda refactors/"
,,0.0556,jna,Many changes/
,,0.0652,jna,Testsuite fixes./
,,0.08,jna,"enforce declaration of structure field order/set all structure fields, add android as a recognized platform/"
,,0.0778,jna,clean up before merge/clean up/functional detach switch from callback/
,,0.0894,jna,"amd64/linux pthread investigations/use tls for callback detach indication, avoid potential conflict with last error/fix compiler warnings on win64/improve performance saving last error (per thread)/"
,,0.0811,jna,"use tls for callback detach indication, avoid potential conflict with last error/improve performance saving last error (per thread)/"
,,0.0737,jna,clean up before merge/clean up/functional detach switch from callback/
,,0.0883,jna,"use tls for callback detach indication, avoid potential conflict with last error/improve performance saving last error (per thread)/"
,,0.0891,jna,enforce declaration of structure field order/
,,0.087,jna,enforce declaration of structure field order/
,,0.0933,jna,enforce declaration of structure field order/
,,0.0954,jna,enforce declaration of structure field order/
,,0.0912,jna,enforce declaration of structure field order/
,,0.0954,jna,enforce declaration of structure field order/
,,0.0828,jna,enforce declaration of structure field order/
,,0.0954,jna,enforce declaration of structure field order/
,,0.0577,jna,clean up before merge/
,,0.0956,jna,Add platform.win32.Kernel32.DeleteFile and com.sun.jna.platform.win32.deleteFile. Add Event Logging functions to platform.win32.Advapi32. git-svn-id: 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/
,,0.1019,jna,File security and registry QWORD changes merged by samuel-aubin./
,,0.1019,jna,File security and registry QWORD changes merged by samuel-aubin./
,,0.0998,jna,File security and registry QWORD changes merged by samuel-aubin./
,,0.1019,jna,File security and registry QWORD changes merged by samuel-aubin./
,,0.1363,jna,fix/cleanup platform tests/Additional changes per twall/Additional changes per twall/File security and registry QWORD changes merged by samuel-aubin./
,,0.0673,jna,"Fix: platform.win32.Secur32.AcquireCredentialsHandle, InitializeSecurityContext and AcceptSecurityContext./"
,,0.066,jna,Add encryption and decryption functions to Advapi32/
,,0.1222,jna,Add Win32 Service functions to platform.win32.Advapi32 CR: dBlock git-svn-id: 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add platform.win32.Kernel32.DeleteFile and com.sun.jna.platform.win32.deleteFile. Add Event Logging functions to platform.win32.Advapi32. git-svn-id: 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/
,,0.1299,jna,"Added support for GetFileType./fix javadoc warnings, move interface method definitions to WinNT from WinBase/fix/cleanup platform tests/Additional changes per twall/Additional changes per twall/File security and registry QWORD changes merged by samuel-aubin./"
,,0.1409,jna,"Add ACL constructor that tolerates files with unknown ACE types If an ACL contained supported (ACCESS_ALLOWED_ACE_TYPE, ACCESS_DENIED_ACE_TYPE) and unsupported types (i.e. ACCESS_ALLOWED_CALLBACK_ACE_TYPE) the constructor threw an IllegalArgumentException. The extraction logic for the ACEs was moved to the accessor function and unsupported ACEs are skipped./"
,,0.066,jna,"closes platform.win32.Secur32.AcquireCredentialsHandle, InitializeSecurityContext and AcceptSecurityContext./"
,,0.1046,jna,enforce declaration of structure field order/Use Structure.toArray() instead of domains.getTrusts()/Some DS_DOMAIN_TRUSTS fields were mapping ULONG to NativeLong instead of int./
,,0.0954,jna,enforce declaration of structure field order/
,,0.0673,jna,"Fix: platform.win32.Secur32.AcquireCredentialsHandle, InitializeSecurityContext and AcceptSecurityContext./"
,,0.0912,jna,enforce declaration of structure field order/
,,0.0669,jna,Allow interoperation when JNI version revision changes/
,,0.0686,OpenDDS,ChangeLogTag: Sun Oct 23 16:19:14 MST 2005 Trevor Fields
,,0.0686,OpenDDS,Thu Nov 17 06:23:48 MST 2005 Scott Harris Oct 25 15:22:28 MST 2005 Trevor Fields
,,0.0664,OpenDDS,Thu Dec 15 10:08:28 USMST 2005 Yan Dai Sun Oct 23 16:19:14 MST 2005 Trevor Fields
,,0.0833,OpenDDS,ChangeLogTag:Tue Nov 29 13:30:35 MST 2005 Trevor Fields Oct 25 15:22:28 MST 2005 Trevor Fields Sun Oct 23 16:19:14 MST 2005 Trevor Fields
,,0.0686,OpenDDS,ChangeLogTag: Sun Oct 23 16:19:14 MST 2005 Trevor Fields
,,0.0686,OpenDDS,ChangeLogTag: Sun Oct 23 16:19:14 MST 2005 Trevor Fields
,,0.0673,OpenDDS,ChangeLogTag:Wed Jan 04 14:51:42 MST 2006 Trevor Fields
,,0.0686,OpenDDS,Fri Jan 20 13:21:40 USMST 2006 Yan Dai
,,0.0686,OpenDDS,ChangeLogTag:Sat Jan 14 15:22:43 MST 2006 Trevor Fields
,,0.0686,OpenDDS,ChangeLogTag:Sat Jan 14 15:22:43 MST 2006 Trevor Fields
,,0.0686,OpenDDS,ChangeLogTag:Sat Jan 14 15:22:43 MST 2006 Trevor Fields
,,0.0686,OpenDDS,Fri Jan 20 13:21:40 USMST 2006 Yan Dai
,,0.0686,OpenDDS,ChangeLogTag:Sat Jan 14 15:22:43 MST 2006 Trevor Fields
,,0.0664,OpenDDS,ChangeLogTag:Sat Jan 14 15:22:43 MST 2006 Trevor Fields
,,0.0664,OpenDDS,ChangeLogTag:Sat Jan 14 15:22:43 MST 2006 Trevor Fields
,,0.0686,OpenDDS,ChangeLogTag:Sat Jan 14 15:22:43 MST 2006 Trevor Fields
,,0.0686,OpenDDS,ChangeLogTag:Sat Jan 14 15:22:43 MST 2006 Trevor Fields
,,0.0664,OpenDDS,ChangeLogTag:Sat Jan 14 15:22:43 MST 2006 Trevor Fields
,,0.0686,OpenDDS,ChangeLogTag:Sat Jan 14 15:22:43 MST 2006 Trevor Fields
,,0.0686,OpenDDS,Fri Jan 20 13:21:40 USMST 2006 Yan Dai
,,0.0686,OpenDDS,Fri Jan 20 13:21:40 USMST 2006 Yan Dai
,,0.0686,OpenDDS,ChangeLogTag:Sat Jan 14 15:22:43 MST 2006 Trevor Fields
,,0.0686,OpenDDS,ChangeLogTag:Sat Jan 14 15:22:43 MST 2006 Trevor Fields
,,0.0686,OpenDDS,ChangeLogTag:Sat Jan 14 15:22:43 MST 2006 Trevor Fields
,,0.0686,OpenDDS,ChangeLogTag:Sat Jan 14 15:22:43 MST 2006 Trevor Fields
,,0.0686,OpenDDS,Fri Jan 20 13:21:40 USMST 2006 Yan Dai
,,0.0686,OpenDDS,ChangeLogTag:Sat Jan 14 15:22:43 MST 2006 Trevor Fields
,,0.0686,OpenDDS,Fri Jan 20 13:21:40 USMST 2006 Yan Dai
,,0.0849,OpenDDS,Mon Mar 27 16:14:47 USMST 2006 Yan Dai Jan 25 11:15:55 MST 2006 Trevor Fields Jan 11 23:47:37 UTC 2006 Scott Harris
,,0.0686,OpenDDS,Tue Apr 11 10:10:41 USMST 2006 Yan Dai
,,0.0865,OpenDDS,Wed Sep 7 06:59:35 UTC 2006 Yan Dai
,,0.0686,OpenDDS,Thu Sep 8 06:19:22 UTC 2006 Yan Dai Sep 7 06:59:35 UTC 2006 Yan Dai Jul 3 8:42:38 UTC 2006 Yan Dai
,,0.0865,OpenDDS,Wed Sep 7 06:59:35 UTC 2006 Yan Dai
,,0.0865,OpenDDS,Wed Sep 7 06:59:35 UTC 2006 Yan Dai
,,0.0865,OpenDDS,Wed Sep 7 06:59:35 UTC 2006 Yan Dai
,,0.0686,OpenDDS,Mon Jul 3 09:23:33 UTC 2006 Yan Dai
,,0.0673,OpenDDS,ChangeLogTag: Wed Dec 20 16:16:03 UTC 2006 Ciju John
,,0.0686,OpenDDS,ChangeLogTag: Tue Jan 23 22:56:33 UTC 2007 Ciju John
,,0.0686,OpenDDS,ChangeLogTag: Fri Jan 12 16:20:48 UTC 2007 Ciju John
,,0.114,OpenDDS,ChangeLogTag: Wed Jun 27 19:41:00 UTC 2007 Jonathan S. Pollack Wed Jun 27 18:48:54 UTC 2007 Jonathan S. Pollack Wed Jun 27 16:20:33 UTC 2007 Jonathan S. Pollack Jun 12 19:06:13 UTC 2007 Wallace Zhang ChangeLog/Thu Apr 26 14:25:09 UTC 2007 Yan Dai Apr 18 16:25:09 UTC 2007 Yan Dai
,,0.0686,OpenDDS,Thu Apr 26 14:25:09 UTC 2007 Yan Dai
,,0.1446,OpenDDS,Mon Jul 2 22:05:48 UTC 2007 Yan Dai Thu Jun 21 16:22:05 UTC 2007 Jonathan S. Pollack Jun 1 19:56:29 UTC 2007 Yan Dai Wed May 30 19:19:38 UTC 2007 Scott Harris May 2 22:03:56 UTC 2007 Scott Harris Apr 26 14:25:09 UTC 2007 Yan Dai Apr 18 16:25:09 UTC 2007 Yan Dai
,,0.0865,OpenDDS,Wed Apr 18 16:25:09 UTC 2007 Yan Dai
,,0.0673,OpenDDS,Fri Jun 22 18:58:47 USMST 2007 Yan Dai Wed May 30 19:19:38 UTC 2007 Scott Harris
,,0.0849,OpenDDS,Mon Jul 2 22:05:48 UTC 2007 Yan Dai Wed May 30 19:19:38 UTC 2007 Scott Harris Apr 26 14:25:09 UTC 2007 Yan Dai Apr 18 16:25:09 UTC 2007 Yan Dai
,,0.0865,OpenDDS,ChangeLogTag: Fri Apr 13 20:54:05 UTC 2007 Ciju John at ociweb dot com>/
,,0.0686,OpenDDS,ChangeLogTag:Tue Jul 10 17:07:05 UTC 2007 Trevor Fields
,,0.0865,OpenDDS,ChangeLogTag: Tue Aug 21 17:56:14 UTC 2007 Ciju John at ociweb dot com>/
,,0.0844,OpenDDS,ChangeLogTag: Tue Aug 21 17:56:14 UTC 2007 Ciju John at ociweb dot com>/
,,0.0686,OpenDDS,ChangeLogTag: Fri Jul 06 18:06:18 UTC 2007 Trevor Fields
,,0.0865,OpenDDS,ChangeLogTag: Tue Aug 21 17:56:14 UTC 2007 Ciju John at ociweb dot com>/
,,0.0686,OpenDDS,Wed Apr 23 12:13:42 UTC 2008 Brian Johnson
,,0.0865,OpenDDS,Wed Jan 30 15:56:10 UTC 2008 Mike Martinez
,,0.0865,OpenDDS,Wed Jan 30 15:56:10 UTC 2008 Mike Martinez
,,0.0865,OpenDDS,Wed Jan 30 15:56:10 UTC 2008 Mike Martinez
,,0.0686,OpenDDS,ChangeLogTag: Wed Jan 30 19:51:02 UTC 2008 Adam Mitz Jan 30 15:56:10 UTC 2008 Mike Martinez
,,0.0865,OpenDDS,Wed Jan 30 15:56:10 UTC 2008 Mike Martinez
,,0.0865,OpenDDS,Wed Jan 30 15:56:10 UTC 2008 Mike Martinez
,,0.0865,OpenDDS,Wed Jan 30 15:56:10 UTC 2008 Mike Martinez
,,0.0865,OpenDDS,ChangeLogTag: Fri Apr 11 21:45:54 UTC 2008 Ciju John at ociweb dot com>/
,,0.1121,OpenDDS,Wed Apr 23 12:13:42 UTC 2008 Brian Johnson Fri Apr 11 21:45:54 UTC 2008 Ciju John at ociweb dot com>/Fri Mar 14 19:07:28 UTC 2008 Brian Johnson qos propagation feature (see RT 11023)/
,,0.0833,OpenDDS,Tue Apr 29 19:35:38 UTC 2008 Brian Johnson Apr 25 13:14:29 UTC 2008 Brian Johnson qos propagation feature (see RT 11023)/
,,0.0848,OpenDDS,Wed Apr 23 12:13:42 UTC 2008 Brian Johnson Fri Apr 11 21:45:54 UTC 2008 Ciju John at ociweb dot com>/Added qos propagation feature (see RT 11023)/
,,0.0865,OpenDDS,ChangeLogTag: Sun May 11 07:12:25 UTC 2008 Ciju John at ociweb dot com>/
,,0.0844,OpenDDS,Wed Jul 16 22:34:10 UTC 2008 Yan Dai Tue May 13 14:26:10 UTC 2008 Ciju John at ociweb dot com>/
,,0.1019,OpenDDS,ChangeLogTag: Tue May 6 20:41:21 UTC 2008 Ciju John at ociweb dot com>/Mon May 5 23:19:57 UTC 2008 Yan Dai Apr 30 00:17:58 UTC 2008 Yan Dai
,,0.0686,OpenDDS,Mon May 5 19:15:05 UTC 2008 Mike Martinez
,,0.1161,OpenDDS,Fri Jul 11 22:45:25 UTC 2008 Yan Dai Jun 6 08:27:23 UTC 2008 Ossama Othman May 6 20:37:31 UTC 2008 Brian Johnson
,,0.0849,OpenDDS,Fri Jul 11 22:45:25 UTC 2008 Yan Dai
,,0.0865,OpenDDS,Wed Jul 16 22:34:10 UTC 2008 Yan Dai Jul 12 20:52:56 UTC 2008 Yan Dai Jul 11 22:45:25 UTC 2008 Yan Dai
,,0.0865,OpenDDS,Wed Jul 16 22:34:10 UTC 2008 Yan Dai Jul 12 20:52:56 UTC 2008 Yan Dai Jul 11 22:45:25 UTC 2008 Yan Dai
,,0.0865,OpenDDS,Tue Oct 28 21:34:20 UTC 2008 Yan Dai Oct 6 22:22:34 UTC 2008 Mike Martinez
,,0.0673,OpenDDS,ChangeLogTag: Thu Oct 23 21:43:57 UTC 2008 Adam Mitz Oct 10 20:26:41 UTC 2008 Yan Dai Oct 6 22:22:34 UTC 2008 Mike Martinez
,,0.0686,OpenDDS,Wed Oct 8 18:45:16 UTC 2008 Mike Martinez
,,0.0673,OpenDDS,ChangeLogTag: Thu Oct 23 21:43:57 UTC 2008 Adam Mitz Oct 6 22:22:34 UTC 2008 Mike Martinez
,,0.0865,OpenDDS,Thu Oct 16 23:09:41 UTC 2008 Yan Dai Oct 6 22:22:34 UTC 2008 Mike Martinez
,,0.0865,OpenDDS,Fri Oct 10 22:13:49 UTC 2008 Yan Dai Oct 6 22:22:34 UTC 2008 Mike Martinez
,,0.0865,OpenDDS,Wed Oct 15 18:46:14 UTC 2008 Yan Dai Oct 6 22:22:34 UTC 2008 Mike Martinez
,,0.0686,OpenDDS,Mon Jan 5 20:45:31 UTC 2009 Yan Dai
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Oct 31 23:01:18 UTC 2008 Yan Dai
,,0.0686,OpenDDS,Fri Oct 31 23:01:18 UTC 2008 Yan Dai
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Mon Jan 5 20:45:31 UTC 2009 Yan Dai
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez Jan 5 20:45:31 UTC 2009 Yan Dai
,,0.0686,OpenDDS,Mon Jan 5 20:45:31 UTC 2009 Yan Dai
,,0.0686,OpenDDS,Mon Jan 5 20:45:31 UTC 2009 Yan Dai
,,0.0686,OpenDDS,Mon Jan 5 20:45:31 UTC 2009 Yan Dai
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0664,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0664,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Fri Jan 9 02:33:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Mon Jan 5 20:45:31 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Wed Jan 21 04:48:42 UTC 2009 Mike Martinez Jan 5 20:45:31 UTC 2009 Yan Dai
,,0.0686,OpenDDS,Mon Jan 5 20:45:31 UTC 2009 Yan Dai
,,0.0686,OpenDDS,Mon Jan 5 20:45:31 UTC 2009 Yan Dai
,,0.0686,OpenDDS,Fri Jan 9 21:22:52 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Mon Jan 5 20:45:31 UTC 2009 Yan Dai
,,0.0686,OpenDDS,Mon Jan 5 20:45:31 UTC 2009 Yan Dai
,,0.0686,OpenDDS,Mon Jan 5 20:45:31 UTC 2009 Yan Dai
,,0.0686,OpenDDS,Fri Jan 16 04:14:06 UTC 2009 Mike Martinez
,,0.0673,OpenDDS,Wed Jan 28 22:57:01 UTC 2009 Mike Martinez Jan 21 04:48:42 UTC 2009 Mike Martinez Jan 16 04:14:06 UTC 2009 Mike Martinez Jan 9 21:22:52 UTC 2009 Mike Martinez Jan 9 17:08:42 UTC 2009 Mike Martinez Jan 9 02:33:13 UTC 2009 Mike Martinez Jan 5 20:45:31 UTC 2009 Yan Dai Fri Dec 5 23:23:24 UTC 2008 Adam Mitz
,,0.0686,OpenDDS,Mon Jan 5 20:45:31 UTC 2009 Yan Dai
,,0.0686,OpenDDS,Wed Jan 21 21:39:50 UTC 2009 Yan Dai
,,0.0673,OpenDDS,Fri Jan 16 04:14:06 UTC 2009 Mike Martinez Jan 5 20:45:31 UTC 2009 Yan Dai Fri Dec 5 23:23:24 UTC 2008 Adam Mitz
,,0.0673,OpenDDS,Wed Apr 8 15:42:27 UTC 2009 Mike Martinez Apr 8 01:30:15 UTC 2009 Mike Martinez Apr 1 22:21:56 UTC 2009 Mike Martinez Apr 1 02:18:37 UTC 2009 Mike Martinez Mar 13 20:19:27 UTC 2009 Steven Stallion
,,0.1466,OpenDDS,Wed Apr 8 01:30:15 UTC 2009 Mike Martinez Apr 6 21:23:22 UTC 2009 Mike Martinez Apr 2 21:16:18 UTC 2009 Mike Martinez Mar 13 20:19:27 UTC 2009 Steven Stallion Mar 12 18:45:08 UTC 2009 Mike Martinez Feb 25 00:35:07 UTC 2009 Steven Stallion Feb 25 00:29:33 UTC 2009 Mike Martinez Feb 16 22:16:27 UTC 2009 Mike Martinez Feb 6 15:47:29 UTC 2009 Mike Martinez Jan 30 23:28:13 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Wed Apr 1 02:18:37 UTC 2009 Mike Martinez
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Sep 3 16:22:45 UTC 2009 Yan Dai
,,0.1019,OpenDDS,Thu Sep 3 16:22:45 UTC 2009 Yan Dai Jul 9 17:47:10 UTC 2009 Yan Dai Wed Jun 17 20:44:46 UTC 2009 Adam Mitz
,,0.0686,OpenDDS,Tue Aug 25 21:38:02 UTC 2009 Yan Dai Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.066,OpenDDS,Tue Aug 4 02:46:26 UTC 2009 Yan Dai Aug 3 19:18:22 UTC 2009 Steven Stallion Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0673,OpenDDS,Tue Aug 25 21:38:02 UTC 2009 Yan Dai Wed Jun 17 20:44:46 UTC 2009 Adam Mitz
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0686,OpenDDS,Tue Aug 25 23:14:53 UTC 2009 Steven Stallion Aug 14 22:54:02 UTC 2009 Steven Stallion Aug 13 04:41:21 UTC 2009 Yan Dai
,,0.0833,OpenDDS,Mon Jul 13 20:41:41 UTC 2009 Yan Dai Jul 9 22:17:52 UTC 2009 Yan Dai Fri Jun 12 21:36:18 UTC 2009 Adam Mitz
,,0.0865,OpenDDS,Thu Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.0686,OpenDDS,Thu Jul 30 23:24:42 UTC 2009 Yan Dai Jul 30 02:08:33 UTC 2009 Yan Dai
,,0.066,OpenDDS,Tue Aug 25 21:38:02 UTC 2009 Yan Dai Aug 13 22:17:02 UTC 2009 Steven Stallion
,,0.066,OpenDDS,Tue Aug 11 04:42:34 UTC 2009 Yan Dai Aug 5 17:15:08 UTC 2009 Steven Stallion
,,0.0686,OpenDDS,Mon Aug 24 15:55:16 UTC 2009 Mike Martinez
,,0.0686,OpenDDS,Mon Aug 24 15:55:16 UTC 2009 Mike Martinez
,,0.0865,OpenDDS,Fri Sep 11 18:30:53 UTC 2009 Yan Dai
,,0.0673,OpenDDS,Tue Sep 8 19:05:55 UTC 2009 Steven Stallion
,,0.0686,OpenDDS,Mon Nov 23 14:28:01 UTC 2009 Paul Calabrese
,,0.0686,OpenDDS,Mon Nov 23 14:28:01 UTC 2009 Paul Calabrese
,,0.0686,OpenDDS,Mon Nov 23 14:28:01 UTC 2009 Paul Calabrese
,,0.0686,OpenDDS,Mon Nov 23 14:28:01 UTC 2009 Paul Calabrese
,,0.0686,OpenDDS,Mon Nov 23 14:28:01 UTC 2009 Paul Calabrese
,,0.0686,OpenDDS,Mon Jan 4 22:51:20 UTC 2010 Yan Dai
,,0.0648,OpenDDS,Wed Jan 27 23:37:53 UTC 2010 Steven Stallion Jan 19 22:22:48 UTC 2010 Steven Stallion
,,0.066,OpenDDS,Wed Jan 27 23:37:53 UTC 2010 Steven Stallion Dec 10 22:45:18 UTC 2009 Steven Stallion
,,0.066,OpenDDS,Wed Jan 20 22:07:26 UTC 2010 Steven Stallion Dec 10 23:16:19 UTC 2009 Steven Stallion
,,0.0686,OpenDDS,Thu Mar 11 23:54:38 UTC 2010 Yan Dai
,,0.0823,OpenDDS,Sat May 1 17:34:52 UTC 2010 Yan Dai Apr 9 18:11:38 UTC 2010 Yan Dai
,,0.0673,OpenDDS,Mon May 24 18:54:38 UTC 2010 Mike Martinez Tue Apr 27 16:22:44 UTC 2010 Adam Mitz Mar 19 21:23:54 UTC 2010 Yan Dai
,,0.0686,OpenDDS,Mon Mar 22 19:53:59 UTC 2010 Yan Dai
,,0.0686,OpenDDS,Mon Mar 22 19:53:59 UTC 2010 Yan Dai
,,0.0686,OpenDDS,Fri Apr 9 18:11:38 UTC 2010 Yan Dai
,,0.066,OpenDDS,Mon May 24 18:54:38 UTC 2010 Mike Martinez May 13 05:51:44 UTC 2010 Yan Dai Tue Apr 27 16:22:44 UTC 2010 Adam Mitz Apr 9 18:11:38 UTC 2010 Yan Dai Mar 11 23:54:38 UTC 2010 Yan Dai
,,0.0686,OpenDDS,Mon Jun 14 04:26:23 UTC 2010 Yan Dai
,,0.0849,OpenDDS,Fri Aug 6 21:14:26 UTC 2010 Yan Dai
,,0.0865,OpenDDS,Mon Aug 9 17:46:13 UTC 2010 Yan Dai Aug 6 21:14:26 UTC 2010 Yan Dai
,,0.0849,OpenDDS,Fri Aug 6 21:14:26 UTC 2010 Yan Dai
,,0.0865,OpenDDS,Mon Aug 9 17:46:13 UTC 2010 Yan Dai Aug 6 21:14:26 UTC 2010 Yan Dai
,,0.0849,OpenDDS,Fri Aug 6 21:14:26 UTC 2010 Yan Dai
,,0.0686,OpenDDS,Wed Aug 4 16:45:10 UTC 2010 Yan Dai
,,0.0686,OpenDDS,Wed Aug 4 16:45:10 UTC 2010 Yan Dai
,,0.0686,OpenDDS,Wed Aug 4 16:45:10 UTC 2010 Yan Dai
,,0.0686,OpenDDS,Fri Jun 18 22:42:30 UTC 2010 Yan Dai
,,0.0686,OpenDDS,Fri Jun 18 22:42:30 UTC 2010 Yan Dai
,,0.0833,OpenDDS,Fri Jun 18 22:42:30 UTC 2010 Yan Dai Fri Jun 18 20:23:40 UTC 2010 Adam Mitz
,,0.0686,OpenDDS,Fri Jun 18 22:42:30 UTC 2010 Yan Dai
,,0.0686,OpenDDS,Fri Jun 18 22:42:30 UTC 2010 Yan Dai
,,0.0686,OpenDDS,Fri Jun 18 22:42:30 UTC 2010 Yan Dai
,,0.0686,OpenDDS,Wed Aug 4 16:45:10 UTC 2010 Yan Dai
,,0.0686,OpenDDS,Wed Aug 4 16:45:10 UTC 2010 Yan Dai
,,0.0673,OpenDDS,Wed Aug 4 16:45:10 UTC 2010 Yan Dai Jul 14 20:56:38 UTC 2010 Brian Johnson Fri Jun 18 20:23:40 UTC 2010 Adam Mitz
,,0.2005,OpenDDS,Tue Nov 2 18:29:27 UTC 2010 Don Hudson Made minor tweaks to formatting of error and debug messages for consistency and readability. Corrected a few incorrect method names in error and debug messages. Corrected a few spelling errors./
,,0.1884,OpenDDS,Tue Nov 2 18:29:27 UTC 2010 Don Hudson Made minor tweaks to formatting of error and debug messages for consistency and readability. Corrected a few incorrect method names in error and debug messages. Corrected a few spelling errors./
,,0.1849,OpenDDS,Tue Nov 2 18:29:27 UTC 2010 Don Hudson Made minor tweaks to formatting of error and debug messages for consistency and readability. Corrected a few incorrect method names in error and debug messages. Corrected a few spelling errors./
,,0.2163,OpenDDS,Tue Nov 2 18:29:27 UTC 2010 Don Hudson Made minor tweaks to formatting of error and debug messages for consistency and readability. Corrected a few incorrect method names in error and debug messages. Corrected a few spelling errors./Thu Sep 16 00:13:51 UTC 2010 Yan Dai
,,0.1849,OpenDDS,Thu Nov 4 19:11:05 UTC 2010 Don Hudson Nov 2 18:29:27 UTC 2010 Don Hudson Made minor tweaks to formatting of error and debug messages for consistency and readability. Corrected a few incorrect method names in error and debug messages. Corrected a few spelling errors./
,,0.0686,OpenDDS,Wed Apr 27 18:21:08 UTC 2011 Paul Calabrese
,,0.0686,OpenDDS,Fri Apr 15 15:23:13 UTC 2011 Paul Calabrese
,,0.0686,OpenDDS,Wed Apr 27 18:21:08 UTC 2011 Paul Calabrese
,,0.0686,OpenDDS,Fri Apr 15 15:23:13 UTC 2011 Paul Calabrese
,,0.0833,OpenDDS,Thu Aug 18 22:25:59 UTC 2011 Trevor Fields Reverting Thu Aug 18 21:59:26 UTC 2011 Trevor Fields
,,0.0686,OpenDDS,Mon Jul 18 13:35:36 UTC 2011 Paul Calabrese
,,0.0673,OpenDDS,Fri Jul 15 16:43:42 UTC 2011 Paul Calabrese
,,0.0673,OpenDDS,Fri Jul 15 16:43:42 UTC 2011 Paul Calabrese
,,0.0673,OpenDDS,Fri Jul 15 16:43:42 UTC 2011 Paul Calabrese
,,0.0673,OpenDDS,Fri Jul 15 16:43:42 UTC 2011 Paul Calabrese
,,0.0686,OpenDDS,Wed Jun 15 15:33:47 UTC 2011 Paul Calabrese
,,0.0673,OpenDDS,Tue Aug 2 21:19:07 UTC 2011 Paul Calabrese Jul 2 04:34:29 UTC 2011 Paul Calabrese
,,0.0673,OpenDDS,ChangeLogTag: Thu Sep 29 22:22:00 UTC 2011 Adam Mitz Tue Sep 13 17:56:55 UTC 2011 Adam Mitz
,,0.0673,OpenDDS,ChangeLogTag: Thu Sep 29 22:22:00 UTC 2011 Adam Mitz Tue Sep 13 17:56:55 UTC 2011 Adam Mitz
,,0.0849,OpenDDS,Wed Nov 30 17:07:58 UTC 2011 Jeff Schmitz Nov 29 20:58:57 UTC 2011 Jeff Schmitz
,,0.0686,OpenDDS,Fri Oct 14 14:23:44 UTC 2011 Paul Calabrese
,,0.0686,OpenDDS,ChangeLogTag: Fri Mar 2 21:18:21 UTC 2012 Brian Johnson
,,0.0686,OpenDDS,Fri Mar 9 14:37:49 UTC 2012 Paul Calabrese
,,0.0664,OpenDDS,ChangeLogTag: Tue Mar 6 14:34:37 UTC 2012 Brian Johnson
,,0.0664,OpenDDS,Fri Mar 9 14:37:49 UTC 2012 Paul Calabrese
,,0.0686,OpenDDS,Fri Mar 9 14:37:49 UTC 2012 Paul Calabrese
,,0.0673,OpenDDS,ChangeLogTag: Wed Feb 15 17:29:45 UTC 2012 Brian Johnson Wed Feb 8 21:21:24 UTC 2012 Brian Johnson
,,0.0686,OpenDDS,Fri Mar 9 14:37:49 UTC 2012 Paul Calabrese
,,0.0686,OpenDDS,Fri Mar 9 14:37:49 UTC 2012 Paul Calabrese
,,0.0686,OpenDDS,Fri Mar 9 14:37:49 UTC 2012 Paul Calabrese
,,0.0865,OpenDDS,ChangeLogTag: Thu Jan 5 16:52:57 UTC 2012 Brian Johnson Wed Jan 4 18:57:25 UTC 2012 Brian Johnson
,,0.0765,OpenDDS,ChangeLogTag: Mon Jan 30 16:56:02 UTC 2012 Adam Mitz Wed Jan 11 20:06:14 UTC 2012 Brian Johnson
,,0.0686,OpenDDS,Fri Mar 9 14:37:49 UTC 2012 Paul Calabrese
,,0.1308,OpenDDS,ChangeLogTag: Fri Mar 9 23:19:06 UTC 2012 Adam Mitz for durability support in RTPS transport/ChangeLogTag: Fri Mar 2 21:18:21 UTC 2012 Brian Johnson Thu Mar 1 19:06:33 UTC 2012 Adam Mitz Fri Feb 10 17:53:13 UTC 2012 Adam Mitz Jan 27 17:48:31 UTC 2012 Jeff Schmitz Jan 25 20:05:51 UTC 2012 Jeff Schmitz Mon Jan 23 18:57:27 UTC 2012 Adam Mitz Jan 19 16:45:53 UTC 2012 Jeff Schmitz Thu Jan 19 16:11:04 UTC 2012 Adam Mitz Thu Jan 19 15:48:59 UTC 2012 Adam Mitz Jan 18 20:55:52 UTC 2012 Jeff Schmitz Dec 12 21:16:25 UTC 2011 Jeff Schmitz
,,0.0686,OpenDDS,ChangeLogTag: Thu Apr 12 16:17:39 UTC 2012 Brian Johnson
,,0.0686,OpenDDS,Tue Jun 5 16:04:37 UTC 2012 Byron Harris Mon Apr 23 21:23:34 UTC 2012 Brian Johnson Thu Apr 12 16:17:39 UTC 2012 Brian Johnson
,,0.0686,OpenDDS,ChangeLogTag: Thu Apr 12 16:17:39 UTC 2012 Brian Johnson
,,0.0686,OpenDDS,Wed May 9 20:16:05 UTC 2012 Paul Calabrese
,,0.0686,OpenDDS,ChangeLogTag: Thu Apr 12 16:17:39 UTC 2012 Brian Johnson
,,0.0673,OpenDDS,Wed May 9 20:16:05 UTC 2012 Paul Calabrese Thu Mar 29 20:42:00 UTC 2012 Adam Mitz
,,0.0686,OpenDDS,Wed May 9 20:16:05 UTC 2012 Paul Calabrese
,,0.0686,OpenDDS,Wed May 9 20:16:05 UTC 2012 Paul Calabrese
,,0.0686,OpenDDS,Wed May 9 20:16:05 UTC 2012 Paul Calabrese
,,0.0686,OpenDDS,ChangeLogTag: Fri Apr 6 13:11:11 UTC 2012 Brian Johnson
,,0.0673,OpenDDS,ChangeLogTag: Mon Apr 16 15:52:13 UTC 2012 Brian Johnson
,,0.1843,OpenDDS,ChangeLogTag:Thu Jun 7 19:21:57 UTC 2012 Trevor Fields May 30 19:46:19 UTC 2012 Byron Harris May 29 20:07:51 UTC 2012 Byron Harris Apr 30 20:15:35 UTC 2012 Byron Harris Thu Apr 19 14:49:43 UTC 2012 Brian Johnson Mon Apr 16 15:52:13 UTC 2012 Brian Johnson work in progress on moving the ORB to the inforepodiscovery library/ChangeLogTag: Thu Apr 12 16:17:39 UTC 2012 Brian Johnson DCPS_debug_level used for every received sample/
,,0.0686,OpenDDS,ChangeLogTag: Thu Apr 12 16:17:39 UTC 2012 Brian Johnson
,,0.1204,OpenDDS,ChangeLogTag:Thu Jun 7 19:21:57 UTC 2012 Trevor Fields May 30 19:46:19 UTC 2012 Byron Harris Mon Apr 23 21:23:34 UTC 2012 Brian Johnson Mon Apr 16 15:52:13 UTC 2012 Brian Johnson Thu Apr 12 16:17:39 UTC 2012 Brian Johnson
,,0.0673,OpenDDS,ChangeLogTag: Mon Apr 16 15:52:13 UTC 2012 Brian Johnson
,,0.1222,OpenDDS,ChangeLogTag: Fri Jun 8 17:03:06 UTC 2012 Trevor Fields Jun 7 19:21:57 UTC 2012 Trevor Fields May 30 19:46:19 UTC 2012 Byron Harris Mon Apr 23 21:23:34 UTC 2012 Brian Johnson Mon Apr 16 15:52:13 UTC 2012 Brian Johnson work in progress on moving the ORB to the inforepodiscovery library/ChangeLogTag: Thu Apr 12 16:17:39 UTC 2012 Brian Johnson
,,0.0686,OpenDDS,Fri Jun 29 21:02:12 UTC 2012 Byron Harris Jun 19 16:02:10 UTC 2012 Byron Harris
,,0.0686,OpenDDS,Fri Jun 29 17:04:21 UTC 2012 Paul Calabrese
,,0.0673,OpenDDS,Wed Aug 15 16:40:00 UTC 2012 Paul Calabrese Fri Aug 10 21:08:28 UTC 2012 Adam Mitz
,,0.0686,OpenDDS,Fri Jun 29 17:04:21 UTC 2012 Paul Calabrese
,,0.066,OpenDDS,Wed Jun 27 17:42:36 UTC 2012 Paul Calabrese Tue Jun 12 21:32:52 UTC 2012 Adam Mitz
,,0.0686,OpenDDS,Fri Jun 29 17:04:21 UTC 2012 Paul Calabrese
,,0.0686,OpenDDS,Tue Jun 12 20:20:59 UTC 2012 Byron Harris Jun 12 15:21:29 UTC 2012 Byron Harris
,,0.0686,OpenDDS,Tue Sep 18 20:48:55 UTC 2012 Huang-Ming Huang
,,0.0686,OpenDDS,Fri Jun 7 18:14:52 UTC 2013 Mike Martinez
,,0.0686,OpenDDS,Tue Jun 18 20:23:16 UTC 2013 Mike Martinez Jun 14 22:57:38 UTC 2013 Mike Martinez
,,0.1161,OpenDDS,work in progress on async associations/Mon Aug 19 10:26:32 UTC 2013 Mike Martinez Aug 16 02:25:15 UTC 2013 Mike Martinez Aug 1 23:08:51 UTC 2013 Mike Martinez Aug 1 22:13:39 UTC 2013 Mike Martinez
,,0.0865,OpenDDS,Mon Jun 17 22:13:36 UTC 2013 Mike Martinez Jun 17 16:28:08 UTC 2013 Mike Martinez Jun 14 22:57:38 UTC 2013 Mike Martinez
,,0.0686,OpenDDS,Fri Jun 14 22:57:38 UTC 2013 Mike Martinez
,,0.0686,OpenDDS,Tue Jun 18 20:23:16 UTC 2013 Mike Martinez Jun 17 15:40:44 UTC 2013 Mike Martinez
,,0.0686,OpenDDS,Wed Nov 13 22:07:19 UTC 2013 Mike Martinez
,,0.0865,OpenDDS,Wed Jan 8 02:59:39 UTC 2014 Mike Martinez
,,0.0686,OpenDDS,Fri Dec 20 00:25:35 UTC 2013 Mike Martinez
,,0.0686,OpenDDS,Fri Dec 20 00:25:35 UTC 2013 Mike Martinez
,,0.0865,OpenDDS,Wed Jan 8 02:59:39 UTC 2014 Mike Martinez
,,0.0686,OpenDDS,ChangeLogTag: Sat May 17 19:30:21 UTC 2014 Brian Johnson
,,0.0673,OpenDDS,ChangeLogTag: Wed Apr 30 19:35:16 UTC 2014 Jeff Schmitz
,,0.0686,OpenDDS,ChangeLogTag: Tue Apr 22 15:27:09 UTC 2014 Jeff Schmitz
,,0.0686,OpenDDS,ChangeLogTag: Fri Apr 11 17:28:21 UTC 2014 Brian Johnson
,,0.0865,OpenDDS,ChangeLogTag: Thu Apr 17 16:53:23 UTC 2014 Brian Johnson Tue Apr 15 20:57:02 UTC 2014 Brian Johnson Fri Apr 11 17:28:21 UTC 2014 Brian Johnson
,,0.0686,OpenDDS,ChangeLogTag: Thu Apr 24 18:32:40 UTC 2014 Brian Johnson
,,0.0673,OpenDDS,ChangeLogTag: Mon Apr 14 19:17:26 UTC 2014 Jeff Schmitz
,,0.0673,OpenDDS,ChangeLogTag: Wed Jun 25 16:06:59 UTC 2014 Brian Johnson
,,0.0673,OpenDDS,ChangeLogTag: Wed Jun 4 16:50:22 UTC 2014 Brian Johnson
,,0.0686,OpenDDS,ChangeLogTag: Mon Sep 29 18:21:52 UTC 2014 Jeff Schmitz
,,0.0686,OpenDDS,ChangeLogTag: Mon Sep 29 18:21:52 UTC 2014 Jeff Schmitz
,,0.0673,OpenDDS,ChangeLogTag: Thu Sep 18 18:49:53 UTC 2014 Jeff Schmitz Wed Sep 17 19:06:39 UTC 2014 Jeff Schmitz
,,0.0686,OpenDDS,ChangeLogTag: Fri Aug 8 22:23:33 UTC 2014 Jeff Schmitz
,,0.0686,OpenDDS,ChangeLogTag: Thu Sep 18 22:00:16 UTC 2014 Jeff Schmitz
,,0.0849,OpenDDS,ChangeLogTag: Wed Jul 9 17:59:26 UTC 2014 Brian Johnson Tue Jul 1 17:50:00 UTC 2014 Brian Johnson
,,0.0686,OpenDDS,ChangeLogTag: Tue Oct 7 17:49:08 UTC 2014 Jeff Schmitz
,,0.0686,OpenDDS,ChangeLogTag: Tue Nov 11 19:03:42 UTC 2014 Jeff Schmitz
,,0.0686,OpenDDS,ChangeLogTag: Tue Nov 11 19:03:42 UTC 2014 Jeff Schmitz
,,0.0686,OpenDDS,ChangeLogTag: Thu Oct 30 17:25:46 UTC 2014 Jeff Schmitz
,,0.0686,OpenDDS,ChangeLogTag: Thu Oct 30 17:25:46 UTC 2014 Jeff Schmitz
,,0.0673,OpenDDS,Wed Dec 17 15:59:19 UTC 2014 Paul Calabrese Nov 20 18:20:01 UTC 2014 Paul Calabrese
,,0.0686,OpenDDS,Thu Nov 13 17:59:51 UTC 2014 Paul Calabrese
,,0.0673,OpenDDS,BranchChangeLogTag: Fri Jan 16 20:53:39 UTC 2015 Jeff Schmitz Wed Jan 7 15:54:48 UTC 2015 Jeff Schmitz Tue Jan 6 22:17:58 UTC 2015 Jeff Schmitz
,,0.078,OpenDDS,Use ctime_r instead of ctime for safety profile. Manually translate localhost to 127.0.0.1./Updates to build entire tree on LynxOS-178 static w/ safety profile./
,,0.0636,OpenDDS,Use ctime_r instead of ctime for safety profile. Manually translate localhost to 127.0.0.1./
,,0.0959,OpenDDS,Refactoring to provide easier common conversions to OPENDDS_STRING for logging in Safety Profile builds/convert int to string/Removing use of streams for Safety Profile compliance/
,,0.0689,OpenDDS,Removing use of streams for Safety Profile compliance/
,,0.0686,OpenDDS,More clang warnings/
,,0.0664,OpenDDS,More clang warnings/
,,0.1138,OpenDDS,Update safety profile logging Removed the default safetyprofile.log. Tests enabled in safety profile must use the test framework whichw will supply and translate a log file name./
,,0.1174,OpenDDS,Update safety profile logging Removed the default safetyprofile.log. Tests enabled in safety profile must use the test framework whichw will supply and translate a log file name./
,,0.0795,OpenDDS,ManualAssertLiveliness test: need to track liveliness lost callbacks more accurately remove much duplicated code/
,,0.071,OpenDDS,Dispose could cause error Unable to take sample/
,,0.0673,OpenDDS,Fix SubscriptionInstance/PublicationInstance being accessed by watchdogs after deletion/
,,0.0673,OpenDDS,Fix SubscriptionInstance/PublicationInstance being accessed by watchdogs after deletion/
,,0.0673,OpenDDS,Fix SubscriptionInstance/PublicationInstance being accessed by watchdogs after deletion/
,,0.1161,OpenDDS,"Fix Liveliness Qos bug where the liveliness check interval timer is not reset/adjusted to account for liveliness activity occurring during a partial interval, and thus liveliness was lost earlier than it should have been. Remove unnecessary last_liveliness_check_time as well as initial delta calculation/check/reschedule as it is taken care of by second check and should not be occurring at all since the reactor should handle the timer properly./minor cleanup and style guide changes from PR DataWriterImpl accessed after deletion bug/"
,,0.0648,OpenDDS,Fix IPv6 address text representation problem/
,,0.0763,OpenDDS,Addressing Coverity Scan Report Defects: Untrusted loop bound due to tainted data./
,,0.0648,OpenDDS,Addressing Coverity Scan reported defect of uninitialized members./
,,0.0697,OpenDDS,Addressing Coverity Scan reported defect of not restoring ostream format./
,,0.0763,OpenDDS,Addressing Coverity Scan Report Defects: Untrusted loop bound due to tainted data./
,,0.0744,OpenDDS,Addressing Coverity Scan Report Defects: Untrusted loop bound due to tainted data./
,,0.0782,OpenDDS,Build new code in Safety Profile / Use OPENDDS_SECURITY to reduce what needs to be compiled when security is not in use/Spdp/Sedp: simplify namespace usage; new helper for send_builtin_crypto_tokens/
,,0.0609,OpenDDS,Spdp/Sedp: simplify namespace usage; new helper for send_builtin_crypto_tokens/
,,0.092,OpenDDS,Build new code in Safety Profile / Use OPENDDS_SECURITY to reduce what needs to be compiled when security is not in use/Spdp/Sedp: cppcheck cleanup/Spdp/Sedp: simplify namespace usage; new helper for send_builtin_crypto_tokens/
,,0.0697,OpenDDS,Build new code in Safety Profile / Use OPENDDS_SECURITY to reduce what needs to be compiled when security is not in use/
,,0.063,OpenDDS,Make other changes from PR/
,,0.1518,OpenDDS,Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.1518,OpenDDS,Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.1518,OpenDDS,Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.1791,OpenDDS,Make TimePoint_T cstr More Similar to time_point/Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.0648,OpenDDS,Topic Annotation Migration Guide/
,,0.4015,OpenDDS,"Fix Coverity issues/Fix Out of Order Declaration, Simplify/Modified code per code review suggestions/Modified GuidGenerator and added sequence reset GuidGenerator Code was modified to add a random generated number to the counter value. The counter value will increment from the initial random generated number. Added RTPSDiscovery configuration value MaxSpdpSequenceMsgResetChecks. This value is the number of sequence numbers that must be received that are less than the initial last sequence number value before a discovered participant is removed. Added Spdp code changes to check for a sequence number reset. A reset occurs when a defined number of sequence numbers are received that are less than than an initial last sequence value. On a reset the discovered participant will be removed and rediscovered./Make TimePoint_T cstr More Similar to time_point/Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./"
,,0.1518,OpenDDS,Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.18100000000000002,OpenDDS,Make TimePoint_T cstr More Similar to time_point/Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.1518,OpenDDS,Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.2772,OpenDDS,"Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./updating datalink to use reactor interceptor for immediate calling of on_start_callbacks with pending association notifications, updating tcp transport for bi-directional assocation messages and async association for RTPS discovery, minor updates to other transports/"
,,0.1791,OpenDDS,Make TimePoint_T cstr More Similar to time_point/Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.285,OpenDDS,"Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./ReactorInterceptor wait is broken To support a straight enqueue while processing commands in the ReactorInterceptor, it was necessary to release the queue lock before each command was executed. This broke the existing semantics of wait because the following sequence was possible: Non-reactor thread: execute_or_enqueue (command is placed on the queue) Reactor thread: command is take off the queue but not executed yet Non-reactor thread: wait (returns immediately since the queue is empty) ... wait returned without the command being executed ... Solution: enqueue and execute_or_enqueue return a Command with a wait method. A thread can use this wait on a specify command to complete. The ReactorInterceptor signals the Command to unblock any waiting thread./fixing implicit ACE_Time_Value stuff, removing TimedDelay mutex / guards (not needed, as reactor thread is always only involved), resolving PR comments/adding quick replies for initial heartbeats by changing TimedDelay::schedule to allow input timeout different from constructed timeout/"
,,0.0577,OpenDDS,resolving PR 1263 comments/
,,0.2898,OpenDDS,"attempting to fix thrasher test post-assoc data / heartbeat race condition by storing assoc hb.last as start of nackable range for non-durable readers/attempt to get Thrasher tests working for RTPS/Fixing deadlock race condition from user thread sends, adding thread safety to single send buffer/Make TimePoint_T cstr More Similar to time_point/Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./resolving PR comments/Fix RtpsUdpDataLink.cpp/removing RtpsWriter locking around MultiSendBuffer to prevent deadlocking/Merge remote-tracking branch upstream/master into igtd/monotonic/Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./fixing implicit ACE_Time_Value stuff, removing TimedDelay mutex / guards (not needed, as reactor thread is always only involved), resolving PR comments/adding quick replies for initial heartbeats by changing TimedDelay::schedule to allow input timeout different from constructed timeout/"
,,0.2529,OpenDDS,"resolving pr comments, adding RcHandle to commands to prevent destruction while active, giving transport RcHandle to ReconnectTask (while active) in order to prevent task from self-destruction/explicitly call shutdown on connections during transport shutdown, wait for connection task to end during shutdown/Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./"
,,0.2365,OpenDDS,"Merge remote-tracking branch origin/master into reinstate_tcp_reconnect_task/resolving PR comments, fixing valgrind issue/resolving pr comments, adding RcHandle to commands to prevent destruction while active, giving transport RcHandle to ReconnectTask (while active) in order to prevent task from self-destruction/updating TcpReconnectTask to protect TcpTransport / Reactor during reconnect actions, updating TcpConnection to use ReactorInterceptor/migrating TcpReconnectTask to use ACE_Task_Base, removing TcpConnection spawn thread + ref-counting in favor of TcpTransport_rch & TcpReconnectTask members/Fixes after Review/updating tcp reconnect thread to contain rchandle to receive strategy object, since thats where the actual reactor for this svc_handler lives/Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./"
,,0.235,OpenDDS,"Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./"
,,0.1518,OpenDDS,Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.2402,OpenDDS,"Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./"
,,0.1518,OpenDDS,Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.3255,OpenDDS,"Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./InstanceState: use the ReactorInterceptor to mediate threading with the ACE Recator made the InstanceState an RcObject and cleaned up its uses in OpenDDS_Dcps/"
,,0.1518,OpenDDS,Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.3386,OpenDDS,"Make TimePoint_T cstr More Similar to time_point/Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./"
,,0.18100000000000002,OpenDDS,Make TimePoint_T cstr More Similar to time_point/Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.2997,OpenDDS,"Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./"
,,0.3161,OpenDDS,"Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./ReactorInterceptor wait is broken To support a straight enqueue while processing commands in the ReactorInterceptor, it was necessary to release the queue lock before each command was executed. This broke the existing semantics of wait because the following sequence was possible: Non-reactor thread: execute_or_enqueue (command is placed on the queue) Reactor thread: command is take off the queue but not executed yet Non-reactor thread: wait (returns immediately since the queue is empty) ... wait returned without the command being executed ... Solution: enqueue and execute_or_enqueue return a Command with a wait method. A thread can use this wait on a specify command to complete. The ReactorInterceptor signals the Command to unblock any waiting thread./Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./"
,,0.1518,OpenDDS,Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.3705,OpenDDS,"Allow RtpsRelay and Stun addresses to be changed on the fly/RtpsRelay: Implement rapid association (#1317) * Implement rapid association * Install the RtpsRelay library * Fixes from review * Fix whitespace * Fix control flow * Fix Coverity/Modified to meet coding standards/Modified GuidGenerator and added sequence reset GuidGenerator Code was modified to add a random generated number to the counter value. The counter value will increment from the initial random generated number. Added RTPSDiscovery configuration value MaxSpdpSequenceMsgResetChecks. This value is the number of sequence numbers that must be received that are less than the initial last sequence number value before a discovered participant is removed. Added Spdp code changes to check for a sequence number reset. A reset occurs when a defined number of sequence numbers are received that are less than than an initial last sequence value. On a reset the discovered participant will be removed and rediscovered./Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./"
,,0.2848,OpenDDS,RtpsRelay: Implement rapid association (#1317) * Implement rapid association * Install the RtpsRelay library * Fixes from review * Fix whitespace * Fix control flow * Fix Coverity/Response to Review 2: The Sequel/Response to Review/Respond to Review/Modified GuidGenerator and added sequence reset GuidGenerator Code was modified to add a random generated number to the counter value. The counter value will increment from the initial random generated number. Added RTPSDiscovery configuration value MaxSpdpSequenceMsgResetChecks. This value is the number of sequence numbers that must be received that are less than the initial last sequence number value before a discovered participant is removed. Added Spdp code changes to check for a sequence number reset. A reset occurs when a defined number of sequence numbers are received that are less than than an initial last sequence value. On a reset the discovered participant will be removed and rediscovered./moving Sedp::Writer call of association_complete to enqueued ReactorInterceptor call to avoid deadlock/
,,0.2903,OpenDDS,RtpsRelay: Implement rapid association (#1317) * Implement rapid association * Install the RtpsRelay library * Fixes from review * Fix whitespace * Fix control flow * Fix Coverity/Respond to Review/Modified GuidGenerator and added sequence reset GuidGenerator Code was modified to add a random generated number to the counter value. The counter value will increment from the initial random generated number. Added RTPSDiscovery configuration value MaxSpdpSequenceMsgResetChecks. This value is the number of sequence numbers that must be received that are less than the initial last sequence number value before a discovered participant is removed. Added Spdp code changes to check for a sequence number reset. A reset occurs when a defined number of sequence numbers are received that are less than than an initial last sequence value. On a reset the discovered participant will be removed and rediscovered./
,,0.2753,OpenDDS,"Make TimePoint_T cstr More Similar to time_point/Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./"
,,0.2961,OpenDDS,"Make TimePoint_T cstr More Similar to time_point/Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./ReactorInterceptor wait is broken To support a straight enqueue while processing commands in the ReactorInterceptor, it was necessary to release the queue lock before each command was executed. This broke the existing semantics of wait because the following sequence was possible: Non-reactor thread: execute_or_enqueue (command is placed on the queue) Reactor thread: command is take off the queue but not executed yet Non-reactor thread: wait (returns immediately since the queue is empty) ... wait returned without the command being executed ... Solution: enqueue and execute_or_enqueue return a Command with a wait method. A thread can use this wait on a specify command to complete. The ReactorInterceptor signals the Command to unblock any waiting thread./"
,,0.0849,OpenDDS,Make TimePoint_T cstr More Similar to time_point/
,,0.1425,OpenDDS,Disable builtin SEDP writers/Use BIT for RtpsRelay routing (#1286) Use BIT for routing in RtpsRelay/Response to Review 2: The Sequel/moving Sedp::Writer call of association_complete to enqueued ReactorInterceptor call to avoid deadlock/Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.3046,OpenDDS,"SPDP improvements for the RtpsRelay * Add INFO_DST to SPDP messages that are sent in response to discovered a new participant. This allows the RtpsRelay to only forward the SPDP message to the intended destination. * Both SPDP and RTPS transports send a beacon to the RtpsRelay. The period of the beacon is configurable. The beacon is sent unconditionally. * Polling was converted to events in SPDP to handle authentication timeouts and resends. * Three helper classes: * JobQueue allows a thread to post a job on a Reactor. * PeriodicTask a wrapper for periodic tasks. * SporadicTask a wrapper for sporadic (one-shot) tasks. * ReactorTask has an implicit ReactorInterceptor. As an aside, the JobQueue was motivated by a deadlock where a ReactorInterceptor command acquired a lock so that a subsequenct execute_or_enqueue was not safe because the same lock was already held. This suggests that there are probably other situations where ReactorInterceptor commands are acquiring locks which may result in the same problem. I recommend the following: 1. Dont use the ReactorInterceptor as a general-purpose job queue. Use JobQueue. 2. Limit ReactorInterceptor commands to dealing with the reactor and perhaps a small number of control variables. Furthermore, all state updates should be performed by ReactorInterceptor commands. This implicitly provides atomicity. PeriodicTask and SporadicTask are examples of this. 3. Avoid waiting for ReactorInterceptor commands. Specifically, it is common to wait for a timer id so that it can be cancelled later. An alternative approach would be to writer a helper and use multiple instances so the timer id is not necessary. Alternatively, the helper can maintain a list of timer ids. In either case, writing a helper is good because it separates out the complexity of deadling with the reactor./Disable builtin SEDP writers/RtpsRelay: Implement rapid association (#1317) * Implement rapid association * Install the RtpsRelay library * Fixes from review * Fix whitespace * Fix control flow * Fix Coverity/Use BIT for RtpsRelay routing (#1286) Use BIT for routing in RtpsRelay/Response to Review 2: The Sequel/Response to Review/Fix Out of Order Declaration, Simplify/Modified to meet coding standards/Modified GuidGenerator and added sequence reset GuidGenerator Code was modified to add a random generated number to the counter value. The counter value will increment from the initial random generated number. Added RTPSDiscovery configuration value MaxSpdpSequenceMsgResetChecks. This value is the number of sequence numbers that must be received that are less than the initial last sequence number value before a discovered participant is removed. Added Spdp code changes to check for a sequence number reset. A reset occurs when a defined number of sequence numbers are received that are less than than an initial last sequence value. On a reset the discovered participant will be removed and rediscovered./Make TimePoint_T cstr More Similar to time_point/Fixes after Review/moving Sedp::Writer call of association_complete to enqueued ReactorInterceptor call to avoid deadlock/Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./"
,,0.2821,OpenDDS,"Bug fix + test app for: ""create_new_topic(), called near the end of create_topic_i(), can return nullptr. This needs to be checked before attempting to enable() it.""/Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./"
,,0.0906,OpenDDS,InstanceState: use the ReactorInterceptor to mediate threading with the ACE Recator made the InstanceState an RcObject and cleaned up its uses in OpenDDS_Dcps/
,,0.1491,OpenDDS,Create TheServiceParticipant->default_configuration_file()/Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.0926,OpenDDS,InstanceState: use the ReactorInterceptor to mediate threading with the ACE Recator made the InstanceState an RcObject and cleaned up its uses in OpenDDS_Dcps/
,,0.0945,OpenDDS,InstanceState: use the ReactorInterceptor to mediate threading with the ACE Recator made the InstanceState an RcObject and cleaned up its uses in OpenDDS_Dcps/
,,0.1518,OpenDDS,Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.1518,OpenDDS,Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.1518,OpenDDS,Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.3028,OpenDDS,"Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./"
,,0.18100000000000002,OpenDDS,Make TimePoint_T cstr More Similar to time_point/Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.3401,OpenDDS,"Make TimePoint_T cstr More Similar to time_point/Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./"
,,0.1518,OpenDDS,Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.1518,OpenDDS,Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.2934,OpenDDS,"Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./"
,,0.1518,OpenDDS,Use Monotonic for Internal Timing Have OpenDDS use monotonic timing where possible to protect OpenDDS from changes to the system clock./
,,0.0738,pljava,"Rework SQLInputFromChunk using direct bytebuffers. This will allow accommodating different byte orders, using the provisions built into ByteBuffer./"
,,0.0718,pljava,Rework SQLOutputToChunk using direct bytebuffers. This will allow accommodating different byte orders using the provisions built into ByteBuffer./
,,0.0673,realm-java,"Removed "".generated"" suffix in generated sources packages (issue"
,,0.0645,realm-java,Updated to new Tightdb version (9) which has new file format incompatible with previous versions/
,,0.0652,realm-java,"Wire the ""like"" predicate into RealmQuery (#3992) * Wire the ""like"" predicate into RealmQuery Fixes"
,,0.3259,realm-java,"Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/improve performance of getters and setters in proxy classes (#4206) * improve performance of getters and setters in proxy classes This change is a part of fixes of * removed unused argment * Update CHANGELOG.md/"
,,0.1509,realm-java,"Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/"
,,0.2875,realm-java,"Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/"
,,0.2977,realm-java,"Introduce DynamicRealmObject#linkingObjects(String srcClassName, String srcFieldName) (#4492)/Fix exception thrown from backlinks field (#4500) * add test case that reproduce * now backlinks geters throw IllegalStateException if the object is deleted or not yet loaded. * update CHANGELOG * add test * update a test * modify method name Row.checkIfBacklinkAvailable() to Row.checkIfAttached() * update variable names in test/Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/Run code formatter over all code (#4351)/Merge branch master into merge-6d0712-to-master/Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/Fix default values crashing if calling another constructor (#4249)/improve performance of getters and setters in proxy classes (#4206) * improve performance of getters and setters in proxy classes This change is a part of fixes of * removed unused argment * Update CHANGELOG.md/"
,,0.2984,realm-java,"Add support for transient fields (#4436)/Run code formatter over all code (#4351)/Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/"
,,0.1417,realm-java,"Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/"
,,0.138,realm-java,"Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/"
,,0.1843,realm-java,Fix threading bugs in RunInLooperThread rule (#4563) * Fix threading bugs in RunInLooperThread rule * Respond to comments Fix spelling errors Clean up multi-error recovery./Introduce ErrorProne plugin (#4342)/fix warnings reported by ErrorProne (#4341)/
,,0.0806,realm-java,Backport Unit Test PRs to releases (#4581)/Introduce ErrorProne plugin (#4342)/Add thread check to methods in RealmQuery. (#4257) * Throw IllegalStateException instead of process crash when any of thread confined methods in RealmQuery is called from wrong thread (#4228). * fix some bugs in test and remove methodParams * no need to add realm.checkIfValid(); to RealmQuery.isValid() * PR fixes * removed section header comments/
,,0.2839,realm-java,"Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/"
,,0.1645,realm-java,Fix threading bugs in RunInLooperThread rule (#4563) * Fix threading bugs in RunInLooperThread rule * Respond to comments Fix spelling errors Clean up multi-error recovery./remove breaking changes in SyncSession.ErrorHandler (#4408) * remove breaking changes in SyncSession.ErrorHandler * update CHANGELOG * update JNI file * update CMakeLists.txt * address review comments/Correctly report Client Reset (#4313)/
,,0.063,realm-java,Run code formatter over all code (#4351)/
,,0.2875,realm-java,"Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/"
,,0.2814,realm-java,"Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/"
,,0.0673,realm-java,Fix ErrorProne warnings/
,,0.066,realm-java,Including LinkingObjects in subscriptions (#6489)/
,,0.1909,rocksdb,"Speed up Snappy uncompression, new Logger interface. Removed one copy of an uncompressed block contents changing the signature of Snappy_Uncompress() so it uncompresses into a flat array instead of a std::string. Speeds up readrandom ~10%. Instead of a combination of Env/WritableFile, we now have a Logger interface that can be easily overridden applications that want to supply their own logging. Separated out the gcc and Sun Studio parts of atomic_pointer.h so we can use asm, volatile keywords for Sun Studio. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/"
,,0.1909,rocksdb,"Speed up Snappy uncompression, new Logger interface. Removed one copy of an uncompressed block contents changing the signature of Snappy_Uncompress() so it uncompresses into a flat array instead of a std::string. Speeds up readrandom ~10%. Instead of a combination of Env/WritableFile, we now have a Logger interface that can be easily overridden applications that want to supply their own logging. Separated out the gcc and Sun Studio parts of atomic_pointer.h so we can use asm, volatile keywords for Sun Studio. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/"
,,0.1944,rocksdb,"Speed up Snappy uncompression, new Logger interface. Removed one copy of an uncompressed block contents changing the signature of Snappy_Uncompress() so it uncompresses into a flat array instead of a std::string. Speeds up readrandom ~10%. Instead of a combination of Env/WritableFile, we now have a Logger interface that can be easily overridden applications that want to supply their own logging. Separated out the gcc and Sun Studio parts of atomic_pointer.h so we can use asm, volatile keywords for Sun Studio. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/"
,,0.1812,rocksdb,"Speed up Snappy uncompression, new Logger interface. Removed one copy of an uncompressed block contents changing the signature of Snappy_Uncompress() so it uncompresses into a flat array instead of a std::string. Speeds up readrandom ~10%. Instead of a combination of Env/WritableFile, we now have a Logger interface that can be easily overridden applications that want to supply their own logging. Separated out the gcc and Sun Studio parts of atomic_pointer.h so we can use asm, volatile keywords for Sun Studio. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/Sun Studio support, and fix for test related memory fixes. LevelDB patch for Sun Studio Based on a patch submitted by Theo Schlossnagle thanks This fixes Issue 17. Fix a couple of test related memory leaks. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/"
,,0.1882,rocksdb,"Speed up Snappy uncompression, new Logger interface. Removed one copy of an uncompressed block contents changing the signature of Snappy_Uncompress() so it uncompresses into a flat array instead of a std::string. Speeds up readrandom ~10%. Instead of a combination of Env/WritableFile, we now have a Logger interface that can be easily overridden applications that want to supply their own logging. Separated out the gcc and Sun Studio parts of atomic_pointer.h so we can use asm, volatile keywords for Sun Studio. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/Sun Studio support, and fix for test related memory fixes. LevelDB patch for Sun Studio Based on a patch submitted by Theo Schlossnagle thanks This fixes Issue 17. Fix a couple of test related memory leaks. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/"
,,0.1891,rocksdb,"Speed up Snappy uncompression, new Logger interface. Removed one copy of an uncompressed block contents changing the signature of Snappy_Uncompress() so it uncompresses into a flat array instead of a std::string. Speeds up readrandom ~10%. Instead of a combination of Env/WritableFile, we now have a Logger interface that can be easily overridden applications that want to supply their own logging. Separated out the gcc and Sun Studio parts of atomic_pointer.h so we can use asm, volatile keywords for Sun Studio. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/"
,,0.1909,rocksdb,"Speed up Snappy uncompression, new Logger interface. Removed one copy of an uncompressed block contents changing the signature of Snappy_Uncompress() so it uncompresses into a flat array instead of a std::string. Speeds up readrandom ~10%. Instead of a combination of Env/WritableFile, we now have a Logger interface that can be easily overridden applications that want to supply their own logging. Separated out the gcc and Sun Studio parts of atomic_pointer.h so we can use asm, volatile keywords for Sun Studio. git-svn-id: 62dab493-f737-651d-591e-8d6aee1b9529/"
,,0.1014,rocksdb,"Performant util/histogram. Summary: Earlier way to record in histogram=> Linear search BucketLimit array to find the bucket and increment the counter Current way to record in histogram=> Store a HistMap statically which points the buckets of each value in the range [kFirstValue, kLastValue); In the proccess use vectors instead of arrays and refactor some code to HistogramHelper class. Test Plan: run db_bench with histogram=1 and see a histogram being printed. Reviewers: dhruba, chip, heyongqiang Reviewed By: chip CC: leveldb Differential Revision:"
,,0.0849,rocksdb,"Revert ""Fbson to Json"" This reverts commit 7ce1b2c19c00f303214305ac4cc9a67296ede84a./"
,,0.0849,rocksdb,"Revert ""Fbson to Json"" This reverts commit 7ce1b2c19c00f303214305ac4cc9a67296ede84a./"
,,0.0849,rocksdb,"Revert ""Fbson to Json"" This reverts commit 7ce1b2c19c00f303214305ac4cc9a67296ede84a./"
,,0.0849,rocksdb,"Revert ""Fbson to Json"" This reverts commit 7ce1b2c19c00f303214305ac4cc9a67296ede84a./"
,,0.0849,rocksdb,"Revert ""Fbson to Json"" This reverts commit 7ce1b2c19c00f303214305ac4cc9a67296ede84a./"
,,0.0849,rocksdb,"Revert ""Fbson to Json"" This reverts commit 7ce1b2c19c00f303214305ac4cc9a67296ede84a./"
,,0.0849,rocksdb,"Revert ""Fbson to Json"" This reverts commit 7ce1b2c19c00f303214305ac4cc9a67296ede84a./"
,,0.0849,rocksdb,"Revert ""Fbson to Json"" This reverts commit 7ce1b2c19c00f303214305ac4cc9a67296ede84a./"
,,0.0849,rocksdb,"Revert ""Fbson to Json"" This reverts commit 7ce1b2c19c00f303214305ac4cc9a67296ede84a./"
,,0.0849,rocksdb,"Revert ""Fbson to Json"" This reverts commit 7ce1b2c19c00f303214305ac4cc9a67296ede84a./"
,,0.0849,rocksdb,"Revert ""Fbson to Json"" This reverts commit 7ce1b2c19c00f303214305ac4cc9a67296ede84a./"
,,0.0849,rocksdb,"Revert ""Fbson to Json"" This reverts commit 7ce1b2c19c00f303214305ac4cc9a67296ede84a./"
,,0.3186,rocksdb,"Move rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.3158,rocksdb,"Move rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.32,rocksdb,"Move rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.3143,rocksdb,"Move rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.1414,rocksdb,"Merge the latest changes from github/master/add rocksdb::WritableFileWrapper similar to rocksdb::EnvWrapper Summary: It used to be no good (known to me) non-intrusive way to wrap WritableFile you cant call protected virtual methods of the wrapped pointer to WritableFile. This diff adds a convenience class WritableFileWrapper that makes wrapping WritableFile both possible and easy. Test Plan: `make clean; make release`, `make clean; OPT=-DROCKSDB_LITE make release`, `make clean; USE_CLANG=1 make all`. Reviewers: sdong, yhchiang, rven Reviewed By: rven Subscribers: dhruba, tnovak, march Differential Revision:"
,,0.1609,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.2778,rocksdb,"Removing duplicate code Summary: While working on , I found duplicate code in the tests. This patch removes it. Test Plan: make clean all check Reviewers: igor, sdong, rven, anthony, yhchiang Reviewed By: yhchiang Subscribers: dhruba, leveldb Differential Revision: rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.3286,rocksdb,"Move rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision: the latest changes from github/master/add rocksdb::WritableFileWrapper similar to rocksdb::EnvWrapper Summary: It used to be no good (known to me) non-intrusive way to wrap WritableFile you cant call protected virtual methods of the wrapped pointer to WritableFile. This diff adds a convenience class WritableFileWrapper that makes wrapping WritableFile both possible and easy. Test Plan: `make clean; make release`, `make clean; OPT=-DROCKSDB_LITE make release`, `make clean; USE_CLANG=1 make all`. Reviewers: sdong, yhchiang, rven Reviewed By: rven Subscribers: dhruba, tnovak, march Differential Revision:"
,,0.1658,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.1625,rocksdb,"""make format"" against last 10 commits Summary: This helps Windows port to format their changes, as discussed. Might have formatted some other codes too becasue last 10 commits include more. Test Plan: Build it. Reviewers: anthony, IslamAbdelRahman, kradhakrishnan, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.1626,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.1658,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.1642,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.2107,rocksdb,"Improved FileExists API Summary: Add new CheckFileExists method. Considered changing the FileExists api but didnt want to break anyones builds. Test Plan: unit tests Reviewers: yhchiang, igor, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision: error handling in BackupEngine Summary: Couple of changes here: * NewBackupEngine() and NewReadOnlyBackupEngine() are now removed. They were deprecated since RocksDB 3.8. Changing these to new functions should be pretty straight-forward. As a followup, Ill fix all fbcode callsights * Instead of initializing backup engine in the constructor, we initialize it in a separate function now. That way, we can catch all errors and return appropriate status code. * We catch all errors during initializations and return them to the client properly. * Added new tests to backupable_db_test, to make sure that we cant open BackupEngine when there are Env errors. * Transitioned backupable_db_test to use BackupEngine rather than BackupableDB. From the two available APIs, judging by the current use-cases, it looks like BackupEngine API won. Its much more flexible since it doesnt require StackableDB. Test Plan: Added a new unit test to backupable_db_test Reviewers: yhchiang, sdong, AaronFeldman Reviewed By: AaronFeldman Subscribers: dhruba, leveldb Differential Revision: format"" against last 10 commits Summary: This helps Windows port to format their changes, as discussed. Might have formatted some other codes too becasue last 10 commits include more. Test Plan: Build it. Reviewers: anthony, IslamAbdelRahman, kradhakrishnan, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision: threads later in constructor Summary: This addresses a test failure where an exception occured in the constructors call to CreateDirIfMissing(). The existence of unjoined threads prevented this exception from propogating properly. See Test Plan: Re-run tests from task Reviewers: sdong, anthony, igor Reviewed By: igor Subscribers: dhruba Differential Revision: the latest changes from github/master/Multithreaded backup and restore in BackupEngineImpl Summary: Add a new field: BackupableDBOptions.max_background_copies. CreateNewBackup() and RestoreDBFromBackup() will use this number of threads to perform copies. If there is a backup rate limit, then max_background_copies must be 1. Update backupable_db_test.cc to test multi-threaded backup and restore. Update backupable_db_test.cc to test backups when the backup environment is not the same as the database environment. Test Plan: Run ./backupable_db_test Run valgrind ./backupable_db_test Run with TSAN and ASAN Reviewers: yhchiang, rven, anthony, sdong, igor Reviewed By: igor Subscribers: yhchiang, anthony, sdong, leveldb, dhruba Differential Revision:"
,,0.1708,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.141,rocksdb,"Skip unsupported tests in ROCKSDB_LITE Summary: Skipping these tests in ROCKSDB_LITE since they are not supported json_document_test wal_manager_test ttl_test sst_dump_test deletefile_test compact_files_test prefix_test checkpoint_test Test Plan: json_document_test wal_manager_test ttl_test sst_dump_test deletefile_test compact_files_test prefix_test checkpoint_test Reviewers: igor, sdong, yhchiang, kradhakrishnan, anthony Reviewed By: anthony Subscribers: dhruba Differential Revision:"
,,0.1855,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.1625,rocksdb,"""make format"" against last 10 commits Summary: This helps Windows port to format their changes, as discussed. Might have formatted some other codes too becasue last 10 commits include more. Test Plan: Build it. Reviewers: anthony, IslamAbdelRahman, kradhakrishnan, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.1675,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.1675,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.3087,rocksdb,"Move rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.1675,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.1608,rocksdb,"""make format"" against last 10 commits Summary: This helps Windows port to format their changes, as discussed. Might have formatted some other codes too becasue last 10 commits include more. Test Plan: Build it. Reviewers: anthony, IslamAbdelRahman, kradhakrishnan, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.3101,rocksdb,"Move rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.3115,rocksdb,"Move rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.2309,rocksdb,"""make format"" against last 10 commits Summary: This helps Windows port to format their changes, as discussed. Might have formatted some other codes too becasue last 10 commits include more. Test Plan: Build it. Reviewers: anthony, IslamAbdelRahman, kradhakrishnan, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision: Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.2944,rocksdb,"Block cuckoo table tests in ROCKSDB_LITE Summary: Cuckoo table is not supported in ROCKSDB_LITE, blocking its tests Test Plan: cuckoo_table_builder_test cuckoo_table_db_test cuckoo_table_reader_test Reviewers: sdong, igor, yhchiang Reviewed By: yhchiang Subscribers: dhruba Differential Revision: rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.3115,rocksdb,"Move rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.3411,rocksdb,"Skip unsupported tests in ROCKSDB_LITE Summary: Skipping these tests in ROCKSDB_LITE since they are not supported json_document_test wal_manager_test ttl_test sst_dump_test deletefile_test compact_files_test prefix_test checkpoint_test Test Plan: json_document_test wal_manager_test ttl_test sst_dump_test deletefile_test compact_files_test prefix_test checkpoint_test Reviewers: igor, sdong, yhchiang, kradhakrishnan, anthony Reviewed By: anthony Subscribers: dhruba Differential Revision: rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.33299999999999996,rocksdb,"Move rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision: WAL recovery consistency levels Summary: The ""one size fits all"" approach with WAL recovery will only introduce inconvenience for our varied clients as we go forward. The current recovery is a bit heuristic. We introduce the following levels of consistency while replaying the WAL. 1. RecoverAfterRestart (kTolerateCorruptedTailRecords) This mocks the current recovery mode. 2. RecoverAfterCleanShutdown (kAbsoluteConsistency) This is ideal for unit test and cases where the store is shutdown cleanly. We tolerate no corruption or incomplete writes. 3. RecoverPointInTime (kPointInTimeRecovery) This is ideal when using devices with controller cache or file systems which can loose data on restart. We recover upto the point were is no corruption or incomplete write. 4. RecoverAfterDisaster (kSkipAnyCorruptRecord) This is ideal mode to recover data. We tolerate corruption and incomplete writes, and we hop over those sections that we cannot make sense of salvaging as many records as possible. Test Plan: (1) Run added unit test to cover all levels. (2) Run make check. Reviewers: leveldb, sdong, igor Subscribers: yoshinorim, dhruba Differential Revision:"
,,0.1444,rocksdb,"Skip unsupported tests in ROCKSDB_LITE Summary: Skipping these tests in ROCKSDB_LITE since they are not supported json_document_test wal_manager_test ttl_test sst_dump_test deletefile_test compact_files_test prefix_test checkpoint_test Test Plan: json_document_test wal_manager_test ttl_test sst_dump_test deletefile_test compact_files_test prefix_test checkpoint_test Reviewers: igor, sdong, yhchiang, kradhakrishnan, anthony Reviewed By: anthony Subscribers: dhruba Differential Revision:"
,,0.3436,rocksdb,"Move rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision: format"" against last 10 commits Summary: This helps Windows port to format their changes, as discussed. Might have formatted some other codes too becasue last 10 commits include more. Test Plan: Build it. Reviewers: anthony, IslamAbdelRahman, kradhakrishnan, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.3186,rocksdb,"Move rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.2164,rocksdb,"Measure file read latency histogram per level Summary: In internal stats, remember read latency histogram, if statistics is enabled. It can be retrieved from DB::GetProperty() with ""rocksdb.dbstats"" property, if it is enabled. Test Plan: Manually run db_bench and prints out ""rocksdb.dbstats"" by hand and make sure it prints out as expected Reviewers: igor, IslamAbdelRahman, rven, kradhakrishnan, anthony, yhchiang Reviewed By: yhchiang Subscribers: MarkCallaghan, leveldb, dhruba Differential Revision: rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision: GetThreadList to report Flush properties. Summary: Allow GetThreadList to report Flush properties, which includes: * job id * number of bytes that has been written since flush started. * total size of input mem-tables Test Plan: ./db_bench Sample output from db_bench which tracks same flush job ThreadID ThreadType cfName Operation ElapsedTime Stage State OperationProperties 140213879898240 High Pri default Flush 5789 us FlushJob::WriteLevel0Table BytesMemtables 4112835 | BytesWritten 577104 | JobID 8 | ThreadID ThreadType cfName Operation ElapsedTime Stage State OperationProperties 140213879898240 High Pri default Flush 30.634 ms FlushJob::WriteLevel0Table BytesMemtables 4112835 | BytesWritten 1734865 | JobID 8 | Reviewers: rven, igor, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision:"
,,0.2765,rocksdb,"Removing duplicate code Summary: While working on , I found duplicate code in the tests. This patch removes it. Test Plan: make clean all check Reviewers: igor, sdong, rven, anthony, yhchiang Reviewed By: yhchiang Subscribers: dhruba, leveldb Differential Revision: rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision:"
,,0.3352,rocksdb,"Move rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision: WAL recovery consistency levels Summary: The ""one size fits all"" approach with WAL recovery will only introduce inconvenience for our varied clients as we go forward. The current recovery is a bit heuristic. We introduce the following levels of consistency while replaying the WAL. 1. RecoverAfterRestart (kTolerateCorruptedTailRecords) This mocks the current recovery mode. 2. RecoverAfterCleanShutdown (kAbsoluteConsistency) This is ideal for unit test and cases where the store is shutdown cleanly. We tolerate no corruption or incomplete writes. 3. RecoverPointInTime (kPointInTimeRecovery) This is ideal when using devices with controller cache or file systems which can loose data on restart. We recover upto the point were is no corruption or incomplete write. 4. RecoverAfterDisaster (kSkipAnyCorruptRecord) This is ideal mode to recover data. We tolerate corruption and incomplete writes, and we hop over those sections that we cannot make sense of salvaging as many records as possible. Test Plan: (1) Run added unit test to cover all levels. (2) Run make check. Reviewers: leveldb, sdong, igor Subscribers: yoshinorim, dhruba Differential Revision:"
,,0.3282,rocksdb,"Measure file read latency histogram per level Summary: In internal stats, remember read latency histogram, if statistics is enabled. It can be retrieved from DB::GetProperty() with ""rocksdb.dbstats"" property, if it is enabled. Test Plan: Manually run db_bench and prints out ""rocksdb.dbstats"" by hand and make sure it prints out as expected Reviewers: igor, IslamAbdelRahman, rven, kradhakrishnan, anthony, yhchiang Reviewed By: yhchiang Subscribers: MarkCallaghan, leveldb, dhruba Differential Revision: rate_limiter, write buffering, most perf context instrumentation and most random kill out of Env Summary: We want to keep Env a think layer for better portability. Less platform dependent codes should be moved out of Env. In this patch, I create a wrapper of file readers and writers, and put rate limiting, write buffering, as well as most perf context instrumentation and random kill out of Env. It will make it easier to maintain multiple Env in the future. Test Plan: Run all existing unit tests. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision: Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.2898,rocksdb,"log_{reader,write}: recyclable record format Introduce new tags for records that have a log_number. This changes the header size from 7 to 11 for these records, making this a backward-incompatible change. If we read a record that belongs to a different log_number (i.e., a previous instantiation of this log file, before it was most recently recycled), we return kOldRecord from ReadPhysicalRecord. ReadRecord will translate this into a kEof or kBadRecord depending on what the WAL recovery mode is. We make several adjustments to the log_test.cc tests to compensate for the fact that the header size varies between the two modes. Signed-off-by: Sage Weil"
,,0.3011,rocksdb,"log_{reader,write}: recyclable record format Introduce new tags for records that have a log_number. This changes the header size from 7 to 11 for these records, making this a backward-incompatible change. If we read a record that belongs to a different log_number (i.e., a previous instantiation of this log file, before it was most recently recycled), we return kOldRecord from ReadPhysicalRecord. ReadRecord will translate this into a kEof or kBadRecord depending on what the WAL recovery mode is. We make several adjustments to the log_test.cc tests to compensate for the fact that the header size varies between the two modes. Signed-off-by: Sage Weil"
,,0.3106,rocksdb,"log_{reader,write}: recyclable record format Introduce new tags for records that have a log_number. This changes the header size from 7 to 11 for these records, making this a backward-incompatible change. If we read a record that belongs to a different log_number (i.e., a previous instantiation of this log file, before it was most recently recycled), we return kOldRecord from ReadPhysicalRecord. ReadRecord will translate this into a kEof or kBadRecord depending on what the WAL recovery mode is. We make several adjustments to the log_test.cc tests to compensate for the fact that the header size varies between the two modes. Signed-off-by: Sage Weil introduce kBadHeader; drop wal mode from ReadPhysicalRecord Move the WAL recovery mode logic out of ReadPhysicalRecord. To do this we introduce a new type indicating when we fail to read a valid header. Signed-off-by: Sage Weil pass in WALRecoveryMode instead of bool report_eof_inconsistency Soon our behavior will depend on more than just whther we are in kAbsoluteConsistency or not. Signed-off-by: Sage Weil pass log_number and optional info_log to ctor We will need the log number to validate the recycle-style CRCs. The log is helpful for debugging, but optional, as not all callers have it. Signed-off-by: Sage Weil"
,,0.3366,rocksdb,"log_{reader,write}: recyclable record format Introduce new tags for records that have a log_number. This changes the header size from 7 to 11 for these records, making this a backward-incompatible change. If we read a record that belongs to a different log_number (i.e., a previous instantiation of this log file, before it was most recently recycled), we return kOldRecord from ReadPhysicalRecord. ReadRecord will translate this into a kEof or kBadRecord depending on what the WAL recovery mode is. We make several adjustments to the log_test.cc tests to compensate for the fact that the header size varies between the two modes. Signed-off-by: Sage Weil pass in WALRecoveryMode instead of bool report_eof_inconsistency Soon our behavior will depend on more than just whther we are in kAbsoluteConsistency or not. Signed-off-by: Sage Weil pass log_number and optional info_log to ctor We will need the log number to validate the recycle-style CRCs. The log is helpful for debugging, but optional, as not all callers have it. Signed-off-by: Sage Weil pass log number and whether recycling is enabled to ctor When we recycle log files, we need to mix the log number into the CRC for each record. Note that for logs that dont get recycled (like the manifest), we always pass a log_number of 0 and false. Signed-off-by: Sage Weil"
,,0.0702,rocksdb,Build on Visual Studio 2015 Update 1/
,,0.1102,rocksdb,"Avoid overloaded virtual function/Publish log numbers for column family to wal_filter, and provide log number in the record callback/"
,,0.2308,rocksdb,"Direct IO capability for RocksDB Summary: This patch adds direct IO capability to RocksDB Env. The direct IO capability is required for persistent cache since NVM is best accessed as 4K direct IO. SSDs can leverage direct IO for reading. Direct IO requires the offset and size be sector size aligned, and memory to be kernel page aligned. Since neither RocksDB/Persistent read cache data layout is aligned to sector size, the code can accommodate reading unaligned IO size (or unaligned memory) at the cost of an alloc/copy. The write code path expects the size and memory to be aligned. Test Plan: Run RocksDB unit tests Reviewers: sdong Subscribers: andrewkr, dhruba, leveldb Differential Revision:"
,,0.2047,rocksdb,"Fix Windows build break Summary: Direct IO checkin breaks Windows build. Fixing the code to work for Windows. Test Plan: Run env_test in Windows 10 and make check in Linux Reviewers: sdong Subscribers: andrewkr, dhruba, leveldb Differential Revision: IO capability for RocksDB Summary: This patch adds direct IO capability to RocksDB Env. The direct IO capability is required for persistent cache since NVM is best accessed as 4K direct IO. SSDs can leverage direct IO for reading. Direct IO requires the offset and size be sector size aligned, and memory to be kernel page aligned. Since neither RocksDB/Persistent read cache data layout is aligned to sector size, the code can accommodate reading unaligned IO size (or unaligned memory) at the cost of an alloc/copy. The write code path expects the size and memory to be aligned. Test Plan: Run RocksDB unit tests Reviewers: sdong Subscribers: andrewkr, dhruba, leveldb Differential Revision:"
,,0.20199999999999999,rocksdb,"Direct IO fix for Mac Summary: O_DIRECT is not available in Mac as a flag for open. The fix is to make use of fctl after the file is opened Test Plan: Run the tests on mac and Linux Reviewers: sdong Subscribers: andrewkr, dhruba, leveldb Differential Revision: IO capability for RocksDB Summary: This patch adds direct IO capability to RocksDB Env. The direct IO capability is required for persistent cache since NVM is best accessed as 4K direct IO. SSDs can leverage direct IO for reading. Direct IO requires the offset and size be sector size aligned, and memory to be kernel page aligned. Since neither RocksDB/Persistent read cache data layout is aligned to sector size, the code can accommodate reading unaligned IO size (or unaligned memory) at the cost of an alloc/copy. The write code path expects the size and memory to be aligned. Test Plan: Run RocksDB unit tests Reviewers: sdong Subscribers: andrewkr, dhruba, leveldb Differential Revision:"
,,0.0621,rocksdb,Correct geHistogramData() getHistogramData() (#1257)/
,,0.1153,rocksdb,"db/log_reader: combine kBadRecord{Len,Checksum} for readability These vary only by the corruption string reported. Signed-off-by: Sage Weil move kBadRecord{Len,Checksum} handling into ReadRecord The behavior here needs to depend on the WAL recovery mode. No functional change in this patch. Signed-off-by: Sage Weil"
,,0.2764,rocksdb,"db/log_reader: treat bad record length or checksum as EOF If we are in kTolerateCorruptedTailRecords, treat these errors as the end of the log. This is particularly important for recycled logs, where we will regularly see corrupted headers (bad length or checksum) when replaying a log. If we are aligned with a block boundary or get lucky, we will land on an old header and see the log number mismatch, but more commonly we will land midway through some previous block and record and effectively see noise. These must be treated as the end of the log in order for recycling to work. This makes the LogTest.Recycle/1 test pass. We also modify a number of existing tests because the recycled log files behave fundamentally differently in that they always stop when they reach the first bad record. Signed-off-by: Sage Weil add recycle log test This currently fails because we do not properly map a corrupt header to the logical end of the log. Signed-off-by: Sage Weil"
,,0.1426,rocksdb,"Making persistent cache more resilient to filesystem failures Summary: The persistent cache is designed to hop over errors and return key not found. So far, it has shown resilience to write errors, encoding errors, data corruption etc. It is not resilient against disappearing files/directories. This was exposed during testing when multiple instances of persistence cache was started sharing the same directory simulating an unpredictable filesystem environment. This patch makes the write code path more resilient to errors while creating files makes the read code path more resilient to handle situation where files are not found added a test that does negative write/read testing by removing the directory while writes are in progress Closes Differential Revision: D4143413 Pulled By: kradhakrishnan fbshipit-source-id: fd25e9b/"
,,0.1296,rocksdb,"Making persistent cache more resilient to filesystem failures Summary: The persistent cache is designed to hop over errors and return key not found. So far, it has shown resilience to write errors, encoding errors, data corruption etc. It is not resilient against disappearing files/directories. This was exposed during testing when multiple instances of persistence cache was started sharing the same directory simulating an unpredictable filesystem environment. This patch makes the write code path more resilient to errors while creating files makes the read code path more resilient to handle situation where files are not found added a test that does negative write/read testing by removing the directory while writes are in progress Closes Differential Revision: D4143413 Pulled By: kradhakrishnan fbshipit-source-id: fd25e9b/"
,,0.2479,rocksdb,"Disable readahead when using mmap for reads Summary: `ReadaheadRandomAccessFile` had an unwritten assumption, which was that its wrapped files `Read()` function always copies into the provided scratch buffer. Actually this was not true when the wrapped file was `PosixMmapReadableFile`, whose `Read()` implementation does no copying and instead returns a `Slice` pointing directly into the `mmap`d memory region. This PR: prevents `ReadaheadRandomAccessFile` from ever wrapping mmap readable files adds an assert for the assumption `ReadaheadRandomAccessFile` makes about the wrapped files use of scratch buffer Closes Differential Revision: D7891513 Pulled By: ajkr fbshipit-source-id: dc64a55222d6af280c39a1852ee39e9e9d7cde7d/uint64_t and size_t changes to compile for iOS Summary: In attempting to build a static lib for use in iOS, I ran in to lots of type errors between uint64_t and size_t. This PR contains the changes I made to get `TARGET_OS=IOS make static_lib` to succeed while also getting Xcode to build successfully with the resulting `librocksdb.a` library imported. This also compiles for me on macOS and tests fine, but Im really not sure if I made the correct decisions about where to `static_cast` and where to change types. Also up for discussion: is iOS worth supporting? Getting the static lib is just part one, we arent providing any bridging headers or wrappers like the ObjectiveRocks project, it wont be a great experience. Closes Differential Revision: D7106457 Pulled By: gfosco fbshipit-source-id: 82ac2073de7e1f09b91f6b4faea91d18bd311f8e/"
,,0.41100000000000003,rocksdb,"Skip deleted WALs during recovery Summary: This patch record min log number to keep to the manifest while flushing SST files to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic. Before the commit, for 2PC case, we determined which log number to keep in FindObsoleteFiles(). We looked at the earliest logs with outstanding prepare entries, or prepare entries whose respective commit or abort are in memtable. With the commit, the same calculation is done while we apply the SST flush. Just before installing the flush file, we precompute the earliest log file to keep after the flush finishes using the same logic (but skipping the memtables just flushed), record this information to the manifest entry for this new flushed SST file. This pre-computed value is also remembered in memory, and will later be used to determine whether a log file can be deleted. This value is unlikely to change until next flush because the commit entry will stay in memtable. (In WritePrepared, we could have removed the older log files as soon as all prepared entries are committed. Its not yet done anyway. Even if we do it, the only thing we loss with this new approach is earlier log deletion between two flushes, which does not guarantee to happen anyway because the obsolete file clean-up function is only executed after flush or compaction) This min log number to keep is stored in the manifest using the safely-ignore customized field of AddFile entry, in order to guarantee that the DB generated using newer release can be opened by previous releases no older than 4.2. Closes Differential Revision: D7747618 Pulled By: siying fbshipit-source-id: d00c92105b4f83852e9754a1b70d6b64cb590729/"
,,0.2476,rocksdb,"uint64_t and size_t changes to compile for iOS Summary: In attempting to build a static lib for use in iOS, I ran in to lots of type errors between uint64_t and size_t. This PR contains the changes I made to get `TARGET_OS=IOS make static_lib` to succeed while also getting Xcode to build successfully with the resulting `librocksdb.a` library imported. This also compiles for me on macOS and tests fine, but Im really not sure if I made the correct decisions about where to `static_cast` and where to change types. Also up for discussion: is iOS worth supporting? Getting the static lib is just part one, we arent providing any bridging headers or wrappers like the ObjectiveRocks project, it wont be a great experience. Closes Differential Revision: D7106457 Pulled By: gfosco fbshipit-source-id: 82ac2073de7e1f09b91f6b4faea91d18bd311f8e/"
,,0.4549,rocksdb,"Skip deleted WALs during recovery Summary: This patch record min log number to keep to the manifest while flushing SST files to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic. Before the commit, for 2PC case, we determined which log number to keep in FindObsoleteFiles(). We looked at the earliest logs with outstanding prepare entries, or prepare entries whose respective commit or abort are in memtable. With the commit, the same calculation is done while we apply the SST flush. Just before installing the flush file, we precompute the earliest log file to keep after the flush finishes using the same logic (but skipping the memtables just flushed), record this information to the manifest entry for this new flushed SST file. This pre-computed value is also remembered in memory, and will later be used to determine whether a log file can be deleted. This value is unlikely to change until next flush because the commit entry will stay in memtable. (In WritePrepared, we could have removed the older log files as soon as all prepared entries are committed. Its not yet done anyway. Even if we do it, the only thing we loss with this new approach is earlier log deletion between two flushes, which does not guarantee to happen anyway because the obsolete file clean-up function is only executed after flush or compaction) This min log number to keep is stored in the manifest using the safely-ignore customized field of AddFile entry, in order to guarantee that the DB generated using newer release can be opened by previous releases no older than 4.2. Closes Differential Revision: D7747618 Pulled By: siying fbshipit-source-id: d00c92105b4f83852e9754a1b70d6b64cb590729/WritePrepared Txn: make recoverable state visible after flush Summary: Currently if the CommitTimeWriteBatch is set to be used only as a state that is required only for recovery , the user cannot see that in DB until it is restarted. This while the state is already inserted into the DB after the memtable flush. It would be useful for debugging if make this state visible to the user after the flush by committing it. The patch does it by a invoking a callback that does the commit on the recoverable state. Closes Differential Revision: D7424577 Pulled By: maysamyabandeh fbshipit-source-id: 137f9408662f0853938b33fa440f27f04c1bbf5c/FlushReason improvement Summary: Right now flush reason ""SuperVersion Change"" covers a few different scenarios which is a bit vague. For example, the following db_bench job should trigger ""Write Buffer Full"" > $ TEST_TMPDIR=/dev/shm ./db_bench $ grep flush_reason /dev/shm/dbbench/LOG ... 2018/03/06-17:30:42.543638 7f2773b99700 EVENT_LOG_v1 {""time_micros"": 1520386242543634, ""job"": 192, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7006, ""num_deletes"": 0, ""memory_usage"": 1018024, ""flush_reason"": ""SuperVersion Change""} 2018/03/06-17:30:42.569541 7f2773b99700 EVENT_LOG_v1 {""time_micros"": 1520386242569536, ""job"": 193, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7006, ""num_deletes"": 0, ""memory_usage"": 1018104, ""flush_reason"": ""SuperVersion Change""} 2018/03/06-17:30:42.596396 7f2773b99700 EVENT_LOG_v1 {""time_micros"": 1520386242596392, ""job"": 194, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7008, ""num_deletes"": 0, ""memory_usage"": 1018048, ""flush_reason"": ""SuperVersion Change""} 2018/03/06-17:30:42.622444 7f2773b99700 EVENT_LOG_v1 {""time_micros"": 1520386242622440, ""job"": 195, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7006, ""num_deletes"": 0, ""memory_usage"": 1018104, ""flush_reason"": ""SuperVersion Change""} With the fix: > 2018/03/19-14:40:02.341451 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602341444, ""job"": 98, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7009, ""num_deletes"": 0, ""memory_usage"": 1018008, ""flush_reason"": ""Write Buffer Full""} 2018/03/19-14:40:02.379655 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602379642, ""job"": 100, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7006, ""num_deletes"": 0, ""memory_usage"": 1018016, ""flush_reason"": ""Write Buffer Full""} 2018/03/19-14:40:02.418479 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602418474, ""job"": 101, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7009, ""num_deletes"": 0, ""memory_usage"": 1018104, ""flush_reason"": ""Write Buffer Full""} 2018/03/19-14:40:02.455084 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602455079, ""job"": 102, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7009, ""num_deletes"": 0, ""memory_usage"": 1018048, ""flush_reason"": ""Write Buffer Full""} 2018/03/19-14:40:02.492293 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602492288, ""job"": 104, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7007, ""num_deletes"": 0, ""memory_usage"": 1018056, ""flush_reason"": ""Write Buffer Full""} 2018/03/19-14:40:02.528720 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602528715, ""job"": 105, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7006, ""num_deletes"": 0, ""memory_usage"": 1018104, ""flush_reason"": ""Write Buffer Full""} 2018/03/19-14:40:02.566255 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602566238, ""job"": 107, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7009, ""num_deletes"": 0, ""memory_usage"": 1018112, ""flush_reason"": ""Write Buffer Full""} Closes Differential Revision: D7328772 Pulled By: miasantreble fbshipit-source-id: 67c94065fbdd36930f09930aad0aaa6d2c152bb8/WritePrepared Txn: fix race condition on publishing seq Summary: This commit fixes a race condition on calling SetLastPublishedSequence. The function must be called only from the 2nd write queue when two_write_queues is enabled. However there was a bug that would also call it from the main write queue if CommitTimeWriteBatch is provided to the commit request and yet use_only_the_last_commit_time_batch_for_recovery optimization is not enabled. To fix that we penalize the commit request in such cases by doing an additional write solely to publish the seq number from the 2nd queue. Closes Differential Revision: D7361508 Pulled By: maysamyabandeh fbshipit-source-id: bf8f7a27e5cccf5425dccbce25eb0032e8e5a4d7/uint64_t and size_t changes to compile for iOS Summary: In attempting to build a static lib for use in iOS, I ran in to lots of type errors between uint64_t and size_t. This PR contains the changes I made to get `TARGET_OS=IOS make static_lib` to succeed while also getting Xcode to build successfully with the resulting `librocksdb.a` library imported. This also compiles for me on macOS and tests fine, but Im really not sure if I made the correct decisions about where to `static_cast` and where to change types. Also up for discussion: is iOS worth supporting? Getting the static lib is just part one, we arent providing any bridging headers or wrappers like the ObjectiveRocks project, it wont be a great experience. Closes Differential Revision: D7106457 Pulled By: gfosco fbshipit-source-id: 82ac2073de7e1f09b91f6b4faea91d18bd311f8e/"
,,0.3999,rocksdb,"Skip deleted WALs during recovery Summary: This patch record min log number to keep to the manifest while flushing SST files to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic. Before the commit, for 2PC case, we determined which log number to keep in FindObsoleteFiles(). We looked at the earliest logs with outstanding prepare entries, or prepare entries whose respective commit or abort are in memtable. With the commit, the same calculation is done while we apply the SST flush. Just before installing the flush file, we precompute the earliest log file to keep after the flush finishes using the same logic (but skipping the memtables just flushed), record this information to the manifest entry for this new flushed SST file. This pre-computed value is also remembered in memory, and will later be used to determine whether a log file can be deleted. This value is unlikely to change until next flush because the commit entry will stay in memtable. (In WritePrepared, we could have removed the older log files as soon as all prepared entries are committed. Its not yet done anyway. Even if we do it, the only thing we loss with this new approach is earlier log deletion between two flushes, which does not guarantee to happen anyway because the obsolete file clean-up function is only executed after flush or compaction) This min log number to keep is stored in the manifest using the safely-ignore customized field of AddFile entry, in order to guarantee that the DB generated using newer release can be opened by previous releases no older than 4.2. Closes Differential Revision: D7747618 Pulled By: siying fbshipit-source-id: d00c92105b4f83852e9754a1b70d6b64cb590729/"
,,0.2415,rocksdb,"Revert ""Skip deleted WALs during recovery"" Summary: This reverts commit 73f21a7b2177aeb82b9f518222e2b9ea8fbb7c4f. It breaks compatibility. When created a DB using a build with this new change, opening the DB and reading the data will fail with this error: ""Corruption: Cant access /000000.sst: IO error: while stat a file for size: /tmp/xxxx/000000.sst: No such file or directory"" This is because the dummy AddFile4 entry generated by the new code will be treated as a real entry by an older build. The older build will think there is a real file with number 0, but there isnt such a file. Closes Differential Revision: D7730035 Pulled By: siying fbshipit-source-id: f2051859eff20ef1837575ecb1e1bb96b3751e77/Skip deleted WALs during recovery Summary: This patch record the deleted WAL numbers in the manifest to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic. Closes Differential Revision: D6967893 Pulled By: maysamyabandeh fbshipit-source-id: 13119feb155a08ab6d4909f437c7a750480dc8a1/"
,,0.3948,rocksdb,"Skip deleted WALs during recovery Summary: This patch record min log number to keep to the manifest while flushing SST files to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic. Before the commit, for 2PC case, we determined which log number to keep in FindObsoleteFiles(). We looked at the earliest logs with outstanding prepare entries, or prepare entries whose respective commit or abort are in memtable. With the commit, the same calculation is done while we apply the SST flush. Just before installing the flush file, we precompute the earliest log file to keep after the flush finishes using the same logic (but skipping the memtables just flushed), record this information to the manifest entry for this new flushed SST file. This pre-computed value is also remembered in memory, and will later be used to determine whether a log file can be deleted. This value is unlikely to change until next flush because the commit entry will stay in memtable. (In WritePrepared, we could have removed the older log files as soon as all prepared entries are committed. Its not yet done anyway. Even if we do it, the only thing we loss with this new approach is earlier log deletion between two flushes, which does not guarantee to happen anyway because the obsolete file clean-up function is only executed after flush or compaction) This min log number to keep is stored in the manifest using the safely-ignore customized field of AddFile entry, in order to guarantee that the DB generated using newer release can be opened by previous releases no older than 4.2. Closes Differential Revision: D7747618 Pulled By: siying fbshipit-source-id: d00c92105b4f83852e9754a1b70d6b64cb590729/"
,,0.225,rocksdb,"Add max_subcompactions as a compaction option Summary: Sometimes we want to compact files as fast as possible, but dont want to set a large `max_subcompactions` in the `DBOptions` by default. I add a `max_subcompactions` options to `CompactionOptions` so that we can choose a proper concurrency dynamically. Closes Differential Revision: D7792357 Pulled By: ajkr fbshipit-source-id: 94f54c3784dce69e40a229721a79a97e80cd6a6c/comment unused parameters to turn on flag Summary: This PR comments out the rest of the unused arguments which allow us to turn on the flag. This is the second part of a codemod relating to Closes Differential Revision: D7426121 Pulled By: Dayvedde fbshipit-source-id: 223994923b42bd4953eb016a0129e47560f7e352/Enable cancelling manual compactions if they hit the sfm size limit Summary: Manual compactions should be cancelled, just like scheduled compactions are cancelled, if sfm->EnoughRoomForCompaction is not true. Closes Differential Revision: D7457683 Pulled By: amytai fbshipit-source-id: 669b02fdb707f75db576d03d2c818fb98d1876f5/Throw NoSpace instead of IOError when out of space. Summary: Replaces and is updated from feedback. Closes Differential Revision: D7457395 Pulled By: gfosco fbshipit-source-id: 25a21dd8cfa5a6e42e024208b444d9379d920c82/FlushReason improvement Summary: Right now flush reason ""SuperVersion Change"" covers a few different scenarios which is a bit vague. For example, the following db_bench job should trigger ""Write Buffer Full"" > $ TEST_TMPDIR=/dev/shm ./db_bench $ grep flush_reason /dev/shm/dbbench/LOG ... 2018/03/06-17:30:42.543638 7f2773b99700 EVENT_LOG_v1 {""time_micros"": 1520386242543634, ""job"": 192, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7006, ""num_deletes"": 0, ""memory_usage"": 1018024, ""flush_reason"": ""SuperVersion Change""} 2018/03/06-17:30:42.569541 7f2773b99700 EVENT_LOG_v1 {""time_micros"": 1520386242569536, ""job"": 193, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7006, ""num_deletes"": 0, ""memory_usage"": 1018104, ""flush_reason"": ""SuperVersion Change""} 2018/03/06-17:30:42.596396 7f2773b99700 EVENT_LOG_v1 {""time_micros"": 1520386242596392, ""job"": 194, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7008, ""num_deletes"": 0, ""memory_usage"": 1018048, ""flush_reason"": ""SuperVersion Change""} 2018/03/06-17:30:42.622444 7f2773b99700 EVENT_LOG_v1 {""time_micros"": 1520386242622440, ""job"": 195, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7006, ""num_deletes"": 0, ""memory_usage"": 1018104, ""flush_reason"": ""SuperVersion Change""} With the fix: > 2018/03/19-14:40:02.341451 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602341444, ""job"": 98, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7009, ""num_deletes"": 0, ""memory_usage"": 1018008, ""flush_reason"": ""Write Buffer Full""} 2018/03/19-14:40:02.379655 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602379642, ""job"": 100, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7006, ""num_deletes"": 0, ""memory_usage"": 1018016, ""flush_reason"": ""Write Buffer Full""} 2018/03/19-14:40:02.418479 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602418474, ""job"": 101, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7009, ""num_deletes"": 0, ""memory_usage"": 1018104, ""flush_reason"": ""Write Buffer Full""} 2018/03/19-14:40:02.455084 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602455079, ""job"": 102, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7009, ""num_deletes"": 0, ""memory_usage"": 1018048, ""flush_reason"": ""Write Buffer Full""} 2018/03/19-14:40:02.492293 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602492288, ""job"": 104, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7007, ""num_deletes"": 0, ""memory_usage"": 1018056, ""flush_reason"": ""Write Buffer Full""} 2018/03/19-14:40:02.528720 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602528715, ""job"": 105, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7006, ""num_deletes"": 0, ""memory_usage"": 1018104, ""flush_reason"": ""Write Buffer Full""} 2018/03/19-14:40:02.566255 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602566238, ""job"": 107, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7009, ""num_deletes"": 0, ""memory_usage"": 1018112, ""flush_reason"": ""Write Buffer Full""} Closes Differential Revision: D7328772 Pulled By: miasantreble fbshipit-source-id: 67c94065fbdd36930f09930aad0aaa6d2c152bb8/skip CompactRange flush based on memtable contents Summary: CompactRange has a call to Flush because we guarantee that, at the time its called, all existing keys in the range will be pushed through the users compaction filter. However, previously the flush was done blindly, so itd happen even if the memtable does not contain keys in the range specified by the user. This caused unnecessarily many L0 files to be created, leading to write stalls in some cases. This PR checks the memtables contents, and decides to flush only if it overlaps with `CompactRange`s range. Move the memtable overlap check logic from `ExternalSstFileIngestionJob` to `ColumnFamilyData::RangesOverlapWithMemtables` Reuse the above logic in `CompactRange` and skip flushing if no overlap Closes Differential Revision: D7018897 Pulled By: ajkr fbshipit-source-id: a3c6b1cfae56687b49dd89ccac7c948e53545934/Add delay before flush in CompactRange to avoid write stalling Summary: Refactored logic for checking write stall condition to a helper function: `GetWriteStallConditionAndCause`. Now it is decoupled from the logic for updating WriteController / stats in `RecalculateWriteStallConditions`, so we can reuse it for predicting whether write stall will occur. Updated `CompactRange` to first check whether the one additional immutable memtable / L0 file would cause stalling before it flushes. If so, it waits until that is no longer true. Updated `bg_cv_` to be signaled on `SetOptions` calls. The stall conditions `CompactRange` cares about can change when (1) flush finishes, (2) compaction finishes, or (3) options dynamically change. The cv was already signaled for (1) and (2) but not yet for (3). Closes Differential Revision: D6754983 Pulled By: ajkr fbshipit-source-id: 5613e03f1524df7192dc6ae885d40fd8f091d972/"
,,0.4525,rocksdb,"Skip deleted WALs during recovery Summary: This patch record min log number to keep to the manifest while flushing SST files to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic. Before the commit, for 2PC case, we determined which log number to keep in FindObsoleteFiles(). We looked at the earliest logs with outstanding prepare entries, or prepare entries whose respective commit or abort are in memtable. With the commit, the same calculation is done while we apply the SST flush. Just before installing the flush file, we precompute the earliest log file to keep after the flush finishes using the same logic (but skipping the memtables just flushed), record this information to the manifest entry for this new flushed SST file. This pre-computed value is also remembered in memory, and will later be used to determine whether a log file can be deleted. This value is unlikely to change until next flush because the commit entry will stay in memtable. (In WritePrepared, we could have removed the older log files as soon as all prepared entries are committed. Its not yet done anyway. Even if we do it, the only thing we loss with this new approach is earlier log deletion between two flushes, which does not guarantee to happen anyway because the obsolete file clean-up function is only executed after flush or compaction) This min log number to keep is stored in the manifest using the safely-ignore customized field of AddFile entry, in order to guarantee that the DB generated using newer release can be opened by previous releases no older than 4.2. Closes Differential Revision: D7747618 Pulled By: siying fbshipit-source-id: d00c92105b4f83852e9754a1b70d6b64cb590729/Skip deleted WALs during recovery Summary: This patch record the deleted WAL numbers in the manifest to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic. Closes Differential Revision: D6967893 Pulled By: maysamyabandeh fbshipit-source-id: 13119feb155a08ab6d4909f437c7a750480dc8a1/"
,,0.1876,rocksdb,"Skip deleted WALs during recovery Summary: This patch record the deleted WAL numbers in the manifest to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic. Closes Differential Revision: D6967893 Pulled By: maysamyabandeh fbshipit-source-id: 13119feb155a08ab6d4909f437c7a750480dc8a1/Optimize overlap checking for external file ingestion Summary: If there are a lot of overlapped files in L0, creating a merging iterator for all files in L0 to check overlap can be very slow because we need to read and seek all files in L0. However, in that case, the ingested file is likely to overlap with some files in L0, so if we check those files one by one, we can stop once we encounter overlap. Ref: Closes Differential Revision: D7196784 Pulled By: anand1976 fbshipit-source-id: 8700c1e903bd515d0fa7005b6ce9b3a3d9db2d67/"
,,0.2503,rocksdb,"Revert ""Skip deleted WALs during recovery"" Summary: This reverts commit 73f21a7b2177aeb82b9f518222e2b9ea8fbb7c4f. It breaks compatibility. When created a DB using a build with this new change, opening the DB and reading the data will fail with this error: ""Corruption: Cant access /000000.sst: IO error: while stat a file for size: /tmp/xxxx/000000.sst: No such file or directory"" This is because the dummy AddFile4 entry generated by the new code will be treated as a real entry by an older build. The older build will think there is a real file with number 0, but there isnt such a file. Closes Differential Revision: D7730035 Pulled By: siying fbshipit-source-id: f2051859eff20ef1837575ecb1e1bb96b3751e77/Skip deleted WALs during recovery Summary: This patch record the deleted WAL numbers in the manifest to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic. Closes Differential Revision: D6967893 Pulled By: maysamyabandeh fbshipit-source-id: 13119feb155a08ab6d4909f437c7a750480dc8a1/"
,,0.2569,rocksdb,Skip deleted WALs during recovery Summary: This patch record the deleted WAL numbers in the manifest to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic. Closes Differential Revision: D6967893 Pulled By: maysamyabandeh fbshipit-source-id: 13119feb155a08ab6d4909f437c7a750480dc8a1/
,,0.2332,rocksdb,"Revert ""Skip deleted WALs during recovery"" Summary: This reverts commit 73f21a7b2177aeb82b9f518222e2b9ea8fbb7c4f. It breaks compatibility. When created a DB using a build with this new change, opening the DB and reading the data will fail with this error: ""Corruption: Cant access /000000.sst: IO error: while stat a file for size: /tmp/xxxx/000000.sst: No such file or directory"" This is because the dummy AddFile4 entry generated by the new code will be treated as a real entry by an older build. The older build will think there is a real file with number 0, but there isnt such a file. Closes Differential Revision: D7730035 Pulled By: siying fbshipit-source-id: f2051859eff20ef1837575ecb1e1bb96b3751e77/make MockTimeEnv::current_time_ atomic to fix data race Summary: fix a new TSAN failure Closes Differential Revision: D7565310 Pulled By: miasantreble fbshipit-source-id: f672c96e925797b34dec6e20b59527e8eebaa825/Skip deleted WALs during recovery Summary: This patch record the deleted WAL numbers in the manifest to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic. Closes Differential Revision: D6967893 Pulled By: maysamyabandeh fbshipit-source-id: 13119feb155a08ab6d4909f437c7a750480dc8a1/"
,,0.3297,rocksdb,"Trace and Replay for RocksDB (#3837) Summary: A framework for tracing and replaying RocksDB operations. A binary trace file is created by capturing the DB operations, and it can be replayed back at the same rate using db_bench. Column-families are supported Multi-threaded tracing is supported. TraceReader and TraceWriter are exposed to the user, so that tracing to various destinations can be enabled (say, to other messaging/logging services). By default, a FileTraceReader and FileTraceWriter are implemented to capture to a file and replay from it. This is not yet ideal to be enabled in production due to large performance overhead, but it can be safely tried out in a shadow setup, say, for analyzing RocksDB operations. Currently supported DB operations: Writes: Put Merge Delete SingleDelete DeleteRange Write Reads: Get (point lookups) Pull Request resolved: Differential Revision: D7974837 Pulled By: sagar0 fbshipit-source-id: 8ec65aaf336504bc1f6ed0feae67f6ed5ef97a72/db_bench periodically dump stats to info log (#4109) Summary: give control of how often stats are printed, including jemalloc stats if enabled. Previously the default was 10 minutes so wed only see updated stats for very long benchmark runs. Pull Request resolved: Differential Revision: D8796444 Pulled By: ajkr fbshipit-source-id: fd7902fe3f105fae89322c4ab63316bba4a2b15e/run make format for PR 3838 (#3954) Summary: PR made some changes that triggers lint warnings. Run `make format` to fix formatting as suggested by siying . Also piggyback two changes: 1) fix singleton destruction order for windows and posix env 2) fix two clang warnings Closes Differential Revision: D8272041 Pulled By: miasantreble fbshipit-source-id: 7c4fd12bd17aac13534520de0c733328aa3c6c9f/Provide a way to override windows memory allocator with jemalloc for ZSTD Summary: Windows does not have LD_PRELOAD mechanism to override all memory allocation functions and ZSTD makes use of C-tuntime calloc. During flushes and compactions default system allocator fragments and the system slows down considerably. For builds with jemalloc we employ an advanced ZSTD context creation API that re-directs memory allocation to jemalloc. To reduce the cost of context creation on each block we cache ZSTD context within the block based table builder while a new SST file is being built, this will help all platform builds including those w/o jemalloc. This avoids system allocator fragmentation and improves the performance. The change does not address random reads and currently on Windows reads with ZSTD regress as compared with SNAPPY compression. Closes Differential Revision: D8229794 Pulled By: miasantreble fbshipit-source-id: 719b622ab7bf4109819bc44f45ec66f0dd3ee80d/LRUCache midpoint insertion Summary: Implement midpoint insertion strategy where new blocks will be insert to the middle of LRU list, then move the head on the first hit in cache. Closes Differential Revision: D8100895 Pulled By: yiwu-arbug fbshipit-source-id: f4bd83cb8be469e5d02072cfc8bd66011391f3da/"
,,0.3762,rocksdb,"run make format for PR 3838 (#3954) Summary: PR made some changes that triggers lint warnings. Run `make format` to fix formatting as suggested by siying . Also piggyback two changes: 1) fix singleton destruction order for windows and posix env 2) fix two clang warnings Closes Differential Revision: D8272041 Pulled By: miasantreble fbshipit-source-id: 7c4fd12bd17aac13534520de0c733328aa3c6c9f/Provide a way to override windows memory allocator with jemalloc for ZSTD Summary: Windows does not have LD_PRELOAD mechanism to override all memory allocation functions and ZSTD makes use of C-tuntime calloc. During flushes and compactions default system allocator fragments and the system slows down considerably. For builds with jemalloc we employ an advanced ZSTD context creation API that re-directs memory allocation to jemalloc. To reduce the cost of context creation on each block we cache ZSTD context within the block based table builder while a new SST file is being built, this will help all platform builds including those w/o jemalloc. This avoids system allocator fragmentation and improves the performance. The change does not address random reads and currently on Windows reads with ZSTD regress as compared with SNAPPY compression. Closes Differential Revision: D8229794 Pulled By: miasantreble fbshipit-source-id: 719b622ab7bf4109819bc44f45ec66f0dd3ee80d/Introduce library-independent default compression level Summary: Previously we were using as the default for every library, which was legacy from our zlib options. That worked for a while, but after zstd introduced it started giving poor compression ratios by default in zstd. This PR adds a constant to RocksDB public API, `CompressionOptions::kDefaultCompressionLevel`, which will get translated to the default value specific to the compression library being used in ""util/compression.h"". The constant uses a number that appears to be larger than any librarys maximum compression level. Closes Differential Revision: D8125780 Pulled By: ajkr fbshipit-source-id: 2db157a89118cd4f94577c2f4a0a5ff31c8391c6/"
,,0.1366,rocksdb,"Trace and Replay for RocksDB (#3837) Summary: A framework for tracing and replaying RocksDB operations. A binary trace file is created by capturing the DB operations, and it can be replayed back at the same rate using db_bench. Column-families are supported Multi-threaded tracing is supported. TraceReader and TraceWriter are exposed to the user, so that tracing to various destinations can be enabled (say, to other messaging/logging services). By default, a FileTraceReader and FileTraceWriter are implemented to capture to a file and replay from it. This is not yet ideal to be enabled in production due to large performance overhead, but it can be safely tried out in a shadow setup, say, for analyzing RocksDB operations. Currently supported DB operations: Writes: Put Merge Delete SingleDelete DeleteRange Write Reads: Get (point lookups) Pull Request resolved: Differential Revision: D7974837 Pulled By: sagar0 fbshipit-source-id: 8ec65aaf336504bc1f6ed0feae67f6ed5ef97a72/"
,,0.3969,rocksdb,"run make format for PR 3838 (#3954) Summary: PR made some changes that triggers lint warnings. Run `make format` to fix formatting as suggested by siying . Also piggyback two changes: 1) fix singleton destruction order for windows and posix env 2) fix two clang warnings Closes Differential Revision: D8272041 Pulled By: miasantreble fbshipit-source-id: 7c4fd12bd17aac13534520de0c733328aa3c6c9f/Provide a way to override windows memory allocator with jemalloc for ZSTD Summary: Windows does not have LD_PRELOAD mechanism to override all memory allocation functions and ZSTD makes use of C-tuntime calloc. During flushes and compactions default system allocator fragments and the system slows down considerably. For builds with jemalloc we employ an advanced ZSTD context creation API that re-directs memory allocation to jemalloc. To reduce the cost of context creation on each block we cache ZSTD context within the block based table builder while a new SST file is being built, this will help all platform builds including those w/o jemalloc. This avoids system allocator fragmentation and improves the performance. The change does not address random reads and currently on Windows reads with ZSTD regress as compared with SNAPPY compression. Closes Differential Revision: D8229794 Pulled By: miasantreble fbshipit-source-id: 719b622ab7bf4109819bc44f45ec66f0dd3ee80d/Move prefix_extractor to MutableCFOptions Summary: Currently it is not possible to change bloom filter config without restart the db, which is causing a lot of operational complexity for users. This PR aims to make it possible to dynamically change bloom filter config. Closes Differential Revision: D7253114 Pulled By: miasantreble fbshipit-source-id: f22595437d3e0b86c95918c484502de2ceca120c/"
,,0.449,rocksdb,"run make format for PR 3838 (#3954) Summary: PR made some changes that triggers lint warnings. Run `make format` to fix formatting as suggested by siying . Also piggyback two changes: 1) fix singleton destruction order for windows and posix env 2) fix two clang warnings Closes Differential Revision: D8272041 Pulled By: miasantreble fbshipit-source-id: 7c4fd12bd17aac13534520de0c733328aa3c6c9f/Provide a way to override windows memory allocator with jemalloc for ZSTD Summary: Windows does not have LD_PRELOAD mechanism to override all memory allocation functions and ZSTD makes use of C-tuntime calloc. During flushes and compactions default system allocator fragments and the system slows down considerably. For builds with jemalloc we employ an advanced ZSTD context creation API that re-directs memory allocation to jemalloc. To reduce the cost of context creation on each block we cache ZSTD context within the block based table builder while a new SST file is being built, this will help all platform builds including those w/o jemalloc. This avoids system allocator fragmentation and improves the performance. The change does not address random reads and currently on Windows reads with ZSTD regress as compared with SNAPPY compression. Closes Differential Revision: D8229794 Pulled By: miasantreble fbshipit-source-id: 719b622ab7bf4109819bc44f45ec66f0dd3ee80d/"
,,0.3651,rocksdb,"BlobDB: Can return expiration together with Get() (#4227) Summary: Add API to allow fetching expiration of a key with `Get()`. Pull Request resolved: Differential Revision: D9169897 Pulled By: yiwu-arbug fbshipit-source-id: 2a6f216c493dc75731ddcef1daa689b517fab31b/BlobDB: Cleanup TTLExtractor interface (#4229) Summary: Cleanup TTLExtractor interface. The original purpose of it is to allow our users keep using existing `Write()` interface but allow it to accept TTL via `TTLExtractor`. However the interface is confusing. Will replace it with something like `WriteWithTTL(batch, ttl)` in the future. Pull Request resolved: Differential Revision: D9174390 Pulled By: yiwu-arbug fbshipit-source-id: 68201703d784408b851336ab4dd9b84188245b2d/run make format for PR 3838 (#3954) Summary: PR made some changes that triggers lint warnings. Run `make format` to fix formatting as suggested by siying . Also piggyback two changes: 1) fix singleton destruction order for windows and posix env 2) fix two clang warnings Closes Differential Revision: D8272041 Pulled By: miasantreble fbshipit-source-id: 7c4fd12bd17aac13534520de0c733328aa3c6c9f/Provide a way to override windows memory allocator with jemalloc for ZSTD Summary: Windows does not have LD_PRELOAD mechanism to override all memory allocation functions and ZSTD makes use of C-tuntime calloc. During flushes and compactions default system allocator fragments and the system slows down considerably. For builds with jemalloc we employ an advanced ZSTD context creation API that re-directs memory allocation to jemalloc. To reduce the cost of context creation on each block we cache ZSTD context within the block based table builder while a new SST file is being built, this will help all platform builds including those w/o jemalloc. This avoids system allocator fragmentation and improves the performance. The change does not address random reads and currently on Windows reads with ZSTD regress as compared with SNAPPY compression. Closes Differential Revision: D8229794 Pulled By: miasantreble fbshipit-source-id: 719b622ab7bf4109819bc44f45ec66f0dd3ee80d/"
,,0.4551,rocksdb,"run make format for PR 3838 (#3954) Summary: PR made some changes that triggers lint warnings. Run `make format` to fix formatting as suggested by siying . Also piggyback two changes: 1) fix singleton destruction order for windows and posix env 2) fix two clang warnings Closes Differential Revision: D8272041 Pulled By: miasantreble fbshipit-source-id: 7c4fd12bd17aac13534520de0c733328aa3c6c9f/Provide a way to override windows memory allocator with jemalloc for ZSTD Summary: Windows does not have LD_PRELOAD mechanism to override all memory allocation functions and ZSTD makes use of C-tuntime calloc. During flushes and compactions default system allocator fragments and the system slows down considerably. For builds with jemalloc we employ an advanced ZSTD context creation API that re-directs memory allocation to jemalloc. To reduce the cost of context creation on each block we cache ZSTD context within the block based table builder while a new SST file is being built, this will help all platform builds including those w/o jemalloc. This avoids system allocator fragmentation and improves the performance. The change does not address random reads and currently on Windows reads with ZSTD regress as compared with SNAPPY compression. Closes Differential Revision: D8229794 Pulled By: miasantreble fbshipit-source-id: 719b622ab7bf4109819bc44f45ec66f0dd3ee80d/"
,,0.3265,rocksdb,"Index value delta encoding (#3983) Summary: Given that index value is a BlockHandle, which is basically an size> pair we can apply delta encoding on the values. The first value at each index restart interval encoded the full BlockHandle but the rest encode only the size. Refer to IndexBlockIter::DecodeCurrentValue for the detail of the encoding. This reduces the index size which helps using the block cache more efficiently. The feature is enabled with using format_version 4. The feature comes with a bit of cpu overhead which should be paid back by the higher cache hits due to smaller index block size. Results with sysbench read-only using 4k blocks and using 16 index restart interval: Format 2: 19585 rocksdb read-only range=100 Format 3: 19569 rocksdb read-only range=100 Format 4: 19352 rocksdb read-only range=100 Pull Request resolved: Differential Revision: D8361343 Pulled By: maysamyabandeh fbshipit-source-id: f882ee082322acac32b0072e2bdbb0b5f854e651/run make format for PR 3838 (#3954) Summary: PR made some changes that triggers lint warnings. Run `make format` to fix formatting as suggested by siying . Also piggyback two changes: 1) fix singleton destruction order for windows and posix env 2) fix two clang warnings Closes Differential Revision: D8272041 Pulled By: miasantreble fbshipit-source-id: 7c4fd12bd17aac13534520de0c733328aa3c6c9f/Provide a way to override windows memory allocator with jemalloc for ZSTD Summary: Windows does not have LD_PRELOAD mechanism to override all memory allocation functions and ZSTD makes use of C-tuntime calloc. During flushes and compactions default system allocator fragments and the system slows down considerably. For builds with jemalloc we employ an advanced ZSTD context creation API that re-directs memory allocation to jemalloc. To reduce the cost of context creation on each block we cache ZSTD context within the block based table builder while a new SST file is being built, this will help all platform builds including those w/o jemalloc. This avoids system allocator fragmentation and improves the performance. The change does not address random reads and currently on Windows reads with ZSTD regress as compared with SNAPPY compression. Closes Differential Revision: D8229794 Pulled By: miasantreble fbshipit-source-id: 719b622ab7bf4109819bc44f45ec66f0dd3ee80d/"
,,0.397,rocksdb,"Fix a bug caused by not copying the block trailer. (#4096) Summary: This was caught by crash test, and the following is a simple way to reproduce it and verify the fix. One way to trigger this code path is to use the following configuration: Compress SST file Enable direct IO and prefetch buffer Do NOT use compressed block cache Closes Differential Revision: D8742009 Pulled By: riversand963 fbshipit-source-id: f13381078bbb0dce92f60bd313a78ab602bcacd2/run make format for PR 3838 (#3954) Summary: PR made some changes that triggers lint warnings. Run `make format` to fix formatting as suggested by siying . Also piggyback two changes: 1) fix singleton destruction order for windows and posix env 2) fix two clang warnings Closes Differential Revision: D8272041 Pulled By: miasantreble fbshipit-source-id: 7c4fd12bd17aac13534520de0c733328aa3c6c9f/Provide a way to override windows memory allocator with jemalloc for ZSTD Summary: Windows does not have LD_PRELOAD mechanism to override all memory allocation functions and ZSTD makes use of C-tuntime calloc. During flushes and compactions default system allocator fragments and the system slows down considerably. For builds with jemalloc we employ an advanced ZSTD context creation API that re-directs memory allocation to jemalloc. To reduce the cost of context creation on each block we cache ZSTD context within the block based table builder while a new SST file is being built, this will help all platform builds including those w/o jemalloc. This avoids system allocator fragmentation and improves the performance. The change does not address random reads and currently on Windows reads with ZSTD regress as compared with SNAPPY compression. Closes Differential Revision: D8229794 Pulled By: miasantreble fbshipit-source-id: 719b622ab7bf4109819bc44f45ec66f0dd3ee80d/"
,,0.3858,rocksdb,"Provide a way to override windows memory allocator with jemalloc for ZSTD Summary: Windows does not have LD_PRELOAD mechanism to override all memory allocation functions and ZSTD makes use of C-tuntime calloc. During flushes and compactions default system allocator fragments and the system slows down considerably. For builds with jemalloc we employ an advanced ZSTD context creation API that re-directs memory allocation to jemalloc. To reduce the cost of context creation on each block we cache ZSTD context within the block based table builder while a new SST file is being built, this will help all platform builds including those w/o jemalloc. This avoids system allocator fragmentation and improves the performance. The change does not address random reads and currently on Windows reads with ZSTD regress as compared with SNAPPY compression. Closes Differential Revision: D8229794 Pulled By: miasantreble fbshipit-source-id: 719b622ab7bf4109819bc44f45ec66f0dd3ee80d/"
,,0.0862,rocksdb,Add PerfContextByLevel to provide per level perf context information (#4226) Summary: Current implementation of perf context is level agnostic. Making it hard to do performance evaluation for the LSM tree. This PR adds `PerfContextByLevel` to decompose the counters by level. This will be helpful when analyzing point and range query performance as well as tuning bloom filter Also replaced __thread with thread_local keyword for perf_context Pull Request resolved: Differential Revision: D10369509 Pulled By: miasantreble fbshipit-source-id: f1ced4e0de5fcebdb7f9cff36164516bc6382d82/
,,0.0939,rocksdb,"Lock free MultiGet (#4754) Summary: Avoid locking the DB mutex in order to reference SuperVersions. Instead, we get the thread local cached SuperVersion for each column family in the list. It depends on finding a sequence number that overlaps with all the open memtables. We start with the latest published sequence number, and if any of the memtables is sealed before we can get all the SuperVersions, the process is repeated. After a few times, give up and lock the DB mutex. Tests: 1. Unit tests 2. make check 3. db_bench TEST_TMPDIR=/dev/shm ./db_bench readrandom : 0.167 micros/op 5983920 ops/sec; 426.2 MB/s (1000000 of 1000000 found) Multireadrandom with batch size 1: multireadrandom : 0.176 micros/op 5684033 ops/sec; (1000000 of 1000000 found) Pull Request resolved: Differential Revision: D13363550 Pulled By: anand1976 fbshipit-source-id: 6243e8de7dbd9c8bb490a8eca385da0c855b1dd4/"
,,0.0977,rocksdb,"Lock free MultiGet (#4754) Summary: Avoid locking the DB mutex in order to reference SuperVersions. Instead, we get the thread local cached SuperVersion for each column family in the list. It depends on finding a sequence number that overlaps with all the open memtables. We start with the latest published sequence number, and if any of the memtables is sealed before we can get all the SuperVersions, the process is repeated. After a few times, give up and lock the DB mutex. Tests: 1. Unit tests 2. make check 3. db_bench TEST_TMPDIR=/dev/shm ./db_bench readrandom : 0.167 micros/op 5983920 ops/sec; 426.2 MB/s (1000000 of 1000000 found) Multireadrandom with batch size 1: multireadrandom : 0.176 micros/op 5684033 ops/sec; (1000000 of 1000000 found) Pull Request resolved: Differential Revision: D13363550 Pulled By: anand1976 fbshipit-source-id: 6243e8de7dbd9c8bb490a8eca385da0c855b1dd4/"
,,0.0875,rocksdb,"Lock free MultiGet (#4754) Summary: Avoid locking the DB mutex in order to reference SuperVersions. Instead, we get the thread local cached SuperVersion for each column family in the list. It depends on finding a sequence number that overlaps with all the open memtables. We start with the latest published sequence number, and if any of the memtables is sealed before we can get all the SuperVersions, the process is repeated. After a few times, give up and lock the DB mutex. Tests: 1. Unit tests 2. make check 3. db_bench TEST_TMPDIR=/dev/shm ./db_bench readrandom : 0.167 micros/op 5983920 ops/sec; 426.2 MB/s (1000000 of 1000000 found) Multireadrandom with batch size 1: multireadrandom : 0.176 micros/op 5684033 ops/sec; (1000000 of 1000000 found) Pull Request resolved: Differential Revision: D13363550 Pulled By: anand1976 fbshipit-source-id: 6243e8de7dbd9c8bb490a8eca385da0c855b1dd4/"
,,0.1197,rocksdb,Apply modernize-use-override (2nd iteration) Summary: Use C++11ís override and remove virtual where applicable. Change are automatically generated. Reviewed By: Orvid Differential Revision: D14090024 fbshipit-source-id: 1e9432e87d2657e1ff0028e15370a85d1739ba2a/
,,0.1178,rocksdb,Apply modernize-use-override (2nd iteration) Summary: Use C++11ís override and remove virtual where applicable. Change are automatically generated. Reviewed By: Orvid Differential Revision: D14090024 fbshipit-source-id: 1e9432e87d2657e1ff0028e15370a85d1739ba2a/
,,0.1034,rocksdb,Apply modernize-use-override (3) Summary: Use C++11ís override and remove virtual where applicable. Change are automatically generated. bypass-lint drop-conflicts Reviewed By: igorsugak Differential Revision: D14131816 fbshipit-source-id: f20e7f7cecf2e699d70f5fa036f72c0e3f59b50e/
,,0.3878,rocksdb,"WriteUnPrepared: fix ubsan complaint (#5148) Summary: Ubsna complains that in initialization of WriteUnpreparedTxnReadCallback the method of the child class is used before the parent class is constructed. The patch fixes that by making the aforementioned method static. Pull Request resolved: Differential Revision: D14760098 Pulled By: maysamyabandeh fbshipit-source-id: cf19b7c1fdb5de0a54e62c1deebe09a0fa048ded/WriteUnPrepared: less virtual in iterator callback (#5049) Summary: WriteUnPrepared adds a virtual function, MaxUnpreparedSequenceNumber, to ReadCallback, which returns 0 unless WriteUnPrepared is enabled and the transaction has uncommitted data written to the DB. Together with snapshot sequence number, this determines the last sequence that is visible to reads. The patch clarifies the guarantees of the GetIterator API in WriteUnPrepared transactions and make use of that to statically initialize the read callback and thus avoid the virtual call. Furthermore it increases the minimum value for min_uncommitted from 0 to 1 as seq 0 is used only for last level keys that are committed in all snapshots. The following benchmark shows +0.26% higher throughput in seekrandom benchmark. Benchmark: ./db_bench ./db_bench seekrandom [AVG 10 runs] : 20355 ops/sec; 225.2 MB/sec seekrandom [MEDIAN 10 runs] : 20425 ops/sec; 225.9 MB/sec ./db_bench_lessvirtual3 seekrandom [AVG 10 runs] : 20409 ops/sec; 225.8 MB/sec seekrandom [MEDIAN 10 runs] : 20487 ops/sec; 226.6 MB/sec Pull Request resolved: Differential Revision: D14366459 Pulled By: maysamyabandeh fbshipit-source-id: ebaff8908332a5ae9af7defeadabcb624be660ef/WritePrepared: optimize read path by avoiding virtual (#5018) Summary: The read path includes a callback function, ReadCallback, which would eventually calls IsInSnapshot to figure if a particular seq is in the reading snapshot or not. This callback is virtual, which adds the cost of multiple virtual function call to each read. The first few checks in IsInSnapshot, however, are quite trivial and take care of majority of the cases. The patch moves those to a non-virtual function in the the parent class, ReadCallback, to lower the virtual callback cost. Pull Request resolved: Differential Revision: D14226562 Pulled By: maysamyabandeh fbshipit-source-id: 6feed5b34f3b082e52092c5ef143e29b49c46b44/"
,,0.3414,rocksdb,"WriteUnPrepared: less virtual in iterator callback (#5049) Summary: WriteUnPrepared adds a virtual function, MaxUnpreparedSequenceNumber, to ReadCallback, which returns 0 unless WriteUnPrepared is enabled and the transaction has uncommitted data written to the DB. Together with snapshot sequence number, this determines the last sequence that is visible to reads. The patch clarifies the guarantees of the GetIterator API in WriteUnPrepared transactions and make use of that to statically initialize the read callback and thus avoid the virtual call. Furthermore it increases the minimum value for min_uncommitted from 0 to 1 as seq 0 is used only for last level keys that are committed in all snapshots. The following benchmark shows +0.26% higher throughput in seekrandom benchmark. Benchmark: ./db_bench ./db_bench seekrandom [AVG 10 runs] : 20355 ops/sec; 225.2 MB/sec seekrandom [MEDIAN 10 runs] : 20425 ops/sec; 225.9 MB/sec ./db_bench_lessvirtual3 seekrandom [AVG 10 runs] : 20409 ops/sec; 225.8 MB/sec seekrandom [MEDIAN 10 runs] : 20487 ops/sec; 226.6 MB/sec Pull Request resolved: Differential Revision: D14366459 Pulled By: maysamyabandeh fbshipit-source-id: ebaff8908332a5ae9af7defeadabcb624be660ef/"
,,0.3994,rocksdb,"WriteUnPrepared: less virtual in iterator callback (#5049) Summary: WriteUnPrepared adds a virtual function, MaxUnpreparedSequenceNumber, to ReadCallback, which returns 0 unless WriteUnPrepared is enabled and the transaction has uncommitted data written to the DB. Together with snapshot sequence number, this determines the last sequence that is visible to reads. The patch clarifies the guarantees of the GetIterator API in WriteUnPrepared transactions and make use of that to statically initialize the read callback and thus avoid the virtual call. Furthermore it increases the minimum value for min_uncommitted from 0 to 1 as seq 0 is used only for last level keys that are committed in all snapshots. The following benchmark shows +0.26% higher throughput in seekrandom benchmark. Benchmark: ./db_bench ./db_bench seekrandom [AVG 10 runs] : 20355 ops/sec; 225.2 MB/sec seekrandom [MEDIAN 10 runs] : 20425 ops/sec; 225.9 MB/sec ./db_bench_lessvirtual3 seekrandom [AVG 10 runs] : 20409 ops/sec; 225.8 MB/sec seekrandom [MEDIAN 10 runs] : 20487 ops/sec; 226.6 MB/sec Pull Request resolved: Differential Revision: D14366459 Pulled By: maysamyabandeh fbshipit-source-id: ebaff8908332a5ae9af7defeadabcb624be660ef/WriteUnPrepared: Enable auto-compaction after max_evicted_seq_ init (#5128) Summary: Compaction would depend on max_evicted_seq_ value. The ::Initialize method should do that after max_evicted_seq_ is properly initialized. The patch also back ports from WritePrepared txn to WriteUnPrepared. Pull Request resolved: Differential Revision: D14686562 Pulled By: maysamyabandeh fbshipit-source-id: b2355025712a72676ac3b20a95258adcf4774490/WritePrepared: optimize read path by avoiding virtual (#5018) Summary: The read path includes a callback function, ReadCallback, which would eventually calls IsInSnapshot to figure if a particular seq is in the reading snapshot or not. This callback is virtual, which adds the cost of multiple virtual function call to each read. The first few checks in IsInSnapshot, however, are quite trivial and take care of majority of the cases. The patch moves those to a non-virtual function in the the parent class, ReadCallback, to lower the virtual callback cost. Pull Request resolved: Differential Revision: D14226562 Pulled By: maysamyabandeh fbshipit-source-id: 6feed5b34f3b082e52092c5ef143e29b49c46b44/Apply modernize-use-override (2nd iteration) Summary: Use C++11ís override and remove virtual where applicable. Change are automatically generated. Reviewed By: Orvid Differential Revision: D14090024 fbshipit-source-id: 1e9432e87d2657e1ff0028e15370a85d1739ba2a/"
,,0.3579,rocksdb,"WritePrepared: fix race condition in reading batch with duplicate keys (#5147) Summary: When ReadOption doesnt specify a snapshot, WritePrepared::Get used kMaxSequenceNumber to avoid the cost of creating a new snapshot object (that requires sync over db_mutex). This creates a race condition if it is reading from the writes of a transaction that had duplicate keys: each instance of duplicate key is inserted with a different sequence number and depending on the ordering the ::Get might skip the newer one and read the older one that is obsolete. The patch fixes that by using last published seq as the snapshot sequence number. It also adds a check after the read is done to ensure that the max_evicted_seq has not advanced the aforementioned seq, which is a very unlikely event. If it did, then the read is not valid since the seq is not backed by an actually snapshot to let IsInSnapshot handle that properly when an overlapping commit is evicted from commit cache. A unit test is added to reproduce the race condition with duplicate keys. Pull Request resolved: Differential Revision: D14758815 Pulled By: maysamyabandeh fbshipit-source-id: a56915657132cf6ba5e3f5ea1b5d78c803407719/WriteUnPrepared: less virtual in iterator callback (#5049) Summary: WriteUnPrepared adds a virtual function, MaxUnpreparedSequenceNumber, to ReadCallback, which returns 0 unless WriteUnPrepared is enabled and the transaction has uncommitted data written to the DB. Together with snapshot sequence number, this determines the last sequence that is visible to reads. The patch clarifies the guarantees of the GetIterator API in WriteUnPrepared transactions and make use of that to statically initialize the read callback and thus avoid the virtual call. Furthermore it increases the minimum value for min_uncommitted from 0 to 1 as seq 0 is used only for last level keys that are committed in all snapshots. The following benchmark shows +0.26% higher throughput in seekrandom benchmark. Benchmark: ./db_bench ./db_bench seekrandom [AVG 10 runs] : 20355 ops/sec; 225.2 MB/sec seekrandom [MEDIAN 10 runs] : 20425 ops/sec; 225.9 MB/sec ./db_bench_lessvirtual3 seekrandom [AVG 10 runs] : 20409 ops/sec; 225.8 MB/sec seekrandom [MEDIAN 10 runs] : 20487 ops/sec; 226.6 MB/sec Pull Request resolved: Differential Revision: D14366459 Pulled By: maysamyabandeh fbshipit-source-id: ebaff8908332a5ae9af7defeadabcb624be660ef/WritePrepared: optimize read path by avoiding virtual (#5018) Summary: The read path includes a callback function, ReadCallback, which would eventually calls IsInSnapshot to figure if a particular seq is in the reading snapshot or not. This callback is virtual, which adds the cost of multiple virtual function call to each read. The first few checks in IsInSnapshot, however, are quite trivial and take care of majority of the cases. The patch moves those to a non-virtual function in the the parent class, ReadCallback, to lower the virtual callback cost. Pull Request resolved: Differential Revision: D14226562 Pulled By: maysamyabandeh fbshipit-source-id: 6feed5b34f3b082e52092c5ef143e29b49c46b44/Apply modernize-use-override (2nd iteration) Summary: Use C++11ís override and remove virtual where applicable. Change are automatically generated. Reviewed By: Orvid Differential Revision: D14090024 fbshipit-source-id: 1e9432e87d2657e1ff0028e15370a85d1739ba2a/"
,,0.1197,rocksdb,Apply modernize-use-override (2nd iteration) Summary: Use C++11ís override and remove virtual where applicable. Change are automatically generated. Reviewed By: Orvid Differential Revision: D14090024 fbshipit-source-id: 1e9432e87d2657e1ff0028e15370a85d1739ba2a/
,,0.4209,rocksdb,"WriteUnPrepared: less virtual in iterator callback (#5049) Summary: WriteUnPrepared adds a virtual function, MaxUnpreparedSequenceNumber, to ReadCallback, which returns 0 unless WriteUnPrepared is enabled and the transaction has uncommitted data written to the DB. Together with snapshot sequence number, this determines the last sequence that is visible to reads. The patch clarifies the guarantees of the GetIterator API in WriteUnPrepared transactions and make use of that to statically initialize the read callback and thus avoid the virtual call. Furthermore it increases the minimum value for min_uncommitted from 0 to 1 as seq 0 is used only for last level keys that are committed in all snapshots. The following benchmark shows +0.26% higher throughput in seekrandom benchmark. Benchmark: ./db_bench ./db_bench seekrandom [AVG 10 runs] : 20355 ops/sec; 225.2 MB/sec seekrandom [MEDIAN 10 runs] : 20425 ops/sec; 225.9 MB/sec ./db_bench_lessvirtual3 seekrandom [AVG 10 runs] : 20409 ops/sec; 225.8 MB/sec seekrandom [MEDIAN 10 runs] : 20487 ops/sec; 226.6 MB/sec Pull Request resolved: Differential Revision: D14366459 Pulled By: maysamyabandeh fbshipit-source-id: ebaff8908332a5ae9af7defeadabcb624be660ef/WritePrepared: optimize read path by avoiding virtual (#5018) Summary: The read path includes a callback function, ReadCallback, which would eventually calls IsInSnapshot to figure if a particular seq is in the reading snapshot or not. This callback is virtual, which adds the cost of multiple virtual function call to each read. The first few checks in IsInSnapshot, however, are quite trivial and take care of majority of the cases. The patch moves those to a non-virtual function in the the parent class, ReadCallback, to lower the virtual callback cost. Pull Request resolved: Differential Revision: D14226562 Pulled By: maysamyabandeh fbshipit-source-id: 6feed5b34f3b082e52092c5ef143e29b49c46b44/"
,,0.1121,rocksdb,Apply modernize-use-override (2nd iteration) Summary: Use C++11ís override and remove virtual where applicable. Change are automatically generated. Reviewed By: Orvid Differential Revision: D14090024 fbshipit-source-id: 1e9432e87d2657e1ff0028e15370a85d1739ba2a/
,,0.1078,rocksdb,"add whole key bloom filter support in memtables (#4985) Summary: MyRocks calls `GetForUpdate` on `INSERT`, for unique key check, and in almost all cases GetForUpdate returns empty result. For such cases, whole key bloom filter is helpful. Pull Request resolved: Differential Revision: D14118257 Pulled By: miasantreble fbshipit-source-id: d35cb7109c62fd5ad541a26968e3a3e16d3e85ea/Apply modernize-use-override (2nd iteration) Summary: Use C++11ís override and remove virtual where applicable. Change are automatically generated. Reviewed By: Orvid Differential Revision: D14090024 fbshipit-source-id: 1e9432e87d2657e1ff0028e15370a85d1739ba2a/"
,,0.1814,rocksdb,"DBIter::Next() can skip user key checking if previous entrys seqnum is 0 (#5244) Summary: Right now, DBIter::Next() always checks whether an entry is for the same user key as the previous entry to see whether the key should be hidden to the user. However, if previous entrys sequence number is 0, the check is not needed because 0 is the oldest possible sequence number. We could extend it from seqnum 0 case to simply prev_seqno >= current_seqno. However, it is less robust with bug or unexpected situations, while the gain is relatively low. We can always extend it later when needed. In a readseq benchmark with full formed LSM-tree, number of key comparisons called is reduced from 2.981 to 2.165. readseq against a fully compacted DB, no key comparison is called. Performance in this benchmark didnt show obvious improvement, which is expected because key comparisons only takes small percentage of CPU. But it may show up to be more effective if users have an expensive customized comparator. Pull Request resolved: Differential Revision: D15067257 Pulled By: siying fbshipit-source-id: b7e1ef3ec4fa928cba509683d2b3246e35d270d9/DBIter to use IteratorWrapper for inner iterator (#5214) Summary: Its hard to get DBIter to directly use InternalIterator::NextAndGetResult() because the code change would be complicated. Instead, use IteratorWrapper, where Next() is already using NextAndGetResult(). Performance number is hard to measure because it is small and ther is variation. I run readseq many times, and there seems to be 1% gain. Pull Request resolved: Differential Revision: D15003635 Pulled By: siying fbshipit-source-id: 17af1965c409c2fe90cd85037fbd2c5a1364f82a/WriteUnPrepared: less virtual in iterator callback (#5049) Summary: WriteUnPrepared adds a virtual function, MaxUnpreparedSequenceNumber, to ReadCallback, which returns 0 unless WriteUnPrepared is enabled and the transaction has uncommitted data written to the DB. Together with snapshot sequence number, this determines the last sequence that is visible to reads. The patch clarifies the guarantees of the GetIterator API in WriteUnPrepared transactions and make use of that to statically initialize the read callback and thus avoid the virtual call. Furthermore it increases the minimum value for min_uncommitted from 0 to 1 as seq 0 is used only for last level keys that are committed in all snapshots. The following benchmark shows +0.26% higher throughput in seekrandom benchmark. Benchmark: ./db_bench ./db_bench seekrandom [AVG 10 runs] : 20355 ops/sec; 225.2 MB/sec seekrandom [MEDIAN 10 runs] : 20425 ops/sec; 225.9 MB/sec ./db_bench_lessvirtual3 seekrandom [AVG 10 runs] : 20409 ops/sec; 225.8 MB/sec seekrandom [MEDIAN 10 runs] : 20487 ops/sec; 226.6 MB/sec Pull Request resolved: Differential Revision: D14366459 Pulled By: maysamyabandeh fbshipit-source-id: ebaff8908332a5ae9af7defeadabcb624be660ef/Fix perf_context.user_key_comparison_count for range scan (#5098) Summary: Currently `perf_context.user_key_comparison_count` is bump only in `InternalKeyComparator`. For places user comparator is used directly the counter is not bump. Fixing the majority of it. Index iterator and filter code also use user comparator directly and dont bump the counter. It is not fixed in this patch. Pull Request resolved: Differential Revision: D14603753 Pulled By: siying fbshipit-source-id: 1cd41035644ca9e49b97a51030a5d1e15f5f3cae/Introduce CPU timers for iterator seek and next (#5076) Summary: Introduce CPU timers for iterator seek and next operations. Seek counter includes SeekToFirst, SeekToLast and SeekForPrev, w/ the caveat that SeekToLast timer doesnt include some post processing time if upper bound is defined. Pull Request resolved: Differential Revision: D14525218 Pulled By: fredfsh fbshipit-source-id: 03ba25df3b22b06c072621e4de0eacfa1445f0d9/Reorder DBIter fields to reduce memory usage (#5078) Summary: The patch reorders DBIter fields to put 1-byte fields together and let the compiler optimize the memory usage by using less 64-bit allocations for bools and enums. This might have a negative side effect of putting the variables that are accessed together into different cache lines and hence increasing the cache misses. Not sure what benchmark would verify that thought. I ran simple, single-threaded seekrandom benchmarks but the variance in the results is too much to be conclusive. ./db_bench ./db_bench Pull Request resolved: Differential Revision: D14562676 Pulled By: maysamyabandeh fbshipit-source-id: 2284655d46e079b6e9a860e94be5defb6f482167/"
,,0.23199999999999998,rocksdb,"Merging iterator to avoid child iterator reseek for some cases (#5286) Summary: When reseek happens in merging iterator, reseeking a child iterator can be avoided if: (1) the iterator represents imutable data (2) reseek() to a larger key than the current key (3) the current key of the child iterator is larger than the seek key because it is guaranteed that the result will fall into the same position. This optimization will be useful for use cases where users keep seeking to keys nearby in ascending order. Pull Request resolved: Differential Revision: D15283635 Pulled By: siying fbshipit-source-id: 35f79ffd5ce3609146faa8cd55f2bfd733502f83/WriteUnPrepared: less virtual in iterator callback (#5049) Summary: WriteUnPrepared adds a virtual function, MaxUnpreparedSequenceNumber, to ReadCallback, which returns 0 unless WriteUnPrepared is enabled and the transaction has uncommitted data written to the DB. Together with snapshot sequence number, this determines the last sequence that is visible to reads. The patch clarifies the guarantees of the GetIterator API in WriteUnPrepared transactions and make use of that to statically initialize the read callback and thus avoid the virtual call. Furthermore it increases the minimum value for min_uncommitted from 0 to 1 as seq 0 is used only for last level keys that are committed in all snapshots. The following benchmark shows +0.26% higher throughput in seekrandom benchmark. Benchmark: ./db_bench ./db_bench seekrandom [AVG 10 runs] : 20355 ops/sec; 225.2 MB/sec seekrandom [MEDIAN 10 runs] : 20425 ops/sec; 225.9 MB/sec ./db_bench_lessvirtual3 seekrandom [AVG 10 runs] : 20409 ops/sec; 225.8 MB/sec seekrandom [MEDIAN 10 runs] : 20487 ops/sec; 226.6 MB/sec Pull Request resolved: Differential Revision: D14366459 Pulled By: maysamyabandeh fbshipit-source-id: ebaff8908332a5ae9af7defeadabcb624be660ef/Revert ""Avoid per-key upper bound check in BlockBasedTableIterator (#5101)"" (#5132) Summary: This reverts commit f29dc1b90641e7f44b14f932e3866c5840391cd5. In BlockBasedTableIterator, index_iter_->key() is sometimes a user key, so it is wrong to call ExtractUserKey() against it. This is a bug introduced by Temporarily revert the diff to keep the branch clean. Pull Request resolved: Differential Revision: D14718584 Pulled By: siying fbshipit-source-id: 0ac55dc9b5dbc18c7809092146bdf7eb9364b9ad/Avoid per-key upper bound check in BlockBasedTableIterator (#5101) Summary: `BlockBasedTableIterator` avoid reading next block on `Next()` if it detects the iterator will be out of bound, by checking against index key. The optimization was added in and by the time it only check the bound per block. It seems later change make it a per-key check, which introduce unnecessary key comparisons. Pull Request resolved: Differential Revision: D14678707 Pulled By: siying fbshipit-source-id: 2372446116753c7892ea4cec7b4b49ef87ba463e/Apply modernize-use-override (2nd iteration) Summary: Use C++11ís override and remove virtual where applicable. Change are automatically generated. Reviewed By: Orvid Differential Revision: D14090024 fbshipit-source-id: 1e9432e87d2657e1ff0028e15370a85d1739ba2a/"
,,0.1034,rocksdb,Apply modernize-use-override (3) Summary: Use C++11ís override and remove virtual where applicable. Change are automatically generated. bypass-lint drop-conflicts Reviewed By: igorsugak Differential Revision: D14131816 fbshipit-source-id: f20e7f7cecf2e699d70f5fa036f72c0e3f59b50e/
,,0.1044,rocksdb,"Log replay integration for secondary instance (#5305) Summary: RocksDB secondary can replay both MANIFEST and WAL now. On the one hand, the memory usage by memtables will grow after replaying WAL for sometime. On the other hand, replaying the MANIFEST can bring the database persistent data to a more recent point in time, giving us the opportunity to discard some memtables containing out-dated data. This PR coordinates the MANIFEST and WAL replay, using the updates from MANIFEST replay to update the active memtable and immutable memtable list of each column family. Pull Request resolved: Differential Revision: D15386512 Pulled By: riversand963 fbshipit-source-id: a3ea6fc415f8382d8cf624f52a71ebdcffa3e355/"
,,0.1332,rocksdb,"Prevent an incompatible combination of options (#6254) Summary: allow_concurrent_memtable_write is incompatible with non-zero max_successive_merges. Although we check this at runtime, we currently dont prevent the user from setting this combination in options. This has led to stress tests to fail with this combination is tried in ::SetOptions. The patch fixes that. Pull Request resolved: Differential Revision: D19265819 Pulled By: maysamyabandeh fbshipit-source-id: 47f2e2dc26fe0972c7152f4da15dadb9703f1179/"
,,0.1299,rocksdb,"Prevent an incompatible combination of options (#6254) Summary: allow_concurrent_memtable_write is incompatible with non-zero max_successive_merges. Although we check this at runtime, we currently dont prevent the user from setting this combination in options. This has led to stress tests to fail with this combination is tried in ::SetOptions. The patch fixes that. Pull Request resolved: Differential Revision: D19265819 Pulled By: maysamyabandeh fbshipit-source-id: 47f2e2dc26fe0972c7152f4da15dadb9703f1179/"
,,0.1299,rocksdb,"Prevent an incompatible combination of options (#6254) Summary: allow_concurrent_memtable_write is incompatible with non-zero max_successive_merges. Although we check this at runtime, we currently dont prevent the user from setting this combination in options. This has led to stress tests to fail with this combination is tried in ::SetOptions. The patch fixes that. Pull Request resolved: Differential Revision: D19265819 Pulled By: maysamyabandeh fbshipit-source-id: 47f2e2dc26fe0972c7152f4da15dadb9703f1179/"
,,0.1315,rocksdb,"Prevent an incompatible combination of options (#6254) Summary: allow_concurrent_memtable_write is incompatible with non-zero max_successive_merges. Although we check this at runtime, we currently dont prevent the user from setting this combination in options. This has led to stress tests to fail with this combination is tried in ::SetOptions. The patch fixes that. Pull Request resolved: Differential Revision: D19265819 Pulled By: maysamyabandeh fbshipit-source-id: 47f2e2dc26fe0972c7152f4da15dadb9703f1179/"
