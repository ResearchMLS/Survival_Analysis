Topic_no,Keywords,Contrib,System,Text
11,"summary, error, rocksdb, pull_request, fix, warning, differential_revision, build, size, implementation, memory, variable, make, include, write, hash, compiles_reviewer, version, fail, test_plan",0.066,Frostwire,[android] Avoid internal NPE in android BitmapFactory#decodeFile/
,,0.0967,Frostwire,[desktop] verbose error output in case a binary cant be loaded (does not include jlibtorrent)/
,,0.1063,Frostwire,[desktop] verbose error output in case a binary cant be loaded (does not include jlibtorrent)/
,,0.0891,Frostwire,[desktop] verbose error output in case a binary cant be loaded (does not include jlibtorrent)/
,,0.0872,Frostwire,[desktop] verbose error output in case a binary cant be loaded (does not include jlibtorrent)/
,,0.0948,Frostwire,[desktop] verbose error output in case a binary cant be loaded (does not include jlibtorrent)/
,,0.0677,Frostwire,[android] refactor in GeneralWizardPage and minor string translation fix/
,,0.0744,Frostwire,[android] NPE on EngineBroadcastReceiver::reopenNetworkSockets. Error wording clarification/
,,0.0838,Frostwire,[android] remove stack-overflow causing brainfart on YesNoDialog/[android] better fix for YesNoDialog clicklisteners/[android] Bug fix handling YesNoDialogs without positive or negative custom listeners/
,,0.0697,Frostwire,[desktop] bug loading SystemUtilities.dll on windows 64 (no longer called SystemUtilitiesX64.dll)/
,,0.071,OpenDDS,Merge pull request from objectcomputing/ipv6_updates Fix issues with IPV6 enabled builds on Windows./
,,0.1085,OpenDDS,"Merge pull request from mitza-oci/master Added ACE includes to fix static linking problem, needed template instantiations/Added ACE includes to fix static linking problem, needed template instantiations/"
,,0.0798,OpenDDS,Merge pull request from huangminghuang/RcHandle_fix Some fixes for RcHandle/Fix JNI compile errors/
,,0.0802,OpenDDS,Merge branch security of github.com:objectcomputing/OpenDDS into security (resolving a few conflicts / compile errors)/fixed a unit test for RTPS flags change/
,,0.0566,pljava,Testcase covering bug
,,0.0609,pljava,Testcase covering bug
,,0.0588,pljava,Bugfix 1011181: PL/Java fails to compile with
,,0.0915,realm-java,small update in error-text for Windows/Updated error-msg when we cant find the jni lib/Better Error message when lib cant be loaded./Fixed library path configuration (issue
,,0.0789,realm-java,Merge pull request from realm/ez-findbugs-hunt Add support for Findbugs and fix the issues found/Add support for Findbugs and fix the issues found/
,,0.2665,rocksdb,"Fix TransactionLogIterator EOF caching Summary: When TransactionLogIterator comes to EOF, it calls UnmarkEOF and continues reading. However, if glibc cached the EOF status of the file, it will get EOF again, even though the new data might have been written to it. This has been causing errors in Mac OS. Test Plan: test passes, was failing before Reviewers: dhruba, haobo, sdong Reviewed By: haobo CC: leveldb Differential Revision: a compile error which tries to check whether a size_t 0 in env_posix.cc Summary: Fixed a compile error which tries to check whether a size_t 0 in env_posix.cc util/env_posix.cc:180:16: error: comparison of unsigned expression 0 is always false [-Werror,-Wtautological-compare] } while (r 0 && errno EINTR); ~ ^ ~ 1 error generated. Test Plan: make check all Reviewers: igor, haobo Reviewed By: igor CC: leveldb Differential Revision: compile issue in Mac OS Summary: Compile issues are: * Unused variable env_ * Unused fallocate_with_keep_size_ Test Plan: compiles Reviewers: dhruba, haobo, sdong Reviewed By: dhruba CC: leveldb Differential Revision: fallocation Summary: Based on my recent findings (posted in our internal group), if we use fallocate without KEEP_SIZE flag, we get superior performance of fdatasync() in append-only workloads. This diff provides an option for user to not use KEEP_SIZE flag, thus optimizing his sync performance by up to 2x-3x. At one point we also just called posix_fallocate instead of fallocate, which isnt very fast: (tl;dr it manually writes out zero bytes to allocate storage). This diff also fixes that, by first calling fallocate and then posix_fallocate if fallocate is not supported. Test Plan: make check Reviewers: dhruba, sdong, haobo, ljin Reviewed By: dhruba CC: leveldb Differential Revision: pull request from yumiOS/modify_ftruncate_warning Modify the compile error about ftruncate()/Modify the compile error about ftruncate() Summary: Change to store the return value from ftruncate(). The reason is that ftruncate() has ""warn_unused_result"" attribute in some environment. Signed-off-by: Yumikiyo Osanai"
,,0.1616,rocksdb,"[fix] SIGSEGV when VersionEdit in MANIFEST is corrupted Summary: This was reported by our customers in task Cause: * MANIFEST file contains a VersionEdit, which contains file entries whose smallest and largest internal keys are empty. String with zero characters. Root cause of corruption was not investigated. We should report corruption when this happens. However, we currently SIGSEGV. Heres what happens: * VersionEdit encodes zero-strings happily and stores them in smallest and largest InternalKeys. InternalKey::Encode() does assert when `rep_.empty()`, but we dont assert in production environemnts. Also, we should never assert as a result of DB corruption. * As part of our ConsistencyCheck, we call GetLiveFilesMetaData() * GetLiveFilesMetadata() calls `file->largest.user_key().ToString()` * user_key() function does: 1. assert(size > 8) (ooops, no assert), 2. returns `Slice(internal_key.data(), internal_key.size() 8)` * since `internal_key.size()` is unsigned int, this call translates to `Slice(whatever, 1298471928561892576182756)`. Bazinga. Fix: * VersionEdit checks if InternalKey is valid in `VersionEdit::GetInternalKey()`. If its invalid, returns corruption. Lessons learned: * Always keep in mind that even if you `assert()`, production code will continue execution even if assert fails. * Never `assert` based on DB corruption. Assert only if the code should guarantee that assert cant fail. Test Plan: dumped offending manifest. Before: assert. Now: corruption Reviewers: dhruba, haobo, sdong Reviewed By: dhruba CC: leveldb Differential Revision: store version number in MANIFEST Summary: Talked to internal project name> folks and they found it really scary that they wont be able to roll back once they upgrade to 2.8. We should fix this. Test Plan: make check Reviewers: haobo, ljin Reviewed By: ljin CC: leveldb Differential Revision: the log_number check in Recover() Summary: There is a chance that an old MANIFEST is corrupted in 2.7 but just not noticed. This check would fail them. Change it to log instead of returning a Corruption status. Test Plan: make Reviewers: haobo, igor Reviewed By: igor CC: leveldb Differential Revision: bug in VersionEdit::DebugString()/Add MaxColumnFamily to VersionEdit::DebugString()/"
,,0.0588,rocksdb,Arc lint fixes/Fix build/
,,0.0556,rocksdb,Fix compile/
,,0.2816,rocksdb,"Turn on and fix all the errors Summary: We need to turn on for mobile. See D1671432 (internal phabricator) for details. This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables. Test Plan: compiles Reviewers: ljin, rven, yhchiang, sdong Reviewed By: yhchiang Subscribers: bobbaldwin, dhruba, leveldb Differential Revision: SIGSEGV in db_stresS/Fix for tools Summary: Previously I made `make check` work with but there are some tools that are not compiled using `make check`. Test Plan: make all Reviewers: yhchiang, rven, ljin, sdong Reviewed By: ljin, sdong Subscribers: dhruba, leveldb Differential Revision: for dynamic options Summary: Allow SetOptions() during db_stress test Test Plan: make crash_test Reviewers: sdong, yhchiang, rven, igor Reviewed By: igor Subscribers: leveldb Differential Revision:"
,,0.314,rocksdb,"Turn on and fix all the errors Summary: We need to turn on for mobile. See D1671432 (internal phabricator) for details. This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables. Test Plan: compiles Reviewers: ljin, rven, yhchiang, sdong Reviewed By: yhchiang Subscribers: bobbaldwin, dhruba, leveldb Differential Revision:"
,,0.3218,rocksdb,"Turn on and fix all the errors Summary: We need to turn on for mobile. See D1671432 (internal phabricator) for details. This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables. Test Plan: compiles Reviewers: ljin, rven, yhchiang, sdong Reviewed By: yhchiang Subscribers: bobbaldwin, dhruba, leveldb Differential Revision:"
,,0.2697,rocksdb,"Turn on and fix all the errors Summary: We need to turn on for mobile. See D1671432 (internal phabricator) for details. This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables. Test Plan: compiles Reviewers: ljin, rven, yhchiang, sdong Reviewed By: yhchiang Subscribers: bobbaldwin, dhruba, leveldb Differential Revision: var to suppress compiler warning/error Summary: Revmoed this in D25641, causing compiler complain. put it back Test Plan: make release Reviewers: igor, yhchiang, rven, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: conflict in java/Makefile/Fix timing/limit max bytes that can be read/written per pread/write syscall Summary: BlockBasedTable sst file size can grow to a large size when universal compaction is used. When index block exceeds 2G, pread seems to fail and return truncated data and causes ""trucated block"" error. I tried to use ``` _FILE_OFFSET_BITS 64 ``` But the problem still persists. Splitting a big write/read into smaller batches seems to solve the problem. Test Plan: successfully compacted a case with resulting sst file at ~90G (2.1G index block size) Reviewers: yhchiang, igor, sdong Reviewed By: sdong Subscribers: leveldb Differential Revision: assertion in PosixRandomAccessFile Summary: See Also see this: Test Plan: compiles Reviewers: yhchiang, ljin, sdong Reviewed By: ljin Subscribers: leveldb Differential Revision: pull request from bbiao/master fix compile error under Mac OS X/fix compile error under Mac OS X/"
,,0.3296,rocksdb,"Merge pull request from fyrz/32BitRocksJavaBug 32 Bit RocksJava Fix for overflowing jlongs/32-Bit RocksJava resolution for jlong overflows Summary: This pull request solves the jlong overflow problem on 32-Bit machines as described in 1. There is a new org.rocksdb.test.PlatformRandomHelper to assist in getting random values. For 32 Bit the getLong method is overriden by xpromaches code above. For 64 Bit it behaves as is. 2. The detection should be cross-platform (Windows is supported though it is not ported completely yet). 3. Every JNI method which sets jlong values must check if the value fits into size_t. If it overflows size_t a InvalidArgument Status object will be returned. If its ok a OK Status will be returned. 4. Setters which have this check will throw a RocksDBException if its no OK Status. Additionally some other parts of code were corrected using the wrong type casts. Test Plan: make rocksdbjava make jtest Differential Revision: Fix compile error on DbBenchmark.java Summary: Fix compile error on DbBenchmark.java Test Plan: make rocksdbjava make jdb_bench/[Java] Include WriteBatch into RocksDBSample.java, fix how DbBenchmark.java handles WriteBatch. Summary: Include WriteBatch into RocksDBSample.java, fix how DbBenchmark.java handles WriteBatch. Previously DbBenchmark.java does not use WriteBatch when benchmarks is set to fillbatch. Test Plan: make rocksdbjava make jtest make jdb_bench cd java ./jdb_bench.sh Reviewers: naveenatceg, ljin, sdong, ankgup87 Reviewed By: ankgup87 Subscribers: leveldb Differential Revision:"
,,0.3025,rocksdb,[RocksJava] JavaDoc cleanup warnings with Java8 Java8 is more restrictive than Java7 with generating JavaDocs. This commit resolves current existing Java8 warnings./Merge pull request from EugenePig/java8 suppress JDK8 errors for JDK8 errors for Hardening RocksIterator RocksIterator will sometimes Sigsegv on dispose. Mainly thats related to dispose order. If the related RocksDB instance is freed beforehand RocksIterator.dispose() will fail. Within this commit there is a major change to RocksIterator. RocksIterator will hold a private reference to the RocksDB instance which created the RocksIterator. So even if RocksDB is freed in the same GC cycle the RocksIterator instances will be freed prior to related RocksDB instances. Another aspect targets the dispose logic if the RocksDB is freed previously and already gc`ed. On dispose of a RocksIterator the dispose logic will check if the RocksDB instance points to an initialized DB. If not the dispose logic will not perform any further action. The crash can be reproduced by using the related test provided within this commit. Related information: This relates to facebook rocksdb-dev group post about SigSegv on RocksIterator.dispose()./
,,0.4046,rocksdb,"[RocksJava] JavaDoc cleanup warnings with Java8 Java8 is more restrictive than Java7 with generating JavaDocs. This commit resolves current existing Java8 warnings./Merge pull request from EugenePig/java8 suppress JDK8 errors for JDK8 errors for with ColumnFamilies & Hardening CFHandle Summary: ColumnFamilyHandles face the same problem as RocksIterator previously so used methods were also applied for ColumnFamilyHandles. Another problem with CF was that Options passed to CFs were always filled with default values. To enable Merge, all parts of the database must share the same merge functionality which is not possible using default values. So from now on every CF will inherit from db options. Changes to RocksDB: merge can now take also a cfhandle Changes to MergeTest: Corrected formatting Included also GC tests Extended tests to cover CF related parts Corrected paths to cleanup properly within the test process Reduced verbosity of the test Test Plan: make rocksdbjava make jtest Subscribers: dhruba Differential Revision: Hardening RocksIterator RocksIterator will sometimes Sigsegv on dispose. Mainly thats related to dispose order. If the related RocksDB instance is freed beforehand RocksIterator.dispose() will fail. Within this commit there is a major change to RocksIterator. RocksIterator will hold a private reference to the RocksDB instance which created the RocksIterator. So even if RocksDB is freed in the same GC cycle the RocksIterator instances will be freed prior to related RocksDB instances. Another aspect targets the dispose logic if the RocksDB is freed previously and already gc`ed. On dispose of a RocksIterator the dispose logic will check if the RocksDB instance points to an initialized DB. If not the dispose logic will not perform any further action. The crash can be reproduced by using the related test provided within this commit. Related information: This relates to facebook rocksdb-dev group post about SigSegv on RocksIterator.dispose()./Merge pull request from fyrz/JavaDoc-Cleanup JavaDoc fixes & enhancements RocksJava/Merge pull request from fyrz/findbug_issues Fixed Findbugs issues in RocksJava/Fixed Findbugs issues BackupableDB missing call to super.finalize(major) WriteBatchTest inefficient String usage(minor) RocksDB local dead variable store(medium)/"
,,0.063,rocksdb,Merge pull request from fyrz/JavaDoc-Cleanup JavaDoc fixes & enhancements RocksJava/
,,0.2686,rocksdb,Merge pull request from fyrz/findbug_issues Fixed Findbugs issues in RocksJava/Fixed Findbugs issues BackupableDB missing call to super.finalize(major) WriteBatchTest inefficient String usage(minor) RocksDB local dead variable store(medium)/
,,0.0926,rocksdb,[RocksJava] JavaDoc cleanup warnings with Java8 Java8 is more restrictive than Java7 with generating JavaDocs. This commit resolves current existing Java8 warnings./Merge pull request from EugenePig/java8 suppress JDK8 errors for JDK8 errors for
,,0.0588,rocksdb,Merge pull request from fyrz/JavaDoc-Cleanup JavaDoc fixes & enhancements RocksJava/
,,0.3131,rocksdb,fixed conflict in java/Makefile/Merge pull request from fyrz/32BitRocksJavaBug 32 Bit RocksJava Fix for overflowing jlongs/32-Bit RocksJava resolution for jlong overflows Summary: This pull request solves the jlong overflow problem on 32-Bit machines as described in 1. There is a new org.rocksdb.test.PlatformRandomHelper to assist in getting random values. For 32 Bit the getLong method is overriden by xpromaches code above. For 64 Bit it behaves as is. 2. The detection should be cross-platform (Windows is supported though it is not ported completely yet). 3. Every JNI method which sets jlong values must check if the value fits into size_t. If it overflows size_t a InvalidArgument Status object will be returned. If its ok a OK Status will be returned. 4. Setters which have this check will throw a RocksDBException if its no OK Status. Additionally some other parts of code were corrected using the wrong type casts. Test Plan: make rocksdbjava make jtest Differential Revision:
,,0.3491,rocksdb,"[RocksJava] JavaDoc cleanup warnings with Java8 Java8 is more restrictive than Java7 with generating JavaDocs. This commit resolves current existing Java8 warnings./fixed conflict in java/Makefile/Merge pull request from fyrz/32BitRocksJavaBug 32 Bit RocksJava Fix for overflowing jlongs/32-Bit RocksJava resolution for jlong overflows Summary: This pull request solves the jlong overflow problem on 32-Bit machines as described in 1. There is a new org.rocksdb.test.PlatformRandomHelper to assist in getting random values. For 32 Bit the getLong method is overriden by xpromaches code above. For 64 Bit it behaves as is. 2. The detection should be cross-platform (Windows is supported though it is not ported completely yet). 3. Every JNI method which sets jlong values must check if the value fits into size_t. If it overflows size_t a InvalidArgument Status object will be returned. If its ok a OK Status will be returned. 4. Setters which have this check will throw a RocksDBException if its no OK Status. Additionally some other parts of code were corrected using the wrong type casts. Test Plan: make rocksdbjava make jtest Differential Revision: pull request from fyrz/JavaDoc-Cleanup JavaDoc fixes & enhancements RocksJava/[Java] Fix JNI link error caused by the removal of options.db_stats_log_interval Summary: Fix JNI link error caused by the removal of options.db_stats_log_interval in Test Plan: make rocksdbjava make jtest Reviewers: ljin, ankgup87 Reviewed By: ankgup87 Subscribers: leveldb Differential Revision:"
,,0.3938,rocksdb,[RocksJava] JavaDoc cleanup warnings with Java8 Java8 is more restrictive than Java7 with generating JavaDocs. This commit resolves current existing Java8 warnings./[RocksJava] BackupInfos & Restore-/BackupableDB enhancements Summary: BackupableDB deleteBackup method BackupableDB purgeOldBackups bugfix BackupInfos now available in Restorable-/BackupableDB Extended BackupableDBTest to cover more of the currently implemented functionality. Test Plan: make rocksdbjava make jtest Differential Revision: pull request from fyrz/JavaDoc-Cleanup JavaDoc fixes & enhancements RocksJava/Merge pull request from fyrz/findbug_issues Fixed Findbugs issues in RocksJava/Fixed Findbugs issues BackupableDB missing call to super.finalize(major) WriteBatchTest inefficient String usage(minor) RocksDB local dead variable store(medium)/
,,0.3352,rocksdb,[RocksJava] JavaDoc cleanup warnings with Java8 Java8 is more restrictive than Java7 with generating JavaDocs. This commit resolves current existing Java8 warnings./fixed conflict in java/Makefile/Merge pull request from fyrz/32BitRocksJavaBug 32 Bit RocksJava Fix for overflowing jlongs/32-Bit RocksJava resolution for jlong overflows Summary: This pull request solves the jlong overflow problem on 32-Bit machines as described in 1. There is a new org.rocksdb.test.PlatformRandomHelper to assist in getting random values. For 32 Bit the getLong method is overriden by xpromaches code above. For 64 Bit it behaves as is. 2. The detection should be cross-platform (Windows is supported though it is not ported completely yet). 3. Every JNI method which sets jlong values must check if the value fits into size_t. If it overflows size_t a InvalidArgument Status object will be returned. If its ok a OK Status will be returned. 4. Setters which have this check will throw a RocksDBException if its no OK Status. Additionally some other parts of code were corrected using the wrong type casts. Test Plan: make rocksdbjava make jtest Differential Revision:
,,0.0923,rocksdb,[RocksJava] JavaDoc cleanup warnings with Java8 Java8 is more restrictive than Java7 with generating JavaDocs. This commit resolves current existing Java8 warnings./
,,0.3752,rocksdb,"[RocksJava] BackupInfos & Restore-/BackupableDB enhancements Summary: BackupableDB deleteBackup method BackupableDB purgeOldBackups bugfix BackupInfos now available in Restorable-/BackupableDB Extended BackupableDBTest to cover more of the currently implemented functionality. Test Plan: make rocksdbjava make jtest Differential Revision: conflict in java/Makefile/Fix code style problems identified by lint/Merge pull request from fyrz/32BitRocksJavaBug 32 Bit RocksJava Fix for overflowing jlongs/32-Bit RocksJava resolution for jlong overflows Summary: This pull request solves the jlong overflow problem on 32-Bit machines as described in 1. There is a new org.rocksdb.test.PlatformRandomHelper to assist in getting random values. For 32 Bit the getLong method is overriden by xpromaches code above. For 64 Bit it behaves as is. 2. The detection should be cross-platform (Windows is supported though it is not ported completely yet). 3. Every JNI method which sets jlong values must check if the value fits into size_t. If it overflows size_t a InvalidArgument Status object will be returned. If its ok a OK Status will be returned. 4. Setters which have this check will throw a RocksDBException if its no OK Status. Additionally some other parts of code were corrected using the wrong type casts. Test Plan: make rocksdbjava make jtest Differential Revision: Fixed 32-bit overflowing issue when converting jlong to size_t Summary: Fixed 32-bit overflowing issue when converting jlong to size_t by capping jlong to std::numeric_limits<size_t>::max(). Test Plan: make rocksdbjava make jtest Reviewers: ankgup87, ljin, sdong, igor Reviewed By: igor Subscribers: leveldb Differential Revision:"
,,0.2164,rocksdb,[RocksJava] BackupInfos & Restore-/BackupableDB enhancements Summary: BackupableDB deleteBackup method BackupableDB purgeOldBackups bugfix BackupInfos now available in Restorable-/BackupableDB Extended BackupableDBTest to cover more of the currently implemented functionality. Test Plan: make rocksdbjava make jtest Differential Revision:
,,0.4552,rocksdb,"Turn on and fix all the errors Summary: We need to turn on for mobile. See D1671432 (internal phabricator) for details. This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables. Test Plan: compiles Reviewers: ljin, rven, yhchiang, sdong Reviewed By: yhchiang Subscribers: bobbaldwin, dhruba, leveldb Differential Revision: improvements Minor corrections to resolve build problems with RocksJava code./Merge with ColumnFamilies & Hardening CFHandle Summary: ColumnFamilyHandles face the same problem as RocksIterator previously so used methods were also applied for ColumnFamilyHandles. Another problem with CF was that Options passed to CFs were always filled with default values. To enable Merge, all parts of the database must share the same merge functionality which is not possible using default values. So from now on every CF will inherit from db options. Changes to RocksDB: merge can now take also a cfhandle Changes to MergeTest: Corrected formatting Included also GC tests Extended tests to cover CF related parts Corrected paths to cleanup properly within the test process Reduced verbosity of the test Test Plan: make rocksdbjava make jtest Subscribers: dhruba Differential Revision: pull request from fyrz/32BitRocksJavaBug 32 Bit RocksJava Fix for overflowing jlongs/32-Bit RocksJava resolution for jlong overflows Summary: This pull request solves the jlong overflow problem on 32-Bit machines as described in 1. There is a new org.rocksdb.test.PlatformRandomHelper to assist in getting random values. For 32 Bit the getLong method is overriden by xpromaches code above. For 64 Bit it behaves as is. 2. The detection should be cross-platform (Windows is supported though it is not ported completely yet). 3. Every JNI method which sets jlong values must check if the value fits into size_t. If it overflows size_t a InvalidArgument Status object will be returned. If its ok a OK Status will be returned. 4. Setters which have this check will throw a RocksDBException if its no OK Status. Additionally some other parts of code were corrected using the wrong type casts. Test Plan: make rocksdbjava make jtest Differential Revision:"
,,0.3167,rocksdb,"Turn on and fix all the errors Summary: We need to turn on for mobile. See D1671432 (internal phabricator) for details. This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables. Test Plan: compiles Reviewers: ljin, rven, yhchiang, sdong Reviewed By: yhchiang Subscribers: bobbaldwin, dhruba, leveldb Differential Revision: pull request from dalgaaf/wip-da-SCA-20141001 Fix some issues from SCA/Merge pull request from dalgaaf/wip-da-SCA-20140930 Various SCA fixes/ttl/ttl_test.cc: prefer prefix ++operator for non-primitive types Signed-off-by: Danny Al-Gaaf"
,,0.2965,rocksdb,"Turn on and fix all the errors Summary: We need to turn on for mobile. See D1671432 (internal phabricator) for details. This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables. Test Plan: compiles Reviewers: ljin, rven, yhchiang, sdong Reviewed By: yhchiang Subscribers: bobbaldwin, dhruba, leveldb Differential Revision: cuckoo table builder test Summary: as title Test Plan: ./cuckoo_table_builder_test Reviewers:igor CC:leveldb Task ID: Blame Rev:/Fix compaction bug in Cuckoo Table Builder. Use kvs_.size() instead of num_entries in FileSize() method. Summary: Fix compaction bug in Cuckoo Table Builder. Use kvs_.size() instead of num_entries in FileSize() method. Also added tests. Test Plan: make check all Also ran db_bench to generate multiple files. Reviewers: sdong, ljin Reviewed By: ljin Subscribers: leveldb Differential Revision:"
,,0.1796,rocksdb,"Turn on Summary: ...and fix all the errors :) Jim suggested turning on because it helped him fix number of critical bugs in fbcode. I think its a good idea to be clean. Test Plan: compiles Reviewers: yhchiang, rven, sdong, ljin Reviewed By: ljin Subscribers: dhruba, leveldb Differential Revision: conflict in java/Makefile/Avoid reloading filter on Get() if cache_index_and_filter_blocks false Summary: This fixes the case that filter policy is missing in SST file, but we open the table with filter policy on and cache_index_and_filter_blocks false. The current behavior is that we will try to load it every time on Get() but fail. Test Plan: unit test Reviewers: yhchiang, igor, rven, sdong Reviewed By: sdong Subscribers: leveldb Differential Revision: naked calls to operator new and delete (Fixes This replaces a mishmash of pointers in the Block and BlockContents classes with std::unique_ptr. It also changes the semantics of BlockContents to be limited to use as a constructor parameter for Block objects, as it owns any block buffers handed to it./"
,,0.3156,rocksdb,"Turn on and fix all the errors Summary: We need to turn on for mobile. See D1671432 (internal phabricator) for details. This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables. Test Plan: compiles Reviewers: ljin, rven, yhchiang, sdong Reviewed By: yhchiang Subscribers: bobbaldwin, dhruba, leveldb Differential Revision:"
,,0.311,rocksdb,"Turn on and fix all the errors Summary: We need to turn on for mobile. See D1671432 (internal phabricator) for details. This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables. Test Plan: compiles Reviewers: ljin, rven, yhchiang, sdong Reviewed By: yhchiang Subscribers: bobbaldwin, dhruba, leveldb Differential Revision:"
,,0.4065,rocksdb,"Turn on and fix all the errors Summary: We need to turn on for mobile. See D1671432 (internal phabricator) for details. This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables. Test Plan: compiles Reviewers: ljin, rven, yhchiang, sdong Reviewed By: yhchiang Subscribers: bobbaldwin, dhruba, leveldb Differential Revision: naked calls to operator new and delete (Fixes This replaces a mishmash of pointers in the Block and BlockContents classes with std::unique_ptr. It also changes the semantics of BlockContents to be limited to use as a constructor parameter for Block objects, as it owns any block buffers handed to it./Fix compile Summary: gcc on our dev boxes is not happy about __attribute__((unused)) Test Plan: compiles now Reviewers: sdong, ljin Reviewed By: ljin Subscribers: leveldb Differential Revision:"
,,0.3682,rocksdb,"Turn on and fix all the errors Summary: We need to turn on for mobile. See D1671432 (internal phabricator) for details. This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables. Test Plan: compiles Reviewers: ljin, rven, yhchiang, sdong Reviewed By: yhchiang Subscribers: bobbaldwin, dhruba, leveldb Differential Revision: back on Summary: It turns out that has different rules for gcc than clang. Previous commit fixed clang. This commits fixes the rest of the warnings for gcc. Test Plan: compiles Reviewers: ljin, yhchiang, rven, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: pull request from dalgaaf/wip-da-SCA-20141001 Fix some issues from SCA/Replace naked calls to operator new and delete (Fixes This replaces a mishmash of pointers in the Block and BlockContents classes with std::unique_ptr. It also changes the semantics of BlockContents to be limited to use as a constructor parameter for Block objects, as it owns any block buffers handed to it./[unit test] CompactRange should fail if we dont have space Summary: See t5106397. Also, few more changes: 1. in unit tests, the assumption is that writes will be dropped when there is no space left on device. I changed the wording around it. 2. InvalidArgument() errors are only when user-provided arguments are invalid. When the file is corrupted, we need to return Status::Corruption Test Plan: make check Reviewers: sdong, ljin Reviewed By: ljin Subscribers: leveldb Differential Revision: pull request from tdfischer/perf-timer-destructors Refactor PerfStepTimer to automatically stop on destruct/Refactor PerfStepTimer to stop on destruct This eliminates the need to remember to call PERF_TIMER_STOP when a section has been timed. This allows more useful design with the perf timers and enables possible return value optimizations. Simplistic example: class Foo { public: Foo(int v) : m_v(v); private: int m_v; } Foo makeFrobbedFoo(int *errno) { *errno 0; return Foo(); } Foo bar(int *errno) { PERF_TIMER_GUARD(some_timer); return makeFrobbedFoo(errno); } int main(int argc, char[] argv) { Foo f; int errno; f bar(&errno); if (errno) return return 0; } After bar() is called, perf_context.some_timer would be incremented as if Stop(&perf_context.some_timer) was called at the end, and the compiler is still able to produce optimizations on the return value from makeFrobbedFoo() through to main()./"
,,0.3866,rocksdb,"Turn on and fix all the errors Summary: We need to turn on for mobile. See D1671432 (internal phabricator) for details. This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables. Test Plan: compiles Reviewers: ljin, rven, yhchiang, sdong Reviewed By: yhchiang Subscribers: bobbaldwin, dhruba, leveldb Differential Revision: back on Summary: It turns out that has different rules for gcc than clang. Previous commit fixed clang. This commits fixes the rest of the warnings for gcc. Test Plan: compiles Reviewers: ljin, yhchiang, rven, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: on Summary: ...and fix all the errors :) Jim suggested turning on because it helped him fix number of critical bugs in fbcode. I think its a good idea to be clean. Test Plan: compiles Reviewers: yhchiang, rven, sdong, ljin Reviewed By: ljin Subscribers: dhruba, leveldb Differential Revision: conflict in java/Makefile/fix table_test Summary: SaveValue expects an internal key but I previously added to table a user key Test Plan: ran the test/Avoid reloading filter on Get() if cache_index_and_filter_blocks false Summary: This fixes the case that filter policy is missing in SST file, but we open the table with filter policy on and cache_index_and_filter_blocks false. The current behavior is that we will try to load it every time on Get() but fail. Test Plan: unit test Reviewers: yhchiang, igor, rven, sdong Reviewed By: sdong Subscribers: leveldb Differential Revision: pull request from dalgaaf/wip-da-SCA-20140930 Various SCA fixes/table/table_test.cc: pass func parameter by reference Fix for: [table/table_test.cc:1218]: (performance) Function parameter prefix should be passed by reference. Signed-off-by: Danny Al-Gaaf naked calls to operator new and delete (Fixes This replaces a mishmash of pointers in the Block and BlockContents classes with std::unique_ptr. It also changes the semantics of BlockContents to be limited to use as a constructor parameter for Block objects, as it owns any block buffers handed to it./Fix compile Summary: gcc on our dev boxes is not happy about __attribute__((unused)) Test Plan: compiles now Reviewers: sdong, ljin Reviewed By: ljin Subscribers: leveldb Differential Revision:"
,,0.4072,rocksdb,"Turn on and fix all the errors Summary: We need to turn on for mobile. See D1671432 (internal phabricator) for details. This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables. Test Plan: compiles Reviewers: ljin, rven, yhchiang, sdong Reviewed By: yhchiang Subscribers: bobbaldwin, dhruba, leveldb Differential Revision: back on Summary: It turns out that has different rules for gcc than clang. Previous commit fixed clang. This commits fixes the rest of the warnings for gcc. Test Plan: compiles Reviewers: ljin, yhchiang, rven, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: on Summary: ...and fix all the errors :) Jim suggested turning on because it helped him fix number of critical bugs in fbcode. I think its a good idea to be clean. Test Plan: compiles Reviewers: yhchiang, rven, sdong, ljin Reviewed By: ljin Subscribers: dhruba, leveldb Differential Revision: pull request from Liuchang0812/fix-check fixed replace %ld with % PRId64/fixed replace %ld with % PRId64/Merge pull request from project-zerus/patch-1 fix more compile warnings/fix more compile warnings N/A Change-Id: I5b6f9c70aea7d3f3489328834fed323d41106d9f Signed-off-by: liuhuahang pull request from ShaoYuZhang/master Fix compilation issue on OSX/Fix compilation issue on OSX/"
,,0.303,rocksdb,"Turn on and fix all the errors Summary: We need to turn on for mobile. See D1671432 (internal phabricator) for details. This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables. Test Plan: compiles Reviewers: ljin, rven, yhchiang, sdong Reviewed By: yhchiang Subscribers: bobbaldwin, dhruba, leveldb Differential Revision: OptimizeForPointLookup() Summary: also fix HISTORY.md Test Plan: make all check Reviewers: sdong, yhchiang, igor Reviewed By: igor Subscribers: leveldb Differential Revision:"
,,0.2104,rocksdb,"Turn on Summary: ...and fix all the errors :) Jim suggested turning on because it helped him fix number of critical bugs in fbcode. I think its a good idea to be clean. Test Plan: compiles Reviewers: yhchiang, rven, sdong, ljin Reviewed By: ljin Subscribers: dhruba, leveldb Differential Revision: the bug where compaction does not fail when RocksDB cant create a new file. Summary: This diff has two fixes. 1. Fix the bug where compaction does not fail when RocksDB cant create a new file. 2. When NewWritableFiles() fails in OpenCompactionOutputFiles(), previously such fail-to-created file will be still be included as a compaction output. This patch also fixes this bug. 3. Allow VersionEdit::EncodeTo() to return Status and add basic check. Test Plan: ./version_edit_test export ROCKSDB_TESTS=FileCreationRandomFailure ./db_test Reviewers: ljin, sdong, nkg-, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision: conflict in java/Makefile/Correct the log message in VersionEdit Summary: When VersionEdit fails in kNewFile3, previously it logs ""new-file2 entry"". However, it should be ""new-file3 entry."" Test Plan: make/"
,,0.3391,rocksdb,"Fixed GetEstimatedActiveKeys Summary: Fixed a bug in GetEstimatedActiveKeys which does not normalized the sampled information correctly. Add a test in version_builder_test. Test Plan: version_builder_test Reviewers: ljin, igor, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: on and fix all the errors Summary: We need to turn on for mobile. See D1671432 (internal phabricator) for details. This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables. Test Plan: compiles Reviewers: ljin, rven, yhchiang, sdong Reviewed By: yhchiang Subscribers: bobbaldwin, dhruba, leveldb Differential Revision: back on Summary: It turns out that has different rules for gcc than clang. Previous commit fixed clang. This commits fixes the rest of the warnings for gcc. Test Plan: compiles Reviewers: ljin, yhchiang, rven, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: BaseReferencedVersionBuilders destructor order Summary: BaseReferencedVersionBuilder now unreference version before destructing VersionBuilder, which is wrong. Fix it. Test Plan: make all check valgrind test to tests that used to fail Reviewers: igor, yhchiang, rven, ljin Reviewed By: ljin Subscribers: leveldb, dhruba Differential Revision: on Summary: ...and fix all the errors :) Jim suggested turning on because it helped him fix number of critical bugs in fbcode. I think its a good idea to be clean. Test Plan: compiles Reviewers: yhchiang, rven, sdong, ljin Reviewed By: ljin Subscribers: dhruba, leveldb Differential Revision: the bug where compaction does not fail when RocksDB cant create a new file. Summary: This diff has two fixes. 1. Fix the bug where compaction does not fail when RocksDB cant create a new file. 2. When NewWritableFiles() fails in OpenCompactionOutputFiles(), previously such fail-to-created file will be still be included as a compaction output. This patch also fixes this bug. 3. Allow VersionEdit::EncodeTo() to return Status and add basic check. Test Plan: ./version_edit_test export ROCKSDB_TESTS=FileCreationRandomFailure ./db_test Reviewers: ljin, sdong, nkg-, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision: conflict in java/Makefile/Merge pull request from dalgaaf/wip-da-SCA-20141001 Fix some issues from SCA/db/version_set.cc: remove unnecessary checks Fix for: [db/version_set.cc:1219]: (style) Unsigned variable last_file cant be negative so it is unnecessary to test it. [db/version_set.cc:1234]: (style) Unsigned variable first_file cant be negative so it is unnecessary to test it. Signed-off-by: Danny Al-Gaaf pull request from dalgaaf/wip-da-SCA-20140930 Various SCA fixes/db/version_set.cc: use empty() instead of size() > 0 Use empty() since it should be prefered as it has, following the standard, a constant time complexity regardless of the containter type. The same is not guaranteed for size(). Fix for: [db/version_set.cc:2250]: (performance) Possible inefficient checking for column_families_not_found emptiness. Signed-off-by: Danny Al-Gaaf version_set options_ to db_options_ to avoid confusion Summary: as title Test Plan: make release Reviewers: sdong, yhchiang, igor Reviewed By: igor Subscribers: leveldb Differential Revision: instead of pull-model for managing Write stalls Summary: Introducing WriteController, which is a source of truth about per-DB write delays. Lets define an DB epoch as a period where there are no flushes and compactions (i.e. new epoch is started when flush or compaction finishes). Each epoch can either: * proceed with all writes without delay * delay all writes by fixed time * stop all writes The three modes are recomputed at each epoch change (flush, compaction), rather than on every write (which is currently the case). When we have a lot of column families, our current pull behavior adds a big overhead, since we need to loop over every column family for every write. With new push model, overhead on Write code-path is minimal. This is just the start. Next step is to also take care of stalls introduced by slow memtable flushes. The final goal is to eliminate function MakeRoomForWrite(), which currently needs to be called for every column family by every write. Test Plan: make check for now. Ill add some unit tests later. Also, perf test. Reviewers: dhruba, yhchiang, MarkCallaghan, sdong, ljin Reviewed By: ljin Subscribers: leveldb Differential Revision: pull request from project-zerus/patch-1 fix more compile warnings/fix more compile warnings N/A Change-Id: I5b6f9c70aea7d3f3489328834fed323d41106d9f Signed-off-by: liuhuahang retrying to read property block from a table when it does not exist. Summary: Avoid retrying to read property block from a table when it does not exist in updating stats for compensating deletion entries. In addition, ReadTableProperties() now returns Status::NotFound instead of Status::Corruption when table properties does not exist in the file. Test Plan: make db_test export ROCKSDB_TESTS=CompactionDeleteionTrigger ./db_test Reviewers: ljin, sdong Reviewed By: sdong Subscribers: leveldb Differential Revision:"
,,0.3512,rocksdb,"Turn on and fix all the errors Summary: We need to turn on for mobile. See D1671432 (internal phabricator) for details. This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables. Test Plan: compiles Reviewers: ljin, rven, yhchiang, sdong Reviewed By: yhchiang Subscribers: bobbaldwin, dhruba, leveldb Differential Revision: c_test Summary: as title Test Plan: ./c_test Reviewers: igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision: on Summary: ...and fix all the errors :) Jim suggested turning on because it helped him fix number of critical bugs in fbcode. I think its a good idea to be clean. Test Plan: compiles Reviewers: yhchiang, rven, sdong, ljin Reviewed By: ljin Subscribers: dhruba, leveldb Differential Revision: valgrind error in c_test caused by BlockBasedTableOptions Summary: It was creating BlockBasedTableOptions object in a loop without calling destroy() Test Plan: valgrind ./c_test Reviewers: sdong, igor Reviewed By: igor Subscribers: leveldb Differential Revision: the error of c_test.c Summary: Fix the error of c_test.c Test Plan: make c_test ./c_test/Fix valgrind error in c_test/Merge pull request from cockroachdb/spencerkimball/send-user-keys-to-v2-filter Pass parsed user key to prefix extractor in V2 compaction/"
,,0.1155,rocksdb,"Turn back on Summary: It turns out that has different rules for gcc than clang. Previous commit fixed clang. This commits fixes the rest of the warnings for gcc. Test Plan: compiles Reviewers: ljin, yhchiang, rven, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision:"
,,0.1019,rocksdb,RocksJava FindBugs issues Addressed some FindBugs issues./
,,0.0862,rocksdb,"[RocksJava] Quality improvements Summary: Addressed some FindBugs issues. Remove obsolete dbFolder cleanup Comparator tests for CF Added AbstractComparatorTest. Fixed a bug in the JNI Part about Java comparators Minor test improvements Test Plan: make rocksdbjava make jtest mvn rocksjni.pom package Reviewers: adamretter, yhchiang, ankgup87 Subscribers: dhruba Differential Revision:"
,,0.0998,rocksdb,RocksJava FindBugs issues Addressed some FindBugs issues./
,,0.1019,rocksdb,RocksJava FindBugs issues Addressed some FindBugs issues./
,,0.1174,rocksdb,Merge pull request from fyrz/RocksJava-Restore-PrecisionFix [RocksJava] Fixed MacOS build of RocksJava/[RocksJava] Fixed MacOS build of RocksJava There were still some precision loss problems remainging in RocksJava. This pull request resolve these./Merge pull request from fyrz/RocksJava-PrecisionFix [RocksJava] Fix precision problem in rocksjni/[RocksJava] Fix precision problem in rocksjni/
,,0.0876,rocksdb,Merge pull request from StanislavGlebik/document_db_improvement Fixed negative numbers comparison in DocumentDB/Fixed negative numbers comparison in DocumentDB/
,,0.1731,rocksdb,"build: avoid unused-variable warning Summary: [noticed a new warning when building with the very latest gcc] * db/memtablerep_bench.cc (FLAGS_env): Remove declaration of unused varaible, to avoid this warning/error: db/memtablerep_bench.cc:135:22: error: ëFLAGS_enví defined but not\ used [-Werror=unused-variable] static rocksdb::Env* FLAGS_env rocksdb::Env::Default(); ^ Test Plan: compile Reviewers: ljin, rven, igor.sugak, yhchiang, sdong, igor Reviewed By: igor Subscribers: dhruba Differential Revision:"
,,0.2007,rocksdb,"Improved FileExists API Summary: Add new CheckFileExists method. Considered changing the FileExists api but didnt want to break anyones builds. Test Plan: unit tests Reviewers: yhchiang, igor, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.2048,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.2109,rocksdb,"Address GCC compilation issues invalid suffix on literal no return statement in function returning non-void CuckooStep::operator= extra qualification ërocksdb::spatial::Variant:: dereferencing type-punned pointer will break strict-aliasing rules/Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.2164,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.0869,rocksdb,"add support for capped prefix extractor in java/Fixing Java tests. Summary: While working on , I realized that some Java tests are failing due to a deprecated option. This patch removes the offending tests, adds annotations to the Java interface and removes the corresponding functions in rocksjni Test Plan: make jtest (all tests are passing now) Reviewers: rven, igor, sdong, anthony, yhchiang Reviewed By: yhchiang Subscribers: dhruba, leveldb Differential Revision:"
,,0.0947,rocksdb,"add support for capped prefix extractor in java/Fixing Java tests. Summary: While working on , I realized that some Java tests are failing due to a deprecated option. This patch removes the offending tests, adds annotations to the Java interface and removes the corresponding functions in rocksjni Test Plan: make jtest (all tests are passing now) Reviewers: rven, igor, sdong, anthony, yhchiang Reviewed By: yhchiang Subscribers: dhruba, leveldb Differential Revision:"
,,0.2027,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov branch master of github.com:facebook/rocksdb D40233: Replace %llu with format macros in ParsedInternalKey::DebugString())/Make ""make all"" work for CYGWIN Summary: Some test and benchmark codes dont build for CYGWIN. Fix it. Test Plan: Build ""make all"" with TARGET_OS=Cygwin on cygwin and make sure it passes. Reviewers: rven, yhchiang, anthony, igor, kradhakrishnan Reviewed By: igor, kradhakrishnan Subscribers: leveldb, dhruba Differential Revision:"
,,0.2081,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.2098,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.2474,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov malloc_usable_size() for accounting block cache size Summary: Currently, when we insert something into block cache, we say that the block cache capacity decreased by the size of the block. However, size of the block might be less than the actual memory used by this object. For example, 4.5KB block will actually use 8KB of memory. So even if we configure block cache to 10GB, our actually memory usage of block cache will be 20GB This problem showed up a lot in testing and just recently also showed up in MongoRocks production where we were using 30GB more memory than expected. This diff will fix the problem. Instead of counting the block size, we will count memory used by the block. That way, a block cache configured to be 10GB will actually use only 10GB of memory. Im using non-portable function and I couldnt find info on portability on Google. However, it seems to work on Linux, which will cover majority of our use-cases. Test Plan: 1. fill up mongo instance with 80GB of data 2. restart mongo with block cache size configured to 10GB 3. do a table scan in mongo 4. memory usage before the diff: 12GB. memory usage after the diff: 10.5GB Reviewers: sdong, MarkCallaghan, rven, yhchiang Reviewed By: yhchiang Subscribers: dhruba, leveldb Differential Revision:"
,,0.1949,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.1713,rocksdb,"Use malloc_usable_size() for accounting block cache size Summary: Currently, when we insert something into block cache, we say that the block cache capacity decreased by the size of the block. However, size of the block might be less than the actual memory used by this object. For example, 4.5KB block will actually use 8KB of memory. So even if we configure block cache to 10GB, our actually memory usage of block cache will be 20GB This problem showed up a lot in testing and just recently also showed up in MongoRocks production where we were using 30GB more memory than expected. This diff will fix the problem. Instead of counting the block size, we will count memory used by the block. That way, a block cache configured to be 10GB will actually use only 10GB of memory. Im using non-portable function and I couldnt find info on portability on Google. However, it seems to work on Linux, which will cover majority of our use-cases. Test Plan: 1. fill up mongo instance with 80GB of data 2. restart mongo with block cache size configured to 10GB 3. do a table scan in mongo 4. memory usage before the diff: 12GB. memory usage after the diff: 10.5GB Reviewers: sdong, MarkCallaghan, rven, yhchiang Reviewed By: yhchiang Subscribers: dhruba, leveldb Differential Revision:"
,,0.2065,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.1998,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.1807,rocksdb,"Fixing dead code in table_properties_collector_test Summary: There was a bug in table_properties_collector_test that this patch is fixing: `backward_mode && test_int_tbl_prop_collector` in TestCustomizedTablePropertiesCollector was never true, so the code in the if-block never got executed. The reason is that the CustomizedTablePropertiesCollector test was skipping tests with `backward_mode_ && encode_as_internal`. The reason for skipping the tests is unknown. Test Plan: make table_properties_collector_test && ./table_properties_collector_test Reviewers: rven, igor, yhchiang, anthony, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov"
,,0.1889,rocksdb,"Windows Port from Microsoft Summary: Make RocksDb build and run on Windows to be functionally complete and performant. All existing test cases run with no regressions. Performance numbers are in the pull-request. Test plan: make all of the existing unit tests pass, obtain perf numbers. Co-authored-by: Praveen Rao Co-authored-by: Sherlock Huang Co-authored-by: Alex Zinoviev Co-authored-by: Dmitri Smirnov branch master of github.com:facebook/rocksdb D40233: Replace %llu with format macros in ParsedInternalKey::DebugString())/Fix ASAN errors in c_test Summary: key_sizes claims that 3rd key is of length 8, but its really only 3. This diff makes it length 8. Test Plan: asan c_test works again. Reviewers: sdong, yhchiang Subscribers: dhruba, leveldb Differential Revision:"
,,0.1214,rocksdb,"New amalgamation target This commit adds two new targets to the Makefile: rocksdb.cc and rocksdb.h These files, when combined with the c.h header, are a self-contained RocksDB source distribution called an amalgamation. (The name comes from SQLites, which is similar in concept.) The main benefit of an amalgamation is that its very easy to drop into a new project. It also compiles faster compared to compiling individual source files and potentially gives the compiler more opportunity to make optimizations since it can see all functions at once. rocksdb.cc and rocksdb.h are generated by a new script, amalgamate.py. A detailed description of how amalgamate.py works is in a comment at the top of the file. There are also some small changes to existing files to enable the amalgamation: * Use quotes for includes in unity build * Fix an old header inclusion in util/xfunc.cc * Move some includes outside ifdef in util/env_hdfs.cc * Separate out tool sources in Makefile so they wont be included in unity.cc * Unity build now produces a static library Closes"
,,0.1871,rocksdb,"Merge pull request from OverlordQ/unused-variable-warning Fix introduced in 2ab7065 was reverted by 18285c1./Fix introduced in 2ab7065 was reverted by 18285c1. Corrects: db/memtablerep_bench.cc:135:22: error: ëFLAGS_enví defined but not used [-Werror=unused-variable] static rocksdb::Env* FLAGS_env rocksdb::Env::Default(); ^ cc1plus: all warnings being treated as errors Makefile:1147: recipe for target db/memtablerep_bench.o failed/Fix benchmarks under ROCKSDB_LITE Summary: Fix db_bench and memtablerep_bench under ROCKSDB_LITE Test Plan: OPT=-DROCKSDB_LITE make db_bench OPT=-DROCKSDB_LITE make memtablerep_bench make db_bench make memtablerep_bench Reviewers: yhchiang, anthony, rven, igor, sdong Reviewed By: sdong Subscribers: dhruba Differential Revision:"
,,0.0784,rocksdb,Merge pull request from zhipeng-jia/fix_clang_warning Fix clang warnings/Fix clang warnings regarding unnecessary std::move/
,,0.079,rocksdb,"Fix Java Break Related to memtable bloom bits to size ratio change Summary: Need to change several more places for the change to fix Java tests Test Plan: make jtest under java, run ""make db_bench"" Reviewers: yhchiang, andrewkr, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: leveldb, andrewkr, dhruba Differential Revision:"
,,0.2414,rocksdb,"Change max_bytes_for_level_multiplier to double Summary: Closes Differential Revision: D4094732 Pulled By: yiwu-arbug fbshipit-source-id: b9b79e9/db_bench: takes no effect Summary: Fix the bug that is set before opening the DB. Closes Differential Revision: D4106001 Pulled By: siying fbshipit-source-id: 4e746da/Fix db_bench memory use after free (detected by clang_analyze) Summary: Fix using `arg[i].thread` after deleting it Test Plan: run clang_analyze Subscribers: andrewkr, dhruba Differential Revision: Support single benchmark arguments (Repeat for X times, Warm up for X times), Support CombinedStats (AVG / MEDIAN) Summary: This diff allow us to run a single benchmark X times and warm it up for Y times. and see the AVG & MEDIAN throughput of these X runs for example ``` $ ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 4.12 Date: Wed Aug 24 10:45:26 2016 CPU: 32 * Intel(R) Xeon(R) CPU E5-2660 0 2.20GHz CPUCache: 20480 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-8616/dbbench] fillseq : 4.695 micros/op 212971 ops/sec; 23.6 MB/s DB path: [/tmp/rocksdbtest-8616/dbbench] Warming up benchmark by running 2 times readseq : 0.214 micros/op 4677005 ops/sec; 517.4 MB/s readseq : 0.212 micros/op 4706834 ops/sec; 520.7 MB/s Running benchmark for 5 times readseq : 0.218 micros/op 4588187 ops/sec; 507.6 MB/s readseq : 0.208 micros/op 4816538 ops/sec; 532.8 MB/s readseq : 0.213 micros/op 4685376 ops/sec; 518.3 MB/s readseq : 0.214 micros/op 4676787 ops/sec; 517.4 MB/s readseq : 0.217 micros/op 4618532 ops/sec; 510.9 MB/s readseq [AVG 5 runs] : 4677084 ops/sec; 517.4 MB/sec readseq [MEDIAN 5 runs] : 4676787 ops/sec; 517.4 MB/sec ``` Test Plan: run db_bench Reviewers: sdong, andrewkr, yhchiang Reviewed By: yhchiang Subscribers: andrewkr, dhruba Differential Revision: ClockCache Summary: Clock-based cache implemenetation aim to have better concurreny than default LRU cache. See inline comments for implementation details. Test Plan: Update cache_test to run on both LRUCache and ClockCache. Adding some new tests to catch some of the bugs that I fixed while implementing the cache. Reviewers: kradhakrishnan, sdong Reviewed By: sdong Subscribers: andrewkr, dhruba, leveldb Differential Revision:"
,,0.0778,rocksdb,"Add NoSpace subcode to IOError (#1320) Add a sub code to distinguish ""out of space"" errors from regular I/O errors/"
,,0.0577,rocksdb,Fix bug in UnScSigned-off-by: xh931076284 (#1336) Fix HdfsEnv::UnSchedule() API error/
,,0.2561,rocksdb,"Move db_bench flags out of unnamed namespace Summary: I want to be able to, e.g., DECLARE_string(statistics_string); in my application such that I can override the default value of statistics_string. For this to work, we need to remove the unnamed namespace containing all the flags, and make sure all variables/functions covered by that namespace are static. Replaces due to internal tool issues. Closes Differential Revision: D4515124 Pulled By: ajkr fbshipit-source-id: 23b695e/Generalize Env registration framework Summary: The Env registration framework supports registering client Envs and selecting which one to instantiate according to a text field. This enabled things like adding the argument to db_bench, so the same binary could be reused with different Envs just by changing CLI config. Now this problem has come up again in a non-Env context, as I want to instantiate a client Statistics implementation from db_bench, which is configured entirely via text parameters. Also, in the future we may wish to use it for deserializing client objects when loading OPTIONS file. This diff generalizes the Env registration logic to work with arbitrary types. Generalized registration and instantiation code by templating them The entire implementation is in a header file as thats Google style guides recommendation for template definitions Pattern match with std::regex_match rather than checking prefix, which was the previous behavior Rename functions/files to be non-Env-specific Closes Differential Revision: D4421933 Pulled By: ajkr fbshipit-source-id: 34647d1/Fix MS warnings. Use ROCKSDB_Prsz for size_t. Summary: Closes Differential Revision: D4378852 Pulled By: yiwu-arbug fbshipit-source-id: ba8b02d/Update db_bench and sst_dump to test with block cache mid-point inser? Summary: ?tion Add flags in db_bench to test with block cache mid-point insertion. Also update sst_dump to dump total block sizes of each type. I find it useful to look at these test db stats and I dont know if we have them elsewhere. Closes Differential Revision: D4355812 Pulled By: yiwu-arbug fbshipit-source-id: 3e4a348/direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/Gcc-7 buffer size insufficient Summary: Bunch of commits related to insufficient buffer size. Errors in individual commits. Closes Differential Revision: D4332127 Pulled By: IslamAbdelRahman fbshipit-source-id: 878f73c/fix db_bench argument type Summary: Closes Differential Revision: D4298161 Pulled By: yiwu-arbug fbshipit-source-id: 2c7af35/Add memtable_insert_with_hint_prefix_size option to db_bench Summary: Add memtable_insert_with_hint_prefix_size option to db_bench Closes Differential Revision: D4260549 Pulled By: yiwu-arbug fbshipit-source-id: cee5ef7/Cache heap::downheap() root comparison (optimize heap cmp call) Summary: Reduce number of comparisons in heap by caching which child node in the first level is smallest (left_child or right_child) So next time we can compare directly against the smallest child I see that the total number of calls to comparator drops significantly when using this optimization Before caching (~2mil key comparison for iterating the DB) ``` $ DEBUG_LEVEL=0 make db_bench && ./db_bench readseq : 0.338 micros/op 2959201 ops/sec; 327.4 MB/s user_key_comparison_count 2000008 ``` After caching (~1mil key comparison for iterating the DB) ``` $ DEBUG_LEVEL=0 make db_bench && ./db_bench readseq : 0.309 micros/op 3236801 ops/sec; 358.1 MB/s user_key_comparison_count 1000011 ``` It also improves Closes Differential Revision: D4256027 Pulled By: IslamAbdelRahman fbshipit-source-id: 76fcc66/"
,,0.4961,rocksdb,"direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/Return finer-granularity status from Env::GetChildren* Summary: Itd be nice to use the error status type to distinguish between user error and system error. For example, GetChildren can fail listing a backup directorys contents either because a bad path was provided (user error) or because an operation failed, e.g., a remote storage service call failed (system error). In the former case, we want to continue and treat the backup directory as empty; in the latter case, we want to immediately propagate the error to the caller. This diff uses NotFound to indicate user error and IOError to indicate system error. Previously IOError indicated both. Closes Differential Revision: D4312157 Pulled By: ajkr fbshipit-source-id: 51b4f24/"
,,0.1339,rocksdb,Gcc 7 error expansion to defined Summary: sorry if these gcc-7/clang-4 cleanups are getting tedious. Closes Differential Revision: D4318792 Pulled By: yiwu-arbug fbshipit-source-id: 8e85891/
,,0.1321,rocksdb,Gcc 7 error expansion to defined Summary: sorry if these gcc-7/clang-4 cleanups are getting tedious. Closes Differential Revision: D4318792 Pulled By: yiwu-arbug fbshipit-source-id: 8e85891/
,,0.1375,rocksdb,Gcc 7 error expansion to defined Summary: sorry if these gcc-7/clang-4 cleanups are getting tedious. Closes Differential Revision: D4318792 Pulled By: yiwu-arbug fbshipit-source-id: 8e85891/
,,0.3776,rocksdb,"Fix OSX build break after the fallocate change Summary: The recent update about fallocate failed OSX build. Fix it. Closes Differential Revision: D4500235 Pulled By: siying fbshipit-source-id: a5f2b40/Remove fadvise with direct IO read Summary: Remove the logic since we dont use buffer cache with direct IO. Resolve read regression we currently have. Closes Differential Revision: D4430408 Pulled By: yiwu-arbug fbshipit-source-id: 5557bba/fix warning of unused direct io helper functions Summary: add build guard Closes Differential Revision: D4410779 Pulled By: siying fbshipit-source-id: 3796c30/Guarding extra fallocate call with TRAVIS because its not working proÖ Summary: Öperly on travis There is some old code in PosixWritableFile::Close(), which truncates the file to the measured size and then does an extra fallocate with KEEP_SIZE. This is commented as a failsafe because in some cases ftruncate doesnt do the right job (I dont know of an instance of this btw). However doing an fallocate with KEEP_SIZE should not increase the file size. However on Travis Worker which is Docker (likely AUFS ) its not working. There are comments on web that show that the AUFS author had initially not implemented fallocate, and then did it later. So not sure what is the quality of the implementation. Closes Differential Revision: D4401340 Pulled By: anirbanr-fb fbshipit-source-id: e2d8100/direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/"
,,0.2772,rocksdb,"Return finer-granularity status from Env::GetChildren* Summary: Itd be nice to use the error status type to distinguish between user error and system error. For example, GetChildren can fail listing a backup directorys contents either because a bad path was provided (user error) or because an operation failed, e.g., a remote storage service call failed (system error). In the former case, we want to continue and treat the backup directory as empty; in the latter case, we want to immediately propagate the error to the caller. This diff uses NotFound to indicate user error and IOError to indicate system error. Previously IOError indicated both. Closes Differential Revision: D4312157 Pulled By: ajkr fbshipit-source-id: 51b4f24/"
,,0.4842,rocksdb,"direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/Return finer-granularity status from Env::GetChildren* Summary: Itd be nice to use the error status type to distinguish between user error and system error. For example, GetChildren can fail listing a backup directorys contents either because a bad path was provided (user error) or because an operation failed, e.g., a remote storage service call failed (system error). In the former case, we want to continue and treat the backup directory as empty; in the latter case, we want to immediately propagate the error to the caller. This diff uses NotFound to indicate user error and IOError to indicate system error. Previously IOError indicated both. Closes Differential Revision: D4312157 Pulled By: ajkr fbshipit-source-id: 51b4f24/"
,,0.1357,rocksdb,Gcc 7 error expansion to defined Summary: sorry if these gcc-7/clang-4 cleanups are getting tedious. Closes Differential Revision: D4318792 Pulled By: yiwu-arbug fbshipit-source-id: 8e85891/
,,0.4249,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.4186,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.4211,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.4198,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.29,rocksdb,"Add KEEP_DB env var option Summary: When debugging tests, its useful to preserve the DB to investigate it and check the logs This will allow us to set KEEP_DB=1 to preserve the DB Closes Differential Revision: D4393826 Pulled By: IslamAbdelRahman fbshipit-source-id: 1bff689/direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/Iterator should be in corrupted status if merge operator return false Summary: Iterator should be in corrupted status if merge operator return false. Also add test to make sure if max_successive_merges is hit during write, data will not be lost. Closes Differential Revision: D4322695 Pulled By: yiwu-arbug fbshipit-source-id: b327b05/Missing break in case in DBTestBase::CurrentOptions Summary: Found by gcc-7 compile error. This appeared to be a fault as these options seems too different. Closes Differential Revision: D4324174 Pulled By: yiwu-arbug fbshipit-source-id: 0f65383/Add WriteOptions.no_slowdown Summary: If the WriteOptions.no_slowdown flag is set AND we need to wait or sleep for the write request, then fail immediately with Status::Incomplete(). Closes Differential Revision: D4191405 Pulled By: maysamyabandeh fbshipit-source-id: 7f3ce3f/Range deletion microoptimizations Summary: Made RangeDelAggregators InternalKeyComparator member a reference-to-const so we dont need to copy-construct it. Also added InternalKeyComparator to ImmutableCFOptions so we dont need to construct one for each DBIter. Made MemTable::NewRangeTombstoneIterator and the table readers NewRangeTombstoneIterator() functions return nullptr instead of NewEmptyInternalIterator to avoid the allocation. Updated callers accordingly. Closes Differential Revision: D4208169 Pulled By: ajkr fbshipit-source-id: 2fd65cf/"
,,0.3015,rocksdb,improving the C wrapper Summary: rocksdb_property_int (so that we dont have to parse strings) and rocksdb_set_options (to allow controlling options via strings) a few other missing options exposed a documentation comment fix Closes Differential Revision: D4456569 Pulled By: yiwu-arbug fbshipit-source-id: 9f1fac1/c: allow set savepoint to writebatch Summary: Allow set SavePoint to WriteBatch in C ABI. Closes Differential Revision: D4378556 Pulled By: yiwu-arbug fbshipit-source-id: afca746/direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/C API: support get usage and pinned_usage for cache Summary: Closes Differential Revision: D4327453 Pulled By: yiwu-arbug fbshipit-source-id: bcdbc65/CompactRangeOptions C API Summary: Add C API for CompactRangeOptions. Closes Differential Revision: D4252339 Pulled By: yiwu-arbug fbshipit-source-id: f768f93/c api: expose option for dynamic level size target Summary: Closes Differential Revision: D4245923 Pulled By: yiwu-arbug fbshipit-source-id: 6ee7291/Add C API to set base_backgroud_compactions Summary: Add C API to set base_backgroud_compactions Closes Differential Revision: D4245709 Pulled By: yiwu-arbug fbshipit-source-id: 792c6b8/
,,0.3811,rocksdb,"Fix Windows environment issues Summary: Enable directIO on WritableFileImpl::Append with offset being current length of the file. Enable UniqueID tests on Windows, disable others but leeting them to compile. Unique tests are valuable to detect failures on different filesystems and upcoming ReFS. Clear output in WinEnv Getchildren.This is different from previous strategy, do not touch output on failure. Make sure DBTest.OpenWhenOpen works with windows error message Closes Differential Revision: D4385681 Pulled By: IslamAbdelRahman fbshipit-source-id: c07b702/Fix rocksdb::Status::getState Summary: This fixes the Java API for Status#getState use in Native code and also simplifies the implementation of rocksdb::Status::getState. Closes Closes Differential Revision: D4364181 Pulled By: yiwu-arbug fbshipit-source-id: 8e073b4/direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/Gcc 7 error expansion to defined Summary: sorry if these gcc-7/clang-4 cleanups are getting tedious. Closes Differential Revision: D4318792 Pulled By: yiwu-arbug fbshipit-source-id: 8e85891/Improve Write Stalling System Summary: Current write stalling system has the problem of lacking of positive feedback if the restricted rate is already too low. Users sometimes stack in very low slowdown value. With the diff, we add a positive feedback (increasing the slowdown value) if we recover from slowdown state back to normal. To avoid the positive feedback to keep the slowdown value to be to high, we add issue a negative feedback every time we are close to the stop condition. Experiments show it is easier to reach a relative balance than before. Also increase level0_stop_writes_trigger default from 24 to 32. Since level0_slowdown_writes_trigger default is 20, stop trigger 24 only gives four files as the buffer time to slowdown writes. In order to avoid stop in four files while 20 files have been accumulated, the slowdown value must be very low, which is amost the same as stop. It also doesnt give enough time for the slowdown value to converge. Increase it to 32 will smooth out the system. Closes Differential Revision: D4218519 Pulled By: siying fbshipit-source-id: 95e4088/Add WriteOptions.no_slowdown Summary: If the WriteOptions.no_slowdown flag is set AND we need to wait or sleep for the write request, then fail immediately with Status::Incomplete(). Closes Differential Revision: D4191405 Pulled By: maysamyabandeh fbshipit-source-id: 7f3ce3f/"
,,0.1321,rocksdb,Gcc 7 error expansion to defined Summary: sorry if these gcc-7/clang-4 cleanups are getting tedious. Closes Differential Revision: D4318792 Pulled By: yiwu-arbug fbshipit-source-id: 8e85891/
,,0.384,rocksdb,"Fix Windows environment issues Summary: Enable directIO on WritableFileImpl::Append with offset being current length of the file. Enable UniqueID tests on Windows, disable others but leeting them to compile. Unique tests are valuable to detect failures on different filesystems and upcoming ReFS. Clear output in WinEnv Getchildren.This is different from previous strategy, do not touch output on failure. Make sure DBTest.OpenWhenOpen works with windows error message Closes Differential Revision: D4385681 Pulled By: IslamAbdelRahman fbshipit-source-id: c07b702/direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/"
,,0.1258,rocksdb,"Fix warnings while generating RocksJava documentation Summary: There are a couple of warnings while building RocksJava, coming from Javadoc generation. ``` Generating target/apidocs/org/rocksdb/RocksDB.html... src/main/java/org/rocksdb/RocksDB.java:2139: warning: no throws for org.rocksdb.RocksDBException public void ingestExternalFile(final List<String> filePathList, ^ src/main/java/org/rocksdb/RocksDB.java:2162: warning: no throws for org.rocksdb.RocksDBException public void ingestExternalFile(final ColumnFamilyHandle columnFamilyHandle, ^ ``` Closes Differential Revision: D5178388 Pulled By: sagar0 fbshipit-source-id: a0ab6696d6de78d089a9a860a559f64cc320019e/Replace deprecated RocksDB#addFile with RocksDB#ingestExternalFile Summary: Previously the Java implementation of `RocksDB#addFile` was both incomplete and not inline with the C++ API. Rather than fix it, as I see that `rocksdb::DB::AddFile` is now deprecated in favour of `rocksdb::DB::IngestExternalFile`, I have removed the old broken implementation and implemented `RocksDB#ingestExternalFile`. Closes Closes Differential Revision: D5061264 Pulled By: sagar0 fbshipit-source-id: 85df0899fa1b1fc3535175cac4f52353511d4104/"
,,0.1557,rocksdb,Fix CLANG Analyze Summary: clang analyze shows warnings after we upgrade the CLANG version. Fix them. Closes Differential Revision: D5769060 Pulled By: siying fbshipit-source-id: 3f8e4df715590d8984f6564b608fa08cfdfa5f14/fix backup engine when latest backup corrupt Summary: Backup engine is intentionally openable even when some backups are corrupt. Previously the engine could write new backups as long as the most recent backup wasnt corrupt. This PR makes the backup engine able to create new backups even when the most recent one is corrupt. We now maintain two ID instance variables: `latest_backup_id_` is used when creating backup to choose the new ID `latest_valid_backup_id_` is used when restoring latest backup since we want most recent valid one Closes Differential Revision: D5734148 Pulled By: ajkr fbshipit-source-id: db440707b31df2c7b084188aa5f6368449e10bcf/
,,0.18100000000000002,rocksdb,"Small issues (#4564) Summary: Couple of very minor improvements (typos in comments, full qualification of class name, reordering members of a struct to make it smaller) Pull Request resolved: Differential Revision: D10510183 Pulled By: maysamyabandeh fbshipit-source-id: c7ddf9bfbf2db08cd31896c3fd93789d3fa68c8b/Support pragma once in all header files and cleanup some warnings (#4339) Summary: As you know, almost all compilers support ""pragma once"" keyword instead of using include guards. To be keep consistency between header files, all header files are edited. Besides this, try to fix some warnings about loss of data. Pull Request resolved: Differential Revision: D9654990 Pulled By: ajkr fbshipit-source-id: c2cf3d2d03a599847684bed81378c401920ca848/"
,,0.0956,rocksdb,"WriteBatch::Iterate wrongly returns Status::Corruption (#4478) Summary: Wrong I overwrite `WriteBatch::Handler::Continue` to return _false_ at some point, I always get the `Status::Corruption` error. I dont think this check is used correctly here: The counter in `found` cannot reflect all entries in the WriteBatch when we exit the loop early. Pull Request resolved: Differential Revision: D10317416 Pulled By: yiwu-arbug fbshipit-source-id: cccae3382805035f9b3239b66682b5fcbba6bb61/"
,,0.1789,rocksdb,"Support pragma once in all header files and cleanup some warnings (#4339) Summary: As you know, almost all compilers support ""pragma once"" keyword instead of using include guards. To be keep consistency between header files, all header files are edited. Besides this, try to fix some warnings about loss of data. Pull Request resolved: Differential Revision: D9654990 Pulled By: ajkr fbshipit-source-id: c2cf3d2d03a599847684bed81378c401920ca848/Add path to WritableFileWriter. (#4039) Summary: We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise its hard to tell what has been going on. Pull Request resolved: Differential Revision: D8670178 Pulled By: riversand963 fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/"
,,0.1696,rocksdb,"Support pragma once in all header files and cleanup some warnings (#4339) Summary: As you know, almost all compilers support ""pragma once"" keyword instead of using include guards. To be keep consistency between header files, all header files are edited. Besides this, try to fix some warnings about loss of data. Pull Request resolved: Differential Revision: D9654990 Pulled By: ajkr fbshipit-source-id: c2cf3d2d03a599847684bed81378c401920ca848/"
,,0.1807,rocksdb,"Consolidate hash function used for non-persistent data in a new function (#5155) Summary: Create new function NPHash64() and GetSliceNPHash64(), which are currently implemented using murmurhash. Replace the current direct call of murmurhash() to use the new functions if the hash results are not used in on-disk format. This will make it easier to try out or switch to alternative functions in the uses where data format compatibility doesnt need to be considered. This part shouldnt have any performance impact. Also, the sharded cache hash function is changed to the new format, because it falls into this categoery. It doesnt show visible performance impact in db_bench results. CPU showed by perf is increased from about 0.2% to 0.4% in an extreme benchmark setting (4KB blocks, no-compression, everything cached in block cache). Weve known that the current hash function used, our own Hash() has serious hash quality problem. It can generate a lots of conflicts with similar input. In this use case, it means extra lock contention for reads from the same file. This slight CPU regression is worthy to me to counter the potential bad performance with hot keys. And hopefully this will get further improved in the future with a better hash function. cache_tests condition is relaxed a little bit to. The new hash is slightly more skewed in this use case, but I manually checked the data and see the hash results are still in a reasonable range. Pull Request resolved: Differential Revision: D14834821 Pulled By: siying fbshipit-source-id: ec9a2c0a2f8ae4b54d08b13a5c2e9cc97aa80cb5/"
,,0.0962,rocksdb,"Fix memorty leak in `rocksdb_wal_iter_get_batch` function (#5515) Summary: `wal_batch.writeBatchPtr.release()` gives up the ownership of the original `WriteBatch`, but there is no new owner, which causes memory leak. The patch is simple. Removing `release()` prevent ownership change. `std::move` is for speed. Pull Request resolved: Differential Revision: D16264281 Pulled By: riversand963 fbshipit-source-id: 51c556b7a1c977325c3aa24acb636303847151fa/"
,,0.4787,rocksdb,"Add new persistent 64-bit hash (#5984) Summary: For upcoming new SST filter implementations, we will use a new 64-bit hash function (XXH3 preview, slightly modified). This change updates hash.{h,cc} for that change, adds unit tests, and out-of-lines the implementations to keep hash.h as clean/small as possible. In developing the unit tests, I discovered that the XXH3 preview always returns zero for the empty string. Zero is problematic for some algorithms (including an upcoming SST filter implementation) if it occurs more often than at the ""natural"" rate, so it should not be returned from trivial values using trivial seeds. I modified our fork of XXH3 to return a modest hash of the seed for the empty string. With hash function details out-of-lines in hash.h, it makes sense to enable XXH_INLINE_ALL, so that direct calls to XXH64/XXH32/XXH3p are inlined. To fix array-bounds warnings on some inline calls, I injected some casts to uintptr_t in xxhash.cc. (Issue reported to Yann.) Revised: Reverted using XXH_INLINE_ALL for now. Some Facebook checks are unhappy about on xxhash.cc file. I would fix that by rename to xxhash_cc.h, but to best preserve history I want to do that in a separate commit (PR) from the uintptr casts. Also updated filter_bench for this change, improving the performance predictability of dry run hashing and adding support for 64-bit hash (for upcoming new SST filter implementations, minor dead code in the tool for now). Pull Request resolved: Differential Revision: D18246567 Pulled By: pdillinger fbshipit-source-id: 6162fbf6381d63c8cc611dd7ec70e1ddc883fbb8/Update xxhash.cc to allow combined compilation (#5969) Summary: To fix unity_test Pull Request resolved: Test Plan: make unity_test Differential Revision: D18140426 Pulled By: pdillinger fbshipit-source-id: d5516e6d665f57e3706b9f9b965b0c458e58ccef/Misc hashing updates / upgrades (#5909) Summary: Updated our included xxhash implementation to version 0.7.2 (== the latest dev version as of 2019-10-09). Using XXH_NAMESPACE (like other fb projects) to avoid potential name collisions. Added fastrange64, and unit tests for it and fastrange32. These are faster alternatives to hash % range. Use preview version of XXH3 instead of MurmurHash64A for NPHash64 Had to update cache_test to increase probability of passing for any given hash function. Use fastrange64 instead of % with uses of NPHash64 Had to fix WritePreparedTransactionTest.CommitOfDelayedPrepared to avoid deadlock apparently caused by new hash collision. Set default seed for NPHash64 because specifying a seed rarely makes sense for it. Removed unnecessary include xxhash.h in a popular .h file Rename preview version of XXH3 to XXH3p for clarity and to ease backward compatibility in case final version of XXH3 is integrated. Relying on existing unit tests for NPHash64-related changes. Each new implementation of fastrange64 passed unit tests when manipulating my local build to select it. I havent done any integration performance tests, but I consider the improved performance of the pieces being swapped in to be well established. Pull Request resolved: Differential Revision: D18125196 Pulled By: pdillinger fbshipit-source-id: f6bf83d49d20cbb2549926adf454fd035f0ecc0d/"
,,0.4967,rocksdb,"Add new persistent 64-bit hash (#5984) Summary: For upcoming new SST filter implementations, we will use a new 64-bit hash function (XXH3 preview, slightly modified). This change updates hash.{h,cc} for that change, adds unit tests, and out-of-lines the implementations to keep hash.h as clean/small as possible. In developing the unit tests, I discovered that the XXH3 preview always returns zero for the empty string. Zero is problematic for some algorithms (including an upcoming SST filter implementation) if it occurs more often than at the ""natural"" rate, so it should not be returned from trivial values using trivial seeds. I modified our fork of XXH3 to return a modest hash of the seed for the empty string. With hash function details out-of-lines in hash.h, it makes sense to enable XXH_INLINE_ALL, so that direct calls to XXH64/XXH32/XXH3p are inlined. To fix array-bounds warnings on some inline calls, I injected some casts to uintptr_t in xxhash.cc. (Issue reported to Yann.) Revised: Reverted using XXH_INLINE_ALL for now. Some Facebook checks are unhappy about on xxhash.cc file. I would fix that by rename to xxhash_cc.h, but to best preserve history I want to do that in a separate commit (PR) from the uintptr casts. Also updated filter_bench for this change, improving the performance predictability of dry run hashing and adding support for 64-bit hash (for upcoming new SST filter implementations, minor dead code in the tool for now). Pull Request resolved: Differential Revision: D18246567 Pulled By: pdillinger fbshipit-source-id: 6162fbf6381d63c8cc611dd7ec70e1ddc883fbb8/Misc hashing updates / upgrades (#5909) Summary: Updated our included xxhash implementation to version 0.7.2 (== the latest dev version as of 2019-10-09). Using XXH_NAMESPACE (like other fb projects) to avoid potential name collisions. Added fastrange64, and unit tests for it and fastrange32. These are faster alternatives to hash % range. Use preview version of XXH3 instead of MurmurHash64A for NPHash64 Had to update cache_test to increase probability of passing for any given hash function. Use fastrange64 instead of % with uses of NPHash64 Had to fix WritePreparedTransactionTest.CommitOfDelayedPrepared to avoid deadlock apparently caused by new hash collision. Set default seed for NPHash64 because specifying a seed rarely makes sense for it. Removed unnecessary include xxhash.h in a popular .h file Rename preview version of XXH3 to XXH3p for clarity and to ease backward compatibility in case final version of XXH3 is integrated. Relying on existing unit tests for NPHash64-related changes. Each new implementation of fastrange64 passed unit tests when manipulating my local build to select it. I havent done any integration performance tests, but I consider the improved performance of the pieces being swapped in to be well established. Pull Request resolved: Differential Revision: D18125196 Pulled By: pdillinger fbshipit-source-id: f6bf83d49d20cbb2549926adf454fd035f0ecc0d/Faster new DynamicBloom implementation (for memtable) (#5762) Summary: Since DynamicBloom is now only used in-memory, were free to change it without schema compatibility issues. The new implementation is drawn from (with manifest permission) This has several speed advantages over the prior implementation: * Uses fastrange instead of % * Minimum logic to determine first (and all) probed memory addresses * (Major) Two probes per 64-bit memory fetch/write. * Very fast and effective (murmur-like) hash expansion/re-mixing. (At least on recent CPUs, integer multiplication is very cheap.) While a Bloom filter with 512-bit cache locality has about a 1.15x FP rate penalty (e.g. 0.84% to 0.97%), further restricting to two probes per 64 bits incurs an additional 1.12x FP rate penalty (e.g. 0.97% to 1.09%). Nevertheless, the unit tests show no ""mediocre"" FP rate samples, unlike the old implementation with more erratic FP rates. Especially for the memtable, we expect speed to outweigh somewhat higher FP rates. For example, a negative table query would have to be 1000x slower than a BF query to justify doubling BF query time to shave 10% off FP rate (working assumption around 1% FP rate). While that seems likely for SSTs, my data suggests a speed factor of roughly 50x for the memtable (vs. BF; ~1.5% lower write throughput when enabling memtable Bloom filter, after this change). Thus, its probably not worth even 5% more time in the Bloom filter to shave off 1/10th of the Bloom FP rate, or 0.1% in absolute terms, and its probably at least 20% slower to recoup that much FP rate from this new implementation. Because of this, we do not see a need for a locality option that affects the MemTable Bloom filter and have decoupled the MemTable Bloom filter from Options::bloom_locality. Note that just 3% more memory to the Bloom filter (10.3 bits per key vs. just 10) is able to make up for the ~12% FP rate drop in the new implementation: [] Nearly ""ideal"" FP-wise but reasonably fast cache-local implementation [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_WORM64_FROM32_any.out 10000000 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_WORM64_FROM32_any.out time: 3.29372 sampled_fp_rate: 0.00985956 ... [] Close match to this new implementation [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out 10000000 6 10.3 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out time: 2.10072 sampled_fp_rate: 0.00985655 ... [] Old locality=1 implementation [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_ROCKSDB_DYNAMIC_any.out 10000000 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_ROCKSDB_DYNAMIC_any.out time: 3.95472 sampled_fp_rate: 0.00988943 ... Also note the dramatic speed improvement vs. alternatives. Performance unit test: DynamicBloomTest.concurrent_with_perf is updated to report more precise timing data. (Measure running time of each thread, not just longest running thread, etc.) Results averaged over various sizes enabled with and 20 runs each; old dynamic bloom refers to locality=1, the faster of the old: old dynamic bloom, avg add latency 65.6468 new dynamic bloom, avg add latency 44.3809 old dynamic bloom, avg query latency 50.6485 new dynamic bloom, avg query latency 43.2186 old avg parallel add latency 41.678 new avg parallel add latency 24.5238 old avg parallel hit latency 14.6322 new avg parallel hit latency 12.3939 old avg parallel miss latency 16.7289 new avg parallel miss latency 12.2134 Tested on a dedicated 64-bit production machine at Facebook. Significant improvement all around. Despite now using std::atomic<uint64_t>, quick before-and-after test on a 32-bit machine (Intel Atom N270, released 2008) shows no regression in performance, in some cases modest improvement. Performance integration test (synthetic): with DEBUG_LEVEL=0, used TEST_TMPDIR=/dev/shm ./db_bench and optionally with 300 runs each configuration. Write throughput change by enabling memtable bloom: Old locality=0: Old locality=1: New: conclusion seems to substantially close the gap Readmissing throughput change by enabling memtable bloom: Old locality=0: +34.47% Old locality=1: +34.80% New: +33.25% conclusion maybe a small new penalty from FP rate Readrandom throughput change by enabling memtable bloom: Old locality=0: +31.54% Old locality=1: +31.13% New: +30.60% conclusion maybe also from FP rate (after memtable flush) Another conclusion we can draw from this new implementation is that the existing 32-bit hash function is not inherently crippling the Bloom filter speed or accuracy, below about 5 million keys. For speed, the implementation is essentially the same whether starting with 32-bits or 64-bits of hash; it just determines whether the first multiplication after fastrange is a pseudorandom expansion or needed re-mix. Note that this multiplication can occur while memory is fetching. For accuracy, in a standard configuration, you need about 5 million keys before you have about a 1.1x FP penalty due to using a 32-bit hash vs. 64-bit: [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out $((5 * 1000 * 1000 * 10)) 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out time: 2.52069 sampled_fp_rate: 0.0118267 ... [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_any.out $((5 * 1000 * 1000 * 10)) 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_any.out time: 2.43871 sampled_fp_rate: 0.0109059 Pull Request resolved: Differential Revision: D17214194 Pulled By: pdillinger fbshipit-source-id: ad9da031772e985fd6b62a0e1db8e81892520595/"
,,0.3854,rocksdb,"Misc hashing updates / upgrades (#5909) Summary: Updated our included xxhash implementation to version 0.7.2 (== the latest dev version as of 2019-10-09). Using XXH_NAMESPACE (like other fb projects) to avoid potential name collisions. Added fastrange64, and unit tests for it and fastrange32. These are faster alternatives to hash % range. Use preview version of XXH3 instead of MurmurHash64A for NPHash64 Had to update cache_test to increase probability of passing for any given hash function. Use fastrange64 instead of % with uses of NPHash64 Had to fix WritePreparedTransactionTest.CommitOfDelayedPrepared to avoid deadlock apparently caused by new hash collision. Set default seed for NPHash64 because specifying a seed rarely makes sense for it. Removed unnecessary include xxhash.h in a popular .h file Rename preview version of XXH3 to XXH3p for clarity and to ease backward compatibility in case final version of XXH3 is integrated. Relying on existing unit tests for NPHash64-related changes. Each new implementation of fastrange64 passed unit tests when manipulating my local build to select it. I havent done any integration performance tests, but I consider the improved performance of the pieces being swapped in to be well established. Pull Request resolved: Differential Revision: D18125196 Pulled By: pdillinger fbshipit-source-id: f6bf83d49d20cbb2549926adf454fd035f0ecc0d/"
,,0.077,rocksdb,fix typo (#6099) Summary: fix a typo in struct ReadOptions Pull Request resolved: Differential Revision: D18729618 fbshipit-source-id: 850a9df71f7c0abebea17feab77b8d5874e8ba0a/
,,0.2435,rocksdb,"Allow fractional bits/key in BloomFilterPolicy (#6092) Summary: Theres no technological impediment to allowing the Bloom filter bits/key to be non-integer (fractional/decimal) values, and it provides finer control over the memory vs. accuracy trade-off. This is especially handy in using the format_version=5 Bloom filter in place of the old one, because bits_per_key=9.55 provides the same accuracy as the old bits_per_key=10. This change not only requires refining the logic for choosing the best num_probes for a given bits/key setting, it revealed a flaw in that logic. As bits/key gets higher, the best num_probes for a cache-local Bloom filter is closer to bpk / 2 than to bpk * 0.69, the best choice for a standard Bloom filter. For example, at 16 bits per key, the best num_probes is 9 (FP rate 0.0843%) not 11 (FP rate 0.0884%). This change fixes and refines that logic (for the format_version=5 Bloom filter only, just in case) based on empirical tests to find accuracy inflection points between each num_probes. Although bits_per_key is now specified as a double, the new Bloom filter converts/rounds this to ""millibits / key"" for predictable/precise internal computations. Just in case of unforeseen compatibility issues, we round to the nearest whole number bits / key for the legacy Bloom filter, so as not to unlock new behaviors for it. Pull Request resolved: Test Plan: unit tests included Differential Revision: D18711313 Pulled By: pdillinger fbshipit-source-id: 1aa73295f152a995328cb846ef9157ae8a05522a/"
,,0.23,rocksdb,"Add an option to prevent DB::Open() from querying sizes of all sst files (#6353) Summary: When paranoid_checks is on, DBImpl::CheckConsistency() iterates over all sst files and calls Env::GetFileSize() for each of them. As far as I could understand, this is pretty arbitrary and doesnt affect correctness if filesystem doesnt corrupt fsynced files, the file sizes will always match; if it does, it may as well corrupt contents as well as sizes, and rocksdb doesnt check contents on open. If there are thousands of sst files, getting all their sizes takes a while. If, on top of that, Env is overridden to use some remote storage instead of local filesystem, it can be *really* slow and overload the remote storage service. This PR adds an option to not do GetFileSize(); instead it does GetChildren() for parent directory to check that all the expected sst files are at least present, but doesnt check their sizes. We cant just disable paranoid_checks instead because paranoid_checks do a few other important things: make the DB read-only on write errors, print error messages on read errors, etc. Pull Request resolved: Test Plan: ran the added sanity check unit test. Will try it out in a LogDevice test cluster where the GetFileSize() calls are causing a lot of trouble. Differential Revision: D19656425 Pulled By: al13n321 fbshipit-source-id: c2c421b367633033760d1f56747bad206d1fbf82/Shorten certain test names to avoid infra failure (#6352) Summary: Unit test names, together with other components, are used to create log files during some internal testing. Overly long names cause infra failure due to file names being too long. Look for internal tests. Pull Request resolved: Differential Revision: D19649307 Pulled By: riversand963 fbshipit-source-id: 6f29de096e33c0eaa87d9c8702f810eda50059e7/Fix error message (#6264) Summary: Fix an error message when CURRENT is not found. Test plan (dev server) ``` make check ``` Pull Request resolved: Differential Revision: D19300699 Pulled By: riversand963 fbshipit-source-id: 303fa206386a125960ecca1dbdeff07422690caf/Fix & test rocksdb_filterpolicy_create_bloom_full (#6132) Summary: Add overrides needed in FilterPolicy wrapper to fix rocksdb_filterpolicy_create_bloom_full (see issue Re-enabled assertion in BloomFilterPolicy::CreateFilter that was being violated. Expanded c_test to identify Bloom filter implementations by FP counts. (Without the fix, updated test will trigger assertion and fail otherwise without the assertion.) Fixes Pull Request resolved: Test Plan: updated c_test, also run under valgrind. Differential Revision: D18864911 Pulled By: pdillinger fbshipit-source-id: 08e81d7b5368b08e501cd402ef5583f2650c19fa/"
,,0.1315,rocksdb,"Fixes for g++ 4.9.2 compatibility (#6053) Summary: Taken from merryChris in Stackoverflow ref on {{}} vs. {}: Note to reader: .clear() does not empty out an ostringstream, but .str("""") suffices because we dont have to worry about clearing error flags. Pull Request resolved: Test Plan: make check, manual run of filter_bench Differential Revision: D18602259 Pulled By: pdillinger fbshipit-source-id: f6190f83b8eab4e80e7c107348839edabe727841/"
,,0.0937,rocksdb,"Work around weird unused errors with Mingw (#6075) Summary: From the reset of the code, it looks this this maybe can be unconditionally given the attribute? But I couldnt test with MSVC so I defensively put under CPP. Pull Request resolved: Differential Revision: D18723749 fbshipit-source-id: 45fc8732c28dd29aab1644225d68f3c6f39bd69b/"
,,0.1986,rocksdb,"Replace namespace name ""rocksdb"" with ROCKSDB_NAMESPACE (#6433) Summary: When dynamically linking two binaries together, different builds of RocksDB from two sources might cause errors. To provide a tool for user to solve the problem, the RocksDB namespace is changed to a flag which can be overridden in build time. Pull Request resolved: Test Plan: Build release, all and jtest. Try to build with ROCKSDB_NAMESPACE with another flag. Differential Revision: D19977691 fbshipit-source-id: aa7f2d0972e1c31d75339ac48478f34f6cfcfb3e/"
,,0.1941,rocksdb,"Replace namespace name ""rocksdb"" with ROCKSDB_NAMESPACE (#6433) Summary: When dynamically linking two binaries together, different builds of RocksDB from two sources might cause errors. To provide a tool for user to solve the problem, the RocksDB namespace is changed to a flag which can be overridden in build time. Pull Request resolved: Test Plan: Build release, all and jtest. Try to build with ROCKSDB_NAMESPACE with another flag. Differential Revision: D19977691 fbshipit-source-id: aa7f2d0972e1c31d75339ac48478f34f6cfcfb3e/"
,,0.2391,rocksdb,"Fix wrong key being read on ingested file with global seqno and delta encoding (#6669) Summary: On reading an ingested SST file, `DataBlockIter` will replace seqno encoded in a key with global seqno. However, if the original seqno was part of the prefix used for the next key, the global seqno is by mistake used as part of the prefix to construct the next key, causing wrong result being returned. Although at this point it is only software error while data in the file is not corrupted, the issue can further cause compaction output out of order and corrupted result when the ingested SST participated in compaction. Fixing the issue by save the actual seqno and restore it before the key being used as prefix to construct next key. The unit test is by Little-Wallace from Fixing Pull Request resolved: Test Plan: New unit test Signed-off-by: Yi Wu Reviewed By: cheng-chang Differential Revision: D20931808 Pulled By: ajkr fbshipit-source-id: f01959c35d6a493954dca981663766c7a5a9e8ab/fix some spelling typos (#6464) Summary: Found from Debians ""Lintian"" program Pull Request resolved: Differential Revision: D20162862 Pulled By: zhichao-cao fbshipit-source-id: 06941ee2437b038b2b8045becbe9d2c6fbff3e12/Replace namespace name ""rocksdb"" with ROCKSDB_NAMESPACE (#6433) Summary: When dynamically linking two binaries together, different builds of RocksDB from two sources might cause errors. To provide a tool for user to solve the problem, the RocksDB namespace is changed to a flag which can be overridden in build time. Pull Request resolved: Test Plan: Build release, all and jtest. Try to build with ROCKSDB_NAMESPACE with another flag. Differential Revision: D19977691 fbshipit-source-id: aa7f2d0972e1c31d75339ac48478f34f6cfcfb3e/"
,,0.2099,rocksdb,"Replace namespace name ""rocksdb"" with ROCKSDB_NAMESPACE (#6433) Summary: When dynamically linking two binaries together, different builds of RocksDB from two sources might cause errors. To provide a tool for user to solve the problem, the RocksDB namespace is changed to a flag which can be overridden in build time. Pull Request resolved: Test Plan: Build release, all and jtest. Try to build with ROCKSDB_NAMESPACE with another flag. Differential Revision: D19977691 fbshipit-source-id: aa7f2d0972e1c31d75339ac48478f34f6cfcfb3e/WriteUnPrepared: Fix assertion during recovery (#6419) Summary: During recovery, multiple (un)prepared batches could exist in the same WAL record due to group commit. This breaks an assertion in `MemTableInserter::MarkBeginPrepare`. To fix, reset unprepared_batch_ to false after `MarkEndPrepare`. Pull Request resolved: Differential Revision: D19896148 Pulled By: lth fbshipit-source-id: b1a32ef88f775a0881264a18bd1a4a5b8c85eee3/"
,,0.1971,rocksdb,"Replace namespace name ""rocksdb"" with ROCKSDB_NAMESPACE (#6433) Summary: When dynamically linking two binaries together, different builds of RocksDB from two sources might cause errors. To provide a tool for user to solve the problem, the RocksDB namespace is changed to a flag which can be overridden in build time. Pull Request resolved: Test Plan: Build release, all and jtest. Try to build with ROCKSDB_NAMESPACE with another flag. Differential Revision: D19977691 fbshipit-source-id: aa7f2d0972e1c31d75339ac48478f34f6cfcfb3e/"
,,0.2139,rocksdb,"Replace namespace name ""rocksdb"" with ROCKSDB_NAMESPACE (#6433) Summary: When dynamically linking two binaries together, different builds of RocksDB from two sources might cause errors. To provide a tool for user to solve the problem, the RocksDB namespace is changed to a flag which can be overridden in build time. Pull Request resolved: Test Plan: Build release, all and jtest. Try to build with ROCKSDB_NAMESPACE with another flag. Differential Revision: D19977691 fbshipit-source-id: aa7f2d0972e1c31d75339ac48478f34f6cfcfb3e/"
