Topic_no,Keywords,Contrib,System,Text
1,"call, add, result, change, time, test, key, object, option, create, warning, refactor, work, copy, reference, single, multiple, filter, bit, share",0.0833,conscrypt,"Retire SecurityManager. This change removes all the code that was calling getSecurityManager, and removes all use of AccessController.doPrivileged. It also changes the implementation of AccessController so it doesnt actually do anything; its only there for source-level compatibility. Bug: 2585285 Change-Id: I1f0295a4f12bce0316d8073011d8593fee116f71/"
,,0.0784,conscrypt,OpenSSLCipher: check for null params The documentation says init with null should be handled. Bug: Change-Id: If640a1f62e6002191d552047ccbe5eba5badacc1/
,,0.0951,conscrypt,"external/conscrypt: remove DHKey. BoringSSL has DH, but its not wired up to EVP any longer. It would be possible to get DHKey working directly using DH because it doesnt use anything non-standard, but its probably not worth worrying about. Bug: 20518803 Bug: 20522271 Change-Id: I7167ba5ae96b0ba914c5759b6293236e4a3302da/"
,,0.1019,conscrypt,"Suppress Error-Prone warnings These warnings are not useful here, so suppress them./"
,,0.0977,conscrypt,"Suppress Error-Prone warnings These warnings are not useful here, so suppress them./"
,,0.0588,Frostwire,[common] fix warnings in mp4 Box class/
,,0.1046,Frostwire,[android] Fixing tab carousel height calculations. Removing unused carousel shadow references
,,0.0597,Frostwire,[android] TODO comment about crash in NotificationHelper#buildNotification/
,,0.192,Frostwire,[WIP] Setting up correclty strings to empty fragments (#641) * [WIP] Setting up correclty strings to empty fragments * Adding default fragment empty message with a field * Removed getString method call by suggestion. Fixing the string empty value for RecentFragment./
,,0.1904,Frostwire,[WIP] Setting up correclty strings to empty fragments (#641) * [WIP] Setting up correclty strings to empty fragments * Adding default fragment empty message with a field * Removed getString method call by suggestion. Fixing the string empty value for RecentFragment./
,,0.192,Frostwire,[WIP] Setting up correclty strings to empty fragments (#641) * [WIP] Setting up correclty strings to empty fragments * Adding default fragment empty message with a field * Removed getString method call by suggestion. Fixing the string empty value for RecentFragment./
,,0.1953,Frostwire,[WIP] Setting up correclty strings to empty fragments (#641) * [WIP] Setting up correclty strings to empty fragments * Adding default fragment empty message with a field * Removed getString method call by suggestion. Fixing the string empty value for RecentFragment./
,,0.0534,Frostwire,[common] commented debug log in extractor/
,,0.0887,Frostwire,[android] should solve issue with non-responding keyword filter first time its flipped to negation/
,,0.0634,Frostwire,[android] avoid header update with wrong data in MyFilesFragment#onLoadFinished/
,,0.107,Frostwire,[android] build fix/[android] s/StartDownloadTask/AsyncStartDownload refactor Favors use of Asyncs api over buggy ContextTask/[android] workaround fix in notifyHistogramsUpdate to avoid excessive number of tasks in background/[android] should solve issue with non-responding keyword filter first time its flipped to negation/
,,0.0664,Frostwire,[android] NPE issue with FWVibrator/
,,0.0664,Frostwire,[android] NPE issue with FWVibrator/
,,0.0686,Frostwire,[android] NPE issue with FWVibrator/
,,0.0686,Frostwire,[android] NPE issue with FWVibrator/
,,0.0737,Frostwire,"[desktop] cleanup, refactors, deprecation fixes/"
,,0.0823,Frostwire,"[desktop] cleanup, refactors, deprecation fixes/"
,,0.0694,Frostwire,"[desktop] cleanup, refactors, deprecation fixes/"
,,0.0716,Frostwire,"[desktop] cleanup, refactors, deprecation fixes/"
,,0.0737,Frostwire,"[desktop] cleanup, refactors, deprecation fixes/"
,,0.0613,javacpp,"* Added new `Pointer.deallocate(false)` call to disable garbage collection on a per object basis, allowing users to deal with memory leaks in other ways * Changed the default compiler option `-mfpu=vfpv` for ARM to `-mfpu=vfpv3-d16`, because the former is not supported by Tegra 2/"
,,0.0648,javacpp,* Catch `SecurityException` in `Loader.getCacheDir()` (pull Logic in the area will already try the next directory./
,,0.0586,javacpp,* Fix `SharedPtrAdapter` and `UniquePtrAdapter` failing to take ownership of temporary objects/
,,0.063,jna,Testsuite fixes./
,,0.1229,OpenDDS,"Fixes for Saftey Profile and C++03/Refactor with Stricter Time Types Types representing monotonic clock time, system clock time and time duration. Refactored the core libraries to use them over ACE_Time_Value wherever possible. Tests were left alone for the most part unless they interacted with the converted values in the core libraries. Also fixes for the previous monotonic commits./"
,,0.0697,pljava,Fixed needed code to accomodate API change for LargeObjects/
,,0.1347,pljava,Merge pull request from tada/bug/REL1_5_STABLE/issue142 Enable row triggers to suppress operations./Enable row triggers to suppress operations. Adds to TriggerData the suppress() method suggested in issue pull request from tada/bug/REL1_5_STABLE/issue134 Accomodate upstream SPI_push/pop API changes (issue
,,0.0784,pljava,Merge pull request from tada/bug/REL1_5_STABLE/issue134 Accomodate upstream SPI_push/pop API changes (issue
,,0.075,realm-java,Merge pull request from mekjaer/gc-issue Gc issue. Implementation of Context in all tightdb objects/Merge pull request from mekjaer/group-readonly-bug check for read-only group mode added in constrcutor + test case/
,,0.0621,realm-java,Merge pull request from zaki50/fix_typo fix typos/fix typos/
,,0.0673,realm-java,Merge pull request from realm/cm-bug-handler Cleanup SharedGroup.java and Group.java/
,,0.0599,realm-java,Merge pull request from zaki50/fix_typo fix typos/fix typos/
,,0.0566,realm-java,Fixed unit tests./
,,0.0692,realm-java,Merge pull request from realm/merge-a94bb3-to-master Fix merge from a94bb3 to master/Enable and fix warnings (#3961) Adapt the same warning options from object store/
,,0.4459,realm-java,"Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/Merge pull request from realm/merge-6d0712-to-master Fix merge from 6d0712 to master/Merge pull request from realm/my/fix_warnings_in_proxy_classes fix warnings in generated code/fix warnings in generated code/Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/Crash when on constructor calls another with default values (#4253)/Fix default values crashing if calling another constructor (#4249)/Merge pull request from realm/merge-ffe5bd-to-master Fix merge from ffe5bd to master/improve performance of getters and setters in proxy classes (#4206) * improve performance of getters and setters in proxy classes This change is a part of fixes of * removed unused argment * Update CHANGELOG.md/"
,,0.4543,realm-java,"Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/Merge pull request from realm/merge-6d0712-to-master Fix merge from 6d0712 to master/Merge pull request from realm/my/fix_warnings_in_proxy_classes fix warnings in generated code/more fix for ErrorProne warnings in generated code/fix warnings in generated code/Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/Crash when on constructor calls another with default values (#4253)/Fix default values crashing if calling another constructor (#4249)/Merge pull request from realm/merge-ffe5bd-to-master Fix merge from ffe5bd to master/improve performance of getters and setters in proxy classes (#4206) * improve performance of getters and setters in proxy classes This change is a part of fixes of * removed unused argment * Update CHANGELOG.md/"
,,0.4392,realm-java,"Fix exception thrown from backlinks field (#4500) * add test case that reproduce * now backlinks geters throw IllegalStateException if the object is deleted or not yet loaded. * update CHANGELOG * add test * update a test * modify method name Row.checkIfBacklinkAvailable() to Row.checkIfAttached() * update variable names in test/Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/Merge pull request from realm/merge-6d0712-to-master Fix merge from 6d0712 to master/Merge pull request from realm/my/fix_warnings_in_proxy_classes fix warnings in generated code/more fix for ErrorProne warnings in generated code/fix warnings in generated code/Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/Crash when on constructor calls another with default values (#4253)/Fix default values crashing if calling another constructor (#4249)/Merge pull request from realm/merge-ffe5bd-to-master Fix merge from ffe5bd to master/improve performance of getters and setters in proxy classes (#4206) * improve performance of getters and setters in proxy classes This change is a part of fixes of * removed unused argment * Update CHANGELOG.md/"
,,0.3697,realm-java,"Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/"
,,0.3724,realm-java,"Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/"
,,0.3289,realm-java,"Resume sending update messages (#4419) Fixes (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/"
,,0.2595,realm-java,"Merge pull request from realm/merge-f3f8ab-to-master Fix merge from f3f8ab to master/Fix threading bugs in RunInLooperThread rule (#4563) * Fix threading bugs in RunInLooperThread rule * Respond to comments Fix spelling errors Clean up multi-error recovery./Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/Merge pull request from realm/merge-52ba43-to-master Fix merge from 52ba43 to master/Introduce ErrorProne plugin (#4342)/Merge pull request from realm/merge-154419-to-master Fix merge from 154419 to master/Fix warnings from error prone plugin (#4339) This PR does not add the plugin, just fix the warnings. Ill add the plugin in another PR with suppressing some warnings./"
,,0.5328,realm-java,"Implement getInstanceAsync (#4570) Fix Add APIs to get Realm instance asynchronously. Remove some useless methods. There some work need to be done before create the first Realm instance in the process, like creating schema table, doing migration, etc.. Those could block the UI thread quite badly. This commit tries to do those initialization work in the background and hold a Realm instance in the background until the 2nd instance created in the caller thread. A better solution than this would be do initialization in the background and only deliver a column indices cache to caller thread without holding a Realm instance in the background. But that is not possible since from the current database design, we cannot know if the schema changes compared with the last time it was opened. Also create a SharedGroup in the background and handover it to the caller thread is not ideal as well. That not only requires some design changes in the Object Store RealmCoordinator, but also is a very special use case of SharedGroup which core is not designed for. SharedGroup Leaking during the handover is another flaw for this solution we can only rely on the GC to collect the leaked SharedGroup during handover then./Fix threading bugs in RunInLooperThread rule (#4563) * Fix threading bugs in RunInLooperThread rule * Respond to comments Fix spelling errors Clean up multi-error recovery./Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/"
,,0.4654,realm-java,"Implement getInstanceAsync (#4570) Fix Add APIs to get Realm instance asynchronously. Remove some useless methods. There some work need to be done before create the first Realm instance in the process, like creating schema table, doing migration, etc.. Those could block the UI thread quite badly. This commit tries to do those initialization work in the background and hold a Realm instance in the background until the 2nd instance created in the caller thread. A better solution than this would be do initialization in the background and only deliver a column indices cache to caller thread without holding a Realm instance in the background. But that is not possible since from the current database design, we cannot know if the schema changes compared with the last time it was opened. Also create a SharedGroup in the background and handover it to the caller thread is not ideal as well. That not only requires some design changes in the Object Store RealmCoordinator, but also is a very special use case of SharedGroup which core is not designed for. SharedGroup Leaking during the handover is another flaw for this solution we can only rely on the GC to collect the leaked SharedGroup during handover then./Fine grained locks for RealmCache (#4551) Separated lock for different RealmConfiguration instead of one lock on the RealmCache class. So Opening Realm instances from different configurations wont block each other. DynamicRealm which is created during opening type Realm will not be associated to any RealmCache to avoid recursive locks and multiple times initial block. (Also make the code easier.) This is for and part of implementation of ./Merge branch releases into my/fix_memory_leaking/Merge pull request from realm/merge-196ee5-to-master Fix merge from 196ee5 to master/fix API incompatibility introduced in 3.1.0 (#4455)/Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/Refactor Schemas into separate native and realm-based implementations (#4382) * Refactor Schemas into separate native and realm-based implementations * Fix all tests * Respond to PR comments * Temporary (git add .) kludge to fix visiblity problem/Add detailed notification for RealmObject (#4331) See Add ObjectChangeSet & RealmObjectChangeListener. Add OsObject to wrap ObjectStores Object for notifications. No more false positive notifications for RealmObject. Use ObserverPairList in ProxyState instead of normal list to solve the potential listener removal problems which is handled well by the ObserverPairList. Fix tests./Fail Realm.migrateRealm() if a SyncConfiguration is used. (#4292)/Implement fine gained notification (#4191) Add RealmObservable and RealmCollectionObservable interfaces. Enable detailed change information for RealmResults through OrderedCollectionChange interface. Fix a bug in the ObserverPairList which could cause the removed listener gets called if it was removed during previous listener iteration. Fix"
,,0.1694,realm-java,"Merge pull request from realm/my/fix_memory_leaking My/fix memory leaking/Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/"
,,0.3737,realm-java,"Merge pull request from realm/merge-154419-to-master Fix merge from 154419 to master/Fix warnings from error prone plugin (#4339) This PR does not add the plugin, just fix the warnings. Ill add the plugin in another PR with suppressing some warnings./Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/Implement fine gained notification (#4191) Add RealmObservable and RealmCollectionObservable interfaces. Enable detailed change information for RealmResults through OrderedCollectionChange interface. Fix a bug in the ObserverPairList which could cause the removed listener gets called if it was removed during previous listener iteration. Fix typo and exception message/RealmResults is always live-to-updated This is the precondition of fine grained notifications. OS will trigger the collection notification immediately when transaction begins on the local thread to compute the change set if there is any. This conflicts with Javas original RealmResults behavior the original RealmResults would only be synced in the next event loop. Also, there are some edge cases dont work well with the original RealmResults behavior, see details in So: RealmResults becomes always up-to-date again which means it will never contains a invalid row. Behavior of iteration on a RealmResults still just works, it will just iterate on snapshot of collection. This means user can still delete elements from a RealmResults inside iteration. Deletion & Modification on RealmResults in simple-for-loop wont work as expected if the changes will impact the order/elements of the results. This could be solved by the future new Collection type RealmCollectionSnapshot. Add Collection.load() and Collection.isLoaded() to support java sync queries. Test fix. wont be an issue anymore since the RealmResults is always up to date and it wont contain any invalid rows. So remove the related tests. Failure tests caused by listener being triggred with beginTransaction() Remove realmResultsListenerAddedAfterCommit. when add listener to the OS Results after commit transaction, the OS CollectionNotifier will be created at the SharedGroup version of transaction committed. So the listener wont be called anymore since the all changes already exist in current SharedGroup./Fix merge from 97fdf6 to master (#4156) * Release v2.3.1 * Prepare next release v2.3.2-SNAPSHOT * Nh/refresh access token (#4147) * Add a timer to refresh the access_token before it expires/"
,,0.4399,realm-java,"Merge branch releases into my/fix_memory_leaking/Merge pull request from realm/merge-196ee5-to-master Fix merge from 196ee5 to master/fix API incompatibility introduced in 3.1.0 (#4455)/Hide StandardRealmSchema class from public API. (#4444) fixes * add package private methods to RealmSchema instead of BaseRealm.getSchemaInternal()./Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/Refactor Schemas into separate native and realm-based implementations (#4382) * Refactor Schemas into separate native and realm-based implementations * Fix all tests * Respond to PR comments * Temporary (git add .) kludge to fix visiblity problem/Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/Merge pull request from CDRussell/master Error message gives wrong class name character limit/Fix error message to show correct character limit and minor grammar fix/"
,,0.1695,realm-java,"Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/"
,,0.141,realm-java,Fix exception thrown from backlinks field (#4500) * add test case that reproduce * now backlinks geters throw IllegalStateException if the object is deleted or not yet loaded. * update CHANGELOG * add test * update a test * modify method name Row.checkIfBacklinkAvailable() to Row.checkIfAttached() * update variable names in test/Merge pull request from realm/merge-3b3364-to-master Fix merge from 3b3364 to master/Fixed element type checking in DynamicRealmOject#setList(). (#4254) * Fixed element type checking in DynamicRealmOject#setList() (#4252). * Update CHANGELOG.md * PR fixes * PR fixes/
,,0.4271,realm-java,"Merge pull request from realm/merge-154419-to-master Fix merge from 154419 to master/Fix warnings from error prone plugin (#4339) This PR does not add the plugin, just fix the warnings. Ill add the plugin in another PR with suppressing some warnings./Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/"
,,0.1312,realm-java,"Merge pull request from realm/merge-154419-to-master Fix merge from 154419 to master/Fix warnings from error prone plugin (#4339) This PR does not add the plugin, just fix the warnings. Ill add the plugin in another PR with suppressing some warnings./"
,,0.38,realm-java,"Fix exception thrown from backlinks field (#4500) * add test case that reproduce * now backlinks geters throw IllegalStateException if the object is deleted or not yet loaded. * update CHANGELOG * add test * update a test * modify method name Row.checkIfBacklinkAvailable() to Row.checkIfAttached() * update variable names in test/Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/"
,,0.1354,realm-java,Fix exception thrown from backlinks field (#4500) * add test case that reproduce * now backlinks geters throw IllegalStateException if the object is deleted or not yet loaded. * update CHANGELOG * add test * update a test * modify method name Row.checkIfBacklinkAvailable() to Row.checkIfAttached() * update variable names in test/
,,0.1734,realm-java,"Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/"
,,0.1234,realm-java,"Merge pull request from realm/merge-52ba43-to-master Fix merge from 52ba43 to master/Introduce ErrorProne plugin (#4342)/Merge pull request from realm/merge-154419-to-master Fix merge from 154419 to master/Fix warnings from error prone plugin (#4339) This PR does not add the plugin, just fix the warnings. Ill add the plugin in another PR with suppressing some warnings./"
,,0.4371,realm-java,"Merge branch releases into my/fix_memory_leaking/Merge pull request from realm/merge-196ee5-to-master Fix merge from 196ee5 to master/fix API incompatibility introduced in 3.1.0 (#4455)/Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/Refactor Schemas into separate native and realm-based implementations (#4382) * Refactor Schemas into separate native and realm-based implementations * Fix all tests * Respond to PR comments * Temporary (git add .) kludge to fix visiblity problem/Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/Merge pull request from CDRussell/master Error message gives wrong class name character limit/Fix error message to show correct character limit and minor grammar fix/"
,,0.5593,realm-java,"Implement getInstanceAsync (#4570) Fix Add APIs to get Realm instance asynchronously. Remove some useless methods. There some work need to be done before create the first Realm instance in the process, like creating schema table, doing migration, etc.. Those could block the UI thread quite badly. This commit tries to do those initialization work in the background and hold a Realm instance in the background until the 2nd instance created in the caller thread. A better solution than this would be do initialization in the background and only deliver a column indices cache to caller thread without holding a Realm instance in the background. But that is not possible since from the current database design, we cannot know if the schema changes compared with the last time it was opened. Also create a SharedGroup in the background and handover it to the caller thread is not ideal as well. That not only requires some design changes in the Object Store RealmCoordinator, but also is a very special use case of SharedGroup which core is not designed for. SharedGroup Leaking during the handover is another flaw for this solution we can only rely on the GC to collect the leaked SharedGroup during handover then./Fine grained locks for RealmCache (#4551) Separated lock for different RealmConfiguration instead of one lock on the RealmCache class. So Opening Realm instances from different configurations wont block each other. DynamicRealm which is created during opening type Realm will not be associated to any RealmCache to avoid recursive locks and multiple times initial block. (Also make the code easier.) This is for and part of implementation of ./Merge pull request from realm/merge-7ae1ee-to-master Fix merge from 7ae1ee to master/Merge pull request from realm/my/fix_memory_leaking My/fix memory leaking/address findbugs warnings/Fix OsRealmSchema leak (#4422)/Feature/backlinks (#4406) * Refactor RealmObjectSchema Clean up Proxy generation Comments addressed * Fix Test, Checkstyle and Findbugs errors * Respond to comments/Refactor Schemas into separate native and realm-based implementations (#4382) * Refactor Schemas into separate native and realm-based implementations * Fix all tests * Respond to PR comments * Temporary (git add .) kludge to fix visiblity problem/Backlinks (#4219) * Document multiple links to the same object * Fix non-object field reference bug * Load all tables before validating any * Update to gradle 3.4.1 * Fix Documentation * Fix Asynchronous UTs * Ignore, instead of throwing on, attempts to load Backlink fields w/JSON * Fix documentation and add notification unit tests * Require that backlink fields be final. * Address PR comments * Add tests for notification and distinct * Add interface methods and most of table validation * Check fields on JSON load * Fix fails in RealmTests * Respond to comments * Compile time type checking Refactor annotation handler * Improved error messages * Add Unit tests * Renamed Backlink to LinkingObjects. Added annotation processor tests. * Added annotation processor unit tests. * Add Backlink annotation/Proper RealmMigrationNeededException is now thrown. (#4304)/Implement fine gained notification (#4191) Add RealmObservable and RealmCollectionObservable interfaces. Enable detailed change information for RealmResults through OrderedCollectionChange interface. Fix a bug in the ObserverPairList which could cause the removed listener gets called if it was removed during previous listener iteration. Fix"
,,0.2663,realm-java,"Evaluate queries immediately for sync queries OsResults.load() actually does evaluate queries if needed now by using newly exposed OS method Results.evaluate_query_if_needed(). So the Resultss mode will be changed to TABLEVIEW from QUERY. This matches the old async query behaviour and solved the performance issues when the query results are huge, the size() method took unnecessary long time even the Results accessor will be called at the next line. close close Update Object Store to 3eb19c014fdf . Refactor the APIs for creating OsResults./"
,,0.2459,realm-java,"Evaluate queries immediately for sync queries OsResults.load() actually does evaluate queries if needed now by using newly exposed OS method Results.evaluate_query_if_needed(). So the Resultss mode will be changed to TABLEVIEW from QUERY. This matches the old async query behaviour and solved the performance issues when the query results are huge, the size() method took unnecessary long time even the Results accessor will be called at the next line. close close Update Object Store to 3eb19c014fdf . Refactor the APIs for creating OsResults./"
,,0.2514,realm-java,"Evaluate queries immediately for sync queries OsResults.load() actually does evaluate queries if needed now by using newly exposed OS method Results.evaluate_query_if_needed(). So the Resultss mode will be changed to TABLEVIEW from QUERY. This matches the old async query behaviour and solved the performance issues when the query results are huge, the size() method took unnecessary long time even the Results accessor will be called at the next line. close close Update Object Store to 3eb19c014fdf . Refactor the APIs for creating OsResults./"
,,0.2541,realm-java,"Evaluate queries immediately for sync queries OsResults.load() actually does evaluate queries if needed now by using newly exposed OS method Results.evaluate_query_if_needed(). So the Resultss mode will be changed to TABLEVIEW from QUERY. This matches the old async query behaviour and solved the performance issues when the query results are huge, the size() method took unnecessary long time even the Results accessor will be called at the next line. close close Update Object Store to 3eb19c014fdf . Refactor the APIs for creating OsResults./"
,,0.2182,realm-java,"Life cycle of temp OsSharedRealm in callbacks (#5576) Every temp OsSharedRealm created during construction for the callbacks have to be closed before the exception throws to users. close queries immediately for sync queries OsResults.load() actually does evaluate queries if needed now by using newly exposed OS method Results.evaluate_query_if_needed(). So the Resultss mode will be changed to TABLEVIEW from QUERY. This matches the old async query behaviour and solved the performance issues when the query results are huge, the size() method took unnecessary long time even the Results accessor will be called at the next line. close close Update Object Store to 3eb19c014fdf . Refactor the APIs for creating OsResults./"
,,0.55,rocksdb,"[Java] Optimize statistics collector, improve object dependency in RocksObjects Summary: This diff merges pull request 208. Contributor: ankgup87 [Java] Optimize statistics collector * Optimize statistics collector by collecting statistics of multiple DBs in a single thread rather than starting up a new thread for each DB. * Also, fix packaging of jnilib file on OS_X platform. * Diff review: [Java] Add documentation on interdependency of dispose call of RocksObjects * Remove transferCppRawPointersOwnershipFrom function. This function was setting opt.filter_ and thus filter_ to be null. This way there is no one holding reference for filter object and can thus be GCd which is not the intention. Replaced it with storeOptionsInstace which stores options instance. Options class internally holds Filter instance. Thus when Options is GCd, filter reference will be GCd automatically. * Added documentation explaining interdependency of Filter, Options and DB. * Diff review: Test Plan: described in their diff reviews Reviewers: haobo sdong swapnilghike zzbennett rsumbaly yhchiang Reviewed by: yhchiang/[Java] Optimize statistics collector, improve object dependency in RocksObjects Summary: This diff merges pull request Contributor: ankgup87 [Java] Optimize statistics collector * Optimize statistics collector by collecting statistics of multiple DBs in a single thread rather than starting up a new thread for each DB. * Also, fix packaging of jnilib file on OS_X platform. * Diff review: [Java] Add documentation on interdependency of dispose call of RocksObjects * Remove transferCppRawPointersOwnershipFrom function. This function was setting opt.filter_ and thus filter_ to be null. This way there is no one holding reference for filter object and can thus be GCd which is not the intention. Replaced it with storeOptionsInstace which stores options instance. Options class internally holds Filter instance. Thus when Options is GCd, filter reference will be GCd automatically. * Added documentation explaining interdependency of Filter, Options and DB. * Diff review: Test Plan: described in their diff reviews Reviewers: haobo sdong swapnilghike zzbennett rsumbaly yhchiang Reviewed by: yhchiang/"
,,0.5572,rocksdb,"[Java] Optimize statistics collector, improve object dependency in RocksObjects Summary: This diff merges pull request 208. Contributor: ankgup87 [Java] Optimize statistics collector * Optimize statistics collector by collecting statistics of multiple DBs in a single thread rather than starting up a new thread for each DB. * Also, fix packaging of jnilib file on OS_X platform. * Diff review: [Java] Add documentation on interdependency of dispose call of RocksObjects * Remove transferCppRawPointersOwnershipFrom function. This function was setting opt.filter_ and thus filter_ to be null. This way there is no one holding reference for filter object and can thus be GCd which is not the intention. Replaced it with storeOptionsInstace which stores options instance. Options class internally holds Filter instance. Thus when Options is GCd, filter reference will be GCd automatically. * Added documentation explaining interdependency of Filter, Options and DB. * Diff review: Test Plan: described in their diff reviews Reviewers: haobo sdong swapnilghike zzbennett rsumbaly yhchiang Reviewed by: yhchiang/[Java] Optimize statistics collector, improve object dependency in RocksObjects Summary: This diff merges pull request Contributor: ankgup87 [Java] Optimize statistics collector * Optimize statistics collector by collecting statistics of multiple DBs in a single thread rather than starting up a new thread for each DB. * Also, fix packaging of jnilib file on OS_X platform. * Diff review: [Java] Add documentation on interdependency of dispose call of RocksObjects * Remove transferCppRawPointersOwnershipFrom function. This function was setting opt.filter_ and thus filter_ to be null. This way there is no one holding reference for filter object and can thus be GCd which is not the intention. Replaced it with storeOptionsInstace which stores options instance. Options class internally holds Filter instance. Thus when Options is GCd, filter reference will be GCd automatically. * Added documentation explaining interdependency of Filter, Options and DB. * Diff review: Test Plan: described in their diff reviews Reviewers: haobo sdong swapnilghike zzbennett rsumbaly yhchiang Reviewed by: yhchiang/"
,,0.0588,rocksdb,Fix a memory leak of Slice objects from org.rocksdb.WBWIRocksIterator#entry1/
,,0.3752,rocksdb,"New Statistics to track Compression/Decompression (#1197) * Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer). * Prevent incrementing compression counter when compression is turned off in options. * Prevent incrementing compression counter when compression is turned off in options. * Added two more supported compression types to test code in db_test.cc * Prevent incrementing compression counter when compression is turned off in options. * Added new StatsLevel that excludes compression timing. * Fixed casting error in coding.h * Fixed CompressionStatsTest for new StatsLevel. * Removed unused variable that was breaking the Linux build/Added ""number of merge operands"" to statistics in ssts. Summary: A couple of notes from the diff: The namespace block I added at the top of table_properties_collector.cc was in reaction to an issue i was having with PutVarint64 and reusing the ""val"" string. Im not sure this is the cleanest way of doing this, but abstracting this out at least results in the correct behavior. I chose ""rocksdb.merge.operands"" as the property name. I am open to suggestions for better names. The change to sst_dump_tool.cc seems a bit inelegant to me. Is there a better way to do the if-else block? Test Plan: I added a test case in table_properties_collector_test.cc. It adds two merge operands and checks to make sure that both of them are reflected by GetMergeOperands. It also checks to make sure the wasPropertyPresent bool is properly set in the method. Running both of these tests should pass: ./table_properties_collector_test ./sst_dump_test Reviewers: IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba Differential Revision:"
,,0.1588,rocksdb,"Fix clang analyzer errors Summary: Fixing erros reported by clang static analyzer. * Removing some unused variables. * Adding assertions to fix false positives reported by clang analyzer. * Adding `__clang_analyzer__` macro to suppress false positive warnings. Test Plan: USE_CLANG=1 OPT=-g make analyze Reviewers: andrewkr, sdong Reviewed By: sdong Subscribers: andrewkr, dhruba, leveldb Differential Revision:"
,,0.6894,rocksdb,"Experiments on column-aware encodings Summary: Experiments on column-aware encodings. Supported features: 1) extract data blocks from SST file and encode with specified encodings; 2) Decode encoded data back into row format; 3) Directly extract data blocks and write in row format (without prefix encoding); 4) Get column distribution statistics for column format; 5) Dump data blocks separated by columns in human-readable format. There is still on-going work on this diff. More refactoring is necessary. Test Plan: Wrote tests in `column_aware_encoding_test.cc`. More tests should be added. Reviewers: sdong Reviewed By: sdong Subscribers: arahut, andrewkr, dhruba Differential Revision: Statistics to track Compression/Decompression (#1197) * Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer). * Prevent incrementing compression counter when compression is turned off in options. * Prevent incrementing compression counter when compression is turned off in options. * Added two more supported compression types to test code in db_test.cc * Prevent incrementing compression counter when compression is turned off in options. * Added new StatsLevel that excludes compression timing. * Fixed casting error in coding.h * Fixed CompressionStatsTest for new StatsLevel. * Removed unused variable that was breaking the Linux build/Miscellaneous performance improvements Summary: I was investigating performance issues in the SstFileWriter and found all of the following: The SstFileWriter::Add() function created a local InternalKey every time it was called generating a allocation and free each time. Changed to have an InternalKey member variable that can be reset with the new InternalKey::Set() function. In SstFileWriter::Add() the smallest_key and largest_key values were assigned the result of a ToString() call, but it is simpler to just assign them directly from the users key. The Slice class had no move constructor so each time one was returned from a function a new one had to be allocated, the old data copied to the new, and the old one was freed. I added the move constructor which also required a copy constructor and assignment operator. The BlockBuilder::CurrentSizeEstimate() function calculates the current estimate size, but was being called 2 or 3 times for each key added. I changed the class to maintain a running estimate (equal to the original calculation) so that the function can return an already calculated value. The code in BlockBuilder::Add() that calculated the shared bytes between the last key and the new key duplicated what Slice::difference_offset does, so I replaced it with the standard function. BlockBuilder::Add() had code to copy just the changed portion into the last key value (and asserted that it now matched the new key). It is more efficient just to copy the whole new key over. Moved this same code up into the if (use_delta_encoding_) since the last key value is only needed when delta encoding is on. FlushBlockBySizePolicy::BlockAlmostFull calculated a standard deviation value each time it was called, but this information would only change if block_size of block_size_deviation changed, so I created a member variable to hold the value to avoid the calculation each time. Each PutVarint??() function has a buffer and calls std::string::append(). Two or three calls in a row could share a buffer and a single call to std::string::append(). Some of these will be helpful outside of the SstFileWriter. Im not 100% the addition of the move constructor is appropriate as I wonder why this wasnt done before maybe because of compiler compatibility? I tried it on gcc 4.8 and 4.9. Test Plan: The changes should not affect the results so the existing tests should all still work and no new tests were added. The value of the changes was seen by manually testing the SstFileWriter class through MyRocks and adding timing code to identify problem areas. Reviewers: sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba Differential Revision: a check mode to verify compressed block can be decompressed back Summary: Try to decompress compressed blocks when a special flag is set. assert and crash in debug builds if we cant decompress the just-compressed input. Test Plan: Run unit-tests. Reviewers: dhruba, andrewkr, sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba Differential Revision:"
,,0.6316,rocksdb,"Miscellaneous performance improvements Summary: I was investigating performance issues in the SstFileWriter and found all of the following: The SstFileWriter::Add() function created a local InternalKey every time it was called generating a allocation and free each time. Changed to have an InternalKey member variable that can be reset with the new InternalKey::Set() function. In SstFileWriter::Add() the smallest_key and largest_key values were assigned the result of a ToString() call, but it is simpler to just assign them directly from the users key. The Slice class had no move constructor so each time one was returned from a function a new one had to be allocated, the old data copied to the new, and the old one was freed. I added the move constructor which also required a copy constructor and assignment operator. The BlockBuilder::CurrentSizeEstimate() function calculates the current estimate size, but was being called 2 or 3 times for each key added. I changed the class to maintain a running estimate (equal to the original calculation) so that the function can return an already calculated value. The code in BlockBuilder::Add() that calculated the shared bytes between the last key and the new key duplicated what Slice::difference_offset does, so I replaced it with the standard function. BlockBuilder::Add() had code to copy just the changed portion into the last key value (and asserted that it now matched the new key). It is more efficient just to copy the whole new key over. Moved this same code up into the if (use_delta_encoding_) since the last key value is only needed when delta encoding is on. FlushBlockBySizePolicy::BlockAlmostFull calculated a standard deviation value each time it was called, but this information would only change if block_size of block_size_deviation changed, so I created a member variable to hold the value to avoid the calculation each time. Each PutVarint??() function has a buffer and calls std::string::append(). Two or three calls in a row could share a buffer and a single call to std::string::append(). Some of these will be helpful outside of the SstFileWriter. Im not 100% the addition of the move constructor is appropriate as I wonder why this wasnt done before maybe because of compiler compatibility? I tried it on gcc 4.8 and 4.9. Test Plan: The changes should not affect the results so the existing tests should all still work and no new tests were added. The value of the changes was seen by manually testing the SstFileWriter class through MyRocks and adding timing code to identify problem areas. Reviewers: sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba Differential Revision: make more options dynamic Summary: make more ColumnFamilyOptions dynamic: compression soft_pending_compaction_bytes_limit hard_pending_compaction_bytes_limit min_partial_merge_operands report_bg_io_stats paranoid_file_checks Test Plan: Add sanity check in `db_test.cc` for all above options except for soft_pending_compaction_bytes_limit and hard_pending_compaction_bytes_limit. All passed. Reviewers: andrewkr, sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba, leveldb Differential Revision:"
,,0.3983,rocksdb,"New Statistics to track Compression/Decompression (#1197) * Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer). * Prevent incrementing compression counter when compression is turned off in options. * Prevent incrementing compression counter when compression is turned off in options. * Added two more supported compression types to test code in db_test.cc * Prevent incrementing compression counter when compression is turned off in options. * Added new StatsLevel that excludes compression timing. * Fixed casting error in coding.h * Fixed CompressionStatsTest for new StatsLevel. * Removed unused variable that was breaking the Linux build/"
,,0.2864,rocksdb,"Experiments on column-aware encodings Summary: Experiments on column-aware encodings. Supported features: 1) extract data blocks from SST file and encode with specified encodings; 2) Decode encoded data back into row format; 3) Directly extract data blocks and write in row format (without prefix encoding); 4) Get column distribution statistics for column format; 5) Dump data blocks separated by columns in human-readable format. There is still on-going work on this diff. More refactoring is necessary. Test Plan: Wrote tests in `column_aware_encoding_test.cc`. More tests should be added. Reviewers: sdong Reviewed By: sdong Subscribers: arahut, andrewkr, dhruba Differential Revision: FullMergeV2 (eliminate memcpy from merge operators) Summary: This diff update the code to pin the merge operator operands while the merge operation is done, so that we can eliminate the memcpy cost, to do that we need a new public API for FullMerge that replace the std::deque<std::string> with std::vector<Slice> This diff is stacked on top of D56493 and D56511 In this diff we Update FullMergeV2 arguments to be encapsulated in MergeOperationInput and MergeOperationOutput which will make it easier to add new arguments in the future Replace std::deque<std::string> with std::vector<Slice> to pass operands Replace MergeContext std::deque with std::vector (based on a simple benchmark I ran Allow FullMergeV2 output to be an existing operand ``` [Everything in Memtable | 10K operands | 10 KB each | 1 operand per key] DEBUG_LEVEL=0 make db_bench && ./db_bench [FullMergeV2] readseq : 0.607 micros/op 1648235 ops/sec; 16121.2 MB/s readseq : 0.478 micros/op 2091546 ops/sec; 20457.2 MB/s readseq : 0.252 micros/op 3972081 ops/sec; 38850.5 MB/s readseq : 0.237 micros/op 4218328 ops/sec; 41259.0 MB/s readseq : 0.247 micros/op 4043927 ops/sec; 39553.2 MB/s [master] readseq : 3.935 micros/op 254140 ops/sec; 2485.7 MB/s readseq : 3.722 micros/op 268657 ops/sec; 2627.7 MB/s readseq : 3.149 micros/op 317605 ops/sec; 3106.5 MB/s readseq : 3.125 micros/op 320024 ops/sec; 3130.1 MB/s readseq : 4.075 micros/op 245374 ops/sec; 2400.0 MB/s ``` ``` [Everything in Memtable | 10K operands | 10 KB each | 10 operand per key] DEBUG_LEVEL=0 make db_bench && ./db_bench [FullMergeV2] readseq : 3.472 micros/op 288018 ops/sec; 2817.1 MB/s readseq : 2.304 micros/op 434027 ops/sec; 4245.2 MB/s readseq : 1.163 micros/op 859845 ops/sec; 8410.0 MB/s readseq : 1.192 micros/op 838926 ops/sec; 8205.4 MB/s readseq : 1.250 micros/op 800000 ops/sec; 7824.7 MB/s [master] readseq : 24.025 micros/op 41623 ops/sec; 407.1 MB/s readseq : 18.489 micros/op 54086 ops/sec; 529.0 MB/s readseq : 18.693 micros/op 53495 ops/sec; 523.2 MB/s readseq : 23.621 micros/op 42335 ops/sec; 414.1 MB/s readseq : 18.775 micros/op 53262 ops/sec; 521.0 MB/s ``` ``` [Everything in Block cache | 10K operands | 10 KB each | 1 operand per key] [FullMergeV2] $ DEBUG_LEVEL=0 make db_bench && ./db_bench readseq : 14.741 micros/op 67837 ops/sec; 663.5 MB/s readseq : 1.029 micros/op 971446 ops/sec; 9501.6 MB/s readseq : 0.974 micros/op 1026229 ops/sec; 10037.4 MB/s readseq : 0.965 micros/op 1036080 ops/sec; 10133.8 MB/s readseq : 0.943 micros/op 1060657 ops/sec; 10374.2 MB/s [master] readseq : 16.735 micros/op 59755 ops/sec; 584.5 MB/s readseq : 3.029 micros/op 330151 ops/sec; 3229.2 MB/s readseq : 3.136 micros/op 318883 ops/sec; 3119.0 MB/s readseq : 3.065 micros/op 326245 ops/sec; 3191.0 MB/s readseq : 3.014 micros/op 331813 ops/sec; 3245.4 MB/s ``` ``` [Everything in Block cache | 10K operands | 10 KB each | 10 operand per key] DEBUG_LEVEL=0 make db_bench && ./db_bench [FullMergeV2] readseq : 24.325 micros/op 41109 ops/sec; 402.1 MB/s readseq : 1.470 micros/op 680272 ops/sec; 6653.7 MB/s readseq : 1.231 micros/op 812347 ops/sec; 7945.5 MB/s readseq : 1.091 micros/op 916590 ops/sec; 8965.1 MB/s readseq : 1.109 micros/op 901713 ops/sec; 8819.6 MB/s [master] readseq : 27.257 micros/op 36687 ops/sec; 358.8 MB/s readseq : 4.443 micros/op 225073 ops/sec; 2201.4 MB/s readseq : 5.830 micros/op 171526 ops/sec; 1677.7 MB/s readseq : 4.173 micros/op 239635 ops/sec; 2343.8 MB/s readseq : 4.150 micros/op 240963 ops/sec; 2356.8 MB/s ``` Test Plan: COMPILE_WITH_ASAN=1 make check Reviewers: yhchiang, andrewkr, sdong Reviewed By: sdong Subscribers: lovro, andrewkr, dhruba Differential Revision: Statistics to track Compression/Decompression (#1197) * Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer). * Prevent incrementing compression counter when compression is turned off in options. * Prevent incrementing compression counter when compression is turned off in options. * Added two more supported compression types to test code in db_test.cc * Prevent incrementing compression counter when compression is turned off in options. * Added new StatsLevel that excludes compression timing. * Fixed casting error in coding.h * Fixed CompressionStatsTest for new StatsLevel. * Removed unused variable that was breaking the Linux build/Fix clang analyzer errors Summary: Fixing erros reported by clang static analyzer. * Removing some unused variables. * Adding assertions to fix false positives reported by clang analyzer. * Adding `__clang_analyzer__` macro to suppress false positive warnings. Test Plan: USE_CLANG=1 OPT=-g make analyze Reviewers: andrewkr, sdong Reviewed By: sdong Subscribers: andrewkr, dhruba, leveldb Differential Revision: Should skip prefix bloom if full key bloom exists Summary: Currently, if users define both of full key bloom and prefix bloom in SST files. During Get(), if full key bloom shows the key may exist, we still go ahead and check prefix bloom. This is wasteful. If bloom filter for full keys exists, we should always ignore prefix bloom in Get(). Test Plan: Run existing tests Reviewers: yhchiang, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: leveldb, andrewkr, dhruba Differential Revision: statistics field to show total size of index and filter blocks in block cache Summary: With `table_options.cache_index_and_filter_blocks true`, index and filter blocks are stored in block cache. Then people are curious how much of the block cache total size is used by indexes and bloom filters. It will be nice we have a way to report that. It can help people tune performance and plan for optimized hardware setting. We add several enum values for db Statistics. BLOCK_CACHE_INDEX/FILTER_BYTES_INSERT BLOCK_CACHE_INDEX/FILTER_BYTES_ERASE current INDEX/FILTER total block size in bytes. Test Plan: write a test case called `DBBlockCacheTest.IndexAndFilterBlocksStats`. The result is: ``` ~/local/rocksdb] make db_block_cache_test && ./db_block_cache_test Makefile:101: Warning: Compiling in debug mode. Dont use the resulting binary in production GEN util/build_version.cc make: `db_block_cache_test is up to date. Note: Google Test filter DBBlockCacheTest.IndexAndFilterBlocksStats [==========] Running 1 test from 1 test case. [----------] Global test environment set-up. [----------] 1 test from DBBlockCacheTest [ RUN ] DBBlockCacheTest.IndexAndFilterBlocksStats [ OK ] DBBlockCacheTest.IndexAndFilterBlocksStats (689 ms) [----------] 1 test from DBBlockCacheTest (689 ms total) [----------] Global test environment tear-down [==========] 1 test from 1 test case ran. (689 ms total) [ PASSED ] 1 test. ``` Reviewers: IslamAbdelRahman, andrewkr, sdong Reviewed By: sdong Subscribers: andrewkr, dhruba, leveldb Differential Revision:"
,,0.4036,rocksdb,"New Statistics to track Compression/Decompression (#1197) * Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer). * Prevent incrementing compression counter when compression is turned off in options. * Prevent incrementing compression counter when compression is turned off in options. * Added two more supported compression types to test code in db_test.cc * Prevent incrementing compression counter when compression is turned off in options. * Added new StatsLevel that excludes compression timing. * Fixed casting error in coding.h * Fixed CompressionStatsTest for new StatsLevel. * Removed unused variable that was breaking the Linux build/"
,,0.4023,rocksdb,"New Statistics to track Compression/Decompression (#1197) * Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer). * Prevent incrementing compression counter when compression is turned off in options. * Prevent incrementing compression counter when compression is turned off in options. * Added two more supported compression types to test code in db_test.cc * Prevent incrementing compression counter when compression is turned off in options. * Added new StatsLevel that excludes compression timing. * Fixed casting error in coding.h * Fixed CompressionStatsTest for new StatsLevel. * Removed unused variable that was breaking the Linux build/"
,,0.7017,rocksdb,"New Statistics to track Compression/Decompression (#1197) * Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer). * Prevent incrementing compression counter when compression is turned off in options. * Prevent incrementing compression counter when compression is turned off in options. * Added two more supported compression types to test code in db_test.cc * Prevent incrementing compression counter when compression is turned off in options. * Added new StatsLevel that excludes compression timing. * Fixed casting error in coding.h * Fixed CompressionStatsTest for new StatsLevel. * Removed unused variable that was breaking the Linux build/Miscellaneous performance improvements Summary: I was investigating performance issues in the SstFileWriter and found all of the following: The SstFileWriter::Add() function created a local InternalKey every time it was called generating a allocation and free each time. Changed to have an InternalKey member variable that can be reset with the new InternalKey::Set() function. In SstFileWriter::Add() the smallest_key and largest_key values were assigned the result of a ToString() call, but it is simpler to just assign them directly from the users key. The Slice class had no move constructor so each time one was returned from a function a new one had to be allocated, the old data copied to the new, and the old one was freed. I added the move constructor which also required a copy constructor and assignment operator. The BlockBuilder::CurrentSizeEstimate() function calculates the current estimate size, but was being called 2 or 3 times for each key added. I changed the class to maintain a running estimate (equal to the original calculation) so that the function can return an already calculated value. The code in BlockBuilder::Add() that calculated the shared bytes between the last key and the new key duplicated what Slice::difference_offset does, so I replaced it with the standard function. BlockBuilder::Add() had code to copy just the changed portion into the last key value (and asserted that it now matched the new key). It is more efficient just to copy the whole new key over. Moved this same code up into the if (use_delta_encoding_) since the last key value is only needed when delta encoding is on. FlushBlockBySizePolicy::BlockAlmostFull calculated a standard deviation value each time it was called, but this information would only change if block_size of block_size_deviation changed, so I created a member variable to hold the value to avoid the calculation each time. Each PutVarint??() function has a buffer and calls std::string::append(). Two or three calls in a row could share a buffer and a single call to std::string::append(). Some of these will be helpful outside of the SstFileWriter. Im not 100% the addition of the move constructor is appropriate as I wonder why this wasnt done before maybe because of compiler compatibility? I tried it on gcc 4.8 and 4.9. Test Plan: The changes should not affect the results so the existing tests should all still work and no new tests were added. The value of the changes was seen by manually testing the SstFileWriter class through MyRocks and adding timing code to identify problem areas. Reviewers: sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba Differential Revision: a check mode to verify compressed block can be decompressed back Summary: Try to decompress compressed blocks when a special flag is set. assert and crash in debug builds if we cant decompress the just-compressed input. Test Plan: Run unit-tests. Reviewers: dhruba, andrewkr, sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba Differential Revision:"
,,0.4376,rocksdb,"New Statistics to track Compression/Decompression (#1197) * Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer). * Prevent incrementing compression counter when compression is turned off in options. * Prevent incrementing compression counter when compression is turned off in options. * Added two more supported compression types to test code in db_test.cc * Prevent incrementing compression counter when compression is turned off in options. * Added new StatsLevel that excludes compression timing. * Fixed casting error in coding.h * Fixed CompressionStatsTest for new StatsLevel. * Removed unused variable that was breaking the Linux build/Fix clang analyzer errors Summary: Fixing erros reported by clang static analyzer. * Removing some unused variables. * Adding assertions to fix false positives reported by clang analyzer. * Adding `__clang_analyzer__` macro to suppress false positive warnings. Test Plan: USE_CLANG=1 OPT=-g make analyze Reviewers: andrewkr, sdong Reviewed By: sdong Subscribers: andrewkr, dhruba, leveldb Differential Revision:"
,,0.3735,rocksdb,"New Statistics to track Compression/Decompression (#1197) * Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer). * Prevent incrementing compression counter when compression is turned off in options. * Prevent incrementing compression counter when compression is turned off in options. * Added two more supported compression types to test code in db_test.cc * Prevent incrementing compression counter when compression is turned off in options. * Added new StatsLevel that excludes compression timing. * Fixed casting error in coding.h * Fixed CompressionStatsTest for new StatsLevel. * Removed unused variable that was breaking the Linux build/Added ""number of merge operands"" to statistics in ssts. Summary: A couple of notes from the diff: The namespace block I added at the top of table_properties_collector.cc was in reaction to an issue i was having with PutVarint64 and reusing the ""val"" string. Im not sure this is the cleanest way of doing this, but abstracting this out at least results in the correct behavior. I chose ""rocksdb.merge.operands"" as the property name. I am open to suggestions for better names. The change to sst_dump_tool.cc seems a bit inelegant to me. Is there a better way to do the if-else block? Test Plan: I added a test case in table_properties_collector_test.cc. It adds two merge operands and checks to make sure that both of them are reflected by GetMergeOperands. It also checks to make sure the wasPropertyPresent bool is properly set in the method. Running both of these tests should pass: ./table_properties_collector_test ./sst_dump_test Reviewers: IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba Differential Revision:"
,,0.6749,rocksdb,"Miscellaneous performance improvements Summary: I was investigating performance issues in the SstFileWriter and found all of the following: The SstFileWriter::Add() function created a local InternalKey every time it was called generating a allocation and free each time. Changed to have an InternalKey member variable that can be reset with the new InternalKey::Set() function. In SstFileWriter::Add() the smallest_key and largest_key values were assigned the result of a ToString() call, but it is simpler to just assign them directly from the users key. The Slice class had no move constructor so each time one was returned from a function a new one had to be allocated, the old data copied to the new, and the old one was freed. I added the move constructor which also required a copy constructor and assignment operator. The BlockBuilder::CurrentSizeEstimate() function calculates the current estimate size, but was being called 2 or 3 times for each key added. I changed the class to maintain a running estimate (equal to the original calculation) so that the function can return an already calculated value. The code in BlockBuilder::Add() that calculated the shared bytes between the last key and the new key duplicated what Slice::difference_offset does, so I replaced it with the standard function. BlockBuilder::Add() had code to copy just the changed portion into the last key value (and asserted that it now matched the new key). It is more efficient just to copy the whole new key over. Moved this same code up into the if (use_delta_encoding_) since the last key value is only needed when delta encoding is on. FlushBlockBySizePolicy::BlockAlmostFull calculated a standard deviation value each time it was called, but this information would only change if block_size of block_size_deviation changed, so I created a member variable to hold the value to avoid the calculation each time. Each PutVarint??() function has a buffer and calls std::string::append(). Two or three calls in a row could share a buffer and a single call to std::string::append(). Some of these will be helpful outside of the SstFileWriter. Im not 100% the addition of the move constructor is appropriate as I wonder why this wasnt done before maybe because of compiler compatibility? I tried it on gcc 4.8 and 4.9. Test Plan: The changes should not affect the results so the existing tests should all still work and no new tests were added. The value of the changes was seen by manually testing the SstFileWriter class through MyRocks and adding timing code to identify problem areas. Reviewers: sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba Differential Revision:"
,,0.14800000000000002,rocksdb,"Added ""number of merge operands"" to statistics in ssts. Summary: A couple of notes from the diff: The namespace block I added at the top of table_properties_collector.cc was in reaction to an issue i was having with PutVarint64 and reusing the ""val"" string. Im not sure this is the cleanest way of doing this, but abstracting this out at least results in the correct behavior. I chose ""rocksdb.merge.operands"" as the property name. I am open to suggestions for better names. The change to sst_dump_tool.cc seems a bit inelegant to me. Is there a better way to do the if-else block? Test Plan: I added a test case in table_properties_collector_test.cc. It adds two merge operands and checks to make sure that both of them are reflected by GetMergeOperands. It also checks to make sure the wasPropertyPresent bool is properly set in the method. Running both of these tests should pass: ./table_properties_collector_test ./sst_dump_test Reviewers: IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba Differential Revision:"
,,0.6766,rocksdb,"Miscellaneous performance improvements Summary: I was investigating performance issues in the SstFileWriter and found all of the following: The SstFileWriter::Add() function created a local InternalKey every time it was called generating a allocation and free each time. Changed to have an InternalKey member variable that can be reset with the new InternalKey::Set() function. In SstFileWriter::Add() the smallest_key and largest_key values were assigned the result of a ToString() call, but it is simpler to just assign them directly from the users key. The Slice class had no move constructor so each time one was returned from a function a new one had to be allocated, the old data copied to the new, and the old one was freed. I added the move constructor which also required a copy constructor and assignment operator. The BlockBuilder::CurrentSizeEstimate() function calculates the current estimate size, but was being called 2 or 3 times for each key added. I changed the class to maintain a running estimate (equal to the original calculation) so that the function can return an already calculated value. The code in BlockBuilder::Add() that calculated the shared bytes between the last key and the new key duplicated what Slice::difference_offset does, so I replaced it with the standard function. BlockBuilder::Add() had code to copy just the changed portion into the last key value (and asserted that it now matched the new key). It is more efficient just to copy the whole new key over. Moved this same code up into the if (use_delta_encoding_) since the last key value is only needed when delta encoding is on. FlushBlockBySizePolicy::BlockAlmostFull calculated a standard deviation value each time it was called, but this information would only change if block_size of block_size_deviation changed, so I created a member variable to hold the value to avoid the calculation each time. Each PutVarint??() function has a buffer and calls std::string::append(). Two or three calls in a row could share a buffer and a single call to std::string::append(). Some of these will be helpful outside of the SstFileWriter. Im not 100% the addition of the move constructor is appropriate as I wonder why this wasnt done before maybe because of compiler compatibility? I tried it on gcc 4.8 and 4.9. Test Plan: The changes should not affect the results so the existing tests should all still work and no new tests were added. The value of the changes was seen by manually testing the SstFileWriter class through MyRocks and adding timing code to identify problem areas. Reviewers: sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba Differential Revision:"
,,0.1009,rocksdb,"Fix shared lock upgrades Summary: Upgrading a shared lock was silently succeeding because the actual locking code was skipped. This is because if the keys are tracked, it is assumed that they are already locked and do not require locking. Fix this by recording in tracked keys whether the key was locked exclusively or not. Note that lock downgrades are impossible, which is the behaviour we expect. This fixes facebook/mysql-5.6#587. Closes Differential Revision: D4861489 Pulled By: IslamAbdelRahman fbshipit-source-id: 58c7ebe7af098bf01b9774b666d3e9867747d8fd/"
,,0.2804,rocksdb,"unbiase readamp bitmap Summary: Consider BlockReadAmpBitmap with bytes_per_bit 32. Suppose bytes [a, b) were used, while bytes [a-32, a) and [b+1, b+33) werent used; more formally, the union of ranges passed to BlockReadAmpBitmap::Mark() contains [a, b) and doesnt intersect with [a-32, a) and [b+1, b+33). Then bits [floor(a/32), ceil(b/32)] will be set, and so the number of useful bytes will be estimated as (ceil(b/32) floor(a/32)) * 32, which is on average equal to b-a+31. An extreme example: if we use 1 byte from each block, itll be counted as 32 bytes from each block. Its easy to remove this bias by slightly changing the semantics of the bitmap. Currently each bit represents a byte range [i*32, (i+1)*32). This diff makes each bit represent a single byte: i*32 + X, where X is a random number in [0, 31] generated when bitmap is created. So, e.g., if you read a single byte at random, with probability 31/32 it wont be counted at all, and with probability 1/32 it will be counted as 32 bytes; so, on average its counted as 1 byte. *But there is one exception: the last bit will always set with the old way.* (*) assuming read_amp_bytes_per_bit 32. Closes Differential Revision: D5035652 Pulled By: lightmark fbshipit-source-id: bd98b1b9b49fbe61f9e3781d07f624e3cbd92356/Move memtable related files into memtable directory Summary: Move memtable related files into memtable directory. Closes Differential Revision: D4829242 Pulled By: yiwu-arbug fbshipit-source-id: ca70ab6/"
,,0.3026,rocksdb,"fix readampbitmap tests Summary: fix test failure of ReadAmpBitmap and ReadAmpBitmapLiveInCacheAfterDBClose. test ReadAmpBitmapLiveInCacheAfterDBClose individually and make check Closes Differential Revision: D5038133 Pulled By: lightmark fbshipit-source-id: 803cd6f45ccfdd14a9d9473c8af311033e164be8/unbiase readamp bitmap Summary: Consider BlockReadAmpBitmap with bytes_per_bit 32. Suppose bytes [a, b) were used, while bytes [a-32, a) and [b+1, b+33) werent used; more formally, the union of ranges passed to BlockReadAmpBitmap::Mark() contains [a, b) and doesnt intersect with [a-32, a) and [b+1, b+33). Then bits [floor(a/32), ceil(b/32)] will be set, and so the number of useful bytes will be estimated as (ceil(b/32) floor(a/32)) * 32, which is on average equal to b-a+31. An extreme example: if we use 1 byte from each block, itll be counted as 32 bytes from each block. Its easy to remove this bias by slightly changing the semantics of the bitmap. Currently each bit represents a byte range [i*32, (i+1)*32). This diff makes each bit represent a single byte: i*32 + X, where X is a random number in [0, 31] generated when bitmap is created. So, e.g., if you read a single byte at random, with probability 31/32 it wont be counted at all, and with probability 1/32 it will be counted as 32 bytes; so, on average its counted as 1 byte. *But there is one exception: the last bit will always set with the old way.* (*) assuming read_amp_bytes_per_bit 32. Closes Differential Revision: D5035652 Pulled By: lightmark fbshipit-source-id: bd98b1b9b49fbe61f9e3781d07f624e3cbd92356/"
,,0.1138,rocksdb,Suppress clang analyzer error (#4299) Summary: Suppress multiple clang-analyzer error. All of them are clang false-positive. Pull Request resolved: Differential Revision: D9430740 Pulled By: yiwu-arbug fbshipit-source-id: fbdd575bdc214d124826d61d35a117995c509279/
