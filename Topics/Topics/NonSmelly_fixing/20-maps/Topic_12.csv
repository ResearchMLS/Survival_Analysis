Topic_no,Keywords,Contrib,System,Text
12,"key, call, change, support, version, case, provide, move, copy, result, byte, fail, platform, work, buffer, crash, operation, part, deletion, implementation",0.1521,conscrypt,"Remove obviously bogus annotations. Weve already agreed Must Die (to be replaced by expectations for DalvikRunner), but some are I think obviously in need of investigation. This patch removes for all cases where the reason looks bogus. Ive left the annotations in cases where I it looks ""reasonable"" in that we simply havent implemented the functionality (pack200, say), and a few other cases. Those should probably be done in a separate patch that adds expectations at the same time. But these ones, I think, all need investigating. (Theres a scary number of Arabic-related bugs in here, given that were supposed to be shipping Arabic in froyo.)/"
,,0.0685,conscrypt,Fixing a dead store in Finished. See bug 2099918. Change-Id: I12f0a53bc5aeacea3ba97820dcd6525e1bf23405/
,,0.1521,conscrypt,"Fix more FindBugs warnings: RR_NOT_CHECKED. ""This method ignores the return value of one of the variants of java.io.InputStream.read() which can return multiple bytes. If the return value is not checked, the caller will not be able to correctly handle the case where fewer bytes were read than the caller requested. This is a particularly insidious kind of bug, because in many programs, reads from input streams usually do read the full amount of data requested, causing the program to fail only sporadically."" Change-Id: I7d7c62836f2037f0cbb4bb0708bd4f034a22a2fc/"
,,0.159,conscrypt,"Fix more FindBugs warnings: RR_NOT_CHECKED. ""This method ignores the return value of one of the variants of java.io.InputStream.read() which can return multiple bytes. If the return value is not checked, the caller will not be able to correctly handle the case where fewer bytes were read than the caller requested. This is a particularly insidious kind of bug, because in many programs, reads from input streams usually do read the full amount of data requested, causing the program to fail only sporadically."" Change-Id: I7d7c62836f2037f0cbb4bb0708bd4f034a22a2fc/"
,,0.1632,conscrypt,"Fix more FindBugs warnings: RR_NOT_CHECKED. ""This method ignores the return value of one of the variants of java.io.InputStream.read() which can return multiple bytes. If the return value is not checked, the caller will not be able to correctly handle the case where fewer bytes were read than the caller requested. This is a particularly insidious kind of bug, because in many programs, reads from input streams usually do read the full amount of data requested, causing the program to fail only sporadically."" Change-Id: I7d7c62836f2037f0cbb4bb0708bd4f034a22a2fc/"
,,0.09699999999999999,conscrypt,"Fix short writes in Socket OutputStreams. Also tidy some code and fix some comments. The OpenSSL OutputStream is already correct: it handles this in the native code. Bug: Change-Id: I69645543ec01f1eecdae4418f86c3a1911c0f752/Remove useless overrides of InputStream.read(byte[]) and OutputStream.write(byte[]). For the particular stream in the bug, the useless override assumes that the implementation of read(byte[], int, int) or write(byte[], int, int) doesnt do anything special. A dangerous and non-local assumption. (In the bug, we need to change the three-argument write.) Bug: Change-Id: I915d4a2e20c98f8e7f5775b555ae77d496a535d0/Fix various FindBugs warnings. Only the ChunkHandler and ZoneInfo ones were real bugs. The former is only called with one input value that doesnt exercise the bug, and the latter would cause us to think that a time zone that stopped using daylight time before 1970 was still using daylight time (which would defeat various optimizations, but should otherwise be harmless). The other stuff is trivia not worth individual changes. Change-Id: Ib0752560cd16edc6538d1fc2b234451a66d48171/"
,,0.1688,conscrypt,"Fix more FindBugs warnings: RR_NOT_CHECKED. ""This method ignores the return value of one of the variants of java.io.InputStream.read() which can return multiple bytes. If the return value is not checked, the caller will not be able to correctly handle the case where fewer bytes were read than the caller requested. This is a particularly insidious kind of bug, because in many programs, reads from input streams usually do read the full amount of data requested, causing the program to fail only sporadically."" Change-Id: I7d7c62836f2037f0cbb4bb0708bd4f034a22a2fc/"
,,0.0955,conscrypt,"Fix short writes in Socket OutputStreams. Also tidy some code and fix some comments. The OpenSSL OutputStream is already correct: it handles this in the native code. Bug: Change-Id: I69645543ec01f1eecdae4418f86c3a1911c0f752/Remove useless overrides of InputStream.read(byte[]) and OutputStream.write(byte[]). For the particular stream in the bug, the useless override assumes that the implementation of read(byte[], int, int) or write(byte[], int, int) doesnt do anything special. A dangerous and non-local assumption. (In the bug, we need to change the three-argument write.) Bug: Change-Id: I915d4a2e20c98f8e7f5775b555ae77d496a535d0/"
,,0.0989,conscrypt,Update both SSLSessions to not use AccessControlContext. When we fully removed the security manager security theatre we broke equals on some AccessControlContexts that were used in map keys. Now we dont include the AccessControlContexts in the map keys. This fixes this test: tests.api.javax.net.ssl.SSLSessionBindingListenerTest#test_valueUnbound Change-Id: I685416c65056c9c540bf75c4aab5e884b66a4394/
,,0.0956,conscrypt,Update both SSLSessions to not use AccessControlContext. When we fully removed the security manager security theatre we broke equals on some AccessControlContexts that were used in map keys. Now we dont include the AccessControlContexts in the map keys. This fixes this test: tests.api.javax.net.ssl.SSLSessionBindingListenerTest#test_valueUnbound Change-Id: I685416c65056c9c540bf75c4aab5e884b66a4394/
,,0.066,conscrypt,Tracking openssl-1.0.1 Bug: 6168278 Change-Id: I240d2cbc91f616fd486efc5203e2221c9896d90f/
,,0.0639,conscrypt,Tracking openssl-1.0.1 Bug: 6168278 Change-Id: I240d2cbc91f616fd486efc5203e2221c9896d90f/
,,0.1774,conscrypt,"Add OIDs for algorithms This allows things from a PKCS#7 container (or any other container that specifies algorithms by OID) to get an instance via OID instead of the common name. Bug: Change-Id: Ie766751a3f7894a558f7e40e7d520800bf7a8a08/Add new Android-only algos to StandardNames The ProviderTest fails if we dont add these to StandardNames. Change the name of Signature.RAWRSA to ""NONEwithRSA"" so it matches the convention in existing algorithms. Change-Id: Id126eca46ee3b9f9d19aee596c1babd489693c7a/Add raw RSA signature support With the new Keystore changes, this is the only way you can get raw RSA signatures which a lot of native code expects to be able to do. (cherry-picked from c531f5f402b4cedcc35a0b7f0b540dc84c545106) Bug: 6787078 Change-Id: I1c5ddd5287be1ab71347eedc864a41c24e156cb4/Add raw RSA signature support With the new Keystore changes, this is the only way you can get raw RSA signatures which a lot of native code expects to be able to do. Bug: 6787078 Change-Id: I1c5ddd5287be1ab71347eedc864a41c24e156cb4/"
,,0.0804,conscrypt,"TrustedCertificateStoreTest: add message to assert Add the target filename to the assert so that a testing issue can be debugged. Currently a file is failing to delete during a CTS run, but cant be reproduced during a targeted test run of just the TrustedCertificateStoreTest. Change-Id: I217d6b92868880ab4456500b290b5c6ac9c45c2c/"
,,0.2355,conscrypt,"am 082089a7: am ba5b30af: Merge ""Stop depending on SSLContextImpl in OpenSSLContextImpl."" * commit 082089a7cc57a1a531a877af94c81829e046be60: Stop depending on SSLContextImpl in OpenSSLContextImpl./am ba5b30af: Merge ""Stop depending on SSLContextImpl in OpenSSLContextImpl."" * commit ba5b30afd83e2e23b5735bbc9179779a9ef9eac3: Stop depending on SSLContextImpl in OpenSSLContextImpl./Merge ""Stop depending on SSLContextImpl in OpenSSLContextImpl.""/Stop depending on SSLContextImpl in OpenSSLContextImpl. SSLContextImpl is the HarmonyJSSE providers SSLContext SPI. OpenSSLContextImpl is the AndroidOpenSSL providers SSLContext SPI. This CL adjusts the class hierarchy to match. This is achieved by: 1. copying all of the functionality from SSLContextImpl into OpenSSLContextImpl, and 2. removing from SSLContextImpl the functionality used only by the default instance of AndroidOpenSSL providers SSLContext. Change-Id: I9e380be04e6a9a1660c3e6c0738ca026c171f4bd/"
,,0.0923,conscrypt,"OpenSSLKey: tolerate null encoding during conversion Since we could have a situation where we have an opaque key backed by some hardware device that we dont know how to handle, just throw an InvalidKeyException instead of NullPointerException. Change-Id: I33588d1654b6b33f11640b2d65e7213c864e6e1a/"
,,0.1637,conscrypt,"am d01c5c89: am cea9ec15: X509Certificate: SignatureException for verify * commit d01c5c89c8e75e712bd4b4fd72254488c9aa9f5b: X509Certificate: SignatureException for verify/am cea9ec15: X509Certificate: SignatureException for verify * commit cea9ec153ef5bf27e3eee74d7c503bce02084bc2: X509Certificate: SignatureException for verify/X509Certificate: SignatureException for verify Any verification error can throw random things like BadPaddingException. Swallow it and catch Exception for all these cases and rethrow as a SignatureException to avoid acting as any kind of oracle. Change-Id: I6b515148f86529fbe0895c9fdb0954306724ae54/OpenSSLX509Certificate: negative serial numbers The constructor BigInteger(byte[]) expects twos complement encoding, but thats not what OpenSSL bn2bin returns. Bug: 12761797 Change-Id: I6c71f6fb88c2b1df7c372bf697728dac26571634/Make some methods public for CTS Some methods are called from CTS. The ClassLoaders are different, so we need to make these public so we dont get any IllegalAccessError during CTS tests. Change-Id: I5ac7931694fb1eceb86ae306fca07fb314643fa9/"
,,0.2402,conscrypt,"am 082089a7: am ba5b30af: Merge ""Stop depending on SSLContextImpl in OpenSSLContextImpl."" * commit 082089a7cc57a1a531a877af94c81829e046be60: Stop depending on SSLContextImpl in OpenSSLContextImpl./am ba5b30af: Merge ""Stop depending on SSLContextImpl in OpenSSLContextImpl."" * commit ba5b30afd83e2e23b5735bbc9179779a9ef9eac3: Stop depending on SSLContextImpl in OpenSSLContextImpl./Merge ""Stop depending on SSLContextImpl in OpenSSLContextImpl.""/Stop depending on SSLContextImpl in OpenSSLContextImpl. SSLContextImpl is the HarmonyJSSE providers SSLContext SPI. OpenSSLContextImpl is the AndroidOpenSSL providers SSLContext SPI. This CL adjusts the class hierarchy to match. This is achieved by: 1. copying all of the functionality from SSLContextImpl into OpenSSLContextImpl, and 2. removing from SSLContextImpl the functionality used only by the default instance of AndroidOpenSSL providers SSLContext. Change-Id: I9e380be04e6a9a1660c3e6c0738ca026c171f4bd/"
,,0.1148,conscrypt,"OpenSSLECPrivateKey: no encoding for ENGINE-backed keys ENGINE-backed keys cant be encoded, so check their status before trying to return anything in getEncoded or getFormat. (cherry picked from commit ba1ea0caa5d6059e73b67068819e5948cfa1bc95) Bug: 12877721 Change-Id: I47a2ee14e9e0198ebdf47bdf5199f6f44bf7153b/OpenSSLECPrivateKey: no encoding for ENGINE-backed keys ENGINE-backed keys cant be encoded, so check their status before trying to return anything in getEncoded or getFormat. Bug: 12877721 Change-Id: I44d07b5edb530664fea07d9c61dc58745eb0a996/"
,,0.0815,conscrypt,"TrustedCertificateStoreTest: use random dir for tests In order to avoid some problems with the tests, use a random name instead of trying to use a potentially-conflicting directory name. Bug: 12469164 Bug: 14818987 Change-Id: I9a144eafff46d84ea794f49babeba11938f665f8/"
,,0.1858,conscrypt,"Add ability to wrap platform keys This is mostly useful for unbundled Conscrypt currently when working with KeyChain-based keys, but could be good for use with PKCS11-like keys in other JSSE providers. Bug: 15469749 Change-Id: I56bf2eaf3228bdf42d671437f4fffdafb8b47b12/am 65fe8afa: am 7591dffb: am 68b3d5f4: DH keys: fix some errors the tests caught * commit 65fe8afa8262cc003d6e110c633c6f5d5a6d4488: DH keys: fix some errors the tests caught/am 7591dffb: am 68b3d5f4: DH keys: fix some errors the tests caught * commit 7591dffb4ba70f238ce27dfb39c5485cd64f9ceb: DH keys: fix some errors the tests caught/am 68b3d5f4: DH keys: fix some errors the tests caught * commit 68b3d5f4f361ff957b4665d1cf8ffc2ac91bac9c: DH keys: fix some errors the tests caught/DH keys: fix some errors the tests caught * Returning ""DSA"" instead of ""DH"" for key algorithm * Not having the key type defined as translatable in OpenSSLKey Change-Id: I19db78ddb6d8697e758692bc4830fb32c8a0176a/"
,,0.1246,conscrypt,"Add ability to wrap platform keys This is mostly useful for unbundled Conscrypt currently when working with KeyChain-based keys, but could be good for use with PKCS11-like keys in other JSSE providers. Bug: 15469749 Change-Id: I56bf2eaf3228bdf42d671437f4fffdafb8b47b12/"
,,0.0609,conscrypt,OpenSSLMessageDigestJDK: support clone Add the ability to clone the MessageDigest state. Bug: 14821275 Change-Id: Ifa1b48db708448b971afe1e7360876f3fbe47588/
,,0.1263,conscrypt,"Add ability to wrap platform keys This is mostly useful for unbundled Conscrypt currently when working with KeyChain-based keys, but could be good for use with PKCS11-like keys in other JSSE providers. Bug: 15469749 Change-Id: I56bf2eaf3228bdf42d671437f4fffdafb8b47b12/"
,,0.1156,conscrypt,"Add ability to wrap platform keys This is mostly useful for unbundled Conscrypt currently when working with KeyChain-based keys, but could be good for use with PKCS11-like keys in other JSSE providers. Bug: 15469749 Change-Id: I56bf2eaf3228bdf42d671437f4fffdafb8b47b12/"
,,0.1246,conscrypt,"Add ability to wrap platform keys This is mostly useful for unbundled Conscrypt currently when working with KeyChain-based keys, but could be good for use with PKCS11-like keys in other JSSE providers. Bug: 15469749 Change-Id: I56bf2eaf3228bdf42d671437f4fffdafb8b47b12/"
,,0.1286,conscrypt,"Reject TLS/SSL certificates which use MD2 or MD4. TLS/SSL certificates which use MD5 are already being rejected (see This CL adds similar rejection logic for MD2 and MD4 which are weaker than MD5. Bug: 17177978 Change-Id: I3ae872dfc43b39ef000e027f9d4b6e5893ca32db/Reject TLS/SSL certificates with very short (EC)DSA keys. TLS/SSL certificates that use RSA keys with modulus shorter than 1024 bits are already being rejected (see This CL adds similar minimum length checks for (EC)DSA keys. The cutoff is at the 80-bit symmetric strength equivalent from NIST 800-57: * RSA: modulus length: 1024 bits. * ECDSA: field size: 160 bits. * DSA: p: 1024 bits, q: 160 bits. Bug: 17177978 Change-Id: Ifbb4a759494665e614bd89cd4bf7fc4d69d27532/"
,,0.1431,conscrypt,"Reject TLS/SSL certificates which use MD2 or MD4. TLS/SSL certificates which use MD5 are already being rejected (see This CL adds similar rejection logic for MD2 and MD4 which are weaker than MD5. Bug: 17177978 Change-Id: I3ae872dfc43b39ef000e027f9d4b6e5893ca32db/Reject TLS/SSL certificates with very short (EC)DSA keys. TLS/SSL certificates that use RSA keys with modulus shorter than 1024 bits are already being rejected (see This CL adds similar minimum length checks for (EC)DSA keys. The cutoff is at the 80-bit symmetric strength equivalent from NIST 800-57: * RSA: modulus length: 1024 bits. * ECDSA: field size: 160 bits. * DSA: p: 1024 bits, q: 160 bits. Bug: 17177978 Change-Id: Ifbb4a759494665e614bd89cd4bf7fc4d69d27532/"
,,0.5684,conscrypt,"external/conscrypt: add NativeConstants. NativeConstants.java is generated by a C program and thus the values will automatically be kept in sync with the contents of the OpenSSL headers. Bug: 20521989 Change-Id: Ib5a97bf6ace05988e3eef4a9c8e02d0f707d46ad/external/conscrypt: remove DH key support. This change should be moot because ce175480 already removed support for DH keys. Bug: 20521989 Change-Id: Ief27adf451accd86d59001cc6752461bc763b3bb/Enable any opaque private keys to be used with TLS/SSL stack. Prior to this CL, opaque private keys those that do not expose/export their key material were not supported by Conscrypts SSLSocket, SSLServerSocket and SSLEngine implementations if the keys were backed by other providers. This CL fixes this issue. Conscrypts TLS/SSL stack now works with arbitrary opaque private keys provided that: * for EC private key: an installed implementation of NONEwithECDSA Signature accepts the key for signing; and * for RSA private key: an installed implementation of NONEwithRSA Signature accepts the key for signing and an installed implementation of RSA/ECB/PKCS1Padding Cipher accepts the key for decryption. This normally requires that the JCA Provider which produced the PrivateKey instance expose the above Cipher transformation and Signature algorithms. HOW THIS WORKS The underlying OpenSSL TLS/SSL stack uses the provided private keys only to decrypt and sign. For opaque private keys these requests are delegated (same as before, via CryptoUpcalls) to corresponding Cipher (RSA/ECB/PKCS1Padding) and Signature (NONEwithRSA or NONEwithECDSA) implementations. Even when signing and decryption is outsourced, OpenSSL still needs the modulus (for RSA) and order (for EC), supposedly to estimate output size of signing or decryption operations. This information is not available via the PrivateKey interface. However, an opaque private key may still implement the RSAKey or ECKey interface which provides access to modulus or order but does not provide access to key material. Moreover, in all use cases of private keys with Conscrypts TLS/SSL stack the modulus or order can be obtained and provided to OpenSSL. In the case of private keys used for client or server authentication, the public key of the certificate is used as the source of the information. In the case of TLS Channel ID, the order is currently fixed and known (only NIST P-256 is supported). Bug: 19284418 Change-Id: I8fea2492f9cf48cfc29c3e7d2ee99a68e84e82ec/"
,,0.5602,conscrypt,"external/conscrypt: add NativeConstants. NativeConstants.java is generated by a C program and thus the values will automatically be kept in sync with the contents of the OpenSSL headers. Bug: 20521989 Change-Id: Ib5a97bf6ace05988e3eef4a9c8e02d0f707d46ad/Enable any opaque private keys to be used with TLS/SSL stack. Prior to this CL, opaque private keys those that do not expose/export their key material were not supported by Conscrypts SSLSocket, SSLServerSocket and SSLEngine implementations if the keys were backed by other providers. This CL fixes this issue. Conscrypts TLS/SSL stack now works with arbitrary opaque private keys provided that: * for EC private key: an installed implementation of NONEwithECDSA Signature accepts the key for signing; and * for RSA private key: an installed implementation of NONEwithRSA Signature accepts the key for signing and an installed implementation of RSA/ECB/PKCS1Padding Cipher accepts the key for decryption. This normally requires that the JCA Provider which produced the PrivateKey instance expose the above Cipher transformation and Signature algorithms. HOW THIS WORKS The underlying OpenSSL TLS/SSL stack uses the provided private keys only to decrypt and sign. For opaque private keys these requests are delegated (same as before, via CryptoUpcalls) to corresponding Cipher (RSA/ECB/PKCS1Padding) and Signature (NONEwithRSA or NONEwithECDSA) implementations. Even when signing and decryption is outsourced, OpenSSL still needs the modulus (for RSA) and order (for EC), supposedly to estimate output size of signing or decryption operations. This information is not available via the PrivateKey interface. However, an opaque private key may still implement the RSAKey or ECKey interface which provides access to modulus or order but does not provide access to key material. Moreover, in all use cases of private keys with Conscrypts TLS/SSL stack the modulus or order can be obtained and provided to OpenSSL. In the case of private keys used for client or server authentication, the public key of the certificate is used as the source of the information. In the case of TLS Channel ID, the order is currently fixed and known (only NIST P-256 is supported). Bug: 19284418 Change-Id: I8fea2492f9cf48cfc29c3e7d2ee99a68e84e82ec/SSLParametersImpl: make some methods public To help with testing, make some of the methods public so we can call them from tests in a different ClassLoader. Bug: 19657440 Change-Id: Ib5cb0629ffb52ac57ff24d9d5c4df1509897bd05/"
,,0.5792,conscrypt,"Enable any opaque private keys to be used with TLS/SSL stack. Prior to this CL, opaque private keys those that do not expose/export their key material were not supported by Conscrypts SSLSocket, SSLServerSocket and SSLEngine implementations if the keys were backed by other providers. This CL fixes this issue. Conscrypts TLS/SSL stack now works with arbitrary opaque private keys provided that: * for EC private key: an installed implementation of NONEwithECDSA Signature accepts the key for signing; and * for RSA private key: an installed implementation of NONEwithRSA Signature accepts the key for signing and an installed implementation of RSA/ECB/PKCS1Padding Cipher accepts the key for decryption. This normally requires that the JCA Provider which produced the PrivateKey instance expose the above Cipher transformation and Signature algorithms. HOW THIS WORKS The underlying OpenSSL TLS/SSL stack uses the provided private keys only to decrypt and sign. For opaque private keys these requests are delegated (same as before, via CryptoUpcalls) to corresponding Cipher (RSA/ECB/PKCS1Padding) and Signature (NONEwithRSA or NONEwithECDSA) implementations. Even when signing and decryption is outsourced, OpenSSL still needs the modulus (for RSA) and order (for EC), supposedly to estimate output size of signing or decryption operations. This information is not available via the PrivateKey interface. However, an opaque private key may still implement the RSAKey or ECKey interface which provides access to modulus or order but does not provide access to key material. Moreover, in all use cases of private keys with Conscrypts TLS/SSL stack the modulus or order can be obtained and provided to OpenSSL. In the case of private keys used for client or server authentication, the public key of the certificate is used as the source of the information. In the case of TLS Channel ID, the order is currently fixed and known (only NIST P-256 is supported). Bug: 19284418 Change-Id: I8fea2492f9cf48cfc29c3e7d2ee99a68e84e82ec/"
,,0.0724,conscrypt,external/conscrypt: add NativeConstants. NativeConstants.java is generated by a C program and thus the values will automatically be kept in sync with the contents of the OpenSSL headers. Bug: 20521989 Change-Id: Ib5a97bf6ace05988e3eef4a9c8e02d0f707d46ad/
,,0.0784,conscrypt,external/conscrypt: add NativeConstants. NativeConstants.java is generated by a C program and thus the values will automatically be kept in sync with the contents of the OpenSSL headers. Bug: 20521989 Change-Id: Ib5a97bf6ace05988e3eef4a9c8e02d0f707d46ad/
,,0.0764,conscrypt,external/conscrypt: add NativeConstants. NativeConstants.java is generated by a C program and thus the values will automatically be kept in sync with the contents of the OpenSSL headers. Bug: 20521989 Change-Id: Ib5a97bf6ace05988e3eef4a9c8e02d0f707d46ad/
,,0.0804,conscrypt,external/conscrypt: add NativeConstants. NativeConstants.java is generated by a C program and thus the values will automatically be kept in sync with the contents of the OpenSSL headers. Bug: 20521989 Change-Id: Ib5a97bf6ace05988e3eef4a9c8e02d0f707d46ad/
,,0.0685,conscrypt,external/conscrypt: add NativeConstants. NativeConstants.java is generated by a C program and thus the values will automatically be kept in sync with the contents of the OpenSSL headers. Bug: 20521989 Change-Id: Ib5a97bf6ace05988e3eef4a9c8e02d0f707d46ad/
,,0.5799,conscrypt,"am 656dba0b: Fix a NullPointerException in CryptoUpcalls. * commit 656dba0b8dcb6a8ab08e58e7abce5ed94d1f666a: Fix a NullPointerException in CryptoUpcalls./Enable any opaque private keys to be used with TLS/SSL stack. Prior to this CL, opaque private keys those that do not expose/export their key material were not supported by Conscrypts SSLSocket, SSLServerSocket and SSLEngine implementations if the keys were backed by other providers. This CL fixes this issue. Conscrypts TLS/SSL stack now works with arbitrary opaque private keys provided that: * for EC private key: an installed implementation of NONEwithECDSA Signature accepts the key for signing; and * for RSA private key: an installed implementation of NONEwithRSA Signature accepts the key for signing and an installed implementation of RSA/ECB/PKCS1Padding Cipher accepts the key for decryption. This normally requires that the JCA Provider which produced the PrivateKey instance expose the above Cipher transformation and Signature algorithms. HOW THIS WORKS The underlying OpenSSL TLS/SSL stack uses the provided private keys only to decrypt and sign. For opaque private keys these requests are delegated (same as before, via CryptoUpcalls) to corresponding Cipher (RSA/ECB/PKCS1Padding) and Signature (NONEwithRSA or NONEwithECDSA) implementations. Even when signing and decryption is outsourced, OpenSSL still needs the modulus (for RSA) and order (for EC), supposedly to estimate output size of signing or decryption operations. This information is not available via the PrivateKey interface. However, an opaque private key may still implement the RSAKey or ECKey interface which provides access to modulus or order but does not provide access to key material. Moreover, in all use cases of private keys with Conscrypts TLS/SSL stack the modulus or order can be obtained and provided to OpenSSL. In the case of private keys used for client or server authentication, the public key of the certificate is used as the source of the information. In the case of TLS Channel ID, the order is currently fixed and known (only NIST P-256 is supported). Bug: 19284418 Change-Id: I8fea2492f9cf48cfc29c3e7d2ee99a68e84e82ec/Fix a NullPointerException in CryptoUpcalls. When RSA/ECB/PKCS1Padding is not supported, CryptoUpcalls.rawCipherWithPrivateKey throws a NullPointerException instead of returning null. This CL fixes the issue. Change-Id: I46a389f22e40084950b80b9825644f2e1ffcff90/"
,,0.5682,conscrypt,"Enable any opaque private keys to be used with TLS/SSL stack. Prior to this CL, opaque private keys those that do not expose/export their key material were not supported by Conscrypts SSLSocket, SSLServerSocket and SSLEngine implementations if the keys were backed by other providers. This CL fixes this issue. Conscrypts TLS/SSL stack now works with arbitrary opaque private keys provided that: * for EC private key: an installed implementation of NONEwithECDSA Signature accepts the key for signing; and * for RSA private key: an installed implementation of NONEwithRSA Signature accepts the key for signing and an installed implementation of RSA/ECB/PKCS1Padding Cipher accepts the key for decryption. This normally requires that the JCA Provider which produced the PrivateKey instance expose the above Cipher transformation and Signature algorithms. HOW THIS WORKS The underlying OpenSSL TLS/SSL stack uses the provided private keys only to decrypt and sign. For opaque private keys these requests are delegated (same as before, via CryptoUpcalls) to corresponding Cipher (RSA/ECB/PKCS1Padding) and Signature (NONEwithRSA or NONEwithECDSA) implementations. Even when signing and decryption is outsourced, OpenSSL still needs the modulus (for RSA) and order (for EC), supposedly to estimate output size of signing or decryption operations. This information is not available via the PrivateKey interface. However, an opaque private key may still implement the RSAKey or ECKey interface which provides access to modulus or order but does not provide access to key material. Moreover, in all use cases of private keys with Conscrypts TLS/SSL stack the modulus or order can be obtained and provided to OpenSSL. In the case of private keys used for client or server authentication, the public key of the certificate is used as the source of the information. In the case of TLS Channel ID, the order is currently fixed and known (only NIST P-256 is supported). Bug: 19284418 Change-Id: I8fea2492f9cf48cfc29c3e7d2ee99a68e84e82ec/"
,,0.5692,conscrypt,"am e90640d7: Merge ""Fix RSA upcalls from TLS/SSL into JCA."" into mnc-dev * commit e90640d772b9c123b8f1ed2cbf30be4d693a30e7: Fix RSA upcalls from TLS/SSL into JCA./Merge ""Fix RSA upcalls from TLS/SSL into JCA."" into mnc-dev/Fix RSA upcalls from TLS/SSL into JCA. When BoringSSL/OpenSSL TLS/SSL stack operates on opaque private keys (those that dont expose their key material) it upcalls (via Conscrypts NativeCrypto) into corresponding JCA Signature and Cipher primitives. This CL fixes two issues with RSA-related upcalls, which prevented the use of opaque RSA private keys for TLS/SSL with Conscrypt backed by BoringSSL: * RSA sign was upcalled into RSA Cipher decrypt using private key. In JCA, the correct upcall is RSA Signature sign. This is now invoked instead of RSA Cipher decrypt. * RSA decrypt was not implemented. Its now implemented. As part of implementing RSA decrypt upcall from BoringSSL, it transpired that BoringSSL requests no padding as opposed to OpenSSL which requests PKCS#1 padding. As a result, this CL modifies the decrypt upcall to take a padding parameter. The implementation of the upcall (see CryptoUpcalls.java) now supports PKCS#1 padding scheme, OAEP padding scheme, and no padding. This CL also drops the encrypt/decrypt flag from the RSA encrypt/decrypt upcall and simplies it into an RSA decrypt upcall. RSA encrypt upcall is not needed at all. (cherry-picked from commit 279e98451390d0a90c5fc04eac7ddd4045180465) Bug: 21738458 Change-Id: I075aa74e4cd89dd3ceab99f728ce371c7bc89cf0/am 79a9e89f: am 279e9845: Fix RSA upcalls from TLS/SSL into JCA. * commit 79a9e89fa34f1ea96be9dc4bf742ca2884eaf858: Fix RSA upcalls from TLS/SSL into JCA./am 279e9845: Fix RSA upcalls from TLS/SSL into JCA. * commit 279e98451390d0a90c5fc04eac7ddd4045180465: Fix RSA upcalls from TLS/SSL into JCA./Fix RSA upcalls from TLS/SSL into JCA. When BoringSSL/OpenSSL TLS/SSL stack operates on opaque private keys (those that dont expose their key material) it upcalls (via Conscrypts NativeCrypto) into corresponding JCA Signature and Cipher primitives. This CL fixes two issues with RSA-related upcalls, which prevented the use of opaque RSA private keys for TLS/SSL with Conscrypt backed by BoringSSL: * RSA sign was upcalled into RSA Cipher decrypt using private key. In JCA, the correct upcall is RSA Signature sign. This is now invoked instead of RSA Cipher decrypt. * RSA decrypt was not implemented. Its now implemented. As part of implementing RSA decrypt upcall from BoringSSL, it transpired that BoringSSL requests no padding as opposed to OpenSSL which requests PKCS#1 padding. As a result, this CL modifies the decrypt upcall to take a padding parameter. The implementation of the upcall (see CryptoUpcalls.java) now supports PKCS#1 padding scheme, OAEP padding scheme, and no padding. This CL also drops the encrypt/decrypt flag from the RSA encrypt/decrypt upcall and simplies it into an RSA decrypt upcall. RSA encrypt upcall is not needed at all. Bug: 21738458 Change-Id: I2a4610890ea1ed1a2e99eb1d5c34348fbf406e54/Move BoringSSL indication to NativeConstants Toucing NativeCrypto causes System.loadLibrary(...) to be called which causes classloader initialization to fail during compile time. To allow more to be initialized, move this to NativeConstants. (cherry picked from commit f5b4518ebe23c76f931ddb157c44503c2f6b7dee) Bug: 21036900 Change-Id: I07f0f5be9559a9fa9a652d1bcd82a9f88640653e/Move BoringSSL indication to NativeConstants Toucing NativeCrypto causes System.loadLibrary(...) to be called which causes classloader initialization to fail during compile time. To allow more to be initialized, move this to NativeConstants. Bug: 21036900 Change-Id: I07f0f5be9559a9fa9a652d1bcd82a9f88640653e/"
,,0.1133,conscrypt,"am 53629cfd: OpenSSLKey: unsupported algorithm is an InvalidKeyException * commit 53629cfd4176ef5b24f4eff553f636b701a95a05: OpenSSLKey: unsupported algorithm is an InvalidKeyException/am bbc1d9ce: am aa029a4d: Merge ""OpenSSLKey: unsupported algorithm is an InvalidKeyException"" * commit bbc1d9ce0101c3a91b10ab76734c6024bc671f99: OpenSSLKey: unsupported algorithm is an InvalidKeyException/am aa029a4d: Merge ""OpenSSLKey: unsupported algorithm is an InvalidKeyException"" * commit aa029a4d2b21faf740a75f16b849b46ca84fa855: OpenSSLKey: unsupported algorithm is an InvalidKeyException/OpenSSLKey: unsupported algorithm is an InvalidKeyException When an invalid key is passed in we may throw NoSuchAlgorithmException if its a key we dont support, but we should convert this to the correct exception for this API. (cherry picked from commit ed396e937f8e0ef878cb9a8d16cff2e5a07f8c7d) Bug: 21209493 Change-Id: I55123035295203f2676538ac89ba4eb91141b273/Merge ""OpenSSLKey: unsupported algorithm is an InvalidKeyException""/OpenSSLKey: unsupported algorithm is an InvalidKeyException When an invalid key is passed in we may throw NoSuchAlgorithmException if its a key we dont support, but we should convert this to the correct exception for this API. Bug: 21209493 Change-Id: I55123035295203f2676538ac89ba4eb91141b273/"
,,0.5126,conscrypt,"am 6fd6f862: am 05b39385: Merge changes I960960c3,Ifc556ba6,I34b9d839 * commit 6fd6f8620f883387f2b24c9654dfbabf76c3c591: Update CryptoUpcalls documentation Documentation fixes OpenSSLCipher: remove unused variable/am 05b39385: Merge changes I960960c3,Ifc556ba6,I34b9d839 * commit 05b393852f1f6f5529ee454503dfd2c795e64330: Update CryptoUpcalls documentation Documentation fixes OpenSSLCipher: remove unused variable/Merge changes I960960c3,Ifc556ba6,I34b9d839 * changes: Update CryptoUpcalls documentation Documentation fixes OpenSSLCipher: remove unused variable/am e90640d7: Merge ""Fix RSA upcalls from TLS/SSL into JCA."" into mnc-dev * commit e90640d772b9c123b8f1ed2cbf30be4d693a30e7: Fix RSA upcalls from TLS/SSL into JCA./Merge ""Fix RSA upcalls from TLS/SSL into JCA."" into mnc-dev/Try to get preferred external provider When using an opaque key, try to honor the systems preferred provider which is selected via late binding. If its not found, try to find the first provider that initializes correctly with the given key. (cherry picked from commit c590a930a5faff2563fdf4247eb694a243b71b96) Bug: 21737886 Change-Id: I17483136aa5c1c5e474109525aefac9facaf7379/Fix RSA upcalls from TLS/SSL into JCA. When BoringSSL/OpenSSL TLS/SSL stack operates on opaque private keys (those that dont expose their key material) it upcalls (via Conscrypts NativeCrypto) into corresponding JCA Signature and Cipher primitives. This CL fixes two issues with RSA-related upcalls, which prevented the use of opaque RSA private keys for TLS/SSL with Conscrypt backed by BoringSSL: * RSA sign was upcalled into RSA Cipher decrypt using private key. In JCA, the correct upcall is RSA Signature sign. This is now invoked instead of RSA Cipher decrypt. * RSA decrypt was not implemented. Its now implemented. As part of implementing RSA decrypt upcall from BoringSSL, it transpired that BoringSSL requests no padding as opposed to OpenSSL which requests PKCS#1 padding. As a result, this CL modifies the decrypt upcall to take a padding parameter. The implementation of the upcall (see CryptoUpcalls.java) now supports PKCS#1 padding scheme, OAEP padding scheme, and no padding. This CL also drops the encrypt/decrypt flag from the RSA encrypt/decrypt upcall and simplies it into an RSA decrypt upcall. RSA encrypt upcall is not needed at all. (cherry-picked from commit 279e98451390d0a90c5fc04eac7ddd4045180465) Bug: 21738458 Change-Id: I075aa74e4cd89dd3ceab99f728ce371c7bc89cf0/Try to get preferred external provider When using an opaque key, try to honor the systems preferred provider which is selected via late binding. If its not found, try to find the first provider that initializes correctly with the given key. Bug: 21737886 Change-Id: I17483136aa5c1c5e474109525aefac9facaf7379/am 79a9e89f: am 279e9845: Fix RSA upcalls from TLS/SSL into JCA. * commit 79a9e89fa34f1ea96be9dc4bf742ca2884eaf858: Fix RSA upcalls from TLS/SSL into JCA./am 279e9845: Fix RSA upcalls from TLS/SSL into JCA. * commit 279e98451390d0a90c5fc04eac7ddd4045180465: Fix RSA upcalls from TLS/SSL into JCA./Fix RSA upcalls from TLS/SSL into JCA. When BoringSSL/OpenSSL TLS/SSL stack operates on opaque private keys (those that dont expose their key material) it upcalls (via Conscrypts NativeCrypto) into corresponding JCA Signature and Cipher primitives. This CL fixes two issues with RSA-related upcalls, which prevented the use of opaque RSA private keys for TLS/SSL with Conscrypt backed by BoringSSL: * RSA sign was upcalled into RSA Cipher decrypt using private key. In JCA, the correct upcall is RSA Signature sign. This is now invoked instead of RSA Cipher decrypt. * RSA decrypt was not implemented. Its now implemented. As part of implementing RSA decrypt upcall from BoringSSL, it transpired that BoringSSL requests no padding as opposed to OpenSSL which requests PKCS#1 padding. As a result, this CL modifies the decrypt upcall to take a padding parameter. The implementation of the upcall (see CryptoUpcalls.java) now supports PKCS#1 padding scheme, OAEP padding scheme, and no padding. This CL also drops the encrypt/decrypt flag from the RSA encrypt/decrypt upcall and simplies it into an RSA decrypt upcall. RSA encrypt upcall is not needed at all. Bug: 21738458 Change-Id: I2a4610890ea1ed1a2e99eb1d5c34348fbf406e54/"
,,0.2908,conscrypt,"Move BoringSSL indication to NativeConstants Toucing NativeCrypto causes System.loadLibrary(...) to be called which causes classloader initialization to fail during compile time. To allow more to be initialized, move this to NativeConstants. (cherry picked from commit f5b4518ebe23c76f931ddb157c44503c2f6b7dee) Bug: 21036900 Change-Id: I07f0f5be9559a9fa9a652d1bcd82a9f88640653e/Move BoringSSL indication to NativeConstants Toucing NativeCrypto causes System.loadLibrary(...) to be called which causes classloader initialization to fail during compile time. To allow more to be initialized, move this to NativeConstants. Bug: 21036900 Change-Id: I07f0f5be9559a9fa9a652d1bcd82a9f88640653e/"
,,0.5034,conscrypt,"Merge ""Speed up digesting by avoiding unnecessary operations."" am: 22324dd963 * commit 22324dd9635b9a7fa0b0e524a9313bba524db3ad: Speed up digesting by avoiding unnecessary operations./Merge ""Speed up digesting by avoiding unnecessary operations.""/Speed up digesting by avoiding unnecessary operations. Conscrypts MessageDigest implementations at the end of computing a digest create and initialize a new EVP_MD_CTX and then also intialize the digest struct there. This is done because the MessageDigest instance could be reused for a new digesting session. This change implements three optimizations: 1. MessageDigestSpi now reuses its EVP_MD_CTX instead of creating a new one for each new digesting session. 2. MessageDigestSpi now defers the initialization of the digest struct in EVP_MD_CTX till the first invocation of engineUpdate/engineDigest. 3. MessagDigestSpi (and SignatureSpi) no longer invoke EVP_MD_CTX_init after EVP_MD_CTX_create because EVP_MD_CTX_create initializes the EVP_MD_CTX it creates. libcores MessageDigestBenchmark on Nexus 5 shows: * 10-15% faster performance for a single digest of 8192 bytes. * 15-20% faster performance for reusing a MessageDigest instance to compute a digest of 8192 bytes ten times. Change-Id: I8a0697310ef7efcd4db6870e54eb46102fd4a941/Merge ""Revert ""Speed up digesting by avoiding unnecessary operations."""" am: a31af9612c am: 8bfea2c249 * commit 8bfea2c24960591d64b745aaedc6634e39c577ba: Revert ""Speed up digesting by avoiding unnecessary operations.""/Merge ""Revert ""Speed up digesting by avoiding unnecessary operations."""" am: a31af9612c * commit a31af9612cfeb3cb6a84c8e4e50954580f712046: Revert ""Speed up digesting by avoiding unnecessary operations.""/Merge ""Revert ""Speed up digesting by avoiding unnecessary operations.""""/Revert ""Speed up digesting by avoiding unnecessary operations."" This reverts commit 5041dd13c9499e4154436ef1f105a3d5d46caa19. This change broke a libcore test: org.apache.harmony.security.tests.java.security.DigestInputStream2Test#test_onZ java.lang.RuntimeException: Unable to copy EVP_MD_CTX at com.android.org.conscrypt.NativeCrypto.EVP_MD_CTX_copy(Native Method) at com.android.org.conscrypt.OpenSSLMessageDigestJDK.clone(OpenSSLMessageDigestJDK.java:200) at java.security.MessageDigest$MessageDigestImpl.clone(MessageDigest.java:428) at org.apache.harmony.security.tests.java.security.DigestInputStream2Test.test_onZ(DigestInputStream2Test.java:62) org.apache.harmony.security.tests.java.security.DigestInputStream2Test#test_onZ FAIL (EXEC_FAILED) Change-Id: Ib925bc0aadb633bbad4240f1d52bdb6676afc56f/Merge ""Speed up digesting by avoiding unnecessary operations."" am: b88f0fe123 am: d1734d96bd * commit d1734d96bd66ffad0f27b654ecab5eb4ea97efa6: Speed up digesting by avoiding unnecessary operations./Merge ""Speed up digesting by avoiding unnecessary operations."" am: b88f0fe123 * commit b88f0fe1237e17dbd9cc4e056d7e6211d89993b1: Speed up digesting by avoiding unnecessary operations./Merge ""Speed up digesting by avoiding unnecessary operations.""/Speed up digesting by avoiding unnecessary operations. Conscrypts MessageDigest implementations at the end of computing a digest create and initialize a new EVP_MD_CTX and then also intialize the digest struct there. This is done because the MessageDigest instance could be reused for a new digesting session. This change implements two optimizations: 1. MessageDigestImpl instance now reuses its EVP_MD_CTX instead of creating a new one for each new digesting session. 2. MessageDigestImpl instance now defers the initialization of the digest struct in EVP_MD_CTX till the first invocation of engineUpdate/engineDigest. libcores MessageDigestBenchmark on Nexus 5 shows: * 10-15% faster performance for a single digest of 8192 bytes. * 15-20% faster performance for reusing a MessageDigest instance to compute a digest of 8192 bytes ten times. Change-Id: I0e476381321127642315355f848a1ba90114fe7d/Zero-copy digesting for direct ByteBuffer input. Prior to this change, Conscrypts MessageDigest.update(ByteBuffer) invoked for a direct ByteBuffer resulted in the creation of a new byte[] of size ByteBuffer.remaining() and the copying of the ByteBuffers contents into that array. This change implements an optimization which avoids the allocation and copying, by making BoringSSL EVP_DigestUpdate read directly from the memory region represented by the direct ByteBuffer. Change-Id: I112d318128402d1d78e226df9dfe54af55955953/"
,,0.1788,conscrypt,"Zero-copy HMAC and signing/verification for direct ByteBuffer. Prior to this change, Conscrypts Mac and Signature implementations copied the contents of direct ByteBuffer inputs. This change implements an optimization which avoids the allocation and copying of contents of direct ByteBuffer inputs. Bug: 24674857 Change-Id: I1436839182483fd42318d4b0af4d633283e3453d/"
,,0.3262,conscrypt,"Merge ""Fix sanity checks around direct ByteBuffer memory access."" am: 4a41ff4a4e * commit 4a41ff4a4e7d07be60fcf2357a3df6ce8f2f3724: Fix sanity checks around direct ByteBuffer memory access./Merge ""Speed up digesting by avoiding unnecessary operations."" am: 22324dd963 * commit 22324dd9635b9a7fa0b0e524a9313bba524db3ad: Speed up digesting by avoiding unnecessary operations./Merge ""Revert ""Speed up digesting by avoiding unnecessary operations."""" am: a31af9612c am: 8bfea2c249 * commit 8bfea2c24960591d64b745aaedc6634e39c577ba: Revert ""Speed up digesting by avoiding unnecessary operations.""/Merge ""Speed up digesting by avoiding unnecessary operations."" am: b88f0fe123 am: d1734d96bd * commit d1734d96bd66ffad0f27b654ecab5eb4ea97efa6: Speed up digesting by avoiding unnecessary operations./Merge ""Fix sanity checks around direct ByteBuffer memory access."" am: 4a41ff4a4e * commit 4a41ff4a4e7d07be60fcf2357a3df6ce8f2f3724: Fix sanity checks around direct ByteBuffer memory access./Merge ""Fix sanity checks around direct ByteBuffer memory access.""/Fix sanity checks around direct ByteBuffer memory access. This fixes the sanity checks around access to memory backing direct BytBuffer instances. The previous checks wouldve erronously failed if pointers crossed the 2^63 boundary. There is no need for check for pointer overflow. Bug: 24674857 Change-Id: Ic8b5a651418c401d32eb0c8053217988963cd326/"
,,0.2888,conscrypt,"Merge ""Fix sanity checks around direct ByteBuffer memory access."" am: 4a41ff4a4e * commit 4a41ff4a4e7d07be60fcf2357a3df6ce8f2f3724: Fix sanity checks around direct ByteBuffer memory access./Merge ""Fix sanity checks around direct ByteBuffer memory access."" am: 4a41ff4a4e * commit 4a41ff4a4e7d07be60fcf2357a3df6ce8f2f3724: Fix sanity checks around direct ByteBuffer memory access./Merge ""Fix sanity checks around direct ByteBuffer memory access.""/Fix sanity checks around direct ByteBuffer memory access. This fixes the sanity checks around access to memory backing direct BytBuffer instances. The previous checks wouldve erronously failed if pointers crossed the 2^63 boundary. There is no need for check for pointer overflow. Bug: 24674857 Change-Id: Ic8b5a651418c401d32eb0c8053217988963cd326/"
,,0.2664,conscrypt,OpenSSLSessionImpl: add better errors when converting am: de8236f4bb * commit de8236f4bb9d70fa4e6a52679b4bf40b04c44f9b: OpenSSLSessionImpl: add better errors when converting/OpenSSLSessionImpl: add better errors when converting Frequently an old SSLSession cache from a different version of OpenSSL or BoringSSL will cause the de-serialization of the SSLSession information to fail. This will spam the logs and happens Frequently when GmsCores ProviderInstaller is used. For now try to extract a bit more useful information from the error thrown by native code and dont bother to print the stack trace since its not fatal. (cherry picked from commit de8236f4bb9d70fa4e6a52679b4bf40b04c44f9b) Bug: 25328662 Change-Id: I0a396a52418e7911b98133b45bbfafcc6651e863/OpenSSLSessionImpl: add better errors when converting Frequently an old SSLSession cache from a different version of OpenSSL or BoringSSL will cause the de-serialization of the SSLSession information to fail. This will spam the logs and happens Frequently when GmsCores ProviderInstaller is used. For now try to extract a bit more useful information from the error thrown by native code and dont bother to print the stack trace since its not fatal. Bug: 25328662 Change-Id: I0a396a52418e7911b98133b45bbfafcc6651e863/
,,0.5423,conscrypt,"Wrap cached sessions before returning SSLSession should be wrapped so that cached sessions might have the functionality that ExtendedSSLSession offers. This also made the SSLSessionTest fail because the pre-cached instance would be ExtendedSSLSession and the post-cached session would be a regular SSLSession. To keep compatibility with older versions of the platform, it was impossible to directly switch OpenSSLSessionImpl over to ExtendedSSLSession. So the use of a delegate in the case when the platform does have ExtendedSSLSession was required. Since older platform versions still use OpenSSLSessionImpl that extends SSLSession, we just directly inflate the serialized sessions to that. The SSLSessionTest was changed to accomodate the delegate scheme since SSLSession does not have an equals method, the tests for SSLSessionTest were directly comparing object instance equality which fails when the sessions are wrapped in a delegate like this. (cherry picked from commit 710c0817a2a13135b35f14faaef5ca069daf7b6c) Bug: 27123298 Change-Id: Iefbea03a72dbcc76ae0b439cfdcecd817926b7d0/Wrap cached sessions before returning SSLSession should be wrapped so that cached sessions might have the functionality that ExtendedSSLSession offers. This also made the SSLSessionTest fail because the pre-cached instance would be ExtendedSSLSession and the post-cached session would be a regular SSLSession. To keep compatibility with older versions of the platform, it was impossible to directly switch OpenSSLSessionImpl over to ExtendedSSLSession. So the use of a delegate in the case when the platform does have ExtendedSSLSession was required. Since older platform versions still use OpenSSLSessionImpl that extends SSLSession, we just directly inflate the serialized sessions to that. The SSLSessionTest was changed to accomodate the delegate scheme since SSLSession does not have an equals method, the tests for SSLSessionTest were directly comparing object instance equality which fails when the sessions are wrapped in a delegate like this. Bug: 27123298 Change-Id: Iefbea03a72dbcc76ae0b439cfdcecd817926b7d0/"
,,0.5681,conscrypt,"Use SSL_session_reused to check when a session was reused The returned session_id could be exactly the same in the case of TLS session tickets, so use the SSL_session_reused API to determine exactly when a session was reused. (cherry picked from commit 1115fa0f6dbbff3a913fbce39ca98f9a78425c72) Bug: 28751153 Change-Id: Ie82e4d1bb326d7e7deb7981a1e57df393f6c0e1f/Use SSL_session_reused to check when a session was reused The returned session_id could be exactly the same in the case of TLS session tickets, so use the SSL_session_reused API to determine exactly when a session was reused. (cherry picked from commit 1115fa0f6dbbff3a913fbce39ca98f9a78425c72) Bug: 28751153 Change-Id: Ie82e4d1bb326d7e7deb7981a1e57df393f6c0e1f/Use SSL_session_reused to check when a session was reused The returned session_id could be exactly the same in the case of TLS session tickets, so use the SSL_session_reused API to determine exactly when a session was reused. Bug: 28751153 Change-Id: Ie82e4d1bb326d7e7deb7981a1e57df393f6c0e1f/Wrap cached sessions before returning SSLSession should be wrapped so that cached sessions might have the functionality that ExtendedSSLSession offers. This also made the SSLSessionTest fail because the pre-cached instance would be ExtendedSSLSession and the post-cached session would be a regular SSLSession. To keep compatibility with older versions of the platform, it was impossible to directly switch OpenSSLSessionImpl over to ExtendedSSLSession. So the use of a delegate in the case when the platform does have ExtendedSSLSession was required. Since older platform versions still use OpenSSLSessionImpl that extends SSLSession, we just directly inflate the serialized sessions to that. The SSLSessionTest was changed to accomodate the delegate scheme since SSLSession does not have an equals method, the tests for SSLSessionTest were directly comparing object instance equality which fails when the sessions are wrapped in a delegate like this. (cherry picked from commit 710c0817a2a13135b35f14faaef5ca069daf7b6c) Bug: 27123298 Change-Id: Iefbea03a72dbcc76ae0b439cfdcecd817926b7d0/Wrap cached sessions before returning SSLSession should be wrapped so that cached sessions might have the functionality that ExtendedSSLSession offers. This also made the SSLSessionTest fail because the pre-cached instance would be ExtendedSSLSession and the post-cached session would be a regular SSLSession. To keep compatibility with older versions of the platform, it was impossible to directly switch OpenSSLSessionImpl over to ExtendedSSLSession. So the use of a delegate in the case when the platform does have ExtendedSSLSession was required. Since older platform versions still use OpenSSLSessionImpl that extends SSLSession, we just directly inflate the serialized sessions to that. The SSLSessionTest was changed to accomodate the delegate scheme since SSLSession does not have an equals method, the tests for SSLSessionTest were directly comparing object instance equality which fails when the sessions are wrapped in a delegate like this. Bug: 27123298 Change-Id: Iefbea03a72dbcc76ae0b439cfdcecd817926b7d0/"
,,0.5288,conscrypt,"OpenSSLSessionImpl: add better errors when converting am: de8236f4bb * commit de8236f4bb9d70fa4e6a52679b4bf40b04c44f9b: OpenSSLSessionImpl: add better errors when converting/OpenSSLSessionImpl: add better errors when converting Frequently an old SSLSession cache from a different version of OpenSSL or BoringSSL will cause the de-serialization of the SSLSession information to fail. This will spam the logs and happens Frequently when GmsCores ProviderInstaller is used. For now try to extract a bit more useful information from the error thrown by native code and dont bother to print the stack trace since its not fatal. (cherry picked from commit de8236f4bb9d70fa4e6a52679b4bf40b04c44f9b) Bug: 25328662 Change-Id: I0a396a52418e7911b98133b45bbfafcc6651e863/OpenSSLSessionImpl: add better errors when converting Frequently an old SSLSession cache from a different version of OpenSSL or BoringSSL will cause the de-serialization of the SSLSession information to fail. This will spam the logs and happens Frequently when GmsCores ProviderInstaller is used. For now try to extract a bit more useful information from the error thrown by native code and dont bother to print the stack trace since its not fatal. Bug: 25328662 Change-Id: I0a396a52418e7911b98133b45bbfafcc6651e863/Wrap cached sessions before returning SSLSession should be wrapped so that cached sessions might have the functionality that ExtendedSSLSession offers. This also made the SSLSessionTest fail because the pre-cached instance would be ExtendedSSLSession and the post-cached session would be a regular SSLSession. To keep compatibility with older versions of the platform, it was impossible to directly switch OpenSSLSessionImpl over to ExtendedSSLSession. So the use of a delegate in the case when the platform does have ExtendedSSLSession was required. Since older platform versions still use OpenSSLSessionImpl that extends SSLSession, we just directly inflate the serialized sessions to that. The SSLSessionTest was changed to accomodate the delegate scheme since SSLSession does not have an equals method, the tests for SSLSessionTest were directly comparing object instance equality which fails when the sessions are wrapped in a delegate like this. (cherry picked from commit 710c0817a2a13135b35f14faaef5ca069daf7b6c) Bug: 27123298 Change-Id: Iefbea03a72dbcc76ae0b439cfdcecd817926b7d0/Wrap cached sessions before returning SSLSession should be wrapped so that cached sessions might have the functionality that ExtendedSSLSession offers. This also made the SSLSessionTest fail because the pre-cached instance would be ExtendedSSLSession and the post-cached session would be a regular SSLSession. To keep compatibility with older versions of the platform, it was impossible to directly switch OpenSSLSessionImpl over to ExtendedSSLSession. So the use of a delegate in the case when the platform does have ExtendedSSLSession was required. Since older platform versions still use OpenSSLSessionImpl that extends SSLSession, we just directly inflate the serialized sessions to that. The SSLSessionTest was changed to accomodate the delegate scheme since SSLSession does not have an equals method, the tests for SSLSessionTest were directly comparing object instance equality which fails when the sessions are wrapped in a delegate like this. Bug: 27123298 Change-Id: Iefbea03a72dbcc76ae0b439cfdcecd817926b7d0/"
,,0.5533,conscrypt,"Infer what signature algorithms would be used BoringSSL currently has no API to check which algorithms were sent in the signature_algorithms extension, so just include the known signature algorithms for BoringSSL plus the required signature algorithms for the remote side. This may not be technically correct, but its the best we can do until we have an API in BoringSSL. The previous behavior of throwing UnsupportedOperationException was not very nice to users of this API. (cherry picked from commit 2ff9e88c46b53338d1f0132fa32c4a4f9479ebeb) Bug: 27123298 Change-Id: Icf99a82abfe827584ab80f6a13398119b23d35d5/Wrap cached sessions before returning SSLSession should be wrapped so that cached sessions might have the functionality that ExtendedSSLSession offers. This also made the SSLSessionTest fail because the pre-cached instance would be ExtendedSSLSession and the post-cached session would be a regular SSLSession. To keep compatibility with older versions of the platform, it was impossible to directly switch OpenSSLSessionImpl over to ExtendedSSLSession. So the use of a delegate in the case when the platform does have ExtendedSSLSession was required. Since older platform versions still use OpenSSLSessionImpl that extends SSLSession, we just directly inflate the serialized sessions to that. The SSLSessionTest was changed to accomodate the delegate scheme since SSLSession does not have an equals method, the tests for SSLSessionTest were directly comparing object instance equality which fails when the sessions are wrapped in a delegate like this. (cherry picked from commit 710c0817a2a13135b35f14faaef5ca069daf7b6c) Bug: 27123298 Change-Id: Iefbea03a72dbcc76ae0b439cfdcecd817926b7d0/Wrap cached sessions before returning SSLSession should be wrapped so that cached sessions might have the functionality that ExtendedSSLSession offers. This also made the SSLSessionTest fail because the pre-cached instance would be ExtendedSSLSession and the post-cached session would be a regular SSLSession. To keep compatibility with older versions of the platform, it was impossible to directly switch OpenSSLSessionImpl over to ExtendedSSLSession. So the use of a delegate in the case when the platform does have ExtendedSSLSession was required. Since older platform versions still use OpenSSLSessionImpl that extends SSLSession, we just directly inflate the serialized sessions to that. The SSLSessionTest was changed to accomodate the delegate scheme since SSLSession does not have an equals method, the tests for SSLSessionTest were directly comparing object instance equality which fails when the sessions are wrapped in a delegate like this. Bug: 27123298 Change-Id: Iefbea03a72dbcc76ae0b439cfdcecd817926b7d0/Infer what signature algorithms would be used BoringSSL currently has no API to check which algorithms were sent in the signature_algorithms extension, so just include the known signature algorithms for BoringSSL plus the required signature algorithms for the remote side. This may not be technically correct, but its the best we can do until we have an API in BoringSSL. The previous behavior of throwing UnsupportedOperationException was not very nice to users of this API. Bug: 27123298 Change-Id: Icf99a82abfe827584ab80f6a13398119b23d35d5/"
,,0.1053,conscrypt,Remove legacy certificate pinning code This removes the old CertPinManager code and moves CertPinManager to being an interface that the platform can use to have certificate pinning for the network security config done as part of chain building instead of after a valid chain has been found. Bug: 30829862 Bug: 22666360 Test: Ran CertPinManagerTest Change-Id: Ib4f5100096f7eead3a51533cff44f68093034bb1/
,,0.1169,conscrypt,Remove legacy certificate pinning code This removes the old CertPinManager code and moves CertPinManager to being an interface that the platform can use to have certificate pinning for the network security config done as part of chain building instead of after a valid chain has been found. Bug: 30829862 Bug: 22666360 Test: Ran CertPinManagerTest Change-Id: Ib4f5100096f7eead3a51533cff44f68093034bb1/
,,0.1169,conscrypt,Remove legacy certificate pinning code This removes the old CertPinManager code and moves CertPinManager to being an interface that the platform can use to have certificate pinning for the network security config done as part of chain building instead of after a valid chain has been found. Bug: 30829862 Bug: 22666360 Test: Ran CertPinManagerTest Change-Id: Ib4f5100096f7eead3a51533cff44f68093034bb1/
,,0.1235,conscrypt,Remove legacy certificate pinning code This removes the old CertPinManager code and moves CertPinManager to being an interface that the platform can use to have certificate pinning for the network security config done as part of chain building instead of after a valid chain has been found. Bug: 30829862 Bug: 22666360 Test: Ran CertPinManagerTest Change-Id: Ib4f5100096f7eead3a51533cff44f68093034bb1/
,,0.1136,conscrypt,Remove legacy certificate pinning code This removes the old CertPinManager code and moves CertPinManager to being an interface that the platform can use to have certificate pinning for the network security config done as part of chain building instead of after a valid chain has been found. Bug: 30829862 Bug: 22666360 Test: Ran CertPinManagerTest Change-Id: Ib4f5100096f7eead3a51533cff44f68093034bb1/
,,0.1411,conscrypt,EvpMdRef: rename SIZE to SIZE_BYTES This should end confusion about whether EVP_MD_size is measured in bits or bytes. Test: cts-tradefed run cts CtsLibcoreTestCases arm64-v8a Change-Id: Iae3dab037dd0bc37313f7cdde643cb140545ccaa/Consolidate EVP_MD references to one place There were several places where EVP_get_digestbyname was being called for the same data. Consolidate these all down to one place so there is no need to call it several times in the same program. Test: cts-tradefed run cts CtsLibcoreTestCases arm64-v8a Change-Id: Ib3f8b678c775e74eb5edaabde42f042d7b4eac95/
,,0.2228,conscrypt,"Merge ""CT: avoid unchecked conversions"" am: cbfed7264b am: 4ab81236bf am: 70d91b4746 Change-Id: If86d5d5468cab0841bb12b68760c26c38880b0a8/Merge ""CT: avoid unchecked conversions"" am: cbfed7264b am: 4ab81236bf Change-Id: I31bd353bf9419dea720842af88d2bc281e01b5fd/Merge ""CT: avoid unchecked conversions"" am: cbfed7264b Change-Id: Ib94be684c81b3bea2a9ce3b87da74c5f64d8ff57/Merge ""CT: avoid unchecked conversions""/CT: avoid unchecked conversions Some of the CT code was using unchecked conversions between various types. Add the generic types for some and switch to Collections.emptyList() for others. Test: make make build-art-host vogar; vogar 0 host out/host/common/obj/JAVA_LIBRARIES/bouncycastle-hostdex_intermediates/classes.jack out/host/common/obj/JAVA_LIBRARIES/conscrypt-host_intermediates/javalib.jar out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack out/host/common/obj/JAVA_LIBRARIES/conscrypt-tests-hostdex_intermediates/classes.jack external/conscrypt/src/test/java/org/conscrypt/ct/*Test.java Change-Id: Ie68009f27bcdc78c52508e7fd6f5e27322769d36/Fix imports globally am: d0687b8c0d am: 967b0b11a3 am: be78c56078 Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d am: 967b0b11a3 Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally am: d0687b8c0d Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally Ran script to fix imports globally on all .java files. Committing results. Test: mmma external/conscrypt Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
,,0.3031,conscrypt,"CT: close InputStream after loading log The input stream passed to the log reading method was not closing the stream leading to leaked file descriptors. Close them in the reading method since the only caller expects this. Also note it in the javadoc in case there are other callers in the future. Test: make build-art-host vogar && vogar 0 host out/host/common/obj/JAVA_LIBRARIES/bouncycastle-hostdex_intermediates/classes.jack out/host/common/obj/JAVA_LIBRARIES/conscrypt-host_intermediates/javalib.jar out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack out/host/common/obj/JAVA_LIBRARIES/conscrypt-tests-hostdex_intermediates/classes.jack external/conscrypt/src/test/java/org/conscrypt/ct/*Test.java Change-Id: Ifef4e8cac35f1db969e414c133d214ab6cacfc3d/Merge ""CT: avoid unchecked conversions"" am: cbfed7264b am: 4ab81236bf am: 70d91b4746 Change-Id: If86d5d5468cab0841bb12b68760c26c38880b0a8/Merge ""CT: avoid unchecked conversions"" am: cbfed7264b am: 4ab81236bf Change-Id: I31bd353bf9419dea720842af88d2bc281e01b5fd/Merge ""CT: avoid unchecked conversions"" am: cbfed7264b Change-Id: Ib94be684c81b3bea2a9ce3b87da74c5f64d8ff57/Merge ""CT: avoid unchecked conversions""/CT: avoid unchecked conversions Some of the CT code was using unchecked conversions between various types. Add the generic types for some and switch to Collections.emptyList() for others. Test: make make build-art-host vogar; vogar 0 host out/host/common/obj/JAVA_LIBRARIES/bouncycastle-hostdex_intermediates/classes.jack out/host/common/obj/JAVA_LIBRARIES/conscrypt-host_intermediates/javalib.jar out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack out/host/common/obj/JAVA_LIBRARIES/conscrypt-tests-hostdex_intermediates/classes.jack external/conscrypt/src/test/java/org/conscrypt/ct/*Test.java Change-Id: Ie68009f27bcdc78c52508e7fd6f5e27322769d36/Avoid C-like array initialization am: 4dc3e45f01 am: 0d56ae4110 am: 638334fcbb Change-Id: Ib587e4e2ee9ba3fca19edb9d3c69c7545ba279bc/Track changes to the CT log format Logs are now stored in /data/misc/keychain/ct_trusted_logs/current/ and use \n as a delimiter instead of ,. Bug: 28746284 (cherry picked from commit 788bf530ca321a5d41d546b6888b62c5dc6ad193) Change-Id: Ib4037cee75fbf96ae6b1c6a1b50952221c22c7be/Avoid C-like array initialization am: 4dc3e45f01 am: 0d56ae4110 Change-Id: Id49db33b674ebde91e941bd152ae7b3d77812403/Avoid C-like array initialization am: 4dc3e45f01 Change-Id: I318373b1fc4c5f688d50c66f6c3cac2a4de8a3c5/Avoid C-like array initialization Move the array marker to the type to avoid C-like initializations. Test: make make build-art-host vogar; vogar 0 host out/host/common/obj/JAVA_LIBRARIES/bouncycastle-hostdex_intermediates/classes.jack out/host/common/obj/JAVA_LIBRARIES/conscrypt-host_intermediates/javalib.jar out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack out/host/common/obj/JAVA_LIBRARIES/conscrypt-tests-hostdex_intermediates/classes.jack external/conscrypt/src/test/java/org/conscrypt/ct/*Test.java Change-Id: I54bf2cd6398be56cdb7de7c2e938daf34f02e942/Fix imports globally am: d0687b8c0d am: 967b0b11a3 am: be78c56078 Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d am: 967b0b11a3 Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally am: d0687b8c0d Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally Ran script to fix imports globally on all .java files. Committing results. Test: mmma external/conscrypt Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
,,0.2217,conscrypt,"Merge ""CT: avoid unchecked conversions"" am: cbfed7264b am: 4ab81236bf am: 70d91b4746 Change-Id: If86d5d5468cab0841bb12b68760c26c38880b0a8/Merge ""CT: avoid unchecked conversions"" am: cbfed7264b am: 4ab81236bf Change-Id: I31bd353bf9419dea720842af88d2bc281e01b5fd/Merge ""CT: avoid unchecked conversions"" am: cbfed7264b Change-Id: Ib94be684c81b3bea2a9ce3b87da74c5f64d8ff57/Merge ""CT: avoid unchecked conversions""/CT: avoid unchecked conversions Some of the CT code was using unchecked conversions between various types. Add the generic types for some and switch to Collections.emptyList() for others. Test: make make build-art-host vogar; vogar 0 host out/host/common/obj/JAVA_LIBRARIES/bouncycastle-hostdex_intermediates/classes.jack out/host/common/obj/JAVA_LIBRARIES/conscrypt-host_intermediates/javalib.jar out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack out/host/common/obj/JAVA_LIBRARIES/conscrypt-tests-hostdex_intermediates/classes.jack external/conscrypt/src/test/java/org/conscrypt/ct/*Test.java Change-Id: Ie68009f27bcdc78c52508e7fd6f5e27322769d36/Fix imports globally am: d0687b8c0d am: 967b0b11a3 am: be78c56078 Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d am: 967b0b11a3 Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally am: d0687b8c0d Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally Ran script to fix imports globally on all .java files. Committing results. Test: mmma external/conscrypt Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
,,0.1343,conscrypt,EvpMdRef: rename SIZE to SIZE_BYTES This should end confusion about whether EVP_MD_size is measured in bits or bytes. Test: cts-tradefed run cts CtsLibcoreTestCases arm64-v8a Change-Id: Iae3dab037dd0bc37313f7cdde643cb140545ccaa/Consolidate EVP_MD references to one place There were several places where EVP_get_digestbyname was being called for the same data. Consolidate these all down to one place so there is no need to call it several times in the same program. Test: cts-tradefed run cts CtsLibcoreTestCases arm64-v8a Change-Id: Ib3f8b678c775e74eb5edaabde42f042d7b4eac95/Fix imports globally am: d0687b8c0d am: 967b0b11a3 am: be78c56078 Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d am: 967b0b11a3 Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally am: d0687b8c0d Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally Ran script to fix imports globally on all .java files. Committing results. Test: mmma external/conscrypt Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/
,,0.1966,conscrypt,"Fix length checks for signed vs unsigned/Fix unwrap bug for large messages. (#189) If you write a record and dont have enough destination buffer space to read all the plaintext, the plaintext gets left in the plaintext buffer and the next record you write ends up in the ciphertext buffer (and you read the leftover plaintext from the last record), and you continue to have a record sitting in the ciphertext buffer until you get two records that dont fit in the buffer together, at which point you get the short write and subsequent exception. Also added a test to verify the bug./Dont fill in RSA_METHOD.encrypt when not needed. This resolves a TODO, at the cost of adding two more. Newer BoringSSL revisions ignore the hook as of Its probably unnecessary in older revisions too, but since Conscrypt does not fill in rsa->n or rsa->e, its plausible that, prior to that BoringSSL change, someone might have passed Conscrypts custom RSA objects into a codepath that ultimately used RSA_encrypt. Tracing through Java cryptography goo is probably not worth the trouble, so Ive left it as an which can be removed in a couple weeks./Configure OCSP and SCTs on the SSL, not SSL_CTX. As Conscrypt is currently set up, one SSL_CTX (owned, ultimately, by the SSLContext) may correspond to multiple SSLParameters which, in the Java API, are configured on the SSLSocket or SSLEngine directly. Thus we should use the SSL versions of the APIs which now exist. This avoids mutating an SSL_CTX which may be shared by multiple SSLs with different configurations. Change-Id: I19485c316087004c6050d85520b0169f2ca0d493/Merge upstream master Test: cts-tradefed run cts CtsLibcoreOkHttpTestCases arm64-v8a Test: cts-tradefed run cts CtsLibcoreTestCases arm64-v8a Change-Id: I2c0020c76b48f549b898e09be0612710616ea602/Dont throw away all altnames when a bad one is seen Conscrypt is strict in following RFC 5280s requirement that DNS alternative names listed in X.509 certificates must be IA5Strings (aka 7-bit ASCII), with international domain names encoded in Punycode, but the existing implementation throws an exception when it encounters a nonconforming name, which results in the entire list of altnames being discarded whenever any of them are invalid. This change makes it so that only the nonconforming name is ignored, returning any other conforming names./"
,,0.1442,conscrypt,"Specify all TLS versions 1.0-1.2. (#360) If you specify a set of TLS versions with a gap in them, all versions above the gap are ignored, because the TLS protocol actually only includes a single number (the highest protocol version thats allowable). So the current version was specifying TLS 1.0 only. This fixes it to use whatever version is the highest available./Fix benchmarks broken by (#334) The cipher used in the benchmarks requires TLS 1.2./Support renegotiation with sockets (#321) Fixes Fixes"
,,0.0669,conscrypt,Fix benchmarks broken by (#334) The cipher used in the benchmarks requires TLS 1.2./
,,0.0873,conscrypt,Update more testing infrastructure. (#395) * Update testing build rules. * Move TestKeyStore to org.conscrypt. * Fix up a couple tests so they work in AOSP./
,,0.08199999999999999,conscrypt,Update more testing infrastructure. (#395) * Update testing build rules. * Move TestKeyStore to org.conscrypt. * Fix up a couple tests so they work in AOSP./
,,0.2566,conscrypt,"Add crypto tests to Conscrypt. (#403) These tests are pulled from AOSP with minor modifications. They test the behavior of the Cipher, KeyAgreement, and KeyGenerator classes for all installed providers (which includes Conscrypt when run under the ConscryptSuite). Specific modifications made: * Convert tests to JUnit4 style. * Fixes for running under OpenJDK and with SunJCE installed. * Removed tests for classes themselves rather than providers. Note that these tests are not all up to modern standards in terms of code style and readability, but Id like to commit them as-is on the basis that we can gradually improve them, but theyll do a lot more work being available and accessible than they would stuck in AOSP until they can be cleaned up. * Disable tests when running on HotSpot JRE. Oracles JRE refuses to run crypto providers that come from unsigned jar files. We cant sign the jar files in automated builds and tests and such, since that would require giving the world access to our signing key, so just disable those tests when running in an environment where they cant work. Also update our Travis build to use OpenJDK 8, since that allows these tests to run. * Exclude CipherTest from Java 6 testing for now. CipherTest uses GCMParameterSpec and AEADBadTagException relatively widely, and both were introduced in Java 7./Fix assumption that was disabling tests. (#397)/Update more testing infrastructure. (#395) * Update testing build rules. * Move TestKeyStore to org.conscrypt. * Fix up a couple tests so they work in AOSP./"
,,0.147,conscrypt,"A few small fixes in prep for adding tests. (#402) Add ARC4 KeyGenerator. Upcoming tests assume that every cipher also has a KeyGenerator available, so provide one. Add support for PKCS7PADDING constant and remove ISO10126PADDING. We never use the latter, and the former is used in an alias. When a user requests an alias, OpenJDK provides the alias name in the engineSetPadding call, whereas Android provides the concrete name, so make sure we can handle either. Fix a problem where engineSetPadding would never recognize OAEPPadding when passed to OpenSSLCipherRSA./"
,,0.0804,conscrypt,"Allow localhost as an SNI hostname. (#475) As an exception to the normal rule that you cant have an SNI hostname without dots, localhost is a fine hostname for SNI./"
,,0.0956,conscrypt,"Add method to OS and arch enums for building filenames. (#450) Customize X86_32 to return ""x86"", since nobody calls the architecture ""x86_32"", so switching the filename to that would be pretty odd. Fixes"
,,0.0974,conscrypt,"Add method to OS and arch enums for building filenames. (#450) Customize X86_32 to return ""x86"", since nobody calls the architecture ""x86_32"", so switching the filename to that would be pretty odd. Fixes"
,,0.2684,conscrypt,"Remove CONSCRYPT_LOG_DEBUG. (#467) We only had two places that CONSCRYPT_LOG_DEBUG was used, and theyre really errors, since theyre failures in the code that throws Java exceptions, which ""shouldnt"" happen. In addition, _VERBOSE logging can be suppressed, but _DEBUG cant, which isnt typical for those names. Just go with _VERBOSE logging if we need to log something in a suppressable manner./Add logging macros that work on all platforms. (#462) This adds CONSCRYPT_LOG_X macros that redirect to either ALOG on Android or fprintf(stderr) on non-Android. In the future, we could use these to allow users to register a logging callback and send the logs to a destination of their choice (via java.util.Logger or log4j or what have you), but for now well keep it simple. Fixes short buffer handling. (#440) This fixes a number of problems in Conscrypts ciphers when they are given an output buffer that is too small for the output. We didnt specifically handle CIPHER_R_BUFFER_TOO_SMALL errors from BoringSSL, so we threw RuntimeException on encountering them. We should be throwing ShortBufferException. Raw ChaCha20 didnt check for a short buffer at all, so it just passed the arrays down to native code, which could cause crashes or other weird behavior. EVP_AEAD ciphers used update() to only record data that needed to be encrypted and then did the actual encrypting in doFinal(). This combined with our implementation that implements doFinal() as a combination of updateInternal() + doFinalInternal() led to a situation where if the buffer passed to doFinal() was too small, the data would get added to the buffer to be encrypted in updateInternal() and then doFinalInternal() call would fail, which would mean a future call to doFinal() with the same data would end up encrypting that data twice. This call pattern is used by some internal CipherSpi methods from OpenJDK, so you could see it in practice even if the caller did nothing wrong. Also add tests around short buffer handling./"
,,0.0804,conscrypt,"Allow localhost as an SNI hostname. (#475) As an exception to the normal rule that you cant have an SNI hostname without dots, localhost is a fine hostname for SNI./"
,,0.332,conscrypt,"Update short buffer handling. (#440) This fixes a number of problems in Conscrypts ciphers when they are given an output buffer that is too small for the output. We didnt specifically handle CIPHER_R_BUFFER_TOO_SMALL errors from BoringSSL, so we threw RuntimeException on encountering them. We should be throwing ShortBufferException. Raw ChaCha20 didnt check for a short buffer at all, so it just passed the arrays down to native code, which could cause crashes or other weird behavior. EVP_AEAD ciphers used update() to only record data that needed to be encrypted and then did the actual encrypting in doFinal(). This combined with our implementation that implements doFinal() as a combination of updateInternal() + doFinalInternal() led to a situation where if the buffer passed to doFinal() was too small, the data would get added to the buffer to be encrypted in updateInternal() and then doFinalInternal() call would fail, which would mean a future call to doFinal() with the same data would end up encrypting that data twice. This call pattern is used by some internal CipherSpi methods from OpenJDK, so you could see it in practice even if the caller did nothing wrong. Also add tests around short buffer handling./"
,,0.3202,conscrypt,"Move TrustManagerImpl to common. (#503) This is the first step in making the TrustManager implementation available on OpenJDK, which is necessary for TLS 1.3 because the TrustManager implementations in OpenJDK throw an exception when they encounter an SSLSocket or SSLEngine that reports a protocol not in their enumerated lists. It moves the code and tests over so they compile on OpenJDK, but doesnt yet change anything about the provider, so the code isnt used. There are a few changes necessary: Extract an interface for TrustedCertificateStore, which is still platform-only due to its reliance on specific directories to find certs and other details of the Android platform. Extract an interface for CertBlacklist, for the same reason. Adjust TrustManagerImpl to get implementations of the add-on functionality (CertBlacklist, CTLogStore, and CTPolicy) from the Platform class instead of constructing them itself and tolerate nulls for those classes. The Platform classes for non-platform builds return null for those classes, but we might want to change that in the future. Make a few minor changes while moving things over (JDK 6 source compatibility, adjust tests for JUnit4, etc.)./"
,,0.3213,conscrypt,"Move TrustManagerImpl to common. (#503) This is the first step in making the TrustManager implementation available on OpenJDK, which is necessary for TLS 1.3 because the TrustManager implementations in OpenJDK throw an exception when they encounter an SSLSocket or SSLEngine that reports a protocol not in their enumerated lists. It moves the code and tests over so they compile on OpenJDK, but doesnt yet change anything about the provider, so the code isnt used. There are a few changes necessary: Extract an interface for TrustedCertificateStore, which is still platform-only due to its reliance on specific directories to find certs and other details of the Android platform. Extract an interface for CertBlacklist, for the same reason. Adjust TrustManagerImpl to get implementations of the add-on functionality (CertBlacklist, CTLogStore, and CTPolicy) from the Platform class instead of constructing them itself and tolerate nulls for those classes. The Platform classes for non-platform builds return null for those classes, but we might want to change that in the future. Make a few minor changes while moving things over (JDK 6 source compatibility, adjust tests for JUnit4, etc.)./"
,,0.3286,conscrypt,"Move TrustManagerImpl to common. (#503) This is the first step in making the TrustManager implementation available on OpenJDK, which is necessary for TLS 1.3 because the TrustManager implementations in OpenJDK throw an exception when they encounter an SSLSocket or SSLEngine that reports a protocol not in their enumerated lists. It moves the code and tests over so they compile on OpenJDK, but doesnt yet change anything about the provider, so the code isnt used. There are a few changes necessary: Extract an interface for TrustedCertificateStore, which is still platform-only due to its reliance on specific directories to find certs and other details of the Android platform. Extract an interface for CertBlacklist, for the same reason. Adjust TrustManagerImpl to get implementations of the add-on functionality (CertBlacklist, CTLogStore, and CTPolicy) from the Platform class instead of constructing them itself and tolerate nulls for those classes. The Platform classes for non-platform builds return null for those classes, but we might want to change that in the future. Make a few minor changes while moving things over (JDK 6 source compatibility, adjust tests for JUnit4, etc.)./"
,,0.3084,conscrypt,"Provide TrustManagerFactory (#516) This is necessary for users who want to enable TLS 1.3, since the TrustManagerFactory implementation shipped with OpenJDK throws an exception if it encounters an SSLSocket or SSLEngine thats negotiated TLS 1.3. Use our TrustManager in tests. Also adds a HostnameVerifier in the tests that does the simplest thing, because our TrustManager verifies hostnames by default, whereas the OpenJDK one doesnt, and the bundled HostnameVerifier on OpenJDK just fails to verify anything./Move TrustManagerImpl to common. (#503) This is the first step in making the TrustManager implementation available on OpenJDK, which is necessary for TLS 1.3 because the TrustManager implementations in OpenJDK throw an exception when they encounter an SSLSocket or SSLEngine that reports a protocol not in their enumerated lists. It moves the code and tests over so they compile on OpenJDK, but doesnt yet change anything about the provider, so the code isnt used. There are a few changes necessary: Extract an interface for TrustedCertificateStore, which is still platform-only due to its reliance on specific directories to find certs and other details of the Android platform. Extract an interface for CertBlacklist, for the same reason. Adjust TrustManagerImpl to get implementations of the add-on functionality (CertBlacklist, CTLogStore, and CTPolicy) from the Platform class instead of constructing them itself and tolerate nulls for those classes. The Platform classes for non-platform builds return null for those classes, but we might want to change that in the future. Make a few minor changes while moving things over (JDK 6 source compatibility, adjust tests for JUnit4, etc.)./"
,,0.1908,conscrypt,"Support opaque keys with RSA-PSS signatures. (#513) TLS 1.3 only uses RSA-PSS signatures (rather than RSA-PKCS#1), so we need to support these. Implement it by switching to Cipher.RSA/ECB/NoPadding instead of using Signature.RSA. Fix the opaque key tests so they actually work properly./Use Conscrypt.isConscrypt() in CryptoUpcalls. (#512) Also fix a couple typos./"
,,0.1165,conscrypt,Add buffer allocators to ConscryptEngineSocket (#550) This allows users to set a buffer allocator for both the buffers used by ConscryptEngineSocket directly and the ones use by the enclosed ConscryptEngine. Fixes API to get Conscrypt version (#541) Libraries like OkHttp want to be able to check what version of Conscrypt is available before attempting to enable new features (like TLS 1.3). Add a simple API to check what version of Conscrypt is being used. Fixes
,,0.3409,conscrypt,"Clean up session handling (#594) The session passed to the SSLSessionBindingListener was always an ExternalSession, even when that session was wrapped to support ExtendedSSLSession, which meant that observers saw two different sessions. Refactor putValue() and removeValue() on ExternalSession to take the session so that the wrappers can provide themselves. Add a test for SSLSessionBindingListener calling. Slightly clean up ConscryptEngineSocket.getSession(). It doesnt need to do cache the session from before it tries to handshake, and doing so means that if you call getSession() twice in succession it might return different results for no good reason. Get rid of SSLNullSession.isNullSession, SSLUtils.unwrapSession, and SessionDecorator, since that entire chain was only used in ConscryptEngineSocket.getSession(). Fixes"
,,0.3244,conscrypt,"Clean up session handling (#594) The session passed to the SSLSessionBindingListener was always an ExternalSession, even when that session was wrapped to support ExtendedSSLSession, which meant that observers saw two different sessions. Refactor putValue() and removeValue() on ExternalSession to take the session so that the wrappers can provide themselves. Add a test for SSLSessionBindingListener calling. Slightly clean up ConscryptEngineSocket.getSession(). It doesnt need to do cache the session from before it tries to handshake, and doing so means that if you call getSession() twice in succession it might return different results for no good reason. Get rid of SSLNullSession.isNullSession, SSLUtils.unwrapSession, and SessionDecorator, since that entire chain was only used in ConscryptEngineSocket.getSession(). Fixes"
,,0.3959,conscrypt,"Enable TLS 1.3 by default (#595) TLS 1.3 has seen successful rollouts in Chrome and Firefox, so were enabling it by default as well. We expect this to result in better security and performance. Detailed changes: Change the default TLS version to 1.3. Callers can still get connections that dont use TLS 1.3 by calling SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols() or SSLEngine.setEnabledProtocols(). Change to provide the TrustManager by default on OpenJDK. The TrustManager included in OpenJDK versions prior to 11 throws an exception if it encounters a TLS version higher than 1.2, so we need to provide a trust manager that will work with TLS 1.3. The Android trust manager (which is Conscrypt) will work fine, so dont provide ours there. Parameterize SSLSessionContextTest, since session behavior is significantly different on TLS 1.2 and 1.3. Also parameterized a few other test cases whose behavior significantly differs between the versions. Use session tickets in test connections. BoringSSL only supports session resumption using tickets in 1.3, and we want to have resumption functioning in our tests for the most part./"
,,0.5346,conscrypt,"Update Provider installation in tests (#629) Change CertPinManagerTest and CTVerifierTest to only install the provider if its not installed already and check if the provider was installed before uninstalling. Otherwise, when running on the Android platform they will uninstall the platform copy of Conscrypt and break every following test./Enable TLS 1.3 by default (#595) TLS 1.3 has seen successful rollouts in Chrome and Firefox, so were enabling it by default as well. We expect this to result in better security and performance. Detailed changes: Change the default TLS version to 1.3. Callers can still get connections that dont use TLS 1.3 by calling SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols() or SSLEngine.setEnabledProtocols(). Change to provide the TrustManager by default on OpenJDK. The TrustManager included in OpenJDK versions prior to 11 throws an exception if it encounters a TLS version higher than 1.2, so we need to provide a trust manager that will work with TLS 1.3. The Android trust manager (which is Conscrypt) will work fine, so dont provide ours there. Parameterize SSLSessionContextTest, since session behavior is significantly different on TLS 1.2 and 1.3. Also parameterized a few other test cases whose behavior significantly differs between the versions. Use session tickets in test connections. BoringSSL only supports session resumption using tickets in 1.3, and we want to have resumption functioning in our tests for the most part./Move libcore testing classes into testing (#607) When conscrypt was first separated from AOSP some of the AOSP libcore classes were copied into libcore-stub which is compiled against for both the openjdk and platform builds but only used at runtime by the openjdk builds. Unfortunately, those classes clash with internal classes provided by the Android runtime which will cause problems in future releases. This change moves those libcore-stub classes that are only used for testing from their libcore.... package into a org.conscrypt.... package to prevent clashes. It also moves them out of the libcore-stub module and into the testing module so they will be used on both platform and openjdk builds./"
,,0.3326,conscrypt,"Move libcore testing classes into testing (#607) When conscrypt was first separated from AOSP some of the AOSP libcore classes were copied into libcore-stub which is compiled against for both the openjdk and platform builds but only used at runtime by the openjdk builds. Unfortunately, those classes clash with internal classes provided by the Android runtime which will cause problems in future releases. This change moves those libcore-stub classes that are only used for testing from their libcore.... package into a org.conscrypt.... package to prevent clashes. It also moves them out of the libcore-stub module and into the testing module so they will be used on both platform and openjdk builds./"
,,0.4076,conscrypt,"Enable TLS 1.3 by default (#595) TLS 1.3 has seen successful rollouts in Chrome and Firefox, so were enabling it by default as well. We expect this to result in better security and performance. Detailed changes: Change the default TLS version to 1.3. Callers can still get connections that dont use TLS 1.3 by calling SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols() or SSLEngine.setEnabledProtocols(). Change to provide the TrustManager by default on OpenJDK. The TrustManager included in OpenJDK versions prior to 11 throws an exception if it encounters a TLS version higher than 1.2, so we need to provide a trust manager that will work with TLS 1.3. The Android trust manager (which is Conscrypt) will work fine, so dont provide ours there. Parameterize SSLSessionContextTest, since session behavior is significantly different on TLS 1.2 and 1.3. Also parameterized a few other test cases whose behavior significantly differs between the versions. Use session tickets in test connections. BoringSSL only supports session resumption using tickets in 1.3, and we want to have resumption functioning in our tests for the most part./"
,,0.3129,conscrypt,"Move libcore testing classes into testing (#607) When conscrypt was first separated from AOSP some of the AOSP libcore classes were copied into libcore-stub which is compiled against for both the openjdk and platform builds but only used at runtime by the openjdk builds. Unfortunately, those classes clash with internal classes provided by the Android runtime which will cause problems in future releases. This change moves those libcore-stub classes that are only used for testing from their libcore.... package into a org.conscrypt.... package to prevent clashes. It also moves them out of the libcore-stub module and into the testing module so they will be used on both platform and openjdk builds./"
,,0.4088,conscrypt,"Enable TLS 1.3 by default (#595) TLS 1.3 has seen successful rollouts in Chrome and Firefox, so were enabling it by default as well. We expect this to result in better security and performance. Detailed changes: Change the default TLS version to 1.3. Callers can still get connections that dont use TLS 1.3 by calling SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols() or SSLEngine.setEnabledProtocols(). Change to provide the TrustManager by default on OpenJDK. The TrustManager included in OpenJDK versions prior to 11 throws an exception if it encounters a TLS version higher than 1.2, so we need to provide a trust manager that will work with TLS 1.3. The Android trust manager (which is Conscrypt) will work fine, so dont provide ours there. Parameterize SSLSessionContextTest, since session behavior is significantly different on TLS 1.2 and 1.3. Also parameterized a few other test cases whose behavior significantly differs between the versions. Use session tickets in test connections. BoringSSL only supports session resumption using tickets in 1.3, and we want to have resumption functioning in our tests for the most part./"
,,0.4064,conscrypt,"Enable TLS 1.3 by default (#595) TLS 1.3 has seen successful rollouts in Chrome and Firefox, so were enabling it by default as well. We expect this to result in better security and performance. Detailed changes: Change the default TLS version to 1.3. Callers can still get connections that dont use TLS 1.3 by calling SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols() or SSLEngine.setEnabledProtocols(). Change to provide the TrustManager by default on OpenJDK. The TrustManager included in OpenJDK versions prior to 11 throws an exception if it encounters a TLS version higher than 1.2, so we need to provide a trust manager that will work with TLS 1.3. The Android trust manager (which is Conscrypt) will work fine, so dont provide ours there. Parameterize SSLSessionContextTest, since session behavior is significantly different on TLS 1.2 and 1.3. Also parameterized a few other test cases whose behavior significantly differs between the versions. Use session tickets in test connections. BoringSSL only supports session resumption using tickets in 1.3, and we want to have resumption functioning in our tests for the most part./"
,,0.3129,conscrypt,"Move libcore testing classes into testing (#607) When conscrypt was first separated from AOSP some of the AOSP libcore classes were copied into libcore-stub which is compiled against for both the openjdk and platform builds but only used at runtime by the openjdk builds. Unfortunately, those classes clash with internal classes provided by the Android runtime which will cause problems in future releases. This change moves those libcore-stub classes that are only used for testing from their libcore.... package into a org.conscrypt.... package to prevent clashes. It also moves them out of the libcore-stub module and into the testing module so they will be used on both platform and openjdk builds./"
,,0.3326,conscrypt,"Move libcore testing classes into testing (#607) When conscrypt was first separated from AOSP some of the AOSP libcore classes were copied into libcore-stub which is compiled against for both the openjdk and platform builds but only used at runtime by the openjdk builds. Unfortunately, those classes clash with internal classes provided by the Android runtime which will cause problems in future releases. This change moves those libcore-stub classes that are only used for testing from their libcore.... package into a org.conscrypt.... package to prevent clashes. It also moves them out of the libcore-stub module and into the testing module so they will be used on both platform and openjdk builds./"
,,0.1948,conscrypt,"Update Provider installation in tests (#629) Change CertPinManagerTest and CTVerifierTest to only install the provider if its not installed already and check if the provider was installed before uninstalling. Otherwise, when running on the Android platform they will uninstall the platform copy of Conscrypt and break every following test./"
,,0.4158,conscrypt,"Enable TLS 1.3 by default (#595) TLS 1.3 has seen successful rollouts in Chrome and Firefox, so were enabling it by default as well. We expect this to result in better security and performance. Detailed changes: Change the default TLS version to 1.3. Callers can still get connections that dont use TLS 1.3 by calling SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols() or SSLEngine.setEnabledProtocols(). Change to provide the TrustManager by default on OpenJDK. The TrustManager included in OpenJDK versions prior to 11 throws an exception if it encounters a TLS version higher than 1.2, so we need to provide a trust manager that will work with TLS 1.3. The Android trust manager (which is Conscrypt) will work fine, so dont provide ours there. Parameterize SSLSessionContextTest, since session behavior is significantly different on TLS 1.2 and 1.3. Also parameterized a few other test cases whose behavior significantly differs between the versions. Use session tickets in test connections. BoringSSL only supports session resumption using tickets in 1.3, and we want to have resumption functioning in our tests for the most part./"
,,0.5313,conscrypt,"Enable TLS 1.3 by default (#595) TLS 1.3 has seen successful rollouts in Chrome and Firefox, so were enabling it by default as well. We expect this to result in better security and performance. Detailed changes: Change the default TLS version to 1.3. Callers can still get connections that dont use TLS 1.3 by calling SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols() or SSLEngine.setEnabledProtocols(). Change to provide the TrustManager by default on OpenJDK. The TrustManager included in OpenJDK versions prior to 11 throws an exception if it encounters a TLS version higher than 1.2, so we need to provide a trust manager that will work with TLS 1.3. The Android trust manager (which is Conscrypt) will work fine, so dont provide ours there. Parameterize SSLSessionContextTest, since session behavior is significantly different on TLS 1.2 and 1.3. Also parameterized a few other test cases whose behavior significantly differs between the versions. Use session tickets in test connections. BoringSSL only supports session resumption using tickets in 1.3, and we want to have resumption functioning in our tests for the most part./Clean up session handling (#594) The session passed to the SSLSessionBindingListener was always an ExternalSession, even when that session was wrapped to support ExtendedSSLSession, which meant that observers saw two different sessions. Refactor putValue() and removeValue() on ExternalSession to take the session so that the wrappers can provide themselves. Add a test for SSLSessionBindingListener calling. Slightly clean up ConscryptEngineSocket.getSession(). It doesnt need to do cache the session from before it tries to handshake, and doing so means that if you call getSession() twice in succession it might return different results for no good reason. Get rid of SSLNullSession.isNullSession, SSLUtils.unwrapSession, and SessionDecorator, since that entire chain was only used in ConscryptEngineSocket.getSession(). Fixes"
,,0.3381,conscrypt,"Clean up session handling (#594) The session passed to the SSLSessionBindingListener was always an ExternalSession, even when that session was wrapped to support ExtendedSSLSession, which meant that observers saw two different sessions. Refactor putValue() and removeValue() on ExternalSession to take the session so that the wrappers can provide themselves. Add a test for SSLSessionBindingListener calling. Slightly clean up ConscryptEngineSocket.getSession(). It doesnt need to do cache the session from before it tries to handshake, and doing so means that if you call getSession() twice in succession it might return different results for no good reason. Get rid of SSLNullSession.isNullSession, SSLUtils.unwrapSession, and SessionDecorator, since that entire chain was only used in ConscryptEngineSocket.getSession(). Fixes"
,,0.3395,conscrypt,"Clean up session handling (#594) The session passed to the SSLSessionBindingListener was always an ExternalSession, even when that session was wrapped to support ExtendedSSLSession, which meant that observers saw two different sessions. Refactor putValue() and removeValue() on ExternalSession to take the session so that the wrappers can provide themselves. Add a test for SSLSessionBindingListener calling. Slightly clean up ConscryptEngineSocket.getSession(). It doesnt need to do cache the session from before it tries to handshake, and doing so means that if you call getSession() twice in succession it might return different results for no good reason. Get rid of SSLNullSession.isNullSession, SSLUtils.unwrapSession, and SessionDecorator, since that entire chain was only used in ConscryptEngineSocket.getSession(). Fixes"
,,0.3436,conscrypt,"Clean up session handling (#594) The session passed to the SSLSessionBindingListener was always an ExternalSession, even when that session was wrapped to support ExtendedSSLSession, which meant that observers saw two different sessions. Refactor putValue() and removeValue() on ExternalSession to take the session so that the wrappers can provide themselves. Add a test for SSLSessionBindingListener calling. Slightly clean up ConscryptEngineSocket.getSession(). It doesnt need to do cache the session from before it tries to handshake, and doing so means that if you call getSession() twice in succession it might return different results for no good reason. Get rid of SSLNullSession.isNullSession, SSLUtils.unwrapSession, and SessionDecorator, since that entire chain was only used in ConscryptEngineSocket.getSession(). Fixes"
,,0.3464,conscrypt,"Clean up session handling (#594) The session passed to the SSLSessionBindingListener was always an ExternalSession, even when that session was wrapped to support ExtendedSSLSession, which meant that observers saw two different sessions. Refactor putValue() and removeValue() on ExternalSession to take the session so that the wrappers can provide themselves. Add a test for SSLSessionBindingListener calling. Slightly clean up ConscryptEngineSocket.getSession(). It doesnt need to do cache the session from before it tries to handshake, and doing so means that if you call getSession() twice in succession it might return different results for no good reason. Get rid of SSLNullSession.isNullSession, SSLUtils.unwrapSession, and SessionDecorator, since that entire chain was only used in ConscryptEngineSocket.getSession(). Fixes"
,,0.3368,conscrypt,"Clean up session handling (#594) The session passed to the SSLSessionBindingListener was always an ExternalSession, even when that session was wrapped to support ExtendedSSLSession, which meant that observers saw two different sessions. Refactor putValue() and removeValue() on ExternalSession to take the session so that the wrappers can provide themselves. Add a test for SSLSessionBindingListener calling. Slightly clean up ConscryptEngineSocket.getSession(). It doesnt need to do cache the session from before it tries to handshake, and doing so means that if you call getSession() twice in succession it might return different results for no good reason. Get rid of SSLNullSession.isNullSession, SSLUtils.unwrapSession, and SessionDecorator, since that entire chain was only used in ConscryptEngineSocket.getSession(). Fixes"
,,0.3889,conscrypt,"Enable TLS 1.3 by default (#595) TLS 1.3 has seen successful rollouts in Chrome and Firefox, so were enabling it by default as well. We expect this to result in better security and performance. Detailed changes: Change the default TLS version to 1.3. Callers can still get connections that dont use TLS 1.3 by calling SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols() or SSLEngine.setEnabledProtocols(). Change to provide the TrustManager by default on OpenJDK. The TrustManager included in OpenJDK versions prior to 11 throws an exception if it encounters a TLS version higher than 1.2, so we need to provide a trust manager that will work with TLS 1.3. The Android trust manager (which is Conscrypt) will work fine, so dont provide ours there. Parameterize SSLSessionContextTest, since session behavior is significantly different on TLS 1.2 and 1.3. Also parameterized a few other test cases whose behavior significantly differs between the versions. Use session tickets in test connections. BoringSSL only supports session resumption using tickets in 1.3, and we want to have resumption functioning in our tests for the most part./"
,,0.3228,conscrypt,"Move libcore testing classes into testing (#607) When conscrypt was first separated from AOSP some of the AOSP libcore classes were copied into libcore-stub which is compiled against for both the openjdk and platform builds but only used at runtime by the openjdk builds. Unfortunately, those classes clash with internal classes provided by the Android runtime which will cause problems in future releases. This change moves those libcore-stub classes that are only used for testing from their libcore.... package into a org.conscrypt.... package to prevent clashes. It also moves them out of the libcore-stub module and into the testing module so they will be used on both platform and openjdk builds./"
,,0.3312,conscrypt,"Move libcore testing classes into testing (#607) When conscrypt was first separated from AOSP some of the AOSP libcore classes were copied into libcore-stub which is compiled against for both the openjdk and platform builds but only used at runtime by the openjdk builds. Unfortunately, those classes clash with internal classes provided by the Android runtime which will cause problems in future releases. This change moves those libcore-stub classes that are only used for testing from their libcore.... package into a org.conscrypt.... package to prevent clashes. It also moves them out of the libcore-stub module and into the testing module so they will be used on both platform and openjdk builds./"
,,0.327,conscrypt,"Move libcore testing classes into testing (#607) When conscrypt was first separated from AOSP some of the AOSP libcore classes were copied into libcore-stub which is compiled against for both the openjdk and platform builds but only used at runtime by the openjdk builds. Unfortunately, those classes clash with internal classes provided by the Android runtime which will cause problems in future releases. This change moves those libcore-stub classes that are only used for testing from their libcore.... package into a org.conscrypt.... package to prevent clashes. It also moves them out of the libcore-stub module and into the testing module so they will be used on both platform and openjdk builds./"
,,0.3143,conscrypt,"Move libcore testing classes into testing (#607) When conscrypt was first separated from AOSP some of the AOSP libcore classes were copied into libcore-stub which is compiled against for both the openjdk and platform builds but only used at runtime by the openjdk builds. Unfortunately, those classes clash with internal classes provided by the Android runtime which will cause problems in future releases. This change moves those libcore-stub classes that are only used for testing from their libcore.... package into a org.conscrypt.... package to prevent clashes. It also moves them out of the libcore-stub module and into the testing module so they will be used on both platform and openjdk builds./"
,,0.3172,conscrypt,"Move libcore testing classes into testing (#607) When conscrypt was first separated from AOSP some of the AOSP libcore classes were copied into libcore-stub which is compiled against for both the openjdk and platform builds but only used at runtime by the openjdk builds. Unfortunately, those classes clash with internal classes provided by the Android runtime which will cause problems in future releases. This change moves those libcore-stub classes that are only used for testing from their libcore.... package into a org.conscrypt.... package to prevent clashes. It also moves them out of the libcore-stub module and into the testing module so they will be used on both platform and openjdk builds./"
,,0.5237,conscrypt,"Enable TLS 1.3 by default (#595) TLS 1.3 has seen successful rollouts in Chrome and Firefox, so were enabling it by default as well. We expect this to result in better security and performance. Detailed changes: Change the default TLS version to 1.3. Callers can still get connections that dont use TLS 1.3 by calling SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols() or SSLEngine.setEnabledProtocols(). Change to provide the TrustManager by default on OpenJDK. The TrustManager included in OpenJDK versions prior to 11 throws an exception if it encounters a TLS version higher than 1.2, so we need to provide a trust manager that will work with TLS 1.3. The Android trust manager (which is Conscrypt) will work fine, so dont provide ours there. Parameterize SSLSessionContextTest, since session behavior is significantly different on TLS 1.2 and 1.3. Also parameterized a few other test cases whose behavior significantly differs between the versions. Use session tickets in test connections. BoringSSL only supports session resumption using tickets in 1.3, and we want to have resumption functioning in our tests for the most part./Move libcore testing classes into testing (#607) When conscrypt was first separated from AOSP some of the AOSP libcore classes were copied into libcore-stub which is compiled against for both the openjdk and platform builds but only used at runtime by the openjdk builds. Unfortunately, those classes clash with internal classes provided by the Android runtime which will cause problems in future releases. This change moves those libcore-stub classes that are only used for testing from their libcore.... package into a org.conscrypt.... package to prevent clashes. It also moves them out of the libcore-stub module and into the testing module so they will be used on both platform and openjdk builds./"
,,0.4053,conscrypt,"Enable TLS 1.3 by default (#595) TLS 1.3 has seen successful rollouts in Chrome and Firefox, so were enabling it by default as well. We expect this to result in better security and performance. Detailed changes: Change the default TLS version to 1.3. Callers can still get connections that dont use TLS 1.3 by calling SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols() or SSLEngine.setEnabledProtocols(). Change to provide the TrustManager by default on OpenJDK. The TrustManager included in OpenJDK versions prior to 11 throws an exception if it encounters a TLS version higher than 1.2, so we need to provide a trust manager that will work with TLS 1.3. The Android trust manager (which is Conscrypt) will work fine, so dont provide ours there. Parameterize SSLSessionContextTest, since session behavior is significantly different on TLS 1.2 and 1.3. Also parameterized a few other test cases whose behavior significantly differs between the versions. Use session tickets in test connections. BoringSSL only supports session resumption using tickets in 1.3, and we want to have resumption functioning in our tests for the most part./"
,,0.32,conscrypt,"Move libcore testing classes into testing (#607) When conscrypt was first separated from AOSP some of the AOSP libcore classes were copied into libcore-stub which is compiled against for both the openjdk and platform builds but only used at runtime by the openjdk builds. Unfortunately, those classes clash with internal classes provided by the Android runtime which will cause problems in future releases. This change moves those libcore-stub classes that are only used for testing from their libcore.... package into a org.conscrypt.... package to prevent clashes. It also moves them out of the libcore-stub module and into the testing module so they will be used on both platform and openjdk builds./"
,,0.5327,conscrypt,"Enable TLS 1.3 by default (#595) TLS 1.3 has seen successful rollouts in Chrome and Firefox, so were enabling it by default as well. We expect this to result in better security and performance. Detailed changes: Change the default TLS version to 1.3. Callers can still get connections that dont use TLS 1.3 by calling SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols() or SSLEngine.setEnabledProtocols(). Change to provide the TrustManager by default on OpenJDK. The TrustManager included in OpenJDK versions prior to 11 throws an exception if it encounters a TLS version higher than 1.2, so we need to provide a trust manager that will work with TLS 1.3. The Android trust manager (which is Conscrypt) will work fine, so dont provide ours there. Parameterize SSLSessionContextTest, since session behavior is significantly different on TLS 1.2 and 1.3. Also parameterized a few other test cases whose behavior significantly differs between the versions. Use session tickets in test connections. BoringSSL only supports session resumption using tickets in 1.3, and we want to have resumption functioning in our tests for the most part./Move libcore testing classes into testing (#607) When conscrypt was first separated from AOSP some of the AOSP libcore classes were copied into libcore-stub which is compiled against for both the openjdk and platform builds but only used at runtime by the openjdk builds. Unfortunately, those classes clash with internal classes provided by the Android runtime which will cause problems in future releases. This change moves those libcore-stub classes that are only used for testing from their libcore.... package into a org.conscrypt.... package to prevent clashes. It also moves them out of the libcore-stub module and into the testing module so they will be used on both platform and openjdk builds./"
,,0.5273,conscrypt,"Enable TLS 1.3 by default (#595) TLS 1.3 has seen successful rollouts in Chrome and Firefox, so were enabling it by default as well. We expect this to result in better security and performance. Detailed changes: Change the default TLS version to 1.3. Callers can still get connections that dont use TLS 1.3 by calling SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols() or SSLEngine.setEnabledProtocols(). Change to provide the TrustManager by default on OpenJDK. The TrustManager included in OpenJDK versions prior to 11 throws an exception if it encounters a TLS version higher than 1.2, so we need to provide a trust manager that will work with TLS 1.3. The Android trust manager (which is Conscrypt) will work fine, so dont provide ours there. Parameterize SSLSessionContextTest, since session behavior is significantly different on TLS 1.2 and 1.3. Also parameterized a few other test cases whose behavior significantly differs between the versions. Use session tickets in test connections. BoringSSL only supports session resumption using tickets in 1.3, and we want to have resumption functioning in our tests for the most part./Move libcore testing classes into testing (#607) When conscrypt was first separated from AOSP some of the AOSP libcore classes were copied into libcore-stub which is compiled against for both the openjdk and platform builds but only used at runtime by the openjdk builds. Unfortunately, those classes clash with internal classes provided by the Android runtime which will cause problems in future releases. This change moves those libcore-stub classes that are only used for testing from their libcore.... package into a org.conscrypt.... package to prevent clashes. It also moves them out of the libcore-stub module and into the testing module so they will be used on both platform and openjdk builds./"
,,0.5925,conscrypt,"Enable TLS 1.3 by default (#595) TLS 1.3 has seen successful rollouts in Chrome and Firefox, so were enabling it by default as well. We expect this to result in better security and performance. Detailed changes: Change the default TLS version to 1.3. Callers can still get connections that dont use TLS 1.3 by calling SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols() or SSLEngine.setEnabledProtocols(). Change to provide the TrustManager by default on OpenJDK. The TrustManager included in OpenJDK versions prior to 11 throws an exception if it encounters a TLS version higher than 1.2, so we need to provide a trust manager that will work with TLS 1.3. The Android trust manager (which is Conscrypt) will work fine, so dont provide ours there. Parameterize SSLSessionContextTest, since session behavior is significantly different on TLS 1.2 and 1.3. Also parameterized a few other test cases whose behavior significantly differs between the versions. Use session tickets in test connections. BoringSSL only supports session resumption using tickets in 1.3, and we want to have resumption functioning in our tests for the most part./Move libcore testing classes into testing (#607) When conscrypt was first separated from AOSP some of the AOSP libcore classes were copied into libcore-stub which is compiled against for both the openjdk and platform builds but only used at runtime by the openjdk builds. Unfortunately, those classes clash with internal classes provided by the Android runtime which will cause problems in future releases. This change moves those libcore-stub classes that are only used for testing from their libcore.... package into a org.conscrypt.... package to prevent clashes. It also moves them out of the libcore-stub module and into the testing module so they will be used on both platform and openjdk builds./Clean up session handling (#594) The session passed to the SSLSessionBindingListener was always an ExternalSession, even when that session was wrapped to support ExtendedSSLSession, which meant that observers saw two different sessions. Refactor putValue() and removeValue() on ExternalSession to take the session so that the wrappers can provide themselves. Add a test for SSLSessionBindingListener calling. Slightly clean up ConscryptEngineSocket.getSession(). It doesnt need to do cache the session from before it tries to handshake, and doing so means that if you call getSession() twice in succession it might return different results for no good reason. Get rid of SSLNullSession.isNullSession, SSLUtils.unwrapSession, and SessionDecorator, since that entire chain was only used in ConscryptEngineSocket.getSession(). Fixes"
,,0.1274,conscrypt,"Update OID->name mapping code (#670) Add our own class for the standard OIDs. This should eliminate our reliance on the platform data for the vast majority of cases. Catch IllegalAccessError if thrown in OpenJDK, since java.base doesnt export AlgorithmId so under JPMS we might not have access to it. Fixes"
,,0.1274,conscrypt,"Update OID->name mapping code (#670) Add our own class for the standard OIDs. This should eliminate our reliance on the platform data for the vast majority of cases. Catch IllegalAccessError if thrown in OpenJDK, since java.base doesnt export AlgorithmId so under JPMS we might not have access to it. Fixes"
,,0.4004,conscrypt,"Move openjdk-integ-tests to common (#720) The tests in openjdk-integ-tests havent matched their name in a while: they test Conscrypt-specific features in places, we run them on platforms other than OpenJDK, and theyre a combination of integration, unit, and regression tests. To ease confusion, move them into common alongside other common tests. Their package names (eg, org.conscrypt.java.security) will still indicate that theyre testing the overall interface rather than Conscrypt-specific classes, but it should be more clear that theyre just part of the overall testing scheme of Conscrypt on all platforms. As part of this, remove the architecture-specific test rules in openjdk and only test on the preferred architecture. The additional test classes increase the running time of the test rule to multiple minutes, and neither the new nor the old tests are obviously architecture-sensitive. In the rare case where its desired to test on multiple architectures, we can run the test rule twice in different configurations. We also change the existing OpenJDK tests to run in a suite that installs Conscrypt before running. This works better with the new tests and makes the tests not need to manage provider installation themselves. As part of this, also remove calls to TestUtils methods that need the Conscrypt provider to be installed during static initialization; during static initialization, the provider isnt installed and having those calls makes TLS tests fail on OpenJDK 11./"
,,0.4784,conscrypt,"Move openjdk-integ-tests to common (#720) The tests in openjdk-integ-tests havent matched their name in a while: they test Conscrypt-specific features in places, we run them on platforms other than OpenJDK, and theyre a combination of integration, unit, and regression tests. To ease confusion, move them into common alongside other common tests. Their package names (eg, org.conscrypt.java.security) will still indicate that theyre testing the overall interface rather than Conscrypt-specific classes, but it should be more clear that theyre just part of the overall testing scheme of Conscrypt on all platforms. As part of this, remove the architecture-specific test rules in openjdk and only test on the preferred architecture. The additional test classes increase the running time of the test rule to multiple minutes, and neither the new nor the old tests are obviously architecture-sensitive. In the rare case where its desired to test on multiple architectures, we can run the test rule twice in different configurations. We also change the existing OpenJDK tests to run in a suite that installs Conscrypt before running. This works better with the new tests and makes the tests not need to manage provider installation themselves. As part of this, also remove calls to TestUtils methods that need the Conscrypt provider to be installed during static initialization; during static initialization, the provider isnt installed and having those calls makes TLS tests fail on OpenJDK 11./Fix ConscryptEngine state machine (#687) The SSLEngine state machine is slightly more complicated than our previous code presumed. After closeInbound() or closeOutbound() are called, isInboundDone() and isOutboundDone() shouldnt immediately return true. Rather, closeInbound() and closeOutbound() indicate the callers intention to never supply any more input data in the given direction, but isInboundDone() and isOutboundDone() indicate that no more output data in the given direction will be produced. This means those methods need to be adjusted to take into account the state of internal plaintext/ciphertext buffers. This simplifies and corrects some of the other code as well. In particular, we no longer have to stash exceptions that are thrown during the handshake, because the caller is expected to see those exceptions and drain the outgoing buffer (which previously they had no way of doing). Fixes"
,,0.4011,conscrypt,"Move openjdk-integ-tests to common (#720) The tests in openjdk-integ-tests havent matched their name in a while: they test Conscrypt-specific features in places, we run them on platforms other than OpenJDK, and theyre a combination of integration, unit, and regression tests. To ease confusion, move them into common alongside other common tests. Their package names (eg, org.conscrypt.java.security) will still indicate that theyre testing the overall interface rather than Conscrypt-specific classes, but it should be more clear that theyre just part of the overall testing scheme of Conscrypt on all platforms. As part of this, remove the architecture-specific test rules in openjdk and only test on the preferred architecture. The additional test classes increase the running time of the test rule to multiple minutes, and neither the new nor the old tests are obviously architecture-sensitive. In the rare case where its desired to test on multiple architectures, we can run the test rule twice in different configurations. We also change the existing OpenJDK tests to run in a suite that installs Conscrypt before running. This works better with the new tests and makes the tests not need to manage provider installation themselves. As part of this, also remove calls to TestUtils methods that need the Conscrypt provider to be installed during static initialization; during static initialization, the provider isnt installed and having those calls makes TLS tests fail on OpenJDK 11./"
,,0.4057,conscrypt,"Move openjdk-integ-tests to common (#720) The tests in openjdk-integ-tests havent matched their name in a while: they test Conscrypt-specific features in places, we run them on platforms other than OpenJDK, and theyre a combination of integration, unit, and regression tests. To ease confusion, move them into common alongside other common tests. Their package names (eg, org.conscrypt.java.security) will still indicate that theyre testing the overall interface rather than Conscrypt-specific classes, but it should be more clear that theyre just part of the overall testing scheme of Conscrypt on all platforms. As part of this, remove the architecture-specific test rules in openjdk and only test on the preferred architecture. The additional test classes increase the running time of the test rule to multiple minutes, and neither the new nor the old tests are obviously architecture-sensitive. In the rare case where its desired to test on multiple architectures, we can run the test rule twice in different configurations. We also change the existing OpenJDK tests to run in a suite that installs Conscrypt before running. This works better with the new tests and makes the tests not need to manage provider installation themselves. As part of this, also remove calls to TestUtils methods that need the Conscrypt provider to be installed during static initialization; during static initialization, the provider isnt installed and having those calls makes TLS tests fail on OpenJDK 11./"
,,0.2599,conscrypt,"Fix engine socket tests (#707) The engine test system property was being overwritten, which resulted in the engine socket test not actually being executed with the engine socket. This fixes that problem, so :testEngineSocket now actually runs with the engine socket. This revealed several test failures that were all due to the engine and engine socket closing behavior. In particular, the engine wouldnt mark itself as closed when an SSLException was thrown, which it is supposed to per the documentation. This meant that when the engine socket attempted to flush the outgoing buffer, it would just trigger whatever exception had originally caused the problem again, the outgoing buffer wouldnt get flushed, and alerts wouldnt reach the peer. Closing the engine whenever an exception propagates out fixes this problem, along with tolerating a CLOSED status return in the engine socket./Fix implementation of available() in sockets (#694) The file descriptor socket used the default implementation of available(), which just always returns 0. We can at least return the pending bytes in the plaintext buffer, since those are definitely available. The engine socket had two issues. First, it used fromSocket.remaining(), but fromSocket was in a writing posture, so it always had a high return from remaining() regardless of whether there was pending readable data in the buffer. This was the cause of a BufferedReader would read some data, then check available() to see if it could freely fill some more data without blocking. The engine socket would report that it could, so it would try to read that data and then unexpectedly block. The second issue is that incoming socket data doesnt necessarily imply readable plaintext data: it might be a partial TLS record, a handshake or other management record, etc. So we should only report plaintext data thats actually been successfully decrypted from available(). Fixes ConscryptEngine state machine (#687) The SSLEngine state machine is slightly more complicated than our previous code presumed. After closeInbound() or closeOutbound() are called, isInboundDone() and isOutboundDone() shouldnt immediately return true. Rather, closeInbound() and closeOutbound() indicate the callers intention to never supply any more input data in the given direction, but isInboundDone() and isOutboundDone() indicate that no more output data in the given direction will be produced. This means those methods need to be adjusted to take into account the state of internal plaintext/ciphertext buffers. This simplifies and corrects some of the other code as well. In particular, we no longer have to stash exceptions that are thrown during the handshake, because the caller is expected to see those exceptions and drain the outgoing buffer (which previously they had no way of doing). Fixes"
,,0.2456,conscrypt,"Ignore RuntimeExceptions thrown in CryptoUpcalls (#684) Signatures provider selection code ignores RuntimeExceptions thrown during init and continues to test providers to see if a lower priority provider will be successful, whereas we previously allowed RuntimeExceptions to propagate out of our provider selection code. Follow Signatures lead and catch RuntimeExceptions. The motivation for this change is a problem on Android versions up to L where Android Keystore opaque keys are used in signing operations. They appear to be valid EC keys, but throw UnsupportedOperationException when their key material is accessed, which causes Conscrypts delegate selection code to explode. Instead now we will catch the RuntimeException and continue to test providers until one is found that can use the key. As part of this, move OpaqueProvider to testing infrastructure and add a BrokenProvider that just explodes on everything. Fixes"
,,0.3041,conscrypt,"Fix ConscryptEngine state machine (#687) The SSLEngine state machine is slightly more complicated than our previous code presumed. After closeInbound() or closeOutbound() are called, isInboundDone() and isOutboundDone() shouldnt immediately return true. Rather, closeInbound() and closeOutbound() indicate the callers intention to never supply any more input data in the given direction, but isInboundDone() and isOutboundDone() indicate that no more output data in the given direction will be produced. This means those methods need to be adjusted to take into account the state of internal plaintext/ciphertext buffers. This simplifies and corrects some of the other code as well. In particular, we no longer have to stash exceptions that are thrown during the handshake, because the caller is expected to see those exceptions and drain the outgoing buffer (which previously they had no way of doing). Fixes"
,,0.2591,conscrypt,"Minor cleanup (#688) Clean up some unused variable and method ErrorProne warnings. Eliminate debug logging from NativeLibraryLoader in tests./Fix ConscryptEngine state machine (#687) The SSLEngine state machine is slightly more complicated than our previous code presumed. After closeInbound() or closeOutbound() are called, isInboundDone() and isOutboundDone() shouldnt immediately return true. Rather, closeInbound() and closeOutbound() indicate the callers intention to never supply any more input data in the given direction, but isInboundDone() and isOutboundDone() indicate that no more output data in the given direction will be produced. This means those methods need to be adjusted to take into account the state of internal plaintext/ciphertext buffers. This simplifies and corrects some of the other code as well. In particular, we no longer have to stash exceptions that are thrown during the handshake, because the caller is expected to see those exceptions and drain the outgoing buffer (which previously they had no way of doing). Fixes"
,,0.1012,frostwire,"[common] Fixed SC search result size (of by x1000), thanks Fixed SC search result size/[android] checkboxs work. finished breaking dependency on SearchResult for ConfirmListDialog./[android] checkboxs work. finished breaking dependency on SearchResult for ConfirmListDialog./"
,,0.0854,frostwire,[android] Killed Screen Rotation lock feature Fragmentation seems to be a problem when it comes to reporting the right orientation of the device at the right moment./[android] bug fix replacing toolbar view width layout parameter/[android] better control of toolbar custom view gravity and fixed visibility issue/
,,0.0954,frostwire,[android] avoid possible ANR installing HttpResponseCache The installation of the HttpResponseCache when a secondary storage is being mounted can be a costly operation on the main thread once SystemUtils.getCacheDir() gets called which can be slow once it hits ContextWrapper.getExternalCacheDir()/
,,0.0677,frostwire,[common] OKHTTPClient.prepareRequestBuilder() better report header encoding issues/
,,0.1462,frostwire,"[android] Issue revert last commit, refactor, copy list before submitting to thread/[android] issue ConcurrentModificationException fix KeywordDetector.feedSearchResults() triggers a ConcurrentModificationException while trying to make a copy of these filtered search results, copy which was done in the first place to avoid ConcurrentModificationException, however, while the copy constructor is called, the ArrayLists could be modified it seems. Online discussions recommend using CopyOnWriteArrayList since it makes an underlying copy of the elements on any mutation operation/"
,,0.073,frostwire,[android] dont deliver results if data is null (NPE fix attempt
,,0.0758,frostwire,[desktop] Bug fix in playlist rendering Playlist rendering would cut off if a track had no track number. cleanup./
,,0.0778,frostwire,[desktop] Bug fix in playlist rendering Playlist rendering would cut off if a track had no track number. cleanup./
,,0.0778,frostwire,[desktop] Bug fix in playlist rendering Playlist rendering would cut off if a track had no track number. cleanup./
,,0.0717,frostwire,[desktop] Bug fix in playlist rendering Playlist rendering would cut off if a track had no track number. cleanup./
,,0.0661,frostwire,"[common] Archive.org, fixed stream only results and save path/"
,,0.0628,frostwire,[android] try to fix context leak related to mopub promotions view destroy/
,,0.0652,frostwire,[common] keyword search encoding bug fix/
,,0.0918,javacpp,"* By default, `Builder` now links to the `jvm` library only when required, when using the `-header` command line option (issue * Fixed duplicate code getting generated when both specifying the output filename with ""-o and using wildcards on packages containing nested classes/"
,,0.1355,javacpp,"* Fix a few more small issues with the `Parser` and the `Generator`/ * Add `SharedPtrAdapter` and corresponding annotation to support `shared_ptr` containers * Fix a few small issues with the `Parser` and the `Generator`/ * Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.142,javacpp,"* Add `SharedPtrAdapter` and corresponding annotation to support `shared_ptr` containers * Fix a few small issues with the `Parser` and the `Generator`/ * Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1319,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1339,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.1319,javacpp,"* Append to annotation types to have them picked up by Javadoc * Fix `friend` functions not getting skipped by the `Parser` * Add `Info` for `__int8`, `__int16`, `__int32`, and `__int64` to `InfoMap.defaults`/"
,,0.0849,javacpp,Fix up functionality for `Info.flatten`/
,,0.1044,javacpp,"* Include new `platform.compiler.debug` options inside the default properties file (pull * Always use the `platform.compiler.default` options unless ...)` is specified * Move optimization options from `platform.compiler.output` to `platform.compiler.default`, allowing users to override/"
,,0.0717,javacpp,* Fix `Builder` not processing all classes when given `.**` as input (issue bytedeco/javacv#1311)/
,,0.0758,jna,fix bug with aliasing buffers in Memory ByteBuffer tracking/
,,0.0712,jna,clean up platform tests and error handling on windows/fix javadoc warnings/
,,0.0648,jna,GetProcessTimes and GetProcessIoCounters (#959) * GetProcessTimes and GetProcessIoCounters * Fix unit test ticks calculation/
,,0.0778,jna,clean up platform tests and error handling on windows/
,,0.0717,jna,clean up platform tests and error handling on windows/
,,0.075,jna,remove debug output/avoid negative interactions with system install of JNA/
,,0.1064,jna,"Merge pull request from aschnab/master Cleanup of temporarily extracted files in case of errors. Thanks for the contribution, that temporary library files extracted from resource path are cleaned up, even in case something goes wrong while actually opening the library. Added test for cleanup of extracted files on loading errors. Documented cleanup of extracted files on loading errors in CHANGES./"
,,0.0915,jna,Add arm softfloat variant as platform armel add prebuild arm softfloat binaries add option to override prefix detection by specifying jna.prefix add prefix autodetection to platform code. Autodetection is based on the JVM image adjust build.xml to implement prefix detection Closes:
,,0.1271,jna,"Merge pull request from aschnab/master Cleanup of temporarily extracted files in case of errors. Thanks for the contribution, that temporary library files extracted from resource path are cleaned up, even in case something goes wrong while actually opening the library. Added test for cleanup of extracted files on loading errors. Documented cleanup of extracted files on loading errors in CHANGES./fix sporadically failing test on OSX/"
,,0.0921,jna,"Merge pull request from matthiasblaesing/unittest_W32APIMapperTest Fix W32APIMapperTest failing on non-CP1252 encodings/Fix W32APIMapperTest failing on non-CP1252 encodings The choosen character \u0444 (CYRILLIC SMALL LETTER EF) is not present in all CP* charsets. This change switches to \u203a SINGLE RIGHT-POINTING ANGLE QUOTATION MARK: õ, which was found to be present in CP1250-CP1258. Closes:"
,,0.1091,jna,"Changing Class<T> to Class<T extends Library> for Native.loadLibrary It was possible to pass a non-library class into this method and get a runtime exception, when the same check can be done at compile-time, so this fix changes it to be done at compile-time. After erasure, with this change the return type changes from `Object` to `Library`. So as far as backwards compatibility: 1. If you were assigning the result to `Object`, that will still work 2. If you were passing something that wasnt a `Class<? extends Library>`, your code will now not compile, instead of failing at runtime. 3. I cant remember the rules for binary compatibility. Fixes"
,,0.0811,jna,"make unpacked path available as a system property, track down JVM error in System.load/fix broken test on XP/"
,,0.0609,jna,last error now always preserved/
,,0.0665,jna,use correct type mapper for SERVICE_FAILURE_ACTIONS/implemented failure configuration of windows services/
,,0.0648,jna,GetProcessTimes and GetProcessIoCounters (#959) * GetProcessTimes and GetProcessIoCounters * Fix unit test ticks calculation/
,,0.0657,jna,clean up platform tests and error handling on windows/
,,0.0782,jna,clean up platform tests and error handling on windows/fix javadoc warning/add CoInit constants fix last error formatting/
,,0.0778,jna,clean up platform tests and error handling on windows/
,,0.0848,jna,fix WORDByReference definition/clean up platform tests and error handling on windows/
,,0.1401,jna,"Use correct bit masks when extracting low/high word from DWORD This is a regression introduced by commit 4218a075499f3937c1bfa3cf28ea967be2ca2530 The applied bit masks a 8 bit value, while word is 16 bit sized. Closes:"
,,0.0859,jna,clean up platform tests and error handling on windows/
,,0.0697,jna,clean up platform tests and error handling on windows/
,,0.0719,jna,Merge pull request from lwahonen/master Small COM fixes/Use read-only access for enumerating classes to prevent access denied bugs/
,,0.11199999999999999,jna,Merge pull request from lwahonen/upstream Fix SUCCEEDED and FAILED instead of trying to fix the bug where its vis.../Fix SUCCEEDED and FAILED instead of trying to fix the bug where its visible. See MSDN for FAILED and SUCCEEDED definitions Changes/
,,0.0636,jna,clean up platform tests and error handling on windows/
,,0.09699999999999999,jna,clean up platform tests and error handling on windows/add CoInit constants fix last error formatting/
,,0.0717,jna,clean up platform tests and error handling on windows/
,,0.0717,jna,clean up platform tests and error handling on windows/
,,0.0717,jna,clean up platform tests and error handling on windows/
,,0.0737,jna,clean up platform tests and error handling on windows/
,,0.0778,jna,clean up platform tests and error handling on windows/
,,0.0758,jna,clean up platform tests and error handling on windows/
,,0.0706,jna,"Merge pull request from lwahonen/fix_most_com_tests Fix most com tests/Fix 17/19 tests, ignore the last 2/Removed not implemented due to complexity failures./"
,,0.12300000000000001,jna,Merge pull request from lwahonen/upstream Fix SUCCEEDED and FAILED instead of trying to fix the bug where its vis.../Fix SUCCEEDED and FAILED instead of trying to fix the bug where its visible. See MSDN for FAILED and SUCCEEDED definitions Changes/
,,0.1067,jna,"Merge pull request from matthiasblaesing/combindingbaseobject_exceptionhandling Exception from COMBindingBaseObject swallows real reason + HRESULT/Exception from COMBindingBaseObject swallows real reason + HRESULT The exception thrown from COMBindingBaseObject when instatiation fails is misleading: COM object with CLSID {0002DF01-0000-0000-C000-000000000046} not registered properly In the concrete case COM was not properly initialized, the same error now reports (in german locale): CoInitialize wurde nicht aufgerufen.(HRESULT: 800401f0) (puArgErr=) For english locale this should be along the lines of: CoInitialize was not called.(HRESULT: 800401f0) (puArgErr=) The message now points out the correct problem (as far as the windows error code translation works) and the HRESULT can be used for a locale independend report + search. Closes"
,,0.0983,jna,Add arm softfloat variant as platform armel add prebuild arm softfloat binaries add option to override prefix detection by specifying jna.prefix add prefix autodetection to platform code. Autodetection is based on the JVM image adjust build.xml to implement prefix detection Closes:
,,0.0685,jna,Fixes broken platform tests broken on OSX/
,,0.0842,jna,"Merge pull request from matthiasblaesing/fix_windows Fix build/test errors on Windows/Fix W32Service test The classloader structure of java was changed with JDK 9. The requirement for this case is, that the locations for the JNA and JNA platform jars can be determined. Instead of relying on the classloader, use the ProtectionDomain as basis./"
,,0.071,OpenDDS,Reverting failed attempt at 1.1 release/
,,0.0792,OpenDDS,"Fixed fuzz, attempted to fix errors on clang and older GCC versions./"
,,0.0669,OpenDDS,"Fixed fuzz, attempted to fix errors on clang and older GCC versions./"
,,0.1104,OpenDDS,"TS API Update: Get_Connection_Parameters() Treat name and ID as both optional. If not provided, fill in, if both provided, validate, if neither provided, error. Connection_Id is only out param if specified as 0 otherwise will assume connection id has been specified. Updated Messenger tests get connection params validation section with a couple additional scenarios to test new functionality./"
,,0.0838,OpenDDS,Add processing of timeout in send_message to report an error if less than a reliable writers max_blocking_time as well as add cases to Reliability test to verify success/error combinations/
,,0.0897,OpenDDS,Merge remote branch upstream/master into face-conf-test-suite Conflicts: dds/CORBA/tao/BasicSequences.cpp dds/CORBA/tao/ORB_Misc.cpp dds/CORBA/tao/OctetSeqC.cpp dds/CORBA/tao/SystemException.cpp/Fixed allocation bug in Dynamic_*. Disabled non-built tests. Initialized variables in ParameterListConverter test./
,,0.0586,OpenDDS,Merge pull request from objectcomputing/ipv6_updates Fix issues with IPV6 enabled builds on Windows./
,,0.0607,OpenDDS,Merge pull request from objectcomputing/ipv6_updates Fix issues with IPV6 enabled builds on Windows./
,,0.0586,OpenDDS,Merge pull request from objectcomputing/ipv6_updates Fix issues with IPV6 enabled builds on Windows./
,,0.0648,OpenDDS,Merge pull request from objectcomputing/ipv6_updates Fix issues with IPV6 enabled builds on Windows./
,,0.1121,OpenDDS,MSVC14 support requires workaround to avoid compiler-generated copy ctor and assignment for a few classes/
,,0.11199999999999999,OpenDDS,Merge pull request from mitza-oci/master Removed workarounds for GCC 3.3.x bugs./Removed workarounds for GCC 3.3.x bugs./MSVC14 support requires workaround to avoid compiler-generated copy ctor and assignment for a few classes/
,,0.1068,OpenDDS,Merge pull request from mitza-oci/master Warnings fixes for SunCC./Warnings fixes for SunCC./MSVC14 support requires workaround to avoid compiler-generated copy ctor and assignment for a few classes/
,,0.1216,OpenDDS,Remove the DataReaderRemoteImpls reference back to the DataReaderImpl (parent) prior to notifying the orb so that asynchronous add_association calls do not still see the DataReaderImpl and access it after it has gone away. Provide try/catch blocks around calls from InfoRepoDiscovery which could not result in a thrown exception if the orb object has been disabled already by the remove operation/
,,0.1135,OpenDDS,Remove the DataReaderRemoteImpls reference back to the DataReaderImpl (parent) prior to notifying the orb so that asynchronous add_association calls do not still see the DataReaderImpl and access it after it has gone away. Provide try/catch blocks around calls from InfoRepoDiscovery which could not result in a thrown exception if the orb object has been disabled already by the remove operation/
,,0.1216,OpenDDS,Remove the DataReaderRemoteImpls reference back to the DataReaderImpl (parent) prior to notifying the orb so that asynchronous add_association calls do not still see the DataReaderImpl and access it after it has gone away. Provide try/catch blocks around calls from InfoRepoDiscovery which could not result in a thrown exception if the orb object has been disabled already by the remove operation/
,,0.1184,OpenDDS,Remove the DataReaderRemoteImpls reference back to the DataReaderImpl (parent) prior to notifying the orb so that asynchronous add_association calls do not still see the DataReaderImpl and access it after it has gone away. Provide try/catch blocks around calls from InfoRepoDiscovery which could not result in a thrown exception if the orb object has been disabled already by the remove operation/
,,0.062,OpenDDS,"Introduce a new Loaner interface which is now used as part of the zero copy sequences so that they dont pull in the full reader implementation, see issue * dds/DCPS/Loaner.h: Added. * dds/DCPS/DataReaderImpl.h: * dds/DCPS/MultiTopicDataReaderBase.h: * dds/DCPS/WriterInfo.h: * dds/DCPS/ZeroCopySeq_T.h: * dds/DCPS/ZeroCopySeq_T.inl:/"
,,0.1193,OpenDDS,Merge branch master of into jwi-gendirbug/Merge pull request from huangminghuang/DataSampleElement_fix Fix memory access problem for the copy constructor of DataSampleElement/Fix memory access problem for the copy constructor of DataSampleElement/Fix SubscriptionInstance/PublicationInstance being accessed by watchdogs after deletion/
,,0.1206,OpenDDS,"Fix Liveliness Qos bug where the liveliness check interval timer is not reset/adjusted to account for liveliness activity occurring during a partial interval, and thus liveliness was lost earlier than it should have been. Remove unnecessary last_liveliness_check_time as well as initial delta calculation/check/reschedule as it is taken care of by second check and should not be occurring at all since the reactor should handle the timer properly./Fix SubscriptionInstance/PublicationInstance being accessed by watchdogs after deletion/Merge pull request from jwillemsen/master Minor typo and doxygen fixes/Merge pull request from huangminghuang/transport_client_fix Fix DataWriterImpl accessed after deletion bug/Fix DataWriterImpl accessed after deletion bug/Fix DataWriterImpl accessed after deletion bug/Fix DataWriterImpl accessed after deletion bug/"
,,0.1144,OpenDDS,"Fix Liveliness Qos bug where the liveliness check interval timer is not reset/adjusted to account for liveliness activity occurring during a partial interval, and thus liveliness was lost earlier than it should have been. Remove unnecessary last_liveliness_check_time as well as initial delta calculation/check/reschedule as it is taken care of by second check and should not be occurring at all since the reactor should handle the timer properly./Fix SubscriptionInstance/PublicationInstance being accessed by watchdogs after deletion/Merge pull request from huangminghuang/transport_client_fix Fix DataWriterImpl accessed after deletion bug/Fix DataWriterImpl accessed after deletion bug/Fix DataWriterImpl accessed after deletion bug/Fix DataWriterImpl accessed after deletion bug/"
,,0.1053,OpenDDS,Merge branch jwi-gendirbug/Merge pull request from mitza-oci/issue460-multidim Fix for issue multi-dimensional arrays of primitive types./Fix for issue multi-dimensional arrays of primitive types. Need to dereference the higher dimensional array to treat it as linear./
,,0.0686,OpenDDS,Fixed typo * dds/DCPS/SubscriberImpl.cpp:/
,,0.0849,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./
,,0.1255,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Addressing Coverity Scan reported defect of uninitialized members./
,,0.1182,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Adding checks after dynamic_cast to address coverity defect reports./
,,0.0949,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./According to the DDS specification get_key_value should return RETCODE_BAD_PARAMETER at the moment an unknown handle is passed. This fixes issue * dds/DCPS/DataReaderImpl_T.h: * dds/DCPS/DataWriterImpl_T.h: * tests/DCPS/FooTest3_0/PubDriver.cpp: * tests/DCPS/FooTest4/Reader.cpp: * tests/DCPS/MultiTopic/MultiTopicTest.cpp:/
,,0.2148,OpenDDS,"Some more fixes for safety * tests/DCPS/Serializer/SerializerTest.cpp:/Implemented std::(w)string insertion and extraction for the Serializer. Serializer.h has to include Definitions.h to get the correct setting of DDS_HAS_WCHAR but this lead to a cyclic include, moved SequenceNumber out of Definitions.h to break this. Updated some other files to include the new SequenceNumber.h. This implements issue * dds/DCPS/SequenceNumber.h: Added. * dds/DCPS/CoherentChangeControl.h: * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DisjointSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/Serializer.inl: * dds/DCPS/transport/framework/TransportHeader.h: * dds/DCPS/transport/framework/TransportQueueElement.h: * dds/DCPS/transport/rtps_udp/RtpsTransportHeader.h: * tests/DCPS/Serializer/SerializerTest.cpp:/Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Addressing Coverity Scan reported defect of division by zero./"
,,0.0833,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Merge branch master into jwi-endhistorysampleleak/Dont call close on a file that failed to open./
,,0.0833,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Merge branch master into jwi-endhistorysampleleak/
,,0.114,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Fuzz fixes./Adding checks after dynamic_cast to address coverity defect reports./
,,0.1121,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Merge branch master into jwi-endhistorysampleleak/Adding checks after dynamic_cast to address coverity defect reports./
,,0.0849,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./
,,0.1182,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Adding checks after dynamic_cast to address coverity defect reports./
,,0.0804,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Fix build issue/Merge branch master into jwi-endhistorysampleleak/
,,0.0849,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./
,,0.1182,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Adding checks after dynamic_cast to address coverity defect reports./
,,0.1162,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Adding checks after dynamic_cast to address coverity defect reports./
,,0.1182,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Adding checks after dynamic_cast to address coverity defect reports./
,,0.0849,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./
,,0.1658,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Merge branch master into jwi-endhistorysampleleak/Use RestoreOutputStreamState helper class to address Coverity Scan reported defects of not restoring ostream format./Addressing Coverity Scan reported defect of not restoring ostream format./
,,0.1335,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Merge branch master into jwi-endhistorysampleleak/Use RestoreOutputStreamState helper class to address Coverity Scan reported defects of not restoring ostream format./Merge pull request from mitza-oci/tests-coverity-bugs Fixed Coverity-reported issues in tests/According to the DDS specification get_key_value should return RETCODE_BAD_PARAMETER at the moment an unknown handle is passed. This fixes issue * dds/DCPS/DataReaderImpl_T.h: * dds/DCPS/DataWriterImpl_T.h: * tests/DCPS/FooTest3_0/PubDriver.cpp: * tests/DCPS/FooTest4/Reader.cpp: * tests/DCPS/MultiTopic/MultiTopicTest.cpp:/
,,0.0849,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./
,,0.1347,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Addressing Coverity Scan reported defect of uncaught exception of DATA_CONVERSION./
,,0.0946,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Fix braces for style./Addressing Coverity Scan Report Defects: Untrusted loop bound due to tainted data./
,,0.1335,OpenDDS,"Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Addressing Coverity Scan Report Defect. Initialize max_msg_size to 0, it should get set from the topic when create connection is called./"
,,0.1182,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Adding checks after dynamic_cast to address coverity defect reports./
,,0.0849,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./
,,0.1182,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Adding checks after dynamic_cast to address coverity defect reports./
,,0.1182,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Adding checks after dynamic_cast to address coverity defect reports./
,,0.1182,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Adding checks after dynamic_cast to address coverity defect reports./
,,0.1182,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Adding checks after dynamic_cast to address coverity defect reports./
,,0.1174,OpenDDS,"Merge branch master into jwi-endhistorysampleleak/Merge pull request from huangminghuang/master Fix RemoveAssociationSweeper failed to remove association problem/Fix RemoveAssociationSweeper failed to remove association problem/Merge pull request from jwillemsen/jwi-grouppresentation Fix GroupPresentation test failures by reverting a small part of the change of PR initialized_ flag, was only used to check if some points need to be deleted, but at the moment we havent allocated them they are zero which is not a problem when calling delete on them * dds/DCPS/DataReaderImpl.cpp: * dds/DCPS/DataReaderImpl.h: * dds/DCPS/DataWriterImpl.cpp: * dds/DCPS/DataWriterImpl.h: * dds/DCPS/ReplayerImpl.h:/Revert part of PR testing whether this solves the hang on windows * dds/DCPS/DataReaderImpl.cpp: * dds/DCPS/DataReaderImpl.h: * dds/DCPS/SubscriberImpl.cpp: * dds/DCPS/SubscriberImpl.h:/"
,,0.0959,OpenDDS,"Removed initialized_ flag, was only used to check if some points need to be deleted, but at the moment we havent allocated them they are zero which is not a problem when calling delete on them * dds/DCPS/DataReaderImpl.cpp: * dds/DCPS/DataReaderImpl.h: * dds/DCPS/DataWriterImpl.cpp: * dds/DCPS/DataWriterImpl.h: * dds/DCPS/ReplayerImpl.h:/"
,,0.1182,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Adding checks after dynamic_cast to address coverity defect reports./
,,0.1584,OpenDDS,"Implemented std::(w)string insertion and extraction for the Serializer. Serializer.h has to include Definitions.h to get the correct setting of DDS_HAS_WCHAR but this lead to a cyclic include, moved SequenceNumber out of Definitions.h to break this. Updated some other files to include the new SequenceNumber.h. This implements issue * dds/DCPS/SequenceNumber.h: Added. * dds/DCPS/CoherentChangeControl.h: * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DisjointSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/Serializer.inl: * dds/DCPS/transport/framework/TransportHeader.h: * dds/DCPS/transport/framework/TransportQueueElement.h: * dds/DCPS/transport/rtps_udp/RtpsTransportHeader.h: * tests/DCPS/Serializer/SerializerTest.cpp:/"
,,0.1539,OpenDDS,"Implemented std::(w)string insertion and extraction for the Serializer. Serializer.h has to include Definitions.h to get the correct setting of DDS_HAS_WCHAR but this lead to a cyclic include, moved SequenceNumber out of Definitions.h to break this. Updated some other files to include the new SequenceNumber.h. This implements issue * dds/DCPS/SequenceNumber.h: Added. * dds/DCPS/CoherentChangeControl.h: * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DisjointSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/Serializer.inl: * dds/DCPS/transport/framework/TransportHeader.h: * dds/DCPS/transport/framework/TransportQueueElement.h: * dds/DCPS/transport/rtps_udp/RtpsTransportHeader.h: * tests/DCPS/Serializer/SerializerTest.cpp:/"
,,0.11900000000000001,OpenDDS,Moved RepoIdTypes to its own header to break another cyclic include which now happens in the case of safety profile * dds/DCPS/RepoIdTypes.h: Added. * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DiscoveryListener.h: * dds/DCPS/InstanceState.h: * dds/DCPS/PublicationInstance.h: * dds/DCPS/Recorder.h: * dds/DCPS/Replayer.h: * dds/DCPS/SafetyProfileSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/transport/framework/TransportSendListener.h: * dds/FACE/FaceTSS.h:/
,,0.0849,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./
,,0.0849,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./
,,0.0849,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./
,,0.1644,OpenDDS,"Implemented std::(w)string insertion and extraction for the Serializer. Serializer.h has to include Definitions.h to get the correct setting of DDS_HAS_WCHAR but this lead to a cyclic include, moved SequenceNumber out of Definitions.h to break this. Updated some other files to include the new SequenceNumber.h. This implements issue * dds/DCPS/SequenceNumber.h: Added. * dds/DCPS/CoherentChangeControl.h: * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DisjointSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/Serializer.inl: * dds/DCPS/transport/framework/TransportHeader.h: * dds/DCPS/transport/framework/TransportQueueElement.h: * dds/DCPS/transport/rtps_udp/RtpsTransportHeader.h: * tests/DCPS/Serializer/SerializerTest.cpp:/"
,,0.1155,OpenDDS,Moved RepoIdTypes to its own header to break another cyclic include which now happens in the case of safety profile * dds/DCPS/RepoIdTypes.h: Added. * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DiscoveryListener.h: * dds/DCPS/InstanceState.h: * dds/DCPS/PublicationInstance.h: * dds/DCPS/Recorder.h: * dds/DCPS/Replayer.h: * dds/DCPS/SafetyProfileSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/transport/framework/TransportSendListener.h: * dds/FACE/FaceTSS.h:/
,,0.0841,OpenDDS,"Revert the fix for the moment, need a different solution. * dds/DCPS/DataReaderImpl_T.h: * tests/DCPS/FooTest3_0/DataReaderQCListener.cpp:/Revert the fix for the moment, need a different solution. * dds/DCPS/DataReaderImpl_T.h: * tests/DCPS/FooTest3_0/DataReaderQCListener.cpp:/Merge pull request from jwillemsen/jwi-docutypos Fixed some typos in comments/According to the DDS specification get_key_value should return RETCODE_BAD_PARAMETER at the moment an unknown handle is passed. This fixes issue * dds/DCPS/DataReaderImpl_T.h: * dds/DCPS/DataWriterImpl_T.h: * tests/DCPS/FooTest3_0/PubDriver.cpp: * tests/DCPS/FooTest4/Reader.cpp: * tests/DCPS/MultiTopic/MultiTopicTest.cpp:/Reset total_count_change to zero after we called a listener, fixed typo in method name * dds/DCPS/DataReaderImpl_T.h: * dds/DCPS/DataWriterImpl.cpp:/Fixed fuzz * dds/DCPS/DataReaderImpl_T.h:/Fixed fuzz * dds/DCPS/DataReaderImpl_T.h:/Fixed some typos in comments * dds/DCPS/DataReaderImpl_T.h: * dds/DCPS/InstanceState.inl:/"
,,0.1582,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Adding checks after dynamic_cast to address coverity defect reports./Merge pull request from jwillemsen/jwi-grouppresentation Fix GroupPresentation test failures by reverting a small part of the change of PR part of PR testing whether this solves the hang on windows * dds/DCPS/DataReaderImpl.cpp: * dds/DCPS/DataReaderImpl.h: * dds/DCPS/SubscriberImpl.cpp: * dds/DCPS/SubscriberImpl.h:/Fixed log format specifier for size_t * dds/DCPS/PublisherImpl.cpp: * dds/DCPS/SubscriberImpl.cpp:/
,,0.1182,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Adding checks after dynamic_cast to address coverity defect reports./
,,0.1182,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Adding checks after dynamic_cast to address coverity defect reports./
,,0.1704,OpenDDS,"Implemented std::(w)string insertion and extraction for the Serializer. Serializer.h has to include Definitions.h to get the correct setting of DDS_HAS_WCHAR but this lead to a cyclic include, moved SequenceNumber out of Definitions.h to break this. Updated some other files to include the new SequenceNumber.h. This implements issue * dds/DCPS/SequenceNumber.h: Added. * dds/DCPS/CoherentChangeControl.h: * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DisjointSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/Serializer.inl: * dds/DCPS/transport/framework/TransportHeader.h: * dds/DCPS/transport/framework/TransportQueueElement.h: * dds/DCPS/transport/rtps_udp/RtpsTransportHeader.h: * tests/DCPS/Serializer/SerializerTest.cpp:/"
,,0.1208,OpenDDS,Moved RepoIdTypes to its own header to break another cyclic include which now happens in the case of safety profile * dds/DCPS/RepoIdTypes.h: Added. * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DiscoveryListener.h: * dds/DCPS/InstanceState.h: * dds/DCPS/PublicationInstance.h: * dds/DCPS/Recorder.h: * dds/DCPS/Replayer.h: * dds/DCPS/SafetyProfileSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/transport/framework/TransportSendListener.h: * dds/FACE/FaceTSS.h:/
,,0.1243,OpenDDS,Moved RepoIdTypes to its own header to break another cyclic include which now happens in the case of safety profile * dds/DCPS/RepoIdTypes.h: Added. * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DiscoveryListener.h: * dds/DCPS/InstanceState.h: * dds/DCPS/PublicationInstance.h: * dds/DCPS/Recorder.h: * dds/DCPS/Replayer.h: * dds/DCPS/SafetyProfileSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/transport/framework/TransportSendListener.h: * dds/FACE/FaceTSS.h:/
,,0.1135,OpenDDS,"Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Handling uncaught BAD_PARAM exception per Coverity Scan defect report./Merge pull request from jwillemsen/jwi-shutdown-565 Fixed memory leaks/valgrind issues when having a double shutdown, issue close invocation * dds/DCPS/Service_Participant.cpp:/Fixed typo * dds/DCPS/Service_Participant.cpp:/"
,,0.1138,OpenDDS,"Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Adding checks after dynamic_cast to address coverity defect reports./Merge pull request from jwillemsen/jwi-qc-crash-550 Check typed_sample before we pass it to the filter, it is check for nÖ/"
,,0.2063,OpenDDS,"Moved RepoIdTypes to its own header to break another cyclic include which now happens in the case of safety profile * dds/DCPS/RepoIdTypes.h: Added. * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DiscoveryListener.h: * dds/DCPS/InstanceState.h: * dds/DCPS/PublicationInstance.h: * dds/DCPS/Recorder.h: * dds/DCPS/Replayer.h: * dds/DCPS/SafetyProfileSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/transport/framework/TransportSendListener.h: * dds/FACE/FaceTSS.h:/Implemented std::(w)string insertion and extraction for the Serializer. Serializer.h has to include Definitions.h to get the correct setting of DDS_HAS_WCHAR but this lead to a cyclic include, moved SequenceNumber out of Definitions.h to break this. Updated some other files to include the new SequenceNumber.h. This implements issue * dds/DCPS/SequenceNumber.h: Added. * dds/DCPS/CoherentChangeControl.h: * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DisjointSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/Serializer.inl: * dds/DCPS/transport/framework/TransportHeader.h: * dds/DCPS/transport/framework/TransportQueueElement.h: * dds/DCPS/transport/rtps_udp/RtpsTransportHeader.h: * tests/DCPS/Serializer/SerializerTest.cpp:/"
,,0.1226,OpenDDS,Moved RepoIdTypes to its own header to break another cyclic include which now happens in the case of safety profile * dds/DCPS/RepoIdTypes.h: Added. * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DiscoveryListener.h: * dds/DCPS/InstanceState.h: * dds/DCPS/PublicationInstance.h: * dds/DCPS/Recorder.h: * dds/DCPS/Replayer.h: * dds/DCPS/SafetyProfileSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/transport/framework/TransportSendListener.h: * dds/FACE/FaceTSS.h:/
,,0.11900000000000001,OpenDDS,Moved RepoIdTypes to its own header to break another cyclic include which now happens in the case of safety profile * dds/DCPS/RepoIdTypes.h: Added. * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DiscoveryListener.h: * dds/DCPS/InstanceState.h: * dds/DCPS/PublicationInstance.h: * dds/DCPS/Recorder.h: * dds/DCPS/Replayer.h: * dds/DCPS/SafetyProfileSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/transport/framework/TransportSendListener.h: * dds/FACE/FaceTSS.h:/
,,0.10300000000000001,OpenDDS,Merge pull request from jwillemsen/jwi-grouppresentation Fix GroupPresentation test failures by reverting a small part of the change of PR part of PR testing whether this solves the hang on windows * dds/DCPS/DataReaderImpl.cpp: * dds/DCPS/DataReaderImpl.h: * dds/DCPS/SubscriberImpl.cpp: * dds/DCPS/SubscriberImpl.h:/
,,0.21899999999999997,OpenDDS,"Moved RepoIdTypes to its own header to break another cyclic include which now happens in the case of safety profile * dds/DCPS/RepoIdTypes.h: Added. * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DiscoveryListener.h: * dds/DCPS/InstanceState.h: * dds/DCPS/PublicationInstance.h: * dds/DCPS/Recorder.h: * dds/DCPS/Replayer.h: * dds/DCPS/SafetyProfileSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/transport/framework/TransportSendListener.h: * dds/FACE/FaceTSS.h:/Implemented std::(w)string insertion and extraction for the Serializer. Serializer.h has to include Definitions.h to get the correct setting of DDS_HAS_WCHAR but this lead to a cyclic include, moved SequenceNumber out of Definitions.h to break this. Updated some other files to include the new SequenceNumber.h. This implements issue * dds/DCPS/SequenceNumber.h: Added. * dds/DCPS/CoherentChangeControl.h: * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DisjointSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/Serializer.inl: * dds/DCPS/transport/framework/TransportHeader.h: * dds/DCPS/transport/framework/TransportQueueElement.h: * dds/DCPS/transport/rtps_udp/RtpsTransportHeader.h: * tests/DCPS/Serializer/SerializerTest.cpp:/"
,,0.125,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Fuzz fixes./Adding checks after dynamic_cast to address coverity defect reports./Fixed log format specifier for size_t * dds/DCPS/PublisherImpl.cpp: * dds/DCPS/SubscriberImpl.cpp:/
,,0.1226,OpenDDS,Moved RepoIdTypes to its own header to break another cyclic include which now happens in the case of safety profile * dds/DCPS/RepoIdTypes.h: Added. * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DiscoveryListener.h: * dds/DCPS/InstanceState.h: * dds/DCPS/PublicationInstance.h: * dds/DCPS/Recorder.h: * dds/DCPS/Replayer.h: * dds/DCPS/SafetyProfileSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/transport/framework/TransportSendListener.h: * dds/FACE/FaceTSS.h:/
,,0.1036,OpenDDS,"Merge pull request from jwillemsen/jwi-endhistorysampleleak Fixed valgrind reported leakage of end_historic_sample at shutdown/Removed initialized_ flag, was only used to check if some points need to be deleted, but at the moment we havent allocated them they are zero which is not a problem when calling delete on them * dds/DCPS/DataReaderImpl.cpp: * dds/DCPS/DataReaderImpl.h: * dds/DCPS/DataWriterImpl.cpp: * dds/DCPS/DataWriterImpl.h: * dds/DCPS/ReplayerImpl.h:/"
,,0.2088,OpenDDS,"Moved RepoIdTypes to its own header to break another cyclic include which now happens in the case of safety profile * dds/DCPS/RepoIdTypes.h: Added. * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DiscoveryListener.h: * dds/DCPS/InstanceState.h: * dds/DCPS/PublicationInstance.h: * dds/DCPS/Recorder.h: * dds/DCPS/Replayer.h: * dds/DCPS/SafetyProfileSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/transport/framework/TransportSendListener.h: * dds/FACE/FaceTSS.h:/Implemented std::(w)string insertion and extraction for the Serializer. Serializer.h has to include Definitions.h to get the correct setting of DDS_HAS_WCHAR but this lead to a cyclic include, moved SequenceNumber out of Definitions.h to break this. Updated some other files to include the new SequenceNumber.h. This implements issue * dds/DCPS/SequenceNumber.h: Added. * dds/DCPS/CoherentChangeControl.h: * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DisjointSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/Serializer.inl: * dds/DCPS/transport/framework/TransportHeader.h: * dds/DCPS/transport/framework/TransportQueueElement.h: * dds/DCPS/transport/rtps_udp/RtpsTransportHeader.h: * tests/DCPS/Serializer/SerializerTest.cpp:/"
,,0.1704,OpenDDS,"Implemented std::(w)string insertion and extraction for the Serializer. Serializer.h has to include Definitions.h to get the correct setting of DDS_HAS_WCHAR but this lead to a cyclic include, moved SequenceNumber out of Definitions.h to break this. Updated some other files to include the new SequenceNumber.h. This implements issue * dds/DCPS/SequenceNumber.h: Added. * dds/DCPS/CoherentChangeControl.h: * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DisjointSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/Serializer.inl: * dds/DCPS/transport/framework/TransportHeader.h: * dds/DCPS/transport/framework/TransportQueueElement.h: * dds/DCPS/transport/rtps_udp/RtpsTransportHeader.h: * tests/DCPS/Serializer/SerializerTest.cpp:/"
,,0.1982,OpenDDS,Moved RepoIdTypes to its own header to break another cyclic include which now happens in the case of safety profile * dds/DCPS/RepoIdTypes.h: Added. * dds/DCPS/DataSampleHeader.h: * dds/DCPS/Definitions.h: * dds/DCPS/DiscoveryListener.h: * dds/DCPS/InstanceState.h: * dds/DCPS/PublicationInstance.h: * dds/DCPS/Recorder.h: * dds/DCPS/Replayer.h: * dds/DCPS/SafetyProfileSequence.h: * dds/DCPS/Serializer.h: * dds/DCPS/transport/framework/TransportSendListener.h: * dds/FACE/FaceTSS.h:/Merge pull request from oschwaldp-oci/coverity_issues_fixes Coverity Scan Defect Report issues./Fix namespace of INVALID_PARAM. Fix warning of unused variable ex./Add try/catch for CORBA::BAD_PARAM exceptions at the FaceTSS API boundary./Merge pull request from oschwaldp-oci/coverity_issues_fixes Addressing Coverity Scan Reported Defects./Adding checks after dynamic_cast to address coverity defect reports./
,,0.0737,OpenDDS,Put the TestCase construction within the try/catch * tests/DCPS/SharedTransport/TestCase.cpp:/
,,0.0876,OpenDDS,Merge pull request from oschwaldp-oci/coverity_issues_fixes Coverity Scan updates/Coverity Scan Defect: Address 1380592 Check stub_ready_filename to make sure it has been set before passing it to fopen./
,,0.0716,OpenDDS,Break reference cycle inside DataWriterImpl/
,,0.0586,OpenDDS,Fix race condition for accessing ownership manager/Merge pull request from huangminghuang/master Fix memory leak in ZeroCopySeq/Fix memory leak in ZeroCopySeq/
,,0.0577,OpenDDS,Fix safety profile allocator move construct operation/
,,0.0702,OpenDDS,Fix race condition for accessing ownership manager/
,,0.0737,OpenDDS,Break reference cycle inside DataWriterImpl/
,,0.0903,OpenDDS,style/warnings: prefer prefix iterator increment/
,,0.0744,OpenDDS,fixed issue 808: support all kinds of bool-discriminated unions/
,,0.066,OpenDDS,fixed export macro/
,,0.0951,OpenDDS,"Adding Support for DCPSSecurity runtime flag (disabled by default), fixing DomainParticipant return codes, adding temporary unique guid generation to builtin auth plugin/"
,,0.0822,OpenDDS,"Continued interop fixes/fixed more issues with PropertyQos and Property serialization/fixing bug in parameter list converter, setting up local permissions and governance files for Messenger test with correct domain, temporary work around for missing permissions CA cert file/"
,,0.0985,OpenDDS,"Adding Support for DCPSSecurity runtime flag (disabled by default), fixing DomainParticipant return codes, adding temporary unique guid generation to builtin auth plugin/"
,,0.0849,OpenDDS,Interop workaround: allow illegal 0-strings/
,,0.0785,OpenDDS,"DataWriterImpl: when enable() fails, let WriteDataContainer shut down cleanly/Initial implementation of 8.8.5 and rest of 8.8.6, changes to tests & script & dds log messages to allow for failure test/"
,,0.1087,OpenDDS,"Restore ""Normal"" Failure of Persistent IR BIT Test/Init IR BIT entities first So that they always have the same GUIDs acess InfoRepo Persistence. This does not solve the ongoing problem with the persistent repo BIT test as hoped though./"
,,0.0954,OpenDDS,Shared Memory Transport Platform Macros Created common shared memory platform macros to reduce redundancy. Incorporated fix for older Android NDKs with newer APIs:
,,0.092,OpenDDS,Shared Memory Transport Platform Macros Created common shared memory platform macros to reduce redundancy. Incorporated fix for older Android NDKs with newer APIs:
,,0.086,OpenDDS,"Merge pull request from simpsont-oci/diffie_hellman_test_fix Fix Periodic Diffie Hellman Test Failure/fixing diffie hellman code public key retrieval to use BN_num_bytes for the key size instead of DH_size, which is for derived keys. This seems to have been the primary cause of the intermittent failure. Also some general code cleanup in DiffieHellman, including removal of operator()() for a bit more clarity and updating initial key general to just use higher-level EVP_ methods for key generation (after that, we still use some DH_ methods when necessary/"
,,0.0861,OpenDDS,DiffieHellmanTest: removed a test case for a call that already has coverage elsewhere. This failed in the .4% of times the random number started with a 0 byte/
,,0.0697,OpenDDS,opendds_idl: Fix Invalid Free in C++11 Union Prevent union from being tricked into calling a destructor on an invalid object./
,,0.0778,pljava,Fixed bug in hash key calculation/
,,0.0905,pljava,Fixed bug causing primitive arrays to fail./Fixed usage text (-jar deploy.jar org.postgresql.pljava.test.Tester)/
,,0.1032,pljava,Fixed signed/unsigned warnings/Fixed so that LargeObject functionality is initialized on startup./Fixed needed code to accomodate API change for LargeObjects/
,,0.0607,pljava,Fixed some issues with Meta-data/
,,0.11699999999999999,pljava,"When deploying a jar file with a deployment descriptor, the deployment failed if the default schema already had a classpath set. A typo was setting the current schema value to the classpath, instead of the default schema. When trying to set the new classpath this bailed out with ""No such schema:"
,,0.0833,pljava,"For a server built with integer datetimes, conversion from SQL to Java timestamps produced bogus results as the result of overflow. Prior to conversion to milliseconds, cast the difference in PG and Unix epochs to a 64 bit type. Lucas Madar/"
,,0.1944,pljava,"For a multi-threaded pljava function we need to adjust stack_base_ptr before calling into the backend to avoid stack depth limit exceeded errors. Previously this was done only on query execution, but we need to do it on iteration of the ResultSet as well. In general it seems that anything operating inside of synchronized(Backend.THREADLOCK) might need to adjust the stack unless its certain the work its doing is trivial and wont invoke check_stack_depth. Unfortunately I dont know enough about when pg calls check_stack_depth to know offhand what is/is not safe. A more thorough audit is required here. Per report from Alexander Wˆhrer./"
,,0.1826,pljava,"If the call to a type output function is the first pljava call in a session, we get a crash. The first pljava call results in a SPI connection being established and torn down. The type output function was allocating the result in the SPI memory context which gets destroyed prior to returning the data to the caller. Allocate the result in the correct context to survive function exit./"
,,0.0801,pljava,Bug 1010962: Release tuple descriptor once copied. Heikki Linnakangas./
,,0.0556,pljava,Bugfix 1011181: PL/Java fails to compile with
,,0.1699,pljava,"Changes are required because of move of GETSTRUCT() and timeout handling framework changes done in PG 9.3. Along with that I fixes minor issue in DDRProcessor.java that is causing ""illegal start of expression"" error. Maven did not worked for me to build it and hang endlessly while building c source code (pljava-so). As a workaround I temporarily fixed makefiles to test PG9.3 related fix that seems worked and generated pljava.jar and pljava.so files and their basic sanity seems working fine./"
,,0.188,pljava,"Changes are required because of move of GETSTRUCT() and timeout handling framework changes done in PG 9.3. Along with that I fixes minor issue in DDRProcessor.java that is causing ""illegal start of expression"" error. Maven did not worked for me to build it and hang endlessly while building c source code (pljava-so). As a workaround I temporarily fixed makefiles to test PG9.3 related fix that seems worked and generated pljava.jar and pljava.so files and their basic sanity seems working fine./"
,,0.1933,pljava,"Conditional DDR as proposed on pljava-dev. Delayed by a nice pljava trivia brain teaser ... IF a functions SQL declaration says its immutable (or even stable, I guess), AND you call it from the deployment descriptor install commands of the jar that contains it, AND thats the first reference youve made to its containing class ... ClassNotFoundException. Go ahead, explain THAT one to Aunt Tillie.... (Hint: SPI change visibility rules.)/"
,,0.3437,pljava,"Conditional DDR as proposed on pljava-dev. Delayed by a nice pljava trivia brain teaser ... IF a functions SQL declaration says its immutable (or even stable, I guess), AND you call it from the deployment descriptor install commands of the jar that contains it, AND thats the first reference youve made to its containing class ... ClassNotFoundException. Go ahead, explain THAT one to Aunt Tillie.... (Hint: SPI change visibility rules.)/Merge pull request from jcflack/bug/master/ddrorder Run deployment descriptors in correct order./Run deployment descriptors in correct order. Previously determined the order of multiple deployment descriptors in a single jar according to the order of those entries as stored in the jar (used in that order for install, and that order reversed for remove). But that wasnt correct. I got my hands on 2003 and 2006 drafts of the SQL/JRT spec and they both clearly say it is the order _as the entries are listed in the manifest_ that matters (again, in that order for install, and the reverse for remove). This should be a welcome improvement, because I had noted back in commit 0edc9e5f that maven doesnt always put things in a jar in the same order, and that was causing the pljava-examples jar to be broken about half the time (for autodeployment anyway). But the manifest is a static file listing the ddrs in the right order, so as long as maven doesnt reorder it while putting it in the jar, that behavior should now be stable./Merge pull request from jcflack/bug/master/replaceJar Fix obsoleted query in sqlj.replace_jar./Fix obsoleted query in sqlj.replace_jar. Ken Olson caught this a year ago in his pull request but it was my oversight; when rearranging the sqlj relations back in to accommodate more than one deployment descriptor, I updated the sql in install_jar and remove_jar (and deployInstall and deployRemove), but I just totally overlooked replace_jar. Oops./"
,,0.2058,pljava,"Conditional DDR as proposed on pljava-dev. Delayed by a nice pljava trivia brain teaser ... IF a functions SQL declaration says its immutable (or even stable, I guess), AND you call it from the deployment descriptor install commands of the jar that contains it, AND thats the first reference youve made to its containing class ... ClassNotFoundException. Go ahead, explain THAT one to Aunt Tillie.... (Hint: SPI change visibility rules.)/MSVC profile using profile more, properties less. This will have to be tested by someone with MSVC access. Its behavior should be close to what I _think_ it should do. Possible nits: it puts the MSVC extra include paths late in the list; if thats a problem because they need to be early, I found syntax for that too, only a little bit uglier. Also, an MSVC link will mention libjvm twice, once in the right place (I think), but also still in the wrong one; I _think_ that should be harmless. Nothing another barrage of XML cant fix, if its a problem./Merge pull request from kenolson/bug/master/msvc_build Fix to allow building pljava with Microsoft Visual C/Fix to allow building pljava with Microsoft Visual C Code changes to allow compilation and linking with Microsoft Visual C. Maven build process conditionalized to to detect Visual C and adjust options appropriately. See msvc-build-notes.txt for full details. Property names updated for clarity/Merge pull request from jcflack/bug/master/1011181 The rest of ""Bugfix 1011181""/The rest of ""Bugfix 1011181"" This was one problem being solved two ways. First there was code to double any percent signs in a string that would be passed to elog. But then myrkraverk in 2012 (622d0ac) got a compiler warning about using a non-constant format string, and changed the elog call to pass the supplied string as an argument to `%s` format, which is the cleaner solution anyway, but didnt remove the old code, so `%` signs were printing out doubled./"
,,0.3061,pljava,"Workaround Windows creating_extension visibility. Should now detect (in most cases?) when an extension is being created, even in versions where creating_extension isnt visible in Windows. Test depends on seeing the command in ActivePortal; I am not sure what contexts could be contrived where that wouldnt work right, but ordinary foreseeable cases seem to work. Got rid of pljavaInExtension: the idea that two cases have to be distinguished (loading PL/Java itself as an extension, or using it in the creation of some other extension) was sound, but the second case isnt something that can be checked once at load time; it needs a backend function that sqlj.install_jar can invoke whenever needed./Dont fail in remove_jar if schema dropped. The pljava-examples jar has long had an annoying behavior because its remove actions drop its schema, and if deployRemove had changed the schemas classpath to include the jar, it would fail upon trying to restore the original classpath on the now-nonexistent schema. Resolved by telling deployRemove its ok for the classpath restoration to fail if the reason is the schemas gone. All references to the removed jar will be gone from classpath_entry anyway; referential integrity sees to that./Part of issue schema migration. Add a naming system for schema variants that have existed during PL/Javas VCS history. A quick check looks at the existing tables, if any, to infer what schema is there. This allows a second or subsequent LOAD to succeed without trying to recreate tables, if a quick check suggests the existing tables are as the code expects. If an earlier PL/Java schema is recognized, and a recipe for migrating from it is available, the schema is migrated. (Recommendation: do PL/Java upgrade in a transaction, so schema changes can be rolled back if something is unsatisfactory.) The two supplied recipes handle schemas as far back as 2006-02-26, anyway./Merge pull request from tada/chore/master/javadoc8 Could as well have been called a bug, because javadoc 8 lint _stops_ `mvn site`./"
,,0.2818,pljava,"Work around symbols MSVC cant link to. The long pgsql-hackers thread in 2014 discovering that MSVC could silently link global variables to the wrong stuff if not properly decorated in PGs .h files documents how the problem of silently succeeding was solved by making such cases fail instead. Thats great, only now they fail. These patches make the pessimistic assumption that no working way to access the global variables will be found. That might not be the case, because theres a recent new pgsql-hackers thread that has rekindled some interest in finding a better solution to the problem. Anyway, until that day, these workarounds should achieve the correct behavior under MSVC./"
,,0.3211,pljava,"Add a GUC option for libjvm location. The linker used to embed a dependency for libjvm into the pljava shared object, which required using one of several system-specific ways to get the systems library loader (not PostgreSQLs) to be able to find libjvm, or loading pljava would simply fail. By omitting the linked-in dependency on libjvm, pljava can now successfully load and then use PostgreSQLs own dlopen wrapper to find libjvm using the pljava.libjvm_location option, or give a helpful error report. The history of PGDLLEXPORT through the years has been somewhat bewildering, and it begins to seem tidier to cleanly define a PLJAVADLLEXPORT that is used only here and doesnt change its meaning across PG releases./"
,,0.0759,pljava,"Correct two converted conditions. While making everything as simple as possible, avoid making it simpler..../Dont leave SET ROLE broken after DDR execution. Comments in miscinit.c suggest the PostgreSQL team considers {Get,Set}UserIdAndContext to be obsolete API kept around only for PL/Java, with {Get,Set}UserIdAndSecContext being the preferred newer API. Something for another day..../"
,,0.1064,pljava,"Merge pull request from tada/bug/master/issue61 Avoid crash on exception before String_init./Avoid crash on exception before String_init. Exceptions thrown trying to load the first PL/Java implementation class may need to be handled before String_init has completed, so String needs some partial functionality at that point./Observe C90 decls-before-stmts rule. Ken Olson points out that a recent change breaks compilation under MSVC which does not, apparently, support the C99 standard before Visual Studio 2013 (not used in EDB builds before PG 9.4)./"
,,0.1296,pljava,"Fix overlooked consequence of pull req 68. Deriving PGSQL_*_VER from PG_VERSION_NUM in pljava.h changed behavior in one case where an protected an *before* pljava.h was included. (Theres another instance in AclId, but that is for a pre-8.1 condition that can be removed entirely.) Note: PG_VERSION_NUM itself appeared in 8.2, so that is now a version minimum. Given that, it would be even safer (and reduce verbosity) to dedicate one future commit to just rototill all of the sources and change PGSQL_*_VER conditionals to direct ones on PG_VERSION_NUM. Committing without a separate pull request, as follow-on to PR 68./"
,,0.2876,pljava,"Work around symbols MSVC cant link to. The long pgsql-hackers thread in 2014 discovering that MSVC could silently link global variables to the wrong stuff if not properly decorated in PGs .h files documents how the problem of silently succeeding was solved by making such cases fail instead. Thats great, only now they fail. These patches make the pessimistic assumption that no working way to access the global variables will be found. That might not be the case, because theres a recent new pgsql-hackers thread that has rekindled some interest in finding a better solution to the problem. Anyway, until that day, these workarounds should achieve the correct behavior under MSVC./"
,,0.4816,pljava,"Shortcircuit assign hooks during abort. Make sure assign hooks wont do things that could throw errors during transaction abort./Workaround Windows creating_extension visibility. Should now detect (in most cases?) when an extension is being created, even in versions where creating_extension isnt visible in Windows. Test depends on seeing the command in ActivePortal; I am not sure what contexts could be contrived where that wouldnt work right, but ordinary foreseeable cases seem to work. Got rid of pljavaInExtension: the idea that two cases have to be distinguished (loading PL/Java itself as an extension, or using it in the creation of some other extension) was sound, but the second case isnt something that can be checked once at load time; it needs a backend function that sqlj.install_jar can invoke whenever needed./PL/Java as a PostgreSQL 9.1+ extension. Because PL/Java installation is already touched off by a simple library LOAD (even on pre-9.1 databases without the extension framework), extension support is largely a matter of having extension scripts that touch off a LOAD. But the library does need to detect that case and change some behaviors slightly. When LOAD is used directly and something fails because the settings arent right, Backend reports a WARNING rather than an ERROR, to make it as easy as possible to keep explore settings and eventually get them right, without forcing a rollback. However, under CREATE EXTENSION, it must be reported as an error, or the extension machinery will think all is well. Also, playing with the settings after CREATE EXTENSION failed can result in getting PL/Java successfully installed but not as an extension--easily remedied with CREATE EXTENSION FROM UNPACKAGED, so a NOTICE suggesting that is reported in that case. The method of finding the module pathname from the LOAD argument doesnt work under CREATE EXTENSION (ActivePortal still refers to the CREATE EXTENSION command itself, not the LOAD command in the script), so as a workaround the script creates a temporary table with the module pathname in it. This turns out to be useful anyway, because it allows distinguishing the case of PL/Java itself being installed by CREATE EXTENSION from the case where PL/Java is already installed and its library is getting loaded in passing during CREATE EXTENSION for something that depends on it. (Actual support for PL/Java-managed extensions will have to come later, but the case needs to be recognized even to say ""you cant do that yet."") Reorganized the archives created by pljava-packaging so files are at directory prefixes like pljava/pkglibdir, pljava/sharedir, etc. That makes it easy to know where things should go in a manual installation, but also opens the possibility of a self-extracting archive that will use pg_config to look up the corresponding paths at extraction time./TWO more omissions caught late. Supply one missing C prototype for completeness. Cant claim a goal of not breaking PG 8.2 without providing a CppAsString2 macro./One cut/paste error caught late./Work around symbols MSVC cant link to. The long pgsql-hackers thread in 2014 discovering that MSVC could silently link global variables to the wrong stuff if not properly decorated in PGs .h files documents how the problem of silently succeeding was solved by making such cases fail instead. Thats great, only now they fail. These patches make the pessimistic assumption that no working way to access the global variables will be found. That might not be the case, because theres a recent new pgsql-hackers thread that has rekindled some interest in finding a better solution to the problem. Anyway, until that day, these workarounds should achieve the correct behavior under MSVC./Factor init sequence into a restartable routine. The initsequencer routine can pick up where it left off, whether started by _PG_init, by the internal call handler, or by a GUC hook if the admin is trying a different config setting. Continue moving bits out of the initializeJavaVM, etc., routines into additional stages in the sequencer. Eventually: have a stage where the JVM is running and a Java method can be called to check for and do the SQL function declarations, SQLJ schema population, etc. Ability to re-create the VM to try a new classpath is what I had hoped for, but in many years of the JNI docs the restriction to one JVM per process hasnt been relaxed yet, and it seems to mean you cant start a second even after shutting down the first. So in many cases the admin will have to exit and start a new session if installation fails at that point. Thats still not too bad./Add a GUC option for libjvm location. The linker used to embed a dependency for libjvm into the pljava shared object, which required using one of several system-specific ways to get the systems library loader (not PostgreSQLs) to be able to find libjvm, or loading pljava would simply fail. By omitting the linked-in dependency on libjvm, pljava can now successfully load and then use PostgreSQLs own dlopen wrapper to find libjvm using the pljava.libjvm_location option, or give a helpful error report. The history of PGDLLEXPORT through the years has been somewhat bewildering, and it begins to seem tidier to cleanly define a PLJAVADLLEXPORT that is used only here and doesnt change its meaning across PG releases./Expand $libdir a simpler way. Backend.c has relied on a compile-time define PKGLIBDIR ever since the first commit, but pkglib_path has been a global in miscadmin.h for almost as long only maybe seven months later. :) Also fix an appendStringInfo{ String} that had been missed, in the same place./"
,,0.0687,pljava,"Bit of vacuuming after release 1.5.0. Old Deployer is obsolete, as are install/uninstall.sql and old fixes for GCJ. In 1.5.0 theyve seen their last release. Its all in the history if ever needed./"
,,0.0908,pljava,Merge branch bug/REL1_5_STABLE/rxbacktrack into REL1_5_STABLE Trim the insane stack utilization that formerly required options for builds on small-memory systems./
,,0.1713,pljava,"Lexicals.identifierFrom. Fixed a typo in ISO_UNICODE_IDENTIFIER and added JUnit test (not necessarily in that order). This changes Lexicals from an interface to an abstract class. That should not affect any client code unless it was written to inherit from Lexicals, which would have been an example of the ""constant interface antipattern"" so with any luck will not have been common./Merge branch chore/master/java7ify Bump the minimum Java to 7 and begin adopting Java 7 features in places where the fruit hangs low./Merge branch bug/REL1_5_STABLE/rxbacktrack into REL1_5_STABLE Trim the insane stack utilization that formerly required options for builds on small-memory systems./"
,,0.0849,pljava,Merge branch chore/master/java7ify Bump the minimum Java to 7 and begin adopting Java 7 features in places where the fruit hangs low./
,,0.0849,pljava,Merge branch chore/master/java7ify Bump the minimum Java to 7 and begin adopting Java 7 features in places where the fruit hangs low./
,,0.0849,pljava,Merge branch chore/master/java7ify Bump the minimum Java to 7 and begin adopting Java 7 features in places where the fruit hangs low./
,,0.0849,pljava,Merge branch chore/master/java7ify Bump the minimum Java to 7 and begin adopting Java 7 features in places where the fruit hangs low./
,,0.0849,pljava,Merge branch chore/master/java7ify Bump the minimum Java to 7 and begin adopting Java 7 features in places where the fruit hangs low./
,,0.0849,pljava,Merge branch chore/master/java7ify Bump the minimum Java to 7 and begin adopting Java 7 features in places where the fruit hangs low./
,,0.0849,pljava,Merge branch chore/master/java7ify Bump the minimum Java to 7 and begin adopting Java 7 features in places where the fruit hangs low./
,,0.0807,pljava,Merge branch chore/master/java7ify Bump the minimum Java to 7 and begin adopting Java 7 features in places where the fruit hangs low./
,,0.1197,pljava,"Add large object truncate and 64-bit offsets. PG 8.3 introduced inv_truncate, and 9.3 made offsets/lengths 64 bit. Whats nice is that the Java and JNI method signatures have always been 64-bit ready; now just stop downcasting to 32 on 9.3+ PostgreSQLs where 64 bit offsets are really accepted./"
,,0.0687,pljava,"Bit of vacuuming after release 1.5.0. Old Deployer is obsolete, as are install/uninstall.sql and old fixes for GCJ. In 1.5.0 theyve seen their last release. Its all in the history if ever needed./"
,,0.1182,pljava,"Out with my pessimism; PARALLEL SAFE works fine. A simple test with a PL/Java function declared PARALLEL SAFE, and used in a parallel query, did just what it says on the tin, on the first try. There may still be cases lurking in which PL/Javas inner workings would do something a SAFE or RESTRICTED function isnt supposed to do, but I had imagined there would be problems galore and there arent, so the capability may as well be announced and documented./"
,,0.0937,pljava,"Handle widening of SPITupleTable .alloced and .free. Not many choices available here. Wider-than-32-bit array indices in Java seem as far off as ever, so without reimplementing TupleTable to do something else besides copying the whole megillah into a Java array, there is no choice but to check and report a suitable error if the table is too big./"
,,0.0692,pljava,"Clarify currentRow in ResultSetProvider. Fill in the missing explanation (reported in issue of the currentRow parameter in ResultSetProvider. Trivial doc fix, pushing directly./"
,,0.11199999999999999,pljava,"Merge pull request from tada/bug/REL1_5_STABLE/issue125 Honor client_min_messages too at PL/Java startup./Honor client_min_messages too at PL/Java startup. Fix the easier complaint in issue if Java will be summarily discarding log messages finer than a level derived from PostgreSQLs settings just once at PL/Java startup, at least derive the level from the finer of log_min_messages and client_min_messages, rather than from log_min_messages alone./"
,,0.0679,pljava,"Merge pull request from tada/bug/REL1_5_STABLE/issue134 Accomodate upstream SPI_push/pop API changes (issue SPI_result_code_string more. While thinking of SPI and its error codes, report those as strings rather than numeric codes in a couple more places./"
,,0.075,realm-java,Added wrapper and tests for mixed type retrieval method (issue
,,0.08,realm-java,"Added tests and examples for the ""average"" method (issue high-level wrapper for the average method (issue"
,,0.0758,realm-java,Adjusted examples to the inline subtable construction (issue
,,0.0737,realm-java,Adjusted examples to the inline subtable construction (issue
,,0.0628,realm-java,Adjusted docs and examples to the refactoring (issue and issue
,,0.0738,realm-java,Now throws exception when calling a method on a closed Group() Updated tutorial and showcase a bit./
,,0.0718,realm-java,Now throws exception when calling a method on a closed Group() Updated tutorial and showcase a bit./
,,0.0672,realm-java,"A config step has been introduced into the build procedure. The main reason is that it allows reliable uninstallation, but there are several other benefits too. Also, support for running in debug mode has been improved./"
,,0.0607,realm-java,Merge branch master into cm/bug/local-install/fix tests/
,,0.1061,realm-java,Make security copies of the key in RealmConfiguration Saving and providing a mutable reference of the key is both a security threat and possibly the origin of subtle bugs. We now make security copies of the byte arrays to solve the issue./Merge pull request from realm/mc-enc-not-supported Add RealmEncryptionNotSupportedException/Update core to v0.89.8 Add RealmEncryptionNotSupportedException/
,,0.0625,realm-java,Add minVersion and targetVersion to metrics collected by the Realm Tranformer (#4143) Fixes
,,0.0702,realm-java,Fix getLocalInstanceCount crashing when Realms are closed again. (#3798)/
,,0.0755,realm-java,Client reset fixes (#5159) * Exposing a `SyncConfiguration` that allows a user to open the backup Realm after the client reset (#4759)./Merge pull request from realm/merge-c9206c-to-master-4.0 Fix merge from c9206c to master-4.0/Remove ObjectServerUser (#5020) * remove ObjectServerUser * add multiple session tests * Add regression test for old SyncUser JSON * Using identity with authURL to identity a SyncUser/
,,0.0792,realm-java,Enabling client reset test (#5388) * fixes reset fixes (#5159) * Exposing a `SyncConfiguration` that allows a user to open the backup Realm after the client reset (#4759)./Merge pull request from realm/merge-c9206c-to-master-4.0 Fix merge from c9206c to master-4.0/Remove ObjectServerUser (#5020) * remove ObjectServerUser * add multiple session tests * Add regression test for old SyncUser JSON * Using identity with authURL to identity a SyncUser/
,,0.0704,realm-java,Remove ObjectServerUser (#5020) * remove ObjectServerUser * add multiple session tests * Add regression test for old SyncUser JSON * Using identity with authURL to identity a SyncUser/
,,0.0643,realm-java,Merge pull request from realm/merge-7930c8-to-next-major Fix merge from 7930c8 to next-major/Fix module example (#5830)/
,,0.1458,rocksdb,"Fix for the weird behaviour encountered by ldb Get where it could read only the second-latest value Summary: Changed the Get and Scan options with openForReadOnly mode to have access to the memtable. Changed the visibility of NewInternalIterator in db_impl from private to protected so that the derived class db_impl_read_only can call that in its NewIterator function for the scan case. The previous approach which changed the default for flush_on_destroy_ from false to true caused many problems in the unit tests due to empty sst files that it created. All unit tests pass now. Test Plan: make clean; make all check; ldb put and get and scans Reviewers: dhruba, heyongqiang, sheki Reviewed By: dhruba CC: kosievdmerwe, zshao, dilipj, kailiu Differential Revision: ""Fix for the weird behaviour encountered by ldb Get where it could read only the second-latest value"" This reverts commit 4c696ed0018800b62e2448a4ead438255140fc25./Fix for the weird behaviour encountered by ldb Get where it could read only the second-latest value Summary: flush_on_destroy has a default value of false and the memtable is flushed in the dbimpl-destructor only when that is set to true. Because we want the memtable to be flushed everytime that the destructor is called(db is closed) and the cases where we work with the memtable only are very less it is a good idea to give this a default value of true. Thus the put from ldb wil have its data flushed to disk in the destructor and the next Get will be able to read it when opened with OpenForReadOnly. The reason that ldb could read the latest value when the db was opened in the normal Open mode is that the Get from normal Open first reads the memtable and directly finds the latest value written there and the Get from OpenForReadOnly doesnt have access to the memtable (which is correct because all its Put/Modify) are disabled Test Plan: make all; ldb put and get and scans Reviewers: dhruba, heyongqiang, sheki Reviewed By: heyongqiang CC: kosievdmerwe, zshao, dilipj, kailiu Differential Revision:"
,,0.2068,rocksdb,"[Kill randomly at various points in source code for testing] Summary: This is initial version. A few ways in which this could be extended in the future are: (a) Killing from more places in source code (b) Hashing stack and using that hash in determining whether to crash. This is to avoid crashing more often at source lines that are executed more often. (c) Raising exceptions or returning errors instead of killing Test Plan: This whole thing is for testing. Here is part of output: python2.7 tools/db_crashtest2.py 600 Running db_stress db_stress retncode output LevelDB version : 1.5 Number of threads : 32 Ops per thread : 10000000 Read percentage : 50 Write-buffer-size : 4194304 Delete percentage : 30 Max key : 1000 Ratio : 320000 Num times DB reopens: 0 Batches/snapshots : 1 Purge redundant % : 50 Num keys per lock : 4 Compression : snappy No lock creation because test_batches_snapshots set 2013/04/26-17:55:17 Starting database operations Created bg thread 0x7fc1f07ff700 ... finished 60000 ops Running db_stress db_stress retncode output LevelDB version : 1.5 Number of threads : 32 Ops per thread : 10000000 Read percentage : 50 Write-buffer-size : 4194304 Delete percentage : 30 Max key : 1000 Ratio : 320000 Num times DB reopens: 0 Batches/snapshots : 1 Purge redundant % : 50 Num keys per lock : 4 Compression : snappy Created bg thread 0x7ff0137ff700 No lock creation because test_batches_snapshots set 2013/04/26-17:56:15 Starting database operations ... finished 90000 ops Revert Plan: OK Task ID: Reviewers: dhruba, emayanke Reviewed By: emayanke CC: leveldb, haobo Differential Revision:"
,,0.2124,rocksdb,"[RocksDB] Improve manifest dump to print internal keys in hex for version edits. Summary: Currently, VersionEdit::DebugString always display internal keys in the original ascii format. This could cause manifest dump to be truncated if internal keys contain special charactors (like null). Also added an option for ldb idump to indicate that the passed in user keys are in hex. Test Plan: run ldb manifest_dump Reviewers: dhruba, emayanke CC: leveldb Differential Revision: timeranged scan, timeranged dump in ldb. Also the ability to count in time-batches during Dump Summary: Scan and Dump commands in ldb use iterator. We need to also print timestamp for ttl databases for debugging. For this I create a TtlIterator class pointer in these functions and assign it the value of Iterator pointer which actually points to t TtlIterator object, and access the new function ValueWithTS which can return TS also. Buckets feature for dump command: gives a count of different key-values in the specified time-range distributed across the time-range partitioned according to bucket-size. start_time and end_time are specified in unixtimestamp and bucket in seconds on the user-commandline Have commented out 3 ines from ldb_test.py so that the test does not break right now. It breaks because timestamp is also printed now and I have to look at wildcards in python to compare properly. Test Plan: python tools/ldb_test.py Reviewers: vamsi, dhruba, haobo, sheki Reviewed By: vamsi CC: leveldb Differential Revision:"
,,0.2267,rocksdb,"Introducing timeranged scan, timeranged dump in ldb. Also the ability to count in time-batches during Dump Summary: Scan and Dump commands in ldb use iterator. We need to also print timestamp for ttl databases for debugging. For this I create a TtlIterator class pointer in these functions and assign it the value of Iterator pointer which actually points to t TtlIterator object, and access the new function ValueWithTS which can return TS also. Buckets feature for dump command: gives a count of different key-values in the specified time-range distributed across the time-range partitioned according to bucket-size. start_time and end_time are specified in unixtimestamp and bucket in seconds on the user-commandline Have commented out 3 ines from ldb_test.py so that the test does not break right now. It breaks because timestamp is also printed now and I have to look at wildcards in python to compare properly. Test Plan: python tools/ldb_test.py Reviewers: vamsi, dhruba, haobo, sheki Reviewed By: vamsi CC: leveldb Differential Revision:"
,,0.2318,rocksdb,"Dbid feature Summary: Create a new type of file on startup if it doesnt already exist called DBID. This will store a unique number generated from boost librarys uuid header file. The use-case is to identify the case of a db losing all its data and coming back up either empty or from an image(backup/live replicas recovery) the key point to note is that DBID is not stored in a backup or db snapshot Its preferable to use Boost for uuid because: 1) A non-standard way of generating uuid is not good 2) /proc/sys/kernel/random/uuid generates a uuid but only on linux environments and the solution would not be clean 3) c++ doesnt have any direct way to get a uuid 4) Boost is a very good library that was already having linkage in rocksdb from third-party Note: I had to update the TOOLCHAIN_REV in build files to get latest verison of boost from third-party as the older version had a bug. I had to put Wno-uninitialized in Makefile because boost-1.51 has an unitialized variable and rocksdb would not comiple otherwise. Latet open-source for boost is 1.54 but is not there in third-party. I have notified the concerned people in fbcode about it. : While releasing to third-party, an additional dependency will need to be created for boost in TARGETS file. I can help identify. Test Plan: Expand db_test to test 2 cases 1) Restarting db with Id file present verify that no change to Id 2)Restarting db with Id file deleted verify that a different Id is there after reopen Also run make all check Reviewers: dhruba, haobo, kailiu, sdong Reviewed By: dhruba CC: leveldb Differential Revision: option for storing transaction logs in a separate dir Summary: In some cases, you might not want to store the data log (write ahead log) files in the same dir as the sst files. An example use case is leaf, which stores sst files in tmpfs. And would like to save the log files in a separate dir (disk) to save memory. Test Plan: make all. Ran db_test test. A few test failing. P2785018. If you guys dont see an obvious problem with the code, maybe somebody from the rocksdb team could help me debug the issue here. Running this on leaf worked well. I could see logs stored on disk, and deleted appropriately after compactions. Obviously this is only one set of options. The unit tests cover different options. Seems like Im missing some edge cases. Reviewers: dhruba, haobo, leveldb CC: xinyaohu, sumeet Differential Revision: build caused by DeleteFile not tolerating / at the beginning Summary: db->DeleteFile calls ParseFileName to check name that was returned for sst file. Now, sst filename is returned using TableFileName which uses MakeFileName. This puts a / at the front of the name and ParseFileName doesnt like that. Changed ParseFileName to tolerate /s at the beginning. The test delet_file_test used to pass earlier because this behaviour of MakeFileName had been changed a while back to not return a / during which delete_file_test was checked in. But MakeFileName had to be reverted to add / at the front because GetLiveFiles used at many places outside rocksdb used the previous behaviour of MakeFileName. Test Plan: make;./delete_filetest;make all check Reviewers: dhruba, haobo, vamsi Reviewed By: dhruba CC: leveldb Differential Revision:"
,,0.3016,rocksdb,"Dbid feature Summary: Create a new type of file on startup if it doesnt already exist called DBID. This will store a unique number generated from boost librarys uuid header file. The use-case is to identify the case of a db losing all its data and coming back up either empty or from an image(backup/live replicas recovery) the key point to note is that DBID is not stored in a backup or db snapshot Its preferable to use Boost for uuid because: 1) A non-standard way of generating uuid is not good 2) /proc/sys/kernel/random/uuid generates a uuid but only on linux environments and the solution would not be clean 3) c++ doesnt have any direct way to get a uuid 4) Boost is a very good library that was already having linkage in rocksdb from third-party Note: I had to update the TOOLCHAIN_REV in build files to get latest verison of boost from third-party as the older version had a bug. I had to put Wno-uninitialized in Makefile because boost-1.51 has an unitialized variable and rocksdb would not comiple otherwise. Latet open-source for boost is 1.54 but is not there in third-party. I have notified the concerned people in fbcode about it. : While releasing to third-party, an additional dependency will need to be created for boost in TARGETS file. I can help identify. Test Plan: Expand db_test to test 2 cases 1) Restarting db with Id file present verify that no change to Id 2)Restarting db with Id file deleted verify that a different Id is there after reopen Also run make all check Reviewers: dhruba, haobo, kailiu, sdong Reviewed By: dhruba CC: leveldb Differential Revision: names of properties from leveldb prefix to rocksdb prefix. Summary: Migrate names of properties from leveldb prefix to rocksdb prefix. Test Plan: make check Reviewers: emayanke, haobo Reviewed By: haobo CC: leveldb Differential Revision:"
,,0.1386,rocksdb,"Add a call DisownData() to Cache, which should speed up shutdown Summary: On a shutdown, freeing memory takes a long time. If were shutting down, we dont really care about memory leaks. I added a call to Cache that will avoid freeing all objects in cache. Test Plan: I created a script to test the speedup and demonstrate how to use the call: Clean shutdown took 7.2 seconds, while fast and dirty one took 6.3 seconds. Unfortunately, the speedup is not that big, but should be bigger with bigger block_cache. I have set up the capacity to 80GB, but the script filled up only ~7GB. Reviewers: dhruba, haobo, MarkCallaghan, xjin Reviewed By: dhruba CC: leveldb Differential Revision:"
,,0.13,rocksdb,"Add a call DisownData() to Cache, which should speed up shutdown Summary: On a shutdown, freeing memory takes a long time. If were shutting down, we dont really care about memory leaks. I added a call to Cache that will avoid freeing all objects in cache. Test Plan: I created a script to test the speedup and demonstrate how to use the call: Clean shutdown took 7.2 seconds, while fast and dirty one took 6.3 seconds. Unfortunately, the speedup is not that big, but should be bigger with bigger block_cache. I have set up the capacity to 80GB, but the script filled up only ~7GB. Reviewers: dhruba, haobo, MarkCallaghan, xjin Reviewed By: dhruba CC: leveldb Differential Revision:"
,,0.1195,rocksdb,"MergingIterator.Seek() to lazily initialize MinHeap Summary: For the use cases that prefix filtering is enabled, initializing heaps when doing MergingIterator.Seek() might introduce non-negligible costs. This patch makes it lazily done. Test Plan: make all check Reviewers: haobo,dhruba,kailiu CC: Task ID: Blame Rev:/"
,,0.0597,rocksdb,Fix memtable construction in tests/
,,0.1802,rocksdb,"Fix share_table_files bug Summary: constructor wasnt properly constructing BackupableDBOptions Test Plan: no test Reviewers: benj Reviewed By: benj CC: leveldb Differential Revision: options in backupable DB Summary: We should dump options in backupable DB log, just like with to with RocksDB. This will aid debugging. Test Plan: checked the log Reviewers: ljin Reviewed By: ljin CC: leveldb Differential Revision: fixes to BackupableDB Summary: (1) Report corruption if backup meta file has tailing data that was not read. This should fix: (also, reported similar issue) (2) Dont use OS buffer when copying file to backup directory. We dont need the file in cache since we wont be reading it twice (3) Dont delete newer backups when somebody tries to backup the diverged DB (restore from older backup, add new data, try to backup). Rather, just fail the new backup. Test Plan: backupable_db_test Reviewers: ljin, dhruba, sdong Reviewed By: ljin CC: leveldb, sdong Differential Revision:"
,,0.17600000000000002,rocksdb,"fix valgrind/Fix share_table_files bug Summary: constructor wasnt properly constructing BackupableDBOptions Test Plan: no test Reviewers: benj Reviewed By: benj CC: leveldb Differential Revision: options in backupable DB Summary: We should dump options in backupable DB log, just like with to with RocksDB. This will aid debugging. Test Plan: checked the log Reviewers: ljin Reviewed By: ljin CC: leveldb Differential Revision: fixes to BackupableDB Summary: (1) Report corruption if backup meta file has tailing data that was not read. This should fix: (also, reported similar issue) (2) Dont use OS buffer when copying file to backup directory. We dont need the file in cache since we wont be reading it twice (3) Dont delete newer backups when somebody tries to backup the diverged DB (restore from older backup, add new data, try to backup). Rather, just fail the new backup. Test Plan: backupable_db_test Reviewers: ljin, dhruba, sdong Reviewed By: ljin CC: leveldb, sdong Differential Revision:"
,,0.1746,rocksdb,"[fix] SIGSEGV when VersionEdit in MANIFEST is corrupted Summary: This was reported by our customers in task Cause: * MANIFEST file contains a VersionEdit, which contains file entries whose smallest and largest internal keys are empty. String with zero characters. Root cause of corruption was not investigated. We should report corruption when this happens. However, we currently SIGSEGV. Heres what happens: * VersionEdit encodes zero-strings happily and stores them in smallest and largest InternalKeys. InternalKey::Encode() does assert when `rep_.empty()`, but we dont assert in production environemnts. Also, we should never assert as a result of DB corruption. * As part of our ConsistencyCheck, we call GetLiveFilesMetaData() * GetLiveFilesMetadata() calls `file->largest.user_key().ToString()` * user_key() function does: 1. assert(size > 8) (ooops, no assert), 2. returns `Slice(internal_key.data(), internal_key.size() 8)` * since `internal_key.size()` is unsigned int, this call translates to `Slice(whatever, 1298471928561892576182756)`. Bazinga. Fix: * VersionEdit checks if InternalKey is valid in `VersionEdit::GetInternalKey()`. If its invalid, returns corruption. Lessons learned: * Always keep in mind that even if you `assert()`, production code will continue execution even if assert fails. * Never `assert` based on DB corruption. Assert only if the code should guarantee that assert cant fail. Test Plan: dumped offending manifest. Before: assert. Now: corruption Reviewers: dhruba, haobo, sdong Reviewed By: dhruba CC: leveldb Differential Revision: a bug in IterKey Summary: IterKey set buffer_size_ to a wrong initial value, causing it to always allocate values from heap instead of stack if the key size is smaller. Fix it. Test Plan: make all check Reviewers: haobo, ljin Reviewed By: haobo CC: igor, dhruba, yhchiang, leveldb Differential Revision: not to store copied key in std::string Summary: Move PlainTableIterators copied key from std::string local buffer to avoid paying the extra costs in std::string related to sharing. Reuse the same buffer class in DbIter. Move the class to dbformat.h. This patch improves iterator performance significantly. Running this benchmark: ./table_reader_bench The average latency is improved to about 750 nanoseconds from 1100 nanoseconds. Test Plan: Add a unit test. make all check Reviewers: haobo, ljin Reviewed By: haobo CC: igor, yhchiang, dhruba, leveldb Differential Revision:"
,,0.1435,rocksdb,"Explicitly cast char to signed char in Hash() Summary: The compilers we use treat char as signed. However, this is not guarantee of C standard and some compilers (for ARM platform for example), treat char as unsigned. Code that assumes that char is either signed or unsigned is wrong. This change explicitly casts the char to signed version. This will not break any of our use cases on x86, which, I believe are all of them. In case somebody out there is using RocksDB on ARM AND using bloom filters, theyre going to have a bad time. However, it is very unlikely that this is the case. Test Plan: sanity test with previous commit (with new sanity test) Reviewers: yhchiang, ljin, sdong Reviewed By: ljin Subscribers: dhruba, leveldb Differential Revision:"
,,0.1719,rocksdb,"Improve Backup Engine. Summary: Improve the backup engine by not deleting the corrupted backup when it is detected; instead leaving it to the client to delete the corrupted backup. Also add a BackupEngine::Open() call. Test Plan: Add check to CorruptionTest inside backupable_db_test to check that the corrupt backups are not deleted. The previous version of the code failed this test as backups were deleted, but after the changes in this commit, this test passes. Run make check to ensure that no other tests fail. Reviewers: sdong, benj, sanketh, sumeet, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision:"
,,0.0926,rocksdb,"[RocksJava] Quality improvements Summary: Addressed some FindBugs issues. Remove obsolete dbFolder cleanup Comparator tests for CF Added AbstractComparatorTest. Fixed a bug in the JNI Part about Java comparators Minor test improvements Test Plan: make rocksdbjava make jtest mvn rocksjni.pom package Reviewers: adamretter, yhchiang, ankgup87 Subscribers: dhruba Differential Revision: Extended testcases + 7% coverage + 3% branch coverage/[RocksJava] Testcase improvements/"
,,0.0599,rocksdb,[RocksJava] Testcase improvements/
,,0.1155,rocksdb,"Merge pull request from fyrz/RocksJava-DirectSlice-Fix [RocksJava] DirectSlice String termination fix/[RocksJava] DirectSlice String termination fix DirectSlice fix for non terminated String copy. This lead sometimes to problems with DirectSliceTest./Merge pull request from adamretter/java-api-fix Fix the Java API build on Mac OS X/Fix the build on Mac OS X/[RocksJava] Slice / DirectSlice improvements Summary: AssertionError when initialized with Non-Direct Buffer Tests + coverage for DirectSlice Slice sigsegv fixes when initializing from String and byte arrays Slice Tests Test Plan: Run tests without source modifications. Reviewers: yhchiang, adamretter, ankgup87 Subscribers: dhruba Differential Revision:"
,,0.2366,rocksdb,"Fix build on older compilers emplace() is not available/Fix ASAN failure with backupable DB Summary: It looks like ASAN with gcc 4.9 works better than 4.8.1. It detected this possibility of heap buffer overflow. This was in our codebase for a year :) Test Plan: COMPILE_WITH_ASAN=1 make backupable_db && ./backupable_db Reviewers: yhchiang, rven, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: memory footprint in backupable db. * Use emplace when possible. * Make FileInfo shared among all BackupMeta, instead of storing filenames. * Make checksum_value in FileInfo constant. * Reserve space beforehand if container size is known. * Make FileInfo and BackupMeta non-copyable and non-assignable to prevent future logic errors. It is very dangerous to copy BackupMeta without careful handling refcounts of FileInfo. * Remove a copy of BackupMeta when detected corrupt backup./Fix errors when using not issue extra GetFileSize() calls when loading BackupMeta./Improve Backup Engine. Summary: Improve the backup engine by not deleting the corrupted backup when it is detected; instead leaving it to the client to delete the corrupted backup. Also add a BackupEngine::Open() call. Test Plan: Add check to CorruptionTest inside backupable_db_test to check that the corrupt backups are not deleted. The previous version of the code failed this test as backups were deleted, but after the changes in this commit, this test passes. Run make check to ensure that no other tests fail. Reviewers: sdong, benj, sanketh, sumeet, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision:"
,,0.1233,rocksdb,"build: do not relink every single binary just for a timestamp Summary: Prior to this change, ""make check"" would always waste a lot of time relinking 60+ binaries. With this change, it does that only when the generated file, util/build_version.cc, changes, and that happens only when the date changes or when the current git SHA changes. This change makes some other improvements: before, there was no rule to build a deleted util/build_version.cc. If it was somehow removed, any attempt to link a program would fail. There is no longer any need for the separate file, build_tools/build_detect_version. Its functionality is now in the Makefile. * Makefile (DEPFILES): Dont filter-out util/build_version.cc. No need, and besides, removing that dependency was wrong. (date, git_sha, gen_build_version): New helper variables. (util/build_version.cc): New rule, to create this file and update it only if it would contain new information. * build_tools/build_detect_platform: Remove file. * db/db_impl.cc: Now, print only date (not the time). * util/build_version.h (rocksdb_build_compile_time): Remove declaration. No longer used. Test Plan: Run ""make check"" twice, and note that the second time no linking is performed. Remove util/build_version.cc and ensure that any ""make"" command regenerates it before doing anything else. Run this: strings librocksdb.a|grep _build_. That prints output including the following: rocksdb_build_git_date:2015-02-19 rocksdb_build_git_sha:2.8.fb-1792-g3cb6cc0 Reviewers: ljin, sdong, igor Reviewed By: igor Subscribers: dhruba Differential Revision:"
,,0.293,rocksdb,"rocksdb: Fixed Dead assignment and Dead initialization scan-build warnings Summary: This diff contains trivial fixes for 6 scan-build warnings: **db/c_test.c** `db` variable is never read. Removed assignment. scan-build report: **db/db_iter.cc** `skipping` local variable is assigned to false. Then in the next switch block the only ""non return"" case assign `skipping` to true, the rest cases dont use it and all do return. scan-build report: **db/log_reader.cc** In `bool Reader::SkipToInitialBlock()` `offset_in_block` local variable is assigned to 0 `if (offset_in_block > kBlockSize 6)` and then never used. Removed the assignment and renamed it to `initial_offset_in_block` to avoid confusion. scan-build report: In `bool Reader::ReadRecord(Slice* record, std::string* scratch)` local variable `in_fragmented_record` in switch case `kFullType` block is assigned to false and then does `return` without use. In the other switch case `kFirstType` block the same `in_fragmented_record` is assigned to false, but later assigned to true without prior use. Removed assignment for both cases. scan-build reprots: **table/plain_table_key_coding.cc** Local variable `user_key_size` is assigned when declared. But then in both places where it is used assigned to `static_cast<uint32_t>(key.size() 8)`. Changed to initialize the variable to the proper value in declaration. scan-build report: **tools/db_stress.cc** Missing `break` in switch case block. This seems to be a bug. Added missing `break`. Test Plan: Make sure all tests are passing and scan-build does not report Dead assignment and Dead initialization bugs. ```lang=bash % make check % make analyze ``` Reviewers: meyering, igor, kradhakrishnan, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision:"
,,0.1382,rocksdb,Merge pull request from yuslepukhin/fix_now_microsec_win Fix WinEnv::NowMicros/Fix WinEnv::NowMicrosec * std::chrono does not provide enough granularity for microsecs and periodically emits duplicates * the bug is manifested in log rotation logic where we get duplicate log file names and loose previous log content * msvc does not imlement COW on std::strings adjusted the test to use refs in the loops as auto does not retain ref info * adjust auto_log rotation test with Windows specific command to remove a folder. The test previously worked because we have unix utils installed in house but this may not be the case for everyone./
,,0.1341,rocksdb,"Better error handling in BackupEngine Summary: Couple of changes here: * NewBackupEngine() and NewReadOnlyBackupEngine() are now removed. They were deprecated since RocksDB 3.8. Changing these to new functions should be pretty straight-forward. As a followup, Ill fix all fbcode callsights * Instead of initializing backup engine in the constructor, we initialize it in a separate function now. That way, we can catch all errors and return appropriate status code. * We catch all errors during initializations and return them to the client properly. * Added new tests to backupable_db_test, to make sure that we cant open BackupEngine when there are Env errors. * Transitioned backupable_db_test to use BackupEngine rather than BackupableDB. From the two available APIs, judging by the current use-cases, it looks like BackupEngine API won. Its much more flexible since it doesnt require StackableDB. Test Plan: Added a new unit test to backupable_db_test Reviewers: yhchiang, sdong, AaronFeldman Reviewed By: AaronFeldman Subscribers: dhruba, leveldb Differential Revision:"
,,0.2342,rocksdb,"crash_test to trigger some less frequent crash point more frequently Summary: crash_test still has a very low chance to hit some crash point. Have another mode for covering them more likely. Test Plan: Run crash_test and see db_stress is called with expected prameters. Reviewers: kradhakrishnan, igor, anthony, rven, IslamAbdelRahman, yhchiang Reviewed By: yhchiang Subscribers: leveldb, dhruba Differential Revision: users to disable some kill points in db_stress Summary: Give a name for every kill point, and allow users to disable some kill points based on prefixes. The kill points can be passed by db_stress through a command line paramter. This provides a way for users to boost the chance of triggering low frequency kill points This allow follow up changes in crash test scripts to improve crash test coverage. Test Plan: Manually run db_stress with variable values of and Like this: Reviewers: igor, kradhakrishnan, rven, IslamAbdelRahman, yhchiang Reviewed By: yhchiang Subscribers: leveldb, dhruba Differential Revision:"
,,0.4408,rocksdb,"Support for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.2485,rocksdb,"Allow users to disable some kill points in db_stress Summary: Give a name for every kill point, and allow users to disable some kill points based on prefixes. The kill points can be passed by db_stress through a command line paramter. This provides a way for users to boost the chance of triggering low frequency kill points This allow follow up changes in crash test scripts to improve crash test coverage. Test Plan: Manually run db_stress with variable values of and Like this: Reviewers: igor, kradhakrishnan, rven, IslamAbdelRahman, yhchiang Reviewed By: yhchiang Subscribers: leveldb, dhruba Differential Revision:"
,,0.3483,rocksdb,"Address code review comments both GH and internal Fix compilation issues on GCC/CLANG Address Windows Release test build issues due to Sync/Refactor to support file_reader_writer on Windows. Summary. A change Has attempted to move common functionality out of platform dependent code to a new facility called file_reader_writer. This includes: perf counters Buffering RateLimiting However, the change did not attempt to refactor Windows code. To mitigate, we introduce new quering interfaces such as UseOSBuffer(), GetRequiredBufferAlignment() and ReaderWriterForward() for pure forwarding where required. Introduce WritableFile got a new method Truncate(). This is to communicate to the file as to how much data it has on close. When space is pre-allocated on Linux it is filled with zeros implicitly, no such thing exist on Windows so we must truncate file on close. When operating in unbuffered mode the last page is filled with zeros but we still want to truncate. Previously, Close() would take care of it but now buffer management is shifted to the wrappers and the file has no idea about the file true size. This means that Close() on the wrapper level must always include Truncate() as well as wrapper __dtor should call Close() and against double Close(). Move buffered/unbuffered write logic to the wrapper. Utilize Aligned buffer class. Adjust tests and implement Truncate() where necessary. Come up with reasonable defaults for new virtual interfaces. Forward calls for RandomAccessReadAhead class to avoid double buffering and locking (double locking in unbuffered mode on WIndows)./ReadaheadRandomAccessFile userspace readahead Summary: ReadaheadRandomAccessFile acts as a transparent layer on top of RandomAccessFile. When a Read() request is issued, it issues a much bigger request to the OS and caches the result. When a new request comes in and we already have the data cached, it doesnt have to issue any requests to the OS. We add ReadaheadRandomAccessFile layer only when file is read during compactions. D45105 was incorrectly closed by Phabricator because I committed it to a separate branch (not master), so Im resubmitting the diff. Test Plan: make check Reviewers: MarkCallaghan, sdong Reviewed By: sdong Subscribers: leveldb, dhruba Differential Revision:"
,,0.3766,rocksdb,"Fix WritableFileWriter::Append() return Summary: It looks like WritableFileWriter::Append() was returning OK() even when there is an error Test Plan: make check Reviewers: sdong, yhchiang, anthony, rven, kradhakrishnan, igor Reviewed By: igor Subscribers: dhruba Differential Revision: iOS build Summary: We dont yet have a CI build for iOS, so our iOS compile gets broken sometimes. Most of the errors are from assumption that size_t is 64-bit, while its actually 32-bit on some (all?) iOS platforms. This diff fixes the compile. Test Plan: TARGET_OS=IOS make static_lib Observe there are no warnings Reviewers: sdong, anthony, IslamAbdelRahman, kradhakrishnan, yhchiang Reviewed By: yhchiang Subscribers: dhruba, leveldb Differential Revision: users to disable some kill points in db_stress Summary: Give a name for every kill point, and allow users to disable some kill points based on prefixes. The kill points can be passed by db_stress through a command line paramter. This provides a way for users to boost the chance of triggering low frequency kill points This allow follow up changes in crash test scripts to improve crash test coverage. Test Plan: Manually run db_stress with variable values of and Like this: Reviewers: igor, kradhakrishnan, rven, IslamAbdelRahman, yhchiang Reviewed By: yhchiang Subscribers: leveldb, dhruba Differential Revision: code review comments both GH and internal Fix compilation issues on GCC/CLANG Address Windows Release test build issues due to Sync/Refactor to support file_reader_writer on Windows. Summary. A change Has attempted to move common functionality out of platform dependent code to a new facility called file_reader_writer. This includes: perf counters Buffering RateLimiting However, the change did not attempt to refactor Windows code. To mitigate, we introduce new quering interfaces such as UseOSBuffer(), GetRequiredBufferAlignment() and ReaderWriterForward() for pure forwarding where required. Introduce WritableFile got a new method Truncate(). This is to communicate to the file as to how much data it has on close. When space is pre-allocated on Linux it is filled with zeros implicitly, no such thing exist on Windows so we must truncate file on close. When operating in unbuffered mode the last page is filled with zeros but we still want to truncate. Previously, Close() would take care of it but now buffer management is shifted to the wrappers and the file has no idea about the file true size. This means that Close() on the wrapper level must always include Truncate() as well as wrapper __dtor should call Close() and against double Close(). Move buffered/unbuffered write logic to the wrapper. Utilize Aligned buffer class. Adjust tests and implement Truncate() where necessary. Come up with reasonable defaults for new virtual interfaces. Forward calls for RandomAccessReadAhead class to avoid double buffering and locking (double locking in unbuffered mode on WIndows)./ReadaheadRandomAccessFile userspace readahead Summary: ReadaheadRandomAccessFile acts as a transparent layer on top of RandomAccessFile. When a Read() request is issued, it issues a much bigger request to the OS and caches the result. When a new request comes in and we already have the data cached, it doesnt have to issue any requests to the OS. We add ReadaheadRandomAccessFile layer only when file is read during compactions. D45105 was incorrectly closed by Phabricator because I committed it to a separate branch (not master), so Im resubmitting the diff. Test Plan: make check Reviewers: MarkCallaghan, sdong Reviewed By: sdong Subscribers: leveldb, dhruba Differential Revision:"
,,0.4236,rocksdb,"Fix WritableFileWriter::Append() return Summary: It looks like WritableFileWriter::Append() was returning OK() even when there is an error Test Plan: make check Reviewers: sdong, yhchiang, anthony, rven, kradhakrishnan, igor Reviewed By: igor Subscribers: dhruba Differential Revision: to support file_reader_writer on Windows. Summary. A change Has attempted to move common functionality out of platform dependent code to a new facility called file_reader_writer. This includes: perf counters Buffering RateLimiting However, the change did not attempt to refactor Windows code. To mitigate, we introduce new quering interfaces such as UseOSBuffer(), GetRequiredBufferAlignment() and ReaderWriterForward() for pure forwarding where required. Introduce WritableFile got a new method Truncate(). This is to communicate to the file as to how much data it has on close. When space is pre-allocated on Linux it is filled with zeros implicitly, no such thing exist on Windows so we must truncate file on close. When operating in unbuffered mode the last page is filled with zeros but we still want to truncate. Previously, Close() would take care of it but now buffer management is shifted to the wrappers and the file has no idea about the file true size. This means that Close() on the wrapper level must always include Truncate() as well as wrapper __dtor should call Close() and against double Close(). Move buffered/unbuffered write logic to the wrapper. Utilize Aligned buffer class. Adjust tests and implement Truncate() where necessary. Come up with reasonable defaults for new virtual interfaces. Forward calls for RandomAccessReadAhead class to avoid double buffering and locking (double locking in unbuffered mode on WIndows)./"
,,0.1003,rocksdb,"Remove ldb HexToString methods usage of sscanf Summary: Fix hex2String performance issues by removing sscanf dependency. Also fixed some edge case handling (odd length, bad input). Test Plan: Created a test file which called old and new implementation, and validated results are the same. Ill paste results in the phabricator diff. Reviewers: igor, rven, anthony, IslamAbdelRahman, kradhakrishnan, yhchiang, sdong Reviewed By: sdong Subscribers: thatsafunnyname, leveldb, dhruba Differential Revision:"
,,0.185,rocksdb,"New amalgamation target This commit adds two new targets to the Makefile: rocksdb.cc and rocksdb.h These files, when combined with the c.h header, are a self-contained RocksDB source distribution called an amalgamation. (The name comes from SQLites, which is similar in concept.) The main benefit of an amalgamation is that its very easy to drop into a new project. It also compiles faster compared to compiling individual source files and potentially gives the compiler more opportunity to make optimizations since it can see all functions at once. rocksdb.cc and rocksdb.h are generated by a new script, amalgamate.py. A detailed description of how amalgamate.py works is in a comment at the top of the file. There are also some small changes to existing files to enable the amalgamation: * Use quotes for includes in unity build * Fix an old header inclusion in util/xfunc.cc * Move some includes outside ifdef in util/env_hdfs.cc * Separate out tool sources in Makefile so they wont be included in unity.cc * Unity build now produces a static library Closes"
,,0.4031,rocksdb,"Revert ""Avoid to reply on ROCKSDB_FALLOCATE_PRESENT in include/posix/io_posix.h"" This reverts commit c37223c0836d1637c628f9cef3acb5b55ad3d51b./Avoid to reply on ROCKSDB_FALLOCATE_PRESENT in include/posix/io_posix.h Summary: include/posix/io_posix.h should not depend on ROCKSDB_FALLOCATE_PRESENT. Remove it. Test Plan: Build it with both of ROCKSDB_FALLOCATE_PRESENT defined and not defined. Reviewers: rven, yhchiang, anthony, kradhakrishnan, IslamAbdelRahman, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision: to support file_reader_writer on Windows. Summary. A change Has attempted to move common functionality out of platform dependent code to a new facility called file_reader_writer. This includes: perf counters Buffering RateLimiting However, the change did not attempt to refactor Windows code. To mitigate, we introduce new quering interfaces such as UseOSBuffer(), GetRequiredBufferAlignment() and ReaderWriterForward() for pure forwarding where required. Introduce WritableFile got a new method Truncate(). This is to communicate to the file as to how much data it has on close. When space is pre-allocated on Linux it is filled with zeros implicitly, no such thing exist on Windows so we must truncate file on close. When operating in unbuffered mode the last page is filled with zeros but we still want to truncate. Previously, Close() would take care of it but now buffer management is shifted to the wrappers and the file has no idea about the file true size. This means that Close() on the wrapper level must always include Truncate() as well as wrapper __dtor should call Close() and against double Close(). Move buffered/unbuffered write logic to the wrapper. Utilize Aligned buffer class. Adjust tests and implement Truncate() where necessary. Come up with reasonable defaults for new virtual interfaces. Forward calls for RandomAccessReadAhead class to avoid double buffering and locking (double locking in unbuffered mode on WIndows)./"
,,0.4732,rocksdb,"Support for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision: wrong constants in db_test_util Summary: Fix two constants in WaitFor() that multiply a value with 000 instead of 1000. Test Plan: make clean all check Reviewers: rven, anthony, yhchiang, aekmekji, sdong, MarkCallaghan, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision: to support file_reader_writer on Windows. Summary. A change Has attempted to move common functionality out of platform dependent code to a new facility called file_reader_writer. This includes: perf counters Buffering RateLimiting However, the change did not attempt to refactor Windows code. To mitigate, we introduce new quering interfaces such as UseOSBuffer(), GetRequiredBufferAlignment() and ReaderWriterForward() for pure forwarding where required. Introduce WritableFile got a new method Truncate(). This is to communicate to the file as to how much data it has on close. When space is pre-allocated on Linux it is filled with zeros implicitly, no such thing exist on Windows so we must truncate file on close. When operating in unbuffered mode the last page is filled with zeros but we still want to truncate. Previously, Close() would take care of it but now buffer management is shifted to the wrappers and the file has no idea about the file true size. This means that Close() on the wrapper level must always include Truncate() as well as wrapper __dtor should call Close() and against double Close(). Move buffered/unbuffered write logic to the wrapper. Utilize Aligned buffer class. Adjust tests and implement Truncate() where necessary. Come up with reasonable defaults for new virtual interfaces. Forward calls for RandomAccessReadAhead class to avoid double buffering and locking (double locking in unbuffered mode on WIndows)./Add Subcompactions to Universal Compaction Unit Tests Summary: Now that the approach to parallelizing L0-L1 level-based compactions by breaking the compaction job into subcompactions is being extended to apply to universal compactions as well, the unit tests need to account for this and run the universal compaction tests with subcompactions both enabled and disabled. Test Plan: make all && make check Reviewers: sdong, igor, noetzli, anthony, yhchiang Reviewed By: yhchiang Subscribers: dhruba Differential Revision:"
,,0.3831,rocksdb,"Fix iOS build Summary: We dont yet have a CI build for iOS, so our iOS compile gets broken sometimes. Most of the errors are from assumption that size_t is 64-bit, while its actually 32-bit on some (all?) iOS platforms. This diff fixes the compile. Test Plan: TARGET_OS=IOS make static_lib Observe there are no warnings Reviewers: sdong, anthony, IslamAbdelRahman, kradhakrishnan, yhchiang Reviewed By: yhchiang Subscribers: dhruba, leveldb Differential Revision: for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision: should fail if the column family has been dropped Summary: This patch finally fixes the ColumnFamilyTest.ReadDroppedColumnFamily test. The test has been failing very sporadically and it was hard to repro. However, I managed to write a new tests that reproes the failure deterministically. Heres what happens: 1. We start the flush for the column family 2. We check if the column family was dropped here: 3. This check goes through, ends up in InstallMemtableFlushResults() and it goes into LogAndApply() 4. At about this time, we start dropping the column family. Dropping the column family process gets to LogAndApply() at about the same time as LogAndApply() from flush process 5. Drop column family goes through LogAndApply() first, marking the column family as dropped. 6. Flush process gets woken up and gets a chance to write to the MANIFEST. However, this is where it gets stuck: 7. We see that the column family was dropped, so there is no need to write to the MANIFEST. We return OK. 8. Flush gets OK back from LogAndApply() and it deletes the memtable, thinking that the data is now safely persisted to sst file. The fix is pretty simple. Instead of OK, we return ShutdownInProgress. This is not really true, but we have been using this status code to also mean ""this operation was canceled because the column family has been dropped"". The fix is only one LOC. All other code is related to tests. I added a new test that reproes the failure. I also moved SleepingBackgroundTask to util/testutil.h (because I needed it in column_family_test for my new test). Theres plenty of other places where we reimplement SleepingBackgroundTask, but Ill address that in a separate commit. Test Plan: 1. new test 2. make check 3. Make sure the ColumnFamilyTest.ReadDroppedColumnFamily doesnt fail on Travis: Reviewers: yhchiang, anthony, IslamAbdelRahman, kradhakrishnan, rven, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: to support file_reader_writer on Windows. Summary. A change Has attempted to move common functionality out of platform dependent code to a new facility called file_reader_writer. This includes: perf counters Buffering RateLimiting However, the change did not attempt to refactor Windows code. To mitigate, we introduce new quering interfaces such as UseOSBuffer(), GetRequiredBufferAlignment() and ReaderWriterForward() for pure forwarding where required. Introduce WritableFile got a new method Truncate(). This is to communicate to the file as to how much data it has on close. When space is pre-allocated on Linux it is filled with zeros implicitly, no such thing exist on Windows so we must truncate file on close. When operating in unbuffered mode the last page is filled with zeros but we still want to truncate. Previously, Close() would take care of it but now buffer management is shifted to the wrappers and the file has no idea about the file true size. This means that Close() on the wrapper level must always include Truncate() as well as wrapper __dtor should call Close() and against double Close(). Move buffered/unbuffered write logic to the wrapper. Utilize Aligned buffer class. Adjust tests and implement Truncate() where necessary. Come up with reasonable defaults for new virtual interfaces. Forward calls for RandomAccessReadAhead class to avoid double buffering and locking (double locking in unbuffered mode on WIndows)./"
,,0.3802,rocksdb,"env: add ReuseWritableFile Add an environment method to reuse an existing file. Provide a generic implementation that does a simple rename + open (writeable), and also a posix variant that is more careful about error handling (if we fail to open, do not rename, etc.). Signed-off-by: Sage Weil boolean variable to guard fallocate() calls Summary: Added boolean variable to guard fallocate() calls. Set to false to prevent space leaks when tests fail. Test Plan: Compliles Set to false and ran log device tests Reviewers: sdong, lovro, igor Reviewed By: igor Subscribers: dhruba Differential Revision: code review comments both GH and internal Fix compilation issues on GCC/CLANG Address Windows Release test build issues due to Sync/Refactor to support file_reader_writer on Windows. Summary. A change Has attempted to move common functionality out of platform dependent code to a new facility called file_reader_writer. This includes: perf counters Buffering RateLimiting However, the change did not attempt to refactor Windows code. To mitigate, we introduce new quering interfaces such as UseOSBuffer(), GetRequiredBufferAlignment() and ReaderWriterForward() for pure forwarding where required. Introduce WritableFile got a new method Truncate(). This is to communicate to the file as to how much data it has on close. When space is pre-allocated on Linux it is filled with zeros implicitly, no such thing exist on Windows so we must truncate file on close. When operating in unbuffered mode the last page is filled with zeros but we still want to truncate. Previously, Close() would take care of it but now buffer management is shifted to the wrappers and the file has no idea about the file true size. This means that Close() on the wrapper level must always include Truncate() as well as wrapper __dtor should call Close() and against double Close(). Move buffered/unbuffered write logic to the wrapper. Utilize Aligned buffer class. Adjust tests and implement Truncate() where necessary. Come up with reasonable defaults for new virtual interfaces. Forward calls for RandomAccessReadAhead class to avoid double buffering and locking (double locking in unbuffered mode on WIndows)./Make WinEnv::NowMicros return system time Previous change for the function made use of the QueryPerformanceCounter to return microseconds values that do not repeat as std::chrono::system_clock returned values that made auto_roll_logger_test fail. The interface documentation does not state that we need to return system time describing the return value as a number of microsecs since some moment in time. However, because on Linux it is implemented using gettimeofday various pieces of code (such as GenericRateLimiter) took advantage of that and make use of NowMicros() as a system timestamp. Thus the previous change broke rate_limiter_test on Windows. In addition, the interface name NowMicros() suggests that it is actually a timestamp so people use it as such. This change makes use of the new system call on Windows that returns system time with required precision. This change preserves the fix for auto_roll_logger_test and fixes rate_limiter_test. Note that DBTest.RateLimitingTest still fails due to a separately reported issue./"
,,0.4325,rocksdb,"Support for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.3974,rocksdb,"Merge pull request from aloukissas/unused_param Fix unused parameter warnings in db.h/Fix unused parameter warnings./Fix unused parameter warnings./fixed formatting. thanks for pointing me at `make format`/Support for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.3308,rocksdb,"Fix a bug in GetApproximateSizes Summary: Need to pass through the memtable parameter. Test Plan: built, tested through myrocks Reviewers: igor, sdong, rven Reviewed By: rven Subscribers: dhruba Differential Revision: the clang compilation failure Summary: As above. Test Plan: USE_CLANG=1 make check Reviewers: igor Reviewed By: igor Subscribers: dhruba Differential Revision: APIs PauseBackgroundWork() and ContinueBackgroundWork() Summary: To support a new MongoDB capability, we need to make sure that we dont do any IO for a short period of time. For background, see: * * To implement that, I add a new API calls PauseBackgroundWork() and ContinueBackgroundWork() which reuse the capability we already have in place for RefitLevel() function. Test Plan: Added a new test in db_test. Made sure that test fails when PauseBackgroundWork() is commented out. Reviewers: IslamAbdelRahman, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.3647,rocksdb,"Return MergeInProgress when fetching from transactions or WBWI with overwrite_key Summary: WriteBatchWithIndex::GetFromBatchAndDB only works correctly for overwrite_key=false. Transactions use overwrite_key=true (since WriteBatchWithIndex::GetIteratorWithBase only works when overwrite_key=true). So currently, Transactions could return incorrectly merged results when calling Get/GetForUpdate(). Until a permanent fix can be put in place, Transaction::Get[ForUpdate] and WriteBatchWithIndex::GetFromBatch[AndDB] will now return MergeInProgress if the most recent write to a key in the batch is a Merge. Test Plan: more tests Reviewers: sdong, yhchiang, rven, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision: SingleDelete support in WriteBatchWithIndex Summary: Fixed some bugs in using SingleDelete on a WriteBatchWithIndex and added some tests. Test Plan: new tests Reviewers: sdong, yhchiang, rven, kradhakrishnan, IslamAbdelRahman, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision: for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.3513,rocksdb,"bloom hit/miss stats for SST and memtable Summary: hit and miss bloom filter stats for memtable and SST stats added to perf_context struct key matches and prefix matches combined into one stat Test Plan: unit test veryfing the functionality added, see BloomStatsTest in db_test.cc for details Reviewers: yhchiang, igor, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.1254,rocksdb,"Remove the need for LATEST_BACKUP in BackupEngine Summary: In the first implementation of BackupEngine, LATEST_BACKUP was the commit point. The backup became committed after the write to LATEST_BACKUP completed. However, we can avoid the need for LATEST_BACKUP. Instead of write to LATEST_BACKUP, the commit point can be the rename from `meta/<backup_id>.tmp` to `meta/<backup_id>`. Once we see that there exists a file `meta/<backup_id>` (without tmp), we can assume that backup is valid. In this diff, we still write out the file LATEST_BACKUP. We need to do this so that we can maintain backward compatibility. However, the new version doesnt depend on this file anymore. We get the latest backup by `ls`-ing `meta` directory. This diff depends on D41925 Test Plan: Adjusted backupable_db_test to this new behavior Reviewers: benj, yhchiang, sdong, AaronFeldman Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: pull request from yuslepukhin/address_noexcept_windows Address noexcept and const integer lambda capture on win/s/NOEXCEPT/ROCKSDB_NOEXCEPT/Address noexcept and const integer lambda capture VS 2013 does not support noexcept. Complains about usage of ineteger constant within lambda requiring explicit capture./"
,,0.3707,rocksdb,"Return MergeInProgress when fetching from transactions or WBWI with overwrite_key Summary: WriteBatchWithIndex::GetFromBatchAndDB only works correctly for overwrite_key=false. Transactions use overwrite_key=true (since WriteBatchWithIndex::GetIteratorWithBase only works when overwrite_key=true). So currently, Transactions could return incorrectly merged results when calling Get/GetForUpdate(). Until a permanent fix can be put in place, Transaction::Get[ForUpdate] and WriteBatchWithIndex::GetFromBatch[AndDB] will now return MergeInProgress if the most recent write to a key in the batch is a Merge. Test Plan: more tests Reviewers: sdong, yhchiang, rven, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision: SingleDelete support in WriteBatchWithIndex Summary: Fixed some bugs in using SingleDelete on a WriteBatchWithIndex and added some tests. Test Plan: new tests Reviewers: sdong, yhchiang, rven, kradhakrishnan, IslamAbdelRahman, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision: for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.3692,rocksdb,"Return MergeInProgress when fetching from transactions or WBWI with overwrite_key Summary: WriteBatchWithIndex::GetFromBatchAndDB only works correctly for overwrite_key=false. Transactions use overwrite_key=true (since WriteBatchWithIndex::GetIteratorWithBase only works when overwrite_key=true). So currently, Transactions could return incorrectly merged results when calling Get/GetForUpdate(). Until a permanent fix can be put in place, Transaction::Get[ForUpdate] and WriteBatchWithIndex::GetFromBatch[AndDB] will now return MergeInProgress if the most recent write to a key in the batch is a Merge. Test Plan: more tests Reviewers: sdong, yhchiang, rven, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision: SingleDelete support in WriteBatchWithIndex Summary: Fixed some bugs in using SingleDelete on a WriteBatchWithIndex and added some tests. Test Plan: new tests Reviewers: sdong, yhchiang, rven, kradhakrishnan, IslamAbdelRahman, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision: for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.3905,rocksdb,"Return MergeInProgress when fetching from transactions or WBWI with overwrite_key Summary: WriteBatchWithIndex::GetFromBatchAndDB only works correctly for overwrite_key=false. Transactions use overwrite_key=true (since WriteBatchWithIndex::GetIteratorWithBase only works when overwrite_key=true). So currently, Transactions could return incorrectly merged results when calling Get/GetForUpdate(). Until a permanent fix can be put in place, Transaction::Get[ForUpdate] and WriteBatchWithIndex::GetFromBatch[AndDB] will now return MergeInProgress if the most recent write to a key in the batch is a Merge. Test Plan: more tests Reviewers: sdong, yhchiang, rven, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision: pull request from yuslepukhin/fix_write_batch_win_const_expr Fix Windows constexpr issue and column_family_test in Release./Fix Windows constexpr issue and column_family_test in Release./Support for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.4283,rocksdb,"Support for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.3232,rocksdb,"Support for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision: code review comments both GH and internal Fix compilation issues on GCC/CLANG Address Windows Release test build issues due to Sync/DBIter to out extra keys with higher sequence numbers when changing direction from forward to backward Summary: When DBIter changes iterating direction from forward to backward, it might see some much larger keys with higher sequence ID. With this commit, these rows will be actively filtered out. It should fix existing disabled tests in db_iter_test. This may not be a perfect fix, but it introduces least impact on existing codes, in order to be safe. Test Plan: Enable existing tests and make sure they pass. Add a new test DBIterWithMergeIterTest.InnerMergeIteratorDataRace8. Also run all existing tests. Reviewers: yhchiang, rven, anthony, IslamAbdelRahman, kradhakrishnan, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision: add more test cases for the data race bug Summary: Add more test cases of data race causing wrong iterating results. Tag tests not passing as DISABLED_ Test Plan: Run the tests Reviewers: igor, rven, IslamAbdelRahman, anthony, kradhakrishnan, yhchiang Reviewed By: yhchiang Subscribers: tnovak, leveldb, dhruba Differential Revision:"
,,0.3385,rocksdb,"Enable Windows warnings C4307 C4309 C4512 C4701 Enable C4307 operator : integral constant overflow Longs and ints on Windows are 32-bit hence the overflow Enable C4309 conversion : truncation of constant value Enable C4512 class : assignment operator could not be generated Enable C4701 Potentially uninitialized local variable name used/Fix 80 character limit issue./Fix benchmarks under ROCKSDB_LITE Summary: Fix db_bench and memtablerep_bench under ROCKSDB_LITE Test Plan: OPT=-DROCKSDB_LITE make db_bench OPT=-DROCKSDB_LITE make memtablerep_bench make db_bench make memtablerep_bench Reviewers: yhchiang, anthony, rven, igor, sdong Reviewed By: sdong Subscribers: dhruba Differential Revision: for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision: options.hard_pending_compaction_bytes_limit to stop writes if compaction lagging behind Summary: Add an option to stop writes if compaction lefts behind. If estimated pending compaction bytes is more than threshold specified by options.hard_pending_compaction_bytes_liimt, writes will stop until compactions are cleared to under the threshold. Test Plan: Add unit test DBTest.HardLimit Reviewers: rven, kradhakrishnan, anthony, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: MarkCallaghan, leveldb, dhruba Differential Revision: to support file_reader_writer on Windows. Summary. A change Has attempted to move common functionality out of platform dependent code to a new facility called file_reader_writer. This includes: perf counters Buffering RateLimiting However, the change did not attempt to refactor Windows code. To mitigate, we introduce new quering interfaces such as UseOSBuffer(), GetRequiredBufferAlignment() and ReaderWriterForward() for pure forwarding where required. Introduce WritableFile got a new method Truncate(). This is to communicate to the file as to how much data it has on close. When space is pre-allocated on Linux it is filled with zeros implicitly, no such thing exist on Windows so we must truncate file on close. When operating in unbuffered mode the last page is filled with zeros but we still want to truncate. Previously, Close() would take care of it but now buffer management is shifted to the wrappers and the file has no idea about the file true size. This means that Close() on the wrapper level must always include Truncate() as well as wrapper __dtor should call Close() and against double Close(). Move buffered/unbuffered write logic to the wrapper. Utilize Aligned buffer class. Adjust tests and implement Truncate() where necessary. Come up with reasonable defaults for new virtual interfaces. Forward calls for RandomAccessReadAhead class to avoid double buffering and locking (double locking in unbuffered mode on WIndows)./better db_bench options for transactions Summary: Pessimistic Transaction expiration time checking currently causes a performace regression, Lets disable it in db_bench by default. Also, in order to be able to better tune how much contention were simulating, added new optinos to set lock timeout and snapshot. Test Plan: run db_bench randomtranansaction Reviewers: sdong, igor, yhchiang, MarkCallaghan Reviewed By: MarkCallaghan Subscribers: dhruba, leveldb Differential Revision: userspace readahead Summary: ReadaheadRandomAccessFile acts as a transparent layer on top of RandomAccessFile. When a Read() request is issued, it issues a much bigger request to the OS and caches the result. When a new request comes in and we already have the data cached, it doesnt have to issue any requests to the OS. We add ReadaheadRandomAccessFile layer only when file is read during compactions. D45105 was incorrectly closed by Phabricator because I committed it to a separate branch (not master), so Im resubmitting the diff. Test Plan: make check Reviewers: MarkCallaghan, sdong Reviewed By: sdong Subscribers: leveldb, dhruba Differential Revision: race condition in DBTest.DynamicMemtableOptions Summary: This patch fixes a race condition in DBTEst.DynamicMemtableOptions. In rare cases, it was possible that the main thread would fill up both memtables before the flush job acquired its work. Then, the flush job was flushing both memtables together, producing only one L0 file while the test expected two. Now, the test waits for flushes to finish earlier, to make sure that the memtables are flushed in separate flush jobs. Test Plan: Insert ""usleep(10000);"" after ""IOSTATS_SET_THREAD_POOL_ID(Env::Priority::HIGH);"" in BGWorkFlush() to make the issue more likely. Then test with: make db_test && time while ./db_test do true; done Reviewers: rven, sdong, yhchiang, anthony, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision:"
,,0.4519,rocksdb,"Refactor to support file_reader_writer on Windows. Summary. A change Has attempted to move common functionality out of platform dependent code to a new facility called file_reader_writer. This includes: perf counters Buffering RateLimiting However, the change did not attempt to refactor Windows code. To mitigate, we introduce new quering interfaces such as UseOSBuffer(), GetRequiredBufferAlignment() and ReaderWriterForward() for pure forwarding where required. Introduce WritableFile got a new method Truncate(). This is to communicate to the file as to how much data it has on close. When space is pre-allocated on Linux it is filled with zeros implicitly, no such thing exist on Windows so we must truncate file on close. When operating in unbuffered mode the last page is filled with zeros but we still want to truncate. Previously, Close() would take care of it but now buffer management is shifted to the wrappers and the file has no idea about the file true size. This means that Close() on the wrapper level must always include Truncate() as well as wrapper __dtor should call Close() and against double Close(). Move buffered/unbuffered write logic to the wrapper. Utilize Aligned buffer class. Adjust tests and implement Truncate() where necessary. Come up with reasonable defaults for new virtual interfaces. Forward calls for RandomAccessReadAhead class to avoid double buffering and locking (double locking in unbuffered mode on WIndows)./Merge pull request from yuslepukhin/address_windows_build Address windows build issues caused by introducing Subcompaction/Address windows build issues Intro SubCompactionState move functionality copy functionality SyncPoint in tests for Windows Release builds/Address windows build issues Intro SubCompactionState move functionality copy functionality SyncPoint in tests for Windows Release builds/"
,,0.4408,rocksdb,"Support for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.4011,rocksdb,"Dont merge WriteBatch-es if WAL is disabled Summary: Theres no need for WriteImpl to flatten the write batch group into a single WriteBatch if the WAL is disabled. This diff moves the flattening into the WAL step, and skips flattening entirely if it isnt needed. Its good for about 5% speedup on a multi-threaded workload with no WAL. This diff also adds clarifying comments about the chance for partial failure of WriteBatchInternal::InsertInto, and always sets bg_error_ if the memtable state diverges from the logged state or if a WriteBatch succeeds only partially. Benchmark for speedup: db_bench Test Plan: asserts + make check Reviewers: sdong, igor Reviewed By: igor Subscribers: dhruba Differential Revision: for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.4315,rocksdb,"Support for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.3591,rocksdb,"Fixed a bug which causes rocksdb.flush.write.bytes stat is always zero Summary: Fixed a bug which causes rocksdb.flush.write.bytes stat is always zero Test Plan: augment existing db_test Reviewers: sdong, anthony, IslamAbdelRahman, igor Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision: for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.4304,rocksdb,"Support for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.4418,rocksdb,"Support for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.4356,rocksdb,"Support for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.4073,rocksdb,"Dont merge WriteBatch-es if WAL is disabled Summary: Theres no need for WriteImpl to flatten the write batch group into a single WriteBatch if the WAL is disabled. This diff moves the flattening into the WAL step, and skips flattening entirely if it isnt needed. Its good for about 5% speedup on a multi-threaded workload with no WAL. This diff also adds clarifying comments about the chance for partial failure of WriteBatchInternal::InsertInto, and always sets bg_error_ if the memtable state diverges from the logged state or if a WriteBatch succeeds only partially. Benchmark for speedup: db_bench Test Plan: asserts + make check Reviewers: sdong, igor Reviewed By: igor Subscribers: dhruba Differential Revision: for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.3011,rocksdb,"Fix regression failure in PrefixTest.PrefixValid Summary: Use IterKey to store prefix_start_ so that it doesnt get freed Test Plan: PrefixTest.PrefixValid Reviewers: anthony, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: dhruba Differential Revision: iterating only shows keys in prefix Summary: MyRocks testing found an issue that while iterating over keys that are outside the prefix, sometimes wrong results were seen for keys outside the prefix. We now tighten the range of keys seen with a new read option called prefix_seen_at_start. This remembers the starting prefix and then compares it on a Next for equality of prefix. If they are from a different prefix, it sets valid to false. Test Plan: PrefixTest.PrefixValid Reviewers: IslamAbdelRahman, sdong, yhchiang, anthony Reviewed By: anthony Subscribers: spetrunia, hermanlee4, yoshinorim, dhruba, leveldb Differential Revision: for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision: to out extra keys with higher sequence numbers when changing direction from forward to backward Summary: When DBIter changes iterating direction from forward to backward, it might see some much larger keys with higher sequence ID. With this commit, these rows will be actively filtered out. It should fix existing disabled tests in db_iter_test. This may not be a perfect fix, but it introduces least impact on existing codes, in order to be safe. Test Plan: Enable existing tests and make sure they pass. Add a new test DBIterWithMergeIterTest.InnerMergeIteratorDataRace8. Also run all existing tests. Reviewers: yhchiang, rven, anthony, IslamAbdelRahman, kradhakrishnan, igor Reviewed By: igor Subscribers: leveldb, dhruba Differential Revision: the contstaint that iterator upper bound needs to be within a prefix Summary: There is a check to fail the iterator if prefix extractor is specified but upper bound is out of the prefix for the seek key. Relax this constraint to allow users to set upper bound to the next prefix of the current one. Test Plan: make commit-prereq Reviewers: igor, anthony, kradhakrishnan, yhchiang, rven Reviewed By: rven Subscribers: tnovak, leveldb, dhruba Differential Revision:"
,,0.4263,rocksdb,"Support for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.419,rocksdb,"Support for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.2939,rocksdb,"bloom hit/miss stats for SST and memtable Summary: hit and miss bloom filter stats for memtable and SST stats added to perf_context struct key matches and prefix matches combined into one stat Test Plan: unit test veryfing the functionality added, see BloomStatsTest in db_test.cc for details Reviewers: yhchiang, igor, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision: listener_test when using ROCKSDB_MALLOC_USABLE_SIZE Summary: Flushes in listener_test happened to early when ROCKSDB_MALLOC_USABLE_SIZE was active (e.g. when compiling with ROCKSDB_FBCODE_BUILD_WITH_481=1) due to malloc_usable_size() reporting a better estimate (similar to ). This patch grows the write buffer size slightly to compensate for this. Test Plan: ROCKSDB_FBCODE_BUILD_WITH_481=1 make listener_test && ./listener_test Reviewers: rven, anthony, yhchiang, igor, sdong Reviewed By: igor Subscribers: dhruba, leveldb Differential Revision:"
,,0.4325,rocksdb,"Support for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.3277,rocksdb,"Fix tests failing in ROCKSDB_LITE Summary: Fix tests that compile under ROCKSDB_LITE but currently failing. table_test: RandomizedLongDB test is using internal stats which is not supported in ROCKSDB_LITE compaction_job_test: Using CompactionJobStats which is not supported perf_context_test: KeyComparisonCount test try to open DB in ReadOnly mode which is not supported Test Plan: run the tests under ROCKSDB_LITE Reviewers: yhchiang, sdong, igor Reviewed By: igor Subscribers: dhruba Differential Revision: compile failure on Travis Summary: Travis is complaining against using {} to initialize KVMap: db/compaction_job_test.cc:526:26: error: chosen constructor is explicit in copy-initialization RunCompaction({files}, {}); This diff should fix it Test Plan: travis Reviewers: sdong Subscribers: dhruba, leveldb Differential Revision: for SingleDelete() Summary: This patch fixes It introduces SingleDelete as a new database operation. This operation can be used to delete keys that were never overwritten (no put following another put of the same key). If an overwritten key is single deleted the behavior is undefined. Single deletion of a non-existent key has no effect but multiple consecutive single deletions are not allowed (see limitations). In contrast to the conventional Delete() operation, the deletion entry is removed along with the value when the two are lined up in a compaction. Note: The semantics are similar to prototype that allowed to have this behavior on the granularity of a column family ( ). This new patch, however, is more aggressive when it comes to removing tombstones: It removes the SingleDelete together with the value whenever there is no snapshot between them while the older patch only did this when the sequence number of the deletion was older than the earliest snapshot. Most of the complex additions are in the Compaction Iterator, all other changes should be relatively straightforward. The patch also includes basic support for single deletions in db_stress and db_bench. Limitations: Not compatible with cuckoo hash tables Single deletions cannot be used in combination with merges and normal deletions on the same key (other keys are not affected by this) Consecutive single deletions are currently not allowed (and older version of this patch supported this so it could be resurrected if needed) Test Plan: make all check Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor Reviewed By: igor Subscribers: maykov, dhruba, leveldb Differential Revision:"
,,0.2008,rocksdb,"Set max_open_files based on ulimit Summary: We should never set max_open_files to be bigger than the systems ulimit. Otherwise we will get ""Too many open files"" errors. See an example in this Travis run: Test Plan: make check I will also verify that max_max_open_files is reasonable. Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: WinEnv::NowMicros return system time Previous change for the function made use of the QueryPerformanceCounter to return microseconds values that do not repeat as std::chrono::system_clock returned values that made auto_roll_logger_test fail. The interface documentation does not state that we need to return system time describing the return value as a number of microsecs since some moment in time. However, because on Linux it is implemented using gettimeofday various pieces of code (such as GenericRateLimiter) took advantage of that and make use of NowMicros() as a system timestamp. Thus the previous change broke rate_limiter_test on Windows. In addition, the interface name NowMicros() suggests that it is actually a timestamp so people use it as such. This change makes use of the new system call on Windows that returns system time with required precision. This change preserves the fix for auto_roll_logger_test and fixes rate_limiter_test. Note that DBTest.RateLimitingTest still fails due to a separately reported issue./"
,,0.2449,rocksdb,"Crash test to make kill decision for every kill point Summary: In crash test, when coming to each kill point, we start a random class using seed as current second. With this approach, for every second, the random number used is the same. However, in each second, there are multiple kill points with different frequency. It makes it hard to reason about chance of kill point to trigger. With this commit, we use thread local random seed to generate the random number, so that it will take different values per second, hoping it makes chances of killing much easier to reason about. Also significantly reduce the kill odd to make sure time before kiling is similar as before. Test Plan: Run white box crash test and see the killing happens as expected and the run time time before killing reasonable. Reviewers: kradhakrishnan, IslamAbdelRahman, rven, yhchiang, andrewkr, anthony Reviewed By: anthony Subscribers: leveldb, dhruba Differential Revision:"
,,0.2312,rocksdb,"Fixed a dependency issue of ThreadLocalPtr Summary: When a child thread that uses ThreadLocalPtr, ThreadLocalPtr::OnThreadExit will be called when that child thread is destroyed. However, OnThreadExit will try to access a static singleton of ThreadLocalPtr, which will be destroyed when the main thread exit. As a result, when a child thread that uses ThreadLocalPtr exits AFTER the main thread exits, illegal memory access will occur. This diff includes a test that reproduce this legacy bug. AddressSanitizer: heap-use-after-free on address 0x608000007fa0 at pc 0x959b79 bp 0x7f5fa7426b60 sp 0x7f5fa7426b58 READ of size 8 at 0x608000007fa0 thread T1 This patch fix this issue by having the thread local mutex never be deleted (but will leak small piece of memory at the end.) The patch also describe a better solution (thread_local) in the comment that requires gcc 4.8.1 and in latest clang as a future work once we agree to move toward gcc 4.8. Test Plan: COMPILE_WITH_ASAN=1 make thread_local_test ./thread_local_test Reviewers: anthony, hermanlee4, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision:"
,,0.3336,rocksdb,"Fixed a dependency issue of ThreadLocalPtr Summary: When a child thread that uses ThreadLocalPtr, ThreadLocalPtr::OnThreadExit will be called when that child thread is destroyed. However, OnThreadExit will try to access a static singleton of ThreadLocalPtr, which will be destroyed when the main thread exit. As a result, when a child thread that uses ThreadLocalPtr exits AFTER the main thread exits, illegal memory access will occur. This diff includes a test that reproduce this legacy bug. AddressSanitizer: heap-use-after-free on address 0x608000007fa0 at pc 0x959b79 bp 0x7f5fa7426b60 sp 0x7f5fa7426b58 READ of size 8 at 0x608000007fa0 thread T1 This patch fix this issue by having the thread local mutex never be deleted (but will leak small piece of memory at the end.) The patch also describe a better solution (thread_local) in the comment that requires gcc 4.8.1 and in latest clang as a future work once we agree to move toward gcc 4.8. Test Plan: COMPILE_WITH_ASAN=1 make thread_local_test ./thread_local_test Reviewers: anthony, hermanlee4, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: the destruction order of PosixEnv and ThreadLocalPtr Summary: By default, RocksDB initializes the singletons of ThreadLocalPtr first, then initializes PosixEnv via static initializer. Destructor terminates objects in reverse order, so terminating PosixEnv (calling pthread_mutex_lock), then ThreadLocal (calling pthread_mutex_destroy). However, in certain case, application might initialize PosixEnv first, then ThreadLocalPtr. This will cause core dump at the end of the program (eg. This patch fix this issue by ensuring the destruction order by moving the global static singletons to function static singletons. Since function static singletons are initialized when the function is first called, this property allows us invoke to enforce the construction of the static PosixEnv and the singletons of ThreadLocalPtr by calling the function where the ThreadLocalPtr singletons belongs right before we initialize the static PosixEnv. Test Plan: Verified in the MyRocks. Reviewers: yoshinorim, IslamAbdelRahman, rven, kradhakrishnan, anthony, sdong, MarkCallaghan Reviewed By: anthony Subscribers: dhruba, leveldb Differential Revision: pull request from charsyam/feature/typos fix typos in comments/fix typos in comments/"
,,0.0778,rocksdb,"[directory includes cleanup] Move cross-function test points Summary: I split the db-specific test points out into a separate file under db/ directory. There were also a few bugs to fix in xfunc.{h,cc} that prevented it from compiling previously; see Test Plan: compilation works now, below command works, will also run ""make xfunc"". $ make check ROCKSDB_XFUNC_TEST=managed_new tests-regexp=DBTest Reviewers: sdong, yhchiang Subscribers: dhruba Differential Revision:"
,,0.2602,rocksdb,"Fixed a dependency issue of ThreadLocalPtr Summary: When a child thread that uses ThreadLocalPtr, ThreadLocalPtr::OnThreadExit will be called when that child thread is destroyed. However, OnThreadExit will try to access a static singleton of ThreadLocalPtr, which will be destroyed when the main thread exit. As a result, when a child thread that uses ThreadLocalPtr exits AFTER the main thread exits, illegal memory access will occur. This diff includes a test that reproduce this legacy bug. AddressSanitizer: heap-use-after-free on address 0x608000007fa0 at pc 0x959b79 bp 0x7f5fa7426b60 sp 0x7f5fa7426b58 READ of size 8 at 0x608000007fa0 thread T1 This patch fix this issue by having the thread local mutex never be deleted (but will leak small piece of memory at the end.) The patch also describe a better solution (thread_local) in the comment that requires gcc 4.8.1 and in latest clang as a future work once we agree to move toward gcc 4.8. Test Plan: COMPILE_WITH_ASAN=1 make thread_local_test ./thread_local_test Reviewers: anthony, hermanlee4, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: includes cleanup] Remove util->db dependency for ThreadStatusUtil Summary: We can avoid the dependency by forward-declaring ColumnFamilyData and then treating it as a black box. That means callers of ThreadStatusUtil need to explicitly provide more options, even if they can be derived from the ColumnFamilyData, since ThreadStatusUtil doesnt include the definition. This is part of a series of diffs to eliminate circular dependencies between directories (e.g., db/* files depending on util/* files and vice-versa). Test Plan: $ ./db_test $ make commit-prereq Reviewers: sdong, yhchiang, IslamAbdelRahman Subscribers: dhruba, leveldb Differential Revision: manual compactions in parallel with other automatic or manual compactions in restricted cases Summary: This diff provides a framework for doing manual compactions in parallel with other compactions. We now have a deque of manual compactions. We also pass manual compactions as an argument from RunManualCompactions down to BackgroundCompactions, so that RunManualCompactions can be reentrant. Parallelism is controlled by the two routines ConflictingManualCompaction to allow/disallow new parallel/manual compactions based on already existing ManualCompactions. In this diff, by default manual compactions still have to run exclusive of other compactions. However, by setting the compaction option, exclusive_manual_compaction to false, it is possible to run other compactions in parallel with a manual compaction. However, we are still restricted to one manual compaction per column family at a time. All of these restrictions will be relaxed in future diffs. I will be adding more tests later. Test Plan: Rocksdb regression + new tests + valgrind Reviewers: igor, anthony, IslamAbdelRahman, kradhakrishnan, yhchiang, sdong Reviewed By: sdong Subscribers: yoshinorim, dhruba, leveldb Differential Revision: the destruction order of PosixEnv and ThreadLocalPtr Summary: By default, RocksDB initializes the singletons of ThreadLocalPtr first, then initializes PosixEnv via static initializer. Destructor terminates objects in reverse order, so terminating PosixEnv (calling pthread_mutex_lock), then ThreadLocal (calling pthread_mutex_destroy). However, in certain case, application might initialize PosixEnv first, then ThreadLocalPtr. This will cause core dump at the end of the program (eg. This patch fix this issue by ensuring the destruction order by moving the global static singletons to function static singletons. Since function static singletons are initialized when the function is first called, this property allows us invoke to enforce the construction of the static PosixEnv and the singletons of ThreadLocalPtr by calling the function where the ThreadLocalPtr singletons belongs right before we initialize the static PosixEnv. Test Plan: Verified in the MyRocks. Reviewers: yoshinorim, IslamAbdelRahman, rven, kradhakrishnan, anthony, sdong, MarkCallaghan Reviewed By: anthony Subscribers: dhruba, leveldb Differential Revision:"
,,0.1068,rocksdb,Merge pull request from yuslepukhin/fix_db_table_properties_test Avoid empty ranges vector with subsequent zero element access/Avoid empty ranges vector with subsequent zero element access/
,,0.174,rocksdb,"Forge current file for checkpoint Summary: This fixes a similar issue as D54711: ""CURRENT"" file can mutate between GetLiveFiles() and copy to the tmp directory, in which case it would reference the wrong manifest filename. To fix this, I forge the ""CURRENT"" file such that it simply contains the filename for the manifest returned by GetLiveFiles(). Changed CreateCheckpoint() to forge current file Added CreateFile() utility function Added test case that rolls manifest during checkpoint creation Test Plan: $ ./checkpoint_test Reviewers: sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: dhruba, leveldb Differential Revision:"
,,0.1716,rocksdb,"Forge current file for checkpoint Summary: This fixes a similar issue as D54711: ""CURRENT"" file can mutate between GetLiveFiles() and copy to the tmp directory, in which case it would reference the wrong manifest filename. To fix this, I forge the ""CURRENT"" file such that it simply contains the filename for the manifest returned by GetLiveFiles(). Changed CreateCheckpoint() to forge current file Added CreateFile() utility function Added test case that rolls manifest during checkpoint creation Test Plan: $ ./checkpoint_test Reviewers: sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: dhruba, leveldb Differential Revision:"
,,0.19899999999999998,rocksdb,"Properly destroy ChrootEnv in env_test Summary: see title Test Plan: $ /mnt/gvfs/third-party2/valgrind/af85c56f424cd5edfc2c97588299b44ecdec96bb/3.10.0/gcc-4.9-glibc-2.20/e9936bf/bin/valgrind ./env_test Reviewers: IslamAbdelRahman, sdong Reviewed By: sdong Subscribers: andrewkr, dhruba, leveldb Differential Revision: chroot Env Summary: For testing backups, we needed an Env that is fully isolated from other Envs on the same machine. Our in-memory Envs (MockEnv and InMemoryEnv) were insufficient because they dont implement most directory operations. This diff introduces a new Env, ""ChrootEnv"", that translates paths such that the chroot directory appears to be the root directory. This way, multiple Envs can be isolated in the filesystem by using different chroot directories. Since we use the filesystem, all directory operations are trivially supported. Test Plan: I parameterized the existing EnvPosixTest so it runs tests on ChrootEnv except the ioctl-related cases. Reviewers: sdong, lightmark, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba, leveldb Differential Revision: Linux Build (#990) * Musl libc does not provide adaptive mutex. Added feature test for PTHREAD_MUTEX_ADAPTIVE_NP. * Musl libc does not provide backtrace(3). Added a feature check for backtrace(3). * Fixed compiler error. * Musl libc does not implement backtrace(3). Added platform check for libexecinfo. * Alpine does not appear to support gcc option. By default (gcc has PIE option enabled) it fails with: gcc: error: and are incompatible when linking When and are used it fails with: /usr/lib/gcc/x86_64-alpine-linux-musl/5.3.0/../../../../x86_64-alpine-linux-musl/bin/ld: cannot find gcrt1.o: No such file or directory Added gcc platform test and output PROFILING_FLAGS accordingly. Replaced pg var in Makefile with PROFILING_FLAGS. * fix segfault when TEST_IOCTL_FRIENDLY_TMPDIR is undefined and default candidates are not suitable * use ASSERT_DOUBLE_EQ instead of ASSERT_EQ * When compiled with ROCKSDB_MALLOC_USABLE_SIZE UniversalCompactionFourPaths and UniversalCompactionSecondPathRatio tests fail due to premature memtable flushes on systems with 16-byte alignment. Arena runs out of block space before GenerateNewFile() completes. Increased options.write_buffer_size./"
,,0.1056,rocksdb,"[backupable db] Remove file size embedded in name workaround Summary: Now that we get sizes efficiently, we no longer need the workaround to embed file size in filename. Test Plan: $ ./backupable_db_test Reviewers: sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision:"
,,0.0652,rocksdb,Fix formatting identified by `arc lint`/
,,0.1642,rocksdb,"Forge current file for checkpoint Summary: This fixes a similar issue as D54711: ""CURRENT"" file can mutate between GetLiveFiles() and copy to the tmp directory, in which case it would reference the wrong manifest filename. To fix this, I forge the ""CURRENT"" file such that it simply contains the filename for the manifest returned by GetLiveFiles(). Changed CreateCheckpoint() to forge current file Added CreateFile() utility function Added test case that rolls manifest during checkpoint creation Test Plan: $ ./checkpoint_test Reviewers: sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: dhruba, leveldb Differential Revision:"
,,0.1691,rocksdb,"Forge current file for checkpoint Summary: This fixes a similar issue as D54711: ""CURRENT"" file can mutate between GetLiveFiles() and copy to the tmp directory, in which case it would reference the wrong manifest filename. To fix this, I forge the ""CURRENT"" file such that it simply contains the filename for the manifest returned by GetLiveFiles(). Changed CreateCheckpoint() to forge current file Added CreateFile() utility function Added test case that rolls manifest during checkpoint creation Test Plan: $ ./checkpoint_test Reviewers: sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: dhruba, leveldb Differential Revision:"
,,0.1071,rocksdb,"[backupable db] Remove file size embedded in name workaround Summary: Now that we get sizes efficiently, we no longer need the workaround to embed file size in filename. Test Plan: $ ./backupable_db_test Reviewers: sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision:"
,,0.1992,rocksdb,"Fix backupable_db_test test cases that cant run by itself Summary: Several of backupable_db_test fails if running standalone, because of directory missing. Fix it by: (1) garbage collector skips shared directory if it doesnt exit (2) BackupableDBTest.Issue921Test to create the parent directory of the backup directory fist. Test Plan: Run the tests individually and make sure they pass Subscribers: leveldb, andrewkr, dhruba Differential Revision: build errors for windows Summary: Need to use unsigned long long for 64-bit literals on windows Need size_t for backup meta-file length since clang doesnt let us assign size_t to int Test Plan: backupable_db_test and options_test Reviewers: IslamAbdelRahman, yhchiang, sdong Reviewed By: sdong Subscribers: andrewkr, dhruba, leveldb Differential Revision: pull request from SherlockNoMad/BuildFix Fix Windows build/Fix Windows build/[backupable db] Remove file size embedded in name workaround Summary: Now that we get sizes efficiently, we no longer need the workaround to embed file size in filename. Test Plan: $ ./backupable_db_test Reviewers: sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision: concurrent manifest update and backup creation Summary: Fixed two related race conditions in backup creation. (1) CreateNewBackup() uses DB::DisableFileDeletions() to prevent table files from being deleted while it is copying; however, the MANIFEST file could still rotate during this time. The fix is to stop deleting the old manifest in the rotation logic. It will be deleted safely later when PurgeObsoleteFiles() runs (can only happen when file deletions are enabled). (2) CreateNewBackup() did not account for the CURRENT file being mutable. This is significant because the files returned by GetLiveFiles() contain a particular manifest filename, but the manifest to which CURRENT refers can change at any time. This causes problems when CURRENT changes between the call to GetLiveFiles() and when its copied to the backup directory. To workaround this, I manually forge a CURRENT file referring to the manifest filename returned in GetLiveFiles(). (2) also applies to the checkpointing code, so let me know if this approach is good and Ill make the same change there. Test Plan: new test for roll manifest during backup creation. running the test before this change: $ ./backupable_db_test ... IO error: /tmp/rocksdbtest-9383/backupable_db/MANIFEST-000001: No such file or directory running the test after this change: $ ./backupable_db_test ... [ RUN ] BackupableDBTest.ChangeManifestDuringBackupCreation [ OK ] BackupableDBTest.ChangeManifestDuringBackupCreation (2836 ms) Reviewers: IslamAbdelRahman, anthony, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision:"
,,0.2077,rocksdb,Alpine Linux Build (#990) * Musl libc does not provide adaptive mutex. Added feature test for PTHREAD_MUTEX_ADAPTIVE_NP. * Musl libc does not provide backtrace(3). Added a feature check for backtrace(3). * Fixed compiler error. * Musl libc does not implement backtrace(3). Added platform check for libexecinfo. * Alpine does not appear to support gcc option. By default (gcc has PIE option enabled) it fails with: gcc: error: and are incompatible when linking When and are used it fails with: /usr/lib/gcc/x86_64-alpine-linux-musl/5.3.0/../../../../x86_64-alpine-linux-musl/bin/ld: cannot find gcrt1.o: No such file or directory Added gcc platform test and output PROFILING_FLAGS accordingly. Replaced pg var in Makefile with PROFILING_FLAGS. * fix segfault when TEST_IOCTL_FRIENDLY_TMPDIR is undefined and default candidates are not suitable * use ASSERT_DOUBLE_EQ instead of ASSERT_EQ * When compiled with ROCKSDB_MALLOC_USABLE_SIZE UniversalCompactionFourPaths and UniversalCompactionSecondPathRatio tests fail due to premature memtable flushes on systems with 16-byte alignment. Arena runs out of block space before GenerateNewFile() completes. Increased options.write_buffer_size./
,,0.0648,rocksdb,fix wrong assignment of level0_stop_writes_trigger in spatialdb (#1061)/
,,0.1597,rocksdb,"Alpine Linux Build (#990) * Musl libc does not provide adaptive mutex. Added feature test for PTHREAD_MUTEX_ADAPTIVE_NP. * Musl libc does not provide backtrace(3). Added a feature check for backtrace(3). * Fixed compiler error. * Musl libc does not implement backtrace(3). Added platform check for libexecinfo. * Alpine does not appear to support gcc option. By default (gcc has PIE option enabled) it fails with: gcc: error: and are incompatible when linking When and are used it fails with: /usr/lib/gcc/x86_64-alpine-linux-musl/5.3.0/../../../../x86_64-alpine-linux-musl/bin/ld: cannot find gcrt1.o: No such file or directory Added gcc platform test and output PROFILING_FLAGS accordingly. Replaced pg var in Makefile with PROFILING_FLAGS. * fix segfault when TEST_IOCTL_FRIENDLY_TMPDIR is undefined and default candidates are not suitable * use ASSERT_DOUBLE_EQ instead of ASSERT_EQ * When compiled with ROCKSDB_MALLOC_USABLE_SIZE UniversalCompactionFourPaths and UniversalCompactionSecondPathRatio tests fail due to premature memtable flushes on systems with 16-byte alignment. Arena runs out of block space before GenerateNewFile() completes. Increased options.write_buffer_size./Make DBTestUniversalCompaction.IncreaseUniversalCompactionNumLevels more deterministic Summary: DBTestUniversalCompaction, IncreaseUniversalCompactionNumLevels fails one in about 30 runs when running in parallel. We wait for compaction after each flush to make the compaction behavior deterministic. Test Plan: Run the test 1000 times in parallel and it still passes. Reviewers: yhchiang, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: kradhakrishnan, yiwu, leveldb, andrewkr, dhruba Differential Revision: DBTestUniversalCompaction.IncreaseUniversalCompactionNumLevels more robust Summary: Based on thread scheduling, DBTestUniversalCompaction.IncreaseUniversalCompactionNumLevels can fail to flush enough files to trigger expected compactions. Fix it by waiting for flush after inserting each key. There are failrue reported: db/db_universal_compaction_test.cc:1134: Failure Expected: (NumTableFilesAtLevel(options.num_levels 1, 1)) > (0), actual: 0 vs 0 but I cant repro it. Try to fix the bug and see whether it goes away. Test Plan: Run the test multiple time. Reviewers: IslamAbdelRahman, anthony, andrewkr, kradhakrishnan, yhchiang Reviewed By: yhchiang Subscribers: leveldb, dhruba Differential Revision:"
,,0.14,rocksdb,"Fix 32-bit build failure on Mac OSX (#1112) Using explicit 64-bit type in conditional in platforms above 32-bits This appears to be necessary on Mac OSX as std::conditional does not appear to short circuit and evaluates the third template arg Making the third template arg be 64 bits explicitly works around this problem and will work on both 32 bit and 64+ bit platforms./ColumnFamilyOptions SanitizeOptions is buggy on 32-bit platforms. Summary: The pre-existing code is trying to clamp between 65,536 and 0, resulting in clamping to 65,536, resulting in very small buffers, resulting in ShouldFlushNow() being true quite easily, resulting in assertion failing and database performance being ""not what it should be"". Test Plan: make check Reviewers: sdong, andrewkr, IslamAbdelRahman, yhchiang, igor Reviewed By: igor Subscribers: leveldb, andrewkr, dhruba Differential Revision:"
,,0.2045,rocksdb,"Handle concurrent manifest update and backup creation Summary: Fixed two related race conditions in backup creation. (1) CreateNewBackup() uses DB::DisableFileDeletions() to prevent table files from being deleted while it is copying; however, the MANIFEST file could still rotate during this time. The fix is to stop deleting the old manifest in the rotation logic. It will be deleted safely later when PurgeObsoleteFiles() runs (can only happen when file deletions are enabled). (2) CreateNewBackup() did not account for the CURRENT file being mutable. This is significant because the files returned by GetLiveFiles() contain a particular manifest filename, but the manifest to which CURRENT refers can change at any time. This causes problems when CURRENT changes between the call to GetLiveFiles() and when its copied to the backup directory. To workaround this, I manually forge a CURRENT file referring to the manifest filename returned in GetLiveFiles(). (2) also applies to the checkpointing code, so let me know if this approach is good and Ill make the same change there. Test Plan: new test for roll manifest during backup creation. running the test before this change: $ ./backupable_db_test ... IO error: /tmp/rocksdbtest-9383/backupable_db/MANIFEST-000001: No such file or directory running the test after this change: $ ./backupable_db_test ... [ RUN ] BackupableDBTest.ChangeManifestDuringBackupCreation [ OK ] BackupableDBTest.ChangeManifestDuringBackupCreation (2836 ms) Reviewers: IslamAbdelRahman, anthony, sdong Reviewed By: sdong Subscribers: dhruba, leveldb Differential Revision:"
,,0.2037,rocksdb,Alpine Linux Build (#990) * Musl libc does not provide adaptive mutex. Added feature test for PTHREAD_MUTEX_ADAPTIVE_NP. * Musl libc does not provide backtrace(3). Added a feature check for backtrace(3). * Fixed compiler error. * Musl libc does not implement backtrace(3). Added platform check for libexecinfo. * Alpine does not appear to support gcc option. By default (gcc has PIE option enabled) it fails with: gcc: error: and are incompatible when linking When and are used it fails with: /usr/lib/gcc/x86_64-alpine-linux-musl/5.3.0/../../../../x86_64-alpine-linux-musl/bin/ld: cannot find gcrt1.o: No such file or directory Added gcc platform test and output PROFILING_FLAGS accordingly. Replaced pg var in Makefile with PROFILING_FLAGS. * fix segfault when TEST_IOCTL_FRIENDLY_TMPDIR is undefined and default candidates are not suitable * use ASSERT_DOUBLE_EQ instead of ASSERT_EQ * When compiled with ROCKSDB_MALLOC_USABLE_SIZE UniversalCompactionFourPaths and UniversalCompactionSecondPathRatio tests fail due to premature memtable flushes on systems with 16-byte alignment. Arena runs out of block space before GenerateNewFile() completes. Increased options.write_buffer_size./
,,0.2117,rocksdb,Alpine Linux Build (#990) * Musl libc does not provide adaptive mutex. Added feature test for PTHREAD_MUTEX_ADAPTIVE_NP. * Musl libc does not provide backtrace(3). Added a feature check for backtrace(3). * Fixed compiler error. * Musl libc does not implement backtrace(3). Added platform check for libexecinfo. * Alpine does not appear to support gcc option. By default (gcc has PIE option enabled) it fails with: gcc: error: and are incompatible when linking When and are used it fails with: /usr/lib/gcc/x86_64-alpine-linux-musl/5.3.0/../../../../x86_64-alpine-linux-musl/bin/ld: cannot find gcrt1.o: No such file or directory Added gcc platform test and output PROFILING_FLAGS accordingly. Replaced pg var in Makefile with PROFILING_FLAGS. * fix segfault when TEST_IOCTL_FRIENDLY_TMPDIR is undefined and default candidates are not suitable * use ASSERT_DOUBLE_EQ instead of ASSERT_EQ * When compiled with ROCKSDB_MALLOC_USABLE_SIZE UniversalCompactionFourPaths and UniversalCompactionSecondPathRatio tests fail due to premature memtable flushes on systems with 16-byte alignment. Arena runs out of block space before GenerateNewFile() completes. Increased options.write_buffer_size./
,,0.3773,rocksdb,"Write a benchmark to emulate time series data Summary: Add a benchmark to `db_bench`. In this benchmark, a write thread will populate time series data in the format of id | timestamp, and multiple read threads will randomly retrieve all data from one id at a time. Test Plan: Run the benchmark: `num=134217728;bpl=536870912;mb=67108864;overlap=10;mcz=2;del=300000000;levels=6;ctrig=4;delay=8;stop=12;wbn=3;mbc=20;wbs=134217728;dds=0;sync=0;t=32;vs=800;bs=4096;cs=17179869184;of=500000;wps=0;si=10000000; kir=100000; dir=/data/users/jhli/test/; ./db_bench Reviewers: andrewkr, sdong Reviewed By: sdong Subscribers: lgalanis, andrewkr, dhruba, leveldb Differential Revision: Minor Bug on Windows Build and db_bench_tool.cc (#1189) * Fixed Windows build error in CMakeLists.txt and perf_level error in db_bench_tool.cc * Changed hard-coded perf levels in db_bench_tool.cc to enum values from perf_level.h * Replaced remaining FLAGS_perf_level > 0/Improve regression_test.sh Summary: This diff makes the following improvement in regression_test.sh: 1. Add NUM_OPS and DELETE_TEST_PATH to regression_test.sh: * NUM_OPS: The number of operations that will be issued in EACH thread. Default: $NUM_KEYS / $NUM_THREADS * DELETE_TEST_PATH: If true, then the test directory will be deleted after the script ends. Default: 0 2. Add more information in SUMMARY.csv 3. Fix a bug in regression_test.sh where each thread in fillseq will all issue $NUM_KEYS writes. 4. Add in db_bench, which allows us to control the number of deletes instead of must using FLAGS_num. Test Plan: run regression test with and without DELETE_TEST_PATH and NUM_OPS Reviewers: yiwu, sdong, IslamAbdelRahman, gunnarku Reviewed By: gunnarku Subscribers: andrewkr, dhruba, leveldb Differential Revision: Env selection for db_bench Summary: Added an option, When provided, it is used as an argument to NewEnvFromUri(), which instantiates an Env based on it. Test Plan: built a simple binary that registers ChrootEnv for prefix ""/"", then ran: $ ./tmp /tmp/ /abcde /tmp/ is the chroot directory and /abcde is the db_name. Then I verified db_bench uses /tmp/abcde Reviewers: sdong, kradhakrishnan, lightmark Reviewed By: lightmark Subscribers: andrewkr, dhruba, leveldb Differential Revision: db_bench Summary: Fix simple issue with FLAGS_simcache_size condition Test Plan: run db_bench Reviewers: lightmark Reviewed By: lightmark Subscribers: andrewkr, dhruba Differential Revision: simulator Cache as class SimCache/SimLRUCache(with test) Summary: add class SimCache(base class with instrumentation api) and SimLRUCache(derived class with detailed implementation) which is used as an instrumented block cache that can predict hit rate for different cache size Test Plan: Add a test case in `db_block_cache_test.cc` called `SimCacheTest` to test basic logic of SimCache. Also add option `-simcache_size` in db_bench. if set with a value other than then the benchmark will use this value as the size of the simulator cache and finally output the simulation result. ``` ~/local/rocksdb] ./db_bench ""fillseq,readrandom"" 1000000 1000000 RocksDB: version 4.8 Date: Tue May 17 16:56:16 2016 CPU: 32 * Intel(R) Xeon(R) CPU E5-2660 0 2.20GHz CPUCache: 20480 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 0 WARNING: Assertions are enabled; benchmarks unnecessarily slow DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 6.809 micros/op 146874 ops/sec; 16.2 MB/s DB path: [/tmp/rocksdbtest-112628/dbbench] readrandom : 6.343 micros/op 157665 ops/sec; 17.4 MB/s (1000000 of 1000000 found) SIMULATOR CACHE STATISTICS: SimCache LOOKUPs: 986559 SimCache HITs: 264760 SimCache HITRATE: 26.84% ~/local/rocksdb] ./db_bench ""fillseq,readrandom"" 1000000 10000000 RocksDB: version 4.8 Date: Tue May 17 16:57:10 2016 CPU: 32 * Intel(R) Xeon(R) CPU E5-2660 0 2.20GHz CPUCache: 20480 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 0 WARNING: Assertions are enabled; benchmarks unnecessarily slow DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 5.066 micros/op 197394 ops/sec; 21.8 MB/s DB path: [/tmp/rocksdbtest-112628/dbbench] readrandom : 6.457 micros/op 154870 ops/sec; 17.1 MB/s (1000000 of 1000000 found) SIMULATOR CACHE STATISTICS: SimCache LOOKUPs: 1059764 SimCache HITs: 374501 SimCache HITRATE: 35.34% ~/local/rocksdb] ./db_bench ""fillseq,readrandom"" 1000000 100000000 RocksDB: version 4.8 Date: Tue May 17 16:57:32 2016 CPU: 32 * Intel(R) Xeon(R) CPU E5-2660 0 2.20GHz CPUCache: 20480 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 0 WARNING: Assertions are enabled; benchmarks unnecessarily slow DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 5.632 micros/op 177572 ops/sec; 19.6 MB/s DB path: [/tmp/rocksdbtest-112628/dbbench] readrandom : 6.892 micros/op 145094 ops/sec; 16.1 MB/s (1000000 of 1000000 found) SIMULATOR CACHE STATISTICS: SimCache LOOKUPs: 1150767 SimCache HITs: 1034535 SimCache HITRATE: 89.90% ``` Reviewers: IslamAbdelRahman, andrewkr, sdong Reviewed By: sdong Subscribers: MarkCallaghan, andrewkr, dhruba, leveldb Differential Revision:"
,,0.3256,rocksdb,"Simplify thread-local static initialization Summary: The call stack used to look like this during static initialization: 0x00000000008032d1 in rocksdb::ThreadLocalPtr::StaticMeta::StaticMeta() (this=0x7ffff683b300) at util/thread_local.cc:172 0x00000000008030a7 in rocksdb::ThreadLocalPtr::Instance() () at util/thread_local.cc:135 0x000000000080310f in rocksdb::ThreadLocalPtr::StaticMeta::Mutex() () at util/thread_local.cc:141 0x0000000000803103 in rocksdb::ThreadLocalPtr::StaticMeta::InitSingletons() () at util/thread_local.cc:139 0x000000000080305d in rocksdb::ThreadLocalPtr::InitSingletons() () at util/thread_local.cc:106 It involves outer/inner classes and the call stacks goes outer->inner->outer->inner, which is too difficult to understand. We can avoid a level of back-and-forth by skipping StaticMeta::InitSingletons(), which doesnt initialize anything beyond what ThreadLocalPtr::Instance() already initializes. Now the call stack looks like this during static initialization: 0x00000000008032c5 in rocksdb::ThreadLocalPtr::StaticMeta::StaticMeta() (this=0x7ffff683b300) at util/thread_local.cc:170 0x00000000008030a7 in rocksdb::ThreadLocalPtr::Instance() () at util/thread_local.cc:135 0x000000000080305d in rocksdb::ThreadLocalPtr::InitSingletons() () at util/thread_local.cc:106 Test Plan: unit tests verify StaticMeta::mutex_ is still initialized in DefaultEnv() (StaticMeta::mutex_ is the only variable intended to be initialized via StaticMeta::InitSingletons() which I removed) 0x00000000005cee17 in rocksdb::port::Mutex::Mutex(bool) (this=0x7ffff69500b0, adaptive=false) at port/port_posix.cc:52 0x0000000000769cf8 in rocksdb::ThreadLocalPtr::StaticMeta::StaticMeta() (this=0x7ffff6950000) at util/thread_local.cc:168 0x0000000000769a53 in rocksdb::ThreadLocalPtr::Instance() () at util/thread_local.cc:133 0x0000000000769a09 in rocksdb::ThreadLocalPtr::InitSingletons() () at util/thread_local.cc:105 0x0000000000647d98 in rocksdb::Env::Default() () at util/env_posix.cc:845 Reviewers: lightmark, yhchiang, sdong Reviewed By: sdong Subscribers: arahut, IslamAbdelRahman, yiwu, andrewkr, dhruba, leveldb Differential Revision:"
,,0.5479,rocksdb,"Fix clang build failure and refactor unit test Summary: is not platform independent. Switch to our own endianness transformation function instead. Test Plan: Pass Travis CI. Refactor tests to make sure endianness transformation runs properly. Reviewers: IslamAbdelRahman, sdong Reviewed By: sdong Subscribers: andrewkr, dhruba, leveldb Differential Revision: Statistics to track Compression/Decompression (#1197) * Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer). * Prevent incrementing compression counter when compression is turned off in options. * Prevent incrementing compression counter when compression is turned off in options. * Added two more supported compression types to test code in db_test.cc * Prevent incrementing compression counter when compression is turned off in options. * Added new StatsLevel that excludes compression timing. * Fixed casting error in coding.h * Fixed CompressionStatsTest for new StatsLevel. * Removed unused variable that was breaking the Linux build/Miscellaneous performance improvements Summary: I was investigating performance issues in the SstFileWriter and found all of the following: The SstFileWriter::Add() function created a local InternalKey every time it was called generating a allocation and free each time. Changed to have an InternalKey member variable that can be reset with the new InternalKey::Set() function. In SstFileWriter::Add() the smallest_key and largest_key values were assigned the result of a ToString() call, but it is simpler to just assign them directly from the users key. The Slice class had no move constructor so each time one was returned from a function a new one had to be allocated, the old data copied to the new, and the old one was freed. I added the move constructor which also required a copy constructor and assignment operator. The BlockBuilder::CurrentSizeEstimate() function calculates the current estimate size, but was being called 2 or 3 times for each key added. I changed the class to maintain a running estimate (equal to the original calculation) so that the function can return an already calculated value. The code in BlockBuilder::Add() that calculated the shared bytes between the last key and the new key duplicated what Slice::difference_offset does, so I replaced it with the standard function. BlockBuilder::Add() had code to copy just the changed portion into the last key value (and asserted that it now matched the new key). It is more efficient just to copy the whole new key over. Moved this same code up into the if (use_delta_encoding_) since the last key value is only needed when delta encoding is on. FlushBlockBySizePolicy::BlockAlmostFull calculated a standard deviation value each time it was called, but this information would only change if block_size of block_size_deviation changed, so I created a member variable to hold the value to avoid the calculation each time. Each PutVarint??() function has a buffer and calls std::string::append(). Two or three calls in a row could share a buffer and a single call to std::string::append(). Some of these will be helpful outside of the SstFileWriter. Im not 100% the addition of the move constructor is appropriate as I wonder why this wasnt done before maybe because of compiler compatibility? I tried it on gcc 4.8 and 4.9. Test Plan: The changes should not affect the results so the existing tests should all still work and no new tests were added. The value of the changes was seen by manually testing the SstFileWriter class through MyRocks and adding timing code to identify problem areas. Reviewers: sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba Differential Revision:"
,,0.1162,rocksdb,"Fixed output size and removed unneeded loop Summary: In Zlib_Compress and BZip2_Compress the calculation for size was slightly off when using compression_foramt_version 2 (which includes the decompressed size in the output). Also there were unnecessary loops around the deflate/BZ2_bzCompress calls. In Zlib_Compress there was also a possible exit from the function after calling deflateInit2 that didnt call deflateEnd. Test Plan: Standard tests Reviewers: sdong, IslamAbdelRahman, igor Reviewed By: igor Subscribers: sdong, IslamAbdelRahman, andrewkr, dhruba Differential Revision:"
,,0.4542,rocksdb,"add simulator Cache as class SimCache/SimLRUCache(with test) Summary: add class SimCache(base class with instrumentation api) and SimLRUCache(derived class with detailed implementation) which is used as an instrumented block cache that can predict hit rate for different cache size Test Plan: Add a test case in `db_block_cache_test.cc` called `SimCacheTest` to test basic logic of SimCache. Also add option `-simcache_size` in db_bench. if set with a value other than then the benchmark will use this value as the size of the simulator cache and finally output the simulation result. ``` ~/local/rocksdb] ./db_bench ""fillseq,readrandom"" 1000000 1000000 RocksDB: version 4.8 Date: Tue May 17 16:56:16 2016 CPU: 32 * Intel(R) Xeon(R) CPU E5-2660 0 2.20GHz CPUCache: 20480 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 0 WARNING: Assertions are enabled; benchmarks unnecessarily slow DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 6.809 micros/op 146874 ops/sec; 16.2 MB/s DB path: [/tmp/rocksdbtest-112628/dbbench] readrandom : 6.343 micros/op 157665 ops/sec; 17.4 MB/s (1000000 of 1000000 found) SIMULATOR CACHE STATISTICS: SimCache LOOKUPs: 986559 SimCache HITs: 264760 SimCache HITRATE: 26.84% ~/local/rocksdb] ./db_bench ""fillseq,readrandom"" 1000000 10000000 RocksDB: version 4.8 Date: Tue May 17 16:57:10 2016 CPU: 32 * Intel(R) Xeon(R) CPU E5-2660 0 2.20GHz CPUCache: 20480 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 0 WARNING: Assertions are enabled; benchmarks unnecessarily slow DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 5.066 micros/op 197394 ops/sec; 21.8 MB/s DB path: [/tmp/rocksdbtest-112628/dbbench] readrandom : 6.457 micros/op 154870 ops/sec; 17.1 MB/s (1000000 of 1000000 found) SIMULATOR CACHE STATISTICS: SimCache LOOKUPs: 1059764 SimCache HITs: 374501 SimCache HITRATE: 35.34% ~/local/rocksdb] ./db_bench ""fillseq,readrandom"" 1000000 100000000 RocksDB: version 4.8 Date: Tue May 17 16:57:32 2016 CPU: 32 * Intel(R) Xeon(R) CPU E5-2660 0 2.20GHz CPUCache: 20480 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 0 WARNING: Assertions are enabled; benchmarks unnecessarily slow DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 5.632 micros/op 177572 ops/sec; 19.6 MB/s DB path: [/tmp/rocksdbtest-112628/dbbench] readrandom : 6.892 micros/op 145094 ops/sec; 16.1 MB/s (1000000 of 1000000 found) SIMULATOR CACHE STATISTICS: SimCache LOOKUPs: 1150767 SimCache HITs: 1034535 SimCache HITRATE: 89.90% ``` Reviewers: IslamAbdelRahman, andrewkr, sdong Reviewed By: sdong Subscribers: MarkCallaghan, andrewkr, dhruba, leveldb Differential Revision:"
,,0.4607,rocksdb,"add simulator Cache as class SimCache/SimLRUCache(with test) Summary: add class SimCache(base class with instrumentation api) and SimLRUCache(derived class with detailed implementation) which is used as an instrumented block cache that can predict hit rate for different cache size Test Plan: Add a test case in `db_block_cache_test.cc` called `SimCacheTest` to test basic logic of SimCache. Also add option `-simcache_size` in db_bench. if set with a value other than then the benchmark will use this value as the size of the simulator cache and finally output the simulation result. ``` ~/local/rocksdb] ./db_bench ""fillseq,readrandom"" 1000000 1000000 RocksDB: version 4.8 Date: Tue May 17 16:56:16 2016 CPU: 32 * Intel(R) Xeon(R) CPU E5-2660 0 2.20GHz CPUCache: 20480 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 0 WARNING: Assertions are enabled; benchmarks unnecessarily slow DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 6.809 micros/op 146874 ops/sec; 16.2 MB/s DB path: [/tmp/rocksdbtest-112628/dbbench] readrandom : 6.343 micros/op 157665 ops/sec; 17.4 MB/s (1000000 of 1000000 found) SIMULATOR CACHE STATISTICS: SimCache LOOKUPs: 986559 SimCache HITs: 264760 SimCache HITRATE: 26.84% ~/local/rocksdb] ./db_bench ""fillseq,readrandom"" 1000000 10000000 RocksDB: version 4.8 Date: Tue May 17 16:57:10 2016 CPU: 32 * Intel(R) Xeon(R) CPU E5-2660 0 2.20GHz CPUCache: 20480 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 0 WARNING: Assertions are enabled; benchmarks unnecessarily slow DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 5.066 micros/op 197394 ops/sec; 21.8 MB/s DB path: [/tmp/rocksdbtest-112628/dbbench] readrandom : 6.457 micros/op 154870 ops/sec; 17.1 MB/s (1000000 of 1000000 found) SIMULATOR CACHE STATISTICS: SimCache LOOKUPs: 1059764 SimCache HITs: 374501 SimCache HITRATE: 35.34% ~/local/rocksdb] ./db_bench ""fillseq,readrandom"" 1000000 100000000 RocksDB: version 4.8 Date: Tue May 17 16:57:32 2016 CPU: 32 * Intel(R) Xeon(R) CPU E5-2660 0 2.20GHz CPUCache: 20480 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 0 WARNING: Assertions are enabled; benchmarks unnecessarily slow DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 5.632 micros/op 177572 ops/sec; 19.6 MB/s DB path: [/tmp/rocksdbtest-112628/dbbench] readrandom : 6.892 micros/op 145094 ops/sec; 16.1 MB/s (1000000 of 1000000 found) SIMULATOR CACHE STATISTICS: SimCache LOOKUPs: 1150767 SimCache HITs: 1034535 SimCache HITRATE: 89.90% ``` Reviewers: IslamAbdelRahman, andrewkr, sdong Reviewed By: sdong Subscribers: MarkCallaghan, andrewkr, dhruba, leveldb Differential Revision:"
,,0.0597,rocksdb,Bugfix to ensure that logging can be achieved from threads that are not known to the JVM (#1106)/
,,0.1997,rocksdb,"Experiments on column-aware encodings Summary: Experiments on column-aware encodings. Supported features: 1) extract data blocks from SST file and encode with specified encodings; 2) Decode encoded data back into row format; 3) Directly extract data blocks and write in row format (without prefix encoding); 4) Get column distribution statistics for column format; 5) Dump data blocks separated by columns in human-readable format. There is still on-going work on this diff. More refactoring is necessary. Test Plan: Wrote tests in `column_aware_encoding_test.cc`. More tests should be added. Reviewers: sdong Reviewed By: sdong Subscribers: arahut, andrewkr, dhruba Differential Revision: Statistics to track Compression/Decompression (#1197) * Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer). * Prevent incrementing compression counter when compression is turned off in options. * Prevent incrementing compression counter when compression is turned off in options. * Added two more supported compression types to test code in db_test.cc * Prevent incrementing compression counter when compression is turned off in options. * Added new StatsLevel that excludes compression timing. * Fixed casting error in coding.h * Fixed CompressionStatsTest for new StatsLevel. * Removed unused variable that was breaking the Linux build/Add statistics field to show total size of index and filter blocks in block cache Summary: With `table_options.cache_index_and_filter_blocks true`, index and filter blocks are stored in block cache. Then people are curious how much of the block cache total size is used by indexes and bloom filters. It will be nice we have a way to report that. It can help people tune performance and plan for optimized hardware setting. We add several enum values for db Statistics. BLOCK_CACHE_INDEX/FILTER_BYTES_INSERT BLOCK_CACHE_INDEX/FILTER_BYTES_ERASE current INDEX/FILTER total block size in bytes. Test Plan: write a test case called `DBBlockCacheTest.IndexAndFilterBlocksStats`. The result is: ``` ~/local/rocksdb] make db_block_cache_test && ./db_block_cache_test Makefile:101: Warning: Compiling in debug mode. Dont use the resulting binary in production GEN util/build_version.cc make: `db_block_cache_test is up to date. Note: Google Test filter DBBlockCacheTest.IndexAndFilterBlocksStats [==========] Running 1 test from 1 test case. [----------] Global test environment set-up. [----------] 1 test from DBBlockCacheTest [ RUN ] DBBlockCacheTest.IndexAndFilterBlocksStats [ OK ] DBBlockCacheTest.IndexAndFilterBlocksStats (689 ms) [----------] 1 test from DBBlockCacheTest (689 ms total) [----------] Global test environment tear-down [==========] 1 test from 1 test case ran. (689 ms total) [ PASSED ] 1 test. ``` Reviewers: IslamAbdelRahman, andrewkr, sdong Reviewed By: sdong Subscribers: andrewkr, dhruba, leveldb Differential Revision:"
,,0.2691,rocksdb,"New Statistics to track Compression/Decompression (#1197) * Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer). * Prevent incrementing compression counter when compression is turned off in options. * Prevent incrementing compression counter when compression is turned off in options. * Added two more supported compression types to test code in db_test.cc * Prevent incrementing compression counter when compression is turned off in options. * Added new StatsLevel that excludes compression timing. * Fixed casting error in coding.h * Fixed CompressionStatsTest for new StatsLevel. * Removed unused variable that was breaking the Linux build/"
,,0.5802,rocksdb,"Miscellaneous performance improvements Summary: I was investigating performance issues in the SstFileWriter and found all of the following: The SstFileWriter::Add() function created a local InternalKey every time it was called generating a allocation and free each time. Changed to have an InternalKey member variable that can be reset with the new InternalKey::Set() function. In SstFileWriter::Add() the smallest_key and largest_key values were assigned the result of a ToString() call, but it is simpler to just assign them directly from the users key. The Slice class had no move constructor so each time one was returned from a function a new one had to be allocated, the old data copied to the new, and the old one was freed. I added the move constructor which also required a copy constructor and assignment operator. The BlockBuilder::CurrentSizeEstimate() function calculates the current estimate size, but was being called 2 or 3 times for each key added. I changed the class to maintain a running estimate (equal to the original calculation) so that the function can return an already calculated value. The code in BlockBuilder::Add() that calculated the shared bytes between the last key and the new key duplicated what Slice::difference_offset does, so I replaced it with the standard function. BlockBuilder::Add() had code to copy just the changed portion into the last key value (and asserted that it now matched the new key). It is more efficient just to copy the whole new key over. Moved this same code up into the if (use_delta_encoding_) since the last key value is only needed when delta encoding is on. FlushBlockBySizePolicy::BlockAlmostFull calculated a standard deviation value each time it was called, but this information would only change if block_size of block_size_deviation changed, so I created a member variable to hold the value to avoid the calculation each time. Each PutVarint??() function has a buffer and calls std::string::append(). Two or three calls in a row could share a buffer and a single call to std::string::append(). Some of these will be helpful outside of the SstFileWriter. Im not 100% the addition of the move constructor is appropriate as I wonder why this wasnt done before maybe because of compiler compatibility? I tried it on gcc 4.8 and 4.9. Test Plan: The changes should not affect the results so the existing tests should all still work and no new tests were added. The value of the changes was seen by manually testing the SstFileWriter class through MyRocks and adding timing code to identify problem areas. Reviewers: sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba Differential Revision:"
,,0.1584,rocksdb,"Experiments on column-aware encodings Summary: Experiments on column-aware encodings. Supported features: 1) extract data blocks from SST file and encode with specified encodings; 2) Decode encoded data back into row format; 3) Directly extract data blocks and write in row format (without prefix encoding); 4) Get column distribution statistics for column format; 5) Dump data blocks separated by columns in human-readable format. There is still on-going work on this diff. More refactoring is necessary. Test Plan: Wrote tests in `column_aware_encoding_test.cc`. More tests should be added. Reviewers: sdong Reviewed By: sdong Subscribers: arahut, andrewkr, dhruba Differential Revision:"
,,0.5708,rocksdb,"Miscellaneous performance improvements Summary: I was investigating performance issues in the SstFileWriter and found all of the following: The SstFileWriter::Add() function created a local InternalKey every time it was called generating a allocation and free each time. Changed to have an InternalKey member variable that can be reset with the new InternalKey::Set() function. In SstFileWriter::Add() the smallest_key and largest_key values were assigned the result of a ToString() call, but it is simpler to just assign them directly from the users key. The Slice class had no move constructor so each time one was returned from a function a new one had to be allocated, the old data copied to the new, and the old one was freed. I added the move constructor which also required a copy constructor and assignment operator. The BlockBuilder::CurrentSizeEstimate() function calculates the current estimate size, but was being called 2 or 3 times for each key added. I changed the class to maintain a running estimate (equal to the original calculation) so that the function can return an already calculated value. The code in BlockBuilder::Add() that calculated the shared bytes between the last key and the new key duplicated what Slice::difference_offset does, so I replaced it with the standard function. BlockBuilder::Add() had code to copy just the changed portion into the last key value (and asserted that it now matched the new key). It is more efficient just to copy the whole new key over. Moved this same code up into the if (use_delta_encoding_) since the last key value is only needed when delta encoding is on. FlushBlockBySizePolicy::BlockAlmostFull calculated a standard deviation value each time it was called, but this information would only change if block_size of block_size_deviation changed, so I created a member variable to hold the value to avoid the calculation each time. Each PutVarint??() function has a buffer and calls std::string::append(). Two or three calls in a row could share a buffer and a single call to std::string::append(). Some of these will be helpful outside of the SstFileWriter. Im not 100% the addition of the move constructor is appropriate as I wonder why this wasnt done before maybe because of compiler compatibility? I tried it on gcc 4.8 and 4.9. Test Plan: The changes should not affect the results so the existing tests should all still work and no new tests were added. The value of the changes was seen by manually testing the SstFileWriter class through MyRocks and adding timing code to identify problem areas. Reviewers: sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba Differential Revision:"
,,0.5547,rocksdb,"Miscellaneous performance improvements Summary: I was investigating performance issues in the SstFileWriter and found all of the following: The SstFileWriter::Add() function created a local InternalKey every time it was called generating a allocation and free each time. Changed to have an InternalKey member variable that can be reset with the new InternalKey::Set() function. In SstFileWriter::Add() the smallest_key and largest_key values were assigned the result of a ToString() call, but it is simpler to just assign them directly from the users key. The Slice class had no move constructor so each time one was returned from a function a new one had to be allocated, the old data copied to the new, and the old one was freed. I added the move constructor which also required a copy constructor and assignment operator. The BlockBuilder::CurrentSizeEstimate() function calculates the current estimate size, but was being called 2 or 3 times for each key added. I changed the class to maintain a running estimate (equal to the original calculation) so that the function can return an already calculated value. The code in BlockBuilder::Add() that calculated the shared bytes between the last key and the new key duplicated what Slice::difference_offset does, so I replaced it with the standard function. BlockBuilder::Add() had code to copy just the changed portion into the last key value (and asserted that it now matched the new key). It is more efficient just to copy the whole new key over. Moved this same code up into the if (use_delta_encoding_) since the last key value is only needed when delta encoding is on. FlushBlockBySizePolicy::BlockAlmostFull calculated a standard deviation value each time it was called, but this information would only change if block_size of block_size_deviation changed, so I created a member variable to hold the value to avoid the calculation each time. Each PutVarint??() function has a buffer and calls std::string::append(). Two or three calls in a row could share a buffer and a single call to std::string::append(). Some of these will be helpful outside of the SstFileWriter. Im not 100% the addition of the move constructor is appropriate as I wonder why this wasnt done before maybe because of compiler compatibility? I tried it on gcc 4.8 and 4.9. Test Plan: The changes should not affect the results so the existing tests should all still work and no new tests were added. The value of the changes was seen by manually testing the SstFileWriter class through MyRocks and adding timing code to identify problem areas. Reviewers: sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba Differential Revision:"
,,0.2633,rocksdb,"New Statistics to track Compression/Decompression (#1197) * Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer). * Prevent incrementing compression counter when compression is turned off in options. * Prevent incrementing compression counter when compression is turned off in options. * Added two more supported compression types to test code in db_test.cc * Prevent incrementing compression counter when compression is turned off in options. * Added new StatsLevel that excludes compression timing. * Fixed casting error in coding.h * Fixed CompressionStatsTest for new StatsLevel. * Removed unused variable that was breaking the Linux build/"
,,0.2403,rocksdb,"New Statistics to track Compression/Decompression (#1197) * Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer). * Prevent incrementing compression counter when compression is turned off in options. * Prevent incrementing compression counter when compression is turned off in options. * Added two more supported compression types to test code in db_test.cc * Prevent incrementing compression counter when compression is turned off in options. * Added new StatsLevel that excludes compression timing. * Fixed casting error in coding.h * Fixed CompressionStatsTest for new StatsLevel. * Removed unused variable that was breaking the Linux build/Add a check mode to verify compressed block can be decompressed back Summary: Try to decompress compressed blocks when a special flag is set. assert and crash in debug builds if we cant decompress the just-compressed input. Test Plan: Run unit-tests. Reviewers: dhruba, andrewkr, sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba Differential Revision:"
,,0.0577,rocksdb,fix simple typos (#1183)/
,,0.573,rocksdb,"Miscellaneous performance improvements Summary: I was investigating performance issues in the SstFileWriter and found all of the following: The SstFileWriter::Add() function created a local InternalKey every time it was called generating a allocation and free each time. Changed to have an InternalKey member variable that can be reset with the new InternalKey::Set() function. In SstFileWriter::Add() the smallest_key and largest_key values were assigned the result of a ToString() call, but it is simpler to just assign them directly from the users key. The Slice class had no move constructor so each time one was returned from a function a new one had to be allocated, the old data copied to the new, and the old one was freed. I added the move constructor which also required a copy constructor and assignment operator. The BlockBuilder::CurrentSizeEstimate() function calculates the current estimate size, but was being called 2 or 3 times for each key added. I changed the class to maintain a running estimate (equal to the original calculation) so that the function can return an already calculated value. The code in BlockBuilder::Add() that calculated the shared bytes between the last key and the new key duplicated what Slice::difference_offset does, so I replaced it with the standard function. BlockBuilder::Add() had code to copy just the changed portion into the last key value (and asserted that it now matched the new key). It is more efficient just to copy the whole new key over. Moved this same code up into the if (use_delta_encoding_) since the last key value is only needed when delta encoding is on. FlushBlockBySizePolicy::BlockAlmostFull calculated a standard deviation value each time it was called, but this information would only change if block_size of block_size_deviation changed, so I created a member variable to hold the value to avoid the calculation each time. Each PutVarint??() function has a buffer and calls std::string::append(). Two or three calls in a row could share a buffer and a single call to std::string::append(). Some of these will be helpful outside of the SstFileWriter. Im not 100% the addition of the move constructor is appropriate as I wonder why this wasnt done before maybe because of compiler compatibility? I tried it on gcc 4.8 and 4.9. Test Plan: The changes should not affect the results so the existing tests should all still work and no new tests were added. The value of the changes was seen by manually testing the SstFileWriter class through MyRocks and adding timing code to identify problem areas. Reviewers: sdong, IslamAbdelRahman Reviewed By: IslamAbdelRahman Subscribers: andrewkr, dhruba Differential Revision:"
,,0.2531,rocksdb,"Fix flush not being commit while writing manifest Summary: Fix flush not being commit while writing manifest, which is a recent bug introduced by D60075. The issue: Options.max_background_flushes > 1 Background thread A pick up a flush job, flush, then commit to manifest. (Note that mutex is released before writing manifest.) Background thread B pick up another flush job, flush. When it gets to `MemTableList::InstallMemtableFlushResults`, it notices another thread is commiting, so it quit. After the first commit, thread A doesnt double check if there are more flush result need to commit, leaving the second flush uncommitted. Test Plan: run the test. Also verify the new test hit deadlock without the fix. Reviewers: sdong, igor, lightmark Reviewed By: lightmark Subscribers: andrewkr, omegaga, dhruba, leveldb Differential Revision: multiple batch of flush into one manifest file (one call to LogAndApply) Summary: Currently, if several flush outputs are committed together, we issue each manifest write per batch (1 batch 1 flush 1 sst file 1+ continuous memtables). Each manifest write requires one fsync and one fsync to parent directory. In some cases, it becomes the bottleneck of write. We should batch them and write in one manifest write when possible. Test Plan: ` ./db_bench **Before** ``` Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 4.9 Date: Fri Jul 1 15:38:17 2016 CPU: 32 * Intel(R) Xeon(R) CPU E5-2660 0 2.20GHz CPUCache: 20480 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 166.277 micros/op 6014 ops/sec; 0.7 MB/s ``` **After** ``` Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 4.9 Date: Fri Jul 1 15:35:05 2016 CPU: 32 * Intel(R) Xeon(R) CPU E5-2660 0 2.20GHz CPUCache: 20480 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 52.328 micros/op 19110 ops/sec; 2.1 MB/s ``` Reviewers: andrewkr, IslamAbdelRahman, yhchiang, sdong Reviewed By: sdong Subscribers: igor, andrewkr, dhruba, leveldb Differential Revision:"
,,0.3103,rocksdb,"group multiple batch of flush into one manifest file (one call to LogAndApply) Summary: Currently, if several flush outputs are committed together, we issue each manifest write per batch (1 batch 1 flush 1 sst file 1+ continuous memtables). Each manifest write requires one fsync and one fsync to parent directory. In some cases, it becomes the bottleneck of write. We should batch them and write in one manifest write when possible. Test Plan: ` ./db_bench **Before** ``` Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 4.9 Date: Fri Jul 1 15:38:17 2016 CPU: 32 * Intel(R) Xeon(R) CPU E5-2660 0 2.20GHz CPUCache: 20480 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 166.277 micros/op 6014 ops/sec; 0.7 MB/s ``` **After** ``` Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 4.9 Date: Fri Jul 1 15:35:05 2016 CPU: 32 * Intel(R) Xeon(R) CPU E5-2660 0 2.20GHz CPUCache: 20480 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 52.328 micros/op 19110 ops/sec; 2.1 MB/s ``` Reviewers: andrewkr, IslamAbdelRahman, yhchiang, sdong Reviewed By: sdong Subscribers: igor, andrewkr, dhruba, leveldb Differential Revision:"
,,0.2587,rocksdb,"New Statistics to track Compression/Decompression (#1197) * Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer). * Prevent incrementing compression counter when compression is turned off in options. * Prevent incrementing compression counter when compression is turned off in options. * Added two more supported compression types to test code in db_test.cc * Prevent incrementing compression counter when compression is turned off in options. * Added new StatsLevel that excludes compression timing. * Fixed casting error in coding.h * Fixed CompressionStatsTest for new StatsLevel. * Removed unused variable that was breaking the Linux build/"
,,0.0697,rocksdb,Add Status to RocksDBException so that meaningful function result Status from the C++ API isnt lost (#1273)/
,,0.1261,rocksdb,"Minor fix to GFLAGS usage in persistent cache Summary: The general convention in RocksDB is to use GFLAGS instead of google. Fixing the anomaly. Closes Differential Revision: D4149213 Pulled By: kradhakrishnan fbshipit-source-id: 2dafa53/cmake support for linux and osx (#1358) * enable cmake to work on linux and osx also * port part of build_detect_platform not covered by thirdparty.inc to cmake. detect fallocate() detect malloc_usable_size() detect JeMalloc detect snappy * check for asan,tsan,ubsan * create build_version.cc in build directory. * add `check` target to support make check. * add `tools` target to match its counterpart in Makefile. * use `date` on non-win32 platforms. * pass different cflags on non-win32 platforms * detect pthead library using FindThread cmake module. * enable CMP0042 to silence the cmake warning on osx * reorder the linked libraries. because testutillib references gtest, to enable the linker to find the referenced symbols, we need to put gtest after testutillib. Signed-off-by: Marcus Watts Signed-off-by: Kefu Chai * hash_table_bench.cc: fix build without gflags Signed-off-by: Kefu Chai * remove gtest from librocksdb linkage testharness.cc is included in librocksdb sources, and it uses gtest. but gtest is not supposed to be part of the public API of librocksdb. so, in this change, the testharness.cc is moved out out librocksdb, and is built as an object target, then linked with the tools and tests instead. Signed-off-by: Marcus Watts Signed-off-by: Kefu Chai"
,,0.284,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.0981,rocksdb,cast to signed char in ldb_cmd_test for ppc64le Summary: char is unsigned on power by default causing this test to fail with the FF case. ppc64 return 255 while x86 returned Casting works on both platforms. Closes Differential Revision: D4308775 Pulled By: yiwu-arbug fbshipit-source-id: db3e6e0/
,,0.2103,rocksdb,"direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/Dynamic max_total_wal_size option Summary: Closes Differential Revision: D4176426 Pulled By: yiwu-arbug fbshipit-source-id: b57689d/Optimize sequential insert into memtable Part 1: Interface Summary: Currently our skip-list have an optimization to speedup sequential inserts from a single stream, by remembering the last insert position. We extend the idea to support sequential inserts from multiple streams, and even tolerate small reordering wihtin each stream. This PR is the interface part adding the following: Add `memtable_insert_prefix_extractor` to allow specifying prefix for each key. Add `InsertWithHint()` interface to memtable, to allow underlying implementation to return a hint of insert position, which can be later pass back to optimize inserts. Memtable will maintain a map from prefix to hints and pass the hint via `InsertWithHint()` if `memtable_insert_prefix_extractor` is non-null. Closes Differential Revision: D4079367 Pulled By: yiwu-arbug fbshipit-source-id: 3555326/"
,,0.1581,rocksdb,"Generalize Env registration framework Summary: The Env registration framework supports registering client Envs and selecting which one to instantiate according to a text field. This enabled things like adding the argument to db_bench, so the same binary could be reused with different Envs just by changing CLI config. Now this problem has come up again in a non-Env context, as I want to instantiate a client Statistics implementation from db_bench, which is configured entirely via text parameters. Also, in the future we may wish to use it for deserializing client objects when loading OPTIONS file. This diff generalizes the Env registration logic to work with arbitrary types. Generalized registration and instantiation code by templating them The entire implementation is in a header file as thats Google style guides recommendation for template definitions Pattern match with std::regex_match rather than checking prefix, which was the previous behavior Rename functions/files to be non-Env-specific Closes Differential Revision: D4421933 Pulled By: ajkr fbshipit-source-id: 34647d1/std::remove_if requires Summary: fixes error (that occurred on gcc-7): error: util/env_basic_test.cc: In member function virtual rocksdb::Status rocksdb::NormalizingEnvWrapper::GetChildren(const string&, std::vector<std::__cxx11::basic_string<char> >*): util/env_basic_test.cc:27:21: error: remove_if is not a member of std result->erase(std::remove_if(result->begin(), result->end(), ^~~ Closes Differential Revision: D4331221 Pulled By: ajkr fbshipit-source-id: 9bbdc78/Return finer-granularity status from Env::GetChildren* Summary: Itd be nice to use the error status type to distinguish between user error and system error. For example, GetChildren can fail listing a backup directorys contents either because a bad path was provided (user error) or because an operation failed, e.g., a remote storage service call failed (system error). In the former case, we want to continue and treat the backup directory as empty; in the latter case, we want to immediately propagate the error to the caller. This diff uses NotFound to indicate user error and IOError to indicate system error. Previously IOError indicated both. Closes Differential Revision: D4312157 Pulled By: ajkr fbshipit-source-id: 51b4f24/"
,,0.2751,rocksdb,Fix OSX build break after the fallocate change Summary: The recent update about fallocate failed OSX build. Fix it. Closes Differential Revision: D4500235 Pulled By: siying fbshipit-source-id: a5f2b40/direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.2708,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/Dynamic max_total_wal_size option Summary: Closes Differential Revision: D4176426 Pulled By: yiwu-arbug fbshipit-source-id: b57689d/
,,0.289,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.3013,rocksdb,"direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/WritableFileWriter: default buffer size equal min(64k,options.writabl? Summary: ?e_file_max_buffer_size) If we overwrite WritableFile and has a buffer which has the same function of buf_. We hope remove the cache function of WritableFileWriter. So using options.writable_file_max_buffer_size 0 to disable cache function. Signed-off-by: Jianpeng Ma Closes Differential Revision: D4307219 Pulled By: yiwu-arbug fbshipit-source-id: 77a6e26/"
,,0.2602,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/Dynamic max_total_wal_size option Summary: Closes Differential Revision: D4176426 Pulled By: yiwu-arbug fbshipit-source-id: b57689d/
,,0.2915,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.289,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.2485,rocksdb,Change the default of delayed slowdown value to 16MB/s Summary: Change the default of delayed slowdown value to 16MB/s and further increase the L0 stop condition to 36 files. Closes Differential Revision: D4489229 Pulled By: siying fbshipit-source-id: 1003981/direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/fix options_test ubsan Summary: Having value for max_write_buffer_number does not make sense and cause us to do a left shift on a value number Closes Differential Revision: D4240798 Pulled By: IslamAbdelRahman fbshipit-source-id: bd6267e/
,,0.2322,rocksdb,"direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/Optimize sequential insert into memtable Part 1: Interface Summary: Currently our skip-list have an optimization to speedup sequential inserts from a single stream, by remembering the last insert position. We extend the idea to support sequential inserts from multiple streams, and even tolerate small reordering wihtin each stream. This PR is the interface part adding the following: Add `memtable_insert_prefix_extractor` to allow specifying prefix for each key. Add `InsertWithHint()` interface to memtable, to allow underlying implementation to return a hint of insert position, which can be later pass back to optimize inserts. Memtable will maintain a map from prefix to hints and pass the hint via `InsertWithHint()` if `memtable_insert_prefix_extractor` is non-null. Closes Differential Revision: D4079367 Pulled By: yiwu-arbug fbshipit-source-id: 3555326/"
,,0.1233,rocksdb,"EnvPosixTestWithParam should wait for all threads to finish Summary: If we dont wait for the threads to finish after each run, the thread queue may not be empty while the next test starts to run, which can cause unexpected behaviors. Also make some of the relaxed read/write more restrict. Closes Reviewed By: AsyncDBConnMarkedDownDBException Differential Revision: D4245922 Pulled By: AsyncDBConnMarkedDownDBException fbshipit-source-id: f83b74b/Fix Windows environment issues Summary: Enable directIO on WritableFileImpl::Append with offset being current length of the file. Enable UniqueID tests on Windows, disable others but leeting them to compile. Unique tests are valuable to detect failures on different filesystems and upcoming ReFS. Clear output in WinEnv Getchildren.This is different from previous strategy, do not touch output on failure. Make sure DBTest.OpenWhenOpen works with windows error message Closes Differential Revision: D4385681 Pulled By: IslamAbdelRahman fbshipit-source-id: c07b702/"
,,0.2928,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.2684,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/Dynamic max_total_wal_size option Summary: Closes Differential Revision: D4176426 Pulled By: yiwu-arbug fbshipit-source-id: b57689d/
,,0.3166,rocksdb,"direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/Return finer-granularity status from Env::GetChildren* Summary: Itd be nice to use the error status type to distinguish between user error and system error. For example, GetChildren can fail listing a backup directorys contents either because a bad path was provided (user error) or because an operation failed, e.g., a remote storage service call failed (system error). In the former case, we want to continue and treat the backup directory as empty; in the latter case, we want to immediately propagate the error to the caller. This diff uses NotFound to indicate user error and IOError to indicate system error. Previously IOError indicated both. Closes Differential Revision: D4312157 Pulled By: ajkr fbshipit-source-id: 51b4f24/Fix fd leak when using direct IOs Summary: We should close the fd, before overriding it. This bug was introduced by f89caa127baa086cb100976b14da1a531cf0e823 Closes Differential Revision: D4214101 Pulled By: siying fbshipit-source-id: 0d65de0/"
,,0.289,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.284,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.2805,rocksdb,"direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/gcc-7 requires include for std::function Summary: Fixes compile error: In file included from ./util/statistics.h:17:0, from ./util/stop_watch.h:8, from ./util/perf_step_timer.h:9, from ./util/iostats_context_imp.h:8, from ./util/posix_logger.h:27, from ./port/util_logger.h:18, from ./db/auto_roll_logger.h:15, from db/auto_roll_logger.cc:6: ./util/thread_local.h:65:16: error: function in namespace std does not name a template type typedef std::function<void(void*, void*)> FoldFunc; Closes Differential Revision: D4318702 Pulled By: yiwu-arbug fbshipit-source-id: 8c5d17a/Return finer-granularity status from Env::GetChildren* Summary: Itd be nice to use the error status type to distinguish between user error and system error. For example, GetChildren can fail listing a backup directorys contents either because a bad path was provided (user error) or because an operation failed, e.g., a remote storage service call failed (system error). In the former case, we want to continue and treat the backup directory as empty; in the latter case, we want to immediately propagate the error to the caller. This diff uses NotFound to indicate user error and IOError to indicate system error. Previously IOError indicated both. Closes Differential Revision: D4312157 Pulled By: ajkr fbshipit-source-id: 51b4f24/"
,,0.2346,rocksdb,improving the C wrapper Summary: rocksdb_property_int (so that we dont have to parse strings) and rocksdb_set_options (to allow controlling options via strings) a few other missing options exposed a documentation comment fix Closes Differential Revision: D4456569 Pulled By: yiwu-arbug fbshipit-source-id: 9f1fac1/c: allow set savepoint to writebatch Summary: Allow set SavePoint to WriteBatch in C ABI. Closes Differential Revision: D4378556 Pulled By: yiwu-arbug fbshipit-source-id: afca746/direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/C API: support get usage and pinned_usage for cache Summary: Closes Differential Revision: D4327453 Pulled By: yiwu-arbug fbshipit-source-id: bcdbc65/CompactRangeOptions C API Summary: Add C API for CompactRangeOptions. Closes Differential Revision: D4252339 Pulled By: yiwu-arbug fbshipit-source-id: f768f93/c api: expose option for dynamic level size target Summary: Closes Differential Revision: D4245923 Pulled By: yiwu-arbug fbshipit-source-id: 6ee7291/Add C API to set base_backgroud_compactions Summary: Add C API to set base_backgroud_compactions Closes Differential Revision: D4245709 Pulled By: yiwu-arbug fbshipit-source-id: 792c6b8/
,,0.2915,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.2789,rocksdb,include/rocksdb/utilities/env_librados: fix typo Summary: Broken by 972f96b3fbae1a4675043bdf4279c9072ad69645 Signed-off-by: Sage Weil Closes Differential Revision: D4366123 Pulled By: IslamAbdelRahman fbshipit-source-id: a11e535/direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.2853,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.2853,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.2865,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.2915,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.2853,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.2853,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.2683,rocksdb,"direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/gcc-7 requires include for std::function Summary: Fixes compile error: In file included from ./util/statistics.h:17:0, from ./util/stop_watch.h:8, from ./util/perf_step_timer.h:9, from ./util/iostats_context_imp.h:8, from ./util/posix_logger.h:27, from ./port/util_logger.h:18, from ./db/auto_roll_logger.h:15, from db/auto_roll_logger.cc:6: ./util/thread_local.h:65:16: error: function in namespace std does not name a template type typedef std::function<void(void*, void*)> FoldFunc; Closes Differential Revision: D4318702 Pulled By: yiwu-arbug fbshipit-source-id: 8c5d17a/Fail BackupEngine::Open upon meta-file read error Summary: We used to treat any failure to read a backups meta-file as if the backup were corrupted; however, we should distinguish corruption errors from errors in the backup Env. This fixes an issue where callers would get inconsistent results from GetBackupInfo() if they called it on an engine that encountered Env error during initialization. Now we fail Initialize() in this case so callers cannot invoke GetBackupInfo() on such engines. Closes Differential Revision: D4318573 Pulled By: ajkr fbshipit-source-id: f7a7c54/More accurate error status for BackupEngine::Open Summary: Some users are assuming NotFound means the backup does not exist at the provided path, which is a reasonable assumption. We need to stop returning NotFound for system errors. Depends on Closes Differential Revision: D4312233 Pulled By: ajkr fbshipit-source-id: 5343c10/"
,,0.2853,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.1819,rocksdb,"Use more efficient hash map for deadlock detection Summary: Currently, deadlock cycles are held in std::unordered_map. The problem with it is that it allocates/deallocates memory on every insertion/deletion. This limits throughput since were doing this expensive operation while holding a global mutex. Fix this by using a vector which caches memory instead. Running the deadlock stress test, this change increased throughput from 39k txns/s 49k txns/s. The effect is more noticeable in MyRocks. Closes Differential Revision: D4205662 Pulled By: lth fbshipit-source-id: ff990e4/"
,,0.1522,rocksdb,"Fix compile error in trasaction_lock_mgr.cc Summary: Fix error on mac/windows build since they dont recognize `uint`. Closes Differential Revision: D4287139 Pulled By: yiwu-arbug fbshipit-source-id: b7cc88f/Use more efficient hash map for deadlock detection Summary: Currently, deadlock cycles are held in std::unordered_map. The problem with it is that it allocates/deallocates memory on every insertion/deletion. This limits throughput since were doing this expensive operation while holding a global mutex. Fix this by using a vector which caches memory instead. Running the deadlock stress test, this change increased throughput from 39k txns/s 49k txns/s. The effect is more noticeable in MyRocks. Closes Differential Revision: D4205662 Pulled By: lth fbshipit-source-id: ff990e4/"
,,0.2878,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.2494,rocksdb,"Fix tests under GCC_481 Summary: This fix the issue with tests failing under GCC 481, I am not sure what is the exact reason Closes Differential Revision: D4374094 Pulled By: IslamAbdelRahman fbshipit-source-id: b3625bc/direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/Iterator should be in corrupted status if merge operator return false Summary: Iterator should be in corrupted status if merge operator return false. Also add test to make sure if max_successive_merges is hit during write, data will not be lost. Closes Differential Revision: D4322695 Pulled By: yiwu-arbug fbshipit-source-id: b327b05/Add WriteOptions.no_slowdown Summary: If the WriteOptions.no_slowdown flag is set AND we need to wait or sleep for the write request, then fail immediately with Status::Incomplete(). Closes Differential Revision: D4191405 Pulled By: maysamyabandeh fbshipit-source-id: 7f3ce3f/"
,,0.3119,rocksdb,"Fix Windows environment issues Summary: Enable directIO on WritableFileImpl::Append with offset being current length of the file. Enable UniqueID tests on Windows, disable others but leeting them to compile. Unique tests are valuable to detect failures on different filesystems and upcoming ReFS. Clear output in WinEnv Getchildren.This is different from previous strategy, do not touch output on failure. Make sure DBTest.OpenWhenOpen works with windows error message Closes Differential Revision: D4385681 Pulled By: IslamAbdelRahman fbshipit-source-id: c07b702/direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/Return finer-granularity status from Env::GetChildren* Summary: Itd be nice to use the error status type to distinguish between user error and system error. For example, GetChildren can fail listing a backup directorys contents either because a bad path was provided (user error) or because an operation failed, e.g., a remote storage service call failed (system error). In the former case, we want to continue and treat the backup directory as empty; in the latter case, we want to immediately propagate the error to the caller. This diff uses NotFound to indicate user error and IOError to indicate system error. Previously IOError indicated both. Closes Differential Revision: D4312157 Pulled By: ajkr fbshipit-source-id: 51b4f24/"
,,0.2853,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.2815,rocksdb,direct io write support Summary: rocksdb direct io support ``` ~/rocksdb] ./db_bench Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags RocksDB: version 5.0 Date: Wed Nov 23 13:17:43 2016 CPU: 40 * Intel(R) Xeon(R) CPU E5-2660 v2 2.20GHz CPUCache: 25600 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 Prefix: 0 bytes Keys per prefix: 0 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) Write rate: 0 bytes/second Compression: Snappy Memtablerep: skip_list Perf Level: 1 WARNING: Assertions are enabled; benchmarks unnecessarily slow Initializing RocksDB Options from the specified file Initializing RocksDB Options from command-line flags DB path: [/tmp/rocksdbtest-112628/dbbench] fillseq : 4.393 micros/op 227639 ops/sec; 25.2 MB/s ~/roc Closes Differential Revision: D4241093 Pulled By: lightmark fbshipit-source-id: 98c29e3/
,,0.1442,rocksdb,"Reunite checkpoint and backup core logic Summary: These code paths forked when checkpoint was introduced by copy/pasting the core backup logic. Over time they diverged and bug fixes were sometimes applied to one but not the other (like fix to include all relevant WALs for 2PC), or it required extra effort to fix both (like fix to forge CURRENT file). This diff reunites the code paths by extracting the core logic into a function, CreateCustomCheckpoint(), that is customizable via callbacks to implement both checkpoint and backup. Related changes: flush_before_backup is now forcibly enabled when 2PC is enabled Extracted CheckpointImpl class definition into a header file. This is so the function, CreateCustomCheckpoint(), can be called by internal rocksdb code but not exposed to users. Implemented more functions in DummyDB/DummyLogFile (in backupable_db_test.cc) that are used by CreateCustomCheckpoint(). Closes Differential Revision: D4622986 Pulled By: ajkr fbshipit-source-id: 157723884236ee3999a682673b64f7457a7a0d87/"
,,0.16399999999999998,rocksdb,"unbiase readamp bitmap Summary: Consider BlockReadAmpBitmap with bytes_per_bit 32. Suppose bytes [a, b) were used, while bytes [a-32, a) and [b+1, b+33) werent used; more formally, the union of ranges passed to BlockReadAmpBitmap::Mark() contains [a, b) and doesnt intersect with [a-32, a) and [b+1, b+33). Then bits [floor(a/32), ceil(b/32)] will be set, and so the number of useful bytes will be estimated as (ceil(b/32) floor(a/32)) * 32, which is on average equal to b-a+31. An extreme example: if we use 1 byte from each block, itll be counted as 32 bytes from each block. Its easy to remove this bias by slightly changing the semantics of the bitmap. Currently each bit represents a byte range [i*32, (i+1)*32). This diff makes each bit represent a single byte: i*32 + X, where X is a random number in [0, 31] generated when bitmap is created. So, e.g., if you read a single byte at random, with probability 31/32 it wont be counted at all, and with probability 1/32 it will be counted as 32 bytes; so, on average its counted as 1 byte. *But there is one exception: the last bit will always set with the old way.* (*) assuming read_amp_bytes_per_bit 32. Closes Differential Revision: D5035652 Pulled By: lightmark fbshipit-source-id: bd98b1b9b49fbe61f9e3781d07f624e3cbd92356/update IterKey that can get user key and internal key explicitly Summary: to void future bug that caused by the mix of userkey/internalkey Closes Differential Revision: D4825889 Pulled By: lightmark fbshipit-source-id: 28411db/"
,,0.0776,rocksdb,fixed typo in util/dynamic_bloom.h Summary: fixed a typo in util/dynamic_bloom.h Closes Differential Revision: D5242397 Pulled By: IslamAbdelRahman fbshipit-source-id: c47fd18cc79afff6b022201a0410c0cd47626576/
,,0.1919,rocksdb,"Prevent empty memtables from using a lot of memory Summary: This fixes OOMs that we (logdevice) are currently having in production. SkipListRep constructor does a couple small allocations from ConcurrentArena (see InlineSkipList constructor). ConcurrentArena would sometimes allocate an entire block for that, which is a few megabytes (we use Options::arena_block_size 4 MB). So an empty memtable can take take 4 MB of memory. We have ~40k column families (spread across 15 DB instances), so 4 MB per empty memtable easily OOMs a machine for us. This PR makes ConcurrentArena always allocate from Arenas inline block when possible. So as long as InlineSkipLists initial allocations are below 2 KB there would be no blocks allocated for empty memtables. Closes Differential Revision: D5404029 Pulled By: al13n321 fbshipit-source-id: 568ec22a3fd1a485c06123f6b2dfc5e9ef67cd23/"
,,0.2033,rocksdb,"Prevent empty memtables from using a lot of memory Summary: This fixes OOMs that we (logdevice) are currently having in production. SkipListRep constructor does a couple small allocations from ConcurrentArena (see InlineSkipList constructor). ConcurrentArena would sometimes allocate an entire block for that, which is a few megabytes (we use Options::arena_block_size 4 MB). So an empty memtable can take take 4 MB of memory. We have ~40k column families (spread across 15 DB instances), so 4 MB per empty memtable easily OOMs a machine for us. This PR makes ConcurrentArena always allocate from Arenas inline block when possible. So as long as InlineSkipLists initial allocations are below 2 KB there would be no blocks allocated for empty memtables. Closes Differential Revision: D5404029 Pulled By: al13n321 fbshipit-source-id: 568ec22a3fd1a485c06123f6b2dfc5e9ef67cd23/"
,,0.1919,rocksdb,"Prevent empty memtables from using a lot of memory Summary: This fixes OOMs that we (logdevice) are currently having in production. SkipListRep constructor does a couple small allocations from ConcurrentArena (see InlineSkipList constructor). ConcurrentArena would sometimes allocate an entire block for that, which is a few megabytes (we use Options::arena_block_size 4 MB). So an empty memtable can take take 4 MB of memory. We have ~40k column families (spread across 15 DB instances), so 4 MB per empty memtable easily OOMs a machine for us. This PR makes ConcurrentArena always allocate from Arenas inline block when possible. So as long as InlineSkipLists initial allocations are below 2 KB there would be no blocks allocated for empty memtables. Closes Differential Revision: D5404029 Pulled By: al13n321 fbshipit-source-id: 568ec22a3fd1a485c06123f6b2dfc5e9ef67cd23/"
,,0.1092,rocksdb,"Make direct I/O write use incremental buffer Summary: Currently for direct I/O, the large maximum buffer is always allocated. This will be wasteful if users flush the data in much smaller chunks. This diff fix this by changing the behavior of incremental buffer works. When we enlarge buffer, we try to copy the existing data in the buffer to the enlarged buffer, rather than flush the buffer first. This can make sure that no extra I/O is introduced because of buffer enlargement. Closes Differential Revision: D5178403 Pulled By: siying fbshipit-source-id: a8fe1e7304bdb8cab2973340022fe80ff83449fd/"
,,0.1197,rocksdb,"fixed typo Summary: fixed typo Closes Differential Revision: D5242471 Pulled By: IslamAbdelRahman fbshipit-source-id: 832eb3a4c70221444ccd2ae63217823fec56c748/Allow SstFileWriter to use the rate limiter Summary: The default IO priority of WritableFiles is IO_TOTAL, meaning that they will bypass the rate limiter if its passed in the options. This change allows to pass an io priority in construction, so that by setting IO_LOW or IO_HIGH the rate limit will be honored. It also fixes a minor bug: SstFileWriters copy and move constructor are not disabled and incorrect, as any copy/move will result in a double free. Switching to unique_ptr makes the object correctly movable and non-copyable as expected. Also fix minor style inconsistencies. Closes Differential Revision: D5113260 Pulled By: sagar0 fbshipit-source-id: e084236e7ff0b50a56cbeceaa9fedd5e210bf9f8/"
,,0.1202,rocksdb,"Allow SstFileWriter to use the rate limiter Summary: The default IO priority of WritableFiles is IO_TOTAL, meaning that they will bypass the rate limiter if its passed in the options. This change allows to pass an io priority in construction, so that by setting IO_LOW or IO_HIGH the rate limit will be honored. It also fixes a minor bug: SstFileWriters copy and move constructor are not disabled and incorrect, as any copy/move will result in a double free. Switching to unique_ptr makes the object correctly movable and non-copyable as expected. Also fix minor style inconsistencies. Closes Differential Revision: D5113260 Pulled By: sagar0 fbshipit-source-id: e084236e7ff0b50a56cbeceaa9fedd5e210bf9f8/"
,,0.1869,rocksdb,"Encryption at rest support Summary: This PR adds support for encrypting data stored by RocksDB when written to disk. It adds an `EncryptedEnv` override of the `Env` class with matching overrides for sequential&random access files. The encryption itself is done through a configurable `EncryptionProvider`. This class creates is asked to create `BlockAccessCipherStream` for a file. This is where the actual encryption/decryption is being done. Currently there is a Counter mode implementation of `BlockAccessCipherStream` with a `ROT13` block cipher (NOTE the `ROT13` is for demo purposes only). The Counter operation mode uses an initial counter & random initialization vector (IV). Both are created randomly for each file and stored in a 4K (default size) block that is prefixed to that file. The `EncryptedEnv` implementation is such that clients of the `Env` class do not see this prefix (nor data, nor in filesize). The largest part of the prefix block is also encrypted, and there is room left for implementation specific settings/values/keys in there. To test the encryption, the `DBTestBase` class has been extended to consider a new environment variable called `ENCRYPTED_ENV`. If set, the test will setup a encrypted instance of the `Env` class to use for all tests. Typically you would run it like this: ``` ENCRYPTED_ENV=1 make check_some ``` There is also an added test that checks that some data inserted into the database is or is not ""visible"" on disk. With `ENCRYPTED_ENV` active it must not find plain text strings, with `ENCRYPTED_ENV` unset, it must find the plain text strings. Closes Differential Revision: D5322178 Pulled By: sdwilsh fbshipit-source-id: 253b0a9c2c498cc98f580df7f2623cbf7678a27f/using ThreadLocalPtr to hide ROCKSDB_SUPPORT_THREAD_LOCAL from publicÖ Summary: Ö headers should not reference RocksDB-specific macros (like ROCKSDB_SUPPORT_THREAD_LOCAL in this case) to public headers, `iostats_context.h` and `perf_context.h`. We shouldnt do that because users have to provide these compiler flags when building their binary with RocksDB. We should hide the thread local global variable inside our implementation and just expose a function api to retrieve these variables. It may break some users for now but good for long term. make check Closes Differential Revision: D5177896 Pulled By: lightmark fbshipit-source-id: 6fcdfac57f2e2dcfe60992b7385c5403f6dcb390/"
,,0.2568,rocksdb,"Make it explicit blob db doesnt support CF Summary: Blob db doesnt currently support column families. Return NotSupported status explicitly. Closes Differential Revision: D5757438 Pulled By: yiwu-arbug fbshipit-source-id: 44de9408fd032c98e8ae337d4db4ed37169bd9fa/specify SSE42 target attribute for Fast_CRC32() Summary: if we enable SSE42 globally when compiling the tree for preparing a portable binary, which could be running on CPU w/o SSE42 instructions even the GCC on the building host is able to emit SSE42 code, this leads to illegal instruction errors on machines not supporting SSE42. to solve this problem, crc32 detects the supported instruction at runtime, and selects the supported CRC32 implementation according to the result of `cpuid`. but intrinics like ""_mm_crc32_u64()"" will not be available unless the ""target"" machine is appropriately specified in the command line, like ""-msse42"", or using the ""target"" attribute. we could pass ""-msse42"" only when compiling crc32c.cc, and allow the compiler to generate the SSE42 instructions, but we are still at the risk of executing illegal instructions on machines does not support SSE42 if the compiler emits code that is not guarded by our runtime detection. and we need to do the change in both Makefile and CMakefile. or, we can use GCCs ""target"" attribute to enable the machine specific instructions on certain function. in this way, we have finer grained control of the used ""target"". and no need to change the makefiles. so we dont need to duplicate the changes on both makefile and cmake as the previous approach. this problem surfaces when preparing a package for GNU/Linux distribution, and we only applies to optimization for SSE42, so using a feature only available on GCC/Clang is not that formidable. Closes Differential Revision: D5786084 Pulled By: siying fbshipit-source-id: bca5c0f877b8d6fb55f58f8f122254a26422843d/"
,,0.2006,rocksdb,"Add iterators SeekForPrev functionality to the java-api Summary: As discussed in , this pull-requests brings the iterators [SeekForPrev()]( functionality to the java-api. It affects all locations in the code where previously only Seek() was supported. All code changes are essentially a copy & paste of the already existing implementations for Seek(). **Please Note**: the changes to the C++ code were applied without fully understanding its effect, so please take a closer look. However, since Seek() and SeekForPrev() provide exactly the same signature, I do not expect any mistake here. The java-tests are extended by new tests for the additional functionality. Compilation (`make rocksdbjavastatic`) and test (`java/make test`) run without errors. Closes Differential Revision: D5721011 Pulled By: sagar0 fbshipit-source-id: c1f951cddc321592c70dd2d32bc04892f3f119f8/"
,,0.1864,rocksdb,"Added CompactionFilterFactory support to RocksJava Summary: This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support. Closes Differential Revision: D6012778 Pulled By: sagar0 fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/Add iterators SeekForPrev functionality to the java-api Summary: As discussed in , this pull-requests brings the iterators [SeekForPrev()]( functionality to the java-api. It affects all locations in the code where previously only Seek() was supported. All code changes are essentially a copy & paste of the already existing implementations for Seek(). **Please Note**: the changes to the C++ code were applied without fully understanding its effect, so please take a closer look. However, since Seek() and SeekForPrev() provide exactly the same signature, I do not expect any mistake here. The java-tests are extended by new tests for the additional functionality. Compilation (`make rocksdbjavastatic`) and test (`java/make test`) run without errors. Closes Differential Revision: D5721011 Pulled By: sagar0 fbshipit-source-id: c1f951cddc321592c70dd2d32bc04892f3f119f8/"
,,0.11599999999999999,rocksdb,"Added CompactionFilterFactory support to RocksJava Summary: This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support. Closes Differential Revision: D6012778 Pulled By: sagar0 fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/Provide byte[] version of SstFileWriter.merge to reduce GC Stall Summary: In Java API, `SstFileWriter.put/merge/delete` takes `Slice` type of key and value, which is a Java wrapper object around C++ Slice object. The Slice object inherited [ `finalize`]( method, which [added huge overhead]( to JVM while creating new SstFile. To address this issue, this PR overload the merge method to take Java byte array instead of the Slice object, and added unit test for it. We also benchmark these two different merge function, where we could see GC Stall reduced from 50% to 1%, and the throughput increased from 50MB to 200MB. Closes Reviewed By: sagar0 Differential Revision: D5653145 Pulled By: scv119 fbshipit-source-id: b55ea58554b573d0b1c6f6170f8d9223811bc4f5/"
,,0.1994,rocksdb,"Add iterators SeekForPrev functionality to the java-api Summary: As discussed in , this pull-requests brings the iterators [SeekForPrev()]( functionality to the java-api. It affects all locations in the code where previously only Seek() was supported. All code changes are essentially a copy & paste of the already existing implementations for Seek(). **Please Note**: the changes to the C++ code were applied without fully understanding its effect, so please take a closer look. However, since Seek() and SeekForPrev() provide exactly the same signature, I do not expect any mistake here. The java-tests are extended by new tests for the additional functionality. Compilation (`make rocksdbjavastatic`) and test (`java/make test`) run without errors. Closes Differential Revision: D5721011 Pulled By: sagar0 fbshipit-source-id: c1f951cddc321592c70dd2d32bc04892f3f119f8/"
,,0.1907,rocksdb,"Added CompactionFilterFactory support to RocksJava Summary: This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support. Closes Differential Revision: D6012778 Pulled By: sagar0 fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/Add iterators SeekForPrev functionality to the java-api Summary: As discussed in , this pull-requests brings the iterators [SeekForPrev()]( functionality to the java-api. It affects all locations in the code where previously only Seek() was supported. All code changes are essentially a copy & paste of the already existing implementations for Seek(). **Please Note**: the changes to the C++ code were applied without fully understanding its effect, so please take a closer look. However, since Seek() and SeekForPrev() provide exactly the same signature, I do not expect any mistake here. The java-tests are extended by new tests for the additional functionality. Compilation (`make rocksdbjavastatic`) and test (`java/make test`) run without errors. Closes Differential Revision: D5721011 Pulled By: sagar0 fbshipit-source-id: c1f951cddc321592c70dd2d32bc04892f3f119f8/"
,,0.1267,rocksdb,"Provide byte[] version of SstFileWriter.merge to reduce GC Stall Summary: In Java API, `SstFileWriter.put/merge/delete` takes `Slice` type of key and value, which is a Java wrapper object around C++ Slice object. The Slice object inherited [ `finalize`]( method, which [added huge overhead]( to JVM while creating new SstFile. To address this issue, this PR overload the merge method to take Java byte array instead of the Slice object, and added unit test for it. We also benchmark these two different merge function, where we could see GC Stall reduced from 50% to 1%, and the throughput increased from 50MB to 200MB. Closes Reviewed By: sagar0 Differential Revision: D5653145 Pulled By: scv119 fbshipit-source-id: b55ea58554b573d0b1c6f6170f8d9223811bc4f5/"
,,0.2019,rocksdb,"Add iterators SeekForPrev functionality to the java-api Summary: As discussed in , this pull-requests brings the iterators [SeekForPrev()]( functionality to the java-api. It affects all locations in the code where previously only Seek() was supported. All code changes are essentially a copy & paste of the already existing implementations for Seek(). **Please Note**: the changes to the C++ code were applied without fully understanding its effect, so please take a closer look. However, since Seek() and SeekForPrev() provide exactly the same signature, I do not expect any mistake here. The java-tests are extended by new tests for the additional functionality. Compilation (`make rocksdbjavastatic`) and test (`java/make test`) run without errors. Closes Differential Revision: D5721011 Pulled By: sagar0 fbshipit-source-id: c1f951cddc321592c70dd2d32bc04892f3f119f8/"
,,0.187,rocksdb,"Add iterators SeekForPrev functionality to the java-api Summary: As discussed in , this pull-requests brings the iterators [SeekForPrev()]( functionality to the java-api. It affects all locations in the code where previously only Seek() was supported. All code changes are essentially a copy & paste of the already existing implementations for Seek(). **Please Note**: the changes to the C++ code were applied without fully understanding its effect, so please take a closer look. However, since Seek() and SeekForPrev() provide exactly the same signature, I do not expect any mistake here. The java-tests are extended by new tests for the additional functionality. Compilation (`make rocksdbjavastatic`) and test (`java/make test`) run without errors. Closes Differential Revision: D5721011 Pulled By: sagar0 fbshipit-source-id: c1f951cddc321592c70dd2d32bc04892f3f119f8/"
,,0.2216,rocksdb,fix backup engine when latest backup corrupt Summary: Backup engine is intentionally openable even when some backups are corrupt. Previously the engine could write new backups as long as the most recent backup wasnt corrupt. This PR makes the backup engine able to create new backups even when the most recent one is corrupt. We now maintain two ID instance variables: `latest_backup_id_` is used when creating backup to choose the new ID `latest_valid_backup_id_` is used when restoring latest backup since we want most recent valid one Closes Differential Revision: D5734148 Pulled By: ajkr fbshipit-source-id: db440707b31df2c7b084188aa5f6368449e10bcf/
,,0.4228,rocksdb,"Port 3 way SSE4.2 crc32c implementation from Folly Summary: **# Summary** RocksDB uses SSE crc32 intrinsics to calculate the crc32 values but it does it in single way fashion (not pipelined on single CPU core). Intels whitepaper () published an algorithm that uses 3-way pipelining for the crc32 intrinsics, then use pclmulqdq intrinsic to combine the values. Because pclmulqdq has overhead on its own, this algorithm will show perf gains on buffers larger than 216 bytes, which makes RocksDB a perfect user, since most of the buffers RocksDB call crc32c on is over 4KB. Initial db_bench show tremendous CPU gain. This change uses the 3-way SSE algorithm by default. The old SSE algorithm is now behind a compiler tag NO_THREEWAY_CRC32C. If user compiles the code with NO_THREEWAY_CRC32C=1 then the old SSE Crc32c algorithm would be used. If the server does not have SSE4.2 at the run time the slow way (Non SSE) will be used. **# Performance Test Results** We ran the FillRandom and ReadRandom benchmarks in db_bench. ReadRandom is the point of interest here since it calculates the CRC32 for the in-mem buffers. We did 3 runs for each algorithm. Before this change the CRC32 value computation takes about 11.5% of total CPU cost, and with the new 3-way algorithm it reduced to around 4.5%. The overall throughput also improved from 25.53MB/s to 27.63MB/s. 1) ReadRandom in db_bench overall metrics PER RUN Algorithm | run | micros/op | ops/sec |Throughput (MB/s) 3-way | 1 | 4.143 | 241387 | 26.7 3-way | 2 | 3.775 | 264872 | 29.3 3-way | 3 | 4.116 | 242929 | 26.9 FastCrc32c|1 | 4.037 | 247727 | 27.4 FastCrc32c|2 | 4.648 | 215166 | 23.8 FastCrc32c|3 | 4.352 | 229799 | 25.4 AVG Algorithm | Average of micros/op | Average of ops/sec | Average of Throughput (MB/s) 3-way | 4.01 | 249,729 | 27.63 FastCrc32c | 4.35 | 230,897 | 25.53 2) Crc32c computation CPU cost (inclusive samples percentage) PER RUN Implementation†| run |† TotalSamples |†Crc32c percentage 3-way † | 1† † |† 4,572,250,000 | 4.37% 3-way † | 2† † |† 3,779,250,000†| 4.62% 3-way † | 3† † |† 4,129,500,000†| 4.48% FastCrc32c† † †| 1† † |† 4,663,500,000†| 11.24% FastCrc32c† † †| 2† † |† 4,047,500,000†| 12.34% FastCrc32c† † †| 3† † |† 4,366,750,000†| 11.68% **# Test Plan** make corruption_test && ./corruption_test By default it uses 3-way SSE algorithm NO_THREEWAY_CRC32C=1 make corruption_test && ./corruption_test make clean && DEBUG_LEVEL=0 make db_bench make clean && DEBUG_LEVEL=0 NO_THREEWAY_CRC32C=1 make db_bench Closes Differential Revision: D6330882 Pulled By: yingsu00 fbshipit-source-id: 8ec3d89719533b63b536a736663ca6f0dd4482e9/"
,,0.3777,rocksdb,"Compilation fixes for powerpc build, error and missing header guards Summary: This pull request contains miscellaneous compilation fixes. Thanks, Chinmay Closes Differential Revision: D6941424 Pulled By: sagar0 fbshipit-source-id: fe9c26507bf131221f2466740204bff40a15614a/crc32: suppress warnings Summary: Workaround a bunch of ""implicit-fallthrough"" compiler errors, like: ``` util/crc32c.cc:533:7: error: this statement may fall through [-Werror=implicit-fallthrough=] crc _mm_crc32_u64(crc, *(uint64_t*)(buf + offset)); ^ util/crc32c.cc:1016:9: note: in expansion of macro ëCRCsingletí CRCsinglet(crc0, next, * 8); ^~~~~~~~~~ util/crc32c.cc:1017:7: note: here case 1: ``` Closes Reviewed By: sagar0 Differential Revision: D6874736 Pulled By: quark-zju fbshipit-source-id: eec9f3bc135e12fca336928d01711006d5c3cb16/Port 3 way SSE4.2 crc32c implementation from Folly Summary: **# Summary** RocksDB uses SSE crc32 intrinsics to calculate the crc32 values but it does it in single way fashion (not pipelined on single CPU core). Intels whitepaper () published an algorithm that uses 3-way pipelining for the crc32 intrinsics, then use pclmulqdq intrinsic to combine the values. Because pclmulqdq has overhead on its own, this algorithm will show perf gains on buffers larger than 216 bytes, which makes RocksDB a perfect user, since most of the buffers RocksDB call crc32c on is over 4KB. Initial db_bench show tremendous CPU gain. This change uses the 3-way SSE algorithm by default. The old SSE algorithm is now behind a compiler tag NO_THREEWAY_CRC32C. If user compiles the code with NO_THREEWAY_CRC32C=1 then the old SSE Crc32c algorithm would be used. If the server does not have SSE4.2 at the run time the slow way (Non SSE) will be used. **# Performance Test Results** We ran the FillRandom and ReadRandom benchmarks in db_bench. ReadRandom is the point of interest here since it calculates the CRC32 for the in-mem buffers. We did 3 runs for each algorithm. Before this change the CRC32 value computation takes about 11.5% of total CPU cost, and with the new 3-way algorithm it reduced to around 4.5%. The overall throughput also improved from 25.53MB/s to 27.63MB/s. 1) ReadRandom in db_bench overall metrics PER RUN Algorithm | run | micros/op | ops/sec |Throughput (MB/s) 3-way | 1 | 4.143 | 241387 | 26.7 3-way | 2 | 3.775 | 264872 | 29.3 3-way | 3 | 4.116 | 242929 | 26.9 FastCrc32c|1 | 4.037 | 247727 | 27.4 FastCrc32c|2 | 4.648 | 215166 | 23.8 FastCrc32c|3 | 4.352 | 229799 | 25.4 AVG Algorithm | Average of micros/op | Average of ops/sec | Average of Throughput (MB/s) 3-way | 4.01 | 249,729 | 27.63 FastCrc32c | 4.35 | 230,897 | 25.53 2) Crc32c computation CPU cost (inclusive samples percentage) PER RUN Implementation†| run |† TotalSamples |†Crc32c percentage 3-way † | 1† † |† 4,572,250,000 | 4.37% 3-way † | 2† † |† 3,779,250,000†| 4.62% 3-way † | 3† † |† 4,129,500,000†| 4.48% FastCrc32c† † †| 1† † |† 4,663,500,000†| 11.24% FastCrc32c† † †| 2† † |† 4,047,500,000†| 12.34% FastCrc32c† † †| 3† † |† 4,366,750,000†| 11.68% **# Test Plan** make corruption_test && ./corruption_test By default it uses 3-way SSE algorithm NO_THREEWAY_CRC32C=1 make corruption_test && ./corruption_test make clean && DEBUG_LEVEL=0 make db_bench make clean && DEBUG_LEVEL=0 NO_THREEWAY_CRC32C=1 make db_bench Closes Differential Revision: D6330882 Pulled By: yingsu00 fbshipit-source-id: 8ec3d89719533b63b536a736663ca6f0dd4482e9/"
,,0.0954,rocksdb,WritePrepared Txn: stress test Summary: Augment the existing MySQLStyleTransactionTest to check for more core case scenarios. The changes showed effective in revealing the bugs reported in and Closes Differential Revision: D6476862 Pulled By: maysamyabandeh fbshipit-source-id: 5068497702d67ffc206a58ed96f8578fbb510137/
,,0.1321,rocksdb,"fix ASAN for DeleteFilesInRange test case Summary: error message was ``` AddressSanitizer: stack-use-after-scope on address 0x7ffd18216c40 at pc 0x0000005edda1 bp 0x7ffd18215550 sp 0x7ffd18214d00 ... Address 0x7ffd18216c40 is located in stack of thread T0 at offset 1952 in frame internal_repo_rocksdb/db_compaction_test.cc:1520 rocksdb::DBCompactionTest_DeleteFileRangeFileEndpointsOverlapBug_Test::TestBody() ``` It was unsafe to have slices referring to the temporary string objects buffers, as those strings were destroyed before the slices were used. Fixed it by assigning the strings returned by `Key()` to local variables. Closes Differential Revision: D6507864 Pulled By: ajkr fbshipit-source-id: dd07de1a0070c6748c1ab4f3d7bd31f9a81889d0/Preserve overlapping file endpoint invariant Summary: Fix for In `DeleteFilesInRange`, use `GetCleanInputsWithinInterval` instead of `GetOverlappingInputs` to make sure we get a clean cut set of files to delete. In `GetCleanInputsWithinInterval`, support nullptr as `begin_key` or `end_key`. In `GetOverlappingInputsRangeBinarySearch`, move the assertion for non-empty range away from `ExtendFileRangeWithinInterval`, which should be allowed to return an empty range (via `end_index begin_index`). Closes Differential Revision: D5772387 Pulled By: ajkr fbshipit-source-id: e554e8461823c6be82b21a9262a2da02b3957881/"
,,0.1987,rocksdb,"Disable onboard cache for compaction output Summary: FILE_FLAG_WRITE_THROUGH is for disabling device on-board cache in windows API, which should be disabled if user doesnt need system cache. There was a perf issue related with this, we found during memtable flush, the high percentile latency jumps significantly. During profiling, we found those high latency (P99.9) read requests got queue-jumped by write requests from memtable flush and takes 80ms or even more time to wait, even when SSD overall IO throughput is relatively low. After enabling FILE_FLAG_WRITE_THROUGH, we rerun the test found high percentile latency drops a lot without observable impact on writes. Scenario 1: 40MB/s + 40MB/s R/W compaction throughput †Original | FILE_FLAG_WRITE_THROUGH | Percentage reduction P99.9 | 56.897 ms | 35.593 ms | P99 | 3.905 ms | 3.896 ms | Scenario 2: 14MB/s + 14MB/s R/W compaction throughput, cohosted with 100+ other rocksdb instances have manually triggered memtable flush operations (memtable is tiny), creating a lot of randomized the small file writes operations during test. Original | FILE_FLAG_WRITE_THROUGH | Percentage reduction P99.9 | 86.227 ms | 50.436 ms | P99 | 8.415 ms | 3.356 ms | Closes Differential Revision: D6624174 Pulled By: miasantreble fbshipit-source-id: 321b86aee9d74470840c70e5d0d4fa9880660a91/"
,,0.2129,rocksdb,"Disable onboard cache for compaction output Summary: FILE_FLAG_WRITE_THROUGH is for disabling device on-board cache in windows API, which should be disabled if user doesnt need system cache. There was a perf issue related with this, we found during memtable flush, the high percentile latency jumps significantly. During profiling, we found those high latency (P99.9) read requests got queue-jumped by write requests from memtable flush and takes 80ms or even more time to wait, even when SSD overall IO throughput is relatively low. After enabling FILE_FLAG_WRITE_THROUGH, we rerun the test found high percentile latency drops a lot without observable impact on writes. Scenario 1: 40MB/s + 40MB/s R/W compaction throughput †Original | FILE_FLAG_WRITE_THROUGH | Percentage reduction P99.9 | 56.897 ms | 35.593 ms | P99 | 3.905 ms | 3.896 ms | Scenario 2: 14MB/s + 14MB/s R/W compaction throughput, cohosted with 100+ other rocksdb instances have manually triggered memtable flush operations (memtable is tiny), creating a lot of randomized the small file writes operations during test. Original | FILE_FLAG_WRITE_THROUGH | Percentage reduction P99.9 | 86.227 ms | 50.436 ms | P99 | 8.415 ms | 3.356 ms | Closes Differential Revision: D6624174 Pulled By: miasantreble fbshipit-source-id: 321b86aee9d74470840c70e5d0d4fa9880660a91/"
,,0.287,rocksdb,"Support lowering CPU priority of background threads Summary: Background activities like compaction can negatively affect latency of higher-priority tasks like request processing. To avoid this, rocksdb already lowers the IO priority of background threads on Linux systems. While this takes care of typical IO-bound systems, it does not help much when CPU (temporarily) becomes the bottleneck. This is especially likely when using more expensive compression settings. This patch adds an API to allow for lowering the CPU priority of background threads, modeled on the IO priority API. Benchmarks (see below) show significant latency and throughput improvements when CPU bound. As a result, workloads with some CPU usage bursts should benefit from lower latencies at a given utilization, or should be able to push utilization higher at a given request latency target. A useful side effect is that compaction CPU usage is now easily visible in common tools, allowing for an easier estimation of the contribution of compaction vs. request processing threads. As with IO priority, the implementation is limited to Linux, degrading to a no-op on other systems. Closes Differential Revision: D7740096 Pulled By: gwicke fbshipit-source-id: e5d32373e8dc403a7b0c2227023f9ce4f22b413c/"
,,0.1767,rocksdb,"Fix deadlock in ColumnFamilyData::InstallSuperVersion() Summary: Deadlock: a memtable flush holds DB::mutex_ and calls ThreadLocalPtr::Scrape(), which locks ThreadLocalPtr mutex; meanwhile, a thread exit handler locks ThreadLocalPtr mutex and calls SuperVersionUnrefHandle, which tries to lock DB::mutex_. This deadlock is hit all the time on our workload. It blocks our release. In general, the problem is that ThreadLocalPtr takes an arbitrary callback and calls it while holding a lock on a global mutex. The same global mutex is (at least in some cases) locked by almost all ThreadLocalPtr methods, on any instance of ThreadLocalPtr. So, therell be a deadlock if the callback tries to do anything to any instance of ThreadLocalPtr, or waits for another thread to do so. So, probably the only safe way to use ThreadLocalPtr callbacks is to do only do simple and lock-free things in them. This PR fixes the deadlock by making sure that local_sv_ never holds the last reference to a SuperVersion, and therefore SuperVersionUnrefHandle never has to do any nontrivial cleanup. I also searched for other uses of ThreadLocalPtr to see if they may have similar bugs. Theres only one other use, in transaction_lock_mgr.cc, and it looks fine. Closes Reviewed By: sagar0 Differential Revision: D7005346 Pulled By: al13n321 fbshipit-source-id: 37575591b84f07a891d6659e87e784660fde815f/"
,,0.0896,rocksdb,"Fix the Logger::Close() and DBImpl::Close() design pattern Summary: The recent Logger::Close() and DBImpl::Close() implementation rely on calling the CloseImpl() virtual function from the destructor, which will not work. Refactor the implementation to have a private close helper function in derived classes that can be called by both CloseImpl() and the destructor. Closes Reviewed By: gfosco Differential Revision: D7049303 Pulled By: anand1976 fbshipit-source-id: 76a64cbf403209216dfe4864ecf96b5d7f3db9f4/"
,,0.2782,rocksdb,"Support lowering CPU priority of background threads Summary: Background activities like compaction can negatively affect latency of higher-priority tasks like request processing. To avoid this, rocksdb already lowers the IO priority of background threads on Linux systems. While this takes care of typical IO-bound systems, it does not help much when CPU (temporarily) becomes the bottleneck. This is especially likely when using more expensive compression settings. This patch adds an API to allow for lowering the CPU priority of background threads, modeled on the IO priority API. Benchmarks (see below) show significant latency and throughput improvements when CPU bound. As a result, workloads with some CPU usage bursts should benefit from lower latencies at a given utilization, or should be able to push utilization higher at a given request latency target. A useful side effect is that compaction CPU usage is now easily visible in common tools, allowing for an easier estimation of the contribution of compaction vs. request processing threads. As with IO priority, the implementation is limited to Linux, degrading to a no-op on other systems. Closes Differential Revision: D7740096 Pulled By: gwicke fbshipit-source-id: e5d32373e8dc403a7b0c2227023f9ce4f22b413c/"
,,0.1317,rocksdb,"Several small ""fixes"" Summary: removed a few unneeded variables fused some variable declarations and their assignments fixed right-trimming code in string_util.cc to not underflow simplifed an assertion move non-nullptr check assertion before dereferencing of that pointer pass an std::string function parameter by const reference instead of by value (avoiding potential copy) Closes Differential Revision: D7004679 Pulled By: sagar0 fbshipit-source-id: 52944952d9b56dfcac3bea3cd7878e315bb563c4/"
,,0.1051,rocksdb,"Make Optimistic Tx database stackable Summary: This change models Optimistic Tx db after Pessimistic TX db. The motivation for this change is to make the ptr polymorphic so it can be held by the same raw or smart ptr. Currently, due to the inheritance of the Opt Tx db not being rooted in the manner of Pess Tx from a single DB root it is more difficult to write clean code and have clear ownership of the database in cases when options dictate instantiate of plan DB, Pess Tx DB or Opt tx db. Closes Differential Revision: D7184502 Pulled By: yiwu-arbug fbshipit-source-id: 31d06efafd79497bb0c230e971857dba3bd962c3/"
,,0.4248,rocksdb,"Second attempt at db_stress crash-recovery verification Summary: Original commit: a4fb1f8c049ee9d61a9da8cf23b64d2c7d36a33f Revert commit (we reverted as a quick fix to get crash tests passing): 6afe22db2e667799d8c903db61750d676bffe152 This PR includes the contents of the original commit plus two bug fixes, which are: In whitebox crash test, only set `--expected_values_path` for `db_stress` runs in the first half of the crash tests duration. In the second half, a fresh DB is created for each `db_stress` run, so we cannot maintain expected state across `db_stress` runs. Made `Exists()` return true for `UNKNOWN_SENTINEL` values. I previously had an assert in `Exists()` that value was not `UNKNOWN_SENTINEL`. But it is possible for post-crash-recovery expected values to be `UNKNOWN_SENTINEL` (i.e., if the crash happens in the middle of an update), in which case this assertion would be tripped. The effect of returning true in this case is there may be cases where a `SingleDelete` deletes no data. But if we had returned false, the effect would be calling `SingleDelete` on a key with multiple older versions, which is not supported. Closes Differential Revision: D7811671 Pulled By: ajkr fbshipit-source-id: 67e0295bfb1695ff9674837f2e05bb29c50efc30/revert db_stress crash-recovery verification Summary: crash-recovery verification is failing in the whitebox testing, which may or may not be a valid correctness issue need more time to investigate. In the meantime, reverting so we dont mask other failures. Closes Differential Revision: D7794516 Pulled By: ajkr fbshipit-source-id: 28ccdfdb9ec9b3b0fb08c15cbf9d2e282201ff33/Add crash-recovery correctness check to db_stress Summary: Previously, our `db_stress` tool held the expected state of the DB in-memory, so after crash-recovery, there was no way to verify data correctness. This PR adds an option, `--expected_values_file`, which specifies a file holding the expected values. In black-box testing, the `db_stress` process can be killed arbitrarily, so updates to the `--expected_values_file` must be atomic. We achieve this by `mmap`ing the file and relying on `std::atomic<uint32_t>` for atomicity. Actually this doesnt provide a total guarantee on what we want as `std::atomic<uint32_t>` could, in theory, be translated into multiple stores surrounded by a mutex. We can verify our assumption by looking at `std::atomic::is_always_lock_free`. For the `mmap`d file, we didnt have an existing way to expose its contents as a raw memory buffer. This PR adds it in the `Env::NewMemoryMappedFileBuffer` function, and `MemoryMappedFileBuffer` class. `db_crashtest.py` is updated to use an expected values file for black-box testing. On the first iteration (when the DB is created), an empty file is provided as `db_stress` will populate it when it runs. On subsequent iterations, that same filename is provided so `db_stress` can check the data is as expected on startup. Closes Differential Revision: D7463144 Pulled By: ajkr fbshipit-source-id: c8f3e82c93e045a90055e2468316be155633bd8b/"
,,0.3165,rocksdb,"Disallow to open RandomRW file if the file doesnt exist Summary: The only use of RandomRW is to change seqno when bulkloading, and in this use case, the file should exist. We should fail the file opening in this case. Closes Differential Revision: D7913719 Pulled By: siying fbshipit-source-id: 62cf6734f1a6acb9e14f715b927da388131c3492/Second attempt at db_stress crash-recovery verification Summary: Original commit: a4fb1f8c049ee9d61a9da8cf23b64d2c7d36a33f Revert commit (we reverted as a quick fix to get crash tests passing): 6afe22db2e667799d8c903db61750d676bffe152 This PR includes the contents of the original commit plus two bug fixes, which are: In whitebox crash test, only set `--expected_values_path` for `db_stress` runs in the first half of the crash tests duration. In the second half, a fresh DB is created for each `db_stress` run, so we cannot maintain expected state across `db_stress` runs. Made `Exists()` return true for `UNKNOWN_SENTINEL` values. I previously had an assert in `Exists()` that value was not `UNKNOWN_SENTINEL`. But it is possible for post-crash-recovery expected values to be `UNKNOWN_SENTINEL` (i.e., if the crash happens in the middle of an update), in which case this assertion would be tripped. The effect of returning true in this case is there may be cases where a `SingleDelete` deletes no data. But if we had returned false, the effect would be calling `SingleDelete` on a key with multiple older versions, which is not supported. Closes Differential Revision: D7811671 Pulled By: ajkr fbshipit-source-id: 67e0295bfb1695ff9674837f2e05bb29c50efc30/revert db_stress crash-recovery verification Summary: crash-recovery verification is failing in the whitebox testing, which may or may not be a valid correctness issue need more time to investigate. In the meantime, reverting so we dont mask other failures. Closes Differential Revision: D7794516 Pulled By: ajkr fbshipit-source-id: 28ccdfdb9ec9b3b0fb08c15cbf9d2e282201ff33/Add crash-recovery correctness check to db_stress Summary: Previously, our `db_stress` tool held the expected state of the DB in-memory, so after crash-recovery, there was no way to verify data correctness. This PR adds an option, `--expected_values_file`, which specifies a file holding the expected values. In black-box testing, the `db_stress` process can be killed arbitrarily, so updates to the `--expected_values_file` must be atomic. We achieve this by `mmap`ing the file and relying on `std::atomic<uint32_t>` for atomicity. Actually this doesnt provide a total guarantee on what we want as `std::atomic<uint32_t>` could, in theory, be translated into multiple stores surrounded by a mutex. We can verify our assumption by looking at `std::atomic::is_always_lock_free`. For the `mmap`d file, we didnt have an existing way to expose its contents as a raw memory buffer. This PR adds it in the `Env::NewMemoryMappedFileBuffer` function, and `MemoryMappedFileBuffer` class. `db_crashtest.py` is updated to use an expected values file for black-box testing. On the first iteration (when the DB is created), an empty file is provided as `db_stress` will populate it when it runs. On subsequent iterations, that same filename is provided so `db_stress` can check the data is as expected on startup. Closes Differential Revision: D7463144 Pulled By: ajkr fbshipit-source-id: c8f3e82c93e045a90055e2468316be155633bd8b/Disable EnvPosixTest::FilePermission Summary: The test is flaky in our CI but could not be reproduce manually on the same CI host. Disabling it. Closes Differential Revision: D7716320 Pulled By: yiwu-arbug fbshipit-source-id: 6bed3b05880c1d24e8dc86bc970e5181bc98fb45/Disallow compactions if there isnt enough free space Summary: This diff handles cases where compaction causes an ENOSPC error. This does not handle corner cases where another background job is started while compaction is running, and the other background job triggers ENOSPC, although we do allow the user to provision for these background jobs with SstFileManager::SetCompactionBufferSize. It also does not handle the case where compaction has finished and some other background job independently triggers ENOSPC. Usage: Functionality is inside SstFileManager. In particular, users should set SstFileManager::SetMaxAllowedSpaceUsage, which is the reference highwatermark for determining whether to cancel compactions. Closes Differential Revision: D7016941 Pulled By: amytai fbshipit-source-id: 8965ab8dd8b00972e771637a41b4e6c645450445/Windows cumulative patch Summary: This patch addressed several issues. Portability including db_test std::thread port::Thread Cc: and %z to ROCKSDB portable macro. Cc: maysamyabandeh Implement Env::AreFilesSame Make the implementation of file unique number more robust Get rid of C-runtime and go directly to Windows API when dealing with file primitives. Implement GetSectorSize() and aling unbuffered read on the value if available. Adjust Windows Logger for the new interface, implement CloseImpl() Cc: anand1976 Fix test running script issue where $status var was of incorrect scope so the failures were swallowed and not reported. DestroyDB() creates a logger and opens a LOG file in the directory being cleaned up. This holds a lock on the folder and the cleanup is prevented. This fails one of the checkpoin tests. We observe the same in production. We close the log file in this change. Fix DBTest2.ReadAmpBitmapLiveInCacheAfterDBClose failure where the test attempts to open a directory with NewRandomAccessFile which does not work on Windows. Fix DBTest.SoftLimit as it is dependent on thread timing. CC: yiwu-arbug Closes Differential Revision: D7156304 Pulled By: siying fbshipit-source-id: 43db0a757f1dfceffeb2b7988043156639173f5b/fix FreeBSD build Summary: Currently FreeBSD build is broken in master and possibly some previous releases due to unrecognized symbol `O_DIRECT`. This PR will fix the build on FreeBSD Closes Differential Revision: D7148646 Pulled By: miasantreble fbshipit-source-id: 95b6c3d310fa531267c086b2cd40a5ab1c042b5a/Fix the Logger::Close() and DBImpl::Close() design pattern Summary: The recent Logger::Close() and DBImpl::Close() implementation rely on calling the CloseImpl() virtual function from the destructor, which will not work. Refactor the implementation to have a private close helper function in derived classes that can be called by both CloseImpl() and the destructor. Closes Reviewed By: gfosco Differential Revision: D7049303 Pulled By: anand1976 fbshipit-source-id: 76a64cbf403209216dfe4864ecf96b5d7f3db9f4/"
,,0.4012,rocksdb,"Disallow to open RandomRW file if the file doesnt exist Summary: The only use of RandomRW is to change seqno when bulkloading, and in this use case, the file should exist. We should fail the file opening in this case. Closes Differential Revision: D7913719 Pulled By: siying fbshipit-source-id: 62cf6734f1a6acb9e14f715b927da388131c3492/Second attempt at db_stress crash-recovery verification Summary: Original commit: a4fb1f8c049ee9d61a9da8cf23b64d2c7d36a33f Revert commit (we reverted as a quick fix to get crash tests passing): 6afe22db2e667799d8c903db61750d676bffe152 This PR includes the contents of the original commit plus two bug fixes, which are: In whitebox crash test, only set `--expected_values_path` for `db_stress` runs in the first half of the crash tests duration. In the second half, a fresh DB is created for each `db_stress` run, so we cannot maintain expected state across `db_stress` runs. Made `Exists()` return true for `UNKNOWN_SENTINEL` values. I previously had an assert in `Exists()` that value was not `UNKNOWN_SENTINEL`. But it is possible for post-crash-recovery expected values to be `UNKNOWN_SENTINEL` (i.e., if the crash happens in the middle of an update), in which case this assertion would be tripped. The effect of returning true in this case is there may be cases where a `SingleDelete` deletes no data. But if we had returned false, the effect would be calling `SingleDelete` on a key with multiple older versions, which is not supported. Closes Differential Revision: D7811671 Pulled By: ajkr fbshipit-source-id: 67e0295bfb1695ff9674837f2e05bb29c50efc30/revert db_stress crash-recovery verification Summary: crash-recovery verification is failing in the whitebox testing, which may or may not be a valid correctness issue need more time to investigate. In the meantime, reverting so we dont mask other failures. Closes Differential Revision: D7794516 Pulled By: ajkr fbshipit-source-id: 28ccdfdb9ec9b3b0fb08c15cbf9d2e282201ff33/initialize local variable for UBSAN in PosixEnv function Summary: It seems clear to me that the variable is initialized before line 492, but it wasnt clear to UBSAN. The failure was: ``` In file included from ./env/io_posix.h:14:0, from env/env_posix.cc:44: ./include/rocksdb/env.h: In member function ëvirtual rocksdb::Status rocksdb::{anonymous}::PosixEnv::NewMemoryMappedFileBuffer(const string&, std::unique_ptr<rocksdb::MemoryMappedFileBuffer>*)í: ./include/rocksdb/env.h:822:36: error: ëbaseí may be used uninitialized in this function [-Werror=maybe-uninitialized] : base(_base), length(_length) {} ^ env/env_posix.cc:482:11: note: ëbaseí was declared here void* base; ``` We can just initialize to nullptr to keep UBSAN happy. Closes Differential Revision: D7756287 Pulled By: ajkr fbshipit-source-id: 0f2efb9594e2d3a30706a4ca7e1d4a6328031bf2/Add crash-recovery correctness check to db_stress Summary: Previously, our `db_stress` tool held the expected state of the DB in-memory, so after crash-recovery, there was no way to verify data correctness. This PR adds an option, `--expected_values_file`, which specifies a file holding the expected values. In black-box testing, the `db_stress` process can be killed arbitrarily, so updates to the `--expected_values_file` must be atomic. We achieve this by `mmap`ing the file and relying on `std::atomic<uint32_t>` for atomicity. Actually this doesnt provide a total guarantee on what we want as `std::atomic<uint32_t>` could, in theory, be translated into multiple stores surrounded by a mutex. We can verify our assumption by looking at `std::atomic::is_always_lock_free`. For the `mmap`d file, we didnt have an existing way to expose its contents as a raw memory buffer. This PR adds it in the `Env::NewMemoryMappedFileBuffer` function, and `MemoryMappedFileBuffer` class. `db_crashtest.py` is updated to use an expected values file for black-box testing. On the first iteration (when the DB is created), an empty file is provided as `db_stress` will populate it when it runs. On subsequent iterations, that same filename is provided so `db_stress` can check the data is as expected on startup. Closes Differential Revision: D7463144 Pulled By: ajkr fbshipit-source-id: c8f3e82c93e045a90055e2468316be155633bd8b/Support lowering CPU priority of background threads Summary: Background activities like compaction can negatively affect latency of higher-priority tasks like request processing. To avoid this, rocksdb already lowers the IO priority of background threads on Linux systems. While this takes care of typical IO-bound systems, it does not help much when CPU (temporarily) becomes the bottleneck. This is especially likely when using more expensive compression settings. This patch adds an API to allow for lowering the CPU priority of background threads, modeled on the IO priority API. Benchmarks (see below) show significant latency and throughput improvements when CPU bound. As a result, workloads with some CPU usage bursts should benefit from lower latencies at a given utilization, or should be able to push utilization higher at a given request latency target. A useful side effect is that compaction CPU usage is now easily visible in common tools, allowing for an easier estimation of the contribution of compaction vs. request processing threads. As with IO priority, the implementation is limited to Linux, degrading to a no-op on other systems. Closes Differential Revision: D7740096 Pulled By: gwicke fbshipit-source-id: e5d32373e8dc403a7b0c2227023f9ce4f22b413c/Use nullptr instead of NULL / 0 more consistently. Summary: Closes Differential Revision: D7170968 Pulled By: yiwu-arbug fbshipit-source-id: 308a6b7dd358a04fd9a7de3d927bfd8abd57d348/Several small ""fixes"" Summary: removed a few unneeded variables fused some variable declarations and their assignments fixed right-trimming code in string_util.cc to not underflow simplifed an assertion move non-nullptr check assertion before dereferencing of that pointer pass an std::string function parameter by const reference instead of by value (avoiding potential copy) Closes Differential Revision: D7004679 Pulled By: sagar0 fbshipit-source-id: 52944952d9b56dfcac3bea3cd7878e315bb563c4/"
,,0.3752,rocksdb,"Second attempt at db_stress crash-recovery verification Summary: Original commit: a4fb1f8c049ee9d61a9da8cf23b64d2c7d36a33f Revert commit (we reverted as a quick fix to get crash tests passing): 6afe22db2e667799d8c903db61750d676bffe152 This PR includes the contents of the original commit plus two bug fixes, which are: In whitebox crash test, only set `--expected_values_path` for `db_stress` runs in the first half of the crash tests duration. In the second half, a fresh DB is created for each `db_stress` run, so we cannot maintain expected state across `db_stress` runs. Made `Exists()` return true for `UNKNOWN_SENTINEL` values. I previously had an assert in `Exists()` that value was not `UNKNOWN_SENTINEL`. But it is possible for post-crash-recovery expected values to be `UNKNOWN_SENTINEL` (i.e., if the crash happens in the middle of an update), in which case this assertion would be tripped. The effect of returning true in this case is there may be cases where a `SingleDelete` deletes no data. But if we had returned false, the effect would be calling `SingleDelete` on a key with multiple older versions, which is not supported. Closes Differential Revision: D7811671 Pulled By: ajkr fbshipit-source-id: 67e0295bfb1695ff9674837f2e05bb29c50efc30/revert db_stress crash-recovery verification Summary: crash-recovery verification is failing in the whitebox testing, which may or may not be a valid correctness issue need more time to investigate. In the meantime, reverting so we dont mask other failures. Closes Differential Revision: D7794516 Pulled By: ajkr fbshipit-source-id: 28ccdfdb9ec9b3b0fb08c15cbf9d2e282201ff33/Add crash-recovery correctness check to db_stress Summary: Previously, our `db_stress` tool held the expected state of the DB in-memory, so after crash-recovery, there was no way to verify data correctness. This PR adds an option, `--expected_values_file`, which specifies a file holding the expected values. In black-box testing, the `db_stress` process can be killed arbitrarily, so updates to the `--expected_values_file` must be atomic. We achieve this by `mmap`ing the file and relying on `std::atomic<uint32_t>` for atomicity. Actually this doesnt provide a total guarantee on what we want as `std::atomic<uint32_t>` could, in theory, be translated into multiple stores surrounded by a mutex. We can verify our assumption by looking at `std::atomic::is_always_lock_free`. For the `mmap`d file, we didnt have an existing way to expose its contents as a raw memory buffer. This PR adds it in the `Env::NewMemoryMappedFileBuffer` function, and `MemoryMappedFileBuffer` class. `db_crashtest.py` is updated to use an expected values file for black-box testing. On the first iteration (when the DB is created), an empty file is provided as `db_stress` will populate it when it runs. On subsequent iterations, that same filename is provided so `db_stress` can check the data is as expected on startup. Closes Differential Revision: D7463144 Pulled By: ajkr fbshipit-source-id: c8f3e82c93e045a90055e2468316be155633bd8b/Disallow compactions if there isnt enough free space Summary: This diff handles cases where compaction causes an ENOSPC error. This does not handle corner cases where another background job is started while compaction is running, and the other background job triggers ENOSPC, although we do allow the user to provision for these background jobs with SstFileManager::SetCompactionBufferSize. It also does not handle the case where compaction has finished and some other background job independently triggers ENOSPC. Usage: Functionality is inside SstFileManager. In particular, users should set SstFileManager::SetMaxAllowedSpaceUsage, which is the reference highwatermark for determining whether to cancel compactions. Closes Differential Revision: D7016941 Pulled By: amytai fbshipit-source-id: 8965ab8dd8b00972e771637a41b4e6c645450445/Fix the Logger::Close() and DBImpl::Close() design pattern Summary: The recent Logger::Close() and DBImpl::Close() implementation rely on calling the CloseImpl() virtual function from the destructor, which will not work. Refactor the implementation to have a private close helper function in derived classes that can be called by both CloseImpl() and the destructor. Closes Reviewed By: gfosco Differential Revision: D7049303 Pulled By: anand1976 fbshipit-source-id: 76a64cbf403209216dfe4864ecf96b5d7f3db9f4/"
,,0.2312,rocksdb,"Avoid directory renames in BackupEngine Summary: We used to name private directories like ""1.tmp"" while BackupEngine populated them, and then rename without the "".tmp"" suffix (i.e., rename ""1.tmp"" to ""1"") after all files were copied. On glusterfs, directory renames like this require operations across many hosts, and partial failures have caused operational problems. Fortunately we dont need to rename private directories. We already have a meta-file that uses the tempfile-rename pattern to commit a backup atomically after all its files have been successfully copied. So we can copy private files directly to their final location, so now theres no directory rename. Closes Differential Revision: D7705610 Pulled By: ajkr fbshipit-source-id: fd724a28dd2bf993ce323a5f2cb7e7d6980cc346/Fix up backupable_db stack corruption. Summary: Fix up OACR(Lint) warnings. Closes Differential Revision: D7563869 Pulled By: ajkr fbshipit-source-id: 8c1e5045c8a6a2d85b2933fdbc60fde93bf0c9de/Fixed buffer overrun in BackupEngineImpl::BackupMeta::StoreToFile Summary: The 10MB buffer in BackupEngineImpl::BackupMeta::StoreToFile can be corrupted with a large number of files. Added a check to determine current buffer length and append data to file if buffer becomes full. Resolves Closes Differential Revision: D7354160 Pulled By: ajkr fbshipit-source-id: eec12d38095a0d17551a4aaee52b99d30a555722/BackupEngine gluster-friendly file naming convention Summary: Use the rsync tempfile naming convention in our `BackupEngine`. The temp file follows the format, `.<filename>.<suffix>`, which is later renamed to `<filename>`. We fix `tmp` as the `<suffix>` as we dont need to use random bytes for now. The benefit is gluster treats this tempfile naming convention specially and applies hashing only to `<filename>`, so the file wont need to be linked or moved when its renamed. Our gluster team suggested this will make things operationally easier. Closes Differential Revision: D6893333 Pulled By: ajkr fbshipit-source-id: fd7622978f4b2487fce33cde40dd3124f16bcaa8/"
,,0.0984,rocksdb,"Make Optimistic Tx database stackable Summary: This change models Optimistic Tx db after Pessimistic TX db. The motivation for this change is to make the ptr polymorphic so it can be held by the same raw or smart ptr. Currently, due to the inheritance of the Opt Tx db not being rooted in the manner of Pess Tx from a single DB root it is more difficult to write clean code and have clear ownership of the database in cases when options dictate instantiate of plan DB, Pess Tx DB or Opt tx db. Closes Differential Revision: D7184502 Pulled By: yiwu-arbug fbshipit-source-id: 31d06efafd79497bb0c230e971857dba3bd962c3/"
,,0.1595,rocksdb,"save redundant key lookup in map of locked keys Summary: In case it is found that a key is already marked as locked in a stripes map of locked keys, it is not necessary to look it up again using `std::unordered_map<std::string, ...>::at(size_t)`. Instead, we can use the already found position using the iterator produced by the previous `find` operation. Reusing the iterator will avoid having to hash the key again and do additional ""random"" memory lookups in the map of keys (though the data will very likely sit available in caches here already due to the previous find operation) Closes Differential Revision: D7036446 Pulled By: sagar0 fbshipit-source-id: cced51547b2bd2d49394f6bc8c5896f09fa80f68/Several small ""fixes"" Summary: removed a few unneeded variables fused some variable declarations and their assignments fixed right-trimming code in string_util.cc to not underflow simplifed an assertion move non-nullptr check assertion before dereferencing of that pointer pass an std::string function parameter by const reference instead of by value (avoiding potential copy) Closes Differential Revision: D7004679 Pulled By: sagar0 fbshipit-source-id: 52944952d9b56dfcac3bea3cd7878e315bb563c4/"
,,0.1834,rocksdb,Fix the bloom filter skipping empty prefixes Summary: bc0da4b5125ac4f43c88879522013814355338e7 optimized bloom filters by skipping duplicate entires when the whole key and prefixes are both added to the bloom. It however used empty string as the initial value of the last entry added to the bloom. This is incorrect since empty key/prefix are valid entires by themselves. This patch fixes that. Closes Differential Revision: D7778803 Pulled By: maysamyabandeh fbshipit-source-id: d5a065daebee17f9403cac51e9d5626aac87bfbc/Skip duplicate bloom keys when whole_key and prefix are mixed Summary: Currently we rely on FilterBitsBuilder to skip the duplicate keys. It does that by comparing that hash of the key to the hash of the last added entry. This logic breaks however when we have whole_key_filtering mixed with prefix blooms as their addition to FilterBitsBuilder will be interleaved. The patch fixes that by comparing the last whole key and last prefix with the whole key and prefix of the new key respectively and skip the call to FilterBitsBuilder if it is a duplicate. Closes Differential Revision: D7744413 Pulled By: maysamyabandeh fbshipit-source-id: 15df73bbbafdfd754d4e1f42ea07f47b03bc5eb8/
,,0.1332,rocksdb,"Several small ""fixes"" Summary: removed a few unneeded variables fused some variable declarations and their assignments fixed right-trimming code in string_util.cc to not underflow simplifed an assertion move non-nullptr check assertion before dereferencing of that pointer pass an std::string function parameter by const reference instead of by value (avoiding potential copy) Closes Differential Revision: D7004679 Pulled By: sagar0 fbshipit-source-id: 52944952d9b56dfcac3bea3cd7878e315bb563c4/"
,,0.1903,rocksdb,Fix the bloom filter skipping empty prefixes Summary: bc0da4b5125ac4f43c88879522013814355338e7 optimized bloom filters by skipping duplicate entires when the whole key and prefixes are both added to the bloom. It however used empty string as the initial value of the last entry added to the bloom. This is incorrect since empty key/prefix are valid entires by themselves. This patch fixes that. Closes Differential Revision: D7778803 Pulled By: maysamyabandeh fbshipit-source-id: d5a065daebee17f9403cac51e9d5626aac87bfbc/Skip duplicate bloom keys when whole_key and prefix are mixed Summary: Currently we rely on FilterBitsBuilder to skip the duplicate keys. It does that by comparing that hash of the key to the hash of the last added entry. This logic breaks however when we have whole_key_filtering mixed with prefix blooms as their addition to FilterBitsBuilder will be interleaved. The patch fixes that by comparing the last whole key and last prefix with the whole key and prefix of the new key respectively and skip the call to FilterBitsBuilder if it is a duplicate. Closes Differential Revision: D7744413 Pulled By: maysamyabandeh fbshipit-source-id: 15df73bbbafdfd754d4e1f42ea07f47b03bc5eb8/
,,0.166,rocksdb,Skip duplicate bloom keys when whole_key and prefix are mixed Summary: Currently we rely on FilterBitsBuilder to skip the duplicate keys. It does that by comparing that hash of the key to the hash of the last added entry. This logic breaks however when we have whole_key_filtering mixed with prefix blooms as their addition to FilterBitsBuilder will be interleaved. The patch fixes that by comparing the last whole key and last prefix with the whole key and prefix of the new key respectively and skip the call to FilterBitsBuilder if it is a duplicate. Closes Differential Revision: D7744413 Pulled By: maysamyabandeh fbshipit-source-id: 15df73bbbafdfd754d4e1f42ea07f47b03bc5eb8/
,,0.1362,rocksdb,"Several small ""fixes"" Summary: removed a few unneeded variables fused some variable declarations and their assignments fixed right-trimming code in string_util.cc to not underflow simplifed an assertion move non-nullptr check assertion before dereferencing of that pointer pass an std::string function parameter by const reference instead of by value (avoiding potential copy) Closes Differential Revision: D7004679 Pulled By: sagar0 fbshipit-source-id: 52944952d9b56dfcac3bea3cd7878e315bb563c4/"
,,0.1471,rocksdb,Avoid acquiring SyncPoint mutex when it is disabled (#3991) Summary: In `db_stress` profile the vast majority of CPU time is spent acquiring the `SyncPoint` mutex. I mistakenly assumed had fixed this mutex contention problem by disabling `SyncPoint` processing. But actually the lock was still being acquired just to check whether processing is enabled. We can avoid that overhead by using an atomic to track whether its enabled. Closes Differential Revision: D8393825 Pulled By: ajkr fbshipit-source-id: 5bc4e3c722ee7304e7a9c2439998c456b05a6897/
,,0.1353,rocksdb,Avoid acquiring SyncPoint mutex when it is disabled (#3991) Summary: In `db_stress` profile the vast majority of CPU time is spent acquiring the `SyncPoint` mutex. I mistakenly assumed had fixed this mutex contention problem by disabling `SyncPoint` processing. But actually the lock was still being acquired just to check whether processing is enabled. We can avoid that overhead by using an atomic to track whether its enabled. Closes Differential Revision: D8393825 Pulled By: ajkr fbshipit-source-id: 5bc4e3c722ee7304e7a9c2439998c456b05a6897/
,,0.1334,rocksdb,"Fix compilation error when OPT=""-DROCKSDB_LITE"". Summary: Closes Differential Revision: D8187733 Pulled By: riversand963 fbshipit-source-id: e4aa179cd0791ca77167e357f99de9afd4aef910/Fix segfault caused by object premature destruction Summary: Please refer to earlier discussion in [issue 3609]( There was also an alternative fix in [PR 3888]( but the proposed solution requires complex change. To summarize the cause of the problem. Upon creation of a column family, a `BlockBasedTableFactory` object is `new`ed and encapsulated by a `std::shared_ptr`. Since there is no other `std::shared_ptr` pointing to this `BlockBasedTableFactory`, when the column family is dropped, the `ColumnFamilyData` is `delete`d, causing the destructor of `std::shared_ptr`. Since there is no other `std::shared_ptr`, the underlying memory is also freed. Later when the db exits, it releases all the table readers, including the table readers that have been operating on the dropped column family. This needs to access the `table_options` owned by `BlockBasedTableFactory` that has already been deleted. Therefore, a segfault is raised. Previous workaround is to purge all obsolete files upon `ColumnFamilyData` destruction, which leads to a force release of table readers of the dropped column family. However this does not work when the user disables file deletion. Our solution in this PR is making a copy of `table_options` in `BlockBasedTable::Rep`. This solution increases memory copy and usage, but is much simpler. Test plan ``` $ make $ ./column_family_test ``` Expected behavior: All tests should pass. Closes Differential Revision: D8149421 Pulled By: riversand963 fbshipit-source-id: eaecc2e064057ef607fbdd4cc275874f866c3438/"
,,0.1981,rocksdb,"adds missing PopSavePoint method to Transaction (#4256) Summary: Transaction has had methods to deal with SavePoints already, but was missing the PopSavePoint method provided by WriteBatch and WriteBatchWithIndex. This PR adds PopSavePoint to Transaction as well. Having the method on Transaction-level too is useful for applications that repeatedly execute a sequence of operations that normally succeed, but infrequently need to get rolled back. Using SavePoints here is sensible, but as operations normally succeed the application may pile up a lot of useless SavePoints inside a Transaction, leading to slightly increased memory usage for managing the unneeded SavePoints. Pull Request resolved: Differential Revision: D9326932 Pulled By: yiwu-arbug fbshipit-source-id: 53a0af18a6c7e87feff8a56f1f3eab9df7f371d6/"
,,0.1846,rocksdb,"adds missing PopSavePoint method to Transaction (#4256) Summary: Transaction has had methods to deal with SavePoints already, but was missing the PopSavePoint method provided by WriteBatch and WriteBatchWithIndex. This PR adds PopSavePoint to Transaction as well. Having the method on Transaction-level too is useful for applications that repeatedly execute a sequence of operations that normally succeed, but infrequently need to get rolled back. Using SavePoints here is sensible, but as operations normally succeed the application may pile up a lot of useless SavePoints inside a Transaction, leading to slightly increased memory usage for managing the unneeded SavePoints. Pull Request resolved: Differential Revision: D9326932 Pulled By: yiwu-arbug fbshipit-source-id: 53a0af18a6c7e87feff8a56f1f3eab9df7f371d6/"
,,0.1932,rocksdb,"adds missing PopSavePoint method to Transaction (#4256) Summary: Transaction has had methods to deal with SavePoints already, but was missing the PopSavePoint method provided by WriteBatch and WriteBatchWithIndex. This PR adds PopSavePoint to Transaction as well. Having the method on Transaction-level too is useful for applications that repeatedly execute a sequence of operations that normally succeed, but infrequently need to get rolled back. Using SavePoints here is sensible, but as operations normally succeed the application may pile up a lot of useless SavePoints inside a Transaction, leading to slightly increased memory usage for managing the unneeded SavePoints. Pull Request resolved: Differential Revision: D9326932 Pulled By: yiwu-arbug fbshipit-source-id: 53a0af18a6c7e87feff8a56f1f3eab9df7f371d6/"
,,0.1016,rocksdb,"Fix snprintf buffer overflow bug (#4465) Summary: The contract of snprintf says that it returns ""The number of characters that would have been written if n had been sufficiently large"" The existing code however was assuming that the return value is the actual number of written bytes and uses that to reposition the starting point on the next call to snprintf. This leads to buffer overflow when the last call to snprintf has filled up the buffer. Pull Request resolved: Differential Revision: D10224080 Pulled By: maysamyabandeh fbshipit-source-id: 40f44e122d15b0db439812a0a361167cf012de3e/"
,,0.114,rocksdb,"Add compile time option to work with utf8 filename strings (#4469) Summary: The default behaviour of rocksdb is to use the `*A(` windows API functions. These accept filenames in the currently configured system encoding, be it Latin 1, utf8 or whatever. If the Application intends to completely work with utf8 strings internally, converting these to that codepage properly isnt even always possible. Thus this patch adds a switch to use the `*W(` functions, which accept UTF-16 filenames, and uses C++11 features to translate the UTF8 containing std::string to an UTF16 containing std::wstring. This feature is a compile time options, that can be enabled by setting `WITH_WINDOWS_UTF8_FILENAMES` to true. Pull Request resolved: Differential Revision: D10356011 Pulled By: yiwu-arbug fbshipit-source-id: 27b6ae9171f209085894cdf80069e8a896642044/"
,,0.0837,rocksdb,"With ldb and wal_dir doesnt exist, ignore it (#4875) Summary: LDB is frequently used to exam data copied. wal_dir in option file is not modified and it usually points to the path it copied from. The user experience will be better if when ldb sees wal_dir pointed by the option file doesnt exist, rather than fail, just ignore it. Pull Request resolved: Differential Revision: D13643173 Pulled By: siying fbshipit-source-id: 2e64d4ea2ec49a6794b9a706b7fc1ba901128bb8/"
,,0.1206,rocksdb,"Allow copy for PerfContext objects (#4919) Summary: Existing implementation of PerfContext does not define copy constructor or assignment operator, which could potentially cause problems when user create copies and resets the builtin one. This PR address the issue by providing these two constructors with deep copy semantics. Pull Request resolved: Differential Revision: D13960406 Pulled By: miasantreble fbshipit-source-id: 36aab5aaee65d4480f537e4e22148faa45e8e334/use per-level perfcontext for DB::Get calls (#4617) Summary: this PR adds two more per-level perf context counters to track * number of keys returned in Get call, break down by levels * total processing time at each level during Get call Pull Request resolved: Differential Revision: D12898024 Pulled By: miasantreble fbshipit-source-id: 6b84ef1c8097c0d9e97bee1a774958f56ab4a6c4/"
,,0.1235,rocksdb,"Fix Java to C++ ticker conversions (#4719) Summary: Added back `NO_ITERATORS` and moved `NO_ITERATOR_CREATED` to the end of `toCppTickers`. This is a leftover fix which is needed in addition to a138e351bcc017667560c7ecbb295800b30881c2 to correctly convert java tickers to c++ tickers. a138e351bcc017667560c7ecbb295800b30881c2 only updated `toJavaTickerType` but both `toJavaTickerType` and `toCppTickers` need to be changed. Pull Request resolved: Differential Revision: D13208847 Pulled By: sagar0 fbshipit-source-id: 53a42f3d6ffe04034acfde972d73040b92b4c1af/Fix compatibility of public ticker stats (#4701) Summary: Added back the `NO_ITERATORS` that was removed in 5945e16dfc6e99522c607841cfd387eebed256fc. Marked it as deprecated since it is no longer populated, but kept for API compatibility. Made sure the new tickers, `NO_ITERATOR_CREATED` and `NO_ITERATOR_DELETED`, are appended at the end of the enum, in case people are relying on the int values. The change where `NO_ITERATOR_CREATED` and `NO_ITERATOR_DELETED` were introduced is unreleased so I believe it is ok to change their ordering. Pull Request resolved: Differential Revision: D13142887 Pulled By: ajkr fbshipit-source-id: 29a336ce5b46632ce50ad42ccc4a29013f71d6d6/Divide `NO_ITERATORS` into two counters `NO_ITERATOR_CREATED` and `NO_ITERATOR_DELETE` (#4498) Summary: Currently, `Statistics` can record tick by `recordTick()` whose second parameter is an `uint64_t`. That means tick can only increase. If we want to reduce tick, we have to work around like `RecordTick(statistics_, NO_ITERATORS, uint64_t(-1));`. Thats kind of a hack. So, this PR divide `NO_ITERATORS` into two counters `NO_ITERATOR_CREATED` and `NO_ITERATOR_DELETE`, making the counters increase only. Fixes . Pull Request resolved: Differential Revision: D10395010 Pulled By: sagar0 fbshipit-source-id: cfb523b22a37411c794b4e9da090f1ae30293db2/"
,,0.1161,rocksdb,"Allow copy for PerfContext objects (#4919) Summary: Existing implementation of PerfContext does not define copy constructor or assignment operator, which could potentially cause problems when user create copies and resets the builtin one. This PR address the issue by providing these two constructors with deep copy semantics. Pull Request resolved: Differential Revision: D13960406 Pulled By: miasantreble fbshipit-source-id: 36aab5aaee65d4480f537e4e22148faa45e8e334/"
,,0.1175,rocksdb,"Allow copy for PerfContext objects (#4919) Summary: Existing implementation of PerfContext does not define copy constructor or assignment operator, which could potentially cause problems when user create copies and resets the builtin one. This PR address the issue by providing these two constructors with deep copy semantics. Pull Request resolved: Differential Revision: D13960406 Pulled By: miasantreble fbshipit-source-id: 36aab5aaee65d4480f537e4e22148faa45e8e334/"
,,0.3494,rocksdb,"Consolidate hash function used for non-persistent data in a new function (#5155) Summary: Create new function NPHash64() and GetSliceNPHash64(), which are currently implemented using murmurhash. Replace the current direct call of murmurhash() to use the new functions if the hash results are not used in on-disk format. This will make it easier to try out or switch to alternative functions in the uses where data format compatibility doesnt need to be considered. This part shouldnt have any performance impact. Also, the sharded cache hash function is changed to the new format, because it falls into this categoery. It doesnt show visible performance impact in db_bench results. CPU showed by perf is increased from about 0.2% to 0.4% in an extreme benchmark setting (4KB blocks, no-compression, everything cached in block cache). Weve known that the current hash function used, our own Hash() has serious hash quality problem. It can generate a lots of conflicts with similar input. In this use case, it means extra lock contention for reads from the same file. This slight CPU regression is worthy to me to counter the potential bad performance with hot keys. And hopefully this will get further improved in the future with a better hash function. cache_tests condition is relaxed a little bit to. The new hash is slightly more skewed in this use case, but I manually checked the data and see the hash results are still in a reasonable range. Pull Request resolved: Differential Revision: D14834821 Pulled By: siying fbshipit-source-id: ec9a2c0a2f8ae4b54d08b13a5c2e9cc97aa80cb5/"
,,0.3403,rocksdb,"Consolidate hash function used for non-persistent data in a new function (#5155) Summary: Create new function NPHash64() and GetSliceNPHash64(), which are currently implemented using murmurhash. Replace the current direct call of murmurhash() to use the new functions if the hash results are not used in on-disk format. This will make it easier to try out or switch to alternative functions in the uses where data format compatibility doesnt need to be considered. This part shouldnt have any performance impact. Also, the sharded cache hash function is changed to the new format, because it falls into this categoery. It doesnt show visible performance impact in db_bench results. CPU showed by perf is increased from about 0.2% to 0.4% in an extreme benchmark setting (4KB blocks, no-compression, everything cached in block cache). Weve known that the current hash function used, our own Hash() has serious hash quality problem. It can generate a lots of conflicts with similar input. In this use case, it means extra lock contention for reads from the same file. This slight CPU regression is worthy to me to counter the potential bad performance with hot keys. And hopefully this will get further improved in the future with a better hash function. cache_tests condition is relaxed a little bit to. The new hash is slightly more skewed in this use case, but I manually checked the data and see the hash results are still in a reasonable range. Pull Request resolved: Differential Revision: D14834821 Pulled By: siying fbshipit-source-id: ec9a2c0a2f8ae4b54d08b13a5c2e9cc97aa80cb5/"
,,0.4558,rocksdb,"refactor SavePoints (#5192) Summary: Savepoints are assumed to be used in a stack-wise fashion (only the top element should be used), so they were stored by `WriteBatch` in a member variable `save_points` using an std::stack. Conceptually this is fine, but the implementation had a few issues: the `save_points_` instance variable was a plain pointer to a heap- allocated `SavePoints` struct. The destructor of `WriteBatch` simply deletes this pointer. However, the copy constructor of WriteBatch just copied that pointer, meaning that copying a WriteBatch with active savepoints will very likely have crashed before. Now a proper copy of the savepoints is made in the copy constructor, and not just a copy of the pointer `save_points_` was an std::stack, which defaults to `std::deque` for the underlying container. A deque is a bit over the top here, as we only need access to the most recent savepoint (i.e. stack.top()) but never any elements at the front. std::deque is rather expensive to initialize in common environments. For example, the STL implementation shipped with GNU g++ will perform a heap allocation of more than 500 bytes to create an empty deque object. Although the `save_points_` container is created lazily by RocksDB, moving from a deque to a plain `std::vector` is much more memory-efficient. So `save_points_` is now a vector. `save_points_` was changed from a plain pointer to an `std::unique_ptr`, making ownership more explicit. Pull Request resolved: Differential Revision: D15024074 Pulled By: maysamyabandeh fbshipit-source-id: 5b128786d3789cde94e46465c9e91badd07a25d7/"
,,0.3626,rocksdb,"Consolidate hash function used for non-persistent data in a new function (#5155) Summary: Create new function NPHash64() and GetSliceNPHash64(), which are currently implemented using murmurhash. Replace the current direct call of murmurhash() to use the new functions if the hash results are not used in on-disk format. This will make it easier to try out or switch to alternative functions in the uses where data format compatibility doesnt need to be considered. This part shouldnt have any performance impact. Also, the sharded cache hash function is changed to the new format, because it falls into this categoery. It doesnt show visible performance impact in db_bench results. CPU showed by perf is increased from about 0.2% to 0.4% in an extreme benchmark setting (4KB blocks, no-compression, everything cached in block cache). Weve known that the current hash function used, our own Hash() has serious hash quality problem. It can generate a lots of conflicts with similar input. In this use case, it means extra lock contention for reads from the same file. This slight CPU regression is worthy to me to counter the potential bad performance with hot keys. And hopefully this will get further improved in the future with a better hash function. cache_tests condition is relaxed a little bit to. The new hash is slightly more skewed in this use case, but I manually checked the data and see the hash results are still in a reasonable range. Pull Request resolved: Differential Revision: D14834821 Pulled By: siying fbshipit-source-id: ec9a2c0a2f8ae4b54d08b13a5c2e9cc97aa80cb5/"
,,0.3461,rocksdb,"Consolidate hash function used for non-persistent data in a new function (#5155) Summary: Create new function NPHash64() and GetSliceNPHash64(), which are currently implemented using murmurhash. Replace the current direct call of murmurhash() to use the new functions if the hash results are not used in on-disk format. This will make it easier to try out or switch to alternative functions in the uses where data format compatibility doesnt need to be considered. This part shouldnt have any performance impact. Also, the sharded cache hash function is changed to the new format, because it falls into this categoery. It doesnt show visible performance impact in db_bench results. CPU showed by perf is increased from about 0.2% to 0.4% in an extreme benchmark setting (4KB blocks, no-compression, everything cached in block cache). Weve known that the current hash function used, our own Hash() has serious hash quality problem. It can generate a lots of conflicts with similar input. In this use case, it means extra lock contention for reads from the same file. This slight CPU regression is worthy to me to counter the potential bad performance with hot keys. And hopefully this will get further improved in the future with a better hash function. cache_tests condition is relaxed a little bit to. The new hash is slightly more skewed in this use case, but I manually checked the data and see the hash results are still in a reasonable range. Pull Request resolved: Differential Revision: D14834821 Pulled By: siying fbshipit-source-id: ec9a2c0a2f8ae4b54d08b13a5c2e9cc97aa80cb5/"
,,0.3502,rocksdb,"Consolidate hash function used for non-persistent data in a new function (#5155) Summary: Create new function NPHash64() and GetSliceNPHash64(), which are currently implemented using murmurhash. Replace the current direct call of murmurhash() to use the new functions if the hash results are not used in on-disk format. This will make it easier to try out or switch to alternative functions in the uses where data format compatibility doesnt need to be considered. This part shouldnt have any performance impact. Also, the sharded cache hash function is changed to the new format, because it falls into this categoery. It doesnt show visible performance impact in db_bench results. CPU showed by perf is increased from about 0.2% to 0.4% in an extreme benchmark setting (4KB blocks, no-compression, everything cached in block cache). Weve known that the current hash function used, our own Hash() has serious hash quality problem. It can generate a lots of conflicts with similar input. In this use case, it means extra lock contention for reads from the same file. This slight CPU regression is worthy to me to counter the potential bad performance with hot keys. And hopefully this will get further improved in the future with a better hash function. cache_tests condition is relaxed a little bit to. The new hash is slightly more skewed in this use case, but I manually checked the data and see the hash results are still in a reasonable range. Pull Request resolved: Differential Revision: D14834821 Pulled By: siying fbshipit-source-id: ec9a2c0a2f8ae4b54d08b13a5c2e9cc97aa80cb5/"
,,0.3477,rocksdb,"Consolidate hash function used for non-persistent data in a new function (#5155) Summary: Create new function NPHash64() and GetSliceNPHash64(), which are currently implemented using murmurhash. Replace the current direct call of murmurhash() to use the new functions if the hash results are not used in on-disk format. This will make it easier to try out or switch to alternative functions in the uses where data format compatibility doesnt need to be considered. This part shouldnt have any performance impact. Also, the sharded cache hash function is changed to the new format, because it falls into this categoery. It doesnt show visible performance impact in db_bench results. CPU showed by perf is increased from about 0.2% to 0.4% in an extreme benchmark setting (4KB blocks, no-compression, everything cached in block cache). Weve known that the current hash function used, our own Hash() has serious hash quality problem. It can generate a lots of conflicts with similar input. In this use case, it means extra lock contention for reads from the same file. This slight CPU regression is worthy to me to counter the potential bad performance with hot keys. And hopefully this will get further improved in the future with a better hash function. cache_tests condition is relaxed a little bit to. The new hash is slightly more skewed in this use case, but I manually checked the data and see the hash results are still in a reasonable range. Pull Request resolved: Differential Revision: D14834821 Pulled By: siying fbshipit-source-id: ec9a2c0a2f8ae4b54d08b13a5c2e9cc97aa80cb5/"
,,0.461,rocksdb,"refactor SavePoints (#5192) Summary: Savepoints are assumed to be used in a stack-wise fashion (only the top element should be used), so they were stored by `WriteBatch` in a member variable `save_points` using an std::stack. Conceptually this is fine, but the implementation had a few issues: the `save_points_` instance variable was a plain pointer to a heap- allocated `SavePoints` struct. The destructor of `WriteBatch` simply deletes this pointer. However, the copy constructor of WriteBatch just copied that pointer, meaning that copying a WriteBatch with active savepoints will very likely have crashed before. Now a proper copy of the savepoints is made in the copy constructor, and not just a copy of the pointer `save_points_` was an std::stack, which defaults to `std::deque` for the underlying container. A deque is a bit over the top here, as we only need access to the most recent savepoint (i.e. stack.top()) but never any elements at the front. std::deque is rather expensive to initialize in common environments. For example, the STL implementation shipped with GNU g++ will perform a heap allocation of more than 500 bytes to create an empty deque object. Although the `save_points_` container is created lazily by RocksDB, moving from a deque to a plain `std::vector` is much more memory-efficient. So `save_points_` is now a vector. `save_points_` was changed from a plain pointer to an `std::unique_ptr`, making ownership more explicit. Pull Request resolved: Differential Revision: D15024074 Pulled By: maysamyabandeh fbshipit-source-id: 5b128786d3789cde94e46465c9e91badd07a25d7/"
,,0.4669,rocksdb,"refactor SavePoints (#5192) Summary: Savepoints are assumed to be used in a stack-wise fashion (only the top element should be used), so they were stored by `WriteBatch` in a member variable `save_points` using an std::stack. Conceptually this is fine, but the implementation had a few issues: the `save_points_` instance variable was a plain pointer to a heap- allocated `SavePoints` struct. The destructor of `WriteBatch` simply deletes this pointer. However, the copy constructor of WriteBatch just copied that pointer, meaning that copying a WriteBatch with active savepoints will very likely have crashed before. Now a proper copy of the savepoints is made in the copy constructor, and not just a copy of the pointer `save_points_` was an std::stack, which defaults to `std::deque` for the underlying container. A deque is a bit over the top here, as we only need access to the most recent savepoint (i.e. stack.top()) but never any elements at the front. std::deque is rather expensive to initialize in common environments. For example, the STL implementation shipped with GNU g++ will perform a heap allocation of more than 500 bytes to create an empty deque object. Although the `save_points_` container is created lazily by RocksDB, moving from a deque to a plain `std::vector` is much more memory-efficient. So `save_points_` is now a vector. `save_points_` was changed from a plain pointer to an `std::unique_ptr`, making ownership more explicit. Pull Request resolved: Differential Revision: D15024074 Pulled By: maysamyabandeh fbshipit-source-id: 5b128786d3789cde94e46465c9e91badd07a25d7/"
,,0.4558,rocksdb,"refactor SavePoints (#5192) Summary: Savepoints are assumed to be used in a stack-wise fashion (only the top element should be used), so they were stored by `WriteBatch` in a member variable `save_points` using an std::stack. Conceptually this is fine, but the implementation had a few issues: the `save_points_` instance variable was a plain pointer to a heap- allocated `SavePoints` struct. The destructor of `WriteBatch` simply deletes this pointer. However, the copy constructor of WriteBatch just copied that pointer, meaning that copying a WriteBatch with active savepoints will very likely have crashed before. Now a proper copy of the savepoints is made in the copy constructor, and not just a copy of the pointer `save_points_` was an std::stack, which defaults to `std::deque` for the underlying container. A deque is a bit over the top here, as we only need access to the most recent savepoint (i.e. stack.top()) but never any elements at the front. std::deque is rather expensive to initialize in common environments. For example, the STL implementation shipped with GNU g++ will perform a heap allocation of more than 500 bytes to create an empty deque object. Although the `save_points_` container is created lazily by RocksDB, moving from a deque to a plain `std::vector` is much more memory-efficient. So `save_points_` is now a vector. `save_points_` was changed from a plain pointer to an `std::unique_ptr`, making ownership more explicit. Pull Request resolved: Differential Revision: D15024074 Pulled By: maysamyabandeh fbshipit-source-id: 5b128786d3789cde94e46465c9e91badd07a25d7/"
,,0.0903,rocksdb,"Removed const fields in copyable classes (#5095) Summary: This fixed the compile error in Clang-8: ``` error: explicitly defaulted copy assignment operator is implicitly deleted [-Werror,-Wdefaulted-function-deleted] ``` Pull Request resolved: Differential Revision: D14811961 Pulled By: riversand963 fbshipit-source-id: d935d1f85a4e8694dca10033fb5af92d8777eca0/"
,,0.2637,rocksdb,"rename variable to avoid shadowing (#5204) Summary: this PR fixes the following compile warning: ``` db/memtable.cc: In member function ëvirtual void rocksdb::MemTableIterator::Seek(const rocksdb::Slice&)í: db/memtable.cc:321:22: error: declaration of ëuser_keyí shadows a member of this [-Werror=shadow] Slice user_key(ExtractUserKey(k)); ^ db/memtable.cc: In member function ëvirtual void rocksdb::MemTableIterator::SeekForPrev(const rocksdb::Slice&)í: db/memtable.cc:338:22: error: declaration of ëuser_keyí shadows a member of this [-Werror=shadow] Slice user_key(ExtractUserKey(k)); ^ ``` Pull Request resolved: Differential Revision: D14970160 Pulled By: miasantreble fbshipit-source-id: 388eb089f90c4528cc6d615dd4607fb53ceac705/Fix crash with memtable prefix bloom and key out of prefix extractor domain (#5190) Summary: Before using prefix extractor `InDomain()` should be check. All uses in memtable.cc didnt check `InDomain()`. Pull Request resolved: Differential Revision: D14923773 Pulled By: miasantreble fbshipit-source-id: b3ad60bcca5f3a1a2b929a6eb34b0b7ba6326f04/Consolidate hash function used for non-persistent data in a new function (#5155) Summary: Create new function NPHash64() and GetSliceNPHash64(), which are currently implemented using murmurhash. Replace the current direct call of murmurhash() to use the new functions if the hash results are not used in on-disk format. This will make it easier to try out or switch to alternative functions in the uses where data format compatibility doesnt need to be considered. This part shouldnt have any performance impact. Also, the sharded cache hash function is changed to the new format, because it falls into this categoery. It doesnt show visible performance impact in db_bench results. CPU showed by perf is increased from about 0.2% to 0.4% in an extreme benchmark setting (4KB blocks, no-compression, everything cached in block cache). Weve known that the current hash function used, our own Hash() has serious hash quality problem. It can generate a lots of conflicts with similar input. In this use case, it means extra lock contention for reads from the same file. This slight CPU regression is worthy to me to counter the potential bad performance with hot keys. And hopefully this will get further improved in the future with a better hash function. cache_tests condition is relaxed a little bit to. The new hash is slightly more skewed in this use case, but I manually checked the data and see the hash results are still in a reasonable range. Pull Request resolved: Differential Revision: D14834821 Pulled By: siying fbshipit-source-id: ec9a2c0a2f8ae4b54d08b13a5c2e9cc97aa80cb5/"
,,0.2543,rocksdb,"Avoid user key copying for Get/Put/Write with user-timestamp (#5502) Summary: In previous we added user-specified timestamp to `DB::Get()` and `DB::Put()`. Limitation is that these two functions may cause extra memory allocation and key copy. The reason is that `WriteBatch` does not allocate extra memory for timestamps because it is not aware of timestamp size, and we did not provide an API to assign/update timestamp of each key within a `WriteBatch`. We address these issues in this PR by doing the following. 1. Add a `timestamp_size_` to `WriteBatch` so that `WriteBatch` can take timestamps into account when calling `WriteBatch::Put`, `WriteBatch::Delete`, etc. 2. Add APIs `WriteBatch::AssignTimestamp` and `WriteBatch::AssignTimestamps` so that application can assign/update timestamps for each key in a `WriteBatch`. 3. Avoid key copy in `GetImpl` by adding new constructor to `LookupKey`. Test plan (on devserver): ``` $make clean && COMPILE_WITH_ASAN=1 make all $./db_basic_test $make check ``` If the API extension looks good, I will add more unit tests. Some simple benchmark using db_bench. ``` $rm /dev/shm/dbbench/* && TEST_TMPDIR=/dev/shm ./db_bench $rm /dev/shm/dbbench/* && TEST_TMPDIR=/dev/shm ./db_bench ``` Master is at a78503bd6c80a3c4137df1962a972fe406b4d90b. ``` | | readrandom | fillrandom | | master | 15.53 MB/s | 25.97 MB/s | | PR5502 | 16.70 MB/s | 25.80 MB/s | ``` Pull Request resolved: Differential Revision: D16340894 Pulled By: riversand963 fbshipit-source-id: 51132cf792be07d1efc3ac33f5768c4ee2608bb8/"
,,0.2405,rocksdb,"Fix PopSavePoint to merge info into the previous savepoint (#5628) Summary: Transaction::RollbackToSavePoint undos the modification made since the SavePoint beginning, and also unlocks the corresponding keys, which are tracked in the last SavePoint. Currently ::PopSavePoint simply discard these tracked keys, leaving them locked in the lock manager. This breaks a subsequent ::RollbackToSavePoint behavior as it loses track of such keys, and thus cannot unlock them. The patch fixes ::PopSavePoint by passing on the track key information to the previous SavePoint. Fixes Pull Request resolved: Differential Revision: D16505325 Pulled By: lth fbshipit-source-id: 2bc3b30963ab4d36d996d1f66543c93abf358980/"
,,0.2041,rocksdb,"Fix PopSavePoint to merge info into the previous savepoint (#5628) Summary: Transaction::RollbackToSavePoint undos the modification made since the SavePoint beginning, and also unlocks the corresponding keys, which are tracked in the last SavePoint. Currently ::PopSavePoint simply discard these tracked keys, leaving them locked in the lock manager. This breaks a subsequent ::RollbackToSavePoint behavior as it loses track of such keys, and thus cannot unlock them. The patch fixes ::PopSavePoint by passing on the track key information to the previous SavePoint. Fixes Pull Request resolved: Differential Revision: D16505325 Pulled By: lth fbshipit-source-id: 2bc3b30963ab4d36d996d1f66543c93abf358980/simplify include directive involving inttypes (#5402) Summary: When using `PRIu64` type of printf specifier, current code base does the following: ``` __STDC_FORMAT_MACROS __STDC_FORMAT_MACROS ``` However, this can be simplified to ``` ``` as long as flag `-std=c++11` is used. This should solve issues like Pull Request resolved: Differential Revision: D15701195 Pulled By: miasantreble fbshipit-source-id: 6dac0a05f52aadb55e9728038599d3d2e4b59d03/"
,,0.2446,rocksdb,"Fix PopSavePoint to merge info into the previous savepoint (#5628) Summary: Transaction::RollbackToSavePoint undos the modification made since the SavePoint beginning, and also unlocks the corresponding keys, which are tracked in the last SavePoint. Currently ::PopSavePoint simply discard these tracked keys, leaving them locked in the lock manager. This breaks a subsequent ::RollbackToSavePoint behavior as it loses track of such keys, and thus cannot unlock them. The patch fixes ::PopSavePoint by passing on the track key information to the previous SavePoint. Fixes Pull Request resolved: Differential Revision: D16505325 Pulled By: lth fbshipit-source-id: 2bc3b30963ab4d36d996d1f66543c93abf358980/"
,,0.1029,rocksdb,"Fix MyRocks compile warnings-treated-as-errors on Fedora 30, gcc 9.1.1 (#5553) Summary: Provide assignment operator in CompactionStats Provide a copy constructor for FileDescriptor Remove std::move from ""return std::move(t)"" in BoundedQueue Pull Request resolved: Differential Revision: D16230170 fbshipit-source-id: fd7c6e52390b2db1be24141e25649cf62424d078/"
,,0.2181,rocksdb,"Avoid user key copying for Get/Put/Write with user-timestamp (#5502) Summary: In previous we added user-specified timestamp to `DB::Get()` and `DB::Put()`. Limitation is that these two functions may cause extra memory allocation and key copy. The reason is that `WriteBatch` does not allocate extra memory for timestamps because it is not aware of timestamp size, and we did not provide an API to assign/update timestamp of each key within a `WriteBatch`. We address these issues in this PR by doing the following. 1. Add a `timestamp_size_` to `WriteBatch` so that `WriteBatch` can take timestamps into account when calling `WriteBatch::Put`, `WriteBatch::Delete`, etc. 2. Add APIs `WriteBatch::AssignTimestamp` and `WriteBatch::AssignTimestamps` so that application can assign/update timestamps for each key in a `WriteBatch`. 3. Avoid key copy in `GetImpl` by adding new constructor to `LookupKey`. Test plan (on devserver): ``` $make clean && COMPILE_WITH_ASAN=1 make all $./db_basic_test $make check ``` If the API extension looks good, I will add more unit tests. Some simple benchmark using db_bench. ``` $rm /dev/shm/dbbench/* && TEST_TMPDIR=/dev/shm ./db_bench $rm /dev/shm/dbbench/* && TEST_TMPDIR=/dev/shm ./db_bench ``` Master is at a78503bd6c80a3c4137df1962a972fe406b4d90b. ``` | | readrandom | fillrandom | | master | 15.53 MB/s | 25.97 MB/s | | PR5502 | 16.70 MB/s | 25.80 MB/s | ``` Pull Request resolved: Differential Revision: D16340894 Pulled By: riversand963 fbshipit-source-id: 51132cf792be07d1efc3ac33f5768c4ee2608bb8/Add support for timestamp in Get/Put (#5079) Summary: Its useful to be able to (optionally) associate key-value pairs with user-provided timestamps. This PR is an early effort towards this goal and continues the work of facebook#4942. A suite of new unit tests exist in DBBasicTestWithTimestampWithParam. Support for timestamp requires the user to provide timestamp as a slice in `ReadOptions` and `WriteOptions`. All timestamps of the same database must share the same length, format, etc. The format of the timestamp is the same throughout the same database, and the user is responsible for providing a comparator function (Comparator) to order the timestamp> tuples. Once created, the format and length of the timestamp cannot change (at least for now). Test plan (on devserver): ``` $COMPILE_WITH_ASAN=1 make all $./db_basic_test $make check ``` All tests must pass. We also run the following db_bench tests to verify whether there is regression on Get/Put while timestamp is not enabled. ``` $TEST_TMPDIR=/dev/shm ./db_bench $TEST_TMPDIR=/dev/shm ./db_bench ``` Repeat for 6 times for both versions. Results are as follows: ``` | | readrandom | fillrandom | | master | 16.77 MB/s | 47.05 MB/s | | PR5079 | 16.44 MB/s | 47.03 MB/s | ``` Pull Request resolved: Differential Revision: D15132946 Pulled By: riversand963 fbshipit-source-id: 833a0d657eac21182f0f206c910a6438154c742c/"
,,0.2495,rocksdb,"Avoid user key copying for Get/Put/Write with user-timestamp (#5502) Summary: In previous we added user-specified timestamp to `DB::Get()` and `DB::Put()`. Limitation is that these two functions may cause extra memory allocation and key copy. The reason is that `WriteBatch` does not allocate extra memory for timestamps because it is not aware of timestamp size, and we did not provide an API to assign/update timestamp of each key within a `WriteBatch`. We address these issues in this PR by doing the following. 1. Add a `timestamp_size_` to `WriteBatch` so that `WriteBatch` can take timestamps into account when calling `WriteBatch::Put`, `WriteBatch::Delete`, etc. 2. Add APIs `WriteBatch::AssignTimestamp` and `WriteBatch::AssignTimestamps` so that application can assign/update timestamps for each key in a `WriteBatch`. 3. Avoid key copy in `GetImpl` by adding new constructor to `LookupKey`. Test plan (on devserver): ``` $make clean && COMPILE_WITH_ASAN=1 make all $./db_basic_test $make check ``` If the API extension looks good, I will add more unit tests. Some simple benchmark using db_bench. ``` $rm /dev/shm/dbbench/* && TEST_TMPDIR=/dev/shm ./db_bench $rm /dev/shm/dbbench/* && TEST_TMPDIR=/dev/shm ./db_bench ``` Master is at a78503bd6c80a3c4137df1962a972fe406b4d90b. ``` | | readrandom | fillrandom | | master | 15.53 MB/s | 25.97 MB/s | | PR5502 | 16.70 MB/s | 25.80 MB/s | ``` Pull Request resolved: Differential Revision: D16340894 Pulled By: riversand963 fbshipit-source-id: 51132cf792be07d1efc3ac33f5768c4ee2608bb8/"
,,0.1011,rocksdb,"Fix MyRocks compile warnings-treated-as-errors on Fedora 30, gcc 9.1.1 (#5553) Summary: Provide assignment operator in CompactionStats Provide a copy constructor for FileDescriptor Remove std::move from ""return std::move(t)"" in BoundedQueue Pull Request resolved: Differential Revision: D16230170 fbshipit-source-id: fd7c6e52390b2db1be24141e25649cf62424d078/"
,,0.2286,rocksdb,"Avoid user key copying for Get/Put/Write with user-timestamp (#5502) Summary: In previous we added user-specified timestamp to `DB::Get()` and `DB::Put()`. Limitation is that these two functions may cause extra memory allocation and key copy. The reason is that `WriteBatch` does not allocate extra memory for timestamps because it is not aware of timestamp size, and we did not provide an API to assign/update timestamp of each key within a `WriteBatch`. We address these issues in this PR by doing the following. 1. Add a `timestamp_size_` to `WriteBatch` so that `WriteBatch` can take timestamps into account when calling `WriteBatch::Put`, `WriteBatch::Delete`, etc. 2. Add APIs `WriteBatch::AssignTimestamp` and `WriteBatch::AssignTimestamps` so that application can assign/update timestamps for each key in a `WriteBatch`. 3. Avoid key copy in `GetImpl` by adding new constructor to `LookupKey`. Test plan (on devserver): ``` $make clean && COMPILE_WITH_ASAN=1 make all $./db_basic_test $make check ``` If the API extension looks good, I will add more unit tests. Some simple benchmark using db_bench. ``` $rm /dev/shm/dbbench/* && TEST_TMPDIR=/dev/shm ./db_bench $rm /dev/shm/dbbench/* && TEST_TMPDIR=/dev/shm ./db_bench ``` Master is at a78503bd6c80a3c4137df1962a972fe406b4d90b. ``` | | readrandom | fillrandom | | master | 15.53 MB/s | 25.97 MB/s | | PR5502 | 16.70 MB/s | 25.80 MB/s | ``` Pull Request resolved: Differential Revision: D16340894 Pulled By: riversand963 fbshipit-source-id: 51132cf792be07d1efc3ac33f5768c4ee2608bb8/simplify include directive involving inttypes (#5402) Summary: When using `PRIu64` type of printf specifier, current code base does the following: ``` __STDC_FORMAT_MACROS __STDC_FORMAT_MACROS ``` However, this can be simplified to ``` ``` as long as flag `-std=c++11` is used. This should solve issues like Pull Request resolved: Differential Revision: D15701195 Pulled By: miasantreble fbshipit-source-id: 6dac0a05f52aadb55e9728038599d3d2e4b59d03/"
,,0.0974,rocksdb,"Fix MyRocks compile warnings-treated-as-errors on Fedora 30, gcc 9.1.1 (#5553) Summary: Provide assignment operator in CompactionStats Provide a copy constructor for FileDescriptor Remove std::move from ""return std::move(t)"" in BoundedQueue Pull Request resolved: Differential Revision: D16230170 fbshipit-source-id: fd7c6e52390b2db1be24141e25649cf62424d078/"
,,0.2226,rocksdb,"Add new persistent 64-bit hash (#5984) Summary: For upcoming new SST filter implementations, we will use a new 64-bit hash function (XXH3 preview, slightly modified). This change updates hash.{h,cc} for that change, adds unit tests, and out-of-lines the implementations to keep hash.h as clean/small as possible. In developing the unit tests, I discovered that the XXH3 preview always returns zero for the empty string. Zero is problematic for some algorithms (including an upcoming SST filter implementation) if it occurs more often than at the ""natural"" rate, so it should not be returned from trivial values using trivial seeds. I modified our fork of XXH3 to return a modest hash of the seed for the empty string. With hash function details out-of-lines in hash.h, it makes sense to enable XXH_INLINE_ALL, so that direct calls to XXH64/XXH32/XXH3p are inlined. To fix array-bounds warnings on some inline calls, I injected some casts to uintptr_t in xxhash.cc. (Issue reported to Yann.) Revised: Reverted using XXH_INLINE_ALL for now. Some Facebook checks are unhappy about on xxhash.cc file. I would fix that by rename to xxhash_cc.h, but to best preserve history I want to do that in a separate commit (PR) from the uintptr casts. Also updated filter_bench for this change, improving the performance predictability of dry run hashing and adding support for 64-bit hash (for upcoming new SST filter implementations, minor dead code in the tool for now). Pull Request resolved: Differential Revision: D18246567 Pulled By: pdillinger fbshipit-source-id: 6162fbf6381d63c8cc611dd7ec70e1ddc883fbb8/"
,,0.529,rocksdb,"Faster new DynamicBloom implementation (for memtable) (#5762) Summary: Since DynamicBloom is now only used in-memory, were free to change it without schema compatibility issues. The new implementation is drawn from (with manifest permission) This has several speed advantages over the prior implementation: * Uses fastrange instead of % * Minimum logic to determine first (and all) probed memory addresses * (Major) Two probes per 64-bit memory fetch/write. * Very fast and effective (murmur-like) hash expansion/re-mixing. (At least on recent CPUs, integer multiplication is very cheap.) While a Bloom filter with 512-bit cache locality has about a 1.15x FP rate penalty (e.g. 0.84% to 0.97%), further restricting to two probes per 64 bits incurs an additional 1.12x FP rate penalty (e.g. 0.97% to 1.09%). Nevertheless, the unit tests show no ""mediocre"" FP rate samples, unlike the old implementation with more erratic FP rates. Especially for the memtable, we expect speed to outweigh somewhat higher FP rates. For example, a negative table query would have to be 1000x slower than a BF query to justify doubling BF query time to shave 10% off FP rate (working assumption around 1% FP rate). While that seems likely for SSTs, my data suggests a speed factor of roughly 50x for the memtable (vs. BF; ~1.5% lower write throughput when enabling memtable Bloom filter, after this change). Thus, its probably not worth even 5% more time in the Bloom filter to shave off 1/10th of the Bloom FP rate, or 0.1% in absolute terms, and its probably at least 20% slower to recoup that much FP rate from this new implementation. Because of this, we do not see a need for a locality option that affects the MemTable Bloom filter and have decoupled the MemTable Bloom filter from Options::bloom_locality. Note that just 3% more memory to the Bloom filter (10.3 bits per key vs. just 10) is able to make up for the ~12% FP rate drop in the new implementation: [] Nearly ""ideal"" FP-wise but reasonably fast cache-local implementation [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_WORM64_FROM32_any.out 10000000 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_WORM64_FROM32_any.out time: 3.29372 sampled_fp_rate: 0.00985956 ... [] Close match to this new implementation [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out 10000000 6 10.3 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out time: 2.10072 sampled_fp_rate: 0.00985655 ... [] Old locality=1 implementation [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_ROCKSDB_DYNAMIC_any.out 10000000 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_ROCKSDB_DYNAMIC_any.out time: 3.95472 sampled_fp_rate: 0.00988943 ... Also note the dramatic speed improvement vs. alternatives. Performance unit test: DynamicBloomTest.concurrent_with_perf is updated to report more precise timing data. (Measure running time of each thread, not just longest running thread, etc.) Results averaged over various sizes enabled with and 20 runs each; old dynamic bloom refers to locality=1, the faster of the old: old dynamic bloom, avg add latency 65.6468 new dynamic bloom, avg add latency 44.3809 old dynamic bloom, avg query latency 50.6485 new dynamic bloom, avg query latency 43.2186 old avg parallel add latency 41.678 new avg parallel add latency 24.5238 old avg parallel hit latency 14.6322 new avg parallel hit latency 12.3939 old avg parallel miss latency 16.7289 new avg parallel miss latency 12.2134 Tested on a dedicated 64-bit production machine at Facebook. Significant improvement all around. Despite now using std::atomic<uint64_t>, quick before-and-after test on a 32-bit machine (Intel Atom N270, released 2008) shows no regression in performance, in some cases modest improvement. Performance integration test (synthetic): with DEBUG_LEVEL=0, used TEST_TMPDIR=/dev/shm ./db_bench and optionally with 300 runs each configuration. Write throughput change by enabling memtable bloom: Old locality=0: Old locality=1: New: conclusion seems to substantially close the gap Readmissing throughput change by enabling memtable bloom: Old locality=0: +34.47% Old locality=1: +34.80% New: +33.25% conclusion maybe a small new penalty from FP rate Readrandom throughput change by enabling memtable bloom: Old locality=0: +31.54% Old locality=1: +31.13% New: +30.60% conclusion maybe also from FP rate (after memtable flush) Another conclusion we can draw from this new implementation is that the existing 32-bit hash function is not inherently crippling the Bloom filter speed or accuracy, below about 5 million keys. For speed, the implementation is essentially the same whether starting with 32-bits or 64-bits of hash; it just determines whether the first multiplication after fastrange is a pseudorandom expansion or needed re-mix. Note that this multiplication can occur while memory is fetching. For accuracy, in a standard configuration, you need about 5 million keys before you have about a 1.1x FP penalty due to using a 32-bit hash vs. 64-bit: [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out $((5 * 1000 * 1000 * 10)) 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out time: 2.52069 sampled_fp_rate: 0.0118267 ... [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_any.out $((5 * 1000 * 1000 * 10)) 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_any.out time: 2.43871 sampled_fp_rate: 0.0109059 Pull Request resolved: Differential Revision: D17214194 Pulled By: pdillinger fbshipit-source-id: ad9da031772e985fd6b62a0e1db8e81892520595/"
,,0.4675,rocksdb,"Apply formatter on recent 45 commits. (#5827) Summary: Some recent commits might not have passed through the formatter. I formatted recent 45 commits. The script hangs for more commits so I stopped there. Pull Request resolved: Test Plan: Run all existing tests. Differential Revision: D17483727 fbshipit-source-id: af23113ee63015d8a43d89a3bc2c1056189afe8f/Fix block allocation bug in new DynamicBloom (#5783) Summary: Bug found by valgrind. New DynamicBloom wasnt allocating in block sizes. New assertion added that probes starting in final word would be in bounds. Pull Request resolved: Test Plan: ROCKSDB_VALGRIND_RUN=1 DISABLE_JEMALLOC=1 valgrind ./dynamic_bloom_test Differential Revision: D17270623 Pulled By: pdillinger fbshipit-source-id: 1e0407504b875133a771383cd488c70f91be2b87/Faster new DynamicBloom implementation (for memtable) (#5762) Summary: Since DynamicBloom is now only used in-memory, were free to change it without schema compatibility issues. The new implementation is drawn from (with manifest permission) This has several speed advantages over the prior implementation: * Uses fastrange instead of % * Minimum logic to determine first (and all) probed memory addresses * (Major) Two probes per 64-bit memory fetch/write. * Very fast and effective (murmur-like) hash expansion/re-mixing. (At least on recent CPUs, integer multiplication is very cheap.) While a Bloom filter with 512-bit cache locality has about a 1.15x FP rate penalty (e.g. 0.84% to 0.97%), further restricting to two probes per 64 bits incurs an additional 1.12x FP rate penalty (e.g. 0.97% to 1.09%). Nevertheless, the unit tests show no ""mediocre"" FP rate samples, unlike the old implementation with more erratic FP rates. Especially for the memtable, we expect speed to outweigh somewhat higher FP rates. For example, a negative table query would have to be 1000x slower than a BF query to justify doubling BF query time to shave 10% off FP rate (working assumption around 1% FP rate). While that seems likely for SSTs, my data suggests a speed factor of roughly 50x for the memtable (vs. BF; ~1.5% lower write throughput when enabling memtable Bloom filter, after this change). Thus, its probably not worth even 5% more time in the Bloom filter to shave off 1/10th of the Bloom FP rate, or 0.1% in absolute terms, and its probably at least 20% slower to recoup that much FP rate from this new implementation. Because of this, we do not see a need for a locality option that affects the MemTable Bloom filter and have decoupled the MemTable Bloom filter from Options::bloom_locality. Note that just 3% more memory to the Bloom filter (10.3 bits per key vs. just 10) is able to make up for the ~12% FP rate drop in the new implementation: [] Nearly ""ideal"" FP-wise but reasonably fast cache-local implementation [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_WORM64_FROM32_any.out 10000000 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_WORM64_FROM32_any.out time: 3.29372 sampled_fp_rate: 0.00985956 ... [] Close match to this new implementation [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out 10000000 6 10.3 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out time: 2.10072 sampled_fp_rate: 0.00985655 ... [] Old locality=1 implementation [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_ROCKSDB_DYNAMIC_any.out 10000000 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_ROCKSDB_DYNAMIC_any.out time: 3.95472 sampled_fp_rate: 0.00988943 ... Also note the dramatic speed improvement vs. alternatives. Performance unit test: DynamicBloomTest.concurrent_with_perf is updated to report more precise timing data. (Measure running time of each thread, not just longest running thread, etc.) Results averaged over various sizes enabled with and 20 runs each; old dynamic bloom refers to locality=1, the faster of the old: old dynamic bloom, avg add latency 65.6468 new dynamic bloom, avg add latency 44.3809 old dynamic bloom, avg query latency 50.6485 new dynamic bloom, avg query latency 43.2186 old avg parallel add latency 41.678 new avg parallel add latency 24.5238 old avg parallel hit latency 14.6322 new avg parallel hit latency 12.3939 old avg parallel miss latency 16.7289 new avg parallel miss latency 12.2134 Tested on a dedicated 64-bit production machine at Facebook. Significant improvement all around. Despite now using std::atomic<uint64_t>, quick before-and-after test on a 32-bit machine (Intel Atom N270, released 2008) shows no regression in performance, in some cases modest improvement. Performance integration test (synthetic): with DEBUG_LEVEL=0, used TEST_TMPDIR=/dev/shm ./db_bench and optionally with 300 runs each configuration. Write throughput change by enabling memtable bloom: Old locality=0: Old locality=1: New: conclusion seems to substantially close the gap Readmissing throughput change by enabling memtable bloom: Old locality=0: +34.47% Old locality=1: +34.80% New: +33.25% conclusion maybe a small new penalty from FP rate Readrandom throughput change by enabling memtable bloom: Old locality=0: +31.54% Old locality=1: +31.13% New: +30.60% conclusion maybe also from FP rate (after memtable flush) Another conclusion we can draw from this new implementation is that the existing 32-bit hash function is not inherently crippling the Bloom filter speed or accuracy, below about 5 million keys. For speed, the implementation is essentially the same whether starting with 32-bits or 64-bits of hash; it just determines whether the first multiplication after fastrange is a pseudorandom expansion or needed re-mix. Note that this multiplication can occur while memory is fetching. For accuracy, in a standard configuration, you need about 5 million keys before you have about a 1.1x FP penalty due to using a 32-bit hash vs. 64-bit: [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out $((5 * 1000 * 1000 * 10)) 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out time: 2.52069 sampled_fp_rate: 0.0118267 ... [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_any.out $((5 * 1000 * 1000 * 10)) 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_any.out time: 2.43871 sampled_fp_rate: 0.0109059 Pull Request resolved: Differential Revision: D17214194 Pulled By: pdillinger fbshipit-source-id: ad9da031772e985fd6b62a0e1db8e81892520595/"
,,0.5007,rocksdb,"Apply formatter on recent 45 commits. (#5827) Summary: Some recent commits might not have passed through the formatter. I formatted recent 45 commits. The script hangs for more commits so I stopped there. Pull Request resolved: Test Plan: Run all existing tests. Differential Revision: D17483727 fbshipit-source-id: af23113ee63015d8a43d89a3bc2c1056189afe8f/Faster new DynamicBloom implementation (for memtable) (#5762) Summary: Since DynamicBloom is now only used in-memory, were free to change it without schema compatibility issues. The new implementation is drawn from (with manifest permission) This has several speed advantages over the prior implementation: * Uses fastrange instead of % * Minimum logic to determine first (and all) probed memory addresses * (Major) Two probes per 64-bit memory fetch/write. * Very fast and effective (murmur-like) hash expansion/re-mixing. (At least on recent CPUs, integer multiplication is very cheap.) While a Bloom filter with 512-bit cache locality has about a 1.15x FP rate penalty (e.g. 0.84% to 0.97%), further restricting to two probes per 64 bits incurs an additional 1.12x FP rate penalty (e.g. 0.97% to 1.09%). Nevertheless, the unit tests show no ""mediocre"" FP rate samples, unlike the old implementation with more erratic FP rates. Especially for the memtable, we expect speed to outweigh somewhat higher FP rates. For example, a negative table query would have to be 1000x slower than a BF query to justify doubling BF query time to shave 10% off FP rate (working assumption around 1% FP rate). While that seems likely for SSTs, my data suggests a speed factor of roughly 50x for the memtable (vs. BF; ~1.5% lower write throughput when enabling memtable Bloom filter, after this change). Thus, its probably not worth even 5% more time in the Bloom filter to shave off 1/10th of the Bloom FP rate, or 0.1% in absolute terms, and its probably at least 20% slower to recoup that much FP rate from this new implementation. Because of this, we do not see a need for a locality option that affects the MemTable Bloom filter and have decoupled the MemTable Bloom filter from Options::bloom_locality. Note that just 3% more memory to the Bloom filter (10.3 bits per key vs. just 10) is able to make up for the ~12% FP rate drop in the new implementation: [] Nearly ""ideal"" FP-wise but reasonably fast cache-local implementation [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_WORM64_FROM32_any.out 10000000 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_WORM64_FROM32_any.out time: 3.29372 sampled_fp_rate: 0.00985956 ... [] Close match to this new implementation [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out 10000000 6 10.3 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out time: 2.10072 sampled_fp_rate: 0.00985655 ... [] Old locality=1 implementation [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_ROCKSDB_DYNAMIC_any.out 10000000 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_ROCKSDB_DYNAMIC_any.out time: 3.95472 sampled_fp_rate: 0.00988943 ... Also note the dramatic speed improvement vs. alternatives. Performance unit test: DynamicBloomTest.concurrent_with_perf is updated to report more precise timing data. (Measure running time of each thread, not just longest running thread, etc.) Results averaged over various sizes enabled with and 20 runs each; old dynamic bloom refers to locality=1, the faster of the old: old dynamic bloom, avg add latency 65.6468 new dynamic bloom, avg add latency 44.3809 old dynamic bloom, avg query latency 50.6485 new dynamic bloom, avg query latency 43.2186 old avg parallel add latency 41.678 new avg parallel add latency 24.5238 old avg parallel hit latency 14.6322 new avg parallel hit latency 12.3939 old avg parallel miss latency 16.7289 new avg parallel miss latency 12.2134 Tested on a dedicated 64-bit production machine at Facebook. Significant improvement all around. Despite now using std::atomic<uint64_t>, quick before-and-after test on a 32-bit machine (Intel Atom N270, released 2008) shows no regression in performance, in some cases modest improvement. Performance integration test (synthetic): with DEBUG_LEVEL=0, used TEST_TMPDIR=/dev/shm ./db_bench and optionally with 300 runs each configuration. Write throughput change by enabling memtable bloom: Old locality=0: Old locality=1: New: conclusion seems to substantially close the gap Readmissing throughput change by enabling memtable bloom: Old locality=0: +34.47% Old locality=1: +34.80% New: +33.25% conclusion maybe a small new penalty from FP rate Readrandom throughput change by enabling memtable bloom: Old locality=0: +31.54% Old locality=1: +31.13% New: +30.60% conclusion maybe also from FP rate (after memtable flush) Another conclusion we can draw from this new implementation is that the existing 32-bit hash function is not inherently crippling the Bloom filter speed or accuracy, below about 5 million keys. For speed, the implementation is essentially the same whether starting with 32-bits or 64-bits of hash; it just determines whether the first multiplication after fastrange is a pseudorandom expansion or needed re-mix. Note that this multiplication can occur while memory is fetching. For accuracy, in a standard configuration, you need about 5 million keys before you have about a 1.1x FP penalty due to using a 32-bit hash vs. 64-bit: [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out $((5 * 1000 * 1000 * 10)) 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out time: 2.52069 sampled_fp_rate: 0.0118267 ... [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_any.out $((5 * 1000 * 1000 * 10)) 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_any.out time: 2.43871 sampled_fp_rate: 0.0109059 Pull Request resolved: Differential Revision: D17214194 Pulled By: pdillinger fbshipit-source-id: ad9da031772e985fd6b62a0e1db8e81892520595/"
,,0.3899,rocksdb,"Auto-GarbageCollect on PurgeOldBackups and DeleteBackup (#6015) Summary: Only if there is a crash, power failure, or I/O error in DeleteBackup, shared or private files from the backup might be left behind that are not cleaned up by PurgeOldBackups or DeleteBackup-- only by GarbageCollect. This makes the BackupEngine API ""leaky by default."" Even if it means a modest performance hit, I think we should make Delete and Purge do as they say, with ongoing best effort: i.e. future calls will attempt to finish any incomplete work from earlier calls. This change does that by having DeleteBackup and PurgeOldBackups do a GarbageCollect, unless (to minimize performance hit) this BackupEngine has already done a GarbageCollect and there have been no deletion-related I/O errors in that GarbageCollect or since then. Rejected alternative 1: remove meta file last instead of first. This would in theory turn partially deleted backups into corrupted backups, but code changes would be needed to allow the missing files and consider it acceptably corrupt, rather than failing to open the BackupEngine. This might be a reasonable choice, but I mostly rejected it because it doesnt solve the legacy problem of cleaning up existing lingering files. Rejected alternative 2: use a deletion marker file. If deletion started with creating a file that marks a backup as flagged for deletion, then we could reliably detect partially deleted backups and efficiently finish removing them. In addition to not solving the legacy problem, this could be precarious if theres a disk full situation, and we try to create a new file in order to delete some files. Ugh. Pull Request resolved: Test Plan: Updated unit tests Differential Revision: D18401333 Pulled By: pdillinger fbshipit-source-id: 12944e372ce6809f3f5a4c416c3b321a8927d925/"
,,0.3905,rocksdb,"Auto-GarbageCollect on PurgeOldBackups and DeleteBackup (#6015) Summary: Only if there is a crash, power failure, or I/O error in DeleteBackup, shared or private files from the backup might be left behind that are not cleaned up by PurgeOldBackups or DeleteBackup-- only by GarbageCollect. This makes the BackupEngine API ""leaky by default."" Even if it means a modest performance hit, I think we should make Delete and Purge do as they say, with ongoing best effort: i.e. future calls will attempt to finish any incomplete work from earlier calls. This change does that by having DeleteBackup and PurgeOldBackups do a GarbageCollect, unless (to minimize performance hit) this BackupEngine has already done a GarbageCollect and there have been no deletion-related I/O errors in that GarbageCollect or since then. Rejected alternative 1: remove meta file last instead of first. This would in theory turn partially deleted backups into corrupted backups, but code changes would be needed to allow the missing files and consider it acceptably corrupt, rather than failing to open the BackupEngine. This might be a reasonable choice, but I mostly rejected it because it doesnt solve the legacy problem of cleaning up existing lingering files. Rejected alternative 2: use a deletion marker file. If deletion started with creating a file that marks a backup as flagged for deletion, then we could reliably detect partially deleted backups and efficiently finish removing them. In addition to not solving the legacy problem, this could be precarious if theres a disk full situation, and we try to create a new file in order to delete some files. Ugh. Pull Request resolved: Test Plan: Updated unit tests Differential Revision: D18401333 Pulled By: pdillinger fbshipit-source-id: 12944e372ce6809f3f5a4c416c3b321a8927d925/"
,,0.3793,rocksdb,"Auto-GarbageCollect on PurgeOldBackups and DeleteBackup (#6015) Summary: Only if there is a crash, power failure, or I/O error in DeleteBackup, shared or private files from the backup might be left behind that are not cleaned up by PurgeOldBackups or DeleteBackup-- only by GarbageCollect. This makes the BackupEngine API ""leaky by default."" Even if it means a modest performance hit, I think we should make Delete and Purge do as they say, with ongoing best effort: i.e. future calls will attempt to finish any incomplete work from earlier calls. This change does that by having DeleteBackup and PurgeOldBackups do a GarbageCollect, unless (to minimize performance hit) this BackupEngine has already done a GarbageCollect and there have been no deletion-related I/O errors in that GarbageCollect or since then. Rejected alternative 1: remove meta file last instead of first. This would in theory turn partially deleted backups into corrupted backups, but code changes would be needed to allow the missing files and consider it acceptably corrupt, rather than failing to open the BackupEngine. This might be a reasonable choice, but I mostly rejected it because it doesnt solve the legacy problem of cleaning up existing lingering files. Rejected alternative 2: use a deletion marker file. If deletion started with creating a file that marks a backup as flagged for deletion, then we could reliably detect partially deleted backups and efficiently finish removing them. In addition to not solving the legacy problem, this could be precarious if theres a disk full situation, and we try to create a new file in order to delete some files. Ugh. Pull Request resolved: Test Plan: Updated unit tests Differential Revision: D18401333 Pulled By: pdillinger fbshipit-source-id: 12944e372ce6809f3f5a4c416c3b321a8927d925/"
,,0.0802,rocksdb,Fix double deletion in transaction_test (#5700) Summary: Fix the following clang analyze failures: ``` In file included from utilities/transactions/transaction_test.cc:8: ./utilities/transactions/transaction_test.h:174:14: warning: Attempt to delete released memory delete root_db; ^ ``` The destructor of StackableDB already deletes the root db and there is no need to delete the db separately. Pull Request resolved: Test Plan: USE_CLANG=1 TEST_TMPDIR=/dev/shm/rocksdb OPT=-g make analyze Differential Revision: D16800579 Pulled By: maysamyabandeh fbshipit-source-id: 64c2d70f23e07e6a15242add97c744902ea33be5/
,,0.1317,rocksdb,"Fix local includes Summary: Pull Request resolved: Differential Revision: D16908380 fbshipit-source-id: 6a0e3cb2730b08d6012d3d7f31c937f01c399846/Fix compiler error by deleting GetContext default ctor (#5685) Summary: When updating compiler version for MyRocks Im seeing this error with rocksdb: ``` ome/yzha/mysql/mysql-fork2/rocksdb/table/get_context.h:91:3: error: explicitly defaulted default constructor is implicitly deleted [-Werror,-Wdefaulted-function-deleted] GetContext() default; ^ /home/yzha/mysql/mysql-fork2/rocksdb/table/get_context.h:166:18: note: default constructor of GetContext is implicitly deleted because field tracing_get_id_ of const-qualified type const uint64_t (aka const unsigned long) would not be initialized const uint64_t tracing_get_id_; ^ ``` The error itself is rather self explanatory and makes sense. Given that no one seems to be using the default ctor (they shouldnt, anyway), Im deleting it. Pull Request resolved: Differential Revision: D16747712 Pulled By: yizhang82 fbshipit-source-id: 95c0acb958a1ed41154c0047d2e6fce7644de53f/"
,,0.2106,rocksdb,"Add new persistent 64-bit hash (#5984) Summary: For upcoming new SST filter implementations, we will use a new 64-bit hash function (XXH3 preview, slightly modified). This change updates hash.{h,cc} for that change, adds unit tests, and out-of-lines the implementations to keep hash.h as clean/small as possible. In developing the unit tests, I discovered that the XXH3 preview always returns zero for the empty string. Zero is problematic for some algorithms (including an upcoming SST filter implementation) if it occurs more often than at the ""natural"" rate, so it should not be returned from trivial values using trivial seeds. I modified our fork of XXH3 to return a modest hash of the seed for the empty string. With hash function details out-of-lines in hash.h, it makes sense to enable XXH_INLINE_ALL, so that direct calls to XXH64/XXH32/XXH3p are inlined. To fix array-bounds warnings on some inline calls, I injected some casts to uintptr_t in xxhash.cc. (Issue reported to Yann.) Revised: Reverted using XXH_INLINE_ALL for now. Some Facebook checks are unhappy about on xxhash.cc file. I would fix that by rename to xxhash_cc.h, but to best preserve history I want to do that in a separate commit (PR) from the uintptr casts. Also updated filter_bench for this change, improving the performance predictability of dry run hashing and adding support for 64-bit hash (for upcoming new SST filter implementations, minor dead code in the tool for now). Pull Request resolved: Differential Revision: D18246567 Pulled By: pdillinger fbshipit-source-id: 6162fbf6381d63c8cc611dd7ec70e1ddc883fbb8/"
,,0.3748,rocksdb,"Misc hashing updates / upgrades (#5909) Summary: Updated our included xxhash implementation to version 0.7.2 (== the latest dev version as of 2019-10-09). Using XXH_NAMESPACE (like other fb projects) to avoid potential name collisions. Added fastrange64, and unit tests for it and fastrange32. These are faster alternatives to hash % range. Use preview version of XXH3 instead of MurmurHash64A for NPHash64 Had to update cache_test to increase probability of passing for any given hash function. Use fastrange64 instead of % with uses of NPHash64 Had to fix WritePreparedTransactionTest.CommitOfDelayedPrepared to avoid deadlock apparently caused by new hash collision. Set default seed for NPHash64 because specifying a seed rarely makes sense for it. Removed unnecessary include xxhash.h in a popular .h file Rename preview version of XXH3 to XXH3p for clarity and to ease backward compatibility in case final version of XXH3 is integrated. Relying on existing unit tests for NPHash64-related changes. Each new implementation of fastrange64 passed unit tests when manipulating my local build to select it. I havent done any integration performance tests, but I consider the improved performance of the pieces being swapped in to be well established. Pull Request resolved: Differential Revision: D18125196 Pulled By: pdillinger fbshipit-source-id: f6bf83d49d20cbb2549926adf454fd035f0ecc0d/Faster new DynamicBloom implementation (for memtable) (#5762) Summary: Since DynamicBloom is now only used in-memory, were free to change it without schema compatibility issues. The new implementation is drawn from (with manifest permission) This has several speed advantages over the prior implementation: * Uses fastrange instead of % * Minimum logic to determine first (and all) probed memory addresses * (Major) Two probes per 64-bit memory fetch/write. * Very fast and effective (murmur-like) hash expansion/re-mixing. (At least on recent CPUs, integer multiplication is very cheap.) While a Bloom filter with 512-bit cache locality has about a 1.15x FP rate penalty (e.g. 0.84% to 0.97%), further restricting to two probes per 64 bits incurs an additional 1.12x FP rate penalty (e.g. 0.97% to 1.09%). Nevertheless, the unit tests show no ""mediocre"" FP rate samples, unlike the old implementation with more erratic FP rates. Especially for the memtable, we expect speed to outweigh somewhat higher FP rates. For example, a negative table query would have to be 1000x slower than a BF query to justify doubling BF query time to shave 10% off FP rate (working assumption around 1% FP rate). While that seems likely for SSTs, my data suggests a speed factor of roughly 50x for the memtable (vs. BF; ~1.5% lower write throughput when enabling memtable Bloom filter, after this change). Thus, its probably not worth even 5% more time in the Bloom filter to shave off 1/10th of the Bloom FP rate, or 0.1% in absolute terms, and its probably at least 20% slower to recoup that much FP rate from this new implementation. Because of this, we do not see a need for a locality option that affects the MemTable Bloom filter and have decoupled the MemTable Bloom filter from Options::bloom_locality. Note that just 3% more memory to the Bloom filter (10.3 bits per key vs. just 10) is able to make up for the ~12% FP rate drop in the new implementation: [] Nearly ""ideal"" FP-wise but reasonably fast cache-local implementation [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_WORM64_FROM32_any.out 10000000 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_WORM64_FROM32_any.out time: 3.29372 sampled_fp_rate: 0.00985956 ... [] Close match to this new implementation [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out 10000000 6 10.3 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out time: 2.10072 sampled_fp_rate: 0.00985655 ... [] Old locality=1 implementation [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_ROCKSDB_DYNAMIC_any.out 10000000 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_ROCKSDB_DYNAMIC_any.out time: 3.95472 sampled_fp_rate: 0.00988943 ... Also note the dramatic speed improvement vs. alternatives. Performance unit test: DynamicBloomTest.concurrent_with_perf is updated to report more precise timing data. (Measure running time of each thread, not just longest running thread, etc.) Results averaged over various sizes enabled with and 20 runs each; old dynamic bloom refers to locality=1, the faster of the old: old dynamic bloom, avg add latency 65.6468 new dynamic bloom, avg add latency 44.3809 old dynamic bloom, avg query latency 50.6485 new dynamic bloom, avg query latency 43.2186 old avg parallel add latency 41.678 new avg parallel add latency 24.5238 old avg parallel hit latency 14.6322 new avg parallel hit latency 12.3939 old avg parallel miss latency 16.7289 new avg parallel miss latency 12.2134 Tested on a dedicated 64-bit production machine at Facebook. Significant improvement all around. Despite now using std::atomic<uint64_t>, quick before-and-after test on a 32-bit machine (Intel Atom N270, released 2008) shows no regression in performance, in some cases modest improvement. Performance integration test (synthetic): with DEBUG_LEVEL=0, used TEST_TMPDIR=/dev/shm ./db_bench and optionally with 300 runs each configuration. Write throughput change by enabling memtable bloom: Old locality=0: Old locality=1: New: conclusion seems to substantially close the gap Readmissing throughput change by enabling memtable bloom: Old locality=0: +34.47% Old locality=1: +34.80% New: +33.25% conclusion maybe a small new penalty from FP rate Readrandom throughput change by enabling memtable bloom: Old locality=0: +31.54% Old locality=1: +31.13% New: +30.60% conclusion maybe also from FP rate (after memtable flush) Another conclusion we can draw from this new implementation is that the existing 32-bit hash function is not inherently crippling the Bloom filter speed or accuracy, below about 5 million keys. For speed, the implementation is essentially the same whether starting with 32-bits or 64-bits of hash; it just determines whether the first multiplication after fastrange is a pseudorandom expansion or needed re-mix. Note that this multiplication can occur while memory is fetching. For accuracy, in a standard configuration, you need about 5 million keys before you have about a 1.1x FP penalty due to using a 32-bit hash vs. 64-bit: [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out $((5 * 1000 * 1000 * 10)) 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out time: 2.52069 sampled_fp_rate: 0.0118267 ... [~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_any.out $((5 * 1000 * 1000 * 10)) 6 10 $RANDOM 100000000 ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_any.out time: 2.43871 sampled_fp_rate: 0.0109059 Pull Request resolved: Differential Revision: D17214194 Pulled By: pdillinger fbshipit-source-id: ad9da031772e985fd6b62a0e1db8e81892520595/Refactor trimming logic for immutable memtables (#5022) Summary: MyRocks currently sets `max_write_buffer_number_to_maintain` in order to maintain enough history for transaction conflict checking. The effectiveness of this approach depends on the size of memtables. When memtables are small, it may not keep enough history; when memtables are large, this may consume too much memory. We are proposing a new way to configure memtable list history: by limiting the memory usage of immutable memtables. The new option is `max_write_buffer_size_to_maintain` and it will take precedence over the old `max_write_buffer_number_to_maintain` if they are both set to non-zero values. The new option accounts for the total memory usage of flushed immutable memtables and mutable memtable. When the total usage exceeds the limit, RocksDB may start dropping immutable memtables (which is also called trimming history), starting from the oldest one. The semantics of the old option actually works both as an upper bound and lower bound. History trimming will start if number of immutable memtables exceeds the limit, but it will never go below (limit-1) due to history trimming. In order the mimic the behavior with the new option, history trimming will stop if dropping the next immutable memtable causes the total memory usage go below the size limit. For example, assuming the size limit is set to 64MB, and there are 3 immutable memtables with sizes of 20, 30, 30. Although the total memory usage is 80MB > 64MB, dropping the oldest memtable will reduce the memory usage to 60MB 64MB, so in this case no memtable will be dropped. Pull Request resolved: Differential Revision: D14394062 Pulled By: miasantreble fbshipit-source-id: 60457a509c6af89d0993f988c9b5c2aa9e45f5c5/"
,,0.3273,rocksdb,"More fixes to auto-GarbageCollect in BackupEngine (#6023) Summary: Production: * Fixes GarbageCollect (and auto-GC triggered by PurgeOldBackups, DeleteBackup, or CreateNewBackup) to clean up backup directory independent of current settings (except max_valid_backups_to_open; see issue and prior settings used with same backup directory. * Fixes GarbageCollect (and auto-GC) not to attempt to remove ""."" and "".."" entries from directories. * Clarifies contract with users in modifying BackupEngine operations. In short, leftovers from any incomplete operation are cleaned up by any subsequent call to that same kind of operation (PurgeOldBackups and DeleteBackup considered the same kind of operation). GarbageCollect is available to clean up after all kinds. (NB: right now PurgeOldBackups and DeleteBackup will clean up after incomplete CreateNewBackup, but we arent promising to continue that behavior.) Pull Request resolved: Test Plan: * Refactors open parameters to use an option enum, for readability, etc. (Also fixes an unused parameter bug in the redundant OpenDBAndBackupEngineShareWithChecksum.) * Fixes an apparent bug in ShareTableFilesWithChecksumsTransition in which old backup data was destroyed in the transition to be tested. That test is now augmented to ensure GarbageCollect (or auto-GC) does not remove shared files when BackupEngine is opened with share_table_files=false. * Augments DeleteTmpFiles test to ensure that CreateNewBackup does auto-GC when an incompletely created backup is detected. Differential Revision: D18453559 Pulled By: pdillinger fbshipit-source-id: 5e54e7b08d711b161bc9c656181012b69a8feac4/"
,,0.1118,rocksdb,"Avoid heading tags in javadocs; fix EnvironmentTest (#6208) Summary: Should fix Travis build error that randomly showed up upon using Java 13 version of javadoc. AdvancedColumnFamilyOptionsInterface.java:257: error: unexpected heading used: compared to implicit preceding heading: According to this reference it should work to start at h4, but that didnt work, so avoiding headings should be fine. Also fix Java EnvironmentTest for JDK13. Pull Request resolved: Test Plan: Travis run on PR (dont have Java 13 handy) Differential Revision: D19163105 Pulled By: pdillinger fbshipit-source-id: 4a9419cbe7ef780fba771b8a1508e1ea80d17b3e/"
,,0.1147,rocksdb,"Avoid heading tags in javadocs; fix EnvironmentTest (#6208) Summary: Should fix Travis build error that randomly showed up upon using Java 13 version of javadoc. AdvancedColumnFamilyOptionsInterface.java:257: error: unexpected heading used: compared to implicit preceding heading: According to this reference it should work to start at h4, but that didnt work, so avoiding headings should be fine. Also fix Java EnvironmentTest for JDK13. Pull Request resolved: Test Plan: Travis run on PR (dont have Java 13 handy) Differential Revision: D19163105 Pulled By: pdillinger fbshipit-source-id: 4a9419cbe7ef780fba771b8a1508e1ea80d17b3e/"
,,0.32,rocksdb,"More fixes to auto-GarbageCollect in BackupEngine (#6023) Summary: Production: * Fixes GarbageCollect (and auto-GC triggered by PurgeOldBackups, DeleteBackup, or CreateNewBackup) to clean up backup directory independent of current settings (except max_valid_backups_to_open; see issue and prior settings used with same backup directory. * Fixes GarbageCollect (and auto-GC) not to attempt to remove ""."" and "".."" entries from directories. * Clarifies contract with users in modifying BackupEngine operations. In short, leftovers from any incomplete operation are cleaned up by any subsequent call to that same kind of operation (PurgeOldBackups and DeleteBackup considered the same kind of operation). GarbageCollect is available to clean up after all kinds. (NB: right now PurgeOldBackups and DeleteBackup will clean up after incomplete CreateNewBackup, but we arent promising to continue that behavior.) Pull Request resolved: Test Plan: * Refactors open parameters to use an option enum, for readability, etc. (Also fixes an unused parameter bug in the redundant OpenDBAndBackupEngineShareWithChecksum.) * Fixes an apparent bug in ShareTableFilesWithChecksumsTransition in which old backup data was destroyed in the transition to be tested. That test is now augmented to ensure GarbageCollect (or auto-GC) does not remove shared files when BackupEngine is opened with share_table_files=false. * Augments DeleteTmpFiles test to ensure that CreateNewBackup does auto-GC when an incompletely created backup is detected. Differential Revision: D18453559 Pulled By: pdillinger fbshipit-source-id: 5e54e7b08d711b161bc9c656181012b69a8feac4/"
,,0.0949,rocksdb,Implement getfreespace for WinEnv (#6265) Summary: A new interface method Env::GetFreeSpace was added in It needs to be implemented for Windows port. Some error_handler_test cases fail on Windows because recovery cannot succeed without free space being reported. Pull Request resolved: Differential Revision: D19303065 fbshipit-source-id: 1f1a83e53f334284781cf61feabc996e87b945ca/
,,0.0966,rocksdb,Implement getfreespace for WinEnv (#6265) Summary: A new interface method Env::GetFreeSpace was added in It needs to be implemented for Windows port. Some error_handler_test cases fail on Windows because recovery cannot succeed without free space being reported. Pull Request resolved: Differential Revision: D19303065 fbshipit-source-id: 1f1a83e53f334284781cf61feabc996e87b945ca/
,,0.0863,rocksdb,Implement getfreespace for WinEnv (#6265) Summary: A new interface method Env::GetFreeSpace was added in It needs to be implemented for Windows port. Some error_handler_test cases fail on Windows because recovery cannot succeed without free space being reported. Pull Request resolved: Differential Revision: D19303065 fbshipit-source-id: 1f1a83e53f334284781cf61feabc996e87b945ca/
,,0.1198,rocksdb,Fix crash in JNI getApproximateSizes (#6652) Summary: This change is fixing a crash happening in getApproximateSizes JNI implementation. It also reenables Java test that was crashing most likelly because if this bug. Pull Request resolved: Reviewed By: cheng-chang Differential Revision: D20874865 Pulled By: pdillinger fbshipit-source-id: da95516f15e5df2efe1a4e5690a2ce172cb53f87/Add Java API for rocksdb::CancelAllBackgroundWork() (#6657) Summary: Adding a Java API for rocksdb::CancelAllBackgroundWork() so that the user can call this (when required) before closing the DB. This is to **prevent the crashes when manual compaction is running and the user decides to close the DB**. Calling CancelAllBackgroundWork() seems to be the recommended way to make sure that its safe to close the DB (according to RocksDB FAQ: Pull Request resolved: Reviewed By: cheng-chang Differential Revision: D20896395 Pulled By: pdillinger fbshipit-source-id: 8a8208c10093db09bd35db9af362211897870d96/JNI direct buffer support for basic operations (#2283) Summary: It is very useful to support direct ByteBuffers in Java. It allows to have zero memory copy and some serializers are using that directly so one do not need to create byte[] array for it. This change also contains some fixes for Windows JNI build. Pull Request resolved: Differential Revision: D19834971 Pulled By: pdillinger fbshipit-source-id: 44173aa02afc9836c5498c592fd1ea95b6086e8e/
