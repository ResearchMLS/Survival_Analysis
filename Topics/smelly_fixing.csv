System,Message
conscrypt,"Modifies OpenSSLSocketImpl to use a different lock for the instance count. It was using the same lock when use around native methods meaning that the finalizer could be blocked unnecessarily
resulting in a VM crash./"
conscrypt,"Update x-net to Harmony r802921.
Notable changes
- synchronization added where it was needed!
- try/finally added to reliably tear down in DefaultSSLContext
- ContextImpl deleted, it wasn't necessary
- methods reordered to make statics first in the class
- PrivilegedActions parameterized with <Void>
- DigitalSignature now throws AssertionErrors in impossible states
and throws AlertExceptions on invalid keys (rather than dumping
a stacktrace)
- ValueKeys added to SSLSessionImpl instead of TwoKeyMaps
- SSLSessionImpl.clone() simplified to do a traditional clone
Squashed commit of the following:
commit 2d9e43d542ab7086af271bf52e847c582decbab1
Merge: 8b79eb4 a8dc377
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 15:25:21 2009 -0700
Merge branch 'x-net_802921' into x-net_dalvik
Conflicts:
libcore/x-net/.classpath
libcore/x-net/.settings/org.eclipse.jdt.core.prefs
libcore/x-net/build.xml
libcore/x-net/src/main/java/javax/net/DefaultServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/DefaultSocketFactory.java
libcore/x-net/src/main/java/javax/net/ServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/SocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/CertPathTrustManagerParameters.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultHostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedEvent.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedListener.java
libcore/x-net/src/main/java/javax/net/ssl/HostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/HttpsURLConnection.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/KeyStoreBuilderParameters.java
libcore/x-net/src/main/java/javax/net/ssl/ManagerFactoryParameters.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContextSpi.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngine.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngineResult.java
libcore/x-net/src/main/java/javax/net/ssl/SSLException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLHandshakeException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLKeyException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPeerUnverifiedException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPermission.java
libcore/x-net/src/main/java/javax/net/ssl/SSLProtocolException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSession.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingEvent.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingListener.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/X509ExtendedKeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/package-info.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/HandshakeProtocol.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/KeyManagerImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImplWrapper.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketInputStream.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketOutputStream.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/CertPathTrustManagerParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HttpsURLConnectionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/KeyStoreBuilderParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLContext1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLEngineTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLPermissionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLServerSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/TrustManagerFactory1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLHandshakeExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLKeyExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLPeerUnverifiedExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLProtocolExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLSessionBindingEventTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/SocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/HttpsURLConnection_ImplTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/CipherSuiteTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/HandshakeProtocolTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/KeyManagerImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLEngineImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoriesTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFunctionalTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLStreamedInputTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/TrustManagerImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/KeyManagerFactoryImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/ProtocolVersionTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/TrustManagerFactoryImplTest.java
libcore/x-net/src/test/java/javax/net/ssl/KeyManagerFactorySpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/MySSLContextSpi.java
libcore/x-net/src/test/java/javax/net/ssl/MyTrustManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/SSLContextSpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/TrustManagerFactorySpiTests.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory1Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLContext2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLSessionBindingEventTest.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/TrustManagerFactory2Test.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MySSLContextSpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyTrustManagerFactorySpi.java
commit 8b79eb40a27f0b336d5516606d43162ecead09ca
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:58:17 2009 -0700
x-net_dalvik
commit a8dc3778cd2a1a5d6d0cfff6eec22e7bfbdb9c14
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:55 2009 -0700
x-net_802921
commit 07ca0ed8aa5927c909f880559c17d162c111608e
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:07 2009 -0700
x-net_527399
commit 9b44ccfc38c2fc2a6cf2c3cc39a13cc5bce635ba
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 11:14:01 2009 -0700
Small changes missed in the original submission of 22482./"
conscrypt,"Update x-net to Harmony r802921.
Notable changes
- synchronization added where it was needed!
- try/finally added to reliably tear down in DefaultSSLContext
- ContextImpl deleted, it wasn't necessary
- methods reordered to make statics first in the class
- PrivilegedActions parameterized with <Void>
- DigitalSignature now throws AssertionErrors in impossible states
and throws AlertExceptions on invalid keys (rather than dumping
a stacktrace)
- ValueKeys added to SSLSessionImpl instead of TwoKeyMaps
- SSLSessionImpl.clone() simplified to do a traditional clone
Squashed commit of the following:
commit 2d9e43d542ab7086af271bf52e847c582decbab1
Merge: 8b79eb4 a8dc377
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 15:25:21 2009 -0700
Merge branch 'x-net_802921' into x-net_dalvik
Conflicts:
libcore/x-net/.classpath
libcore/x-net/.settings/org.eclipse.jdt.core.prefs
libcore/x-net/build.xml
libcore/x-net/src/main/java/javax/net/DefaultServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/DefaultSocketFactory.java
libcore/x-net/src/main/java/javax/net/ServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/SocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/CertPathTrustManagerParameters.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultHostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedEvent.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedListener.java
libcore/x-net/src/main/java/javax/net/ssl/HostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/HttpsURLConnection.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/KeyStoreBuilderParameters.java
libcore/x-net/src/main/java/javax/net/ssl/ManagerFactoryParameters.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContextSpi.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngine.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngineResult.java
libcore/x-net/src/main/java/javax/net/ssl/SSLException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLHandshakeException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLKeyException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPeerUnverifiedException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPermission.java
libcore/x-net/src/main/java/javax/net/ssl/SSLProtocolException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSession.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingEvent.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingListener.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/X509ExtendedKeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/package-info.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/HandshakeProtocol.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/KeyManagerImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImplWrapper.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketInputStream.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketOutputStream.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/CertPathTrustManagerParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HttpsURLConnectionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/KeyStoreBuilderParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLContext1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLEngineTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLPermissionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLServerSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/TrustManagerFactory1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLHandshakeExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLKeyExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLPeerUnverifiedExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLProtocolExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLSessionBindingEventTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/SocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/HttpsURLConnection_ImplTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/CipherSuiteTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/HandshakeProtocolTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/KeyManagerImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLEngineImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoriesTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFunctionalTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLStreamedInputTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/TrustManagerImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/KeyManagerFactoryImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/ProtocolVersionTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/TrustManagerFactoryImplTest.java
libcore/x-net/src/test/java/javax/net/ssl/KeyManagerFactorySpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/MySSLContextSpi.java
libcore/x-net/src/test/java/javax/net/ssl/MyTrustManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/SSLContextSpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/TrustManagerFactorySpiTests.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory1Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLContext2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLSessionBindingEventTest.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/TrustManagerFactory2Test.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MySSLContextSpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyTrustManagerFactorySpi.java
commit 8b79eb40a27f0b336d5516606d43162ecead09ca
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:58:17 2009 -0700
x-net_dalvik
commit a8dc3778cd2a1a5d6d0cfff6eec22e7bfbdb9c14
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:55 2009 -0700
x-net_802921
commit 07ca0ed8aa5927c909f880559c17d162c111608e
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:07 2009 -0700
x-net_527399
commit 9b44ccfc38c2fc2a6cf2c3cc39a13cc5bce635ba
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 11:14:01 2009 -0700
Small changes missed in the original submission of 22482./"
conscrypt,"Update x-net to Harmony r802921.
Notable changes
- synchronization added where it was needed!
- try/finally added to reliably tear down in DefaultSSLContext
- ContextImpl deleted, it wasn't necessary
- methods reordered to make statics first in the class
- PrivilegedActions parameterized with <Void>
- DigitalSignature now throws AssertionErrors in impossible states
and throws AlertExceptions on invalid keys (rather than dumping
a stacktrace)
- ValueKeys added to SSLSessionImpl instead of TwoKeyMaps
- SSLSessionImpl.clone() simplified to do a traditional clone
Squashed commit of the following:
commit 2d9e43d542ab7086af271bf52e847c582decbab1
Merge: 8b79eb4 a8dc377
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 15:25:21 2009 -0700
Merge branch 'x-net_802921' into x-net_dalvik
Conflicts:
libcore/x-net/.classpath
libcore/x-net/.settings/org.eclipse.jdt.core.prefs
libcore/x-net/build.xml
libcore/x-net/src/main/java/javax/net/DefaultServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/DefaultSocketFactory.java
libcore/x-net/src/main/java/javax/net/ServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/SocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/CertPathTrustManagerParameters.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultHostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedEvent.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedListener.java
libcore/x-net/src/main/java/javax/net/ssl/HostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/HttpsURLConnection.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/KeyStoreBuilderParameters.java
libcore/x-net/src/main/java/javax/net/ssl/ManagerFactoryParameters.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContextSpi.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngine.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngineResult.java
libcore/x-net/src/main/java/javax/net/ssl/SSLException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLHandshakeException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLKeyException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPeerUnverifiedException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPermission.java
libcore/x-net/src/main/java/javax/net/ssl/SSLProtocolException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSession.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingEvent.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingListener.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/X509ExtendedKeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/package-info.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/HandshakeProtocol.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/KeyManagerImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImplWrapper.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketInputStream.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketOutputStream.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/CertPathTrustManagerParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HttpsURLConnectionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/KeyStoreBuilderParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLContext1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLEngineTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLPermissionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLServerSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/TrustManagerFactory1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLHandshakeExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLKeyExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLPeerUnverifiedExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLProtocolExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLSessionBindingEventTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/SocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/HttpsURLConnection_ImplTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/CipherSuiteTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/HandshakeProtocolTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/KeyManagerImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLEngineImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoriesTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFunctionalTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLStreamedInputTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/TrustManagerImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/KeyManagerFactoryImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/ProtocolVersionTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/TrustManagerFactoryImplTest.java
libcore/x-net/src/test/java/javax/net/ssl/KeyManagerFactorySpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/MySSLContextSpi.java
libcore/x-net/src/test/java/javax/net/ssl/MyTrustManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/SSLContextSpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/TrustManagerFactorySpiTests.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory1Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLContext2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLSessionBindingEventTest.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/TrustManagerFactory2Test.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MySSLContextSpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyTrustManagerFactorySpi.java
commit 8b79eb40a27f0b336d5516606d43162ecead09ca
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:58:17 2009 -0700
x-net_dalvik
commit a8dc3778cd2a1a5d6d0cfff6eec22e7bfbdb9c14
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:55 2009 -0700
x-net_802921
commit 07ca0ed8aa5927c909f880559c17d162c111608e
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:07 2009 -0700
x-net_527399
commit 9b44ccfc38c2fc2a6cf2c3cc39a13cc5bce635ba
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 11:14:01 2009 -0700
Small changes missed in the original submission of 22482./"
conscrypt,"Update x-net to Harmony r802921.
Notable changes
- synchronization added where it was needed!
- try/finally added to reliably tear down in DefaultSSLContext
- ContextImpl deleted, it wasn't necessary
- methods reordered to make statics first in the class
- PrivilegedActions parameterized with <Void>
- DigitalSignature now throws AssertionErrors in impossible states
and throws AlertExceptions on invalid keys (rather than dumping
a stacktrace)
- ValueKeys added to SSLSessionImpl instead of TwoKeyMaps
- SSLSessionImpl.clone() simplified to do a traditional clone
Squashed commit of the following:
commit 2d9e43d542ab7086af271bf52e847c582decbab1
Merge: 8b79eb4 a8dc377
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 15:25:21 2009 -0700
Merge branch 'x-net_802921' into x-net_dalvik
Conflicts:
libcore/x-net/.classpath
libcore/x-net/.settings/org.eclipse.jdt.core.prefs
libcore/x-net/build.xml
libcore/x-net/src/main/java/javax/net/DefaultServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/DefaultSocketFactory.java
libcore/x-net/src/main/java/javax/net/ServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/SocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/CertPathTrustManagerParameters.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultHostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedEvent.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedListener.java
libcore/x-net/src/main/java/javax/net/ssl/HostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/HttpsURLConnection.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/KeyStoreBuilderParameters.java
libcore/x-net/src/main/java/javax/net/ssl/ManagerFactoryParameters.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContextSpi.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngine.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngineResult.java
libcore/x-net/src/main/java/javax/net/ssl/SSLException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLHandshakeException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLKeyException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPeerUnverifiedException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPermission.java
libcore/x-net/src/main/java/javax/net/ssl/SSLProtocolException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSession.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingEvent.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingListener.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/X509ExtendedKeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/package-info.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/HandshakeProtocol.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/KeyManagerImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImplWrapper.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketInputStream.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketOutputStream.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/CertPathTrustManagerParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HttpsURLConnectionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/KeyStoreBuilderParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLContext1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLEngineTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLPermissionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLServerSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/TrustManagerFactory1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLHandshakeExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLKeyExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLPeerUnverifiedExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLProtocolExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLSessionBindingEventTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/SocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/HttpsURLConnection_ImplTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/CipherSuiteTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/HandshakeProtocolTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/KeyManagerImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLEngineImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoriesTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFunctionalTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLStreamedInputTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/TrustManagerImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/KeyManagerFactoryImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/ProtocolVersionTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/TrustManagerFactoryImplTest.java
libcore/x-net/src/test/java/javax/net/ssl/KeyManagerFactorySpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/MySSLContextSpi.java
libcore/x-net/src/test/java/javax/net/ssl/MyTrustManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/SSLContextSpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/TrustManagerFactorySpiTests.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory1Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLContext2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLSessionBindingEventTest.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/TrustManagerFactory2Test.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MySSLContextSpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyTrustManagerFactorySpi.java
commit 8b79eb40a27f0b336d5516606d43162ecead09ca
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:58:17 2009 -0700
x-net_dalvik
commit a8dc3778cd2a1a5d6d0cfff6eec22e7bfbdb9c14
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:55 2009 -0700
x-net_802921
commit 07ca0ed8aa5927c909f880559c17d162c111608e
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:07 2009 -0700
x-net_527399
commit 9b44ccfc38c2fc2a6cf2c3cc39a13cc5bce635ba
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 11:14:01 2009 -0700
Small changes missed in the original submission of 22482./"
conscrypt,"Update x-net to Harmony r802921.
Notable changes
- synchronization added where it was needed!
- try/finally added to reliably tear down in DefaultSSLContext
- ContextImpl deleted, it wasn't necessary
- methods reordered to make statics first in the class
- PrivilegedActions parameterized with <Void>
- DigitalSignature now throws AssertionErrors in impossible states
and throws AlertExceptions on invalid keys (rather than dumping
a stacktrace)
- ValueKeys added to SSLSessionImpl instead of TwoKeyMaps
- SSLSessionImpl.clone() simplified to do a traditional clone
Squashed commit of the following:
commit 2d9e43d542ab7086af271bf52e847c582decbab1
Merge: 8b79eb4 a8dc377
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 15:25:21 2009 -0700
Merge branch 'x-net_802921' into x-net_dalvik
Conflicts:
libcore/x-net/.classpath
libcore/x-net/.settings/org.eclipse.jdt.core.prefs
libcore/x-net/build.xml
libcore/x-net/src/main/java/javax/net/DefaultServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/DefaultSocketFactory.java
libcore/x-net/src/main/java/javax/net/ServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/SocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/CertPathTrustManagerParameters.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultHostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedEvent.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedListener.java
libcore/x-net/src/main/java/javax/net/ssl/HostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/HttpsURLConnection.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/KeyStoreBuilderParameters.java
libcore/x-net/src/main/java/javax/net/ssl/ManagerFactoryParameters.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContextSpi.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngine.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngineResult.java
libcore/x-net/src/main/java/javax/net/ssl/SSLException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLHandshakeException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLKeyException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPeerUnverifiedException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPermission.java
libcore/x-net/src/main/java/javax/net/ssl/SSLProtocolException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSession.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingEvent.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingListener.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/X509ExtendedKeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/package-info.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/HandshakeProtocol.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/KeyManagerImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImplWrapper.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketInputStream.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketOutputStream.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/CertPathTrustManagerParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HttpsURLConnectionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/KeyStoreBuilderParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLContext1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLEngineTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLPermissionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLServerSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/TrustManagerFactory1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLHandshakeExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLKeyExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLPeerUnverifiedExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLProtocolExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLSessionBindingEventTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/SocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/HttpsURLConnection_ImplTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/CipherSuiteTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/HandshakeProtocolTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/KeyManagerImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLEngineImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoriesTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFunctionalTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLStreamedInputTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/TrustManagerImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/KeyManagerFactoryImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/ProtocolVersionTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/TrustManagerFactoryImplTest.java
libcore/x-net/src/test/java/javax/net/ssl/KeyManagerFactorySpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/MySSLContextSpi.java
libcore/x-net/src/test/java/javax/net/ssl/MyTrustManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/SSLContextSpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/TrustManagerFactorySpiTests.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory1Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLContext2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLSessionBindingEventTest.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/TrustManagerFactory2Test.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MySSLContextSpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyTrustManagerFactorySpi.java
commit 8b79eb40a27f0b336d5516606d43162ecead09ca
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:58:17 2009 -0700
x-net_dalvik
commit a8dc3778cd2a1a5d6d0cfff6eec22e7bfbdb9c14
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:55 2009 -0700
x-net_802921
commit 07ca0ed8aa5927c909f880559c17d162c111608e
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:07 2009 -0700
x-net_527399
commit 9b44ccfc38c2fc2a6cf2c3cc39a13cc5bce635ba
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 11:14:01 2009 -0700
Small changes missed in the original submission of 22482./"
conscrypt,"Update x-net to Harmony r802921.
Notable changes
- synchronization added where it was needed!
- try/finally added to reliably tear down in DefaultSSLContext
- ContextImpl deleted, it wasn't necessary
- methods reordered to make statics first in the class
- PrivilegedActions parameterized with <Void>
- DigitalSignature now throws AssertionErrors in impossible states
and throws AlertExceptions on invalid keys (rather than dumping
a stacktrace)
- ValueKeys added to SSLSessionImpl instead of TwoKeyMaps
- SSLSessionImpl.clone() simplified to do a traditional clone
Squashed commit of the following:
commit 2d9e43d542ab7086af271bf52e847c582decbab1
Merge: 8b79eb4 a8dc377
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 15:25:21 2009 -0700
Merge branch 'x-net_802921' into x-net_dalvik
Conflicts:
libcore/x-net/.classpath
libcore/x-net/.settings/org.eclipse.jdt.core.prefs
libcore/x-net/build.xml
libcore/x-net/src/main/java/javax/net/DefaultServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/DefaultSocketFactory.java
libcore/x-net/src/main/java/javax/net/ServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/SocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/CertPathTrustManagerParameters.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultHostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedEvent.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedListener.java
libcore/x-net/src/main/java/javax/net/ssl/HostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/HttpsURLConnection.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/KeyStoreBuilderParameters.java
libcore/x-net/src/main/java/javax/net/ssl/ManagerFactoryParameters.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContextSpi.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngine.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngineResult.java
libcore/x-net/src/main/java/javax/net/ssl/SSLException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLHandshakeException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLKeyException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPeerUnverifiedException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPermission.java
libcore/x-net/src/main/java/javax/net/ssl/SSLProtocolException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSession.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingEvent.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingListener.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/X509ExtendedKeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/package-info.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/HandshakeProtocol.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/KeyManagerImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImplWrapper.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketInputStream.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketOutputStream.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/CertPathTrustManagerParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HttpsURLConnectionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/KeyStoreBuilderParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLContext1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLEngineTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLPermissionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLServerSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/TrustManagerFactory1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLHandshakeExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLKeyExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLPeerUnverifiedExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLProtocolExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLSessionBindingEventTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/SocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/HttpsURLConnection_ImplTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/CipherSuiteTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/HandshakeProtocolTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/KeyManagerImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLEngineImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoriesTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFunctionalTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLStreamedInputTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/TrustManagerImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/KeyManagerFactoryImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/ProtocolVersionTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/TrustManagerFactoryImplTest.java
libcore/x-net/src/test/java/javax/net/ssl/KeyManagerFactorySpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/MySSLContextSpi.java
libcore/x-net/src/test/java/javax/net/ssl/MyTrustManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/SSLContextSpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/TrustManagerFactorySpiTests.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory1Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLContext2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLSessionBindingEventTest.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/TrustManagerFactory2Test.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MySSLContextSpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyTrustManagerFactorySpi.java
commit 8b79eb40a27f0b336d5516606d43162ecead09ca
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:58:17 2009 -0700
x-net_dalvik
commit a8dc3778cd2a1a5d6d0cfff6eec22e7bfbdb9c14
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:55 2009 -0700
x-net_802921
commit 07ca0ed8aa5927c909f880559c17d162c111608e
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:07 2009 -0700
x-net_527399
commit 9b44ccfc38c2fc2a6cf2c3cc39a13cc5bce635ba
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 11:14:01 2009 -0700
Small changes missed in the original submission of 22482./"
conscrypt,"Update x-net to Harmony r802921.
Notable changes
- synchronization added where it was needed!
- try/finally added to reliably tear down in DefaultSSLContext
- ContextImpl deleted, it wasn't necessary
- methods reordered to make statics first in the class
- PrivilegedActions parameterized with <Void>
- DigitalSignature now throws AssertionErrors in impossible states
and throws AlertExceptions on invalid keys (rather than dumping
a stacktrace)
- ValueKeys added to SSLSessionImpl instead of TwoKeyMaps
- SSLSessionImpl.clone() simplified to do a traditional clone
Squashed commit of the following:
commit 2d9e43d542ab7086af271bf52e847c582decbab1
Merge: 8b79eb4 a8dc377
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 15:25:21 2009 -0700
Merge branch 'x-net_802921' into x-net_dalvik
Conflicts:
libcore/x-net/.classpath
libcore/x-net/.settings/org.eclipse.jdt.core.prefs
libcore/x-net/build.xml
libcore/x-net/src/main/java/javax/net/DefaultServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/DefaultSocketFactory.java
libcore/x-net/src/main/java/javax/net/ServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/SocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/CertPathTrustManagerParameters.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultHostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedEvent.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedListener.java
libcore/x-net/src/main/java/javax/net/ssl/HostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/HttpsURLConnection.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/KeyStoreBuilderParameters.java
libcore/x-net/src/main/java/javax/net/ssl/ManagerFactoryParameters.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContextSpi.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngine.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngineResult.java
libcore/x-net/src/main/java/javax/net/ssl/SSLException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLHandshakeException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLKeyException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPeerUnverifiedException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPermission.java
libcore/x-net/src/main/java/javax/net/ssl/SSLProtocolException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSession.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingEvent.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingListener.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/X509ExtendedKeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/package-info.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/HandshakeProtocol.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/KeyManagerImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImplWrapper.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketInputStream.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketOutputStream.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/CertPathTrustManagerParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HttpsURLConnectionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/KeyStoreBuilderParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLContext1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLEngineTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLPermissionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLServerSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/TrustManagerFactory1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLHandshakeExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLKeyExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLPeerUnverifiedExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLProtocolExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLSessionBindingEventTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/SocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/HttpsURLConnection_ImplTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/CipherSuiteTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/HandshakeProtocolTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/KeyManagerImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLEngineImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoriesTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFunctionalTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLStreamedInputTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/TrustManagerImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/KeyManagerFactoryImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/ProtocolVersionTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/TrustManagerFactoryImplTest.java
libcore/x-net/src/test/java/javax/net/ssl/KeyManagerFactorySpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/MySSLContextSpi.java
libcore/x-net/src/test/java/javax/net/ssl/MyTrustManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/SSLContextSpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/TrustManagerFactorySpiTests.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory1Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLContext2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLSessionBindingEventTest.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/TrustManagerFactory2Test.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MySSLContextSpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyTrustManagerFactorySpi.java
commit 8b79eb40a27f0b336d5516606d43162ecead09ca
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:58:17 2009 -0700
x-net_dalvik
commit a8dc3778cd2a1a5d6d0cfff6eec22e7bfbdb9c14
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:55 2009 -0700
x-net_802921
commit 07ca0ed8aa5927c909f880559c17d162c111608e
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:07 2009 -0700
x-net_527399
commit 9b44ccfc38c2fc2a6cf2c3cc39a13cc5bce635ba
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 11:14:01 2009 -0700
Small changes missed in the original submission of 22482./"
conscrypt,"Update x-net to Harmony r802921.
Notable changes
- synchronization added where it was needed!
- try/finally added to reliably tear down in DefaultSSLContext
- ContextImpl deleted, it wasn't necessary
- methods reordered to make statics first in the class
- PrivilegedActions parameterized with <Void>
- DigitalSignature now throws AssertionErrors in impossible states
and throws AlertExceptions on invalid keys (rather than dumping
a stacktrace)
- ValueKeys added to SSLSessionImpl instead of TwoKeyMaps
- SSLSessionImpl.clone() simplified to do a traditional clone
Squashed commit of the following:
commit 2d9e43d542ab7086af271bf52e847c582decbab1
Merge: 8b79eb4 a8dc377
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 15:25:21 2009 -0700
Merge branch 'x-net_802921' into x-net_dalvik
Conflicts:
libcore/x-net/.classpath
libcore/x-net/.settings/org.eclipse.jdt.core.prefs
libcore/x-net/build.xml
libcore/x-net/src/main/java/javax/net/DefaultServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/DefaultSocketFactory.java
libcore/x-net/src/main/java/javax/net/ServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/SocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/CertPathTrustManagerParameters.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultHostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedEvent.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedListener.java
libcore/x-net/src/main/java/javax/net/ssl/HostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/HttpsURLConnection.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/KeyStoreBuilderParameters.java
libcore/x-net/src/main/java/javax/net/ssl/ManagerFactoryParameters.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContextSpi.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngine.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngineResult.java
libcore/x-net/src/main/java/javax/net/ssl/SSLException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLHandshakeException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLKeyException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPeerUnverifiedException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPermission.java
libcore/x-net/src/main/java/javax/net/ssl/SSLProtocolException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSession.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingEvent.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingListener.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/X509ExtendedKeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/package-info.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/HandshakeProtocol.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/KeyManagerImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImplWrapper.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketInputStream.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketOutputStream.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/CertPathTrustManagerParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HttpsURLConnectionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/KeyStoreBuilderParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLContext1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLEngineTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLPermissionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLServerSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/TrustManagerFactory1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLHandshakeExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLKeyExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLPeerUnverifiedExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLProtocolExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLSessionBindingEventTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/SocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/HttpsURLConnection_ImplTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/CipherSuiteTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/HandshakeProtocolTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/KeyManagerImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLEngineImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoriesTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFunctionalTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLStreamedInputTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/TrustManagerImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/KeyManagerFactoryImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/ProtocolVersionTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/TrustManagerFactoryImplTest.java
libcore/x-net/src/test/java/javax/net/ssl/KeyManagerFactorySpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/MySSLContextSpi.java
libcore/x-net/src/test/java/javax/net/ssl/MyTrustManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/SSLContextSpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/TrustManagerFactorySpiTests.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory1Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLContext2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLSessionBindingEventTest.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/TrustManagerFactory2Test.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MySSLContextSpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyTrustManagerFactorySpi.java
commit 8b79eb40a27f0b336d5516606d43162ecead09ca
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:58:17 2009 -0700
x-net_dalvik
commit a8dc3778cd2a1a5d6d0cfff6eec22e7bfbdb9c14
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:55 2009 -0700
x-net_802921
commit 07ca0ed8aa5927c909f880559c17d162c111608e
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:07 2009 -0700
x-net_527399
commit 9b44ccfc38c2fc2a6cf2c3cc39a13cc5bce635ba
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 11:14:01 2009 -0700
Small changes missed in the original submission of 22482./"
conscrypt,"Update x-net to Harmony r802921.
Notable changes
- synchronization added where it was needed!
- try/finally added to reliably tear down in DefaultSSLContext
- ContextImpl deleted, it wasn't necessary
- methods reordered to make statics first in the class
- PrivilegedActions parameterized with <Void>
- DigitalSignature now throws AssertionErrors in impossible states
and throws AlertExceptions on invalid keys (rather than dumping
a stacktrace)
- ValueKeys added to SSLSessionImpl instead of TwoKeyMaps
- SSLSessionImpl.clone() simplified to do a traditional clone
Squashed commit of the following:
commit 2d9e43d542ab7086af271bf52e847c582decbab1
Merge: 8b79eb4 a8dc377
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 15:25:21 2009 -0700
Merge branch 'x-net_802921' into x-net_dalvik
Conflicts:
libcore/x-net/.classpath
libcore/x-net/.settings/org.eclipse.jdt.core.prefs
libcore/x-net/build.xml
libcore/x-net/src/main/java/javax/net/DefaultServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/DefaultSocketFactory.java
libcore/x-net/src/main/java/javax/net/ServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/SocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/CertPathTrustManagerParameters.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultHostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/DefaultSSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedEvent.java
libcore/x-net/src/main/java/javax/net/ssl/HandshakeCompletedListener.java
libcore/x-net/src/main/java/javax/net/ssl/HostnameVerifier.java
libcore/x-net/src/main/java/javax/net/ssl/HttpsURLConnection.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/KeyManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/KeyStoreBuilderParameters.java
libcore/x-net/src/main/java/javax/net/ssl/ManagerFactoryParameters.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLContextSpi.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngine.java
libcore/x-net/src/main/java/javax/net/ssl/SSLEngineResult.java
libcore/x-net/src/main/java/javax/net/ssl/SSLException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLHandshakeException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLKeyException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPeerUnverifiedException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLPermission.java
libcore/x-net/src/main/java/javax/net/ssl/SSLProtocolException.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLServerSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSession.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingEvent.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionBindingListener.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSessionContext.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocket.java
libcore/x-net/src/main/java/javax/net/ssl/SSLSocketFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactory.java
libcore/x-net/src/main/java/javax/net/ssl/TrustManagerFactorySpi.java
libcore/x-net/src/main/java/javax/net/ssl/X509ExtendedKeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509KeyManager.java
libcore/x-net/src/main/java/javax/net/ssl/X509TrustManager.java
libcore/x-net/src/main/java/javax/net/ssl/package-info.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/HandshakeProtocol.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/KeyManagerImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImplWrapper.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoryImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketImpl.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketInputStream.java
libcore/x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketOutputStream.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/CertPathTrustManagerParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/HttpsURLConnectionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/KeyStoreBuilderParametersTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLContext1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLEngineTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLPermissionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLServerSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/SSLSocketTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/TrustManagerFactory1Test.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/HandshakeCompletedEventTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLHandshakeExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLKeyExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLPeerUnverifiedExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLProtocolExceptionTest.java
libcore/x-net/src/test/api/java/org/apache/harmony/xnet/tests/javax/net/ssl/serialization/SSLSessionBindingEventTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/SocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/DefaultSSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/HttpsURLConnection_ImplTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLServerSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/javax/net/ssl/SSLSocketFactoryTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/CipherSuiteTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/HandshakeProtocolTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/KeyManagerImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLEngineImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLServerSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionContextImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSessionImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFactoriesTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketFunctionalTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLSocketImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/SSLStreamedInputTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImplTest.java
libcore/x-net/src/test/impl/java.injected/org/apache/harmony/xnet/provider/jsse/TrustManagerImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/DigitalSignatureTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/KeyManagerFactoryImplTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/ProtocolVersionTest.java
libcore/x-net/src/test/impl/java/org/apache/harmony/xnet/tests/provider/jsse/TrustManagerFactoryImplTest.java
libcore/x-net/src/test/java/javax/net/ssl/KeyManagerFactorySpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/MySSLContextSpi.java
libcore/x-net/src/test/java/javax/net/ssl/MyTrustManagerFactorySpi.java
libcore/x-net/src/test/java/javax/net/ssl/SSLContextSpiTests.java
libcore/x-net/src/test/java/javax/net/ssl/TrustManagerFactorySpiTests.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory1Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/KeyManagerFactory2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLContext2Test.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/SSLSessionBindingEventTest.java
libcore/x-net/src/test/java/tests/api/javax/net/ssl/TrustManagerFactory2Test.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyKeyManagerFactorySpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MySSLContextSpi.java
libcore/x-net/src/test/support/common/java/org/apache/harmony/xnet/tests/support/MyTrustManagerFactorySpi.java
commit 8b79eb40a27f0b336d5516606d43162ecead09ca
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:58:17 2009 -0700
x-net_dalvik
commit a8dc3778cd2a1a5d6d0cfff6eec22e7bfbdb9c14
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:55 2009 -0700
x-net_802921
commit 07ca0ed8aa5927c909f880559c17d162c111608e
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 12:56:07 2009 -0700
x-net_527399
commit 9b44ccfc38c2fc2a6cf2c3cc39a13cc5bce635ba
Author: Jesse Wilson <jessewilson@google.com>
Date:   Tue Aug 25 11:14:01 2009 -0700
Small changes missed in the original submission of 22482./"
conscrypt,"Update crypto package to Harmony r802921. Only Javadoc changes.
commit d5d4307b5b9f37e6f66ab1273be1acd2a29177de
Merge: 2c2287b 1c60d7c
Author: Jesse Wilson <jessewilson@google.com>
Date:   Mon Aug 31 15:36:46 2009 -0700
Merge branch 'crypto_802921' into crypto_dalvik
Conflicts:
libcore/crypto/.classpath
libcore/crypto/build.xml
libcore/crypto/src/main/java/javax/crypto/BadPaddingException.java
libcore/crypto/src/main/java/javax/crypto/Cipher.java
libcore/crypto/src/main/java/javax/crypto/CipherInputStream.java
libcore/crypto/src/main/java/javax/crypto/CipherOutputStream.java
libcore/crypto/src/main/java/javax/crypto/CipherSpi.java
libcore/crypto/src/main/java/javax/crypto/EncryptedPrivateKeyInfo.java
libcore/crypto/src/main/java/javax/crypto/ExemptionMechanism.java
libcore/crypto/src/main/java/javax/crypto/ExemptionMechanismException.java
libcore/crypto/src/main/java/javax/crypto/ExemptionMechanismSpi.java
libcore/crypto/src/main/java/javax/crypto/IllegalBlockSizeException.java
libcore/crypto/src/main/java/javax/crypto/KeyAgreement.java
libcore/crypto/src/main/java/javax/crypto/KeyAgreementSpi.java
libcore/crypto/src/main/java/javax/crypto/KeyGenerator.java
libcore/crypto/src/main/java/javax/crypto/KeyGeneratorSpi.java
libcore/crypto/src/main/java/javax/crypto/Mac.java
libcore/crypto/src/main/java/javax/crypto/MacSpi.java
libcore/crypto/src/main/java/javax/crypto/NoSuchPaddingException.java
libcore/crypto/src/main/java/javax/crypto/NullCipher.java
libcore/crypto/src/main/java/javax/crypto/SealedObject.java
libcore/crypto/src/main/java/javax/crypto/SecretKey.java
libcore/crypto/src/main/java/javax/crypto/SecretKeyFactory.java
libcore/crypto/src/main/java/javax/crypto/SecretKeyFactorySpi.java
libcore/crypto/src/main/java/javax/crypto/ShortBufferException.java
libcore/crypto/src/main/java/javax/crypto/interfaces/DHKey.java
libcore/crypto/src/main/java/javax/crypto/interfaces/DHPrivateKey.java
libcore/crypto/src/main/java/javax/crypto/interfaces/DHPublicKey.java
libcore/crypto/src/main/java/javax/crypto/interfaces/PBEKey.java
libcore/crypto/src/main/java/javax/crypto/spec/DESKeySpec.java
libcore/crypto/src/main/java/javax/crypto/spec/DESedeKeySpec.java
libcore/crypto/src/main/java/javax/crypto/spec/DHGenParameterSpec.java
libcore/crypto/src/main/java/javax/crypto/spec/DHParameterSpec.java
libcore/crypto/src/main/java/javax/crypto/spec/DHPrivateKeySpec.java
libcore/crypto/src/main/java/javax/crypto/spec/DHPublicKeySpec.java
libcore/crypto/src/main/java/javax/crypto/spec/IvParameterSpec.java
libcore/crypto/src/main/java/javax/crypto/spec/OAEPParameterSpec.java
libcore/crypto/src/main/java/javax/crypto/spec/PBEKeySpec.java
libcore/crypto/src/main/java/javax/crypto/spec/PBEParameterSpec.java
libcore/crypto/src/main/java/javax/crypto/spec/PSource.java
libcore/crypto/src/main/java/javax/crypto/spec/RC2ParameterSpec.java
libcore/crypto/src/main/java/javax/crypto/spec/RC5ParameterSpec.java
libcore/crypto/src/main/java/javax/crypto/spec/SecretKeySpec.java
commit 2c2287b521cc5f558d9929e14e31ec92da6285b1
Author: Jesse Wilson <jessewilson@google.com>
Date:   Mon Aug 31 14:56:45 2009 -0700
crypto_dalvik
commit 1c60d7c222c55ae49add8345a192c54357bb4a1f
Author: Jesse Wilson <jessewilson@google.com>
Date:   Mon Aug 31 14:56:34 2009 -0700
crypto_802921
commit 50cf7f5d97de2f65ee0769aafec7b5a3551cb5d0
Author: Jesse Wilson <jessewilson@google.com>
Date:   Mon Aug 31 14:56:27 2009 -0700
crypto_527399/"
conscrypt,"Fix our SSLSession implementations to call valueUnbound on remove.
This addresses the other problem from the following abandoned change:
https://android-git.corp.google.com/g/4743/Fix OpenSSLSessionImpl.getCreationTime and getLastAccessedTime.
This addresses one part of this abandoned change from ursg:
https://android-git.corp.google.com/g/4743
I've also tidied up the native method names to use the harmony ""-Impl""
convention, removed useless methods that just forward to a native method,
and removed dead code. I've canonicalized some of the duplication too,
but I want to go through the rest of out OpenSSL code before I really start
trying to remove the duplication.
When this is submitted, I'll fix the other (unrelated) bug the abandoned
change addressed./"
conscrypt,"Set peer for new SSLSessionImpl instances.
Bug: http://code.google.com/p/android/issues/detail?id=4914/"
conscrypt,"Rewrite JSSE code to use one openssl SSL per SSLSocket an one SSL_CTX per SSLSessionContext
Summary:
b/1758225: Revisit OpenSSL locking
Removed the locking original put in to address b/1678800 which
had been causing problems for the HeapWorker thread which was
timing out waiting for the lock in the finalizers while other
threads were connecting.
b/1678800: Reliability tool: Crash in libcrypto @ https://opac.ntu.ac.uk
Properly fixed the native crash by avoid sharing SSL_SESSION objects
between SSL_CTX objects
Testing:
- adb shell run-core-tests --verbose tests.xnet.AllTests
- adb shell run-core-tests --verbose javax.net.ssl.AllTests
- Test app that reloads https://opac.ntu.ac.uk
Details:
Each AbstractSessionContext now has an associated SSL_CTX,
referenced through the sslCtxNativePointer. SSL_CTX on the native
side defines the scope of SSL_SESSION caching, and this brings the
Java SSLSessionContext caching into alignment with the native
code. OpenSSLSessionImpl now uses AbstractSessionContext instead
of SSLSessionContext for access to the underlying SSL_CTX.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParameters.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Added AbstractSessionContext.putSession so OpenSSLSocketImpl/OpenSSLSessionImpl can
directly assign to the current AbstractSessionContext (whether it
be a ClientSessionContext or a ServerSessionContext) without
casting.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Cleaning up use of SSL_CTX and SSL instances in SSLSocket/SSLServerSocket implementation
The major change is that openssl SSL instances are allocated for
the life of the matching Java object, replacing the SSL_CTX and
the SSL objects that had previously been allocated only starting
at handshake time. We should never have been sharing SSL_SESSION
instances between SSL_CTX instances, which was the source of the
native crashes dating back to cupcake which the
OpenSSLSocket.class locking had been preventing.
- NativeCrypto now has better defined and independant wrappers on
openssl functionality. A followon checkin should move the
remaining openssl JNI code here with the intent of being able to
write and end-to-end test of the openssl code using NativeCrypto
without the JSSE implementation classes. The following gives a
list of the new native functions with a mapping to the old
implementation code. The new code has a more functional style
where SSL_CTX and SSL instances are passed and returned as
arguments, not extracted from Java instances
SSL_CTX_new                       OpenSSLSocketImpl.nativeinit, OpenSSLServerSocketImpl.nativeinit, SSLParameters.nativeinitsslctx
SSL_CTX_get_ciphers_list          OpenSSLSocketImpl.nativeGetEnabledCipherSuites
SSL_CTX_free                      OpenSSLSocketImpl.nativefree, OpenSSLServerSocketImpl.nativefree
SSL_new                           OpenSSLSocketImpl.nativeinit, OpenSSLSocketImpl.init, OpenSSLServerSocketImpl.nativeinit, OpenSSLServerSocketImpl.init
SSL_get_options                   OpenSSLSocketImpl.nativesetenabledprotocols
SSL_set_options                   OpenSSLSocketImpl.nativesetenabledprotocols
SSL_get_ciphers                   OpenSSLSocketImpl.nativeGetEnabledCipherSuites
SSL_set_cipher_list               OpenSSLSocketImpl.nativeSetEnabledCipherSuites
SSL_free                          OpenSSLSocketImpl.nativefree, OpenSSLServerSocketImpl.nativefree
- While the focus in NativeCrypto is on native code, it also
contains some helpers/wrappers especially for code that doesn't
depend on specific SSL_CTX, SSL instances or that needs to do
massaging of data formats between Java and OpenSSL. Some of
these had previously been duplicated in the client and server
versions of the code. For example:
getSupportedCipherSuites OpenSSLSocketImpl.nativegetsupportedciphersuites, OpenSSLServerSocketImpl.nativegetsupportedciphersuites
getSupportedProtocols          OpenSSLSocketImpl.getSupportedProtocols, OpenSSLServerSocketImpl.getSupportedProtocols
getEnabledProtocols             OpenSSLSocketImpl.getEnabledProtocols,OpenSSLServerSocketImpl.getEnabledProtocols
setEnabledProtocols             OpenSSLSocketImpl.setEnabledProtocols
setEnabledCipherSuites           OpenSSLSocketImpl.setEnabledCipherSuites
- Moved JNI initialization from OpenSSLSocketImpl to NativeCrypto
which is the future home of all the openssl related native code.
clinit                          OpenSSLSocketImpl.nativeinitstatic
- NativeCrypto.CertificateChainVerifier is a new interface to
decouple callbacks from openssl from a specific dependence on a
OpenSSLSocketImpl.verify_callback method. Changed to return
boolean instead of int.
- Renamed OpenSSLSocketImpl.ssl to OpenSSLSocketImpl.sslNativePointer for consistency
- Changed OpenSSLSocketImpl nativeconnect, nativegetsslsession,
nativecipherauthenticationmethod, nativeaccept, nativeread,
nativewrite, nativeinterrupt, nativeclose, nativefree to take
arguments instead of inspect object state in preparation for
moving to NativeCrypto
- other notable NativeCrypto changes included
* adding SSL_SESSION_get_peer_cert_chain,
SSL_SESSION_get_version, and SSL_get_version (and
get_ssl_version) which are ""missing methods"" in openssl
* ssl_msg_callback_LOG callback and get_content_type for handshake debugging
* removing jfieldID's for our classes now that we pass in values in arguments
* changed aliveAndKicking to be volative since we poll on it to communicate between threads
* changed from C style declarations at beginning of block to C++ at first use on methods with major changes
* stop freeing SSL instances on error, only SSL_clear it
* improved session reuse logging when reproducing b/1678800
* change verify_callback to return verifyCertificateChain result
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketFactoryImpl.java
When we accept a server socket, we pass the existing SSL state
instance from the server socket to the newly accepted socket via
the constructor where it is copied with SSL_dup, instead of
through both the constructor and later the accept method.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
Cleaned up nativesetclientauth from using SSL_CTX to SSL, passing
ssl as argument in preparation for future movement to
NativeCrypto.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
Removed ssl_op_no cache for rarely used enabled protocol methods
so that code could more easily be shared in NativeCrypto between
client and server.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed public getId, getCreationTime, getPeerCertificates,
getCipherSuite, getProtocol from being instance methods that
looked at the OpenSSLSessionImpl object state to be static mthods
that take the native pointers as arguments in preparation for
moving to NativeCrypto. Rename session -> sslSessionNativePointer
for consistency.  Inlined initializeNative, which wasn't really
the native code.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
Removed lock on OpenSSLSocketImpl.class lock from around
OpenSSLSocketImpl's use of nativeconnect, nativegetsslsession, and
nativecipherauthenticationmethod as well as OpenSSLSessionImpl's
use of freeImpl, fixing b/1758225: Revisit OpenSSL locking
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
Unrelated changes
Removed unused ssl_ctx, nativeinitsslctx, getSSLCTX
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParameters.java
Fix bug in both putSession implementations where we cached
sessions with zero length id. Also change indexById to pass in id
in client implementation.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Make sure we clone SSLParameters passed to the SSLSocketFactory
and SSLServerSocketFactory so that muting the client instance does
not change the server instance and vice versa. Explicitly set
setUseClientMode(false) on the server SSLParameters. These changes
are to bring things more into alignment with the original harmony
classes which properly support client/server role switching during
handshaking.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketFactoryImpl.java
Make locks object fields final
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Moved updateInstanceCount(1) logic and sslParameters assignment to init method
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed getCachedClientSession to respect getUseClientMode
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Spelling of listensers to listeners in javadoc
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Spelling SSLInputStream to SSLOutputStream in comment
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed shutdownInput and shutdownOutput to call to the underlying socket
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Set sslNativePointer to 0 when freeing underlying SSL object
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Removed IOException logging in getSession, which is expected to
simply return SSL_NULL_WITH_NULL_NULL when there are problems.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Disabled ""Using factory"" message on successful creation of
SocketFactory which was a bit noisy running tests. However, added
logging in failure case including the related exception:
x-net/src/main/java/javax/net/ssl/SSLSocketFactory.java
Disabled logging of OpenSSL session deallocation
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
Register SSLContextImpl as a source of SSL and SSL3 SSLContexts,
not just TLS and TLSv1.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
Fix whitespace in comment
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/CertificateRequest.java
Change-Id: I99975ae22599c7df0d249fa013ae7ea7c9c08051/"
conscrypt,"Rewrite JSSE code to use one openssl SSL per SSLSocket an one SSL_CTX per SSLSessionContext
Summary:
b/1758225: Revisit OpenSSL locking
Removed the locking original put in to address b/1678800 which
had been causing problems for the HeapWorker thread which was
timing out waiting for the lock in the finalizers while other
threads were connecting.
b/1678800: Reliability tool: Crash in libcrypto @ https://opac.ntu.ac.uk
Properly fixed the native crash by avoid sharing SSL_SESSION objects
between SSL_CTX objects
Testing:
- adb shell run-core-tests --verbose tests.xnet.AllTests
- adb shell run-core-tests --verbose javax.net.ssl.AllTests
- Test app that reloads https://opac.ntu.ac.uk
Details:
Each AbstractSessionContext now has an associated SSL_CTX,
referenced through the sslCtxNativePointer. SSL_CTX on the native
side defines the scope of SSL_SESSION caching, and this brings the
Java SSLSessionContext caching into alignment with the native
code. OpenSSLSessionImpl now uses AbstractSessionContext instead
of SSLSessionContext for access to the underlying SSL_CTX.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParameters.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Added AbstractSessionContext.putSession so OpenSSLSocketImpl/OpenSSLSessionImpl can
directly assign to the current AbstractSessionContext (whether it
be a ClientSessionContext or a ServerSessionContext) without
casting.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Cleaning up use of SSL_CTX and SSL instances in SSLSocket/SSLServerSocket implementation
The major change is that openssl SSL instances are allocated for
the life of the matching Java object, replacing the SSL_CTX and
the SSL objects that had previously been allocated only starting
at handshake time. We should never have been sharing SSL_SESSION
instances between SSL_CTX instances, which was the source of the
native crashes dating back to cupcake which the
OpenSSLSocket.class locking had been preventing.
- NativeCrypto now has better defined and independant wrappers on
openssl functionality. A followon checkin should move the
remaining openssl JNI code here with the intent of being able to
write and end-to-end test of the openssl code using NativeCrypto
without the JSSE implementation classes. The following gives a
list of the new native functions with a mapping to the old
implementation code. The new code has a more functional style
where SSL_CTX and SSL instances are passed and returned as
arguments, not extracted from Java instances
SSL_CTX_new                       OpenSSLSocketImpl.nativeinit, OpenSSLServerSocketImpl.nativeinit, SSLParameters.nativeinitsslctx
SSL_CTX_get_ciphers_list          OpenSSLSocketImpl.nativeGetEnabledCipherSuites
SSL_CTX_free                      OpenSSLSocketImpl.nativefree, OpenSSLServerSocketImpl.nativefree
SSL_new                           OpenSSLSocketImpl.nativeinit, OpenSSLSocketImpl.init, OpenSSLServerSocketImpl.nativeinit, OpenSSLServerSocketImpl.init
SSL_get_options                   OpenSSLSocketImpl.nativesetenabledprotocols
SSL_set_options                   OpenSSLSocketImpl.nativesetenabledprotocols
SSL_get_ciphers                   OpenSSLSocketImpl.nativeGetEnabledCipherSuites
SSL_set_cipher_list               OpenSSLSocketImpl.nativeSetEnabledCipherSuites
SSL_free                          OpenSSLSocketImpl.nativefree, OpenSSLServerSocketImpl.nativefree
- While the focus in NativeCrypto is on native code, it also
contains some helpers/wrappers especially for code that doesn't
depend on specific SSL_CTX, SSL instances or that needs to do
massaging of data formats between Java and OpenSSL. Some of
these had previously been duplicated in the client and server
versions of the code. For example:
getSupportedCipherSuites OpenSSLSocketImpl.nativegetsupportedciphersuites, OpenSSLServerSocketImpl.nativegetsupportedciphersuites
getSupportedProtocols          OpenSSLSocketImpl.getSupportedProtocols, OpenSSLServerSocketImpl.getSupportedProtocols
getEnabledProtocols             OpenSSLSocketImpl.getEnabledProtocols,OpenSSLServerSocketImpl.getEnabledProtocols
setEnabledProtocols             OpenSSLSocketImpl.setEnabledProtocols
setEnabledCipherSuites           OpenSSLSocketImpl.setEnabledCipherSuites
- Moved JNI initialization from OpenSSLSocketImpl to NativeCrypto
which is the future home of all the openssl related native code.
clinit                          OpenSSLSocketImpl.nativeinitstatic
- NativeCrypto.CertificateChainVerifier is a new interface to
decouple callbacks from openssl from a specific dependence on a
OpenSSLSocketImpl.verify_callback method. Changed to return
boolean instead of int.
- Renamed OpenSSLSocketImpl.ssl to OpenSSLSocketImpl.sslNativePointer for consistency
- Changed OpenSSLSocketImpl nativeconnect, nativegetsslsession,
nativecipherauthenticationmethod, nativeaccept, nativeread,
nativewrite, nativeinterrupt, nativeclose, nativefree to take
arguments instead of inspect object state in preparation for
moving to NativeCrypto
- other notable NativeCrypto changes included
* adding SSL_SESSION_get_peer_cert_chain,
SSL_SESSION_get_version, and SSL_get_version (and
get_ssl_version) which are ""missing methods"" in openssl
* ssl_msg_callback_LOG callback and get_content_type for handshake debugging
* removing jfieldID's for our classes now that we pass in values in arguments
* changed aliveAndKicking to be volative since we poll on it to communicate between threads
* changed from C style declarations at beginning of block to C++ at first use on methods with major changes
* stop freeing SSL instances on error, only SSL_clear it
* improved session reuse logging when reproducing b/1678800
* change verify_callback to return verifyCertificateChain result
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketFactoryImpl.java
When we accept a server socket, we pass the existing SSL state
instance from the server socket to the newly accepted socket via
the constructor where it is copied with SSL_dup, instead of
through both the constructor and later the accept method.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
Cleaned up nativesetclientauth from using SSL_CTX to SSL, passing
ssl as argument in preparation for future movement to
NativeCrypto.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
Removed ssl_op_no cache for rarely used enabled protocol methods
so that code could more easily be shared in NativeCrypto between
client and server.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed public getId, getCreationTime, getPeerCertificates,
getCipherSuite, getProtocol from being instance methods that
looked at the OpenSSLSessionImpl object state to be static mthods
that take the native pointers as arguments in preparation for
moving to NativeCrypto. Rename session -> sslSessionNativePointer
for consistency.  Inlined initializeNative, which wasn't really
the native code.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
Removed lock on OpenSSLSocketImpl.class lock from around
OpenSSLSocketImpl's use of nativeconnect, nativegetsslsession, and
nativecipherauthenticationmethod as well as OpenSSLSessionImpl's
use of freeImpl, fixing b/1758225: Revisit OpenSSL locking
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
Unrelated changes
Removed unused ssl_ctx, nativeinitsslctx, getSSLCTX
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParameters.java
Fix bug in both putSession implementations where we cached
sessions with zero length id. Also change indexById to pass in id
in client implementation.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Make sure we clone SSLParameters passed to the SSLSocketFactory
and SSLServerSocketFactory so that muting the client instance does
not change the server instance and vice versa. Explicitly set
setUseClientMode(false) on the server SSLParameters. These changes
are to bring things more into alignment with the original harmony
classes which properly support client/server role switching during
handshaking.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketFactoryImpl.java
Make locks object fields final
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Moved updateInstanceCount(1) logic and sslParameters assignment to init method
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed getCachedClientSession to respect getUseClientMode
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Spelling of listensers to listeners in javadoc
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Spelling SSLInputStream to SSLOutputStream in comment
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed shutdownInput and shutdownOutput to call to the underlying socket
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Set sslNativePointer to 0 when freeing underlying SSL object
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Removed IOException logging in getSession, which is expected to
simply return SSL_NULL_WITH_NULL_NULL when there are problems.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Disabled ""Using factory"" message on successful creation of
SocketFactory which was a bit noisy running tests. However, added
logging in failure case including the related exception:
x-net/src/main/java/javax/net/ssl/SSLSocketFactory.java
Disabled logging of OpenSSL session deallocation
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
Register SSLContextImpl as a source of SSL and SSL3 SSLContexts,
not just TLS and TLSv1.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
Fix whitespace in comment
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/CertificateRequest.java
Change-Id: I99975ae22599c7df0d249fa013ae7ea7c9c08051/"
conscrypt,"Rewrite JSSE code to use one openssl SSL per SSLSocket an one SSL_CTX per SSLSessionContext
Summary:
b/1758225: Revisit OpenSSL locking
Removed the locking original put in to address b/1678800 which
had been causing problems for the HeapWorker thread which was
timing out waiting for the lock in the finalizers while other
threads were connecting.
b/1678800: Reliability tool: Crash in libcrypto @ https://opac.ntu.ac.uk
Properly fixed the native crash by avoid sharing SSL_SESSION objects
between SSL_CTX objects
Testing:
- adb shell run-core-tests --verbose tests.xnet.AllTests
- adb shell run-core-tests --verbose javax.net.ssl.AllTests
- Test app that reloads https://opac.ntu.ac.uk
Details:
Each AbstractSessionContext now has an associated SSL_CTX,
referenced through the sslCtxNativePointer. SSL_CTX on the native
side defines the scope of SSL_SESSION caching, and this brings the
Java SSLSessionContext caching into alignment with the native
code. OpenSSLSessionImpl now uses AbstractSessionContext instead
of SSLSessionContext for access to the underlying SSL_CTX.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParameters.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Added AbstractSessionContext.putSession so OpenSSLSocketImpl/OpenSSLSessionImpl can
directly assign to the current AbstractSessionContext (whether it
be a ClientSessionContext or a ServerSessionContext) without
casting.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Cleaning up use of SSL_CTX and SSL instances in SSLSocket/SSLServerSocket implementation
The major change is that openssl SSL instances are allocated for
the life of the matching Java object, replacing the SSL_CTX and
the SSL objects that had previously been allocated only starting
at handshake time. We should never have been sharing SSL_SESSION
instances between SSL_CTX instances, which was the source of the
native crashes dating back to cupcake which the
OpenSSLSocket.class locking had been preventing.
- NativeCrypto now has better defined and independant wrappers on
openssl functionality. A followon checkin should move the
remaining openssl JNI code here with the intent of being able to
write and end-to-end test of the openssl code using NativeCrypto
without the JSSE implementation classes. The following gives a
list of the new native functions with a mapping to the old
implementation code. The new code has a more functional style
where SSL_CTX and SSL instances are passed and returned as
arguments, not extracted from Java instances
SSL_CTX_new                       OpenSSLSocketImpl.nativeinit, OpenSSLServerSocketImpl.nativeinit, SSLParameters.nativeinitsslctx
SSL_CTX_get_ciphers_list          OpenSSLSocketImpl.nativeGetEnabledCipherSuites
SSL_CTX_free                      OpenSSLSocketImpl.nativefree, OpenSSLServerSocketImpl.nativefree
SSL_new                           OpenSSLSocketImpl.nativeinit, OpenSSLSocketImpl.init, OpenSSLServerSocketImpl.nativeinit, OpenSSLServerSocketImpl.init
SSL_get_options                   OpenSSLSocketImpl.nativesetenabledprotocols
SSL_set_options                   OpenSSLSocketImpl.nativesetenabledprotocols
SSL_get_ciphers                   OpenSSLSocketImpl.nativeGetEnabledCipherSuites
SSL_set_cipher_list               OpenSSLSocketImpl.nativeSetEnabledCipherSuites
SSL_free                          OpenSSLSocketImpl.nativefree, OpenSSLServerSocketImpl.nativefree
- While the focus in NativeCrypto is on native code, it also
contains some helpers/wrappers especially for code that doesn't
depend on specific SSL_CTX, SSL instances or that needs to do
massaging of data formats between Java and OpenSSL. Some of
these had previously been duplicated in the client and server
versions of the code. For example:
getSupportedCipherSuites OpenSSLSocketImpl.nativegetsupportedciphersuites, OpenSSLServerSocketImpl.nativegetsupportedciphersuites
getSupportedProtocols          OpenSSLSocketImpl.getSupportedProtocols, OpenSSLServerSocketImpl.getSupportedProtocols
getEnabledProtocols             OpenSSLSocketImpl.getEnabledProtocols,OpenSSLServerSocketImpl.getEnabledProtocols
setEnabledProtocols             OpenSSLSocketImpl.setEnabledProtocols
setEnabledCipherSuites           OpenSSLSocketImpl.setEnabledCipherSuites
- Moved JNI initialization from OpenSSLSocketImpl to NativeCrypto
which is the future home of all the openssl related native code.
clinit                          OpenSSLSocketImpl.nativeinitstatic
- NativeCrypto.CertificateChainVerifier is a new interface to
decouple callbacks from openssl from a specific dependence on a
OpenSSLSocketImpl.verify_callback method. Changed to return
boolean instead of int.
- Renamed OpenSSLSocketImpl.ssl to OpenSSLSocketImpl.sslNativePointer for consistency
- Changed OpenSSLSocketImpl nativeconnect, nativegetsslsession,
nativecipherauthenticationmethod, nativeaccept, nativeread,
nativewrite, nativeinterrupt, nativeclose, nativefree to take
arguments instead of inspect object state in preparation for
moving to NativeCrypto
- other notable NativeCrypto changes included
* adding SSL_SESSION_get_peer_cert_chain,
SSL_SESSION_get_version, and SSL_get_version (and
get_ssl_version) which are ""missing methods"" in openssl
* ssl_msg_callback_LOG callback and get_content_type for handshake debugging
* removing jfieldID's for our classes now that we pass in values in arguments
* changed aliveAndKicking to be volative since we poll on it to communicate between threads
* changed from C style declarations at beginning of block to C++ at first use on methods with major changes
* stop freeing SSL instances on error, only SSL_clear it
* improved session reuse logging when reproducing b/1678800
* change verify_callback to return verifyCertificateChain result
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketFactoryImpl.java
When we accept a server socket, we pass the existing SSL state
instance from the server socket to the newly accepted socket via
the constructor where it is copied with SSL_dup, instead of
through both the constructor and later the accept method.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
Cleaned up nativesetclientauth from using SSL_CTX to SSL, passing
ssl as argument in preparation for future movement to
NativeCrypto.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
Removed ssl_op_no cache for rarely used enabled protocol methods
so that code could more easily be shared in NativeCrypto between
client and server.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed public getId, getCreationTime, getPeerCertificates,
getCipherSuite, getProtocol from being instance methods that
looked at the OpenSSLSessionImpl object state to be static mthods
that take the native pointers as arguments in preparation for
moving to NativeCrypto. Rename session -> sslSessionNativePointer
for consistency.  Inlined initializeNative, which wasn't really
the native code.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
Removed lock on OpenSSLSocketImpl.class lock from around
OpenSSLSocketImpl's use of nativeconnect, nativegetsslsession, and
nativecipherauthenticationmethod as well as OpenSSLSessionImpl's
use of freeImpl, fixing b/1758225: Revisit OpenSSL locking
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
Unrelated changes
Removed unused ssl_ctx, nativeinitsslctx, getSSLCTX
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParameters.java
Fix bug in both putSession implementations where we cached
sessions with zero length id. Also change indexById to pass in id
in client implementation.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Make sure we clone SSLParameters passed to the SSLSocketFactory
and SSLServerSocketFactory so that muting the client instance does
not change the server instance and vice versa. Explicitly set
setUseClientMode(false) on the server SSLParameters. These changes
are to bring things more into alignment with the original harmony
classes which properly support client/server role switching during
handshaking.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketFactoryImpl.java
Make locks object fields final
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Moved updateInstanceCount(1) logic and sslParameters assignment to init method
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed getCachedClientSession to respect getUseClientMode
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Spelling of listensers to listeners in javadoc
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Spelling SSLInputStream to SSLOutputStream in comment
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed shutdownInput and shutdownOutput to call to the underlying socket
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Set sslNativePointer to 0 when freeing underlying SSL object
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Removed IOException logging in getSession, which is expected to
simply return SSL_NULL_WITH_NULL_NULL when there are problems.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Disabled ""Using factory"" message on successful creation of
SocketFactory which was a bit noisy running tests. However, added
logging in failure case including the related exception:
x-net/src/main/java/javax/net/ssl/SSLSocketFactory.java
Disabled logging of OpenSSL session deallocation
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
Register SSLContextImpl as a source of SSL and SSL3 SSLContexts,
not just TLS and TLSv1.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
Fix whitespace in comment
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/CertificateRequest.java
Change-Id: I99975ae22599c7df0d249fa013ae7ea7c9c08051/"
conscrypt,"Rewrite JSSE code to use one openssl SSL per SSLSocket an one SSL_CTX per SSLSessionContext
Summary:
b/1758225: Revisit OpenSSL locking
Removed the locking original put in to address b/1678800 which
had been causing problems for the HeapWorker thread which was
timing out waiting for the lock in the finalizers while other
threads were connecting.
b/1678800: Reliability tool: Crash in libcrypto @ https://opac.ntu.ac.uk
Properly fixed the native crash by avoid sharing SSL_SESSION objects
between SSL_CTX objects
Testing:
- adb shell run-core-tests --verbose tests.xnet.AllTests
- adb shell run-core-tests --verbose javax.net.ssl.AllTests
- Test app that reloads https://opac.ntu.ac.uk
Details:
Each AbstractSessionContext now has an associated SSL_CTX,
referenced through the sslCtxNativePointer. SSL_CTX on the native
side defines the scope of SSL_SESSION caching, and this brings the
Java SSLSessionContext caching into alignment with the native
code. OpenSSLSessionImpl now uses AbstractSessionContext instead
of SSLSessionContext for access to the underlying SSL_CTX.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParameters.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Added AbstractSessionContext.putSession so OpenSSLSocketImpl/OpenSSLSessionImpl can
directly assign to the current AbstractSessionContext (whether it
be a ClientSessionContext or a ServerSessionContext) without
casting.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Cleaning up use of SSL_CTX and SSL instances in SSLSocket/SSLServerSocket implementation
The major change is that openssl SSL instances are allocated for
the life of the matching Java object, replacing the SSL_CTX and
the SSL objects that had previously been allocated only starting
at handshake time. We should never have been sharing SSL_SESSION
instances between SSL_CTX instances, which was the source of the
native crashes dating back to cupcake which the
OpenSSLSocket.class locking had been preventing.
- NativeCrypto now has better defined and independant wrappers on
openssl functionality. A followon checkin should move the
remaining openssl JNI code here with the intent of being able to
write and end-to-end test of the openssl code using NativeCrypto
without the JSSE implementation classes. The following gives a
list of the new native functions with a mapping to the old
implementation code. The new code has a more functional style
where SSL_CTX and SSL instances are passed and returned as
arguments, not extracted from Java instances
SSL_CTX_new                       OpenSSLSocketImpl.nativeinit, OpenSSLServerSocketImpl.nativeinit, SSLParameters.nativeinitsslctx
SSL_CTX_get_ciphers_list          OpenSSLSocketImpl.nativeGetEnabledCipherSuites
SSL_CTX_free                      OpenSSLSocketImpl.nativefree, OpenSSLServerSocketImpl.nativefree
SSL_new                           OpenSSLSocketImpl.nativeinit, OpenSSLSocketImpl.init, OpenSSLServerSocketImpl.nativeinit, OpenSSLServerSocketImpl.init
SSL_get_options                   OpenSSLSocketImpl.nativesetenabledprotocols
SSL_set_options                   OpenSSLSocketImpl.nativesetenabledprotocols
SSL_get_ciphers                   OpenSSLSocketImpl.nativeGetEnabledCipherSuites
SSL_set_cipher_list               OpenSSLSocketImpl.nativeSetEnabledCipherSuites
SSL_free                          OpenSSLSocketImpl.nativefree, OpenSSLServerSocketImpl.nativefree
- While the focus in NativeCrypto is on native code, it also
contains some helpers/wrappers especially for code that doesn't
depend on specific SSL_CTX, SSL instances or that needs to do
massaging of data formats between Java and OpenSSL. Some of
these had previously been duplicated in the client and server
versions of the code. For example:
getSupportedCipherSuites OpenSSLSocketImpl.nativegetsupportedciphersuites, OpenSSLServerSocketImpl.nativegetsupportedciphersuites
getSupportedProtocols          OpenSSLSocketImpl.getSupportedProtocols, OpenSSLServerSocketImpl.getSupportedProtocols
getEnabledProtocols             OpenSSLSocketImpl.getEnabledProtocols,OpenSSLServerSocketImpl.getEnabledProtocols
setEnabledProtocols             OpenSSLSocketImpl.setEnabledProtocols
setEnabledCipherSuites           OpenSSLSocketImpl.setEnabledCipherSuites
- Moved JNI initialization from OpenSSLSocketImpl to NativeCrypto
which is the future home of all the openssl related native code.
clinit                          OpenSSLSocketImpl.nativeinitstatic
- NativeCrypto.CertificateChainVerifier is a new interface to
decouple callbacks from openssl from a specific dependence on a
OpenSSLSocketImpl.verify_callback method. Changed to return
boolean instead of int.
- Renamed OpenSSLSocketImpl.ssl to OpenSSLSocketImpl.sslNativePointer for consistency
- Changed OpenSSLSocketImpl nativeconnect, nativegetsslsession,
nativecipherauthenticationmethod, nativeaccept, nativeread,
nativewrite, nativeinterrupt, nativeclose, nativefree to take
arguments instead of inspect object state in preparation for
moving to NativeCrypto
- other notable NativeCrypto changes included
* adding SSL_SESSION_get_peer_cert_chain,
SSL_SESSION_get_version, and SSL_get_version (and
get_ssl_version) which are ""missing methods"" in openssl
* ssl_msg_callback_LOG callback and get_content_type for handshake debugging
* removing jfieldID's for our classes now that we pass in values in arguments
* changed aliveAndKicking to be volative since we poll on it to communicate between threads
* changed from C style declarations at beginning of block to C++ at first use on methods with major changes
* stop freeing SSL instances on error, only SSL_clear it
* improved session reuse logging when reproducing b/1678800
* change verify_callback to return verifyCertificateChain result
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketFactoryImpl.java
When we accept a server socket, we pass the existing SSL state
instance from the server socket to the newly accepted socket via
the constructor where it is copied with SSL_dup, instead of
through both the constructor and later the accept method.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
Cleaned up nativesetclientauth from using SSL_CTX to SSL, passing
ssl as argument in preparation for future movement to
NativeCrypto.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
Removed ssl_op_no cache for rarely used enabled protocol methods
so that code could more easily be shared in NativeCrypto between
client and server.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed public getId, getCreationTime, getPeerCertificates,
getCipherSuite, getProtocol from being instance methods that
looked at the OpenSSLSessionImpl object state to be static mthods
that take the native pointers as arguments in preparation for
moving to NativeCrypto. Rename session -> sslSessionNativePointer
for consistency.  Inlined initializeNative, which wasn't really
the native code.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
Removed lock on OpenSSLSocketImpl.class lock from around
OpenSSLSocketImpl's use of nativeconnect, nativegetsslsession, and
nativecipherauthenticationmethod as well as OpenSSLSessionImpl's
use of freeImpl, fixing b/1758225: Revisit OpenSSL locking
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
Unrelated changes
Removed unused ssl_ctx, nativeinitsslctx, getSSLCTX
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParameters.java
Fix bug in both putSession implementations where we cached
sessions with zero length id. Also change indexById to pass in id
in client implementation.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Make sure we clone SSLParameters passed to the SSLSocketFactory
and SSLServerSocketFactory so that muting the client instance does
not change the server instance and vice versa. Explicitly set
setUseClientMode(false) on the server SSLParameters. These changes
are to bring things more into alignment with the original harmony
classes which properly support client/server role switching during
handshaking.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketFactoryImpl.java
Make locks object fields final
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Moved updateInstanceCount(1) logic and sslParameters assignment to init method
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed getCachedClientSession to respect getUseClientMode
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Spelling of listensers to listeners in javadoc
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Spelling SSLInputStream to SSLOutputStream in comment
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed shutdownInput and shutdownOutput to call to the underlying socket
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Set sslNativePointer to 0 when freeing underlying SSL object
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Removed IOException logging in getSession, which is expected to
simply return SSL_NULL_WITH_NULL_NULL when there are problems.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Disabled ""Using factory"" message on successful creation of
SocketFactory which was a bit noisy running tests. However, added
logging in failure case including the related exception:
x-net/src/main/java/javax/net/ssl/SSLSocketFactory.java
Disabled logging of OpenSSL session deallocation
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
Register SSLContextImpl as a source of SSL and SSL3 SSLContexts,
not just TLS and TLSv1.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
Fix whitespace in comment
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/CertificateRequest.java
Change-Id: I99975ae22599c7df0d249fa013ae7ea7c9c08051/"
conscrypt,"Rewrite JSSE code to use one openssl SSL per SSLSocket an one SSL_CTX per SSLSessionContext
Summary:
b/1758225: Revisit OpenSSL locking
Removed the locking original put in to address b/1678800 which
had been causing problems for the HeapWorker thread which was
timing out waiting for the lock in the finalizers while other
threads were connecting.
b/1678800: Reliability tool: Crash in libcrypto @ https://opac.ntu.ac.uk
Properly fixed the native crash by avoid sharing SSL_SESSION objects
between SSL_CTX objects
Testing:
- adb shell run-core-tests --verbose tests.xnet.AllTests
- adb shell run-core-tests --verbose javax.net.ssl.AllTests
- Test app that reloads https://opac.ntu.ac.uk
Details:
Each AbstractSessionContext now has an associated SSL_CTX,
referenced through the sslCtxNativePointer. SSL_CTX on the native
side defines the scope of SSL_SESSION caching, and this brings the
Java SSLSessionContext caching into alignment with the native
code. OpenSSLSessionImpl now uses AbstractSessionContext instead
of SSLSessionContext for access to the underlying SSL_CTX.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParameters.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Added AbstractSessionContext.putSession so OpenSSLSocketImpl/OpenSSLSessionImpl can
directly assign to the current AbstractSessionContext (whether it
be a ClientSessionContext or a ServerSessionContext) without
casting.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Cleaning up use of SSL_CTX and SSL instances in SSLSocket/SSLServerSocket implementation
The major change is that openssl SSL instances are allocated for
the life of the matching Java object, replacing the SSL_CTX and
the SSL objects that had previously been allocated only starting
at handshake time. We should never have been sharing SSL_SESSION
instances between SSL_CTX instances, which was the source of the
native crashes dating back to cupcake which the
OpenSSLSocket.class locking had been preventing.
- NativeCrypto now has better defined and independant wrappers on
openssl functionality. A followon checkin should move the
remaining openssl JNI code here with the intent of being able to
write and end-to-end test of the openssl code using NativeCrypto
without the JSSE implementation classes. The following gives a
list of the new native functions with a mapping to the old
implementation code. The new code has a more functional style
where SSL_CTX and SSL instances are passed and returned as
arguments, not extracted from Java instances
SSL_CTX_new                       OpenSSLSocketImpl.nativeinit, OpenSSLServerSocketImpl.nativeinit, SSLParameters.nativeinitsslctx
SSL_CTX_get_ciphers_list          OpenSSLSocketImpl.nativeGetEnabledCipherSuites
SSL_CTX_free                      OpenSSLSocketImpl.nativefree, OpenSSLServerSocketImpl.nativefree
SSL_new                           OpenSSLSocketImpl.nativeinit, OpenSSLSocketImpl.init, OpenSSLServerSocketImpl.nativeinit, OpenSSLServerSocketImpl.init
SSL_get_options                   OpenSSLSocketImpl.nativesetenabledprotocols
SSL_set_options                   OpenSSLSocketImpl.nativesetenabledprotocols
SSL_get_ciphers                   OpenSSLSocketImpl.nativeGetEnabledCipherSuites
SSL_set_cipher_list               OpenSSLSocketImpl.nativeSetEnabledCipherSuites
SSL_free                          OpenSSLSocketImpl.nativefree, OpenSSLServerSocketImpl.nativefree
- While the focus in NativeCrypto is on native code, it also
contains some helpers/wrappers especially for code that doesn't
depend on specific SSL_CTX, SSL instances or that needs to do
massaging of data formats between Java and OpenSSL. Some of
these had previously been duplicated in the client and server
versions of the code. For example:
getSupportedCipherSuites OpenSSLSocketImpl.nativegetsupportedciphersuites, OpenSSLServerSocketImpl.nativegetsupportedciphersuites
getSupportedProtocols          OpenSSLSocketImpl.getSupportedProtocols, OpenSSLServerSocketImpl.getSupportedProtocols
getEnabledProtocols             OpenSSLSocketImpl.getEnabledProtocols,OpenSSLServerSocketImpl.getEnabledProtocols
setEnabledProtocols             OpenSSLSocketImpl.setEnabledProtocols
setEnabledCipherSuites           OpenSSLSocketImpl.setEnabledCipherSuites
- Moved JNI initialization from OpenSSLSocketImpl to NativeCrypto
which is the future home of all the openssl related native code.
clinit                          OpenSSLSocketImpl.nativeinitstatic
- NativeCrypto.CertificateChainVerifier is a new interface to
decouple callbacks from openssl from a specific dependence on a
OpenSSLSocketImpl.verify_callback method. Changed to return
boolean instead of int.
- Renamed OpenSSLSocketImpl.ssl to OpenSSLSocketImpl.sslNativePointer for consistency
- Changed OpenSSLSocketImpl nativeconnect, nativegetsslsession,
nativecipherauthenticationmethod, nativeaccept, nativeread,
nativewrite, nativeinterrupt, nativeclose, nativefree to take
arguments instead of inspect object state in preparation for
moving to NativeCrypto
- other notable NativeCrypto changes included
* adding SSL_SESSION_get_peer_cert_chain,
SSL_SESSION_get_version, and SSL_get_version (and
get_ssl_version) which are ""missing methods"" in openssl
* ssl_msg_callback_LOG callback and get_content_type for handshake debugging
* removing jfieldID's for our classes now that we pass in values in arguments
* changed aliveAndKicking to be volative since we poll on it to communicate between threads
* changed from C style declarations at beginning of block to C++ at first use on methods with major changes
* stop freeing SSL instances on error, only SSL_clear it
* improved session reuse logging when reproducing b/1678800
* change verify_callback to return verifyCertificateChain result
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketFactoryImpl.java
When we accept a server socket, we pass the existing SSL state
instance from the server socket to the newly accepted socket via
the constructor where it is copied with SSL_dup, instead of
through both the constructor and later the accept method.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
Cleaned up nativesetclientauth from using SSL_CTX to SSL, passing
ssl as argument in preparation for future movement to
NativeCrypto.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
Removed ssl_op_no cache for rarely used enabled protocol methods
so that code could more easily be shared in NativeCrypto between
client and server.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed public getId, getCreationTime, getPeerCertificates,
getCipherSuite, getProtocol from being instance methods that
looked at the OpenSSLSessionImpl object state to be static mthods
that take the native pointers as arguments in preparation for
moving to NativeCrypto. Rename session -> sslSessionNativePointer
for consistency.  Inlined initializeNative, which wasn't really
the native code.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
Removed lock on OpenSSLSocketImpl.class lock from around
OpenSSLSocketImpl's use of nativeconnect, nativegetsslsession, and
nativecipherauthenticationmethod as well as OpenSSLSessionImpl's
use of freeImpl, fixing b/1758225: Revisit OpenSSL locking
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
Unrelated changes
Removed unused ssl_ctx, nativeinitsslctx, getSSLCTX
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParameters.java
Fix bug in both putSession implementations where we cached
sessions with zero length id. Also change indexById to pass in id
in client implementation.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Make sure we clone SSLParameters passed to the SSLSocketFactory
and SSLServerSocketFactory so that muting the client instance does
not change the server instance and vice versa. Explicitly set
setUseClientMode(false) on the server SSLParameters. These changes
are to bring things more into alignment with the original harmony
classes which properly support client/server role switching during
handshaking.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketFactoryImpl.java
Make locks object fields final
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Moved updateInstanceCount(1) logic and sslParameters assignment to init method
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed getCachedClientSession to respect getUseClientMode
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Spelling of listensers to listeners in javadoc
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Spelling SSLInputStream to SSLOutputStream in comment
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed shutdownInput and shutdownOutput to call to the underlying socket
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Set sslNativePointer to 0 when freeing underlying SSL object
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Removed IOException logging in getSession, which is expected to
simply return SSL_NULL_WITH_NULL_NULL when there are problems.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Disabled ""Using factory"" message on successful creation of
SocketFactory which was a bit noisy running tests. However, added
logging in failure case including the related exception:
x-net/src/main/java/javax/net/ssl/SSLSocketFactory.java
Disabled logging of OpenSSL session deallocation
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
Register SSLContextImpl as a source of SSL and SSL3 SSLContexts,
not just TLS and TLSv1.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
Fix whitespace in comment
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/CertificateRequest.java
Change-Id: I99975ae22599c7df0d249fa013ae7ea7c9c08051/Add a setHandshakeTimeout() to OpenSSLSocketImpl, which sets
a read timeout that only applies to the SSL handshake step.
Bug: 2362543/"
conscrypt,"Rewrite JSSE code to use one openssl SSL per SSLSocket an one SSL_CTX per SSLSessionContext
Summary:
b/1758225: Revisit OpenSSL locking
Removed the locking original put in to address b/1678800 which
had been causing problems for the HeapWorker thread which was
timing out waiting for the lock in the finalizers while other
threads were connecting.
b/1678800: Reliability tool: Crash in libcrypto @ https://opac.ntu.ac.uk
Properly fixed the native crash by avoid sharing SSL_SESSION objects
between SSL_CTX objects
Testing:
- adb shell run-core-tests --verbose tests.xnet.AllTests
- adb shell run-core-tests --verbose javax.net.ssl.AllTests
- Test app that reloads https://opac.ntu.ac.uk
Details:
Each AbstractSessionContext now has an associated SSL_CTX,
referenced through the sslCtxNativePointer. SSL_CTX on the native
side defines the scope of SSL_SESSION caching, and this brings the
Java SSLSessionContext caching into alignment with the native
code. OpenSSLSessionImpl now uses AbstractSessionContext instead
of SSLSessionContext for access to the underlying SSL_CTX.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParameters.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Added AbstractSessionContext.putSession so OpenSSLSocketImpl/OpenSSLSessionImpl can
directly assign to the current AbstractSessionContext (whether it
be a ClientSessionContext or a ServerSessionContext) without
casting.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Cleaning up use of SSL_CTX and SSL instances in SSLSocket/SSLServerSocket implementation
The major change is that openssl SSL instances are allocated for
the life of the matching Java object, replacing the SSL_CTX and
the SSL objects that had previously been allocated only starting
at handshake time. We should never have been sharing SSL_SESSION
instances between SSL_CTX instances, which was the source of the
native crashes dating back to cupcake which the
OpenSSLSocket.class locking had been preventing.
- NativeCrypto now has better defined and independant wrappers on
openssl functionality. A followon checkin should move the
remaining openssl JNI code here with the intent of being able to
write and end-to-end test of the openssl code using NativeCrypto
without the JSSE implementation classes. The following gives a
list of the new native functions with a mapping to the old
implementation code. The new code has a more functional style
where SSL_CTX and SSL instances are passed and returned as
arguments, not extracted from Java instances
SSL_CTX_new                       OpenSSLSocketImpl.nativeinit, OpenSSLServerSocketImpl.nativeinit, SSLParameters.nativeinitsslctx
SSL_CTX_get_ciphers_list          OpenSSLSocketImpl.nativeGetEnabledCipherSuites
SSL_CTX_free                      OpenSSLSocketImpl.nativefree, OpenSSLServerSocketImpl.nativefree
SSL_new                           OpenSSLSocketImpl.nativeinit, OpenSSLSocketImpl.init, OpenSSLServerSocketImpl.nativeinit, OpenSSLServerSocketImpl.init
SSL_get_options                   OpenSSLSocketImpl.nativesetenabledprotocols
SSL_set_options                   OpenSSLSocketImpl.nativesetenabledprotocols
SSL_get_ciphers                   OpenSSLSocketImpl.nativeGetEnabledCipherSuites
SSL_set_cipher_list               OpenSSLSocketImpl.nativeSetEnabledCipherSuites
SSL_free                          OpenSSLSocketImpl.nativefree, OpenSSLServerSocketImpl.nativefree
- While the focus in NativeCrypto is on native code, it also
contains some helpers/wrappers especially for code that doesn't
depend on specific SSL_CTX, SSL instances or that needs to do
massaging of data formats between Java and OpenSSL. Some of
these had previously been duplicated in the client and server
versions of the code. For example:
getSupportedCipherSuites OpenSSLSocketImpl.nativegetsupportedciphersuites, OpenSSLServerSocketImpl.nativegetsupportedciphersuites
getSupportedProtocols          OpenSSLSocketImpl.getSupportedProtocols, OpenSSLServerSocketImpl.getSupportedProtocols
getEnabledProtocols             OpenSSLSocketImpl.getEnabledProtocols,OpenSSLServerSocketImpl.getEnabledProtocols
setEnabledProtocols             OpenSSLSocketImpl.setEnabledProtocols
setEnabledCipherSuites           OpenSSLSocketImpl.setEnabledCipherSuites
- Moved JNI initialization from OpenSSLSocketImpl to NativeCrypto
which is the future home of all the openssl related native code.
clinit                          OpenSSLSocketImpl.nativeinitstatic
- NativeCrypto.CertificateChainVerifier is a new interface to
decouple callbacks from openssl from a specific dependence on a
OpenSSLSocketImpl.verify_callback method. Changed to return
boolean instead of int.
- Renamed OpenSSLSocketImpl.ssl to OpenSSLSocketImpl.sslNativePointer for consistency
- Changed OpenSSLSocketImpl nativeconnect, nativegetsslsession,
nativecipherauthenticationmethod, nativeaccept, nativeread,
nativewrite, nativeinterrupt, nativeclose, nativefree to take
arguments instead of inspect object state in preparation for
moving to NativeCrypto
- other notable NativeCrypto changes included
* adding SSL_SESSION_get_peer_cert_chain,
SSL_SESSION_get_version, and SSL_get_version (and
get_ssl_version) which are ""missing methods"" in openssl
* ssl_msg_callback_LOG callback and get_content_type for handshake debugging
* removing jfieldID's for our classes now that we pass in values in arguments
* changed aliveAndKicking to be volative since we poll on it to communicate between threads
* changed from C style declarations at beginning of block to C++ at first use on methods with major changes
* stop freeing SSL instances on error, only SSL_clear it
* improved session reuse logging when reproducing b/1678800
* change verify_callback to return verifyCertificateChain result
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketFactoryImpl.java
When we accept a server socket, we pass the existing SSL state
instance from the server socket to the newly accepted socket via
the constructor where it is copied with SSL_dup, instead of
through both the constructor and later the accept method.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
Cleaned up nativesetclientauth from using SSL_CTX to SSL, passing
ssl as argument in preparation for future movement to
NativeCrypto.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
Removed ssl_op_no cache for rarely used enabled protocol methods
so that code could more easily be shared in NativeCrypto between
client and server.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed public getId, getCreationTime, getPeerCertificates,
getCipherSuite, getProtocol from being instance methods that
looked at the OpenSSLSessionImpl object state to be static mthods
that take the native pointers as arguments in preparation for
moving to NativeCrypto. Rename session -> sslSessionNativePointer
for consistency.  Inlined initializeNative, which wasn't really
the native code.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
Removed lock on OpenSSLSocketImpl.class lock from around
OpenSSLSocketImpl's use of nativeconnect, nativegetsslsession, and
nativecipherauthenticationmethod as well as OpenSSLSessionImpl's
use of freeImpl, fixing b/1758225: Revisit OpenSSL locking
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
Unrelated changes
Removed unused ssl_ctx, nativeinitsslctx, getSSLCTX
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParameters.java
Fix bug in both putSession implementations where we cached
sessions with zero length id. Also change indexById to pass in id
in client implementation.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
Make sure we clone SSLParameters passed to the SSLSocketFactory
and SSLServerSocketFactory so that muting the client instance does
not change the server instance and vice versa. Explicitly set
setUseClientMode(false) on the server SSLParameters. These changes
are to bring things more into alignment with the original harmony
classes which properly support client/server role switching during
handshaking.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketFactoryImpl.java
Make locks object fields final
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Moved updateInstanceCount(1) logic and sslParameters assignment to init method
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed getCachedClientSession to respect getUseClientMode
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Spelling of listensers to listeners in javadoc
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Spelling SSLInputStream to SSLOutputStream in comment
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Changed shutdownInput and shutdownOutput to call to the underlying socket
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Set sslNativePointer to 0 when freeing underlying SSL object
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Removed IOException logging in getSession, which is expected to
simply return SSL_NULL_WITH_NULL_NULL when there are problems.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Disabled ""Using factory"" message on successful creation of
SocketFactory which was a bit noisy running tests. However, added
logging in failure case including the related exception:
x-net/src/main/java/javax/net/ssl/SSLSocketFactory.java
Disabled logging of OpenSSL session deallocation
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
Register SSLContextImpl as a source of SSL and SSL3 SSLContexts,
not just TLS and TLSv1.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
Fix whitespace in comment
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/CertificateRequest.java
Change-Id: I99975ae22599c7df0d249fa013ae7ea7c9c08051/"
conscrypt,"OpenSSLSocket handshake overhaul
Summary:
- SSLSocket.startHandshake now generalized to handle both client and
server handshaking as well as client/server role reversal
- handshake_cutthrough.patch is properly integrated with support
delayed handshake completion now integrated with delayed updates to
session cache and callbacks to HandshakeCompletedListeners
- Many fixes to SSLSession, which is the end product of the handshake
- Generally more RI and SSLEngine compliant behavior.
- More native code deletion through unification of client/server
handshake, unification of client/server certificate chain
verification, etc. More native code moved from various OpenSSL
classes to cleaner NativeCrypto interfaces that more directly mirror
the OpenSSL interfaces.
Details:
Delay SSL_new call until handshake time when we know for sure whether
the OpenSSLSocket will be used in client or server mode and we can
allocate the SSL_new from the apppriate client or server SSL_CTX used
for session caching.
Now that no SSL is allocated for an OpenSSLServerSocketImpl,
store enabledProtocols and enabledCipherSuites in instance String
arrays. Use new NativeCrypto.checkEnabled* methdods for argument
validation. OpenSSLServerSocketImpl passes these enabled arrays to
a new OpenSSLSocket constructor during accept(). Removed finalizer
from OpenSSLServerSocketImpl since it no longer has any native
storage and socket is already closed by PlainSocketImpl finalizer.
X-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
OpenSSLSocket major overhaul to properly implement handshaking
including switching client and server roles and session ID caching
with handshake_cutthrough.patch.
- now implements NativeCrypto.HandshakeCompletedListeners for
properly timed callback when handshake_cutthrough.patch delays
handshake completion until first SSLSocket.getInputStream()
read.
- similar enabledProtocols/enabledCipherSuites changes as
OpenSSLServerSocketImpl since we need to store the state
somewhere other than an openssl SSL struct until we are sure if
we are doing a client or server handshake.
- added handshake completed field so that startHandshake can tell
if handshake was completed during SSL_do_handshake or will be
completed later by a call to HandshakeCompletedCallback.handshakeCompleted.
- removed nativegetsession as the equivalent value is now returned by SSL_do_handshake
- removed nativecipherauthenticationmethod as the value is now passed to verifyCertificateChain
- startHandshake is now a wrapper that forces a fully synchronous handshake
- startHandshake(boolean) is the the most changed method in this
changelist, combinding both the old startHandshake logic, but
also the OpenSSLSocketImpl.accept code as well. Notable
differences from the old code:
* now responsible for SSL_new
* single code path for client/server handshaking dealing with SSLSession caching
* now handles server certificate requests previously in
OpenSSLServerSocketImpl, since a client can request to act
like a server and therefore need to be able to make suck
demands on its peer.
* supports turning off handshake_cutthrough at a callers request
via explicit call to startHandshake()
* certificate verification happens during an upcall from openssl
during SSL_do_handshake to verifyCertificateChain for both
client and server cases. previously there was not quite right
upcall support on the server side and post-handshake checking
on the client, which did not allow for a proper alert to be
sent to the peer informing them of the issue, which the RI and
SSLEngine code do.
* Similarly, setEnableSessionCreation(false) did not send an
alert to the peer as the RI and SSLEngine code in the client
case. In the server case, nothing was previously done.
* The use of local certificates was not determined from
introspecting the SSL struct post-handshake. This is now
partially implemented and will be completed in a later change.
- SSLSocket.{shutdownInput,shutdownOutput} are now restored to the
proper behavior of throwing UnsupportedOperationException.
- Gutted OpenSSLSocketImpl finalizer. The comment explains in
detail the trouble of having the finalizer do anything more than
touch its the instances own state due to unpredictable order of
finalization and the future possability of parallel
finalization.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
SSLSession fixes
- Made OpenSSLSessionImpl.sessionContext non-final so it could be
nulled by SSLSession.invalidate to match RI behavior.
- As noted in AbstractSessionContext discussion, removed
OpenSSLSessionImpl constructor that took SSLParameters, instead
we take the possibly null localCertificates
directly. OpenSSLSessionImpl.getLocalCertificates now simply
returns the localCertificates member variable instead of
incorrectly trying to query the KeyManager for certificates that
may not have been used.
- OpenSSLSessionImpl now caches its native ID to avoid numerious
native calls but also now provides as resetId which will update
the cache when a delayed handshake happens due to the
handshake_cutthrough.patch
- Fixed bug in getPeerPrincipal that it wasn't calling
getPeerCertificates to initialize peerCertificates field.
- freeImpl is now 'public static' in preparation for move to NativeCrypto.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
The old SSLSessionImpl class that is still used for representing
the invalid session now returns
isValid => false
and
getProtocol => ""NONE""
to match the RI.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionImpl.java
NativeCrypto improvements
- Adding NativeCrypto.SSL_{get,set,clear}_mode similar to
NativeCrypto.SSL_{get,set,clear}_options along with
SSL_MODE_HANDSHAKE_CUTTHROUGH constant which is used to
explicitly disable/enable the Android handshake_cutthrough.patch
behavior.
- Added missing NativeCrypto.SSL_clear_options and used to properly
implement NativeCrypto.setEnabledProtocols.
- Added NativeCrypto.checkEnabledProtocols and
NativeCrypto.checkEnabledCipherSuites helpers to implement
exception compatability with the RI. While some of this code is
refactored from existing NativeCrypto code, it is now also used
by OpenSSLServerSocketImpl and OpenSSLSocketImpl which maintain
their own String[]s of what is enabled until startHandshake time. (see below)
- Changed NativeCrypto.findSuite to use foreach style loop for clarity.
- Moved OpenSSLServerSocketImpl nativesetclientauth and
SSL_VERIFY_* constants to NativeCrypto.SSL_set_verify
- Added NativeCrypto.SSL_set_session based on part of old OpenSSLSocketImpl.nativeconnect
- Added NativeCrypto.SSL_set_session_creation_enabled to properly implement
SSLSocket.setEnableSessionCreation(false) which uses new
external/openssl/patches/jsse.patch functionality.
- New NativeCrypto.SSL_do_handshake consolidates
OpenSSLSocketImpl.{nativeconnect, nativeaccept} while properly
implementing SSLSocket.setUseClientMode(false) for clients and
SSLSocket.setUseClientMode(true) for servers.
- New NativeCrypto.SSL_get_certificate is determine if local
certificate requested by peer. While functional, currently
NativeCrypto.SSL_new always sets a value via SSL_use_certificate
instead of relying on a callback set via SSL_CTX_set_client_cert_cb.
- Changed NativeCrypto.CertificateChainVerifier.verifyCertificateChain
to throw a checked CertificateException to match TrustManager.{checkServerTrusted,
checkClientTrusted}. It also takes an authMethod so avoid the need to call
the old OpenSSLSocketImpl.nativecipherauthenticationmethod.
- Added NativeCrypto.HandshakeCompletedCallback which has its
handshakeCompleted method called from OpenSSL when the now
delayed handshake_cutthrough.patch handshake is completed so
SSLSession caching can be delayed until a session ID is available
and to provide a better time for HandshakeCompletedListeners to
be notified.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
Some other changes specific to the naitve side of the code
- Added JNITRACE calls (enabled at compile time with JNI_TRACE)
for future debugging.
- throw SSLException subclass of IOException instead IOException
itself for better RI compatability
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
- changed from old struct app_data to new class AppData at enh's request
Remove dubious usage of SSLParameters within AbstractSessionContext
to pass through to OpenSSLSessionImpl constructor for use in
calling getLocalCertificates for sessions created from a byte array
with AbstractSessionContext.toSession. Our
AbstractSessionContext.toBytes doesn't currently include the local
certificates in its output, so it cannot be expected to have in toSession.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParameters.java
Test maintenance
openssl 1.0.0 adds support for RFC 4507 session tickets which
remove the need for server side session state. These tests needed
to be updated for this new behavior. If IS_RI is true, they still
follow the old behavior.
luni/src/test/java/javax/net/ssl/SSLSessionContextTest.java
luni/src/test/java/javax/net/ssl/SSLSessionTest.java
luni/src/test/java/javax/net/ssl/SSLSocketTest.java
Update KnownFailures and add specific comments at point of failure
about what remains to be fixed.
luni/src/test/java/javax/net/ssl/SSLSessionTest.java
Added tests to cover the use of standard cipher suite
names. Historically Android has used OpenSSL string constants for
cipher suite names, but JSSE actually specifies supported and
expected names.
luni/src/test/java/javax/net/ssl/SSLSocketFactoryTest.java
luni/src/test/java/javax/net/ssl/SSLSocketTest.java
Create new support/src/test/java/javax/net/ssl with old Helper
support code pulled from javax.net.ssl tests:
SSLContextTest.Helper -> TestSSLContext
SSLSocketTest.Helper -> TestSSLSocketPair
SSLSessionTest.Helper -> TestSSLSessions
Also added new StandardNames here, which contains a collection of
expected constants for test validation.
luni/src/test/java/javax/net/ssl/SSLContextTest.java
luni/src/test/java/javax/net/ssl/SSLSocketTest.java
luni/src/test/java/javax/net/ssl/SSLSessionTest.java
support/src/test/java/javax/net/ssl/TestSSLContext.java
support/src/test/java/javax/net/ssl/TestSSLSocketPair.java
support/src/test/java/javax/net/ssl/TestSSLSessions.java
support/src/test/java/javax/net/ssl/StandardNames.java
Removed some now fixed KnownFailures and unneeded !IS_RI
code. Marked some [Un]KnownFailures where exceptions are thrown
and visible in the output but aren't correctly causing the test to
fail. Fixed assertNonNull to assertTrue in
test_SSLSocketTest_Test_create. Added
stress_test_SSLSocketTest_Test_create to track down test
flakiness, leading to rewrite of SSLSocket finalization.
luni/src/test/java/javax/net/ssl/SSLSocketTest.java
Reenable javax.net.ssl.AllTests now that it is does not hang
luni/src/test/java/tests/AllTests.java
Improve error messages while debugging overflow problem.
Added new assert when debugging new RFC 4507 behavior.
Removed KnownFailure annotation for now working test case.
x-net/src/test/java/tests/api/javax/net/ssl/SSLSessionTest.java
Client code changes
Now that startHandshake implies synchronous vs Android's default async handshake, remove unneeded explict calls to SSLSocket.startHandshake
luni/src/main/java/org/apache/harmony/luni/internal/net/www/protocol/http/HttpConnection.java
Removed IBM 1.4.x codepath that involved startHandshake
x-net/src/main/java/javax/net/ssl/DefaultHostnameVerifier.java
Unrelated
Remove unneed SSLSocket.setUseClientMode while removing unneeded SSLSocket.startHandshake
luni/src/main/java/org/apache/harmony/luni/internal/net/www/protocol/http/HttpConnection.java
Removed warnings due to now missing modules in classpath
run-core-tests
Change-Id: I6e149ae259b3feccdfb0673209c85cfeb60befc8/"
conscrypt,"OpenSSLSocket handshake overhaul
Summary:
- SSLSocket.startHandshake now generalized to handle both client and
server handshaking as well as client/server role reversal
- handshake_cutthrough.patch is properly integrated with support
delayed handshake completion now integrated with delayed updates to
session cache and callbacks to HandshakeCompletedListeners
- Many fixes to SSLSession, which is the end product of the handshake
- Generally more RI and SSLEngine compliant behavior.
- More native code deletion through unification of client/server
handshake, unification of client/server certificate chain
verification, etc. More native code moved from various OpenSSL
classes to cleaner NativeCrypto interfaces that more directly mirror
the OpenSSL interfaces.
Details:
Delay SSL_new call until handshake time when we know for sure whether
the OpenSSLSocket will be used in client or server mode and we can
allocate the SSL_new from the apppriate client or server SSL_CTX used
for session caching.
Now that no SSL is allocated for an OpenSSLServerSocketImpl,
store enabledProtocols and enabledCipherSuites in instance String
arrays. Use new NativeCrypto.checkEnabled* methdods for argument
validation. OpenSSLServerSocketImpl passes these enabled arrays to
a new OpenSSLSocket constructor during accept(). Removed finalizer
from OpenSSLServerSocketImpl since it no longer has any native
storage and socket is already closed by PlainSocketImpl finalizer.
X-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
OpenSSLSocket major overhaul to properly implement handshaking
including switching client and server roles and session ID caching
with handshake_cutthrough.patch.
- now implements NativeCrypto.HandshakeCompletedListeners for
properly timed callback when handshake_cutthrough.patch delays
handshake completion until first SSLSocket.getInputStream()
read.
- similar enabledProtocols/enabledCipherSuites changes as
OpenSSLServerSocketImpl since we need to store the state
somewhere other than an openssl SSL struct until we are sure if
we are doing a client or server handshake.
- added handshake completed field so that startHandshake can tell
if handshake was completed during SSL_do_handshake or will be
completed later by a call to HandshakeCompletedCallback.handshakeCompleted.
- removed nativegetsession as the equivalent value is now returned by SSL_do_handshake
- removed nativecipherauthenticationmethod as the value is now passed to verifyCertificateChain
- startHandshake is now a wrapper that forces a fully synchronous handshake
- startHandshake(boolean) is the the most changed method in this
changelist, combinding both the old startHandshake logic, but
also the OpenSSLSocketImpl.accept code as well. Notable
differences from the old code:
* now responsible for SSL_new
* single code path for client/server handshaking dealing with SSLSession caching
* now handles server certificate requests previously in
OpenSSLServerSocketImpl, since a client can request to act
like a server and therefore need to be able to make suck
demands on its peer.
* supports turning off handshake_cutthrough at a callers request
via explicit call to startHandshake()
* certificate verification happens during an upcall from openssl
during SSL_do_handshake to verifyCertificateChain for both
client and server cases. previously there was not quite right
upcall support on the server side and post-handshake checking
on the client, which did not allow for a proper alert to be
sent to the peer informing them of the issue, which the RI and
SSLEngine code do.
* Similarly, setEnableSessionCreation(false) did not send an
alert to the peer as the RI and SSLEngine code in the client
case. In the server case, nothing was previously done.
* The use of local certificates was not determined from
introspecting the SSL struct post-handshake. This is now
partially implemented and will be completed in a later change.
- SSLSocket.{shutdownInput,shutdownOutput} are now restored to the
proper behavior of throwing UnsupportedOperationException.
- Gutted OpenSSLSocketImpl finalizer. The comment explains in
detail the trouble of having the finalizer do anything more than
touch its the instances own state due to unpredictable order of
finalization and the future possability of parallel
finalization.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
SSLSession fixes
- Made OpenSSLSessionImpl.sessionContext non-final so it could be
nulled by SSLSession.invalidate to match RI behavior.
- As noted in AbstractSessionContext discussion, removed
OpenSSLSessionImpl constructor that took SSLParameters, instead
we take the possibly null localCertificates
directly. OpenSSLSessionImpl.getLocalCertificates now simply
returns the localCertificates member variable instead of
incorrectly trying to query the KeyManager for certificates that
may not have been used.
- OpenSSLSessionImpl now caches its native ID to avoid numerious
native calls but also now provides as resetId which will update
the cache when a delayed handshake happens due to the
handshake_cutthrough.patch
- Fixed bug in getPeerPrincipal that it wasn't calling
getPeerCertificates to initialize peerCertificates field.
- freeImpl is now 'public static' in preparation for move to NativeCrypto.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
The old SSLSessionImpl class that is still used for representing
the invalid session now returns
isValid => false
and
getProtocol => ""NONE""
to match the RI.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionImpl.java
NativeCrypto improvements
- Adding NativeCrypto.SSL_{get,set,clear}_mode similar to
NativeCrypto.SSL_{get,set,clear}_options along with
SSL_MODE_HANDSHAKE_CUTTHROUGH constant which is used to
explicitly disable/enable the Android handshake_cutthrough.patch
behavior.
- Added missing NativeCrypto.SSL_clear_options and used to properly
implement NativeCrypto.setEnabledProtocols.
- Added NativeCrypto.checkEnabledProtocols and
NativeCrypto.checkEnabledCipherSuites helpers to implement
exception compatability with the RI. While some of this code is
refactored from existing NativeCrypto code, it is now also used
by OpenSSLServerSocketImpl and OpenSSLSocketImpl which maintain
their own String[]s of what is enabled until startHandshake time. (see below)
- Changed NativeCrypto.findSuite to use foreach style loop for clarity.
- Moved OpenSSLServerSocketImpl nativesetclientauth and
SSL_VERIFY_* constants to NativeCrypto.SSL_set_verify
- Added NativeCrypto.SSL_set_session based on part of old OpenSSLSocketImpl.nativeconnect
- Added NativeCrypto.SSL_set_session_creation_enabled to properly implement
SSLSocket.setEnableSessionCreation(false) which uses new
external/openssl/patches/jsse.patch functionality.
- New NativeCrypto.SSL_do_handshake consolidates
OpenSSLSocketImpl.{nativeconnect, nativeaccept} while properly
implementing SSLSocket.setUseClientMode(false) for clients and
SSLSocket.setUseClientMode(true) for servers.
- New NativeCrypto.SSL_get_certificate is determine if local
certificate requested by peer. While functional, currently
NativeCrypto.SSL_new always sets a value via SSL_use_certificate
instead of relying on a callback set via SSL_CTX_set_client_cert_cb.
- Changed NativeCrypto.CertificateChainVerifier.verifyCertificateChain
to throw a checked CertificateException to match TrustManager.{checkServerTrusted,
checkClientTrusted}. It also takes an authMethod so avoid the need to call
the old OpenSSLSocketImpl.nativecipherauthenticationmethod.
- Added NativeCrypto.HandshakeCompletedCallback which has its
handshakeCompleted method called from OpenSSL when the now
delayed handshake_cutthrough.patch handshake is completed so
SSLSession caching can be delayed until a session ID is available
and to provide a better time for HandshakeCompletedListeners to
be notified.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
Some other changes specific to the naitve side of the code
- Added JNITRACE calls (enabled at compile time with JNI_TRACE)
for future debugging.
- throw SSLException subclass of IOException instead IOException
itself for better RI compatability
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
- changed from old struct app_data to new class AppData at enh's request
Remove dubious usage of SSLParameters within AbstractSessionContext
to pass through to OpenSSLSessionImpl constructor for use in
calling getLocalCertificates for sessions created from a byte array
with AbstractSessionContext.toSession. Our
AbstractSessionContext.toBytes doesn't currently include the local
certificates in its output, so it cannot be expected to have in toSession.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParameters.java
Test maintenance
openssl 1.0.0 adds support for RFC 4507 session tickets which
remove the need for server side session state. These tests needed
to be updated for this new behavior. If IS_RI is true, they still
follow the old behavior.
luni/src/test/java/javax/net/ssl/SSLSessionContextTest.java
luni/src/test/java/javax/net/ssl/SSLSessionTest.java
luni/src/test/java/javax/net/ssl/SSLSocketTest.java
Update KnownFailures and add specific comments at point of failure
about what remains to be fixed.
luni/src/test/java/javax/net/ssl/SSLSessionTest.java
Added tests to cover the use of standard cipher suite
names. Historically Android has used OpenSSL string constants for
cipher suite names, but JSSE actually specifies supported and
expected names.
luni/src/test/java/javax/net/ssl/SSLSocketFactoryTest.java
luni/src/test/java/javax/net/ssl/SSLSocketTest.java
Create new support/src/test/java/javax/net/ssl with old Helper
support code pulled from javax.net.ssl tests:
SSLContextTest.Helper -> TestSSLContext
SSLSocketTest.Helper -> TestSSLSocketPair
SSLSessionTest.Helper -> TestSSLSessions
Also added new StandardNames here, which contains a collection of
expected constants for test validation.
luni/src/test/java/javax/net/ssl/SSLContextTest.java
luni/src/test/java/javax/net/ssl/SSLSocketTest.java
luni/src/test/java/javax/net/ssl/SSLSessionTest.java
support/src/test/java/javax/net/ssl/TestSSLContext.java
support/src/test/java/javax/net/ssl/TestSSLSocketPair.java
support/src/test/java/javax/net/ssl/TestSSLSessions.java
support/src/test/java/javax/net/ssl/StandardNames.java
Removed some now fixed KnownFailures and unneeded !IS_RI
code. Marked some [Un]KnownFailures where exceptions are thrown
and visible in the output but aren't correctly causing the test to
fail. Fixed assertNonNull to assertTrue in
test_SSLSocketTest_Test_create. Added
stress_test_SSLSocketTest_Test_create to track down test
flakiness, leading to rewrite of SSLSocket finalization.
luni/src/test/java/javax/net/ssl/SSLSocketTest.java
Reenable javax.net.ssl.AllTests now that it is does not hang
luni/src/test/java/tests/AllTests.java
Improve error messages while debugging overflow problem.
Added new assert when debugging new RFC 4507 behavior.
Removed KnownFailure annotation for now working test case.
x-net/src/test/java/tests/api/javax/net/ssl/SSLSessionTest.java
Client code changes
Now that startHandshake implies synchronous vs Android's default async handshake, remove unneeded explict calls to SSLSocket.startHandshake
luni/src/main/java/org/apache/harmony/luni/internal/net/www/protocol/http/HttpConnection.java
Removed IBM 1.4.x codepath that involved startHandshake
x-net/src/main/java/javax/net/ssl/DefaultHostnameVerifier.java
Unrelated
Remove unneed SSLSocket.setUseClientMode while removing unneeded SSLSocket.startHandshake
luni/src/main/java/org/apache/harmony/luni/internal/net/www/protocol/http/HttpConnection.java
Removed warnings due to now missing modules in classpath
run-core-tests
Change-Id: I6e149ae259b3feccdfb0673209c85cfeb60befc8/"
conscrypt,"OpenSSLSocket handshake overhaul
Summary:
- SSLSocket.startHandshake now generalized to handle both client and
server handshaking as well as client/server role reversal
- handshake_cutthrough.patch is properly integrated with support
delayed handshake completion now integrated with delayed updates to
session cache and callbacks to HandshakeCompletedListeners
- Many fixes to SSLSession, which is the end product of the handshake
- Generally more RI and SSLEngine compliant behavior.
- More native code deletion through unification of client/server
handshake, unification of client/server certificate chain
verification, etc. More native code moved from various OpenSSL
classes to cleaner NativeCrypto interfaces that more directly mirror
the OpenSSL interfaces.
Details:
Delay SSL_new call until handshake time when we know for sure whether
the OpenSSLSocket will be used in client or server mode and we can
allocate the SSL_new from the apppriate client or server SSL_CTX used
for session caching.
Now that no SSL is allocated for an OpenSSLServerSocketImpl,
store enabledProtocols and enabledCipherSuites in instance String
arrays. Use new NativeCrypto.checkEnabled* methdods for argument
validation. OpenSSLServerSocketImpl passes these enabled arrays to
a new OpenSSLSocket constructor during accept(). Removed finalizer
from OpenSSLServerSocketImpl since it no longer has any native
storage and socket is already closed by PlainSocketImpl finalizer.
X-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
OpenSSLSocket major overhaul to properly implement handshaking
including switching client and server roles and session ID caching
with handshake_cutthrough.patch.
- now implements NativeCrypto.HandshakeCompletedListeners for
properly timed callback when handshake_cutthrough.patch delays
handshake completion until first SSLSocket.getInputStream()
read.
- similar enabledProtocols/enabledCipherSuites changes as
OpenSSLServerSocketImpl since we need to store the state
somewhere other than an openssl SSL struct until we are sure if
we are doing a client or server handshake.
- added handshake completed field so that startHandshake can tell
if handshake was completed during SSL_do_handshake or will be
completed later by a call to HandshakeCompletedCallback.handshakeCompleted.
- removed nativegetsession as the equivalent value is now returned by SSL_do_handshake
- removed nativecipherauthenticationmethod as the value is now passed to verifyCertificateChain
- startHandshake is now a wrapper that forces a fully synchronous handshake
- startHandshake(boolean) is the the most changed method in this
changelist, combinding both the old startHandshake logic, but
also the OpenSSLSocketImpl.accept code as well. Notable
differences from the old code:
* now responsible for SSL_new
* single code path for client/server handshaking dealing with SSLSession caching
* now handles server certificate requests previously in
OpenSSLServerSocketImpl, since a client can request to act
like a server and therefore need to be able to make suck
demands on its peer.
* supports turning off handshake_cutthrough at a callers request
via explicit call to startHandshake()
* certificate verification happens during an upcall from openssl
during SSL_do_handshake to verifyCertificateChain for both
client and server cases. previously there was not quite right
upcall support on the server side and post-handshake checking
on the client, which did not allow for a proper alert to be
sent to the peer informing them of the issue, which the RI and
SSLEngine code do.
* Similarly, setEnableSessionCreation(false) did not send an
alert to the peer as the RI and SSLEngine code in the client
case. In the server case, nothing was previously done.
* The use of local certificates was not determined from
introspecting the SSL struct post-handshake. This is now
partially implemented and will be completed in a later change.
- SSLSocket.{shutdownInput,shutdownOutput} are now restored to the
proper behavior of throwing UnsupportedOperationException.
- Gutted OpenSSLSocketImpl finalizer. The comment explains in
detail the trouble of having the finalizer do anything more than
touch its the instances own state due to unpredictable order of
finalization and the future possability of parallel
finalization.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
SSLSession fixes
- Made OpenSSLSessionImpl.sessionContext non-final so it could be
nulled by SSLSession.invalidate to match RI behavior.
- As noted in AbstractSessionContext discussion, removed
OpenSSLSessionImpl constructor that took SSLParameters, instead
we take the possibly null localCertificates
directly. OpenSSLSessionImpl.getLocalCertificates now simply
returns the localCertificates member variable instead of
incorrectly trying to query the KeyManager for certificates that
may not have been used.
- OpenSSLSessionImpl now caches its native ID to avoid numerious
native calls but also now provides as resetId which will update
the cache when a delayed handshake happens due to the
handshake_cutthrough.patch
- Fixed bug in getPeerPrincipal that it wasn't calling
getPeerCertificates to initialize peerCertificates field.
- freeImpl is now 'public static' in preparation for move to NativeCrypto.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
The old SSLSessionImpl class that is still used for representing
the invalid session now returns
isValid => false
and
getProtocol => ""NONE""
to match the RI.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionImpl.java
NativeCrypto improvements
- Adding NativeCrypto.SSL_{get,set,clear}_mode similar to
NativeCrypto.SSL_{get,set,clear}_options along with
SSL_MODE_HANDSHAKE_CUTTHROUGH constant which is used to
explicitly disable/enable the Android handshake_cutthrough.patch
behavior.
- Added missing NativeCrypto.SSL_clear_options and used to properly
implement NativeCrypto.setEnabledProtocols.
- Added NativeCrypto.checkEnabledProtocols and
NativeCrypto.checkEnabledCipherSuites helpers to implement
exception compatability with the RI. While some of this code is
refactored from existing NativeCrypto code, it is now also used
by OpenSSLServerSocketImpl and OpenSSLSocketImpl which maintain
their own String[]s of what is enabled until startHandshake time. (see below)
- Changed NativeCrypto.findSuite to use foreach style loop for clarity.
- Moved OpenSSLServerSocketImpl nativesetclientauth and
SSL_VERIFY_* constants to NativeCrypto.SSL_set_verify
- Added NativeCrypto.SSL_set_session based on part of old OpenSSLSocketImpl.nativeconnect
- Added NativeCrypto.SSL_set_session_creation_enabled to properly implement
SSLSocket.setEnableSessionCreation(false) which uses new
external/openssl/patches/jsse.patch functionality.
- New NativeCrypto.SSL_do_handshake consolidates
OpenSSLSocketImpl.{nativeconnect, nativeaccept} while properly
implementing SSLSocket.setUseClientMode(false) for clients and
SSLSocket.setUseClientMode(true) for servers.
- New NativeCrypto.SSL_get_certificate is determine if local
certificate requested by peer. While functional, currently
NativeCrypto.SSL_new always sets a value via SSL_use_certificate
instead of relying on a callback set via SSL_CTX_set_client_cert_cb.
- Changed NativeCrypto.CertificateChainVerifier.verifyCertificateChain
to throw a checked CertificateException to match TrustManager.{checkServerTrusted,
checkClientTrusted}. It also takes an authMethod so avoid the need to call
the old OpenSSLSocketImpl.nativecipherauthenticationmethod.
- Added NativeCrypto.HandshakeCompletedCallback which has its
handshakeCompleted method called from OpenSSL when the now
delayed handshake_cutthrough.patch handshake is completed so
SSLSession caching can be delayed until a session ID is available
and to provide a better time for HandshakeCompletedListeners to
be notified.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
Some other changes specific to the naitve side of the code
- Added JNITRACE calls (enabled at compile time with JNI_TRACE)
for future debugging.
- throw SSLException subclass of IOException instead IOException
itself for better RI compatability
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
- changed from old struct app_data to new class AppData at enh's request
Remove dubious usage of SSLParameters within AbstractSessionContext
to pass through to OpenSSLSessionImpl constructor for use in
calling getLocalCertificates for sessions created from a byte array
with AbstractSessionContext.toSession. Our
AbstractSessionContext.toBytes doesn't currently include the local
certificates in its output, so it cannot be expected to have in toSession.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParameters.java
Test maintenance
openssl 1.0.0 adds support for RFC 4507 session tickets which
remove the need for server side session state. These tests needed
to be updated for this new behavior. If IS_RI is true, they still
follow the old behavior.
luni/src/test/java/javax/net/ssl/SSLSessionContextTest.java
luni/src/test/java/javax/net/ssl/SSLSessionTest.java
luni/src/test/java/javax/net/ssl/SSLSocketTest.java
Update KnownFailures and add specific comments at point of failure
about what remains to be fixed.
luni/src/test/java/javax/net/ssl/SSLSessionTest.java
Added tests to cover the use of standard cipher suite
names. Historically Android has used OpenSSL string constants for
cipher suite names, but JSSE actually specifies supported and
expected names.
luni/src/test/java/javax/net/ssl/SSLSocketFactoryTest.java
luni/src/test/java/javax/net/ssl/SSLSocketTest.java
Create new support/src/test/java/javax/net/ssl with old Helper
support code pulled from javax.net.ssl tests:
SSLContextTest.Helper -> TestSSLContext
SSLSocketTest.Helper -> TestSSLSocketPair
SSLSessionTest.Helper -> TestSSLSessions
Also added new StandardNames here, which contains a collection of
expected constants for test validation.
luni/src/test/java/javax/net/ssl/SSLContextTest.java
luni/src/test/java/javax/net/ssl/SSLSocketTest.java
luni/src/test/java/javax/net/ssl/SSLSessionTest.java
support/src/test/java/javax/net/ssl/TestSSLContext.java
support/src/test/java/javax/net/ssl/TestSSLSocketPair.java
support/src/test/java/javax/net/ssl/TestSSLSessions.java
support/src/test/java/javax/net/ssl/StandardNames.java
Removed some now fixed KnownFailures and unneeded !IS_RI
code. Marked some [Un]KnownFailures where exceptions are thrown
and visible in the output but aren't correctly causing the test to
fail. Fixed assertNonNull to assertTrue in
test_SSLSocketTest_Test_create. Added
stress_test_SSLSocketTest_Test_create to track down test
flakiness, leading to rewrite of SSLSocket finalization.
luni/src/test/java/javax/net/ssl/SSLSocketTest.java
Reenable javax.net.ssl.AllTests now that it is does not hang
luni/src/test/java/tests/AllTests.java
Improve error messages while debugging overflow problem.
Added new assert when debugging new RFC 4507 behavior.
Removed KnownFailure annotation for now working test case.
x-net/src/test/java/tests/api/javax/net/ssl/SSLSessionTest.java
Client code changes
Now that startHandshake implies synchronous vs Android's default async handshake, remove unneeded explict calls to SSLSocket.startHandshake
luni/src/main/java/org/apache/harmony/luni/internal/net/www/protocol/http/HttpConnection.java
Removed IBM 1.4.x codepath that involved startHandshake
x-net/src/main/java/javax/net/ssl/DefaultHostnameVerifier.java
Unrelated
Remove unneed SSLSocket.setUseClientMode while removing unneeded SSLSocket.startHandshake
luni/src/main/java/org/apache/harmony/luni/internal/net/www/protocol/http/HttpConnection.java
Removed warnings due to now missing modules in classpath
run-core-tests
Change-Id: I6e149ae259b3feccdfb0673209c85cfeb60befc8/"
conscrypt,"OpenSSLSocket handshake overhaul
Summary:
- SSLSocket.startHandshake now generalized to handle both client and
server handshaking as well as client/server role reversal
- handshake_cutthrough.patch is properly integrated with support
delayed handshake completion now integrated with delayed updates to
session cache and callbacks to HandshakeCompletedListeners
- Many fixes to SSLSession, which is the end product of the handshake
- Generally more RI and SSLEngine compliant behavior.
- More native code deletion through unification of client/server
handshake, unification of client/server certificate chain
verification, etc. More native code moved from various OpenSSL
classes to cleaner NativeCrypto interfaces that more directly mirror
the OpenSSL interfaces.
Details:
Delay SSL_new call until handshake time when we know for sure whether
the OpenSSLSocket will be used in client or server mode and we can
allocate the SSL_new from the apppriate client or server SSL_CTX used
for session caching.
Now that no SSL is allocated for an OpenSSLServerSocketImpl,
store enabledProtocols and enabledCipherSuites in instance String
arrays. Use new NativeCrypto.checkEnabled* methdods for argument
validation. OpenSSLServerSocketImpl passes these enabled arrays to
a new OpenSSLSocket constructor during accept(). Removed finalizer
from OpenSSLServerSocketImpl since it no longer has any native
storage and socket is already closed by PlainSocketImpl finalizer.
X-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
OpenSSLSocket major overhaul to properly implement handshaking
including switching client and server roles and session ID caching
with handshake_cutthrough.patch.
- now implements NativeCrypto.HandshakeCompletedListeners for
properly timed callback when handshake_cutthrough.patch delays
handshake completion until first SSLSocket.getInputStream()
read.
- similar enabledProtocols/enabledCipherSuites changes as
OpenSSLServerSocketImpl since we need to store the state
somewhere other than an openssl SSL struct until we are sure if
we are doing a client or server handshake.
- added handshake completed field so that startHandshake can tell
if handshake was completed during SSL_do_handshake or will be
completed later by a call to HandshakeCompletedCallback.handshakeCompleted.
- removed nativegetsession as the equivalent value is now returned by SSL_do_handshake
- removed nativecipherauthenticationmethod as the value is now passed to verifyCertificateChain
- startHandshake is now a wrapper that forces a fully synchronous handshake
- startHandshake(boolean) is the the most changed method in this
changelist, combinding both the old startHandshake logic, but
also the OpenSSLSocketImpl.accept code as well. Notable
differences from the old code:
* now responsible for SSL_new
* single code path for client/server handshaking dealing with SSLSession caching
* now handles server certificate requests previously in
OpenSSLServerSocketImpl, since a client can request to act
like a server and therefore need to be able to make suck
demands on its peer.
* supports turning off handshake_cutthrough at a callers request
via explicit call to startHandshake()
* certificate verification happens during an upcall from openssl
during SSL_do_handshake to verifyCertificateChain for both
client and server cases. previously there was not quite right
upcall support on the server side and post-handshake checking
on the client, which did not allow for a proper alert to be
sent to the peer informing them of the issue, which the RI and
SSLEngine code do.
* Similarly, setEnableSessionCreation(false) did not send an
alert to the peer as the RI and SSLEngine code in the client
case. In the server case, nothing was previously done.
* The use of local certificates was not determined from
introspecting the SSL struct post-handshake. This is now
partially implemented and will be completed in a later change.
- SSLSocket.{shutdownInput,shutdownOutput} are now restored to the
proper behavior of throwing UnsupportedOperationException.
- Gutted OpenSSLSocketImpl finalizer. The comment explains in
detail the trouble of having the finalizer do anything more than
touch its the instances own state due to unpredictable order of
finalization and the future possability of parallel
finalization.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
SSLSession fixes
- Made OpenSSLSessionImpl.sessionContext non-final so it could be
nulled by SSLSession.invalidate to match RI behavior.
- As noted in AbstractSessionContext discussion, removed
OpenSSLSessionImpl constructor that took SSLParameters, instead
we take the possibly null localCertificates
directly. OpenSSLSessionImpl.getLocalCertificates now simply
returns the localCertificates member variable instead of
incorrectly trying to query the KeyManager for certificates that
may not have been used.
- OpenSSLSessionImpl now caches its native ID to avoid numerious
native calls but also now provides as resetId which will update
the cache when a delayed handshake happens due to the
handshake_cutthrough.patch
- Fixed bug in getPeerPrincipal that it wasn't calling
getPeerCertificates to initialize peerCertificates field.
- freeImpl is now 'public static' in preparation for move to NativeCrypto.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
The old SSLSessionImpl class that is still used for representing
the invalid session now returns
isValid => false
and
getProtocol => ""NONE""
to match the RI.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSessionImpl.java
NativeCrypto improvements
- Adding NativeCrypto.SSL_{get,set,clear}_mode similar to
NativeCrypto.SSL_{get,set,clear}_options along with
SSL_MODE_HANDSHAKE_CUTTHROUGH constant which is used to
explicitly disable/enable the Android handshake_cutthrough.patch
behavior.
- Added missing NativeCrypto.SSL_clear_options and used to properly
implement NativeCrypto.setEnabledProtocols.
- Added NativeCrypto.checkEnabledProtocols and
NativeCrypto.checkEnabledCipherSuites helpers to implement
exception compatability with the RI. While some of this code is
refactored from existing NativeCrypto code, it is now also used
by OpenSSLServerSocketImpl and OpenSSLSocketImpl which maintain
their own String[]s of what is enabled until startHandshake time. (see below)
- Changed NativeCrypto.findSuite to use foreach style loop for clarity.
- Moved OpenSSLServerSocketImpl nativesetclientauth and
SSL_VERIFY_* constants to NativeCrypto.SSL_set_verify
- Added NativeCrypto.SSL_set_session based on part of old OpenSSLSocketImpl.nativeconnect
- Added NativeCrypto.SSL_set_session_creation_enabled to properly implement
SSLSocket.setEnableSessionCreation(false) which uses new
external/openssl/patches/jsse.patch functionality.
- New NativeCrypto.SSL_do_handshake consolidates
OpenSSLSocketImpl.{nativeconnect, nativeaccept} while properly
implementing SSLSocket.setUseClientMode(false) for clients and
SSLSocket.setUseClientMode(true) for servers.
- New NativeCrypto.SSL_get_certificate is determine if local
certificate requested by peer. While functional, currently
NativeCrypto.SSL_new always sets a value via SSL_use_certificate
instead of relying on a callback set via SSL_CTX_set_client_cert_cb.
- Changed NativeCrypto.CertificateChainVerifier.verifyCertificateChain
to throw a checked CertificateException to match TrustManager.{checkServerTrusted,
checkClientTrusted}. It also takes an authMethod so avoid the need to call
the old OpenSSLSocketImpl.nativecipherauthenticationmethod.
- Added NativeCrypto.HandshakeCompletedCallback which has its
handshakeCompleted method called from OpenSSL when the now
delayed handshake_cutthrough.patch handshake is completed so
SSLSession caching can be delayed until a session ID is available
and to provide a better time for HandshakeCompletedListeners to
be notified.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
Some other changes specific to the naitve side of the code
- Added JNITRACE calls (enabled at compile time with JNI_TRACE)
for future debugging.
- throw SSLException subclass of IOException instead IOException
itself for better RI compatability
x-net/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
- changed from old struct app_data to new class AppData at enh's request
Remove dubious usage of SSLParameters within AbstractSessionContext
to pass through to OpenSSLSessionImpl constructor for use in
calling getLocalCertificates for sessions created from a byte array
with AbstractSessionContext.toSession. Our
AbstractSessionContext.toBytes doesn't currently include the local
certificates in its output, so it cannot be expected to have in toSession.
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerSessionContext.java
x-net/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParameters.java
Test maintenance
openssl 1.0.0 adds support for RFC 4507 session tickets which
remove the need for server side session state. These tests needed
to be updated for this new behavior. If IS_RI is true, they still
follow the old behavior.
luni/src/test/java/javax/net/ssl/SSLSessionContextTest.java
luni/src/test/java/javax/net/ssl/SSLSessionTest.java
luni/src/test/java/javax/net/ssl/SSLSocketTest.java
Update KnownFailures and add specific comments at point of failure
about what remains to be fixed.
luni/src/test/java/javax/net/ssl/SSLSessionTest.java
Added tests to cover the use of standard cipher suite
names. Historically Android has used OpenSSL string constants for
cipher suite names, but JSSE actually specifies supported and
expected names.
luni/src/test/java/javax/net/ssl/SSLSocketFactoryTest.java
luni/src/test/java/javax/net/ssl/SSLSocketTest.java
Create new support/src/test/java/javax/net/ssl with old Helper
support code pulled from javax.net.ssl tests:
SSLContextTest.Helper -> TestSSLContext
SSLSocketTest.Helper -> TestSSLSocketPair
SSLSessionTest.Helper -> TestSSLSessions
Also added new StandardNames here, which contains a collection of
expected constants for test validation.
luni/src/test/java/javax/net/ssl/SSLContextTest.java
luni/src/test/java/javax/net/ssl/SSLSocketTest.java
luni/src/test/java/javax/net/ssl/SSLSessionTest.java
support/src/test/java/javax/net/ssl/TestSSLContext.java
support/src/test/java/javax/net/ssl/TestSSLSocketPair.java
support/src/test/java/javax/net/ssl/TestSSLSessions.java
support/src/test/java/javax/net/ssl/StandardNames.java
Removed some now fixed KnownFailures and unneeded !IS_RI
code. Marked some [Un]KnownFailures where exceptions are thrown
and visible in the output but aren't correctly causing the test to
fail. Fixed assertNonNull to assertTrue in
test_SSLSocketTest_Test_create. Added
stress_test_SSLSocketTest_Test_create to track down test
flakiness, leading to rewrite of SSLSocket finalization.
luni/src/test/java/javax/net/ssl/SSLSocketTest.java
Reenable javax.net.ssl.AllTests now that it is does not hang
luni/src/test/java/tests/AllTests.java
Improve error messages while debugging overflow problem.
Added new assert when debugging new RFC 4507 behavior.
Removed KnownFailure annotation for now working test case.
x-net/src/test/java/tests/api/javax/net/ssl/SSLSessionTest.java
Client code changes
Now that startHandshake implies synchronous vs Android's default async handshake, remove unneeded explict calls to SSLSocket.startHandshake
luni/src/main/java/org/apache/harmony/luni/internal/net/www/protocol/http/HttpConnection.java
Removed IBM 1.4.x codepath that involved startHandshake
x-net/src/main/java/javax/net/ssl/DefaultHostnameVerifier.java
Unrelated
Remove unneed SSLSocket.setUseClientMode while removing unneeded SSLSocket.startHandshake
luni/src/main/java/org/apache/harmony/luni/internal/net/www/protocol/http/HttpConnection.java
Removed warnings due to now missing modules in classpath
run-core-tests
Change-Id: I6e149ae259b3feccdfb0673209c85cfeb60befc8/"
conscrypt,"Stop allocating empty arrays.
Bug: 3166662
Change-Id: I151de373b2bf53786d19824336fa434c02b0b0e8/Make OpenSSLSocketFactory and SSLSocketFactory fields final
Bug: 2954292
Change-Id: I4cad068d4da39a9c55ca25fad698f3ea136f2e24/am 1ca26549: am 912db46c: am 6812a2e8: Rename internal SSLParameters to SSLParametersImpl to avoid collision with new javax.net.ssl.SSLParameters
Merge commit '1ca26549fbe0f4bc171ba7bf8ab0a86ae591c618' into dalvik-dev
* commit '1ca26549fbe0f4bc171ba7bf8ab0a86ae591c618':
Rename internal SSLParameters to SSLParametersImpl to avoid collision with new javax.net.ssl.SSLParameters/Rename internal SSLParameters to SSLParametersImpl to avoid collision with new javax.net.ssl.SSLParameters
Bug: 2672817
Change-Id: Iadf21b848eaf8850fce22721b9ba3739ab2e9fca/"
conscrypt,"Stop allocating empty arrays.
Bug: 3166662
Change-Id: I151de373b2bf53786d19824336fa434c02b0b0e8/"
conscrypt,"Scrub missing calls to super.finalize()
Bug: 3024226
Change-Id: I6642cb9d4929ba72244529efe4ebdfa595ae4fa7/am e6b59c28: am 9e8d51c7: am a3de55dd: Implement OpenSSLMessageDigestJDK.clone and fix OpenSSLMessageDigestJDK.digest
Merge commit 'e6b59c287ed3007d76167dd9741dc683f440ed2d' into dalvik-dev
* commit 'e6b59c287ed3007d76167dd9741dc683f440ed2d':
Implement OpenSSLMessageDigestJDK.clone and fix OpenSSLMessageDigestJDK.digest/Implement OpenSSLMessageDigestJDK.clone and fix OpenSSLMessageDigestJDK.digest
DigestInputStream2Test.test_onZ was failing because OpenSSLMessageDigestJDK did not implement Clonable
- Implementing Clonable required a new NativeCrypto.EVP_MD_CTX_copy method
- While adding NativeCrypto.EVP_MD_CTX_copy, noticed other methods
were not properly named in NativeCrypto.EVP_MD_CTX_* convention.
- Converted rest of NativeCrypto.cpp to JNI_TRACE logging while debugging
DigestOutputStreamTest.test_onZ was failing because OpenSSLMessageDigestJDK.digest did an engineReset
- Removing the engineReset revealed that digest() could not be called
repeatedly on an OpenSSLMessageDigestJDK. Problem was that
EVP_DigestFinal can only be called once per digest.
- Changed engineDigest implementation to use new EVP_MD_CTX_copy to
create a temp EVP_MD_CTX which can be used to retreive the digest
and then discarded.
Bug: 2997405
Change-Id: Ie97c22be245911300d2e729e451a9c4afdb27937/"
conscrypt,"Scrub missing calls to super.finalize()
Bug: 3024226
Change-Id: I6642cb9d4929ba72244529efe4ebdfa595ae4fa7/Fix HttpsURLConnectionTest failures
Focusing on HttpsURLConnectionTest.test_doOutput found a number of
unrelated issues, all of which are addressed by this change:
- {HttpURLConnection,HttpsURLConnection}.connect not ignored on subsequent calls
- OpenSSLSessionImpl.{getPeerCertificates,getPeerCertificateChain} did not include client certificate
- OpenSSLSocketImpl.getSession did not skip handshake when SSLSession was already available
- Fix 3 test issues in HttpsURLConnectionTest
- Fix 2 test issues in NativeCryptoTest
Details:
HttpsURLConnectionTest tests (such as test_doOutput) that
tried to call URLConnection.connect() at the end of the test
were raising exception. The RI URLConnection.connect
documentation says calls on connected URLConnections should be ignored.
Use ""connected"" instead of ""connection != null"" as reason to ignore ""connect""
luni/src/main/java/org/apache/harmony/luni/internal/net/www/protocol/http/HttpURLConnectionImpl.java
luni/src/main/java/org/apache/harmony/luni/internal/net/www/protocol/https/HttpsURLConnectionImpl.java
Converted one caller of getPeerCertificateChain to
getPeerCertificates which is the new fast path.  Track
OpenSSLSessionImpl change to take ""java"" vs ""javax"" certificates.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
Move SSL_SESSION_get_peer_cert_chain to be SSL_get_peer_cert_chain
(similar to SSL_get_certificate). The problem was that
SSL_SESSION_get_peer_cert_chain used SSL_get_peer_cert_chain which
in the server case did not include the client cert itself, which
required a call to SSL_get_peer_certificate, which needed the
SSL instance pointer.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
luni/src/main/native/NativeCrypto.cpp
Improved NativeCrypto_SSL_set_verify tracing
luni/src/main/native/NativeCrypto.cpp
As a side effect of the move to
NativeCrypto.SSL_get_peer_certificate, it no longer made sense to
lazily create the peer certificate chain since the SSLSession
should not depend on a particular SSL instance. The peer chain is
now passed in as part of the constructor and the peerCertifcates
in the OpenSSLSession can be final (also made localCertificates
final). Since peerCertifcates is the newew (java not javax) API
and more commonly used, it is what is created from the native
code, and peerCertificateChain is not derived from peerCertifcates
instead of vice versa.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
Factored out code to used to create local certificate chain to
from array of DER byte arrays into createCertChain so it can be
reused to create peer certificate chain.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Fix OpenSSLSocketImpl.getSession to check for existing sslSession
to and skip handshake, which was causing an exception if the
connection had already been closed.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Fix test issues: Removed PrintStream wrapper of System.out which
was causing vogar to lose output. Added null check in closeSocket,
which can happen in timeout case. Removed use of
InputStream.available which in OpenSSLSocket case returned 0,
causing test to fail incorrectly.
luni/src/test/java/org/apache/harmony/luni/tests/internal/net/www/protocol/https/HttpsURLConnectionTest.java
Updating to track change to SSL_get_peer_cert_chain. Also fixed
some other unrelated test failures caused by IOException on
shutdown and false start (aka SSL_MODE_HANDSHAKE_CUTTHROUGH)
causing clientCallback.handshakeCompleted to be false.
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/NativeCryptoTest.java
Bug: b/2981767
Change-Id: Id083beb6496558296c2f74f51ab0970e158b23a9/"
conscrypt,"am 1ca26549: am 912db46c: am 6812a2e8: Rename internal SSLParameters to SSLParametersImpl to avoid collision with new javax.net.ssl.SSLParameters
Merge commit '1ca26549fbe0f4bc171ba7bf8ab0a86ae591c618' into dalvik-dev
* commit '1ca26549fbe0f4bc171ba7bf8ab0a86ae591c618':
Rename internal SSLParameters to SSLParametersImpl to avoid collision with new javax.net.ssl.SSLParameters/Rename internal SSLParameters to SSLParametersImpl to avoid collision with new javax.net.ssl.SSLParameters
Bug: 2672817
Change-Id: Iadf21b848eaf8850fce22721b9ba3739ab2e9fca/"
conscrypt,"Stop allocating empty arrays.
Bug: 3166662
Change-Id: I151de373b2bf53786d19824336fa434c02b0b0e8/SSL* AppData should not hold onto JNI global references
Summary:
NativeCrypto.SSL_do_handshake stored JNI global references in its
AppData instance for use in upcalls from OpenSSL that invoke Java
callbacks. However, one of the references was to the
SSLHandshakeCallbacks which in the common case of OpenSSLSocketImpl is
the OpenSSLSocketImpl instance itself. This meant that if code dropped
the OpenSSLSocketImpl without closing (such as Apache HTTP Client),
the instances would never be collected, and perhaps more importantly,
file descriptors would not be closed.
The fix is to pass in the objects required during a callback in all
downcalls to SSL_* methods that could result in a callback and clear
them on return. The existing code already did this for the JNIEnv*, so
that code was expanded to handle setting the jobjects as well.
Details:
In the native code used to extract the FileDescriptor object from a
Socket on the call to NativeCrypto.SSL_do_handshake. However, since we
need this for every read and write operations, we now do this in Java
to avoid the repeated overhead. NativeCrypto.SSL_do_handshake now
takes a FileDescriptor, which it extracted from the Socket the
convenience function using NativeCrypto.getFileDescriptor(Socket)
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
In addition to tracking changes to pass FileDescriptor and
SSLHandshakeCallbacks, removed final uses of getFieldId since the
code no longer needs to extract FileDescriptors itself
luni/src/main/native/NativeCrypto.cpp
The Socket field used to be non-null in the wrapper case and null in
the non-wrapper case. To simplify things a bit, ""socket == this"" in
the non-wrapper case. The socket field is now also final and joined by
a final FileDescriptor field.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Updated NativeCryptoTest to track FileDescriptor and
SSLHandshakeCallbacks by expanding the Hooks.afterHandshake to provide
them. Also changed to add a 5 second timeout to many test cases.
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/NativeCryptoTest.java
Bug: 2989218
Change-Id: Iccef92b59475f3c1929e990893579493ece9d442/am e6b59c28: am 9e8d51c7: am a3de55dd: Implement OpenSSLMessageDigestJDK.clone and fix OpenSSLMessageDigestJDK.digest
Merge commit 'e6b59c287ed3007d76167dd9741dc683f440ed2d' into dalvik-dev
* commit 'e6b59c287ed3007d76167dd9741dc683f440ed2d':
Implement OpenSSLMessageDigestJDK.clone and fix OpenSSLMessageDigestJDK.digest/Implement OpenSSLMessageDigestJDK.clone and fix OpenSSLMessageDigestJDK.digest
DigestInputStream2Test.test_onZ was failing because OpenSSLMessageDigestJDK did not implement Clonable
- Implementing Clonable required a new NativeCrypto.EVP_MD_CTX_copy method
- While adding NativeCrypto.EVP_MD_CTX_copy, noticed other methods
were not properly named in NativeCrypto.EVP_MD_CTX_* convention.
- Converted rest of NativeCrypto.cpp to JNI_TRACE logging while debugging
DigestOutputStreamTest.test_onZ was failing because OpenSSLMessageDigestJDK.digest did an engineReset
- Removing the engineReset revealed that digest() could not be called
repeatedly on an OpenSSLMessageDigestJDK. Problem was that
EVP_DigestFinal can only be called once per digest.
- Changed engineDigest implementation to use new EVP_MD_CTX_copy to
create a temp EVP_MD_CTX which can be used to retreive the digest
and then discarded.
Bug: 2997405
Change-Id: Ie97c22be245911300d2e729e451a9c4afdb27937/Fix HttpsURLConnectionTest failures
Focusing on HttpsURLConnectionTest.test_doOutput found a number of
unrelated issues, all of which are addressed by this change:
- {HttpURLConnection,HttpsURLConnection}.connect not ignored on subsequent calls
- OpenSSLSessionImpl.{getPeerCertificates,getPeerCertificateChain} did not include client certificate
- OpenSSLSocketImpl.getSession did not skip handshake when SSLSession was already available
- Fix 3 test issues in HttpsURLConnectionTest
- Fix 2 test issues in NativeCryptoTest
Details:
HttpsURLConnectionTest tests (such as test_doOutput) that
tried to call URLConnection.connect() at the end of the test
were raising exception. The RI URLConnection.connect
documentation says calls on connected URLConnections should be ignored.
Use ""connected"" instead of ""connection != null"" as reason to ignore ""connect""
luni/src/main/java/org/apache/harmony/luni/internal/net/www/protocol/http/HttpURLConnectionImpl.java
luni/src/main/java/org/apache/harmony/luni/internal/net/www/protocol/https/HttpsURLConnectionImpl.java
Converted one caller of getPeerCertificateChain to
getPeerCertificates which is the new fast path.  Track
OpenSSLSessionImpl change to take ""java"" vs ""javax"" certificates.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
Move SSL_SESSION_get_peer_cert_chain to be SSL_get_peer_cert_chain
(similar to SSL_get_certificate). The problem was that
SSL_SESSION_get_peer_cert_chain used SSL_get_peer_cert_chain which
in the server case did not include the client cert itself, which
required a call to SSL_get_peer_certificate, which needed the
SSL instance pointer.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
luni/src/main/native/NativeCrypto.cpp
Improved NativeCrypto_SSL_set_verify tracing
luni/src/main/native/NativeCrypto.cpp
As a side effect of the move to
NativeCrypto.SSL_get_peer_certificate, it no longer made sense to
lazily create the peer certificate chain since the SSLSession
should not depend on a particular SSL instance. The peer chain is
now passed in as part of the constructor and the peerCertifcates
in the OpenSSLSession can be final (also made localCertificates
final). Since peerCertifcates is the newew (java not javax) API
and more commonly used, it is what is created from the native
code, and peerCertificateChain is not derived from peerCertifcates
instead of vice versa.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
Factored out code to used to create local certificate chain to
from array of DER byte arrays into createCertChain so it can be
reused to create peer certificate chain.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Fix OpenSSLSocketImpl.getSession to check for existing sslSession
to and skip handshake, which was causing an exception if the
connection had already been closed.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Fix test issues: Removed PrintStream wrapper of System.out which
was causing vogar to lose output. Added null check in closeSocket,
which can happen in timeout case. Removed use of
InputStream.available which in OpenSSLSocket case returned 0,
causing test to fail incorrectly.
luni/src/test/java/org/apache/harmony/luni/tests/internal/net/www/protocol/https/HttpsURLConnectionTest.java
Updating to track change to SSL_get_peer_cert_chain. Also fixed
some other unrelated test failures caused by IOException on
shutdown and false start (aka SSL_MODE_HANDSHAKE_CUTTHROUGH)
causing clientCallback.handshakeCompleted to be false.
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/NativeCryptoTest.java
Bug: b/2981767
Change-Id: Id083beb6496558296c2f74f51ab0970e158b23a9/"
conscrypt,"am 1ca26549: am 912db46c: am 6812a2e8: Rename internal SSLParameters to SSLParametersImpl to avoid collision with new javax.net.ssl.SSLParameters
Merge commit '1ca26549fbe0f4bc171ba7bf8ab0a86ae591c618' into dalvik-dev
* commit '1ca26549fbe0f4bc171ba7bf8ab0a86ae591c618':
Rename internal SSLParameters to SSLParametersImpl to avoid collision with new javax.net.ssl.SSLParameters/Rename internal SSLParameters to SSLParametersImpl to avoid collision with new javax.net.ssl.SSLParameters
Bug: 2672817
Change-Id: Iadf21b848eaf8850fce22721b9ba3739ab2e9fca/"
conscrypt,"TrustManager improvements
Overhaul of TrustManagerImpl
- PKIXParameters can now be final in TrustManagerImpl because we
always immediately create an IndexedPKIXParameters instead of only
doing it in SSLParametersImpl.createDefaultTrustManager.
- Use new KeyStore constructor for IndexedPKIXParameters to remove
duplicate logic for creating set of TrustAnchors from a KeyStore.
- Improved checkTrusted/cleanupCertChain to remove special cases for
directly trusting the end cert or pruning only self signed certs. To
support b/2530852, we need to stop prune the chain as soon as we
find any trust anchor (using newly improved
TrustManagerImpl.isTrustAnchor), which could be at the beginning,
middle, or end. That means cleanupCertChain can return an empty
chain if everything was trusted directly. (and we don't need to do
extra checks on exception cases to see if the problem was just that
the trust anchor was in the chain)
- isDirectlyTrusted -> isTrustAnchor here as well, using new
IndexedPKIXParameters.isTrustAnchor APIs
- Fix incorrect assumption in getAcceptedIssuers that all TrustAnchor
instances have non-null results for getTrustedCert.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/TrustManagerImpl.java
Removed indexing in createDefaultTrustManager since we always index now
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParametersImpl.java
Overhaul of IndexedPKIXParameters
- Single map from subject X500Principal to TrustAnchors
instead of two different X500Principal keyed maps to check
- Removed map based on encoded cert. For b/2530852, we want to treat
certs as equal if they have the same name and public key, not
byte-for-byte equality, which can be done with the remaining map.
Revamped isDirectlyTrusted into isTrustAnchor(cert) to perform this
new name/key based comparison.
- Added helper isTrustAnchor(cert, anchors) to reuse code in
non-IndexedPKIXParameters case in TrustManagerImpl.
- Added constructor from KeyStore
- Moved anchor indexing code to index() from old constructor
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/IndexedPKIXParameters.java
TestKeyStore.getPrivateKey allowed some existing test simplification.
luni/src/test/java/libcore/java/security/KeyStoreTest.java
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/NativeCryptoTest.java
support/src/test/java/libcore/java/security/TestKeyStore.java
Added missing ""fail()"" before catching expected exceptions.
luni/src/test/java/libcore/java/security/KeyStoreTest.java
Expanded KeyManagerFactoryTest to excercise ManagerFactoryParameters b/1628001
luni/src/test/java/libcore/javax/net/ssl/KeyManagerFactoryTest.java
Added KeyStoreBuilderParametersTest because I thought I saw a bug in
KeyStoreBuilderParameters, but this convinced me otherwise.
luni/src/test/java/libcore/javax/net/ssl/KeyStoreBuilderParametersTest.java
New TrustManagerFactory test modeled on expanded KeyManagerFactoryTest.
test_TrustManagerFactory_intermediate specifically is targeting the
new functionality of b/2530852 to handling trust anchors within the
chain.
luni/src/test/java/libcore/javax/net/ssl/TrustManagerFactoryTest.java
support/src/test/java/libcore/java/security/StandardNames.java
Some initial on tests for Elliptic Curve (b/3058375) after the RI
started reporting it was supported. Removed old @KnownFailure
tags. Skipped a test on the RI that it can't handle. Improved some
assert messages.
luni/src/test/java/libcore/javax/net/ssl/SSLEngineTest.java
luni/src/test/java/libcore/javax/net/ssl/SSLSocketTest.java
support/src/test/java/libcore/java/security/StandardNames.java
support/src/test/java/libcore/java/security/TestKeyStore.java
Removed unneeded bytes->javax->bytes->java case of which can just go bytes->java directly.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Removed super()
luni/src/main/java/javax/net/ssl/KeyStoreBuilderParameters.java
Made Security.secprops final
luni/src/main/java/java/security/Security.java
Pulled SamplingProfiler fix from dalvik-dev branch
git cherry-pick --no-commit f9dc3450e8f23cab91efc9df99bb860221ac3d6c
dalvik/src/main/java/dalvik/system/SamplingProfiler.java
Bug: 2530852
Change-Id: I95e0c7ee6a2f66b6986b3a9da9583d1ae52f94dd/Avoid races between OpenSSLSocketImpl I/O and close()
The previous change:
commit 5f2e6872311240319509aed64d9f58cd5b64719b
Author: Brian Carlstrom <bdc@google.com>
Date:   Mon Aug 23 14:06:51 2010 -0700
SSLSocket.read should throw SocketException not NullPointerException
added checkOpen() to throw SocketException instead of
NullPointerException, but there was still a race between read/write on
one thread and close on another that could allow a
NullPointerException to escape. This change moves checkOpen() calls to
be protected by the existing writeLock/readLock/handshakeLock
synchronzied blocks to avoid this case.
byte buffer error checking for read/write is also moved into the to
lock region to preserve compatability as measured by the test:
libcore.javax.net.ssl.SSLSocketTest#test_SSLSocket_close
Bug: 3153162/am 12e7cb01: Avoid races between OpenSSLSocketImpl I/O and close()
* commit '12e7cb011c48b228cdeb2b799fff54d7fbfc6d85':
Avoid races between OpenSSLSocketImpl I/O and close()/Avoid races between OpenSSLSocketImpl I/O and close()
The previous change:
commit 5f2e6872311240319509aed64d9f58cd5b64719b
Author: Brian Carlstrom <bdc@google.com>
Date:   Mon Aug 23 14:06:51 2010 -0700
SSLSocket.read should throw SocketException not NullPointerException
added checkOpen() to throw SocketException instead of
NullPointerException, but there was still a race between read/write on
one thread and close on another that could allow a
NullPointerException to escape. This change moves checkOpen() calls to
be protected by the existing writeLock/readLock/handshakeLock
synchronzied blocks to avoid this case.
byte buffer error checking for read/write is also moved into the to
lock region to preserve compatability as measured by the test:
libcore.javax.net.ssl.SSLSocketTest#test_SSLSocket_close
Bug: 3153162
Change-Id: I16299f09dc91871407e88eb718073d21a816f683/Revised CloseGuard usage pattern
- CloseGuard.get() instants are now ""unopened""
- In constructor cases, guard.open(""..."") is now at the end
- In metod cases, guard.open(""..."") is now after resource acquisition
- guard null pointer checks in finalizers in case constructor threw exception
Bug: 2645458
Change-Id: Ieb874a8c33b347768a9fa7437b3dd16f3d56d886/Remove OpenSSLSocketImpl.instanceCount
Its use in ActivityThread is being replaced with Debug.countInstancesOfClass(OpenSSLSocketImpl.class)
Bug: 3015791
Change-Id: I26ece579f8e0fce62f17f398055b16aceaaf1b08/CloseGuard: finalizers for closeable objects should log complaints
Introducing CloseGuard which warns when resources are implictly
cleaned up by finalizers when an explicit termination method, to use
the Effective Java ""Issue 7: Avoid finalizers"" terminology, should
have been used by the caller.
libcore classes that can use CloseGuard now do so.
Bug: 3041575
Change-Id: I4a4e3554addaf3075c823feb0a0ff0ad1c1f6196/SSL* AppData should not hold onto JNI global references
Summary:
NativeCrypto.SSL_do_handshake stored JNI global references in its
AppData instance for use in upcalls from OpenSSL that invoke Java
callbacks. However, one of the references was to the
SSLHandshakeCallbacks which in the common case of OpenSSLSocketImpl is
the OpenSSLSocketImpl instance itself. This meant that if code dropped
the OpenSSLSocketImpl without closing (such as Apache HTTP Client),
the instances would never be collected, and perhaps more importantly,
file descriptors would not be closed.
The fix is to pass in the objects required during a callback in all
downcalls to SSL_* methods that could result in a callback and clear
them on return. The existing code already did this for the JNIEnv*, so
that code was expanded to handle setting the jobjects as well.
Details:
In the native code used to extract the FileDescriptor object from a
Socket on the call to NativeCrypto.SSL_do_handshake. However, since we
need this for every read and write operations, we now do this in Java
to avoid the repeated overhead. NativeCrypto.SSL_do_handshake now
takes a FileDescriptor, which it extracted from the Socket the
convenience function using NativeCrypto.getFileDescriptor(Socket)
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
In addition to tracking changes to pass FileDescriptor and
SSLHandshakeCallbacks, removed final uses of getFieldId since the
code no longer needs to extract FileDescriptors itself
luni/src/main/native/NativeCrypto.cpp
The Socket field used to be non-null in the wrapper case and null in
the non-wrapper case. To simplify things a bit, ""socket == this"" in
the non-wrapper case. The socket field is now also final and joined by
a final FileDescriptor field.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Updated NativeCryptoTest to track FileDescriptor and
SSLHandshakeCallbacks by expanding the Hooks.afterHandshake to provide
them. Also changed to add a 5 second timeout to many test cases.
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/NativeCryptoTest.java
Bug: 2989218
Change-Id: Iccef92b59475f3c1929e990893579493ece9d442/Scrub missing calls to super.finalize()
Bug: 3024226
Change-Id: I6642cb9d4929ba72244529efe4ebdfa595ae4fa7/OpenSSLSocketImpl should not call NativeCrypto.SSL_set_client_CA_list with an empty array
Bug: 3034616
Change-Id: Ib39ebfa737910f0ebce5ac2ad87715579bd7aa3d/SSLSocket should respect timeout of a wrapped Socket
Change to using getSoTimeout in OpenSSLSocketImpl instead of directly
using the timeout field. This means the proper timeout will be used
for instances of the OpenSSLSocketImplWrapper subclass, which is used
when an SSLSocket is wrapped around an existing connected non-SSL
Socket. The code still maintains the local timeout field, now renamed
timeoutMilliseconds, which is now accesed via
OpenSSLSocketImpl.getSoTimeout. Doing so prevents a getsockopt syscall
that otherwise would be necessary if the super.getSoTimeout() was used.
Added two unit tests for testing timeouts with SSLSockets wrapped
around Socket. One is simply for getters/setters. The second makes
sure the timeout is functioning when set on the underlying socket.
Bug: 2973305
Change-Id: Idac52853f5d777fae5060a840eefbfe85d448e4c/am 1ca26549: am 912db46c: am 6812a2e8: Rename internal SSLParameters to SSLParametersImpl to avoid collision with new javax.net.ssl.SSLParameters
Merge commit '1ca26549fbe0f4bc171ba7bf8ab0a86ae591c618' into dalvik-dev
* commit '1ca26549fbe0f4bc171ba7bf8ab0a86ae591c618':
Rename internal SSLParameters to SSLParametersImpl to avoid collision with new javax.net.ssl.SSLParameters/Fix HttpsURLConnectionTest failures
Focusing on HttpsURLConnectionTest.test_doOutput found a number of
unrelated issues, all of which are addressed by this change:
- {HttpURLConnection,HttpsURLConnection}.connect not ignored on subsequent calls
- OpenSSLSessionImpl.{getPeerCertificates,getPeerCertificateChain} did not include client certificate
- OpenSSLSocketImpl.getSession did not skip handshake when SSLSession was already available
- Fix 3 test issues in HttpsURLConnectionTest
- Fix 2 test issues in NativeCryptoTest
Details:
HttpsURLConnectionTest tests (such as test_doOutput) that
tried to call URLConnection.connect() at the end of the test
were raising exception. The RI URLConnection.connect
documentation says calls on connected URLConnections should be ignored.
Use ""connected"" instead of ""connection != null"" as reason to ignore ""connect""
luni/src/main/java/org/apache/harmony/luni/internal/net/www/protocol/http/HttpURLConnectionImpl.java
luni/src/main/java/org/apache/harmony/luni/internal/net/www/protocol/https/HttpsURLConnectionImpl.java
Converted one caller of getPeerCertificateChain to
getPeerCertificates which is the new fast path.  Track
OpenSSLSessionImpl change to take ""java"" vs ""javax"" certificates.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/AbstractSessionContext.java
Move SSL_SESSION_get_peer_cert_chain to be SSL_get_peer_cert_chain
(similar to SSL_get_certificate). The problem was that
SSL_SESSION_get_peer_cert_chain used SSL_get_peer_cert_chain which
in the server case did not include the client cert itself, which
required a call to SSL_get_peer_certificate, which needed the
SSL instance pointer.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
luni/src/main/native/NativeCrypto.cpp
Improved NativeCrypto_SSL_set_verify tracing
luni/src/main/native/NativeCrypto.cpp
As a side effect of the move to
NativeCrypto.SSL_get_peer_certificate, it no longer made sense to
lazily create the peer certificate chain since the SSLSession
should not depend on a particular SSL instance. The peer chain is
now passed in as part of the constructor and the peerCertifcates
in the OpenSSLSession can be final (also made localCertificates
final). Since peerCertifcates is the newew (java not javax) API
and more commonly used, it is what is created from the native
code, and peerCertificateChain is not derived from peerCertifcates
instead of vice versa.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
Factored out code to used to create local certificate chain to
from array of DER byte arrays into createCertChain so it can be
reused to create peer certificate chain.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Fix OpenSSLSocketImpl.getSession to check for existing sslSession
to and skip handshake, which was causing an exception if the
connection had already been closed.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Fix test issues: Removed PrintStream wrapper of System.out which
was causing vogar to lose output. Added null check in closeSocket,
which can happen in timeout case. Removed use of
InputStream.available which in OpenSSLSocket case returned 0,
causing test to fail incorrectly.
luni/src/test/java/org/apache/harmony/luni/tests/internal/net/www/protocol/https/HttpsURLConnectionTest.java
Updating to track change to SSL_get_peer_cert_chain. Also fixed
some other unrelated test failures caused by IOException on
shutdown and false start (aka SSL_MODE_HANDSHAKE_CUTTHROUGH)
causing clientCallback.handshakeCompleted to be false.
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/NativeCryptoTest.java
Bug: b/2981767
Change-Id: Id083beb6496558296c2f74f51ab0970e158b23a9/Rename internal SSLParameters to SSLParametersImpl to avoid collision with new javax.net.ssl.SSLParameters
Bug: 2672817
Change-Id: Iadf21b848eaf8850fce22721b9ba3739ab2e9fca/Use BlockGuard for OpenSSL sockets.
StrictMode wasn't catching network usage via SSL.
Bug: 2976407
Change-Id: I31fe09861e3aca7b26724b94af88687fb6b9442b/SSLSocket.read should throw SocketException not NullPointerException
OpenSSLSocketImpl now uses checkOpen similar to Socket's
checkOpenAndCreate to ensure that SocketExceptions are thrown if
certain operations are tried after the socket is closed.
Also added *_setUseClientMode_afterHandshake tests for SSLSocket and
SSLEngine. We properly through IllegalArgument exception in this case,
but it wasn't covered by the tests previously.
Bug: 2918499
Change-Id: I393ad39bed40a33725d2c0f3f08b9d0b0d3ff85f/"
conscrypt,"Stop allocating empty arrays.
Bug: 3166662
Change-Id: I151de373b2bf53786d19824336fa434c02b0b0e8/CloseGuard: finalizers for closeable objects should log complaints
Introducing CloseGuard which warns when resources are implictly
cleaned up by finalizers when an explicit termination method, to use
the Effective Java ""Issue 7: Avoid finalizers"" terminology, should
have been used by the caller.
libcore classes that can use CloseGuard now do so.
Bug: 3041575
Change-Id: I4a4e3554addaf3075c823feb0a0ff0ad1c1f6196/"
conscrypt,"SSLParameters.getDefaultTrustManager() should lazily initialize its value
Make SSLParametersImpl's defaultKeyManager, defaultTrustManager,
defaultSecureRandom, and defaultParameters all use the single check
idiom for initialization. Move such initialization for
defaultKeyManager and defaultTrustManager out of SSLParametersImpl
constructor into static functions, replacing original
getDefaultTrustManager simple accessor with code that performs lazy
initialization.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParametersImpl.java
dirrect -> direct
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParametersImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketImpl.java
hanshake -> handshake
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLRecordProtocol.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/HandshakeProtocol.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLSocketImpl.java
Bug: 2954292
Change-Id: I19bae541613666903b57fccf3e8bfef65b74d6cf/am 1ca26549: am 912db46c: am 6812a2e8: Rename internal SSLParameters to SSLParametersImpl to avoid collision with new javax.net.ssl.SSLParameters
Merge commit '1ca26549fbe0f4bc171ba7bf8ab0a86ae591c618' into dalvik-dev
* commit '1ca26549fbe0f4bc171ba7bf8ab0a86ae591c618':
Rename internal SSLParameters to SSLParametersImpl to avoid collision with new javax.net.ssl.SSLParameters/Rename internal SSLParameters to SSLParametersImpl to avoid collision with new javax.net.ssl.SSLParameters
Bug: 2672817
Change-Id: Iadf21b848eaf8850fce22721b9ba3739ab2e9fca/"
conscrypt,"Elliptic Crypto support for OpenSSLSocketImpl
Summary:
- Enable Elliptic Crypto support for OpenSSL based SSLSocket instances
- More RI compliant usage of key types, client auth types, and server auth types
- Steps toward TLS_EMPTY_RENEGOTIATION_INFO_SCSV support, currently test updates
Details:
Elliptic Curve changes
CipherSuite updates for EC
- Adding KEY_EXCHANGE_EC* and corresponding CipherSuites Updated
isAnonymous, getKeyType (now renamed getServerKeyType) to handle
new EC cases.  Added new getAuthType for use by
checkServerTrusted callers.
- Restructured code to handle two SUITES_BY_CODE_* arrays
- Remove KEY_EXCHANGE_DH_* definitions which unused because the
corresponding CipherSuites were previously disabled.
- Changed AES CipherSuites definitions to use ""_CBC"" to match other definitions.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/CipherSuite.java
openssl EC
- NativeCrypto now registers TLS_EC_* cipher suites and has update default list
- Improved auth type arguments to checkClientTrusted/checkServerTrusted
- NativeCrypto support for emphemeral EC keys
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
luni/src/main/native/NativeCrypto.cpp
non-openssl SSL/TLS cleanups
- cleanup around code trying to cope with DiffieHellman vs DH since either should work.
- changed client to use new CipherSuite.getAuthType shared with NativeCrypto implementation
- changed server to use CipherSuite.getKeyType
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/HandshakeProtocol.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/KeyManagerImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImpl.java
Consolidate CertificateRequestType code into CipherSuite so that its
shared between java and openssl implementations. This includes the
KEY_TYPE_ string constants, TLS_CT_* byte constants and the 'String
keyType(byte)' (now renamed getClientKeyType) code that depends on them.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/CertificateRequest.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/CipherSuite.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImpl.java
Tests
Differentiate between supported list of cipher suites openssl-based
SSLSocket and SSLEngine based, since the SSLEngine code does not support EC.
luni/src/test/java/libcore/javax/net/ssl/SSLEngineTest.java
luni/src/test/java/libcore/javax/net/ssl/SSLSocketTest.java
Added testing for expected default cipher suites. Before we just ensured the values were valid.
luni/src/test/java/libcore/javax/net/ssl/SSLSocketFactoryTest.java
support/src/test/java/libcore/java/security/StandardNames.java
Updated to handle new EC cipher suites codes. Added test for new getClientKeyType.
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/CipherSuiteTest.java
Better use of ""standard names"" particularly to correctly deal with
the subtle differences between key types, client auth types, and
server auth types. TestKeyManager and TestTrustManager now verify
the values they are passed are acceptable.
support/src/test/java/libcore/java/security/StandardNames.java
support/src/test/java/libcore/javax/net/ssl/TestKeyManager.java
support/src/test/java/libcore/javax/net/ssl/TestTrustManager.java
Changed to timeout after 30 seconds and to log to reveal both client and server issues.
support/src/test/java/libcore/javax/net/ssl/TestSSLSocketPair.java
Bug: 3058375
Change-Id: I14d1d0285d591c99cc211324f3595a5be682cab1/"
conscrypt,"Add an @hidden Byte.toHexString that does the right thing, and use it.
Turns out most callers don't actually give a toss about case anyway, since
they're just for debugging output.
Bug: 3371169
Change-Id: Ib8dc079be2dcbf6f2415ecb9b71d034ee71f68eb/Most callers of toLowerCase/toUpperCase should pass Locale.US to avoid problems in Turkey.
Some callers should be replaced with equalsIgnoreCase instead.
The one exception is StreamTokenizer, where the RI uses the default
locale, which is arguably the right thing to do. No-one cares because
that's legacy API, but I've added a test anyway.
I've left HttpCookie and GeneralName for my co-conspirators because the
appropriate resolutions aren't as obvious there...
Bug: 3325637
Change-Id: Ia37a1caaa91b11763ae43e61e445adb45c30f793/"
conscrypt,"Retire SecurityManager.
This change removes all the code that was calling getSecurityManager, and
removes all use of AccessController.doPrivileged. It also changes the
implementation of AccessController so it doesn't actually do anything; it's
only there for source-level compatibility.
Bug: 2585285
Change-Id: I1f0295a4f12bce0316d8073011d8593fee116f71/"
conscrypt,"Performance improvements to NativeCrypto based MessageDigest API
NativeCrypto API improvements:
- Move to using EVP_MD related native methods, some of which are derived
from the EVP_MD_CTX versions with similar name. The new
EVP_get_digestbyname allows one time lookup of the EVP_MD from the
string name, avoiding doing it on every call to EVP_DigestInit.
- EVP_MD_CTX_create is now removed, it is just done as part of
EVP_DigestInit and EVP_VerifyInit to an extra JNI call.
- EVP_DigestFinal now destroys the EVP_MD_CTX to avoid needing to make
another call JNI call to EVP_MD_CTX_destroy. EVP_MD_CTX_destroy is
kept for cases when EVP_DigestFinal is never called.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
In addition to the improved NativeCrypto API to allow better
performance for callers, the implementations use of
throwExceptionIfNecessary was made conditional based on the status
code from various operations, which had a noticeable impact on
performance compared to android.security.MessageDigest
luni/src/main/native/NativeCrypto.cpp
Updated MessageDigest.getInstance default implementation to use new
NativeCrypto API. An EVP_MD instance is looked up at class load time
for a specific digest type and then used to call
NativeCrypto.EVP_DigestInit as needed, avoiding a lookup of EVP_MD for
each new digest. The EVP_MD is also for a one-time lookup the digest
output size in bytes, to avoid native calls for
engineGetDigestLength. Finally, the creation of the EVP_MD_CTX is now
lazy, only created when needed, avoiding unnecessarily create/free in
reset cases such as engineDigest. See also external/bouncycastle's
OpenSSLDigest implementation which had similar optimizations.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLMessageDigestJDK.java
OpenSSLSignature also used EVP_MD_CTX_create, and its EVP_VerifyInit
was changed similar to EVP_DigestInit to internally allocate the
EVP_MD_CTX on the call to init.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSignature.java
Fix test to work with arbitrary provider order
luni/src/test/java/org/apache/harmony/security/tests/java/security/MessageDigest2Test.java
Fix CloseGuard warnings
luni/src/test/java/tests/security/MessageDigestTest.java
Bug: 3392028
Change-Id: Idb266ebc0918ffd5550e0f457784256400cd2ff0/"
conscrypt,"Performance improvements to NativeCrypto based MessageDigest API
NativeCrypto API improvements:
- Move to using EVP_MD related native methods, some of which are derived
from the EVP_MD_CTX versions with similar name. The new
EVP_get_digestbyname allows one time lookup of the EVP_MD from the
string name, avoiding doing it on every call to EVP_DigestInit.
- EVP_MD_CTX_create is now removed, it is just done as part of
EVP_DigestInit and EVP_VerifyInit to an extra JNI call.
- EVP_DigestFinal now destroys the EVP_MD_CTX to avoid needing to make
another call JNI call to EVP_MD_CTX_destroy. EVP_MD_CTX_destroy is
kept for cases when EVP_DigestFinal is never called.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
In addition to the improved NativeCrypto API to allow better
performance for callers, the implementations use of
throwExceptionIfNecessary was made conditional based on the status
code from various operations, which had a noticeable impact on
performance compared to android.security.MessageDigest
luni/src/main/native/NativeCrypto.cpp
Updated MessageDigest.getInstance default implementation to use new
NativeCrypto API. An EVP_MD instance is looked up at class load time
for a specific digest type and then used to call
NativeCrypto.EVP_DigestInit as needed, avoiding a lookup of EVP_MD for
each new digest. The EVP_MD is also for a one-time lookup the digest
output size in bytes, to avoid native calls for
engineGetDigestLength. Finally, the creation of the EVP_MD_CTX is now
lazy, only created when needed, avoiding unnecessarily create/free in
reset cases such as engineDigest. See also external/bouncycastle's
OpenSSLDigest implementation which had similar optimizations.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLMessageDigestJDK.java
OpenSSLSignature also used EVP_MD_CTX_create, and its EVP_VerifyInit
was changed similar to EVP_DigestInit to internally allocate the
EVP_MD_CTX on the call to init.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSignature.java
Fix test to work with arbitrary provider order
luni/src/test/java/org/apache/harmony/security/tests/java/security/MessageDigest2Test.java
Fix CloseGuard warnings
luni/src/test/java/tests/security/MessageDigestTest.java
Bug: 3392028
Change-Id: Idb266ebc0918ffd5550e0f457784256400cd2ff0/Elliptic Crypto support for OpenSSLSocketImpl
Summary:
- Enable Elliptic Crypto support for OpenSSL based SSLSocket instances
- More RI compliant usage of key types, client auth types, and server auth types
- Steps toward TLS_EMPTY_RENEGOTIATION_INFO_SCSV support, currently test updates
Details:
Elliptic Curve changes
CipherSuite updates for EC
- Adding KEY_EXCHANGE_EC* and corresponding CipherSuites Updated
isAnonymous, getKeyType (now renamed getServerKeyType) to handle
new EC cases.  Added new getAuthType for use by
checkServerTrusted callers.
- Restructured code to handle two SUITES_BY_CODE_* arrays
- Remove KEY_EXCHANGE_DH_* definitions which unused because the
corresponding CipherSuites were previously disabled.
- Changed AES CipherSuites definitions to use ""_CBC"" to match other definitions.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/CipherSuite.java
openssl EC
- NativeCrypto now registers TLS_EC_* cipher suites and has update default list
- Improved auth type arguments to checkClientTrusted/checkServerTrusted
- NativeCrypto support for emphemeral EC keys
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
luni/src/main/native/NativeCrypto.cpp
non-openssl SSL/TLS cleanups
- cleanup around code trying to cope with DiffieHellman vs DH since either should work.
- changed client to use new CipherSuite.getAuthType shared with NativeCrypto implementation
- changed server to use CipherSuite.getKeyType
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/HandshakeProtocol.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/KeyManagerImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImpl.java
Consolidate CertificateRequestType code into CipherSuite so that its
shared between java and openssl implementations. This includes the
KEY_TYPE_ string constants, TLS_CT_* byte constants and the 'String
keyType(byte)' (now renamed getClientKeyType) code that depends on them.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/CertificateRequest.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/CipherSuite.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImpl.java
Tests
Differentiate between supported list of cipher suites openssl-based
SSLSocket and SSLEngine based, since the SSLEngine code does not support EC.
luni/src/test/java/libcore/javax/net/ssl/SSLEngineTest.java
luni/src/test/java/libcore/javax/net/ssl/SSLSocketTest.java
Added testing for expected default cipher suites. Before we just ensured the values were valid.
luni/src/test/java/libcore/javax/net/ssl/SSLSocketFactoryTest.java
support/src/test/java/libcore/java/security/StandardNames.java
Updated to handle new EC cipher suites codes. Added test for new getClientKeyType.
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/CipherSuiteTest.java
Better use of ""standard names"" particularly to correctly deal with
the subtle differences between key types, client auth types, and
server auth types. TestKeyManager and TestTrustManager now verify
the values they are passed are acceptable.
support/src/test/java/libcore/java/security/StandardNames.java
support/src/test/java/libcore/javax/net/ssl/TestKeyManager.java
support/src/test/java/libcore/javax/net/ssl/TestTrustManager.java
Changed to timeout after 30 seconds and to log to reveal both client and server issues.
support/src/test/java/libcore/javax/net/ssl/TestSSLSocketPair.java
Bug: 3058375
Change-Id: I14d1d0285d591c99cc211324f3595a5be682cab1/Toward EC TLS support
Summary:
- javax.net.ssl tests are now working on the RI
- KeyManager can now handle EC_EC and EC_RSA
- OpenSSLSocketImpl.startHandshake now works if KeyManager contains EC certificates
Details:
Add CipherSuite.getKeyType to provide X509KeyManager key type strings,
refactored from OpenSSLServerSocketImpl.checkEnabledCipherSuites.
getKeyType is now also used in OpenSSLSocketImpl.startHandshake to
avoid calling setCertificate for unnecessary key types.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/CipherSuite.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
New CipherSuiteTest to cover new getKeyType as well as existing functionality
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/CipherSuiteTest.java
Add support to KeyManager implementation for key types of the form
EC_EC and EC_RSA. The first part implies the KeyPair algorithm (EC in
these new key types) with a potentially different signature algorithm
(EC vs RSA in these)
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/KeyManagerImpl.java
Update NativeCrypto.keyType to support EC_EC and EC_RSA in addition to
EC which was added earlier. Change from array of KEY_TYPES to named
KEY_TYPE_* constants.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
Overhauled KeyManagerFactoryTest to cover EC, EC_EC, EC_RSA cases
luni/src/test/java/libcore/javax/net/ssl/KeyManagerFactoryTest.java
support/src/test/java/libcore/java/security/StandardNames.java
Changed TestKeyStore.createKeyStore from always using BKS to now use
JKS on the RI between BC EC Keys and RI X509 certificates. Because JKS
requires a password, we now default ""password"" on the RI.
support/src/test/java/libcore/java/security/TestKeyStore.java
luni/src/test/java/libcore/javax/net/ssl/SSLContextTest.java
support/src/test/java/libcore/java/security/StandardNames.java
TestKeyStore.create now accepts key types like EC_RSA. Changed
TestKeyStore.createKeys to allow a PrivateKeyEntry to be specified for
signing to enable creation of EC_RSA test certificate. Added
getRootCertificate/rootCertificate to allow lookup of PrivateKeyEntry
for signing. Changed TestKeyStore.getPrivateKey to take explicit
signature algorithm to retrieve EC_EC vs EC_RSA entries.
support/src/test/java/libcore/java/security/TestKeyStore.java
luni/src/test/java/libcore/java/security/KeyStoreTest.java
luni/src/test/java/libcore/javax/net/ssl/KeyManagerFactoryTest.java
luni/src/test/java/libcore/java/security/cert/PKIXParametersTest.java
luni/src/test/java/libcore/javax/net/ssl/TrustManagerFactoryTest.java
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/NativeCryptoTest.java
support/src/test/java/libcore/java/security/StandardNames.java
Added support for EC cipher suites on the RI.  Also test with and
without new TLS_EMPTY_RENEGOTIATION_INFO_SCSV cipher suite which is
used to specify the new TLS secure renegotiation.
luni/src/test/java/libcore/javax/net/ssl/SSLEngineTest.java
luni/src/test/java/libcore/javax/net/ssl/SSLSocketTest.java
support/src/test/java/libcore/java/security/StandardNames.java
New TestKeyManager and additional logging in TestTrustManager. Logging
in both is disabled by default using DevNullPrintStream.
support/src/test/java/libcore/javax/net/ssl/TestKeyManager.java
support/src/test/java/libcore/javax/net/ssl/TestTrustManager.java
support/src/test/java/libcore/java/io/DevNullPrintStream.java
Bug: 3058375
Change-Id: Ia5e2a00a025858e10d1076b900886994b481e05a/"
conscrypt,"Most callers of toLowerCase/toUpperCase should pass Locale.US to avoid problems in Turkey.
Some callers should be replaced with equalsIgnoreCase instead.
The one exception is StreamTokenizer, where the RI uses the default
locale, which is arguably the right thing to do. No-one cares because
that's legacy API, but I've added a test anyway.
I've left HttpCookie and GeneralName for my co-conspirators because the
appropriate resolutions aren't as obvious there...
Bug: 3325637
Change-Id: Ia37a1caaa91b11763ae43e61e445adb45c30f793/KeyManager.choose* methods should tolerate null key types
This regression was found by X509KeyManagerTest and now
KeyManagerFactoryTest covers it as well. The underlying problem was
introduced recently when KeyManagerImpl was updated to support key
types with specific signature algorithms like EC_RSA and EC_EC.
Change-Id: Ic99ab10e5ba07e990dc0e8a2d257c2167f2d33bb/Elliptic Crypto support for OpenSSLSocketImpl
Summary:
- Enable Elliptic Crypto support for OpenSSL based SSLSocket instances
- More RI compliant usage of key types, client auth types, and server auth types
- Steps toward TLS_EMPTY_RENEGOTIATION_INFO_SCSV support, currently test updates
Details:
Elliptic Curve changes
CipherSuite updates for EC
- Adding KEY_EXCHANGE_EC* and corresponding CipherSuites Updated
isAnonymous, getKeyType (now renamed getServerKeyType) to handle
new EC cases.  Added new getAuthType for use by
checkServerTrusted callers.
- Restructured code to handle two SUITES_BY_CODE_* arrays
- Remove KEY_EXCHANGE_DH_* definitions which unused because the
corresponding CipherSuites were previously disabled.
- Changed AES CipherSuites definitions to use ""_CBC"" to match other definitions.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/CipherSuite.java
openssl EC
- NativeCrypto now registers TLS_EC_* cipher suites and has update default list
- Improved auth type arguments to checkClientTrusted/checkServerTrusted
- NativeCrypto support for emphemeral EC keys
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
luni/src/main/native/NativeCrypto.cpp
non-openssl SSL/TLS cleanups
- cleanup around code trying to cope with DiffieHellman vs DH since either should work.
- changed client to use new CipherSuite.getAuthType shared with NativeCrypto implementation
- changed server to use CipherSuite.getKeyType
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/HandshakeProtocol.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/KeyManagerImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImpl.java
Consolidate CertificateRequestType code into CipherSuite so that its
shared between java and openssl implementations. This includes the
KEY_TYPE_ string constants, TLS_CT_* byte constants and the 'String
keyType(byte)' (now renamed getClientKeyType) code that depends on them.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/CertificateRequest.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/CipherSuite.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImpl.java
Tests
Differentiate between supported list of cipher suites openssl-based
SSLSocket and SSLEngine based, since the SSLEngine code does not support EC.
luni/src/test/java/libcore/javax/net/ssl/SSLEngineTest.java
luni/src/test/java/libcore/javax/net/ssl/SSLSocketTest.java
Added testing for expected default cipher suites. Before we just ensured the values were valid.
luni/src/test/java/libcore/javax/net/ssl/SSLSocketFactoryTest.java
support/src/test/java/libcore/java/security/StandardNames.java
Updated to handle new EC cipher suites codes. Added test for new getClientKeyType.
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/CipherSuiteTest.java
Better use of ""standard names"" particularly to correctly deal with
the subtle differences between key types, client auth types, and
server auth types. TestKeyManager and TestTrustManager now verify
the values they are passed are acceptable.
support/src/test/java/libcore/java/security/StandardNames.java
support/src/test/java/libcore/javax/net/ssl/TestKeyManager.java
support/src/test/java/libcore/javax/net/ssl/TestTrustManager.java
Changed to timeout after 30 seconds and to log to reveal both client and server issues.
support/src/test/java/libcore/javax/net/ssl/TestSSLSocketPair.java
Bug: 3058375
Change-Id: I14d1d0285d591c99cc211324f3595a5be682cab1/Toward EC TLS support
Summary:
- javax.net.ssl tests are now working on the RI
- KeyManager can now handle EC_EC and EC_RSA
- OpenSSLSocketImpl.startHandshake now works if KeyManager contains EC certificates
Details:
Add CipherSuite.getKeyType to provide X509KeyManager key type strings,
refactored from OpenSSLServerSocketImpl.checkEnabledCipherSuites.
getKeyType is now also used in OpenSSLSocketImpl.startHandshake to
avoid calling setCertificate for unnecessary key types.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/CipherSuite.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
New CipherSuiteTest to cover new getKeyType as well as existing functionality
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/CipherSuiteTest.java
Add support to KeyManager implementation for key types of the form
EC_EC and EC_RSA. The first part implies the KeyPair algorithm (EC in
these new key types) with a potentially different signature algorithm
(EC vs RSA in these)
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/KeyManagerImpl.java
Update NativeCrypto.keyType to support EC_EC and EC_RSA in addition to
EC which was added earlier. Change from array of KEY_TYPES to named
KEY_TYPE_* constants.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
Overhauled KeyManagerFactoryTest to cover EC, EC_EC, EC_RSA cases
luni/src/test/java/libcore/javax/net/ssl/KeyManagerFactoryTest.java
support/src/test/java/libcore/java/security/StandardNames.java
Changed TestKeyStore.createKeyStore from always using BKS to now use
JKS on the RI between BC EC Keys and RI X509 certificates. Because JKS
requires a password, we now default ""password"" on the RI.
support/src/test/java/libcore/java/security/TestKeyStore.java
luni/src/test/java/libcore/javax/net/ssl/SSLContextTest.java
support/src/test/java/libcore/java/security/StandardNames.java
TestKeyStore.create now accepts key types like EC_RSA. Changed
TestKeyStore.createKeys to allow a PrivateKeyEntry to be specified for
signing to enable creation of EC_RSA test certificate. Added
getRootCertificate/rootCertificate to allow lookup of PrivateKeyEntry
for signing. Changed TestKeyStore.getPrivateKey to take explicit
signature algorithm to retrieve EC_EC vs EC_RSA entries.
support/src/test/java/libcore/java/security/TestKeyStore.java
luni/src/test/java/libcore/java/security/KeyStoreTest.java
luni/src/test/java/libcore/javax/net/ssl/KeyManagerFactoryTest.java
luni/src/test/java/libcore/java/security/cert/PKIXParametersTest.java
luni/src/test/java/libcore/javax/net/ssl/TrustManagerFactoryTest.java
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/NativeCryptoTest.java
support/src/test/java/libcore/java/security/StandardNames.java
Added support for EC cipher suites on the RI.  Also test with and
without new TLS_EMPTY_RENEGOTIATION_INFO_SCSV cipher suite which is
used to specify the new TLS secure renegotiation.
luni/src/test/java/libcore/javax/net/ssl/SSLEngineTest.java
luni/src/test/java/libcore/javax/net/ssl/SSLSocketTest.java
support/src/test/java/libcore/java/security/StandardNames.java
New TestKeyManager and additional logging in TestTrustManager. Logging
in both is disabled by default using DevNullPrintStream.
support/src/test/java/libcore/javax/net/ssl/TestKeyManager.java
support/src/test/java/libcore/javax/net/ssl/TestTrustManager.java
support/src/test/java/libcore/java/io/DevNullPrintStream.java
Bug: 3058375
Change-Id: Ia5e2a00a025858e10d1076b900886994b481e05a/"
conscrypt,"SSLSocket.close() should not throw an IOException if there is a problem sending a close notify
Bug: 3405962
Bug: 3350645
git cherry-pick -e 1c64b3adb85345659ac60ad82216268acba18764/am e7291d0d: am c009a7d9: am 1c64b3ad: SSLSocket.close() should not throw an IOException if there is a problem sending a close notify
* commit 'e7291d0d02c84ff650cd50297a348f61fe4978b6':
SSLSocket.close() should not throw an IOException if there is a problem sending a close notify/SSLSocket.close() should not throw an IOException if there is a problem sending a close notify
Bug: 3350645
Change-Id: I23844fc94a26175247538c95d8cddec90f368d64/HttpsURLConnection retry should not invoke X509TrustManager and HostnameVerifier more than once
Summary:
In 2.3, HttpsURLConnection was change to retry TLS connections as SSL
connections w/o compression to deal with servers that are TLS
intolerant. However, if the handshake proceeded to the point of
invoking the X509TrustManager, we should not retry. Similarly, if we
should not invoke the HostnameVerifier repeatedly, and need to wait
until the SSL handshake has completed.
Tested with (includes two new tests for this issue):
libcore/luni/src/test/java/libcore/javax/net/ssl/
libcore/luni/src/test/java/libcore/java/net/URLConnectionTest.java
libcore/luni/src/test/java/org/apache/harmony/luni/tests/internal/net/www/protocol/https/HttpsURLConnectionTest.java
Details:
HttpConnection.setupSecureSocket has been broken into two
pieces. setupSecureSocket now just does the SSL
handshaking. verifySecureSocketHostname now does the
verification. The old HttpConnection code was careful never to
assign its sslSocket field until verification was complete. A new
unverifiedSocket field is added to store the sslSocket before
verification is completed by verifySecureSocketHostname.
luni/src/main/java/org/apache/harmony/luni/internal/net/www/protocol/http/HttpConnection.java
HttpsEngine.makeConnection now skips TLS intolerant retry if the
reason for the makeSslConnection failure was a
CertificateException, since that implies that we failed during
certification validation after initial handshaking. We also
prevent retrying hostname verification by moving it out of
makeSslConnection and only doing it on new SSL connections,
tracking the changes to HttpConnection.setupSecureSocket mentioned
above. We also now skip the redundant call to setUpTransportIO in
makeSslConnection on reused SSLSockets.
luni/src/main/java/org/apache/harmony/luni/internal/net/www/protocol/https/HttpsURLConnectionImpl.java
Instead of throwing away the underlying CertificateExceptions, set
them as the cause of the SSLExceptions. This is what the RI does
in the case of X509TrustManager failures and is now used by
HttpsEngine.makeConnection.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Added new testConnectViaHttpsToUntrustedServer which makes sure
that connections are not retried on certificate verification
failure.
luni/src/test/java/libcore/java/net/URLConnectionTest.java
Added new test_SSLSocket_untrustedServer that verifies that an
SSLHandshakeException is thown containing a CertificateException
is thrown on certificate verification problems.
luni/src/test/java/libcore/javax/net/ssl/SSLSocketTest.java
Added second test CA and a new TestKeyStore.getClientCA2 test key
store that does not trust the primary test key stores. This is
useful for negative testing and is used in the above two new
tests.
support/src/test/java/libcore/java/security/TestKeyStore.java
Issue: http://code.google.com/p/android/issues/detail?id=13178
Bug: 3292412
Change-Id: I37136bb65f04d2bceaf2f32f542d6432c8b76ad4/Lots more bounds-checking/exception-throwing consistency.
Overflow-safe checks all round, plus better detail messages. This isn't
quite everything, but it's a large chunk of the work. Most notably, this
is all of io and nio.
There are numerous changes of exception priority here, and the harmony
tests noticed a subset of them in the nio code. I've modified our checked-out
copy of the tests to accept any of the throwable exceptions.
Change-Id: Id185f1228fb9a1d5fc9494e78375b5623fb0fe14/Rewrite all backwards comparisons.
Strictly, all the ones I could find. This is everything with 0 or null on the
left-hand side.
Note that this touches several incorrect bounds checks, which I haven't fixed:
I'm going to come back and finish that independent cleanup separately.
Change-Id: Ibdb054b53df9aace47c7d2a00ff19122190053e8/Elliptic Crypto support for OpenSSLSocketImpl
Summary:
- Enable Elliptic Crypto support for OpenSSL based SSLSocket instances
- More RI compliant usage of key types, client auth types, and server auth types
- Steps toward TLS_EMPTY_RENEGOTIATION_INFO_SCSV support, currently test updates
Details:
Elliptic Curve changes
CipherSuite updates for EC
- Adding KEY_EXCHANGE_EC* and corresponding CipherSuites Updated
isAnonymous, getKeyType (now renamed getServerKeyType) to handle
new EC cases.  Added new getAuthType for use by
checkServerTrusted callers.
- Restructured code to handle two SUITES_BY_CODE_* arrays
- Remove KEY_EXCHANGE_DH_* definitions which unused because the
corresponding CipherSuites were previously disabled.
- Changed AES CipherSuites definitions to use ""_CBC"" to match other definitions.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/CipherSuite.java
openssl EC
- NativeCrypto now registers TLS_EC_* cipher suites and has update default list
- Improved auth type arguments to checkClientTrusted/checkServerTrusted
- NativeCrypto support for emphemeral EC keys
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
luni/src/main/native/NativeCrypto.cpp
non-openssl SSL/TLS cleanups
- cleanup around code trying to cope with DiffieHellman vs DH since either should work.
- changed client to use new CipherSuite.getAuthType shared with NativeCrypto implementation
- changed server to use CipherSuite.getKeyType
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/HandshakeProtocol.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/KeyManagerImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImpl.java
Consolidate CertificateRequestType code into CipherSuite so that its
shared between java and openssl implementations. This includes the
KEY_TYPE_ string constants, TLS_CT_* byte constants and the 'String
keyType(byte)' (now renamed getClientKeyType) code that depends on them.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/CertificateRequest.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/CipherSuite.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/ClientHandshakeImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/ServerHandshakeImpl.java
Tests
Differentiate between supported list of cipher suites openssl-based
SSLSocket and SSLEngine based, since the SSLEngine code does not support EC.
luni/src/test/java/libcore/javax/net/ssl/SSLEngineTest.java
luni/src/test/java/libcore/javax/net/ssl/SSLSocketTest.java
Added testing for expected default cipher suites. Before we just ensured the values were valid.
luni/src/test/java/libcore/javax/net/ssl/SSLSocketFactoryTest.java
support/src/test/java/libcore/java/security/StandardNames.java
Updated to handle new EC cipher suites codes. Added test for new getClientKeyType.
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/CipherSuiteTest.java
Better use of ""standard names"" particularly to correctly deal with
the subtle differences between key types, client auth types, and
server auth types. TestKeyManager and TestTrustManager now verify
the values they are passed are acceptable.
support/src/test/java/libcore/java/security/StandardNames.java
support/src/test/java/libcore/javax/net/ssl/TestKeyManager.java
support/src/test/java/libcore/javax/net/ssl/TestTrustManager.java
Changed to timeout after 30 seconds and to log to reveal both client and server issues.
support/src/test/java/libcore/javax/net/ssl/TestSSLSocketPair.java
Bug: 3058375
Change-Id: I14d1d0285d591c99cc211324f3595a5be682cab1/Toward EC TLS support
Summary:
- javax.net.ssl tests are now working on the RI
- KeyManager can now handle EC_EC and EC_RSA
- OpenSSLSocketImpl.startHandshake now works if KeyManager contains EC certificates
Details:
Add CipherSuite.getKeyType to provide X509KeyManager key type strings,
refactored from OpenSSLServerSocketImpl.checkEnabledCipherSuites.
getKeyType is now also used in OpenSSLSocketImpl.startHandshake to
avoid calling setCertificate for unnecessary key types.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/CipherSuite.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
New CipherSuiteTest to cover new getKeyType as well as existing functionality
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/CipherSuiteTest.java
Add support to KeyManager implementation for key types of the form
EC_EC and EC_RSA. The first part implies the KeyPair algorithm (EC in
these new key types) with a potentially different signature algorithm
(EC vs RSA in these)
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/KeyManagerImpl.java
Update NativeCrypto.keyType to support EC_EC and EC_RSA in addition to
EC which was added earlier. Change from array of KEY_TYPES to named
KEY_TYPE_* constants.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
Overhauled KeyManagerFactoryTest to cover EC, EC_EC, EC_RSA cases
luni/src/test/java/libcore/javax/net/ssl/KeyManagerFactoryTest.java
support/src/test/java/libcore/java/security/StandardNames.java
Changed TestKeyStore.createKeyStore from always using BKS to now use
JKS on the RI between BC EC Keys and RI X509 certificates. Because JKS
requires a password, we now default ""password"" on the RI.
support/src/test/java/libcore/java/security/TestKeyStore.java
luni/src/test/java/libcore/javax/net/ssl/SSLContextTest.java
support/src/test/java/libcore/java/security/StandardNames.java
TestKeyStore.create now accepts key types like EC_RSA. Changed
TestKeyStore.createKeys to allow a PrivateKeyEntry to be specified for
signing to enable creation of EC_RSA test certificate. Added
getRootCertificate/rootCertificate to allow lookup of PrivateKeyEntry
for signing. Changed TestKeyStore.getPrivateKey to take explicit
signature algorithm to retrieve EC_EC vs EC_RSA entries.
support/src/test/java/libcore/java/security/TestKeyStore.java
luni/src/test/java/libcore/java/security/KeyStoreTest.java
luni/src/test/java/libcore/javax/net/ssl/KeyManagerFactoryTest.java
luni/src/test/java/libcore/java/security/cert/PKIXParametersTest.java
luni/src/test/java/libcore/javax/net/ssl/TrustManagerFactoryTest.java
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/NativeCryptoTest.java
support/src/test/java/libcore/java/security/StandardNames.java
Added support for EC cipher suites on the RI.  Also test with and
without new TLS_EMPTY_RENEGOTIATION_INFO_SCSV cipher suite which is
used to specify the new TLS secure renegotiation.
luni/src/test/java/libcore/javax/net/ssl/SSLEngineTest.java
luni/src/test/java/libcore/javax/net/ssl/SSLSocketTest.java
support/src/test/java/libcore/java/security/StandardNames.java
New TestKeyManager and additional logging in TestTrustManager. Logging
in both is disabled by default using DevNullPrintStream.
support/src/test/java/libcore/javax/net/ssl/TestKeyManager.java
support/src/test/java/libcore/javax/net/ssl/TestTrustManager.java
support/src/test/java/libcore/java/io/DevNullPrintStream.java
Bug: 3058375
Change-Id: Ia5e2a00a025858e10d1076b900886994b481e05a/am 8a720cce: TrustManager should include PrivateKeyEntry CAs, OpenSSLSocketImpl close fix, and debugging improvements
* commit '8a720cceee7ce319d647738dfeda3f302879f370':
TrustManager should include PrivateKeyEntry CAs, OpenSSLSocketImpl close fix, and debugging improvements/TrustManager should include PrivateKeyEntry CAs, OpenSSLSocketImpl close fix, and debugging improvements
Revert to older behavior of creating TrustAnchors from both
PrivateKeyEntry and TrustedCertificateEntry values from the
KeyStore. Added tests to better ensure this slighlt different
behavior from PKIXParameters. Also create the acceptedIssuers
proactively since the real memory cost is the X509Certificates
which are already found in the params.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/TrustManagerImpl.java
luni/src/test/java/libcore/javax/net/ssl/TrustManagerFactoryTest.java
luni/src/test/java/libcore/java/security/cert/PKIXParametersTest.java
Don't just free native state on issue with startHandshake, close
the SSLSocket. While the former addressed a CloseGuard issue, the
latter make sure that checkOpen throws SocketExceptions and we don't
leak a NullPointerException from NativeCrypto.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
Debugging improvements including minor refinements to recently
added NativeCrypto logging, more verbose TestKeyStore.dump output,
and a new TestTrustManager proxy class for logging X509TrustManager
behavior.
luni/src/main/native/NativeCrypto.cpp
support/src/test/java/libcore/java/security/TestKeyStore.java
support/src/test/java/libcore/javax/net/ssl/TestTrustManager.java
Change-Id: I317e1ca34d8e20c77e5cb9c5a5a58cb4ae98d829/"
conscrypt,"Retire SecurityManager.
This change removes all the code that was calling getSecurityManager, and
removes all use of AccessController.doPrivileged. It also changes the
implementation of AccessController so it doesn't actually do anything; it's
only there for source-level compatibility.
Bug: 2585285
Change-Id: I1f0295a4f12bce0316d8073011d8593fee116f71/"
conscrypt,"am 347b2a60: Avoid loading all CA certs into Zygote memory, lazily load instead (2 of 3)
* commit '347b2a604114602da9bc4ae040278f74d11c2f51':
Avoid loading all CA certs into Zygote memory, lazily load instead (2 of 3)/Avoid loading all CA certs into Zygote memory, lazily load instead (2 of 3)
Previously the CA certs stored in the BKS KeyStore at
/system/etc/security/cacerts.bks was loaded in the Zygote. As the the
number of CAs are started to increase, this is causing more and more
memory to be used for rarely used CAs. The new AndroidCAStore KeyStore
implementation reads the CAs as needed out of individual PEM
certificate files. The files can be efficiently found because they are
named based on a hash CA's subject name, similar to OpenSSL.
Bug: 1109242
Details:
build
Removing old cacerts.bks from GRANDFATHERED_ALL_PREBUILT and
adding new cacerts directory to core PRODUCT_PACKAGES
core/legacy_prebuilts.mk
target/product/core.mk
libcore
cacerts build changes. Move cacerts prebuilt logic to new
CaCerts.mk from NativeCode.mk where it didn't make sense. Updated
Android.mk's dalvik-host target to install new cacerts files.
Android.mk
CaCerts.mk
NativeCode.mk
Remove old cacerts.bks and add remove certimport.sh script used to
generate it. Preserved the useful comments from certimport.sh in
the new README.cacerts
luni/src/main/files/cacerts.bks
luni/src/main/files/certimport.sh
luni/src/main/files/README.cacerts
Recanonicalize cacerts files using updated vendor/google/tools/cacerts/certimport.py
(See below discussion of certimport.py changes for details)
luni/src/main/files/cacerts/00673b5b.0
luni/src/main/files/cacerts/03e16f6c.0
luni/src/main/files/cacerts/08aef7bb.0
luni/src/main/files/cacerts/0d188d89.0
luni/src/main/files/cacerts/10531352.0
luni/src/main/files/cacerts/111e6273.0
luni/src/main/files/cacerts/1155c94b.0
luni/src/main/files/cacerts/119afc2e.0
luni/src/main/files/cacerts/11a09b38.0
luni/src/main/files/cacerts/12d55845.0
luni/src/main/files/cacerts/17b51fe6.0
luni/src/main/files/cacerts/1920cacb.0
luni/src/main/files/cacerts/1dac3003.0
luni/src/main/files/cacerts/1dbdda5b.0
luni/src/main/files/cacerts/1dcd6f4c.0
luni/src/main/files/cacerts/1df5ec47.0
luni/src/main/files/cacerts/1e8e7201.0
luni/src/main/files/cacerts/1eb37bdf.0
luni/src/main/files/cacerts/219d9499.0
luni/src/main/files/cacerts/23f4c490.0
luni/src/main/files/cacerts/27af790d.0
luni/src/main/files/cacerts/2afc57aa.0
luni/src/main/files/cacerts/2e8714cb.0
luni/src/main/files/cacerts/2fa87019.0
luni/src/main/files/cacerts/2fb1850a.0
luni/src/main/files/cacerts/33815e15.0
luni/src/main/files/cacerts/343eb6cb.0
luni/src/main/files/cacerts/399e7759.0
luni/src/main/files/cacerts/3a3b02ce.0
luni/src/main/files/cacerts/3ad48a91.0
luni/src/main/files/cacerts/3c58f906.0
luni/src/main/files/cacerts/3c860d51.0
luni/src/main/files/cacerts/3d441de8.0
luni/src/main/files/cacerts/3e7271e8.0
luni/src/main/files/cacerts/418595b9.0
luni/src/main/files/cacerts/455f1b52.0
luni/src/main/files/cacerts/46b2fd3b.0
luni/src/main/files/cacerts/48478734.0
luni/src/main/files/cacerts/4d654d1d.0
luni/src/main/files/cacerts/4e18c148.0
luni/src/main/files/cacerts/4fbd6bfa.0
luni/src/main/files/cacerts/5021a0a2.0
luni/src/main/files/cacerts/5046c355.0
luni/src/main/files/cacerts/524d9b43.0
luni/src/main/files/cacerts/56b8a0b6.0
luni/src/main/files/cacerts/57692373.0
luni/src/main/files/cacerts/58a44af1.0
luni/src/main/files/cacerts/594f1775.0
luni/src/main/files/cacerts/5a3f0ff8.0
luni/src/main/files/cacerts/5a5372fc.0
luni/src/main/files/cacerts/5cf9d536.0
luni/src/main/files/cacerts/5e4e69e7.0
luni/src/main/files/cacerts/60afe812.0
luni/src/main/files/cacerts/635ccfd5.0
luni/src/main/files/cacerts/67495436.0
luni/src/main/files/cacerts/69105f4f.0
luni/src/main/files/cacerts/6adf0799.0
luni/src/main/files/cacerts/6e8bf996.0
luni/src/main/files/cacerts/6fcc125d.0
luni/src/main/files/cacerts/72f369af.0
luni/src/main/files/cacerts/72fa7371.0
luni/src/main/files/cacerts/74c26bd0.0
luni/src/main/files/cacerts/75680d2e.0
luni/src/main/files/cacerts/7651b327.0
luni/src/main/files/cacerts/76579174.0
luni/src/main/files/cacerts/7999be0d.0
luni/src/main/files/cacerts/7a481e66.0
luni/src/main/files/cacerts/7a819ef2.0
luni/src/main/files/cacerts/7d3cd826.0
luni/src/main/files/cacerts/7d453d8f.0
luni/src/main/files/cacerts/81b9768f.0
luni/src/main/files/cacerts/8470719d.0
luni/src/main/files/cacerts/84cba82f.0
luni/src/main/files/cacerts/85cde254.0
luni/src/main/files/cacerts/86212b19.0
luni/src/main/files/cacerts/87753b0d.0
luni/src/main/files/cacerts/882de061.0
luni/src/main/files/cacerts/895cad1a.0
luni/src/main/files/cacerts/89c02a45.0
luni/src/main/files/cacerts/8f7b96c4.0
luni/src/main/files/cacerts/9339512a.0
luni/src/main/files/cacerts/9685a493.0
luni/src/main/files/cacerts/9772ca32.0
luni/src/main/files/cacerts/9d6523ce.0
luni/src/main/files/cacerts/9dbefe7b.0
luni/src/main/files/cacerts/9f533518.0
luni/src/main/files/cacerts/a0bc6fbb.0
luni/src/main/files/cacerts/a15b3b6b.0
luni/src/main/files/cacerts/a3896b44.0
luni/src/main/files/cacerts/a7605362.0
luni/src/main/files/cacerts/a7d2cf64.0
luni/src/main/files/cacerts/ab5346f4.0
luni/src/main/files/cacerts/add67345.0
luni/src/main/files/cacerts/b0f3e76e.0
luni/src/main/files/cacerts/bc3f2570.0
luni/src/main/files/cacerts/bcdd5959.0
luni/src/main/files/cacerts/bda4cc84.0
luni/src/main/files/cacerts/bdacca6f.0
luni/src/main/files/cacerts/bf64f35b.0
luni/src/main/files/cacerts/c0cafbd2.0
luni/src/main/files/cacerts/c215bc69.0
luni/src/main/files/cacerts/c33a80d4.0
luni/src/main/files/cacerts/c527e4ab.0
luni/src/main/files/cacerts/c7e2a638.0
luni/src/main/files/cacerts/c8763593.0
luni/src/main/files/cacerts/ccc52f49.0
luni/src/main/files/cacerts/cdaebb72.0
luni/src/main/files/cacerts/cf701eeb.0
luni/src/main/files/cacerts/d16a5865.0
luni/src/main/files/cacerts/d537fba6.0
luni/src/main/files/cacerts/d64f06f3.0
luni/src/main/files/cacerts/d777342d.0
luni/src/main/files/cacerts/d8274e24.0
luni/src/main/files/cacerts/dbc54cab.0
luni/src/main/files/cacerts/ddc328ff.0
luni/src/main/files/cacerts/e48193cf.0
luni/src/main/files/cacerts/e60bf0c0.0
luni/src/main/files/cacerts/e775ed2d.0
luni/src/main/files/cacerts/e7b8d656.0
luni/src/main/files/cacerts/e8651083.0
luni/src/main/files/cacerts/ea169617.0
luni/src/main/files/cacerts/eb375c3e.0
luni/src/main/files/cacerts/ed049835.0
luni/src/main/files/cacerts/ed524cf5.0
luni/src/main/files/cacerts/ee7cd6fb.0
luni/src/main/files/cacerts/f4996e82.0
luni/src/main/files/cacerts/f58a60fe.0
luni/src/main/files/cacerts/f61bff45.0
luni/src/main/files/cacerts/f80cc7f6.0
luni/src/main/files/cacerts/fac084d7.0
luni/src/main/files/cacerts/facacbc6.0
luni/src/main/files/cacerts/fde84897.0
luni/src/main/files/cacerts/ff783690.0
Change IntegralToString.intToHexString to take width argument to
allow for leading zero padding. Updated existing callers to
specify 0 padding desired. Add testing of new padding
functionality.
luni/src/main/java/java/lang/Character.java
luni/src/main/java/java/lang/Integer.java
luni/src/main/java/java/lang/IntegralToString.java
luni/src/test/java/libcore/java/lang/IntegralToStringTest.java
Improved to throw Exceptions with proper causes
luni/src/main/java/java/security/KeyStore.java
luni/src/main/java/java/security/Policy.java
luni/src/main/java/java/security/cert/CertificateFactory.java
luni/src/main/java/javax/crypto/Cipher.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSignature.java
Indentation fixes
luni/src/main/java/java/security/SecureRandom.java
Fix X509CRLSelector.getIssuerNames to clone result and added test to cover this.
luni/src/main/java/java/security/cert/X509CRLSelector.java
luni/src/test/java/libcore/java/security/cert/X509CRLSelectorTest.java
Fixed bug where we created an X500Principal via a String
representation instead of from its original encoded bytes. This
led to a difficult to track down bug where CA 418595b9.0 where the
NativeCode.X509_NAME_hash of a Harmony (but not BouncyCastle)
X509Certificate would not hash to the expected value because the
encoded form used an ASN.1 PrintableString instead of the
UTF8String form found in the original certificate.
luni/src/main/java/org/apache/harmony/security/x501/Name.java
Add a new RootKeyStoreSpi and register it as the
AndroidCAStore. This new read-only KeyStore implementation that
looks for certificates in $ANDROID_ROOT/etc/security/cacerts/
directory, which is /system/etc/security/cacerts/ on devices. The
files are stored in the directory based on the older md5 based
OpenSSL X509_NAME_hash function (now referred to as
X509_NAME_hash_old in OpenSSL 1.0)
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/RootKeyStoreSpi.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
Added OpenSSL compatible X509_NAME_hash and X509_NAME_hash_old
functions for producting an int hash value from an X500Principal.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
Changed TrustManagerFactoryImpl to use AndroidCAStore for its default KeyStore
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/TrustManagerFactoryImpl.java
Changed TrustManagerImpl to be AndroidCAStore aware. If it detects
an AndroidCAStore, it avoids generating the acceptedIssuers array
at constructions, since doing so would force us to parse all
certificates in the store and the value is only typically used by
SSLServerSockets when requesting a client certifcate. Because we
don't load all the trusted CAs into the IndexedPKIXParameters at
startup in the case of AndroidCAStore, we now check for new CAs
when examining the cert chain for unnecessary TrustAnchors and for
a newly discovered issuer at the end of the chain before
validation.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/TrustManagerImpl.java
Updated KeyStoreTest to cope with read only KeyStore. Update
test_cacerts_bks (now renamed test_cacerts) to use the
AndroidCAStore for validating system CA certificate
validity. Register AndroidCAStore as an expected KeyStore type
with StandardNames.
luni/src/test/java/libcore/java/security/KeyStoreTest.java
support/src/test/java/libcore/java/security/StandardNames.java
Added test of X500Principal serialization while investigating Name
encoding issue. However, the actual Name bug was found and
verified by the new test_cacerts test.
luni/src/test/java/libcore/javax/security/auth/x500/X500PrincipalTest.java
vendor/google
Change canonical format for checked in cacerts to have PEM
certificate at the top, as required by Harmony's X.509
CertificateFactory.
tools/cacerts/certimport.py
Change-Id: If0c9de430f13babb07f96a1177897c536f3db08d/"
conscrypt,"Fix more FindBugs warnings: BC_EQUALS_METHOD_SHOULD_WORK_FOR_ALL_OBJECTS.
""The equals(Object o) method shouldn't make any assumptions about the type
of o. It should simply return false if o is not the same type as this.""
Change-Id: Ib16eb57e8876ec117634b4c9b069a4dccc61c657/"
conscrypt,"am 347b2a60: Avoid loading all CA certs into Zygote memory, lazily load instead (2 of 3)
* commit '347b2a604114602da9bc4ae040278f74d11c2f51':
Avoid loading all CA certs into Zygote memory, lazily load instead (2 of 3)/Avoid loading all CA certs into Zygote memory, lazily load instead (2 of 3)
Previously the CA certs stored in the BKS KeyStore at
/system/etc/security/cacerts.bks was loaded in the Zygote. As the the
number of CAs are started to increase, this is causing more and more
memory to be used for rarely used CAs. The new AndroidCAStore KeyStore
implementation reads the CAs as needed out of individual PEM
certificate files. The files can be efficiently found because they are
named based on a hash CA's subject name, similar to OpenSSL.
Bug: 1109242
Details:
build
Removing old cacerts.bks from GRANDFATHERED_ALL_PREBUILT and
adding new cacerts directory to core PRODUCT_PACKAGES
core/legacy_prebuilts.mk
target/product/core.mk
libcore
cacerts build changes. Move cacerts prebuilt logic to new
CaCerts.mk from NativeCode.mk where it didn't make sense. Updated
Android.mk's dalvik-host target to install new cacerts files.
Android.mk
CaCerts.mk
NativeCode.mk
Remove old cacerts.bks and add remove certimport.sh script used to
generate it. Preserved the useful comments from certimport.sh in
the new README.cacerts
luni/src/main/files/cacerts.bks
luni/src/main/files/certimport.sh
luni/src/main/files/README.cacerts
Recanonicalize cacerts files using updated vendor/google/tools/cacerts/certimport.py
(See below discussion of certimport.py changes for details)
luni/src/main/files/cacerts/00673b5b.0
luni/src/main/files/cacerts/03e16f6c.0
luni/src/main/files/cacerts/08aef7bb.0
luni/src/main/files/cacerts/0d188d89.0
luni/src/main/files/cacerts/10531352.0
luni/src/main/files/cacerts/111e6273.0
luni/src/main/files/cacerts/1155c94b.0
luni/src/main/files/cacerts/119afc2e.0
luni/src/main/files/cacerts/11a09b38.0
luni/src/main/files/cacerts/12d55845.0
luni/src/main/files/cacerts/17b51fe6.0
luni/src/main/files/cacerts/1920cacb.0
luni/src/main/files/cacerts/1dac3003.0
luni/src/main/files/cacerts/1dbdda5b.0
luni/src/main/files/cacerts/1dcd6f4c.0
luni/src/main/files/cacerts/1df5ec47.0
luni/src/main/files/cacerts/1e8e7201.0
luni/src/main/files/cacerts/1eb37bdf.0
luni/src/main/files/cacerts/219d9499.0
luni/src/main/files/cacerts/23f4c490.0
luni/src/main/files/cacerts/27af790d.0
luni/src/main/files/cacerts/2afc57aa.0
luni/src/main/files/cacerts/2e8714cb.0
luni/src/main/files/cacerts/2fa87019.0
luni/src/main/files/cacerts/2fb1850a.0
luni/src/main/files/cacerts/33815e15.0
luni/src/main/files/cacerts/343eb6cb.0
luni/src/main/files/cacerts/399e7759.0
luni/src/main/files/cacerts/3a3b02ce.0
luni/src/main/files/cacerts/3ad48a91.0
luni/src/main/files/cacerts/3c58f906.0
luni/src/main/files/cacerts/3c860d51.0
luni/src/main/files/cacerts/3d441de8.0
luni/src/main/files/cacerts/3e7271e8.0
luni/src/main/files/cacerts/418595b9.0
luni/src/main/files/cacerts/455f1b52.0
luni/src/main/files/cacerts/46b2fd3b.0
luni/src/main/files/cacerts/48478734.0
luni/src/main/files/cacerts/4d654d1d.0
luni/src/main/files/cacerts/4e18c148.0
luni/src/main/files/cacerts/4fbd6bfa.0
luni/src/main/files/cacerts/5021a0a2.0
luni/src/main/files/cacerts/5046c355.0
luni/src/main/files/cacerts/524d9b43.0
luni/src/main/files/cacerts/56b8a0b6.0
luni/src/main/files/cacerts/57692373.0
luni/src/main/files/cacerts/58a44af1.0
luni/src/main/files/cacerts/594f1775.0
luni/src/main/files/cacerts/5a3f0ff8.0
luni/src/main/files/cacerts/5a5372fc.0
luni/src/main/files/cacerts/5cf9d536.0
luni/src/main/files/cacerts/5e4e69e7.0
luni/src/main/files/cacerts/60afe812.0
luni/src/main/files/cacerts/635ccfd5.0
luni/src/main/files/cacerts/67495436.0
luni/src/main/files/cacerts/69105f4f.0
luni/src/main/files/cacerts/6adf0799.0
luni/src/main/files/cacerts/6e8bf996.0
luni/src/main/files/cacerts/6fcc125d.0
luni/src/main/files/cacerts/72f369af.0
luni/src/main/files/cacerts/72fa7371.0
luni/src/main/files/cacerts/74c26bd0.0
luni/src/main/files/cacerts/75680d2e.0
luni/src/main/files/cacerts/7651b327.0
luni/src/main/files/cacerts/76579174.0
luni/src/main/files/cacerts/7999be0d.0
luni/src/main/files/cacerts/7a481e66.0
luni/src/main/files/cacerts/7a819ef2.0
luni/src/main/files/cacerts/7d3cd826.0
luni/src/main/files/cacerts/7d453d8f.0
luni/src/main/files/cacerts/81b9768f.0
luni/src/main/files/cacerts/8470719d.0
luni/src/main/files/cacerts/84cba82f.0
luni/src/main/files/cacerts/85cde254.0
luni/src/main/files/cacerts/86212b19.0
luni/src/main/files/cacerts/87753b0d.0
luni/src/main/files/cacerts/882de061.0
luni/src/main/files/cacerts/895cad1a.0
luni/src/main/files/cacerts/89c02a45.0
luni/src/main/files/cacerts/8f7b96c4.0
luni/src/main/files/cacerts/9339512a.0
luni/src/main/files/cacerts/9685a493.0
luni/src/main/files/cacerts/9772ca32.0
luni/src/main/files/cacerts/9d6523ce.0
luni/src/main/files/cacerts/9dbefe7b.0
luni/src/main/files/cacerts/9f533518.0
luni/src/main/files/cacerts/a0bc6fbb.0
luni/src/main/files/cacerts/a15b3b6b.0
luni/src/main/files/cacerts/a3896b44.0
luni/src/main/files/cacerts/a7605362.0
luni/src/main/files/cacerts/a7d2cf64.0
luni/src/main/files/cacerts/ab5346f4.0
luni/src/main/files/cacerts/add67345.0
luni/src/main/files/cacerts/b0f3e76e.0
luni/src/main/files/cacerts/bc3f2570.0
luni/src/main/files/cacerts/bcdd5959.0
luni/src/main/files/cacerts/bda4cc84.0
luni/src/main/files/cacerts/bdacca6f.0
luni/src/main/files/cacerts/bf64f35b.0
luni/src/main/files/cacerts/c0cafbd2.0
luni/src/main/files/cacerts/c215bc69.0
luni/src/main/files/cacerts/c33a80d4.0
luni/src/main/files/cacerts/c527e4ab.0
luni/src/main/files/cacerts/c7e2a638.0
luni/src/main/files/cacerts/c8763593.0
luni/src/main/files/cacerts/ccc52f49.0
luni/src/main/files/cacerts/cdaebb72.0
luni/src/main/files/cacerts/cf701eeb.0
luni/src/main/files/cacerts/d16a5865.0
luni/src/main/files/cacerts/d537fba6.0
luni/src/main/files/cacerts/d64f06f3.0
luni/src/main/files/cacerts/d777342d.0
luni/src/main/files/cacerts/d8274e24.0
luni/src/main/files/cacerts/dbc54cab.0
luni/src/main/files/cacerts/ddc328ff.0
luni/src/main/files/cacerts/e48193cf.0
luni/src/main/files/cacerts/e60bf0c0.0
luni/src/main/files/cacerts/e775ed2d.0
luni/src/main/files/cacerts/e7b8d656.0
luni/src/main/files/cacerts/e8651083.0
luni/src/main/files/cacerts/ea169617.0
luni/src/main/files/cacerts/eb375c3e.0
luni/src/main/files/cacerts/ed049835.0
luni/src/main/files/cacerts/ed524cf5.0
luni/src/main/files/cacerts/ee7cd6fb.0
luni/src/main/files/cacerts/f4996e82.0
luni/src/main/files/cacerts/f58a60fe.0
luni/src/main/files/cacerts/f61bff45.0
luni/src/main/files/cacerts/f80cc7f6.0
luni/src/main/files/cacerts/fac084d7.0
luni/src/main/files/cacerts/facacbc6.0
luni/src/main/files/cacerts/fde84897.0
luni/src/main/files/cacerts/ff783690.0
Change IntegralToString.intToHexString to take width argument to
allow for leading zero padding. Updated existing callers to
specify 0 padding desired. Add testing of new padding
functionality.
luni/src/main/java/java/lang/Character.java
luni/src/main/java/java/lang/Integer.java
luni/src/main/java/java/lang/IntegralToString.java
luni/src/test/java/libcore/java/lang/IntegralToStringTest.java
Improved to throw Exceptions with proper causes
luni/src/main/java/java/security/KeyStore.java
luni/src/main/java/java/security/Policy.java
luni/src/main/java/java/security/cert/CertificateFactory.java
luni/src/main/java/javax/crypto/Cipher.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSignature.java
Indentation fixes
luni/src/main/java/java/security/SecureRandom.java
Fix X509CRLSelector.getIssuerNames to clone result and added test to cover this.
luni/src/main/java/java/security/cert/X509CRLSelector.java
luni/src/test/java/libcore/java/security/cert/X509CRLSelectorTest.java
Fixed bug where we created an X500Principal via a String
representation instead of from its original encoded bytes. This
led to a difficult to track down bug where CA 418595b9.0 where the
NativeCode.X509_NAME_hash of a Harmony (but not BouncyCastle)
X509Certificate would not hash to the expected value because the
encoded form used an ASN.1 PrintableString instead of the
UTF8String form found in the original certificate.
luni/src/main/java/org/apache/harmony/security/x501/Name.java
Add a new RootKeyStoreSpi and register it as the
AndroidCAStore. This new read-only KeyStore implementation that
looks for certificates in $ANDROID_ROOT/etc/security/cacerts/
directory, which is /system/etc/security/cacerts/ on devices. The
files are stored in the directory based on the older md5 based
OpenSSL X509_NAME_hash function (now referred to as
X509_NAME_hash_old in OpenSSL 1.0)
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/RootKeyStoreSpi.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
Added OpenSSL compatible X509_NAME_hash and X509_NAME_hash_old
functions for producting an int hash value from an X500Principal.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
Changed TrustManagerFactoryImpl to use AndroidCAStore for its default KeyStore
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/TrustManagerFactoryImpl.java
Changed TrustManagerImpl to be AndroidCAStore aware. If it detects
an AndroidCAStore, it avoids generating the acceptedIssuers array
at constructions, since doing so would force us to parse all
certificates in the store and the value is only typically used by
SSLServerSockets when requesting a client certifcate. Because we
don't load all the trusted CAs into the IndexedPKIXParameters at
startup in the case of AndroidCAStore, we now check for new CAs
when examining the cert chain for unnecessary TrustAnchors and for
a newly discovered issuer at the end of the chain before
validation.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/TrustManagerImpl.java
Updated KeyStoreTest to cope with read only KeyStore. Update
test_cacerts_bks (now renamed test_cacerts) to use the
AndroidCAStore for validating system CA certificate
validity. Register AndroidCAStore as an expected KeyStore type
with StandardNames.
luni/src/test/java/libcore/java/security/KeyStoreTest.java
support/src/test/java/libcore/java/security/StandardNames.java
Added test of X500Principal serialization while investigating Name
encoding issue. However, the actual Name bug was found and
verified by the new test_cacerts test.
luni/src/test/java/libcore/javax/security/auth/x500/X500PrincipalTest.java
vendor/google
Change canonical format for checked in cacerts to have PEM
certificate at the top, as required by Harmony's X.509
CertificateFactory.
tools/cacerts/certimport.py
Change-Id: If0c9de430f13babb07f96a1177897c536f3db08d/Don't cache the underlying Socket's underlying SocketImpl's underlying FileDescriptor in OpenSSLSocketImpl.
(OpenSSLSocketImpl, of course, being a Socket, not a SocketImpl.)
Bug: 4192414
git cherry-pick dc33f53f38600943c84146320c748e3c46fd2e7b
Change-Id: I8f481e0fe217aac782ad9d9e9053681ad69e62ef/Don't cache the underlying Socket's underlying SocketImpl's underlying FileDescriptor in OpenSSLSocketImpl.
(OpenSSLSocketImpl, of course, being a Socket, not a SocketImpl.)
Bug: 4192414
Change-Id: I3c7d0fed70b1b98dc8fcc73f35b3feb0e1eeb2f9/Fix NativeCrypto FindBugs warnings.
Change-Id: I102367575b1257582bb20c659223e3f02650fda4/"
conscrypt,"Make CertInstaller installed CA certs trusted by applications via default TrustManager (2 of 6)
frameworks/base
Adding IKeyChainService APIs for CertInstaller and Settings use
keystore/java/android/security/IKeyChainService.aidl
libcore
Improve exceptions to include more information
luni/src/main/java/javax/security/auth/x500/X500Principal.java
Move guts of RootKeyStoreSpi to TrustedCertificateStore, leaving only KeyStoreSpi methods.
Added support for adding user CAs in a separate directory for system.
Added support for removing system CAs by placing a copy in a sytem directory
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/RootKeyStoreSpi.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/TrustedCertificateStore.java
Formerly static methods on RootKeyStoreSpi are now instance methods on TrustedCertificateStore
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/TrustManagerImpl.java
Added test for NativeCrypto.X509_NAME_hash_old and X509_NAME_hash
to make sure the implementing algorithms doe not change since
TrustedCertificateStore depend on X509_NAME_hash_old (OpenSSL
changed the algorithm from MD5 to SHA1 when moving from 0.9.8 to
1.0.0)
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/NativeCryptoTest.java
Extensive test of new TrustedCertificateStore behavior
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/TrustedCertificateStoreTest.java
TestKeyStore improvements
- Refactored TestKeyStore to provide simpler createCA method (and
internal createCertificate)
- Cleaned up to remove use of BouncyCastle specific X509Principal
in the TestKeyStore API when the public X500Principal would do.
- Cleaned up TestKeyStore support methods to not throw Exception
to remove need for static blocks for catch clauses in tests.
support/src/test/java/libcore/java/security/TestKeyStore.java
luni/src/test/java/libcore/java/security/KeyStoreTest.java
luni/src/test/java/org/apache/harmony/xnet/provider/jsse/NativeCryptoTest.java
Added private PKIXParameters contructor for use by
IndexedPKIXParameters to avoid wart of having to lookup and pass
a TrustAnchor to satisfy the super-class sanity check.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/TrustManagerImpl.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/IndexedPKIXParameters.java
luni/src/main/java/java/security/cert/PKIXParameters.java
packages/apps/CertInstaller
Change CertInstaller to call IKeyChainService.installCertificate
for CA certs to pass them to the KeyChainServiceTest which will
make them available to all apps through the
TrustedCertificateStore. Change PKCS12 extraction to use AsyncTask.
src/com/android/certinstaller/CertInstaller.java
Added installCaCertsToKeyChain and hasCaCerts accessor for use by
CertInstaller. Use hasUserCertificate() internally. Cleanup coding
style.
src/com/android/certinstaller/CredentialHelper.java
packages/apps/KeyChain
Added MANAGE_ACCOUNTS so that IKeyChainService.reset
implementation can remove KeyChain accounts.
AndroidManifest.xml
Implement new IKeyChainService methods:
- Added IKeyChainService.installCaCertificate to install certs
provided by CertInstaller using the TrustedCertificateStore.
- Added IKeyChainService.reset to allow Settings to remove the
KeyChain accounts so that any app granted access to keystore
credentials are revoked when the keystore is reset.
src/com/android/keychain/KeyChainService.java
packages/apps/Settings
Changed com.android.credentials.RESET credential reset action to
also call IKeyChainService.reset to remove any installed user CAs
and remove KeyChain accounts to have AccountManager revoke
credential granted to private keys removed during the RESET.
src/com/android/settings/CredentialStorage.java
Added toast text value for failure case
res/values/strings.xml
system/core
Have init create world readable /data/misc/keychain to allow apps
to access user added CA certificates installed by the CertInstaller.
rootdir/init.rc
Change-Id: Ief57672eea38b3eece23b14c94dedb9ea4713744/Don't cache the underlying Socket's underlying SocketImpl's underlying FileDescriptor in OpenSSLSocketImpl.
(OpenSSLSocketImpl, of course, being a Socket, not a SocketImpl.)
Bug: 4192414
git cherry-pick dc33f53f38600943c84146320c748e3c46fd2e7b
Change-Id: I8f481e0fe217aac782ad9d9e9053681ad69e62ef/Don't cache the underlying Socket's underlying SocketImpl's underlying FileDescriptor in OpenSSLSocketImpl.
(OpenSSLSocketImpl, of course, being a Socket, not a SocketImpl.)
Bug: 4192414
Change-Id: I3c7d0fed70b1b98dc8fcc73f35b3feb0e1eeb2f9/"
conscrypt,"am 347b2a60: Avoid loading all CA certs into Zygote memory, lazily load instead (2 of 3)
* commit '347b2a604114602da9bc4ae040278f74d11c2f51':
Avoid loading all CA certs into Zygote memory, lazily load instead (2 of 3)/Avoid loading all CA certs into Zygote memory, lazily load instead (2 of 3)
Previously the CA certs stored in the BKS KeyStore at
/system/etc/security/cacerts.bks was loaded in the Zygote. As the the
number of CAs are started to increase, this is causing more and more
memory to be used for rarely used CAs. The new AndroidCAStore KeyStore
implementation reads the CAs as needed out of individual PEM
certificate files. The files can be efficiently found because they are
named based on a hash CA's subject name, similar to OpenSSL.
Bug: 1109242
Details:
build
Removing old cacerts.bks from GRANDFATHERED_ALL_PREBUILT and
adding new cacerts directory to core PRODUCT_PACKAGES
core/legacy_prebuilts.mk
target/product/core.mk
libcore
cacerts build changes. Move cacerts prebuilt logic to new
CaCerts.mk from NativeCode.mk where it didn't make sense. Updated
Android.mk's dalvik-host target to install new cacerts files.
Android.mk
CaCerts.mk
NativeCode.mk
Remove old cacerts.bks and add remove certimport.sh script used to
generate it. Preserved the useful comments from certimport.sh in
the new README.cacerts
luni/src/main/files/cacerts.bks
luni/src/main/files/certimport.sh
luni/src/main/files/README.cacerts
Recanonicalize cacerts files using updated vendor/google/tools/cacerts/certimport.py
(See below discussion of certimport.py changes for details)
luni/src/main/files/cacerts/00673b5b.0
luni/src/main/files/cacerts/03e16f6c.0
luni/src/main/files/cacerts/08aef7bb.0
luni/src/main/files/cacerts/0d188d89.0
luni/src/main/files/cacerts/10531352.0
luni/src/main/files/cacerts/111e6273.0
luni/src/main/files/cacerts/1155c94b.0
luni/src/main/files/cacerts/119afc2e.0
luni/src/main/files/cacerts/11a09b38.0
luni/src/main/files/cacerts/12d55845.0
luni/src/main/files/cacerts/17b51fe6.0
luni/src/main/files/cacerts/1920cacb.0
luni/src/main/files/cacerts/1dac3003.0
luni/src/main/files/cacerts/1dbdda5b.0
luni/src/main/files/cacerts/1dcd6f4c.0
luni/src/main/files/cacerts/1df5ec47.0
luni/src/main/files/cacerts/1e8e7201.0
luni/src/main/files/cacerts/1eb37bdf.0
luni/src/main/files/cacerts/219d9499.0
luni/src/main/files/cacerts/23f4c490.0
luni/src/main/files/cacerts/27af790d.0
luni/src/main/files/cacerts/2afc57aa.0
luni/src/main/files/cacerts/2e8714cb.0
luni/src/main/files/cacerts/2fa87019.0
luni/src/main/files/cacerts/2fb1850a.0
luni/src/main/files/cacerts/33815e15.0
luni/src/main/files/cacerts/343eb6cb.0
luni/src/main/files/cacerts/399e7759.0
luni/src/main/files/cacerts/3a3b02ce.0
luni/src/main/files/cacerts/3ad48a91.0
luni/src/main/files/cacerts/3c58f906.0
luni/src/main/files/cacerts/3c860d51.0
luni/src/main/files/cacerts/3d441de8.0
luni/src/main/files/cacerts/3e7271e8.0
luni/src/main/files/cacerts/418595b9.0
luni/src/main/files/cacerts/455f1b52.0
luni/src/main/files/cacerts/46b2fd3b.0
luni/src/main/files/cacerts/48478734.0
luni/src/main/files/cacerts/4d654d1d.0
luni/src/main/files/cacerts/4e18c148.0
luni/src/main/files/cacerts/4fbd6bfa.0
luni/src/main/files/cacerts/5021a0a2.0
luni/src/main/files/cacerts/5046c355.0
luni/src/main/files/cacerts/524d9b43.0
luni/src/main/files/cacerts/56b8a0b6.0
luni/src/main/files/cacerts/57692373.0
luni/src/main/files/cacerts/58a44af1.0
luni/src/main/files/cacerts/594f1775.0
luni/src/main/files/cacerts/5a3f0ff8.0
luni/src/main/files/cacerts/5a5372fc.0
luni/src/main/files/cacerts/5cf9d536.0
luni/src/main/files/cacerts/5e4e69e7.0
luni/src/main/files/cacerts/60afe812.0
luni/src/main/files/cacerts/635ccfd5.0
luni/src/main/files/cacerts/67495436.0
luni/src/main/files/cacerts/69105f4f.0
luni/src/main/files/cacerts/6adf0799.0
luni/src/main/files/cacerts/6e8bf996.0
luni/src/main/files/cacerts/6fcc125d.0
luni/src/main/files/cacerts/72f369af.0
luni/src/main/files/cacerts/72fa7371.0
luni/src/main/files/cacerts/74c26bd0.0
luni/src/main/files/cacerts/75680d2e.0
luni/src/main/files/cacerts/7651b327.0
luni/src/main/files/cacerts/76579174.0
luni/src/main/files/cacerts/7999be0d.0
luni/src/main/files/cacerts/7a481e66.0
luni/src/main/files/cacerts/7a819ef2.0
luni/src/main/files/cacerts/7d3cd826.0
luni/src/main/files/cacerts/7d453d8f.0
luni/src/main/files/cacerts/81b9768f.0
luni/src/main/files/cacerts/8470719d.0
luni/src/main/files/cacerts/84cba82f.0
luni/src/main/files/cacerts/85cde254.0
luni/src/main/files/cacerts/86212b19.0
luni/src/main/files/cacerts/87753b0d.0
luni/src/main/files/cacerts/882de061.0
luni/src/main/files/cacerts/895cad1a.0
luni/src/main/files/cacerts/89c02a45.0
luni/src/main/files/cacerts/8f7b96c4.0
luni/src/main/files/cacerts/9339512a.0
luni/src/main/files/cacerts/9685a493.0
luni/src/main/files/cacerts/9772ca32.0
luni/src/main/files/cacerts/9d6523ce.0
luni/src/main/files/cacerts/9dbefe7b.0
luni/src/main/files/cacerts/9f533518.0
luni/src/main/files/cacerts/a0bc6fbb.0
luni/src/main/files/cacerts/a15b3b6b.0
luni/src/main/files/cacerts/a3896b44.0
luni/src/main/files/cacerts/a7605362.0
luni/src/main/files/cacerts/a7d2cf64.0
luni/src/main/files/cacerts/ab5346f4.0
luni/src/main/files/cacerts/add67345.0
luni/src/main/files/cacerts/b0f3e76e.0
luni/src/main/files/cacerts/bc3f2570.0
luni/src/main/files/cacerts/bcdd5959.0
luni/src/main/files/cacerts/bda4cc84.0
luni/src/main/files/cacerts/bdacca6f.0
luni/src/main/files/cacerts/bf64f35b.0
luni/src/main/files/cacerts/c0cafbd2.0
luni/src/main/files/cacerts/c215bc69.0
luni/src/main/files/cacerts/c33a80d4.0
luni/src/main/files/cacerts/c527e4ab.0
luni/src/main/files/cacerts/c7e2a638.0
luni/src/main/files/cacerts/c8763593.0
luni/src/main/files/cacerts/ccc52f49.0
luni/src/main/files/cacerts/cdaebb72.0
luni/src/main/files/cacerts/cf701eeb.0
luni/src/main/files/cacerts/d16a5865.0
luni/src/main/files/cacerts/d537fba6.0
luni/src/main/files/cacerts/d64f06f3.0
luni/src/main/files/cacerts/d777342d.0
luni/src/main/files/cacerts/d8274e24.0
luni/src/main/files/cacerts/dbc54cab.0
luni/src/main/files/cacerts/ddc328ff.0
luni/src/main/files/cacerts/e48193cf.0
luni/src/main/files/cacerts/e60bf0c0.0
luni/src/main/files/cacerts/e775ed2d.0
luni/src/main/files/cacerts/e7b8d656.0
luni/src/main/files/cacerts/e8651083.0
luni/src/main/files/cacerts/ea169617.0
luni/src/main/files/cacerts/eb375c3e.0
luni/src/main/files/cacerts/ed049835.0
luni/src/main/files/cacerts/ed524cf5.0
luni/src/main/files/cacerts/ee7cd6fb.0
luni/src/main/files/cacerts/f4996e82.0
luni/src/main/files/cacerts/f58a60fe.0
luni/src/main/files/cacerts/f61bff45.0
luni/src/main/files/cacerts/f80cc7f6.0
luni/src/main/files/cacerts/fac084d7.0
luni/src/main/files/cacerts/facacbc6.0
luni/src/main/files/cacerts/fde84897.0
luni/src/main/files/cacerts/ff783690.0
Change IntegralToString.intToHexString to take width argument to
allow for leading zero padding. Updated existing callers to
specify 0 padding desired. Add testing of new padding
functionality.
luni/src/main/java/java/lang/Character.java
luni/src/main/java/java/lang/Integer.java
luni/src/main/java/java/lang/IntegralToString.java
luni/src/test/java/libcore/java/lang/IntegralToStringTest.java
Improved to throw Exceptions with proper causes
luni/src/main/java/java/security/KeyStore.java
luni/src/main/java/java/security/Policy.java
luni/src/main/java/java/security/cert/CertificateFactory.java
luni/src/main/java/javax/crypto/Cipher.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSignature.java
Indentation fixes
luni/src/main/java/java/security/SecureRandom.java
Fix X509CRLSelector.getIssuerNames to clone result and added test to cover this.
luni/src/main/java/java/security/cert/X509CRLSelector.java
luni/src/test/java/libcore/java/security/cert/X509CRLSelectorTest.java
Fixed bug where we created an X500Principal via a String
representation instead of from its original encoded bytes. This
led to a difficult to track down bug where CA 418595b9.0 where the
NativeCode.X509_NAME_hash of a Harmony (but not BouncyCastle)
X509Certificate would not hash to the expected value because the
encoded form used an ASN.1 PrintableString instead of the
UTF8String form found in the original certificate.
luni/src/main/java/org/apache/harmony/security/x501/Name.java
Add a new RootKeyStoreSpi and register it as the
AndroidCAStore. This new read-only KeyStore implementation that
looks for certificates in $ANDROID_ROOT/etc/security/cacerts/
directory, which is /system/etc/security/cacerts/ on devices. The
files are stored in the directory based on the older md5 based
OpenSSL X509_NAME_hash function (now referred to as
X509_NAME_hash_old in OpenSSL 1.0)
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/RootKeyStoreSpi.java
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/JSSEProvider.java
Added OpenSSL compatible X509_NAME_hash and X509_NAME_hash_old
functions for producting an int hash value from an X500Principal.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
Changed TrustManagerFactoryImpl to use AndroidCAStore for its default KeyStore
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/TrustManagerFactoryImpl.java
Changed TrustManagerImpl to be AndroidCAStore aware. If it detects
an AndroidCAStore, it avoids generating the acceptedIssuers array
at constructions, since doing so would force us to parse all
certificates in the store and the value is only typically used by
SSLServerSockets when requesting a client certifcate. Because we
don't load all the trusted CAs into the IndexedPKIXParameters at
startup in the case of AndroidCAStore, we now check for new CAs
when examining the cert chain for unnecessary TrustAnchors and for
a newly discovered issuer at the end of the chain before
validation.
luni/src/main/java/org/apache/harmony/xnet/provider/jsse/TrustManagerImpl.java
Updated KeyStoreTest to cope with read only KeyStore. Update
test_cacerts_bks (now renamed test_cacerts) to use the
AndroidCAStore for validating system CA certificate
validity. Register AndroidCAStore as an expected KeyStore type
with StandardNames.
luni/src/test/java/libcore/java/security/KeyStoreTest.java
support/src/test/java/libcore/java/security/StandardNames.java
Added test of X500Principal serialization while investigating Name
encoding issue. However, the actual Name bug was found and
verified by the new test_cacerts test.
luni/src/test/java/libcore/javax/security/auth/x500/X500PrincipalTest.java
vendor/google
Change canonical format for checked in cacerts to have PEM
certificate at the top, as required by Harmony's X.509
CertificateFactory.
tools/cacerts/certimport.py
Change-Id: If0c9de430f13babb07f96a1177897c536f3db08d/"
conscrypt,"Add shutdown(2).
Bug: 3107501
Change-Id: I30354c4cc6e86a4e7b0e3f84e95719539db1d297/Fix short writes in Socket OutputStreams.
Also tidy some code and fix some comments.
The OpenSSL OutputStream is already correct: it handles this in the native code.
Bug: http://code.google.com/p/android/issues/detail?id=15304
Change-Id: I69645543ec01f1eecdae4418f86c3a1911c0f752/"
conscrypt,"Replace NativeCrypto.verifySignature with OpenSSLSignature
Bug: http://code.google.com/p/android/issues/detail?id=18458
Bug: 5037994
Change-Id: Ie9521df80b3b50e69b5cf9e6f8eb861845b4d30e/Add ExceptionCheck after all places we setCallbackState
Also remove byte versions of SSL_read and SSL_write matching rest of
libcore to avoid making the change in even more places.
Note that testing this change required improving SSL_renegotiate which
is only used for testing.
Change-Id: If425764da3a36508a6c65d90eb3d36c5a018fd18/"
conscrypt,"Add ExceptionCheck after all places we setCallbackState
Also remove byte versions of SSL_read and SSL_write matching rest of
libcore to avoid making the change in even more places.
Note that testing this change required improving SSL_renegotiate which
is only used for testing.
Change-Id: If425764da3a36508a6c65d90eb3d36c5a018fd18/OpenSSLSocketImpl should tolerate X509KeyManager returning null values
While this started out as the small fix in
OpenSSLSocketImpl.setCertificate and the corresponding test
test_SSLSocket_clientAuth_bogusAlias, the need to test the behavior of
the X509KeyManager returning null on the RI led to test maintenance to
get libcore.javax.net.ssl tests working on RI 7 thanks to a test
dependency that was added on the new InetAddress.getLoopbackAddress().
Change-Id: I3d8ed1ce453cc3a0b53e23e39c02e6a71413649c/"
conscrypt,"Return real FileDescriptor in Socket wrappers.
In classes that wrap another Socket, return the real FileDescriptor
from the wrapped Socket.
Bug: 5189186
Change-Id: I157feb6991def9110eaf0ea82365b6f5b95b9372/"
conscrypt,"Move OpenSSLSocketImpl.close resource cleanup into a finally clause
Bug: 5466273
(cherry picked from commit d3433cea484f380ab2c889c10e9d9d3268046a6c)
Change-Id: I8618be21a2227d66ea66352342b530906605160f/Move OpenSSLSocketImpl.close resource cleanup into a finally clause
Bug: 5466273
Change-Id: I64758dfd3ca1c35d08616c63982223d84fdc2759/"
conscrypt,"Move OpenSSLSocketImpl.close resource cleanup into a finally clause
Bug: 5466273
(cherry picked from commit d3433cea484f380ab2c889c10e9d9d3268046a6c)
Change-Id: I8618be21a2227d66ea66352342b530906605160f/Move OpenSSLSocketImpl.close resource cleanup into a finally clause
Bug: 5466273
Change-Id: I64758dfd3ca1c35d08616c63982223d84fdc2759/Return real FileDescriptor in Socket wrappers.
In classes that wrap another Socket, return the real FileDescriptor
from the wrapped Socket.
Bug: 5189186
Change-Id: I157feb6991def9110eaf0ea82365b6f5b95b9372/"
conscrypt,"Throw exceptions on wrong key type in Signature
Our engine can handle both RSA and DSA, but we need to throw an error if
the wrong key type is supplied after we've initialized to emulate other
providers.
Also, apparently OpenSSL is really flexible, because calling
EVP_SignInit had the same effect as EVP_VerifyInit. Change this to be
correct even though the underlying implementation in OpenSSL doesn't
care.
Change-Id: If9223d17909fcf86437b9669c204fc544e6d12ff/Ensure faster OpenSSLSignature is used when possible by doing proper case insensitive comparison
Bug: 5934554
Change-Id: I640cd54c227df2bf662d484cb2af95ece4d13421/"
conscrypt,"Tracking openssl-1.0.1
Bug: 6168278
Change-Id: I240d2cbc91f616fd486efc5203e2221c9896d90f/"
conscrypt,"Tracking openssl-1.0.1
Bug: 6168278
Change-Id: I240d2cbc91f616fd486efc5203e2221c9896d90f/getPeerHostName should check for null InetAddress
The address can be null for SSLSockets that have not been connected.
Bug: 5835165
(cherry picked from commit cb047c49abcf3b7b5c231b68431c291fe2d81b52)
Change-Id: I12eb92ab0cdb42b89333361a485979c48365d5da/"
conscrypt,"Use SSL_CTX_set_session_id_context in ServerSessionContext
Without this, OpenSSL with fail when SSLSessions are reused on an
SSLServerSocket when client certificates are requested.
Bug: 6329719
Change-Id: I9b14b32cccee1e5aba1215cebf81eb05a788d63b/"
conscrypt,"Use WRAP/UNWRAP for key exchange
Bug: http://code.google.com/p/android/issues/detail?id=12955
Change-Id: I1a2be021e0a22ec6a00ba354fb3f19a78c601be9/"
conscrypt,"NativeCrypto should honor timeout less than one second
Bug: http://code.google.com/p/android/issues/detail?id=29680
Change-Id: I4507a1e9fe37b1c095f7bb4d3e3a55d6d738f7ad/Avoid session reuse to fix test_SSL_do_handshake_clientCertificateRequested_throws_after_renegotiate for OpenSSL 1.0.1
Bug: 6229570
Change-Id: I891d10db104fda9978310b8be3420e1729971b27/Use SSL_CTX_set_session_id_context in ServerSessionContext
Without this, OpenSSL with fail when SSLSessions are reused on an
SSLServerSocket when client certificates are requested.
Bug: 6329719
Change-Id: I9b14b32cccee1e5aba1215cebf81eb05a788d63b/Disable TLSv1.1 and TLSv1.2 by default
Bug: 6234791
Change-Id: I5d829211c9e1d5672fc96e42ef603c53d789e695/Disable TLSv1.1 and TLSv1.2 by default
Bug: 6234791
Change-Id: I5d829211c9e1d5672fc96e42ef603c53d789e695/Don't use the SSL_CTX prefix for a method that takes an SSL.
The implementation is asymmetric: enabling NPN is per-context, but
actually looking up the negotiated protocol is per-SSL. This caused
me to screw up in following the SSL_CTX naming scheme; I applied it
in too many places.
Change-Id: I5bd1be334d513f220086c901527d0b8416f2ba3f/"
conscrypt,"Only use SSL CUTTHROUGH (False Start) if the server supports NPN.
We enable cutthrough on the client if the server supports NPN.
We never enable cutthrough on the server because most relevant
protocols (ie. HTTP) are client-speaks-first and those don't
benefit from cutthrough on the server.
I verified this by enabling NPN on both client and server and
checking that the client's Application Data was sent before the
server's Change Cipher Spec. To increase the likelihood of this
otherwise racy situation I put the server in SSL debug mode
after it receiving next_protos_advertised_callback. OpenSSL's
debug mode adds a 1-second sleep before each read and write.
Bug: http://b/6331035
Change-Id: I879b5fb26dc237392a36fe0585c8a6519c0e5220/Disable TLSv1.1 and TLSv1.2 by default
Bug: 6234791
Change-Id: I5d829211c9e1d5672fc96e42ef603c53d789e695/Disable TLSv1.1 and TLSv1.2 by default
Bug: 6234791
Change-Id: I5d829211c9e1d5672fc96e42ef603c53d789e695/Don't use the SSL_CTX prefix for a method that takes an SSL.
The implementation is asymmetric: enabling NPN is per-context, but
actually looking up the negotiated protocol is per-SSL. This caused
me to screw up in following the SSL_CTX naming scheme; I applied it
in too many places.
Change-Id: I5bd1be334d513f220086c901527d0b8416f2ba3f/"
conscrypt,"CertificateRequest should handle case where certificate is requested but none is available.
Android SSL client was not handling a CertificateRequest where there was no cert to send.
It had a problem because it was assuming that if the CertificateMessage response is not null,
it means there is a cert included, which is not true (if it has no cert to send an empty CertificateMessage
is sent to the server). So I updated the CertificateVerify creation check to also check whether the CertificateMessage
contained any certs (ClientHandshakeImpl.java).
In testing I found that the same error was in the server code so I made the same change there
(ServerHandshakeImpl.java).
I added two test cases to SSLEngineTest - one to directly test the scenario (test_SSLEngine_clientAuthWantedNoClientCert)
and one to just double-check that the server would not allow the connection if setNeedClientAuth (test_SSLEngine_clientAuthNeededNoClientCert).
Bug: http://code.google.com/p/android/issues/detail?id=31903
Change-Id: Ideb57d6ccbcdd54ca24dc3063e60aba2653c8414/"
conscrypt,"Signature.verify should not throw if called twice
Bug: http://code.google.com/p/android/issues/detail?id=34933
Bug: 6870225
(cherry-picked from 52ec5bcc7d5d042d7ba6d0244d98ee72007a95e4)
Change-Id: I29ee6feb4df9505b1691418a9213fe69f840e1ea/Signature.verify should not throw if called twice
Bug: http://code.google.com/p/android/issues/detail?id=34933
Change-Id: Iad18e46729dcd283f4cecd65994ac7b741bd3036/"
conscrypt,"am a8e0ac07: am f2c8382b: am 5a1225cc: Merge ""NativeCrypto: add assertions for no OpenSSL errors""
* commit 'a8e0ac07166ba25fa50e83773cd18ac9f36bf18e':
NativeCrypto: add assertions for no OpenSSL errors/am f2c8382b: am 5a1225cc: Merge ""NativeCrypto: add assertions for no OpenSSL errors""
* commit 'f2c8382b0aa0fca4b79601cb21a9136b862996c2':
NativeCrypto: add assertions for no OpenSSL errors/am 5a1225cc: Merge ""NativeCrypto: add assertions for no OpenSSL errors""
* commit '5a1225cc1b870ffab8be63f2f4a5baa2f3e26126':
NativeCrypto: add assertions for no OpenSSL errors/NativeCrypto: add assertions for no OpenSSL errors
Some calls in NativeCrypto appear to be not clearing error states. Add
an assertion at the end of each test to make sure this doesn't happen.
Change-Id: I9030891a8dc9e7715e65071fe949a11d7a560e56/OpenSSLCipher: remove buffer for partial blocks
Some block ciphers buffer the first block used. We weren't accounting
for this so we started failing with DES3. This led to another issue that
OpenSSL can sometimes keep things in its internal buffer. Instead of
having multiple levels of buffering, just rely on OpenSSL to do the
buffering.
Change-Id: I40a6c7e92e70d3c9ae530f35e8a4234f62e8d225/Add OpenSSLSocketImpl.setSoWriteTimeout to allow SO_SNDTIMEO to be specified
Bug: 6693087
Change-Id: Ie6903168ca0ada4516c55dfab5f7194baf965b4c/Disable SSL compression
Bug: 7079965
Change-Id: I8e060a827613e212bbcced66507fbf124bb04543/Add raw RSA signature support
With the new Keystore changes, this is the only way you can get raw RSA
signatures which a lot of native code expects to be able to do.
(cherry-picked from c531f5f402b4cedcc35a0b7f0b540dc84c545106)
Bug: 6787078
Change-Id: I1c5ddd5287be1ab71347eedc864a41c24e156cb4/Add raw RSA signature support
With the new Keystore changes, this is the only way you can get raw RSA
signatures which a lot of native code expects to be able to do.
Bug: 6787078
Change-Id: I1c5ddd5287be1ab71347eedc864a41c24e156cb4/"
conscrypt,"Add OpenSSLSocketImpl.setSoWriteTimeout to allow SO_SNDTIMEO to be specified
Bug: 6693087
Change-Id: Ie6903168ca0ada4516c55dfab5f7194baf965b4c/Disable SSL compression
Bug: 7079965
Change-Id: I8e060a827613e212bbcced66507fbf124bb04543/Restore ability for SSLSocket.close() to interrupt reads and writes
SSLSocketTest.test_SSLSocket_interrupt didn't catch this regression so
added new test_SSLSocket_interrupt_read to cover this case
specifically.  Also cleanup SSLSocketTest to use Executors like
NativeCryptoTest instead of Threads for better error checking.
Bug: 7014266
Change-Id: I1160cd283310a0c6197cd3271a25830e0e2b1524/am 165b9dc5: am fe1daea1: Merge ""Fix OpenSSLSocketImpl.close race""
* commit '165b9dc50bc50f69eef05395edb6e70cdaa85225':
Fix OpenSSLSocketImpl.close race/Fix OpenSSLSocketImpl.close race
Move the NativeCrypto.SSL_interrupt call within the close
synchronization. Otherwise there can be problems if
NativeCrypto_SSL_interrupt tries to use the SSL* and another thread
has called NativeCrypto_SSL_free.
Bug: 6707288
Change-Id: Id8b0311b10124f2a08f8e0f24595a6ee46805c33/"
conscrypt,"DO NOT MERGE
Disable SSL compression
Bug: 7079965
Change-Id: I8e060a827613e212bbcced66507fbf124bb04543
modified:   luni/src/main/java/libcore/net/http/HttpConnection.java
modified:   luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
modified:   luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
modified:   luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
modified:   luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
modified:   luni/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
modified:   luni/src/test/java/org/apache/harmony/xnet/provider/jsse/NativeCryptoTest.java/Use OpenSSL to convert from OID to name
OpenSSL has a large database of OID mappings, so fall back to it if the
built-in Harmony database doesn't find it.
Change-Id: I72daa0b4f697d406a0d3f8285ce20d4e9ec04d27/"
conscrypt,"am 5906f9f4: Merge ""verifyCertificateChain should convert unknown exceptions to CertificateException""
* commit '5906f9f4485e02d780c4fec61b62910e994ea5d6':
verifyCertificateChain should convert unknown exceptions to CertificateException/verifyCertificateChain should convert unknown exceptions to CertificateException
Bug: http://code.google.com/p/android/issues/detail?id=42533
Change-Id: Id0e0eb8f007987decb4fee94135be8a92d2f8981/DO NOT MERGE
Disable SSL compression
Bug: 7079965
Change-Id: I8e060a827613e212bbcced66507fbf124bb04543
modified:   luni/src/main/java/libcore/net/http/HttpConnection.java
modified:   luni/src/main/java/org/apache/harmony/xnet/provider/jsse/NativeCrypto.java
modified:   luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLServerSocketImpl.java
modified:   luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSessionImpl.java
modified:   luni/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java
modified:   luni/src/main/native/org_apache_harmony_xnet_provider_jsse_NativeCrypto.cpp
modified:   luni/src/test/java/org/apache/harmony/xnet/provider/jsse/NativeCryptoTest.java/"
conscrypt,"Don't forget to call sessionRemoved from removeEldestEntry
Also to prevent similar problems in the future, remember SSLSession we
are trying to use in case it disappears from SSLSessionContext.
Added test of SSLSocket SSLSession reuse.
Bug: https://code.google.com/p/android/issues/detail?id=52738
Bug: 8313208
(cherry picked from commit b88ab0efb05475fa9d4e2a06175e95e88f507cff)
Change-Id: I229e018c3acb427a7b580eaf880f86d9b263bac7/Don't forget to call sessionRemoved from removeEldestEntry
Also to prevent similar problems in the future, remember SSLSession we
are trying to use in case it disappears from SSLSessionContext.
Added test of SSLSocket SSLSession reuse.
Bug: https://code.google.com/p/android/issues/detail?id=52738
Bug: 8313208
Change-Id: I30824cdf96a0d1086abccb61c011dbc9ad60f8cf/"
conscrypt,"NativeCrypto: adjust BasicConstraints check
OpenSSL checks KeyUsage for ""Certificate Signing"" when checking for a
CA, but Java just specifies that the getBasicConstraints call only looks
at the BasicConstraints itself.
(cherry picked from commit cd59afd3e34cb6b3645babdace22c03882e0ec19)
Bug: 8488314
Change-Id: I72f8d6679169480960630bd73745ebf4c55b383c/NativeCrypto: adjust BasicConstraints check
OpenSSL checks KeyUsage for ""Certificate Signing"" when checking for a
CA, but Java just specifies that the getBasicConstraints call only looks
at the BasicConstraints itself.
Bug: 8488314
Change-Id: I072cd2e9f1a9295a717f7587817149200113c65f/am bb7b75b9: am e699186e: Merge ""NativeCrypto: throw exception on invalid DNS altname""
* commit 'bb7b75b9dccf471f3f52cdb088b0c665cf6ded76':
NativeCrypto: throw exception on invalid DNS altname/NativeCrypto: throw exception on invalid DNS altname
When we receive an invalid DNS alt name (e.g., contains characters
outside of the ASCII printable range), we should throw an exception to
match the previous behavior. This is not validated this against the RI
since the tests currently don't work, but it brings the behavior back to
what it was previously.
Also amend the previous ASN.1 string check to use
ASN1_PRINTABLE_type(...) which actually scans the string to check its
contents. This is what was meant in the last patch.
Bug: 8398461
Change-Id: I260f045a2e144fb9ded7e1d3aa46592da8f63272/NativeCrypto: add CertPath support with PKCS7
Add support for generating CertPath with the
OpenSSLX509CertificateFactory implementation.
This only will encode withrPKCS7 currently. This means it fails the
CertPath serialization test because the serialization and
de-serialization code only uses a provider's default serialization
format. Since this provider is not the default provider and the
default provider uses PkiPath as its default format, the
OpenSSLX509CertPath still fails the tests.
This seems like a problem with the way CertPath is serialized. The
impact of this seems to be that a CertPath implementation must have
""PkiPath"" as its default encoding.
Change-Id: Ie0e3577746345108301b02e7a1d4e8ea189f2bda/am c79900d9: am a190a2ae: Merge ""NativeCrypto: fix more DSA/ECDSA key generation""
# Via Android Git Automerger (1) and others
* commit 'c79900d938d474e3e5271593cc7d274f752fac4e':
NativeCrypto: fix more DSA/ECDSA key generation/am a190a2ae: Merge ""NativeCrypto: fix more DSA/ECDSA key generation""
# Via Gerrit Code Review (1) and Kenny Root (1)
* commit 'a190a2ae9fad41c91eefbcd087403311e28e2e6b':
NativeCrypto: fix more DSA/ECDSA key generation/NativeCrypto: fix more DSA/ECDSA key generation
* Add hidden API to pass along the EC curve name in ECParameterSpec.
The lack of name passing made KeyFactory2Test fail because the
reconstructed ECDSA key had explicit curve parameters instead of an
OID naming the curve.
* Fix some mixing of PKCS8/X509EncodedKeySpec in DSA/ECDSA KeyFactory
implementations.
* Fix the KeyFactory2Test to output more useful error messages.
* Remove known failure which is no longer happening.
* Change EC_GROUP_get_curve_name to return the ""shortName"" string
which matches the EC_GROUP_new_by_curve_name
Bug: 3483365
Change-Id: I0a80be88bef728b2177f3593cc3421fa47b79470/am 4f6d0481: am 7e5832d1: Merge changes Idfb18017,Ifbba9fdf
* commit '4f6d0481607daa0875010b9e1364ba6b98aa6eec':
OpenSSLMac: fix initialization with new key
HarmonyJSSE: convert byte correctly in padding check/am 7e5832d1: Merge changes Idfb18017,Ifbba9fdf
* commit '7e5832d1a709558fca80ecb25fdd0626b2d4312d':
OpenSSLMac: fix initialization with new key
HarmonyJSSE: convert byte correctly in padding check/Merge changes Idfb18017,Ifbba9fdf
* changes:
OpenSSLMac: fix initialization with new key
HarmonyJSSE: convert byte correctly in padding check/OpenSSLMac: fix initialization with new key
If an OpenSSLMac instance was re-initialized with a new key, it wouldn't
produce correct results. Make sure to re-initialize the EVP_MD_CTX as
well.
Change-Id: Idfb18017407ff65866ae7e6f6fca3d646a970803/"
conscrypt,"am e7cc4ea0: am 599f6cf9: Merge ""OpenSSLCipher: fix short buffer error message""
# Via Android Git Automerger (1) and others
* commit 'e7cc4ea0c7ef7982e2cf39d885394e41e9b0df8f':
OpenSSLCipher: fix short buffer error message/am 599f6cf9: Merge ""OpenSSLCipher: fix short buffer error message""
# Via Gerrit Code Review (1) and Kenny Root (1)
* commit '599f6cf95d676fe0dacd65b0d1cfb66c6f89744d':
OpenSSLCipher: fix short buffer error message/OpenSSLCipher: fix short buffer error message
Change-Id: I4f16bee3c57c80a113bd92509451606d5fd2b666/"
conscrypt,"Don't forget to call sessionRemoved from removeEldestEntry
Also to prevent similar problems in the future, remember SSLSession we
are trying to use in case it disappears from SSLSessionContext.
Added test of SSLSocket SSLSession reuse.
Bug: https://code.google.com/p/android/issues/detail?id=52738
Bug: 8313208
(cherry picked from commit b88ab0efb05475fa9d4e2a06175e95e88f507cff)
Change-Id: I229e018c3acb427a7b580eaf880f86d9b263bac7/Don't forget to call sessionRemoved from removeEldestEntry
Also to prevent similar problems in the future, remember SSLSession we
are trying to use in case it disappears from SSLSessionContext.
Added test of SSLSocket SSLSession reuse.
Bug: https://code.google.com/p/android/issues/detail?id=52738
Bug: 8313208
Change-Id: I30824cdf96a0d1086abccb61c011dbc9ad60f8cf/am d2be3ff2: am 5906f9f4: Merge ""verifyCertificateChain should convert unknown exceptions to CertificateException""
* commit 'd2be3ff27ca31b21a229129e760fc713541e9d6d':
verifyCertificateChain should convert unknown exceptions to CertificateException/"
conscrypt,"Do not include bogus certs in final chain output
(cherry-picked from 2cdf54071e7c62ceca7d40d7f6c704b91aad2a9f)
Bug: 8313312
Bug: https://code.google.com/p/android/issues/detail?id=52295
Change-Id: Ie9f58c1bdc676471eaaf3073a78b0b00c5d9a833/Do not include bogus certs in final chain output
Bug: 8313312
Bug: https://code.google.com/p/android/issues/detail?id=52295
Change-Id: I1fa31335de9c9ee002c25869dbaa2574c70f48cf/"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../Make sure ChannelID key is initialized
This test used the test ChannelID key, but it didn't make sure it was
initialized first. This made it appear sometimes depending on the order
the tests were executed.
(cherry picked from commit debfff83084b79b65c092cfe72ebea9d9a9548d6)
Bug: 10210673
Change-Id: I5212e265611208ecb641a7d6b403985df603cb03/"
conscrypt,"am b590aa9f: am e75878c7: Fix mac build
* commit 'b590aa9f4377b810c62bc51e7d3651fd86c89854':
Fix mac build/am e75878c7: Fix mac build
* commit 'e75878c72b717696d7e4f6cc1052f1cdaca3bda8':
Fix mac build/Fix mac build
move #pragma gcc outside of functions for apple's ancient gcc
(cherry picked from commit 37f25af685a795b2f2bfa9abb8bb5109c422c52c)
Change-Id: I3ea7fa22805980cfd5059e75c21e2e943604fb8a/am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../Add specific exception for wrong final block length
EVP_DecryptFinal_ex can have an error on the wrong block length at the
end of a decrypted block, so throw IllegalBlockSizeException when that
happens instead of a RuntimeException.
Bug: 10610957
Bug: https://code.google.com/p/android/issues/detail?id=58396
Change-Id: I70ea040c3b52fc30591963270850871a8cc581d3/Remove dependency on JNIHelp header side effects.
(cherrypick of cc5305a004afc334842a4afadca9530c2ea0c8ff.)
Bug: 10680559
Change-Id: I49ad58dea61a0e558bebfbd76019e7e0730cab52/Properly refcount X509 instances
We were leaking X509 references from stacks before so we could get away
with reusing references that should have been freed. Since we're properly
tracking references now, we need to up the reference of things we're
using.
(cherry picked from commit 499f7cd642cc32f89f793fe356afbebeba8bf9c1)
Bug: 10610037
Change-Id: I4a4beda9b635881c51194410a6da8274c3c1d429/Use sk_FOO_pop_free instead of sk_FOO_free
The proper way to free a stack of owned ""FOO"" items is to use
sk_FOO_pop_free since that will iterate through all the FOO instances
in the stack and free them. Calling sk_FOO_free just frees the stack and
not the items.
(cherry picked from commit 64299318644c0c6b86992d414e68d0af236b52c5)
Bug: 10610037
Bug: http://code.google.com/p/android/issues/detail?id=59536
Change-Id: I8af603b10219acb476666e77cc776b6936a19f8d/Fix BIO_OutputStream::write to return the correct length.
This was leaving bad OpenSSL error states lying around for later
innocent calls to trip over.
Also clean up some of the other error reporting/handling.
Bug: 9822466
Bug: 10344304
Change-Id: I9e6d6fd9a6c5e466336217b47f45c211aff5555d/Fix libcore's NativeCode.mk so we actually compile with -Werror.
Change-Id: Ib665ea7c6f54e43851bc04f0265e65218407c70f/"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../If libcore wants ASCII casing, it needs to ask for it like everyone else.
http://elliotth.blogspot.com/2012/01/beware-convenience-methods.html
Bug: https://code.google.com/p/android/issues/detail?id=58359
Change-Id: I597b2ac940f17b5b2bc176e390dc4b63fe0a4e72/"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"Do not use short-keyed TLS/SSL cipher suites by default.
This removes TLS/SSL cipher suites with bulk cipher secret keys
shorter than 80 bits from the list of cipher suites used by default:
* export-strength cipher suites, and
* cipher suites using DES (but not 3DES) as their bulk cipher.
Bug: 11220570
Change-Id: I04e30f6d634801b36018fecc8f2b257fc6b7adfc/am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../Fix build
Missed this during the git reset -p
Change-Id: I6c089d2fb5192d43934d55949b261b05cb8d67da/"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../Return IvParameters in OpenSSLCipher#getParameters
The getParameters() call was unimplemented in the OpenSSLCipher as an
oversight. Add it so code relying on it will continue to work.
Additionally add tests for getIV() and getParameters() to make sure they
work correctly.
(cherry picked from commit 8d59a14a150738b8b3a2a8c31d1a48b8ae0a3d0c)
Bug: 10423926
Change-Id: I6bc7fc540509242dff9e5411f66f82be54691cb4/"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../Conscrypt: correct key selection with no sigAlg
The KeyManagerImpl was changed to support the ""EC_EC"" and ""EC_RSA"" key
types in the StandardNames document. The intention of those aliases are
to require a certain signature type. If it is missing, it should accept
any signature type as before. However, it was erroneously requiring the
same signature type as the key type if it was missing. This causes RSA
client certificates signed by an EC key, for instance, to fail.
Bug: 10966884
Change-Id: I298bf65ac4c607ae13e24b44fb1b52ec341f9fcf/"
conscrypt,"Tidy up locking in OpenSSLSocketImpl.
We guard all state with a single lock ""stateLock"", which
replaces usages of ""this"" and ""handshakeLock"". We do not
perform any blocking operations while holding this lock.
In particular, startHandshake is no longer synchronized.
We use a single integer to keep track of handshake state
instead of a pair of booleans.
Also fix a bug in getSession, the previous implementation
wouldn't work in cut-through mode.
This fixes a deadlock in SSLSocketTest_interrupt.
Change-Id: I9aef991e0579d4094e287dde8e521d09d6468c51/am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../Some cleanup while investigating test_SSLSocket_interrupt
Bug: 10681815
Change-Id: If9a76f4c55b578c6f135befebcc443ab9aef3073/Delay SSLSocketImpl instantiation until needed
Class preloading will create an instance of objects if they are in
static fields, so put the ones we don't want instantiated into a holder
class that is not preloaded.
(cherry picked from commit da5b7116b58795b169961cbd63c2b21bac741d9a)
Bug: 9984058
Change-Id: If8cb4280cbee79cd4d479fbf6a5297c8e5569b6c/Call SSL_use_certificate before SSL_use_PrivateKey
Bug: https://code.google.com/p/android/issues/detail?id=54433
Change-Id: Icf39b98802e2c6128e79c44eaf2cabc7b4805cc5/"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../"
conscrypt,"am aa03f4a3: Merge history of libcore into conscrypt
* commit 'aa03f4a33968a0e4031ffa8a54309c5b6df24c6a': (366 commits)
Conscrypt: add missing libraries to JNI lib
Conscrypt: fixing Android.mk dependencies
Initial empty commit
Remove unsupported Cipher modes
Conscrypt: correct key selection with no sigAlg
Conscrypt: add SHA-224 with tests
Do not throw exception on Mac#reset
Split Conscrypt makefile out from libcore
Revert ""Restore NativeCrypto#encodeCertificates for now""
Fix build
Restore NativeCrypto#encodeCertificates for now
Conscrypt: use certificate references in SSL code
Add specific exception for wrong final block length
Conscrypt: remove dependence on stlport
Remove dependency on JNIHelp header side effects.
Properly refcount X509 instances
Return IvParameters in OpenSSLCipher#getParameters
Some cleanup while investigating test_SSLSocket_interrupt
Delay SSLSocketImpl instantiation until needed
Use sk_FOO_pop_free instead of sk_FOO_free
.../Delay SSLSocketImpl instantiation until needed
Class preloading will create an instance of objects if they are in
static fields, so put the ones we don't want instantiated into a holder
class that is not preloaded.
(cherry picked from commit da5b7116b58795b169961cbd63c2b21bac741d9a)
Bug: 9984058
Change-Id: If8cb4280cbee79cd4d479fbf6a5297c8e5569b6c/"
conscrypt,"am 16a5cd2f: am f7f723e8: Merge ""Stop depending on CipherSuite in OpenSSL-backed sockets.""
* commit '16a5cd2f17b504aced123b98c75e0ebb1d33815e':
Stop depending on CipherSuite in OpenSSL-backed sockets./am f7f723e8: Merge ""Stop depending on CipherSuite in OpenSSL-backed sockets.""
* commit 'f7f723e868397a1801aa769abd78eb7d36b1662b':
Stop depending on CipherSuite in OpenSSL-backed sockets./Merge ""Stop depending on CipherSuite in OpenSSL-backed sockets.""/Stop depending on CipherSuite in OpenSSL-backed sockets.
This is in preparation for removing Harmony-backed TLS/SSL
implementations.
Change-Id: Ic108e16d086fb99b69f0a4e4faeb816dc50a7643/BEAST attack mitigation for OpenSSL-backed SSLSockets.
This enables 1/n-1 record splitting for SSLSocket instances backed by
OpenSSL.
OpenSSL change: https://android-review.googlesource.com/#/c/69253/
Bug: 11514124
Change-Id: I3fef273edd417c51c5723d290656d2e03331d68a/"
conscrypt,"am 16a5cd2f: am f7f723e8: Merge ""Stop depending on CipherSuite in OpenSSL-backed sockets.""
* commit '16a5cd2f17b504aced123b98c75e0ebb1d33815e':
Stop depending on CipherSuite in OpenSSL-backed sockets./am f7f723e8: Merge ""Stop depending on CipherSuite in OpenSSL-backed sockets.""
* commit 'f7f723e868397a1801aa769abd78eb7d36b1662b':
Stop depending on CipherSuite in OpenSSL-backed sockets./Merge ""Stop depending on CipherSuite in OpenSSL-backed sockets.""/Stop depending on CipherSuite in OpenSSL-backed sockets.
This is in preparation for removing Harmony-backed TLS/SSL
implementations.
Change-Id: Ic108e16d086fb99b69f0a4e4faeb816dc50a7643/"
conscrypt,"SSLEngine: Verify server RSA params signature
The client did not verify the signature of server's RSA params in
ServerKeyExchange.
Bug: 11631299
Change-Id: Id5389129a4c503fd2e504980337fdd351a25d280/SSLEngine: verify DHE signature
The DHE signature wasn't being verified against the server's
certificate. Refactor some code to allow the same code to be used for
both the server and client to create and check the DHE parameters
signature.
Bug: 11631299
Change-Id: I73456c18a57a0f31d856d64d0bfdf4e029db6df9/am f0dc0232: am 3c86fc85: am 3b0eb023: SSLEngineImpl: fix DHE with client certs
* commit 'f0dc0232c9cb8a861eee231e397afdc646a0e69d':
SSLEngineImpl: fix DHE with client certs/am 3c86fc85: am 3b0eb023: SSLEngineImpl: fix DHE with client certs
* commit '3c86fc850174e4759ab3517cd407a44fee2d41ce':
SSLEngineImpl: fix DHE with client certs/am 3b0eb023: SSLEngineImpl: fix DHE with client certs
* commit '3b0eb0236a3750eb175cc0f1211a855c0eb31bda':
SSLEngineImpl: fix DHE with client certs/SSLEngineImpl: fix DHE with client certs
If DHE-based key exchanges were selected and there was no matching
client certificate selected from X509ExtendedKeyManager, the array would
be zero-length and crash.
If the client and server certificates did not have DH public keys, the
client key exchange would never be created and the server would get a
change cipher spec unexpectedly.
Change-Id: Ie23b43f4de65e650658c0fb2931e4c1396c136bf/"
conscrypt,"Remove unnecessary throws CertificateException from isUserAddedCertificate.
Change-Id: If825391c86f7b03fbea42dd6da7700c752d156d7/Support user-installed CA certs for cert pinning.
Additionally expose new isUserAddedCertificate() so clients can set policy
for user-installed CA certs.
Bug: 11257762
Change-Id: If45cd452ab76f393660b34594dcae464af0c0696/"
conscrypt,"Disable MD5 cipher suites in SSLSocket and SSLEngine.
Although HMAC-MD5 is not yet broken, the foundations are shaky --
see http://tools.ietf.org/html/rfc6151.
Scans show that disabling these TLS/SSL cipher suites currently
causes handshake issues with 0.4% of the ecosystem.
Bug: 11220570
Change-Id: I1970d2ecbdf3c0d26e45d439047b1d3884ade2ec/Actually prefer Forward Secrecy cipher suites.
The documentation for the list of TLS/SSL cipher suites used by
default states that cipher suites offering Forward Secrecy are
preferred. This CL adjusts the list to conform: FS cipher suites
that use RC4_128 bulk encryption algorithm were not preferred
over non-FS cipher suites that use AES.
Bug: 11220570
Change-Id: Ic9019306898600086920874474764186b710c3ef/Disable 3DES cipher suites in SSLSocket.
The effective key length for 3DES_EDE bulk encryption algorithm
is only 112 bits. We're now aiming for 128 and higher.
Scans show that removing these cipher suites from the default list
causes handshake issues only with 0.15% of the ecosystem.
Bug: 11220570
Change-Id: Ie01ebe8134d08a36b276295b804540157963be8f/Disable static server key ECDH cipher suites in SSLSocket.
These cipher suites use a static key for ECDH on the server side.
When client certificates are used, a static key is also used on the
client side, leading to the same premaster secret for all connections
between a particular client and server. Also, these cipher suites do
not provide forward secrecy.
Scans show that removing these cipher suites from the default list
does not affect connectivity to servers and is thus safe.
Bug: 11220570
Change-Id: If34f4a3888ed9972c39d171656a85c61dfa98ea1/Enable AES-GCM cipher suites by default in SSLSocket.
AES-GCM is preferred to AES-CBC whose MAC-pad-then-encrypt approach
has issues (e.g., Lucky 13 attack).
Bug: 11220570
Change-Id: Ib007bc89ccf08358ed3f093f630350fa859e7c35/Enable support for TLSv1.2 cipher suites in SSLSocket.
This adds support for AES-GCM and AES-CBC with MACs based on SHA256
and SHA384.
Bug: 11220570
Change-Id: I56e7e25c5cd65a4c7662da6d4bbe5720f427e677/Enable TLSv1.1 and TLSv1.2 by default for SSLSocket.
TLSv1.1 and TLSv1.2 offer built-in protection against BEAST attack
and support for GCM cipher suites.
This change causes TLS/SSL handshake failures with a small fraction
of servers, load balancers and TLS/SSL accelerators with broken
TLS/SSL implementations.
Scans demonstrate that the number is around 0.6%. Breaking
connectivity (using platform default settings) to a tiny minority of
the ecosystem is acceptable because this inconvenience is outweighed
by the added safety for the overwheling majority of the ecosystem.
App developers affected by this issue should consider asking such
servers to be fixed or explicitly disabling TLSv1.1 and TLSv1.2 in
their apps.
Bug: 11220570
Change-Id: Ice9e8ce550401ba5e3385fd369c40f01c06ac7fd/am 16a5cd2f: am f7f723e8: Merge ""Stop depending on CipherSuite in OpenSSL-backed sockets.""
* commit '16a5cd2f17b504aced123b98c75e0ebb1d33815e':
Stop depending on CipherSuite in OpenSSL-backed sockets./am f7f723e8: Merge ""Stop depending on CipherSuite in OpenSSL-backed sockets.""
* commit 'f7f723e868397a1801aa769abd78eb7d36b1662b':
Stop depending on CipherSuite in OpenSSL-backed sockets./Merge ""Stop depending on CipherSuite in OpenSSL-backed sockets.""/Stop depending on CipherSuite in OpenSSL-backed sockets.
This is in preparation for removing Harmony-backed TLS/SSL
implementations.
Change-Id: Ic108e16d086fb99b69f0a4e4faeb816dc50a7643/Deprioritize HMAC-MD5 in default TLS/SSL cipher suites.
Although HMAC-MD5 is not yet broken, the foundations are now much
more shaky that those of HMAC-SHA.
See http://tools.ietf.org/html/rfc6151.
This CL also adds a comment about the key rules governing the
preference order of cipher suites used by default.
Bug: 11220570
Change-Id: I2a2fe4d427650081637efc14fd7c427a33cbea7e/Prefer Forward Secrecy TLS/SSL cipher suites by default.
This modifies the list of TLS/SSL cipher suites used by default to
prefer those offering Forward Secrecy (FS) -- ECDHE and DHE.
Bug: 11220570
Change-Id: I20f635d11e937d64de4f4e2fea34e1c5ea7a67ac/Deprioritize RC4-based TLS/SSL cipher suites.
Now that BEAST and Lucky13 mitigations are enabled, it is prudent to
prefer AES CBC cipher suites over RC4 ones
(see http://www.isg.rhul.ac.uk/tls/).
Bug: 11220570
Change-Id: I52b9724700fd8eaeebbadcfa518a96823a1410b8/BEAST attack mitigation for OpenSSL-backed SSLSockets.
This enables 1/n-1 record splitting for SSLSocket instances backed by
OpenSSL.
OpenSSL change: https://android-review.googlesource.com/#/c/69253/
Bug: 11514124
Change-Id: I3fef273edd417c51c5723d290656d2e03331d68a/"
conscrypt,"OpenSSLCipher: check for null params
The documentation says init with null should be handled.
Bug: https://code.google.com/p/android/issues/detail?id=62640
Change-Id: If640a1f62e6002191d552047ccbe5eba5badacc1/"
conscrypt,"Make some methods public for CTS
Some methods are called from CTS. The ClassLoaders are different, so we
need to make these public so we don't get any IllegalAccessError during
CTS tests.
Change-Id: I5ac7931694fb1eceb86ae306fca07fb314643fa9/am 16a5cd2f: am f7f723e8: Merge ""Stop depending on CipherSuite in OpenSSL-backed sockets.""
* commit '16a5cd2f17b504aced123b98c75e0ebb1d33815e':
Stop depending on CipherSuite in OpenSSL-backed sockets./am f7f723e8: Merge ""Stop depending on CipherSuite in OpenSSL-backed sockets.""
* commit 'f7f723e868397a1801aa769abd78eb7d36b1662b':
Stop depending on CipherSuite in OpenSSL-backed sockets./Merge ""Stop depending on CipherSuite in OpenSSL-backed sockets.""/Stop depending on CipherSuite in OpenSSL-backed sockets.
This is in preparation for removing Harmony-backed TLS/SSL
implementations.
Change-Id: Ic108e16d086fb99b69f0a4e4faeb816dc50a7643/BEAST attack mitigation for OpenSSL-backed SSLSockets.
This enables 1/n-1 record splitting for SSLSocket instances backed by
OpenSSL.
OpenSSL change: https://android-review.googlesource.com/#/c/69253/
Bug: 11514124
Change-Id: I3fef273edd417c51c5723d290656d2e03331d68a/"
conscrypt,"Add OpenSSLEngineImpl
Add support for SSLEngine via OpenSSL APIs. Currently this supports just
the basic SSLEngine functionality. It can be improved in efficiency and
performance, but it appears not to leak anything and be correct
according to our test suites.
Change-Id: Iea2dc3922e7c30e26daca38361877bd2f88ae668/DO NOT MERGE NativeCrypto: Handle 0-byte bignum arrays
Some DSA tests were calling with bignum arrays that had the high bit set
indicating a negative number.
Also an empty array was being passed as another part of the test. This
was working, but it was reading one byte past the end of the buffer.
(cherry picked from commit 5b1934c717914323ddb0395f549ae11075a587da)
Bug: 13789608
Change-Id: Ibd5a0dce61703ea569fd483f8acf66fd149703f8/ALPN: change socket calls to SSL_set_alpn_protos
Calling SSL_CTX_set_alpn_protos appears to be detrimental to thread
safety since the implementation of it resets the values. It's not
idempotent to call it multiple times like SSL_CTX_enable_npn.
Bug: https://code.google.com/p/android/issues/detail?id=67940
Change-Id: I09ed9e75d08528300b86201c3e847b26702d4284/Use the new endpointVerificationAlgorithm API
Use the new X509ExtendedTrustManager and use the new
getEndpointVerificationAlgorithm to check the hostname during the
handshake.
Bug: 13103812
Change-Id: Id0a74d4ef21a7d7c90357a111f99b09971e535d0/am 652ff53b: Fix up concurrent use of APIs
* commit '652ff53bd48ed61389337a42d8e50cdb7ace0fec':
Fix up concurrent use of APIs/am fe959f9a: am 652ff53b: Fix up concurrent use of APIs
* commit 'fe959f9a94cd0d09038401b509a637cc3caf152f':
Fix up concurrent use of APIs/am 652ff53b: Fix up concurrent use of APIs
* commit '652ff53bd48ed61389337a42d8e50cdb7ace0fec':
Fix up concurrent use of APIs/Fix up concurrent use of APIs
Code that is incorrectly using MessageDigest, Signature, or Mac in
multiple threads simultaneously could cause a SEGV if OpenSSL is
clearing out the MD_CTX at the same time another thread is trying to
write to it. Make sure we initialize a new MD_CTX after each run to
avoid crashing. The program using the instances concurrently is still
wrong and will most likely get inconsistent results.
Switch to using a context object instance to make sure we can hold a
reference to the object during the native call.
Bug: 8787753
Change-Id: I2518613a47cf03c811a29d17040804fc708394dd/Harden (EC)DSA signatures against weak nonces.
Private key information is leaked by (EC)DSA signatures when nonces
are produced by a weak RNG. This CL enables a mitigation provided by
OpenSSL: mix in private key and message being signed into randomly
generated nonce. Provided private key was generated by strong RNG,
this should mitigate the weakness.
NOTE: This mitigation is not implemented for signatures which use
hardware-backed private keys (AndroidKeyStore).
Change-Id: I60dbf57bff3cfcdcbbeb18be5d9dfba523cc6bb8/"
conscrypt,"Changes to support asynchronous close interruption
This change contains fixes to conscrypt from libcore change
I37de3e7d1a005a73821221e6156d10b95c595d7a
Bug: 13927110
Change-Id: Ied42e930e32013f93415625968372d3b997bd539/Make AppData creation symmetric
AppData was being created in SSL_do_handshake, but freed in SSL_free.
Make it symmetric by creating AppData in SSL_new instead.
The SSLEngine may call do_handshake multiple times to complete a
handshake, but this was creating an AppData each time it entered.
Creating in SSL_new avoids the problem of checking whether it was
already created on each entry into SSL_do_handshake calls.
Bug: 14247219
Change-Id: I825486798250998a4d4141201bda68a4dffe13a4/Add OpenSSLEngineImpl
Add support for SSLEngine via OpenSSL APIs. Currently this supports just
the basic SSLEngine functionality. It can be improved in efficiency and
performance, but it appears not to leak anything and be correct
according to our test suites.
Change-Id: Iea2dc3922e7c30e26daca38361877bd2f88ae668/DO NOT MERGE NativeCrypto: Handle 0-byte bignum arrays
Some DSA tests were calling with bignum arrays that had the high bit set
indicating a negative number.
Also an empty array was being passed as another part of the test. This
was working, but it was reading one byte past the end of the buffer.
(cherry picked from commit 5b1934c717914323ddb0395f549ae11075a587da)
Bug: 13789608
Change-Id: Ibd5a0dce61703ea569fd483f8acf66fd149703f8/DO NOT MERGE BIGNUM convert to Java BigInteger
Java BigInteger is in two's complement, so it needs conversion for
negative numbers. We were mishandling it before and the previous change
just hacked around it. Actually convert to two's complement instead.
(cherry picked from commit 1744cf2b54cc7183ff83a3a2eab3a92a8d95ff55)
Bug: 13789608
Change-Id: I6bfe9577f0936678476193b55433b7d7dbc04400/ALPN: change socket calls to SSL_set_alpn_protos
Calling SSL_CTX_set_alpn_protos appears to be detrimental to thread
safety since the implementation of it resets the values. It's not
idempotent to call it multiple times like SSL_CTX_enable_npn.
Bug: https://code.google.com/p/android/issues/detail?id=67940
Change-Id: I09ed9e75d08528300b86201c3e847b26702d4284/am 88eb6c92: am a0c196d7: Throw SSLHandshakeException for errors during handshake
* commit '88eb6c927cc0b7e0d03ca21d581ad248030bfa9f':
Throw SSLHandshakeException for errors during handshake/am a0c196d7: Throw SSLHandshakeException for errors during handshake
* commit 'a0c196d76f1ed4fddeb94873b9aef47e50059cf2':
Throw SSLHandshakeException for errors during handshake/Add JNI_TRACE_MD to cut down on noise
During start-up of vogar, it does thousands of digests on the input
class files which makes the output really noisy. Since debugging MD
stuff is uncommon, just hide it behind another debug flag.
Change-Id: I972a1b61c6ffe2d4cc345b089f0be10751ea32e4/Throw SSLHandshakeException for errors during handshake
This is a subclass of SSLHandshake, so it's not technically any
different, but more sophisticated clients use this to differentiate
between a failure during handshake and a general SSL failure.
Bug: 13130968
Change-Id: Ifad026c9af6748c1f7cb6a75f8f49aa3e75deea8/Use the new endpointVerificationAlgorithm API
Use the new X509ExtendedTrustManager and use the new
getEndpointVerificationAlgorithm to check the hostname during the
handshake.
Bug: 13103812
Change-Id: Id0a74d4ef21a7d7c90357a111f99b09971e535d0/am a8d4e027: am eb6d87ee: Merge ""Allow verification failures to send SSL alert""
* commit 'a8d4e02750cf20b92e5ff2895d9f8b2d2e974245':
Allow verification failures to send SSL alert/am eb6d87ee: Merge ""Allow verification failures to send SSL alert""
* commit 'eb6d87ee2d1939aa81e914dc0d4a3bc625ea10dd':
Allow verification failures to send SSL alert/am eb6d87ee: Merge ""Allow verification failures to send SSL alert""
* commit 'eb6d87ee2d1939aa81e914dc0d4a3bc625ea10dd':
Allow verification failures to send SSL alert/Merge ""Allow verification failures to send SSL alert""/Allow verification failures to send SSL alert
Before we were relying on our pending exception to abort the SSL
handshake, but the SSL alert was not sent to the server. This enables
peer verification in the OpenSSL to send the alerts and cut the
handshake off earlier.
In OpenSSL, the ssl/s3_clnt.c had code that only sent an alert if verify
mode was not SSL_VERIFY_NONE. Since we're handling all the verification
during the callback, we can special case anything we want to do for
anonymous ciphers in the callback.
Change-Id: I6c8fd0d0c6402e29ef3cb5fc5156eef2f4191ff0/am 88758d46: Fix LP64 builds
* commit '88758d462641e4d2e72d26e55c270bfac97f3b08':
Fix LP64 builds/am 652ff53b: Fix up concurrent use of APIs
* commit '652ff53bd48ed61389337a42d8e50cdb7ace0fec':
Fix up concurrent use of APIs/am ca852134: Throw ArrayIndexOutOfBoundsException instead of generic
* commit 'ca8521342b2b2269fb2cd31b3c81cf3d49c3f6ba':
Throw ArrayIndexOutOfBoundsException instead of generic/Return SSL_TLSEXT_ERR_NOACK with no NPN/ALPN
We were returning SSL_TLSEXT_ERR_OK even if we did not select any
NPN/ALPN support.
Bug: https://code.google.com/p/android/issues/detail?id=66562
Change-Id: I79ea821512f03f1391247d3bcfc7ac7d042ecb41/am 3bcae05d: Add extra debug statement in NativeCrypto
* commit '3bcae05d3e7d33e19f0e506ce6310570e44f63d5':
Add extra debug statement in NativeCrypto/am a64f5de7: am 88758d46: Fix LP64 builds
* commit 'a64f5de77feb9f795a09e5649d2b2fa961634856':
Fix LP64 builds/am 88758d46: Fix LP64 builds
* commit '88758d462641e4d2e72d26e55c270bfac97f3b08':
Fix LP64 builds/Fix LP64 builds
The last parameter to EVP_DigestUpdate is a size_t which on LP64
platforms doesn't have the same size as unsigned int. Fix the type
of the update_func function pointer accordingly.
Change-Id: Idd3b544e479e05055bffb0470a4ef370fad984fe
Signed-off-by: Kvin PETIT <kevin.petit@arm.com>/am fe959f9a: am 652ff53b: Fix up concurrent use of APIs
* commit 'fe959f9a94cd0d09038401b509a637cc3caf152f':
Fix up concurrent use of APIs/am 652ff53b: Fix up concurrent use of APIs
* commit '652ff53bd48ed61389337a42d8e50cdb7ace0fec':
Fix up concurrent use of APIs/Fix up concurrent use of APIs
Code that is incorrectly using MessageDigest, Signature, or Mac in
multiple threads simultaneously could cause a SEGV if OpenSSL is
clearing out the MD_CTX at the same time another thread is trying to
write to it. Make sure we initialize a new MD_CTX after each run to
avoid crashing. The program using the instances concurrently is still
wrong and will most likely get inconsistent results.
Switch to using a context object instance to make sure we can hold a
reference to the object during the native call.
Bug: 8787753
Change-Id: I2518613a47cf03c811a29d17040804fc708394dd/am c0ec2406: am ca852134: Throw ArrayIndexOutOfBoundsException instead of generic
* commit 'c0ec24066db8121613cdd51604e177e266e5d484':
Throw ArrayIndexOutOfBoundsException instead of generic/am ca852134: Throw ArrayIndexOutOfBoundsException instead of generic
* commit 'ca8521342b2b2269fb2cd31b3c81cf3d49c3f6ba':
Throw ArrayIndexOutOfBoundsException instead of generic/Throw ArrayIndexOutOfBoundsException instead of generic
This exception is specifically for arrays which is what we're dealing
with here.
Change-Id: I11be2c75019844701b305240152815d7c610fbef/Harden (EC)DSA signatures against weak nonces.
Private key information is leaked by (EC)DSA signatures when nonces
are produced by a weak RNG. This CL enables a mitigation provided by
OpenSSL: mix in private key and message being signed into randomly
generated nonce. Provided private key was generated by strong RNG,
this should mitigate the weakness.
NOTE: This mitigation is not implemented for signatures which use
hardware-backed private keys (AndroidKeyStore).
Change-Id: I60dbf57bff3cfcdcbbeb18be5d9dfba523cc6bb8/am f694798c: am 3bcae05d: Add extra debug statement in NativeCrypto
* commit 'f694798cfd850d4158ee454ab10dc3fdc0ca5454':
Add extra debug statement in NativeCrypto/am 3bcae05d: Add extra debug statement in NativeCrypto
* commit '3bcae05d3e7d33e19f0e506ce6310570e44f63d5':
Add extra debug statement in NativeCrypto/Add extra debug statement in NativeCrypto
Need to track the output of X509_get_pubkey
Change-Id: I2196edbe935c32eabce840556958af67abfc1980/"
conscrypt,"Use the new endpointVerificationAlgorithm API
Use the new X509ExtendedTrustManager and use the new
getEndpointVerificationAlgorithm to check the hostname during the
handshake.
Bug: 13103812
Change-Id: Id0a74d4ef21a7d7c90357a111f99b09971e535d0/am a8d4d7cc: am af672dd9: Avoid NullPointerException when no client cert key provided.
* commit 'a8d4d7ccb89c31545f2de9ebda33d6b8a094c038':
Avoid NullPointerException when no client cert key provided./am af672dd9: Avoid NullPointerException when no client cert key provided.
* commit 'af672dd97643a721f2b038660c8a9e105a23576a':
Avoid NullPointerException when no client cert key provided./am af672dd9: Avoid NullPointerException when no client cert key provided.
* commit 'af672dd97643a721f2b038660c8a9e105a23576a':
Avoid NullPointerException when no client cert key provided./Avoid NullPointerException when no client cert key provided.
When the user of a client-mode SSLEngine provides a client
certificate but provides no key, the current implementation blows up
with a NullPointerException.
This CL makes the behavior aligned with RI. It does not blow up, but
rather proceeds without sending a certificate_verify message to the
server. Normally, this then leads to the server terminating the
handshake.
Change-Id: Ib8d3f7e4b4b7fdd9f4ec4acd42513c781a703f96/Support TLS/SSL without X509TrustManager or X509KeyManager.
This makes TLS/SSL primitives operate as expected when no
X509TrustManager or X509KeyManager is provided. Instead of blowing up
with KeyManagementException or NullPointerException (or similar) when
X509TrustManager or X509KeyManager is not provided, this CL makes
SSLContext.init accept such setup, and makes SSLSocket and SSLEngine
reject certificate chains, select no private keys/aliases, and accept
no certificate issuers.
Bug: 13563574
Change-Id: I8de58377a09025258357dd4da9f6cb1b6f2dab80/"
conscrypt,"am 652ff53b: Fix up concurrent use of APIs
* commit '652ff53bd48ed61389337a42d8e50cdb7ace0fec':
Fix up concurrent use of APIs/am fe959f9a: am 652ff53b: Fix up concurrent use of APIs
* commit 'fe959f9a94cd0d09038401b509a637cc3caf152f':
Fix up concurrent use of APIs/am 652ff53b: Fix up concurrent use of APIs
* commit '652ff53bd48ed61389337a42d8e50cdb7ace0fec':
Fix up concurrent use of APIs/Fix up concurrent use of APIs
Code that is incorrectly using MessageDigest, Signature, or Mac in
multiple threads simultaneously could cause a SEGV if OpenSSL is
clearing out the MD_CTX at the same time another thread is trying to
write to it. Make sure we initialize a new MD_CTX after each run to
avoid crashing. The program using the instances concurrently is still
wrong and will most likely get inconsistent results.
Switch to using a context object instance to make sure we can hold a
reference to the object during the native call.
Bug: 8787753
Change-Id: I2518613a47cf03c811a29d17040804fc708394dd/Harden (EC)DSA signatures against weak nonces.
Private key information is leaked by (EC)DSA signatures when nonces
are produced by a weak RNG. This CL enables a mitigation provided by
OpenSSL: mix in private key and message being signed into randomly
generated nonce. Provided private key was generated by strong RNG,
this should mitigate the weakness.
NOTE: This mitigation is not implemented for signatures which use
hardware-backed private keys (AndroidKeyStore).
Change-Id: I60dbf57bff3cfcdcbbeb18be5d9dfba523cc6bb8/"
conscrypt,"Use the new endpointVerificationAlgorithm API
Use the new X509ExtendedTrustManager and use the new
getEndpointVerificationAlgorithm to check the hostname during the
handshake.
Bug: 13103812
Change-Id: Id0a74d4ef21a7d7c90357a111f99b09971e535d0/"
conscrypt,"am f76b17dd: Merge ""SSLEngine: fix some behaviors""
* commit 'f76b17dd896cac185bfec0b980a68a232f948c6a':
SSLEngine: fix some behaviors/Merge ""SSLEngine: fix some behaviors""/SSLEngine: fix some behaviors
* We were not checking buffer lengths.
* wrap/unwrap should start a handshake.
Change-Id: I35fbd8bf5eb699923f4712e7590bce7e7e13e529/SSLEngine: fix some behaviors
* We were not checking buffer lengths.
* wrap/unwrap should start a handshake.
Change-Id: I35fbd8bf5eb699923f4712e7590bce7e7e13e529/Add OpenSSLEngineImpl
Add support for SSLEngine via OpenSSL APIs. Currently this supports just
the basic SSLEngine functionality. It can be improved in efficiency and
performance, but it appears not to leak anything and be correct
according to our test suites.
Change-Id: Iea2dc3922e7c30e26daca38361877bd2f88ae668/ALPN: change socket calls to SSL_set_alpn_protos
Calling SSL_CTX_set_alpn_protos appears to be detrimental to thread
safety since the implementation of it resets the values. It's not
idempotent to call it multiple times like SSL_CTX_enable_npn.
Bug: https://code.google.com/p/android/issues/detail?id=67940
Change-Id: I09ed9e75d08528300b86201c3e847b26702d4284/Use the new endpointVerificationAlgorithm API
Use the new X509ExtendedTrustManager and use the new
getEndpointVerificationAlgorithm to check the hostname during the
handshake.
Bug: 13103812
Change-Id: Id0a74d4ef21a7d7c90357a111f99b09971e535d0/am 652ff53b: Fix up concurrent use of APIs
* commit '652ff53bd48ed61389337a42d8e50cdb7ace0fec':
Fix up concurrent use of APIs/am 7c3263f1: OpenSSLX509Certificate: only catch BadPaddingException
* commit '7c3263f16bae0f1b2125de2c3c1c683303e768ce':
OpenSSLX509Certificate: only catch BadPaddingException/am fe959f9a: am 652ff53b: Fix up concurrent use of APIs
* commit 'fe959f9a94cd0d09038401b509a637cc3caf152f':
Fix up concurrent use of APIs/am 652ff53b: Fix up concurrent use of APIs
* commit '652ff53bd48ed61389337a42d8e50cdb7ace0fec':
Fix up concurrent use of APIs/Fix up concurrent use of APIs
Code that is incorrectly using MessageDigest, Signature, or Mac in
multiple threads simultaneously could cause a SEGV if OpenSSL is
clearing out the MD_CTX at the same time another thread is trying to
write to it. Make sure we initialize a new MD_CTX after each run to
avoid crashing. The program using the instances concurrently is still
wrong and will most likely get inconsistent results.
Switch to using a context object instance to make sure we can hold a
reference to the object during the native call.
Bug: 8787753
Change-Id: I2518613a47cf03c811a29d17040804fc708394dd/Harden (EC)DSA signatures against weak nonces.
Private key information is leaked by (EC)DSA signatures when nonces
are produced by a weak RNG. This CL enables a mitigation provided by
OpenSSL: mix in private key and message being signed into randomly
generated nonce. Provided private key was generated by strong RNG,
this should mitigate the weakness.
NOTE: This mitigation is not implemented for signatures which use
hardware-backed private keys (AndroidKeyStore).
Change-Id: I60dbf57bff3cfcdcbbeb18be5d9dfba523cc6bb8/am 95369a99: am 7c3263f1: OpenSSLX509Certificate: only catch BadPaddingException
* commit '95369a993991b7a1a7bd8060e988d3acacdb4c43':
OpenSSLX509Certificate: only catch BadPaddingException/am 7c3263f1: OpenSSLX509Certificate: only catch BadPaddingException
* commit '7c3263f16bae0f1b2125de2c3c1c683303e768ce':
OpenSSLX509Certificate: only catch BadPaddingException/OpenSSLX509Certificate: only catch BadPaddingException
We only need to catch BadPaddingException right now. Let the other
non-RuntimeException exceptions pass.
Change-Id: I5b6878250d428b1ee953092967b7418003ee9216/"
conscrypt,"Add OpenSSLEngineImpl
Add support for SSLEngine via OpenSSL APIs. Currently this supports just
the basic SSLEngine functionality. It can be improved in efficiency and
performance, but it appears not to leak anything and be correct
according to our test suites.
Change-Id: Iea2dc3922e7c30e26daca38361877bd2f88ae668/ALPN: change socket calls to SSL_set_alpn_protos
Calling SSL_CTX_set_alpn_protos appears to be detrimental to thread
safety since the implementation of it resets the values. It's not
idempotent to call it multiple times like SSL_CTX_enable_npn.
Bug: https://code.google.com/p/android/issues/detail?id=67940
Change-Id: I09ed9e75d08528300b86201c3e847b26702d4284/Use the new endpointVerificationAlgorithm API
Use the new X509ExtendedTrustManager and use the new
getEndpointVerificationAlgorithm to check the hostname during the
handshake.
Bug: 13103812
Change-Id: Id0a74d4ef21a7d7c90357a111f99b09971e535d0/am a8d4e027: am eb6d87ee: Merge ""Allow verification failures to send SSL alert""
* commit 'a8d4e02750cf20b92e5ff2895d9f8b2d2e974245':
Allow verification failures to send SSL alert/am eb6d87ee: Merge ""Allow verification failures to send SSL alert""
* commit 'eb6d87ee2d1939aa81e914dc0d4a3bc625ea10dd':
Allow verification failures to send SSL alert/am eb6d87ee: Merge ""Allow verification failures to send SSL alert""
* commit 'eb6d87ee2d1939aa81e914dc0d4a3bc625ea10dd':
Allow verification failures to send SSL alert/Merge ""Allow verification failures to send SSL alert""/Allow verification failures to send SSL alert
Before we were relying on our pending exception to abort the SSL
handshake, but the SSL alert was not sent to the server. This enables
peer verification in the OpenSSL to send the alerts and cut the
handshake off earlier.
In OpenSSL, the ssl/s3_clnt.c had code that only sent an alert if verify
mode was not SSL_VERIFY_NONE. Since we're handling all the verification
during the callback, we can special case anything we want to do for
anonymous ciphers in the callback.
Change-Id: I6c8fd0d0c6402e29ef3cb5fc5156eef2f4191ff0/Support TLS/SSL without X509TrustManager or X509KeyManager.
This makes TLS/SSL primitives operate as expected when no
X509TrustManager or X509KeyManager is provided. Instead of blowing up
with KeyManagementException or NullPointerException (or similar) when
X509TrustManager or X509KeyManager is not provided, this CL makes
SSLContext.init accept such setup, and makes SSLSocket and SSLEngine
reject certificate chains, select no private keys/aliases, and accept
no certificate issuers.
Bug: 13563574
Change-Id: I8de58377a09025258357dd4da9f6cb1b6f2dab80/"
conscrypt,"Expose support for TLS-PSK.
TLS-PSK (Pre-Shared Key) is a set of TLS/SSL cipher suites that use
symmetric (pre-shared) keys for mutual authentication of peers. These
cipher suites are in some scenarios more suitable than those based on
public key cryptography and X.509. See RFC 4279 (Pre-Shared Key
Ciphersuites for Transport Layer Security (TLS)) for more information.
OpenSSL currently supports only the following PSK cipher suites:
* TLS_ECDHE_PSK_WITH_AES_128_CBC_SHA256
* TLS_ECDHE_PSK_WITH_AES_256_CBC_SHA384
* TLS_PSK_WITH_3DES_EDE_CBC_SHA
* TLS_PSK_WITH_AES_128_CBC_SHA
* TLS_PSK_WITH_AES_256_CBC_SHA
* TLS_PSK_WITH_RC4_128_SHA
The last four cipher suites mutually authenticate the peers and
secure the connection using a pre-shared symmetric key. These cipher
suites do not provide Forward Secrecy -- once the pre-shared key is
compromised, all previous communications secured with that key can be
decrypted. The first two cipher suites combine the pre-shared
symmetric key with an ephemeral key obtained from an ECDH key
exchange performed during the TLS/SSL handshake, thus providing
Forward Secrecy.
Users of TLS-PSK are expected to provide an implementation of
PSKKeyManager to SSLContext.init and then enable at least one PSK
cipher suite in SSLSocket/SSLEngine.
Bug: 15073623
Change-Id: I8e59264455f980f23a5e66099c27b5b4d932b9bb/am cc46d578: am 5934ada9: am 81c66678: NativeCryptoTest: fix shutdown test
* commit 'cc46d5785d0b529019555450c7286d2aba2ee66a':
NativeCryptoTest: fix shutdown test/am 5934ada9: am 81c66678: NativeCryptoTest: fix shutdown test
* commit '5934ada9abff559ff9443b450716531cb2dc2155':
NativeCryptoTest: fix shutdown test/am 81c66678: NativeCryptoTest: fix shutdown test
* commit '81c666781f8e24242e997e2666b656b240c5a145':
NativeCryptoTest: fix shutdown test/NativeCryptoTest: fix shutdown test
These weren't actually testing that the exceptions were thrown before.
Since we actually throw now, make sure we're throwing the expected
exception type.
Change-Id: I57b11492118dd7c04faa57c58de7b023294b179c/SSL: also allow calls to read/write after cutthrough
Also add test to make sure this works.
(cherry picked from commit 68a3f229cd71c1367173ebc31e5363293b9b5dbc)
Bug: 14832989
Change-Id: If0189d2b84178bc074148119f5d8927ed7ce38a0/SSL: also allow calls to read/write after cutthrough
Also add test to make sure this works.
(cherry picked from commit 68a3f229cd71c1367173ebc31e5363293b9b5dbc)
Bug: 14832989
Change-Id: If0189d2b84178bc074148119f5d8927ed7ce38a0/SSL: also allow calls to read/write after cutthrough
Also add test to make sure this works.
Bug: 14832989
Change-Id: I046111cdcc4086a7104d462696078a767e86b12c/"
conscrypt,"DHKeyPairGenerator: use provided params
If the prime is provided in the DHParameterSpec, then use it to generate
the key.
Bug: 16188130
Change-Id: I42de02c71a58d691ef7ba6e2252367105687b758/Use the new version of TLS Channel ID extension.
Bug: 14083889
Change-Id: I5fe0a1558184d44eb8a24bd92c0e7517937f3a5c/am 23d99f15: am 1b60d4ff: Fix 64-bit build error.
* commit '23d99f1554d9d14d46459041ba434b0406927849':
Fix 64-bit build error./am 1b60d4ff: Fix 64-bit build error.
* commit '1b60d4ff4dc301b46f4ac8a48dc63da0be113a05':
Fix 64-bit build error./Fix 64-bit build error.
Change-Id: I7ff48af2991fc03811c7874a974b9052934d27ae/Add ability to wrap platform keys
This is mostly useful for unbundled Conscrypt currently when working
with KeyChain-based keys, but could be good for use with PKCS11-like
keys in other JSSE providers.
Bug: 15469749
Change-Id: I56bf2eaf3228bdf42d671437f4fffdafb8b47b12/am c5a998dd: am fee2d0f1: Add more debugging for getting methods
* commit 'c5a998dd356e50772c088467f513fba5ad5a0e6b':
Add more debugging for getting methods/am fee2d0f1: Add more debugging for getting methods
* commit 'fee2d0f1c55ffcb436ecc23af54bf7863a44ab8f':
Add more debugging for getting methods/Add more debugging for getting methods
When JNI registration fails, we should log it immediately to help
with debugging. Otherwise, it will tell you that you called a JNI
function with an exception pending.
Change-Id: I7cbba4d6639265a79a9d043d120f1a2bf72a85f7/Expose support for TLS-PSK.
TLS-PSK (Pre-Shared Key) is a set of TLS/SSL cipher suites that use
symmetric (pre-shared) keys for mutual authentication of peers. These
cipher suites are in some scenarios more suitable than those based on
public key cryptography and X.509. See RFC 4279 (Pre-Shared Key
Ciphersuites for Transport Layer Security (TLS)) for more information.
OpenSSL currently supports only the following PSK cipher suites:
* TLS_ECDHE_PSK_WITH_AES_128_CBC_SHA256
* TLS_ECDHE_PSK_WITH_AES_256_CBC_SHA384
* TLS_PSK_WITH_3DES_EDE_CBC_SHA
* TLS_PSK_WITH_AES_128_CBC_SHA
* TLS_PSK_WITH_AES_256_CBC_SHA
* TLS_PSK_WITH_RC4_128_SHA
The last four cipher suites mutually authenticate the peers and
secure the connection using a pre-shared symmetric key. These cipher
suites do not provide Forward Secrecy -- once the pre-shared key is
compromised, all previous communications secured with that key can be
decrypted. The first two cipher suites combine the pre-shared
symmetric key with an ephemeral key obtained from an ECDH key
exchange performed during the TLS/SSL handshake, thus providing
Forward Secrecy.
Users of TLS-PSK are expected to provide an implementation of
PSKKeyManager to SSLContext.init and then enable at least one PSK
cipher suite in SSLSocket/SSLEngine.
Bug: 15073623
Change-Id: I8e59264455f980f23a5e66099c27b5b4d932b9bb/Unbundle: hacks to let Conscrypt compile standalone
This is the first pass at getting Conscrypt to compile standalone. It
works fine in apps currently. There are a few TODOs to fix.
Change-Id: I9b43ba12c55e04c8897ccacf38979ca671a55a26/am cc46d578: am 5934ada9: am 81c66678: NativeCryptoTest: fix shutdown test
* commit 'cc46d5785d0b529019555450c7286d2aba2ee66a':
NativeCryptoTest: fix shutdown test/am 5934ada9: am 81c66678: NativeCryptoTest: fix shutdown test
* commit '5934ada9abff559ff9443b450716531cb2dc2155':
NativeCryptoTest: fix shutdown test/am 81c66678: NativeCryptoTest: fix shutdown test
* commit '81c666781f8e24242e997e2666b656b240c5a145':
NativeCryptoTest: fix shutdown test/NativeCryptoTest: fix shutdown test
These weren't actually testing that the exceptions were thrown before.
Since we actually throw now, make sure we're throwing the expected
exception type.
Change-Id: I57b11492118dd7c04faa57c58de7b023294b179c/am 7ea02b4c: am 7f9e7554: am 3f8d6407: Fix of native crash in the evpUpdate method
* commit '7ea02b4c1c0e95077996dcc5890aa8a2239faceb':
Fix of native crash in the evpUpdate method/am 7f9e7554: am 3f8d6407: Fix of native crash in the evpUpdate method
* commit '7f9e7554c13e138cfec98605e38b86062c55df72':
Fix of native crash in the evpUpdate method/am 3f8d6407: Fix of native crash in the evpUpdate method
* commit '3f8d64078d49672f6301661baa59d24f1d2b74c0':
Fix of native crash in the evpUpdate method/Fix of native crash in the evpUpdate method
The org.apache.harmony.security.tests.java.security.MessageDigest1Test
CTS test class's testSHAProvider method was causing a SIGSEGV when
""md.update(bytes, 1, -1);"" was called, as the evpUpdate method was not
checking for the inLength parameter being negative. This has been
rectified and the test now passes.
Bug: 14821275
Change-Id: I94489a518f7a2d4a6e84e58f91d8eee6f0ceb045
Signed-off-by: Marcus Oakland <marcus.oakland@arm.com>/DO NOT MERGE Return SSL_TLSEXT_ERR_NOACK with no NPN/ALPN
We were returning SSL_TLSEXT_ERR_OK even if we did not select any
NPN/ALPN support.
(cherry picked from commit fc7924bc78afc46c3c75722a735fe4db65c33304)
Bug: https://code.google.com/p/android/issues/detail?id=66562
Change-Id: I79ea821512f03f1391247d3bcfc7ac7d042ecb41/SSL: also allow calls to read/write after cutthrough
Also add test to make sure this works.
(cherry picked from commit 68a3f229cd71c1367173ebc31e5363293b9b5dbc)
Bug: 14832989
Change-Id: If0189d2b84178bc074148119f5d8927ed7ce38a0/SSL: also allow calls to read/write after cutthrough
Also add test to make sure this works.
(cherry picked from commit 68a3f229cd71c1367173ebc31e5363293b9b5dbc)
Bug: 14832989
Change-Id: If0189d2b84178bc074148119f5d8927ed7ce38a0/SSL: also allow calls to read/write after cutthrough
Also add test to make sure this works.
Bug: 14832989
Change-Id: I046111cdcc4086a7104d462696078a767e86b12c/SSLSocket: restore previous pre-handshake behavior
Before AppData was created in the initial handshake, calling SSL_read or
SSL_write would have a NULL appData field. This caused an exception to
be thrown. Now we have to check to make sure the handshake completed
before we continue on with SSL_read and SSL_write.
Change-Id: I969577cf56f61858450a7981a5196f58a6502968/am b4f1e9ad: am a320e0c8: am b45c8e9b: Merge ""BIO_Stream: check for pending exception""
* commit 'b4f1e9ada6bb74bfe085add43ec404cdb17bbb19':
BIO_Stream: check for pending exception/am a320e0c8: am b45c8e9b: Merge ""BIO_Stream: check for pending exception""
* commit 'a320e0c80a778d0eb7cf8e6146d540ea520ba2c4':
BIO_Stream: check for pending exception/am b45c8e9b: Merge ""BIO_Stream: check for pending exception""
* commit 'b45c8e9b993ed4da0edcdd38621c8eda44a0ada0':
BIO_Stream: check for pending exception/Merge ""BIO_Stream: check for pending exception""/BIO_Stream: check for pending exception
OpenSSL may make several callbacks in a row, so we need to check whether
a pending exception is in flight before calling into the JVM again.
Bug: 14477174
Change-Id: I104fa0af08a229430e193c7ed7b147d115215cd2/"
conscrypt,"Unbundle: hacks to let Conscrypt compile standalone
This is the first pass at getting Conscrypt to compile standalone. It
works fine in apps currently. There are a few TODOs to fix.
Change-Id: I9b43ba12c55e04c8897ccacf38979ca671a55a26/"
conscrypt,"Remove direct reference to PROVIDER_NAME
It's unnecessary and this is the only code that does it like this. It
casuses problems with unbundling since the PROVIDER_NAME can change when
used unbundled.
Bug: 15771893
Change-Id: I1450cf7033b0629e7b79616c3660ec12b8afb8d6/Remove direct reference to PROVIDER_NAME
It's unnecessary and this is the only code that does it like this. It
casuses problems with unbundling since the PROVIDER_NAME can change when
used unbundled.
(cherry-picked from commit c59af1c17b96618de24aa2d6bc682bac5ea6cf24)
Bug: 15771893
Change-Id: I1450cf7033b0629e7b79616c3660ec12b8afb8d6/"
conscrypt,"Enable PSK cipher suites when PSKKeyManager is provided.
This enables TLS-PSK cipher suites by default iff SSLContext is
initialized with a PSKKeyManager. For consistency, X.509 based
cipher suites are no longer enabled by default at all times -- they
are now only enabled by default iff SSLContext is initialized with a
X509KeyManager or a X509TrustManager.
When both X.509 and PSK cipher suites need to be enabled, PSK cipher
suites are given higher priority in the resulting list of cipher
suites. This is based on the assumption that in most cases users of
TLS/SSL who enable TLS-PSK would prefer TLS-PSK to be used when the
peer supports TLS-PSK.
Bug: 15073623
(cherry picked from commit 8f9ac1af0cbdf00e5e47aee32c132522ebc3bd17)
Change-Id: Icd7fe066147a6b2fc64d807204cc99f6af821313/Enable PSK cipher suites when PSKKeyManager is provided.
This enables TLS-PSK cipher suites by default iff SSLContext is
initialized with a PSKKeyManager. For consistency, X.509 based
cipher suites are no longer enabled by default at all times -- they
are now only enabled by default iff SSLContext is initialized with a
X509KeyManager or a X509TrustManager.
When both X.509 and PSK cipher suites need to be enabled, PSK cipher
suites are given higher priority in the resulting list of cipher
suites. This is based on the assumption that in most cases users of
TLS/SSL who enable TLS-PSK would prefer TLS-PSK to be used when the
peer supports TLS-PSK.
Bug: 15073623
Change-Id: I8e2bc3e7a1ea8a986e468973b6bad19dc6b7bc3c/DHKeyPairGenerator: use provided params
If the prime is provided in the DHParameterSpec, then use it to generate
the key.
Bug: 16188130
Change-Id: I42de02c71a58d691ef7ba6e2252367105687b758/Adjust the list of supported ECDHE-PSK cipher suites.
The SHA-2 based cipher suites cannot be used with SSLv3 but there is
no way to express that in OpenSSL's configuration. This CL thus
adjusts the list of supported cipher suites accordingly.
Bug: 15073623
Change-Id: I427c99f4c1c72690d95e5a3c63763631c41ddae2/Add ability to wrap platform keys
This is mostly useful for unbundled Conscrypt currently when working
with KeyChain-based keys, but could be good for use with PKCS11-like
keys in other JSSE providers.
Bug: 15469749
Change-Id: I56bf2eaf3228bdf42d671437f4fffdafb8b47b12/Expose support for TLS-PSK.
TLS-PSK (Pre-Shared Key) is a set of TLS/SSL cipher suites that use
symmetric (pre-shared) keys for mutual authentication of peers. These
cipher suites are in some scenarios more suitable than those based on
public key cryptography and X.509. See RFC 4279 (Pre-Shared Key
Ciphersuites for Transport Layer Security (TLS)) for more information.
OpenSSL currently supports only the following PSK cipher suites:
* TLS_ECDHE_PSK_WITH_AES_128_CBC_SHA256
* TLS_ECDHE_PSK_WITH_AES_256_CBC_SHA384
* TLS_PSK_WITH_3DES_EDE_CBC_SHA
* TLS_PSK_WITH_AES_128_CBC_SHA
* TLS_PSK_WITH_AES_256_CBC_SHA
* TLS_PSK_WITH_RC4_128_SHA
The last four cipher suites mutually authenticate the peers and
secure the connection using a pre-shared symmetric key. These cipher
suites do not provide Forward Secrecy -- once the pre-shared key is
compromised, all previous communications secured with that key can be
decrypted. The first two cipher suites combine the pre-shared
symmetric key with an ephemeral key obtained from an ECDH key
exchange performed during the TLS/SSL handshake, thus providing
Forward Secrecy.
Users of TLS-PSK are expected to provide an implementation of
PSKKeyManager to SSLContext.init and then enable at least one PSK
cipher suite in SSLSocket/SSLEngine.
Bug: 15073623
Change-Id: I8e59264455f980f23a5e66099c27b5b4d932b9bb/DO NOT MERGE OpenSSLX509Certificate: only catch BadPaddingException
We only need to catch BadPaddingException right now. Let the other
non-RuntimeException exceptions pass.
(cherry picked from commit 7c3263f16bae0f1b2125de2c3c1c683303e768ce)
Bug: 13746671
Change-Id: I5b6878250d428b1ee953092967b7418003ee9216/"
conscrypt,"Keep enough state to completely reset cipher instances
OpenSSL's RC4 mutates the given key. AES/CTR mutates the IV. We must
store these values locally to enable ""doFinal"" to cause the Cipher
instance to be reset to what it was right after ""init"".
Note that resetting and encrypting with the same key or IV breaks
semantic security.
(cherry picked from commit 084e3086be1d7a6b9280b64c7c8cdb7b41a13bea)
Bug: 16298401
Bug: https://code.google.com/p/android/issues/detail?id=73339
Change-Id: Ie7e4dcb6cf6cc33ddad31d6b47066dc1b34e6894/Keep enough state to completely reset cipher instances
OpenSSL's RC4 mutates the given key. AES/CTR mutates the IV. We must
store these values locally to enable ""doFinal"" to cause the Cipher
instance to be reset to what it was right after ""init"".
Note that resetting and encrypting with the same key or IV breaks
semantic security.
Bug: 16298401
Bug: https://code.google.com/p/android/issues/detail?id=73339
Change-Id: Ie7e4dcb6cf6cc33ddad31d6b47066dc1b34e6894/"
conscrypt,"Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
(cherry picked from 26163c268a6d2625384b87e907afad8ef19f9a47)
Bug: 16352665
Bug: https://code.google.com/p/android/issues/detail?id=73745
Change-Id: I5bcaf3ee8910ff75e785baed4c4604fee6c5e700/Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
Bug: https://code.google.com/p/android/issues/detail?id=73745
Change-Id: I5bcaf3ee8910ff75e785baed4c4604fee6c5e700/OpenSSLEngineImpl: fix unwrap behavior with array
The decrypted bytes should written sequentially into each buffer of
the destination array until it's full before moving to the next
buffer.
(cherry picked from commit 41eb5b65e524d01e28da474bd37e4349b12fb494)
Bug: 16352665
Change-Id: I2454249c167deafde6c12134d3c8cd658cd7c21b/am 5f03b4d6: am 41eb5b65: OpenSSLEngineImpl: fix unwrap behavior with array
* commit '5f03b4d63c7632581b032879de791dc82f05ffa0':
OpenSSLEngineImpl: fix unwrap behavior with array/am 41eb5b65: OpenSSLEngineImpl: fix unwrap behavior with array
* commit '41eb5b65e524d01e28da474bd37e4349b12fb494':
OpenSSLEngineImpl: fix unwrap behavior with array/OpenSSLEngineImpl: fix unwrap behavior with array
The decrypted bytes should written sequentially into each buffer of
the destination array until it's full before moving to the next
buffer.
Change-Id: I2454249c167deafde6c12134d3c8cd658cd7c21b/am af4fa685: Merge ""Log CCS exceptions do not merge."" into lmp-dev
* commit 'af4fa685f246aaa80c93af62faadbc2fe87dc034':
Log CCS exceptions do not merge./Merge ""Log CCS exceptions do not merge."" into lmp-dev/Log CCS exceptions do not merge.
Unlike the previous CL, this uses reflection for android.os.Process and
android.util.EventLog throughout.
(cherry picked from commit 35b1f354ec2b647966a198ffed932d82eb8eeb5b)
Bug: 15452942
Change-Id: I34b9eaedf1f1e450b1f8004887bb0482601d789e/am 5713cdf7: am e08f2385: OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
* commit '5713cdf71c5c6e5179e8369263c702e9512afdd0':
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN./am cf557195: am 986aeb78: Merge ""Various fixes in OpenSSLEngineImpl.""
* commit 'cf557195a9b60d7f51a48500afde38481ddbc91c':
Various fixes in OpenSSLEngineImpl./OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
(cherry picked from commit e08f238580e8ee471012bef8240c8d3397c7b780)
Bug: 16352665
Change-Id: Idc78204b7077fb367b64e1867c807cd39f596f98/Various fixes in OpenSSLEngineImpl.
Fix ""Buffers were not large enough"" exception by directly using the
destination buffers.
Corrections around bytesProduced and bytesConsumed behavior.
Return BUFFER_OVERFLOW if a zero length destination is provided to
unwrap.
(cherry picked from commit bdfcc189efe41a3f812aeb55ea634bace67d159a)
Bug: 16352665
Change-Id: I1f1e9b72cd6968ed4f3c3c0edccbccebc33d6790/am e08f2385: OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
* commit 'e08f238580e8ee471012bef8240c8d3397c7b780':
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN./am 986aeb78: Merge ""Various fixes in OpenSSLEngineImpl.""
* commit '986aeb78e533540463daf1753e24840f75b25ce6':
Various fixes in OpenSSLEngineImpl./OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
Change-Id: Idc78204b7077fb367b64e1867c807cd39f596f98/Merge ""Various fixes in OpenSSLEngineImpl.""/Various fixes in OpenSSLEngineImpl.
Fix ""Buffers were not large enough"" exception by directly using the
destination buffers.
Corrections around bytesProduced and bytesConsumed behavior.
Return BUFFER_OVERFLOW if a zero length destination is provided to
unwrap.
Change-Id: I1f1e9b72cd6968ed4f3c3c0edccbccebc33d6790/Log CCS exceptions
Unlike the previous CL, this uses reflection for android.os.Process and
android.util.EventLog throughout.
Bug: 15452942
Change-Id: I34b9eaedf1f1e450b1f8004887bb0482601d789e/Revert ""Log OpenSSL CCS errors""
This reverts commit b1599520cdcdda73babffc051590a2dd25cd50be.
Some build targets (e.g. git_dalvik-dev) do not have API-1 Android APIs available, like android.os.Process and android.util.EventLog. Investigating.
Change-Id: Iddce3f445be0502d1afa4f8244a7b8867721613e/Log OpenSSL CCS errors
Bug: 15452942
Change-Id: I49e7bad6a65c70e113324c02fc23315cff168f5b/Expose support for TLS-PSK.
TLS-PSK (Pre-Shared Key) is a set of TLS/SSL cipher suites that use
symmetric (pre-shared) keys for mutual authentication of peers. These
cipher suites are in some scenarios more suitable than those based on
public key cryptography and X.509. See RFC 4279 (Pre-Shared Key
Ciphersuites for Transport Layer Security (TLS)) for more information.
OpenSSL currently supports only the following PSK cipher suites:
* TLS_ECDHE_PSK_WITH_AES_128_CBC_SHA256
* TLS_ECDHE_PSK_WITH_AES_256_CBC_SHA384
* TLS_PSK_WITH_3DES_EDE_CBC_SHA
* TLS_PSK_WITH_AES_128_CBC_SHA
* TLS_PSK_WITH_AES_256_CBC_SHA
* TLS_PSK_WITH_RC4_128_SHA
The last four cipher suites mutually authenticate the peers and
secure the connection using a pre-shared symmetric key. These cipher
suites do not provide Forward Secrecy -- once the pre-shared key is
compromised, all previous communications secured with that key can be
decrypted. The first two cipher suites combine the pre-shared
symmetric key with an ephemeral key obtained from an ECDH key
exchange performed during the TLS/SSL handshake, thus providing
Forward Secrecy.
Users of TLS-PSK are expected to provide an implementation of
PSKKeyManager to SSLContext.init and then enable at least one PSK
cipher suite in SSLSocket/SSLEngine.
Bug: 15073623
Change-Id: I8e59264455f980f23a5e66099c27b5b4d932b9bb/Unbundle: hacks to let Conscrypt compile standalone
This is the first pass at getting Conscrypt to compile standalone. It
works fine in apps currently. There are a few TODOs to fix.
Change-Id: I9b43ba12c55e04c8897ccacf38979ca671a55a26/"
conscrypt,"am af4fa685: Merge ""Log CCS exceptions do not merge."" into lmp-dev
* commit 'af4fa685f246aaa80c93af62faadbc2fe87dc034':
Log CCS exceptions do not merge./Merge ""Log CCS exceptions do not merge."" into lmp-dev/Log CCS exceptions do not merge.
Unlike the previous CL, this uses reflection for android.os.Process and
android.util.EventLog throughout.
(cherry picked from commit 35b1f354ec2b647966a198ffed932d82eb8eeb5b)
Bug: 15452942
Change-Id: I34b9eaedf1f1e450b1f8004887bb0482601d789e/Log CCS exceptions
Unlike the previous CL, this uses reflection for android.os.Process and
android.util.EventLog throughout.
Bug: 15452942
Change-Id: I34b9eaedf1f1e450b1f8004887bb0482601d789e/Revert ""Log OpenSSL CCS errors""
This reverts commit b1599520cdcdda73babffc051590a2dd25cd50be.
Some build targets (e.g. git_dalvik-dev) do not have API-1 Android APIs available, like android.os.Process and android.util.EventLog. Investigating.
Change-Id: Iddce3f445be0502d1afa4f8244a7b8867721613e/Log OpenSSL CCS errors
Bug: 15452942
Change-Id: I49e7bad6a65c70e113324c02fc23315cff168f5b/SSLParametersImpl is the source of enabled cipher suites and protocols.
An instance of SSLParametersImpl is associated with SSLContext and is
then cloned into any SSLSocketFactory, SSLServerSocketFactory,
SSLSocket, SSLServerSocket, and SSLEngine. This CL ensures that all
these primitives obtain their list of enabled cipher suites and
protocols from their instance of SSLParametersImpl.
Bug: 15073623
Change-Id: I40bf32e8654b299518ec0e77c3218a0790d9c4fd/Expose support for TLS-PSK.
TLS-PSK (Pre-Shared Key) is a set of TLS/SSL cipher suites that use
symmetric (pre-shared) keys for mutual authentication of peers. These
cipher suites are in some scenarios more suitable than those based on
public key cryptography and X.509. See RFC 4279 (Pre-Shared Key
Ciphersuites for Transport Layer Security (TLS)) for more information.
OpenSSL currently supports only the following PSK cipher suites:
* TLS_ECDHE_PSK_WITH_AES_128_CBC_SHA256
* TLS_ECDHE_PSK_WITH_AES_256_CBC_SHA384
* TLS_PSK_WITH_3DES_EDE_CBC_SHA
* TLS_PSK_WITH_AES_128_CBC_SHA
* TLS_PSK_WITH_AES_256_CBC_SHA
* TLS_PSK_WITH_RC4_128_SHA
The last four cipher suites mutually authenticate the peers and
secure the connection using a pre-shared symmetric key. These cipher
suites do not provide Forward Secrecy -- once the pre-shared key is
compromised, all previous communications secured with that key can be
decrypted. The first two cipher suites combine the pre-shared
symmetric key with an ephemeral key obtained from an ECDH key
exchange performed during the TLS/SSL handshake, thus providing
Forward Secrecy.
Users of TLS-PSK are expected to provide an implementation of
PSKKeyManager to SSLContext.init and then enable at least one PSK
cipher suite in SSLSocket/SSLEngine.
Bug: 15073623
Change-Id: I8e59264455f980f23a5e66099c27b5b4d932b9bb/Unbundle: hacks to let Conscrypt compile standalone
This is the first pass at getting Conscrypt to compile standalone. It
works fine in apps currently. There are a few TODOs to fix.
Change-Id: I9b43ba12c55e04c8897ccacf38979ca671a55a26/"
conscrypt,"Add pre-Honeycomb literal IP matching
This will allow us to run this code on Gingerbread devices and others
that don't have the InetAddress#isNumeric API.
Bug: 16658420
Bug: 17059757
Change-Id: I597d539979d58eeaa2677d6f99e911313a550cc1/Read property to enable SNI
Read the system property ""jsse.enableSNIExtension"" on whether to enable
Server Name Indication (SNI) extension. For unbundled builds, this will
be enabled by default. For platform builds, this will be disabled by
default.
Bug: 16658420
Bug: 17059757
Change-Id: I774f5406bf3fe601a42c4ef5e708b31800147eb9/Validate hostname is usable for SNI
According to RFC 6066 section 3, the hostname listed in the Server Name
Indication (SNI) field is a fully qualified domain name and IP
addresses are not permitted.
Bug: 16658420
Bug: 17059757
Change-Id: I804e46b6e66599b2770f0f4f0534467987e51208/"
conscrypt,"am f427ec90: Fix the ENGINE_finish/ENGINE_free mixup
* commit 'f427ec902fa84d8df4f6dfc2822005a215023dde':
Fix the ENGINE_finish/ENGINE_free mixup/am 532488fd: am 9a4f1dfb: Fix the ENGINE_finish/ENGINE_free mixup
* commit '532488fdcaecc1fb5b3bfe3f31aa3fd0164fd3c6':
Fix the ENGINE_finish/ENGINE_free mixup/am 9a4f1dfb: Fix the ENGINE_finish/ENGINE_free mixup
* commit '9a4f1dfbeea80ec52c0d551afceb68435798c1a8':
Fix the ENGINE_finish/ENGINE_free mixup/am 984b7ec6: Fix the ENGINE_finish/ENGINE_free mixup
* commit '984b7ec6f5aab314117949a48e448ff4f6b65f16':
Fix the ENGINE_finish/ENGINE_free mixup/Fix the ENGINE_finish/ENGINE_free mixup
The tests were calling finish when it meant free. This caused tests to
segmentation fault next time the ENGINE was looked up in the dynamic
engine list.
(cherry picked from commit 984b7ec6f5aab314117949a48e448ff4f6b65f16)
Bug: 14994037
Change-Id: If7379fee26f7e79fa0b43104ac9d13b4ffb62ba8/Fix the ENGINE_finish/ENGINE_free mixup
The tests were calling finish when it meant free. This caused tests to
segmentation fault next time the ENGINE was looked up in the dynamic
engine list.
(cherry picked from commit 984b7ec6f5aab314117949a48e448ff4f6b65f16)
Bug: 14994037
Change-Id: If7379fee26f7e79fa0b43104ac9d13b4ffb62ba8/Fix the ENGINE_finish/ENGINE_free mixup
The tests were calling finish when it meant free. This caused tests to
segmentation fault next time the ENGINE was looked up in the dynamic
engine list.
Bug: 14994037
Change-Id: If7379fee26f7e79fa0b43104ac9d13b4ffb62ba8/"
conscrypt,"Read property to enable SNI
Read the system property ""jsse.enableSNIExtension"" on whether to enable
Server Name Indication (SNI) extension. For unbundled builds, this will
be enabled by default. For platform builds, this will be disabled by
default.
Bug: 16658420
Bug: 17059757
Change-Id: I774f5406bf3fe601a42c4ef5e708b31800147eb9/Validate hostname is usable for SNI
According to RFC 6066 section 3, the hostname listed in the Server Name
Indication (SNI) field is a fully qualified domain name and IP
addresses are not permitted.
Bug: 16658420
Bug: 17059757
Change-Id: I804e46b6e66599b2770f0f4f0534467987e51208/"
conscrypt,"Comment out unused parameters and function.
BUG: 17281763
Change-Id: I6874dc0ef6ddaba66d465c07cabeb5e781337716/No need to select NPN protocols when not enabled
Bug: 16957575
Change-Id: I351316a62f9b583b37b54f3e7fbfaa0450439ca4/OpenSSLSocketImpl: Move state checks inside mutex
Checking the state of the connection is unreliable if SSL_read and
SSL_write are happening in another thread. Move the state checks inside
our application mutex so we don't run into another thread mutating the
state at the same time.
Bug: 15606096
(cherry picked from commit 0931d51c58b2dc2f612298f99fbf0fa6ed4c3706)
Change-Id: I151ecbc57278374007a56827a65295b4c9476732/OpenSSLSocketImpl: Move state checks inside mutex
Checking the state of the connection is unreliable if SSL_read and
SSL_write are happening in another thread. Move the state checks inside
our application mutex so we don't run into another thread mutating the
state at the same time.
Bug: 15606096
Change-Id: I5ecdeb1551a13098d1b66c5e4009607c9951fa38/am f4b895ae: am a260ee6d: Revert ""Revert ""Automatic management of OpenSSL error stack""""
* commit 'f4b895ae9c424b5c2d49c744131606adccbc49d7':
Revert ""Revert ""Automatic management of OpenSSL error stack""""/am a35c4001: am 30550a8b: Fix debugging with unbundled conscrypt
* commit 'a35c40017c8690f821351d6460dfeaa2738b884c':
Fix debugging with unbundled conscrypt/am a260ee6d: Revert ""Revert ""Automatic management of OpenSSL error stack""""
* commit 'a260ee6d0caea43f8010f158a4a35fb712935ae3':
Revert ""Revert ""Automatic management of OpenSSL error stack""""/am 30550a8b: Fix debugging with unbundled conscrypt
* commit '30550a8b64bbcd6ca537680a17b8726932a29937':
Fix debugging with unbundled conscrypt/Revert ""Revert ""Automatic management of OpenSSL error stack""""
The ""else"" statement in OpenSslError::reset wasn't properly resetting
the error state which made a second call into sslRead jump into
sslSelect when it should have just returned immediately.
Change-Id: I22e8025c0497a04e78daa07cef78191a6ca1a70c/Fix debugging with unbundled conscrypt
When JNI_TRACE was enabled, there were missing defines for the debugging
code since no platform code is included.
Also clang complains about more of the debugging statement formats, so
we have to move some things around to get it to be happy.
Change-Id: I1a6695c2ef2639cc01cfc3d3a8603f010c659844/am 2411b8bd: Merge ""Revert ""Automatic management of OpenSSL error stack""""
* commit '2411b8bdcde72c956f4150e9a5909b7501f50bad':
Revert ""Automatic management of OpenSSL error stack""/Revert ""Automatic management of OpenSSL error stack""
This reverts commit 35666e4cb0fcd063a21d17eebbb571b4e4e822b8.
(cherry picked from commit b514d72b93c3996d97e38eca6db1ad684965fd9b)
Change-Id: I926d159c4c4b99250caef750732976c1e601e9ef/Merge ""Revert ""Automatic management of OpenSSL error stack""""/Revert ""Automatic management of OpenSSL error stack""
This reverts commit 35666e4cb0fcd063a21d17eebbb571b4e4e822b8.
Change-Id: I926d159c4c4b99250caef750732976c1e601e9ef/am 107a8fba: am 3262a8c2: Merge ""Automatic management of OpenSSL error stack""
* commit '107a8fba8be5be57933f2638b76ac1243b578b9e':
Automatic management of OpenSSL error stack/am 3262a8c2: Merge ""Automatic management of OpenSSL error stack""
* commit '3262a8c2741b95103149bcdefe2409c24bfddee9':
Automatic management of OpenSSL error stack/Merge ""Automatic management of OpenSSL error stack""/Automatic management of OpenSSL error stack
This removes some complexity in remembering to free the OpenSSL error
stack. If you forget, the error will stick around until you make another
call.
Change-Id: I245a525dcc93077b2bf9909a14a0ef469a2daca4/am 94890aec: am 977f0877: Fix some JNI_TRACE lines
* commit '94890aec5735cde2ea5170fb76cd1b847ea66af8':
Fix some JNI_TRACE lines/am 977f0877: Fix some JNI_TRACE lines
* commit '977f08774c628b4640d5454cde050259856965f8':
Fix some JNI_TRACE lines/Fix some JNI_TRACE lines
During debugging these would be enabled, but they were copy-pasta'd to
with the wrong args.
Change-Id: I23f39ff4807e3fa71f3220912aec3c99db6b9454/"
conscrypt,"Add support for TLS_FALLBACK_SCSV
(cherry picked from commit 8d7e23e117da591a8d48e6bcda9ed6f58ff1a375)
Bug: 17750026
Change-Id: Iaf437ce2bc2b0ae86bb90a67e6e5378b25ae0a81/Add support for TLS_FALLBACK_SCSV
Bug: 17750026
Change-Id: I1c2ecbeb914db645f440d58e7f7daa86d880ad6f/"
conscrypt,"Use consistent naming for SSLSocket arguments
This changes all the 'host' to be 'hostname' and anything that takes an
'InetAddress' will have the name of 'address' to avoid confusing it with
a hostname.
Bug: 16658420
Bug: 17059757
Change-Id: Iac0628d2d156023dbb80c2e636af6bfe63f46650/"
conscrypt,"Rename hostname fields and methods to reflect usage
The hostname that was supplied when the socket was created is stored as
the ""peerHostname""  This is the only one that should be used for Server
Name Indication (SNI) purposes.
The ""peerHostname"" or the resolved IP address may be used for
certificate validation, so keep the use of ""getHostname()"" for
cerificate validation.
Bug: 16658420
Bug: 17059757
Change-Id: Ifd87dead44fb2f00bbfd5eac7e69fb3fc98e94b4/Use consistent naming for SSLSocket arguments
This changes all the 'host' to be 'hostname' and anything that takes an
'InetAddress' will have the name of 'address' to avoid confusing it with
a hostname.
Bug: 16658420
Bug: 17059757
Change-Id: Iac0628d2d156023dbb80c2e636af6bfe63f46650/"
conscrypt,"Squashed commit of changes from lmp-ub-dev
Contains the following changes:
commit e31d982cdb0f8e6ef05d1e412576888015e1da17
Merge: eaebc54 b73be72
Author: Neil Fuller <nfuller@google.com>
Date:   Wed Oct 22 10:34:23 2014 +0000
am b73be72e: am 3e21a289: (-s ours) TLS_FALLBACK_SCSV CTS fix for klp-modular-dev
* commit 'b73be72ed97da8f36450d95d52f485cc6f451c61':
TLS_FALLBACK_SCSV CTS fix for klp-modular-dev
commit eaebc544f3a10c53d7d2f908514122caba569e14
Merge: 223b5da cd50afa
Author: Kenny Root <kroot@google.com>
Date:   Tue Oct 14 17:30:19 2014 +0000
Merge ""Fix SSLEngine to support session resumption."" into lmp-ub-dev
commit 223b5da5d70e47b1a497e86474493925b568f6d7
Merge: 8737796 cb7a360
Author: Neil Fuller <nfuller@google.com>
Date:   Thu Oct 9 14:52:00 2014 +0000
am cb7a3605: am ea961ada: Apply conscrypt changes from merge commit
* commit 'cb7a36050f34d3c16be00d532411820761eeb276':
Apply conscrypt changes from merge commit
commit cd50afad1567b1311e6e979e94a7167b7bf69c94
Author: Doug Steedman <dougsteed@google.com>
Date:   Mon Oct 6 13:16:15 2014 -0700
Fix SSLEngine to support session resumption.
Bug: 17877118
Change-Id: I388b59cde58fdc506ecac9f536e4bbd9161df6ad
commit 8737796a646eaec94df32827752a71aee74bd46f
Merge: 9564a5f 8d7e23e
Author: Kenny Root <kroot@google.com>
Date:   Mon Oct 6 22:34:20 2014 +0000
am 8d7e23e1: Add support for TLS_FALLBACK_SCSV
* commit '8d7e23e117da591a8d48e6bcda9ed6f58ff1a375':
Add support for TLS_FALLBACK_SCSV
commit 9564a5fb9ed2eecf6299788db35213cb08397212
Merge: 4f58feb 7640613
Author: Kenny Root <kroot@google.com>
Date:   Fri Sep 12 17:27:23 2014 +0000
am 76406135: am 6dcb23fe: am f427ec90: Fix the ENGINE_finish/ENGINE_free mixup
* commit '76406135cf3a3b88afc979fe8e847b9c3d8b93c1':
Fix the ENGINE_finish/ENGINE_free mixup
commit 4f58feb0ea49dc089a95efba196032ef3c960a39
Merge: ddac5c6 984b7ec
Author: Kenny Root <kroot@google.com>
Date:   Wed Sep 10 07:07:16 2014 +0000
am 984b7ec6: Fix the ENGINE_finish/ENGINE_free mixup
* commit '984b7ec6f5aab314117949a48e448ff4f6b65f16':
Fix the ENGINE_finish/ENGINE_free mixup
commit ddac5c6d7e413b0d68b388fbdf70dbeb3eeae865
Merge: 5a8ca5b 36ba60b
Author: Kenny Root <kroot@google.com>
Date:   Thu Sep 4 22:41:38 2014 +0000
Merge ""Reset lmp-ub-dev to lmp-dev-plus-aosp"" into lmp-ub-dev
commit 36ba60b039f1f30ab1ea8f0e2a4da8ae4e3906e5
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 27 12:07:07 2014 -0700
Reset lmp-ub-dev to lmp-dev-plus-aosp
Bug: 17059757
Change-Id: I581963360da47b574e1e2e20c2851485c36fa62c
commit 6a4f2ef9e4ea3ebb321d45ca39b30d634ea3b4ad
Merge: 9b187af f67d784
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:17:38 2014 +0000
am f67d784a: Add pre-Honeycomb literal IP matching
* commit 'f67d784abe5cef700240be02c68cecd899cd8e6d':
Add pre-Honeycomb literal IP matching
commit 9b187af33dcd97915a0371d64fe1ee4aba20d0ba
Merge: 714ebea 966ae8a
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:17:37 2014 +0000
am 966ae8a6: Read property to enable SNI
* commit '966ae8a6e12f3235b1cb041e687bda11b41fe4eb':
Read property to enable SNI
commit 714ebeabcb5e35c6df6a5c21f549cdb6130368c4
Merge: 7724204 54a1ba4
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:06:54 2014 +0000
Merge ""resolved conflicts for merge of 342097db to lmp-dev-plus-aosp"" into lmp-dev-plus-aosp
commit 54a1ba421d23bb6d988688c2662715e509172447
Merge: a20d871 342097d
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 21:03:51 2014 -0700
resolved conflicts for merge of 342097db to lmp-dev-plus-aosp
Change-Id: I853c6b0d3725dafbdc84c4d6d6d1b90529bd949d
commit 7724204abf4431d35787c44c4a22cda5489d4e37
Merge: 20f60ac afb3403
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 00:09:27 2014 +0000
am afb34034: Implement write socket timeouts for unbundled apps
* commit 'afb340348bfc54dbc46964e159fe803f9c93a4dd':
Implement write socket timeouts for unbundled apps
commit f67d784abe5cef700240be02c68cecd899cd8e6d
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 14:14:26 2014 -0700
Add pre-Honeycomb literal IP matching
This will allow us to run this code on Gingerbread devices and others
that don't have the InetAddress#isNumeric API.
Bug: 16658420
Bug: 17059757
Change-Id: I597d539979d58eeaa2677d6f99e911313a550cc1
commit 966ae8a6e12f3235b1cb041e687bda11b41fe4eb
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 18 10:12:20 2014 -0700
Read property to enable SNI
Read the system property ""jsse.enableSNIExtension"" on whether to enable
Server Name Indication (SNI) extension. For unbundled builds, this will
be enabled by default. For platform builds, this will be disabled by
default.
Bug: 16658420
Bug: 17059757
Change-Id: I774f5406bf3fe601a42c4ef5e708b31800147eb9
commit 342097db97a9b2736531033b2c4b4d8ce4998c67
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 12:14:52 2014 -0700
Validate hostname is usable for SNI
According to RFC 6066 section 3, the hostname listed in the Server Name
Indication (SNI) field is a fully qualified domain name and IP
addresses are not permitted.
Bug: 16658420
Bug: 17059757
Change-Id: I804e46b6e66599b2770f0f4f0534467987e51208
commit afb340348bfc54dbc46964e159fe803f9c93a4dd
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 19 16:33:07 2014 -0700
Implement write socket timeouts for unbundled apps
Change-Id: I4fd604f057ba4288d4f31bf6b3b93307376023d5
commit 20f60acea153dfdf0c8f75a53d7bd9edb4c7614c
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 11:52:05 2014 -0700
Tracking change from AOSP
Change-Id: I889af3f7c1de9ef34d9328339e1b421651055ad4
commit 68056b7c9db8a9fb384bbadfc5287730f996896d
Merge: 8239dfd cc2ef2e
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 18:03:27 2014 +0000
am cc2ef2e2: Rename hostname fields and methods to reflect usage
* commit 'cc2ef2e2e9ee64f2e0ac2abc7fdf636e2f81fa5e':
Rename hostname fields and methods to reflect usage
commit 8239dfdcc40a69255d7b2feced960d574ea36321
Merge: e9cf759 076138f
Author: Kenny Root <kroot@google.com>
Date:   Thu Aug 21 16:36:24 2014 +0000
am 076138ff: Use consistent naming for SSLSocket arguments
* commit '076138ff29d805ec5a32d6ad96a18ef08c7f1b11':
Use consistent naming for SSLSocket arguments
commit cc2ef2e2e9ee64f2e0ac2abc7fdf636e2f81fa5e
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 11:26:33 2014 -0700
Rename hostname fields and methods to reflect usage
The hostname that was supplied when the socket was created is stored as
the ""peerHostname""  This is the only one that should be used for Server
Name Indication (SNI) purposes.
The ""peerHostname"" or the resolved IP address may be used for
certificate validation, so keep the use of ""getHostname()"" for
cerificate validation.
Bug: 16658420
Bug: 17059757
Change-Id: Ifd87dead44fb2f00bbfd5eac7e69fb3fc98e94b4
commit 076138ff29d805ec5a32d6ad96a18ef08c7f1b11
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 11:24:41 2014 -0700
Use consistent naming for SSLSocket arguments
This changes all the 'host' to be 'hostname' and anything that takes an
'InetAddress' will have the name of 'address' to avoid confusing it with
a hostname.
Bug: 16658420
Bug: 17059757
Change-Id: Iac0628d2d156023dbb80c2e636af6bfe63f46650
commit e9cf759ac89fb053c01f1db19931beb14a823618
Merge: ababdd1 7ed0fae
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 19 19:32:43 2014 +0000
am 7ed0fae1: OpenSSLEngineImpl: reduce number of copies needed
* commit '7ed0fae1906061766d0042e69ccba20e4a702bbe':
OpenSSLEngineImpl: reduce number of copies needed
commit 7ed0fae1906061766d0042e69ccba20e4a702bbe
Author: Kenny Root <kroot@google.com>
Date:   Tue Jul 22 13:03:09 2014 -0700
OpenSSLEngineImpl: reduce number of copies needed
When the ByteBuffer didn't line up exactly with the backing array, it
would allocate a new buffer to write into. Instead, add the ability for
OpenSSL to read at an offset in the given array so a copy isn't needed.
Change-Id: I149d3f94e4b5cbdc010df80439ae3300cbdc87a5
commit ababdd1ae1272eac174e3a449a413ab35afbc435
Merge: 66c31e0 4b050b6
Author: Kenny Root <kroot@google.com>
Date:   Fri Aug 15 16:23:14 2014 +0000
am 4b050b6f: OpenSSLSocketImpl: Move state checks inside mutex
* commit '4b050b6fb06fbb804557eecc72cc4ff0e0277525':
OpenSSLSocketImpl: Move state checks inside mutex
commit 66c31e0b613ceefc167a2e1fb226a14c78f84537
Merge: f4b895a 0931d51
Author: Kenny Root <kroot@google.com>
Date:   Thu Aug 14 20:46:43 2014 +0000
am 0931d51c: OpenSSLSocketImpl: Move state checks inside mutex
* commit '0931d51c58b2dc2f612298f99fbf0fa6ed4c3706':
OpenSSLSocketImpl: Move state checks inside mutex
commit 0931d51c58b2dc2f612298f99fbf0fa6ed4c3706
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 15:45:32 2014 -0700
OpenSSLSocketImpl: Move state checks inside mutex
Checking the state of the connection is unreliable if SSL_read and
SSL_write are happening in another thread. Move the state checks inside
our application mutex so we don't run into another thread mutating the
state at the same time.
Bug: 15606096
Change-Id: I5ecdeb1551a13098d1b66c5e4009607c9951fa38
commit f4b895ae9c424b5c2d49c744131606adccbc49d7
Merge: a35c400 a260ee6
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 13 15:35:28 2014 +0000
am a260ee6d: Revert ""Revert ""Automatic management of OpenSSL error stack""""
* commit 'a260ee6d0caea43f8010f158a4a35fb712935ae3':
Revert ""Revert ""Automatic management of OpenSSL error stack""""
commit a35c40017c8690f821351d6460dfeaa2738b884c
Merge: 0edc483 30550a8
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 13 15:35:27 2014 +0000
am 30550a8b: Fix debugging with unbundled conscrypt
* commit '30550a8b64bbcd6ca537680a17b8726932a29937':
Fix debugging with unbundled conscrypt
commit a260ee6d0caea43f8010f158a4a35fb712935ae3
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:38:10 2014 -0700
Revert ""Revert ""Automatic management of OpenSSL error stack""""
The ""else"" statement in OpenSslError::reset wasn't properly resetting
the error state which made a second call into sslRead jump into
sslSelect when it should have just returned immediately.
Change-Id: I22e8025c0497a04e78daa07cef78191a6ca1a70c
commit 30550a8b64bbcd6ca537680a17b8726932a29937
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:13:33 2014 -0700
Fix debugging with unbundled conscrypt
When JNI_TRACE was enabled, there were missing defines for the debugging
code since no platform code is included.
Also clang complains about more of the debugging statement formats, so
we have to move some things around to get it to be happy.
Change-Id: I1a6695c2ef2639cc01cfc3d3a8603f010c659844
commit 0edc4833091846d6cb45961fc9458df842fbbad9
Merge: 107a8fb 2411b8b
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:46:12 2014 +0000
am 2411b8bd: Merge ""Revert ""Automatic management of OpenSSL error stack""""
* commit '2411b8bdcde72c956f4150e9a5909b7501f50bad':
Revert ""Automatic management of OpenSSL error stack""
commit 2411b8bdcde72c956f4150e9a5909b7501f50bad
Merge: 3262a8c b514d72
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:39:32 2014 +0000
Merge ""Revert ""Automatic management of OpenSSL error stack""""
commit b514d72b93c3996d97e38eca6db1ad684965fd9b
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:39:17 2014 +0000
Revert ""Automatic management of OpenSSL error stack""
This reverts commit 35666e4cb0fcd063a21d17eebbb571b4e4e822b8.
Change-Id: I926d159c4c4b99250caef750732976c1e601e9ef
commit 107a8fba8be5be57933f2638b76ac1243b578b9e
Merge: 1de007f 3262a8c
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:50:14 2014 +0000
am 3262a8c2: Merge ""Automatic management of OpenSSL error stack""
* commit '3262a8c2741b95103149bcdefe2409c24bfddee9':
Automatic management of OpenSSL error stack
commit 1de007f9f01be8f07a56235dd924c897088a03cb
Merge: 94890ae d1bbcd0
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:50:14 2014 +0000
am d1bbcd0e: Relax checks for key vs cert for wrapped keys
* commit 'd1bbcd0ec973e1b8465c204c13b4925fd86e6484':
Relax checks for key vs cert for wrapped keys
commit 3262a8c2741b95103149bcdefe2409c24bfddee9
Merge: d1bbcd0 35666e4
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:31:02 2014 +0000
Merge ""Automatic management of OpenSSL error stack""
commit d1bbcd0ec973e1b8465c204c13b4925fd86e6484
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 11 14:56:58 2014 -0700
Relax checks for key vs cert for wrapped keys
If a key is a wrapped platform key, we must relax the check. The reason
is that we may not have the public values we need to pass the
EVP_PKEY_cmp checks that this does.
Change-Id: I7ab2be51b0968a9cf771edea01d33fe2367c8185
commit 35666e4cb0fcd063a21d17eebbb571b4e4e822b8
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 11:05:00 2014 -0700
Automatic management of OpenSSL error stack
This removes some complexity in remembering to free the OpenSSL error
stack. If you forget, the error will stick around until you make another
call.
Change-Id: I245a525dcc93077b2bf9909a14a0ef469a2daca4
commit 94890aec5735cde2ea5170fb76cd1b847ea66af8
Merge: 8360485 977f087
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 16:44:42 2014 +0000
am 977f0877: Fix some JNI_TRACE lines
* commit '977f08774c628b4640d5454cde050259856965f8':
Fix some JNI_TRACE lines
commit 977f08774c628b4640d5454cde050259856965f8
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 4 12:15:04 2014 -0700
Fix some JNI_TRACE lines
During debugging these would be enabled, but they were copy-pasta'd to
with the wrong args.
Change-Id: I23f39ff4807e3fa71f3220912aec3c99db6b9454
commit 83604854c5160304cafefc9bd40a72c5ee8506eb
Merge: 7db3524 1ffe43e
Author: Zoltan Szatmary-Ban <szatmz@google.com>
Date:   Thu Jul 31 13:28:57 2014 +0000
am 1ffe43e8: Merge ""Add possibility to get deleted system Certificate Aliases"" into lmp-dev
* commit '1ffe43e8277e883c6663c1fb7cfc5e18ba552c40':
Add possibility to get deleted system Certificate Aliases
commit 7db3524880092126962b7f502af76b4c84da7350
Merge: 5767d63 ad0cd83
Author: Prameet Shah <phshah@google.com>
Date:   Wed Jul 30 17:04:13 2014 +0000
am ad0cd830: Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
* commit 'ad0cd83024f38011043d28d70370a8638b88cd72':
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
commit 5767d63d22e87becab387b3bd6597fe41eb34d7e
Merge: b389e17 26163c2
Author: Prameet Shah <phshah@google.com>
Date:   Wed Jul 30 16:31:08 2014 +0000
am 26163c26: Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
* commit '26163c268a6d2625384b87e907afad8ef19f9a47':
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
commit 26163c268a6d2625384b87e907afad8ef19f9a47
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 29 16:45:31 2014 -0700
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
Bug: https://code.google.com/p/android/issues/detail?id=73745
Change-Id: I5bcaf3ee8910ff75e785baed4c4604fee6c5e700
commit b389e1779651f2c58454a5f98acebd3dd7bc0061
Merge: 5f03b4d e427972
Author: Prameet Shah <phshah@google.com>
Date:   Thu Jul 24 19:46:28 2014 +0000
am e427972e: OpenSSLEngineImpl: fix unwrap behavior with array
* commit 'e427972eb6141cd67e6d4c9607863a8d990e6be6':
OpenSSLEngineImpl: fix unwrap behavior with array
commit 5f03b4d63c7632581b032879de791dc82f05ffa0
Merge: 3d935ee 41eb5b6
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 22 19:26:41 2014 +0000
am 41eb5b65: OpenSSLEngineImpl: fix unwrap behavior with array
* commit '41eb5b65e524d01e28da474bd37e4349b12fb494':
OpenSSLEngineImpl: fix unwrap behavior with array
commit 41eb5b65e524d01e28da474bd37e4349b12fb494
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 22 11:50:18 2014 -0700
OpenSSLEngineImpl: fix unwrap behavior with array
The decrypted bytes should written sequentially into each buffer of
the destination array until it's full before moving to the next
buffer.
Change-Id: I2454249c167deafde6c12134d3c8cd658cd7c21b
commit 3d935eeca25e00b56cfd8d37a657c7b2986889b3
Merge: 0a36f6c affd45a
Author: Alex Klyubin <klyubin@google.com>
Date:   Fri Jul 18 00:32:14 2014 +0000
am affd45a4: Merge ""Improve the Javadoc of PSKKeyManager."" into lmp-dev
* commit 'affd45a413cf844dad797ad4972074efb9de43d8':
Improve the Javadoc of PSKKeyManager.
commit 0a36f6c1f8b2e195c2dd5aea1a386df090c6d470
Merge: 6492180 af4fa68
Author: rich cannings <richc@google.com>
Date:   Thu Jul 17 23:47:33 2014 +0000
am af4fa685: Merge ""Log CCS exceptions do not merge."" into lmp-dev
* commit 'af4fa685f246aaa80c93af62faadbc2fe87dc034':
Log CCS exceptions do not merge.
commit 6492180ce17a3b5ff822cff1783f00e7a4176491
Merge: aac4168 3b7268c
Author: Alex Klyubin <klyubin@google.com>
Date:   Thu Jul 17 18:27:39 2014 +0000
am 3b7268cd: Merge ""Improve the Javadoc of PSKKeyManager.""
* commit '3b7268cde4a4fc59591da8a93691927ebf3add57':
Improve the Javadoc of PSKKeyManager.
commit aac4168d8baef7e12d6fa959c6d6ded9892e9651
Merge: 8573ad0 a749c0d
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 17 17:07:05 2014 +0000
am a749c0d3: Keep enough state to completely reset cipher instances
* commit 'a749c0d351216be38879600ee8ed01c6793aa256':
Keep enough state to completely reset cipher instances
commit 8573ad0ddcf7e2f8b2e5ac84c34b7ffab303155c
Merge: 4ca5b06 70fdb6d
Author: Koushik Dutta <koushd@gmail.com>
Date:   Thu Jul 17 17:06:36 2014 +0000
am 70fdb6d2: OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
* commit '70fdb6d2bfa0c313fe389827f0025288f6aeb947':
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
commit 4ca5b0625e3f5a15ae8adf833ab5a69f9d7d517f
Merge: 119abfb ded66f5
Author: Koushik Dutta <koushd@gmail.com>
Date:   Thu Jul 17 17:06:35 2014 +0000
am ded66f5f: Various fixes in OpenSSLEngineImpl.
* commit 'ded66f5f696994ce7620552e16a4e9124e69e052':
Various fixes in OpenSSLEngineImpl.
commit 119abfba1fcd9c9cfbd15d0a4ca9ed2188fdfab0
Merge: 5713cdf cbe1f28
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 17 15:56:57 2014 +0000
am cbe1f28a: Merge ""Keep enough state to completely reset cipher instances""
* commit 'cbe1f28adf64396561a3b65bf1452dfa9b6e35ae':
Keep enough state to completely reset cipher instances
commit cbe1f28adf64396561a3b65bf1452dfa9b6e35ae
Merge: e08f238 084e308
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 17 15:48:58 2014 +0000
Merge ""Keep enough state to completely reset cipher instances""
commit 3b7268cde4a4fc59591da8a93691927ebf3add57
Merge: cbe1f28 7ac13e0
Author: Alex Klyubin <klyubin@google.com>
Date:   Thu Jul 17 18:20:43 2014 +0000
Merge ""Improve the Javadoc of PSKKeyManager.""
commit 5713cdf71c5c6e5179e8369263c702e9512afdd0
Merge: cf55719 e08f238
Author: Koushik Dutta <koushd@gmail.com>
Date:   Wed Jul 16 22:05:17 2014 +0000
am e08f2385: OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
* commit 'e08f238580e8ee471012bef8240c8d3397c7b780':
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
commit cf557195a9b60d7f51a48500afde38481ddbc91c
Merge: cbbd7d1 986aeb7
Author: Kenny Root <kroot@android.com>
Date:   Wed Jul 16 21:41:12 2014 +0000
am 986aeb78: Merge ""Various fixes in OpenSSLEngineImpl.""
* commit '986aeb78e533540463daf1753e24840f75b25ce6':
Various fixes in OpenSSLEngineImpl.
commit e08f238580e8ee471012bef8240c8d3397c7b780
Author: Koushik Dutta <koushd@gmail.com>
Date:   Tue Jul 15 22:40:23 2014 -0700
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
Change-Id: Idc78204b7077fb367b64e1867c807cd39f596f98
commit 7ac13e03a79d0c99d181b1a28b1b3699ba3d5739
Author: Alex Klyubin <klyubin@google.com>
Date:   Wed Jul 16 08:33:02 2014 -0700
Improve the Javadoc of PSKKeyManager.
This clarifies several points and adds sample code.
Bug: 15073623
Change-Id: I6e8aadc52277e238a998d6cee36795dab1151d58
commit 986aeb78e533540463daf1753e24840f75b25ce6
Merge: 8f9ac1a bdfcc18
Author: Kenny Root <kroot@android.com>
Date:   Wed Jul 16 21:15:30 2014 +0000
Merge ""Various fixes in OpenSSLEngineImpl.""
commit bdfcc189efe41a3f812aeb55ea634bace67d159a
Author: Koushik Dutta <koushd@gmail.com>
Date:   Sat Jun 28 19:19:21 2014 -0700
Various fixes in OpenSSLEngineImpl.
Fix ""Buffers were not large enough"" exception by directly using the
destination buffers.
Corrections around bytesProduced and bytesConsumed behavior.
Return BUFFER_OVERFLOW if a zero length destination is provided to
unwrap.
Change-Id: I1f1e9b72cd6968ed4f3c3c0edccbccebc33d6790
commit cbbd7d10e8e484c44a78e5b27e8fecda195f1692
Merge: ec7f8e6 fdb7d8c
Author: Alex Klyubin <klyubin@google.com>
Date:   Tue Jul 15 18:49:14 2014 +0000
am fdb7d8c5: Enable PSK cipher suites when PSKKeyManager is provided.
* commit 'fdb7d8c53dabac5551e2499d045ba6829bcfc0a0':
Enable PSK cipher suites when PSKKeyManager is provided.
commit ec7f8e6b27330160f88540f4f2ace7bc2a0720a3
Merge: 5b8ccf1 8f9ac1a
Author: Alex Klyubin <klyubin@google.com>
Date:   Tue Jul 15 15:53:46 2014 +0000
am 8f9ac1af: Enable PSK cipher suites when PSKKeyManager is provided.
* commit '8f9ac1af0cbdf00e5e47aee32c132522ebc3bd17':
Enable PSK cipher suites when PSKKeyManager is provided.
commit 5b8ccf1b09df6f35c1709bfc8fd727a291094a5b
Merge: 69a2e46 6e2315f
Author: Ed Heyl <edheyl@google.com>
Date:   Tue Jul 15 13:34:25 2014 +0000
am 6e2315fd: reconcile aosp (e79c25bf33e10da41e489c537823f678e1a1169c) after branching. Please do not merge.
* commit '6e2315fd96c3c4a47450c1a437babacc94bc31a6':
reconcile aosp (e79c25bf33e10da41e489c537823f678e1a1169c) after branching. Please do not merge.
commit 084e3086be1d7a6b9280b64c7c8cdb7b41a13bea
Author: Kenny Root <kroot@google.com>
Date:   Mon Jul 14 13:25:32 2014 -0700
Keep enough state to completely reset cipher instances
OpenSSL's RC4 mutates the given key. AES/CTR mutates the IV. We must
store these values locally to enable ""doFinal"" to cause the Cipher
instance to be reset to what it was right after ""init"".
Note that resetting and encrypting with the same key or IV breaks
semantic security.
Bug: 16298401
Bug: https://code.google.com/p/android/issues/detail?id=73339
Change-Id: Ie7e4dcb6cf6cc33ddad31d6b47066dc1b34e6894
commit 69a2e460cc0a40e1b951e400589b9932609079ec
Merge: 8b7bb32 bca895f
Author: David Benjamin <davidben@chromium.org>
Date:   Mon Jul 14 18:17:28 2014 +0000
am bca895f8: Pass output buffer length into EVP_DigestSignFinal.
* commit 'bca895f809dd2cef7a0834f0bfeb2a06e42b277d':
Pass output buffer length into EVP_DigestSignFinal.
commit 8b7bb32af09a01e80442b70dd23e6997a937f103
Merge: a2404c9 e79c25b
Author: Kenny Root <kroot@google.com>
Date:   Mon Jul 14 18:17:28 2014 +0000
am e79c25bf: Merge ""DHKeyPairGenerator: use provided params""
* commit 'e79c25bf33e10da41e489c537823f678e1a1169c':
DHKeyPairGenerator: use provided params
commit 8f9ac1af0cbdf00e5e47aee32c132522ebc3bd17
Author: Alex Klyubin <klyubin@google.com>
Date:   Thu Jun 19 13:37:24 2014 -0700
Enable PSK cipher suites when PSKKeyManager is provided.
This enables TLS-PSK cipher suites by default iff SSLContext is
initialized with a PSKKeyManager. For consistency, X.509 based
cipher suites are no longer enabled by default at all times -- they
are now only enabled by default iff SSLContext is initialized with a
X509KeyManager or a X509TrustManager.
When both X.509 and PSK cipher suites need to be enabled, PSK cipher
suites are given higher priority in the resulting list of cipher
suites. This is based on the assumption that in most cases users of
TLS/SSL who enable TLS-PSK would prefer TLS-PSK to be used when the
peer supports TLS-PSK.
Bug: 15073623
Change-Id: I8e2bc3e7a1ea8a986e468973b6bad19dc6b7bc3c
commit bca895f809dd2cef7a0834f0bfeb2a06e42b277d
Author: David Benjamin <davidben@chromium.org>
Date:   Thu Jul 10 18:12:08 2014 -0400
Pass output buffer length into EVP_DigestSignFinal.
EVP_DigestSignFinal expects the input buffer length as *siglen on input. In
addition, if sigret is NULL, it returns the buffer size needed. Use this rather
than making assumptions about the EVP_PKEY used to initialize the EVP_MD_CTX.
commit e79c25bf33e10da41e489c537823f678e1a1169c
Merge: a328492 9b226f9
Author: Kenny Root <kroot@google.com>
Date:   Fri Jul 11 16:46:23 2014 +0000
Merge ""DHKeyPairGenerator: use provided params""
commit 9b226f90a992a4a2267b7a813e3b869851945c4d
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 10 14:50:48 2014 -0700
DHKeyPairGenerator: use provided params
If the prime is provided in the DHParameterSpec, then use it to generate
the key.
Bug: 16188130
Change-Id: I42de02c71a58d691ef7ba6e2252367105687b758
Bug: 18388980
Change-Id: I853b02a32db113a5af3f6166e7d61fab58c3ff73/"
conscrypt,"Call EVP_CIPHER_CTX_free instead of EVP_CIPHER_CTX_cleanup.
The latter doesn't OpenSSL_free memory allocated by EVP_CIPHER_CTX_new.
It's worth noting that EVP_CIPHER_CTX_free doesn't check the return
value of EVP_CIPHER_CTX_cleanup so we can't throw if cleanup failed, but
we were only ever calling this method from a finalizer anyway.
bug: 18617384
Change-Id: Ida65e14ffbed41f56a59e2f5fe77289cac0f5947/Convert EC_GROUP and EC_POINT to new style
Bug: 16656908
Change-Id: Ie912f376f69327ce634cac50763bf86b418049f5/Switch EVP_CIPHER_CTX to new style
Bug: 16656908
Change-Id: Id519c20474a02c70e72d362bc84d26855a74fa33/Convert EVP_PKEY to new style
To avoid conflicts in the language spec and how Conscrypt does native
calls, we need to wrap all native references in a Java object reference.
Calling NativeCrypto's static native methods with a raw pointer doesn't
guarantee that the calling object won't be finalized during the method
running.
This pass fixes EVP_PKEY references, but more passes are needed.
Bug: 16656908
Change-Id: I5925da40cb37cd328b3a126404944f771732a43e/Convert EVP_MD_CTX to new style
To avoid conflicts in the language spec and how Conscrypt does native
calls, we need to wrap all native references in a Java object reference.
Calling NativeCrypto's static native methods with a raw pointer doesn't
guarantee that the calling object won't be finalized during the method
running.
Bug: 16656908
Change-Id: I165e041a8fe056770d6ce6d6cd064c411575b7c4/Remove Conscrypt support for DSA
BoringSSL removes support for DSA, so there's no point in maintaining
this now. There have been virtually zero SSL certificates issued using
DSA for many years as well.
Change-Id: Id940643b85ba39b03038aabc6da9ec0285db66c4/am 7b7d2e3c: am b9bfe69f: Fix null elements in X509KeyManager.chooseClientAlias keyTypes.
* commit '7b7d2e3cb2ea60307c332de6441da78942145a1c':
Fix null elements in X509KeyManager.chooseClientAlias keyTypes./Remove support for DSS TLS/SSL cipher suites.
This is in preparation for migration from OpenSSL to BoringSSL.
BoringSSL does not support DSS.
DSS cipher suites are used by a vanishingly tiny fraction of the
Android ecosystem. In all cases, the server's SSL certificate is
self-signed (rather than CA issued), making it easy to switch to
a new self-signed certificate which is based on RSA or ECDSA.
Bug: 17409664
Change-Id: I91067ca9df764edd2b7820e5dec995f24f3910a1/am b9bfe69f: Fix null elements in X509KeyManager.chooseClientAlias keyTypes.
* commit 'b9bfe69f1c205ab67a03e10a01e2cc90871a0879':
Fix null elements in X509KeyManager.chooseClientAlias keyTypes./Fix null elements in X509KeyManager.chooseClientAlias keyTypes.
This fixes an issue where client certificate types requested by the
server from the client, but not known by the client, manifest
themselves as null elements in X509KeyManager.chooseClientAlias
keyTypes argument.
The root cause was that for each element in the
CertificateRequest.certificate_types array an element was output into
the keyTypes array. For unknown values of certificate_type, a null
was output.
This CL fixes the issue by ignoring unknown values in
certificate_types array.
Bug: 18414726
Change-Id: I8565e19a610c0ecfb7cab1b7707c335e0eeb8d89/"
conscrypt,"Squashed commit of changes from lmp-ub-dev
Contains the following changes:
commit e31d982cdb0f8e6ef05d1e412576888015e1da17
Merge: eaebc54 b73be72
Author: Neil Fuller <nfuller@google.com>
Date:   Wed Oct 22 10:34:23 2014 +0000
am b73be72e: am 3e21a289: (-s ours) TLS_FALLBACK_SCSV CTS fix for klp-modular-dev
* commit 'b73be72ed97da8f36450d95d52f485cc6f451c61':
TLS_FALLBACK_SCSV CTS fix for klp-modular-dev
commit eaebc544f3a10c53d7d2f908514122caba569e14
Merge: 223b5da cd50afa
Author: Kenny Root <kroot@google.com>
Date:   Tue Oct 14 17:30:19 2014 +0000
Merge ""Fix SSLEngine to support session resumption."" into lmp-ub-dev
commit 223b5da5d70e47b1a497e86474493925b568f6d7
Merge: 8737796 cb7a360
Author: Neil Fuller <nfuller@google.com>
Date:   Thu Oct 9 14:52:00 2014 +0000
am cb7a3605: am ea961ada: Apply conscrypt changes from merge commit
* commit 'cb7a36050f34d3c16be00d532411820761eeb276':
Apply conscrypt changes from merge commit
commit cd50afad1567b1311e6e979e94a7167b7bf69c94
Author: Doug Steedman <dougsteed@google.com>
Date:   Mon Oct 6 13:16:15 2014 -0700
Fix SSLEngine to support session resumption.
Bug: 17877118
Change-Id: I388b59cde58fdc506ecac9f536e4bbd9161df6ad
commit 8737796a646eaec94df32827752a71aee74bd46f
Merge: 9564a5f 8d7e23e
Author: Kenny Root <kroot@google.com>
Date:   Mon Oct 6 22:34:20 2014 +0000
am 8d7e23e1: Add support for TLS_FALLBACK_SCSV
* commit '8d7e23e117da591a8d48e6bcda9ed6f58ff1a375':
Add support for TLS_FALLBACK_SCSV
commit 9564a5fb9ed2eecf6299788db35213cb08397212
Merge: 4f58feb 7640613
Author: Kenny Root <kroot@google.com>
Date:   Fri Sep 12 17:27:23 2014 +0000
am 76406135: am 6dcb23fe: am f427ec90: Fix the ENGINE_finish/ENGINE_free mixup
* commit '76406135cf3a3b88afc979fe8e847b9c3d8b93c1':
Fix the ENGINE_finish/ENGINE_free mixup
commit 4f58feb0ea49dc089a95efba196032ef3c960a39
Merge: ddac5c6 984b7ec
Author: Kenny Root <kroot@google.com>
Date:   Wed Sep 10 07:07:16 2014 +0000
am 984b7ec6: Fix the ENGINE_finish/ENGINE_free mixup
* commit '984b7ec6f5aab314117949a48e448ff4f6b65f16':
Fix the ENGINE_finish/ENGINE_free mixup
commit ddac5c6d7e413b0d68b388fbdf70dbeb3eeae865
Merge: 5a8ca5b 36ba60b
Author: Kenny Root <kroot@google.com>
Date:   Thu Sep 4 22:41:38 2014 +0000
Merge ""Reset lmp-ub-dev to lmp-dev-plus-aosp"" into lmp-ub-dev
commit 36ba60b039f1f30ab1ea8f0e2a4da8ae4e3906e5
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 27 12:07:07 2014 -0700
Reset lmp-ub-dev to lmp-dev-plus-aosp
Bug: 17059757
Change-Id: I581963360da47b574e1e2e20c2851485c36fa62c
commit 6a4f2ef9e4ea3ebb321d45ca39b30d634ea3b4ad
Merge: 9b187af f67d784
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:17:38 2014 +0000
am f67d784a: Add pre-Honeycomb literal IP matching
* commit 'f67d784abe5cef700240be02c68cecd899cd8e6d':
Add pre-Honeycomb literal IP matching
commit 9b187af33dcd97915a0371d64fe1ee4aba20d0ba
Merge: 714ebea 966ae8a
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:17:37 2014 +0000
am 966ae8a6: Read property to enable SNI
* commit '966ae8a6e12f3235b1cb041e687bda11b41fe4eb':
Read property to enable SNI
commit 714ebeabcb5e35c6df6a5c21f549cdb6130368c4
Merge: 7724204 54a1ba4
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:06:54 2014 +0000
Merge ""resolved conflicts for merge of 342097db to lmp-dev-plus-aosp"" into lmp-dev-plus-aosp
commit 54a1ba421d23bb6d988688c2662715e509172447
Merge: a20d871 342097d
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 21:03:51 2014 -0700
resolved conflicts for merge of 342097db to lmp-dev-plus-aosp
Change-Id: I853c6b0d3725dafbdc84c4d6d6d1b90529bd949d
commit 7724204abf4431d35787c44c4a22cda5489d4e37
Merge: 20f60ac afb3403
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 00:09:27 2014 +0000
am afb34034: Implement write socket timeouts for unbundled apps
* commit 'afb340348bfc54dbc46964e159fe803f9c93a4dd':
Implement write socket timeouts for unbundled apps
commit f67d784abe5cef700240be02c68cecd899cd8e6d
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 14:14:26 2014 -0700
Add pre-Honeycomb literal IP matching
This will allow us to run this code on Gingerbread devices and others
that don't have the InetAddress#isNumeric API.
Bug: 16658420
Bug: 17059757
Change-Id: I597d539979d58eeaa2677d6f99e911313a550cc1
commit 966ae8a6e12f3235b1cb041e687bda11b41fe4eb
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 18 10:12:20 2014 -0700
Read property to enable SNI
Read the system property ""jsse.enableSNIExtension"" on whether to enable
Server Name Indication (SNI) extension. For unbundled builds, this will
be enabled by default. For platform builds, this will be disabled by
default.
Bug: 16658420
Bug: 17059757
Change-Id: I774f5406bf3fe601a42c4ef5e708b31800147eb9
commit 342097db97a9b2736531033b2c4b4d8ce4998c67
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 12:14:52 2014 -0700
Validate hostname is usable for SNI
According to RFC 6066 section 3, the hostname listed in the Server Name
Indication (SNI) field is a fully qualified domain name and IP
addresses are not permitted.
Bug: 16658420
Bug: 17059757
Change-Id: I804e46b6e66599b2770f0f4f0534467987e51208
commit afb340348bfc54dbc46964e159fe803f9c93a4dd
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 19 16:33:07 2014 -0700
Implement write socket timeouts for unbundled apps
Change-Id: I4fd604f057ba4288d4f31bf6b3b93307376023d5
commit 20f60acea153dfdf0c8f75a53d7bd9edb4c7614c
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 11:52:05 2014 -0700
Tracking change from AOSP
Change-Id: I889af3f7c1de9ef34d9328339e1b421651055ad4
commit 68056b7c9db8a9fb384bbadfc5287730f996896d
Merge: 8239dfd cc2ef2e
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 18:03:27 2014 +0000
am cc2ef2e2: Rename hostname fields and methods to reflect usage
* commit 'cc2ef2e2e9ee64f2e0ac2abc7fdf636e2f81fa5e':
Rename hostname fields and methods to reflect usage
commit 8239dfdcc40a69255d7b2feced960d574ea36321
Merge: e9cf759 076138f
Author: Kenny Root <kroot@google.com>
Date:   Thu Aug 21 16:36:24 2014 +0000
am 076138ff: Use consistent naming for SSLSocket arguments
* commit '076138ff29d805ec5a32d6ad96a18ef08c7f1b11':
Use consistent naming for SSLSocket arguments
commit cc2ef2e2e9ee64f2e0ac2abc7fdf636e2f81fa5e
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 11:26:33 2014 -0700
Rename hostname fields and methods to reflect usage
The hostname that was supplied when the socket was created is stored as
the ""peerHostname""  This is the only one that should be used for Server
Name Indication (SNI) purposes.
The ""peerHostname"" or the resolved IP address may be used for
certificate validation, so keep the use of ""getHostname()"" for
cerificate validation.
Bug: 16658420
Bug: 17059757
Change-Id: Ifd87dead44fb2f00bbfd5eac7e69fb3fc98e94b4
commit 076138ff29d805ec5a32d6ad96a18ef08c7f1b11
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 11:24:41 2014 -0700
Use consistent naming for SSLSocket arguments
This changes all the 'host' to be 'hostname' and anything that takes an
'InetAddress' will have the name of 'address' to avoid confusing it with
a hostname.
Bug: 16658420
Bug: 17059757
Change-Id: Iac0628d2d156023dbb80c2e636af6bfe63f46650
commit e9cf759ac89fb053c01f1db19931beb14a823618
Merge: ababdd1 7ed0fae
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 19 19:32:43 2014 +0000
am 7ed0fae1: OpenSSLEngineImpl: reduce number of copies needed
* commit '7ed0fae1906061766d0042e69ccba20e4a702bbe':
OpenSSLEngineImpl: reduce number of copies needed
commit 7ed0fae1906061766d0042e69ccba20e4a702bbe
Author: Kenny Root <kroot@google.com>
Date:   Tue Jul 22 13:03:09 2014 -0700
OpenSSLEngineImpl: reduce number of copies needed
When the ByteBuffer didn't line up exactly with the backing array, it
would allocate a new buffer to write into. Instead, add the ability for
OpenSSL to read at an offset in the given array so a copy isn't needed.
Change-Id: I149d3f94e4b5cbdc010df80439ae3300cbdc87a5
commit ababdd1ae1272eac174e3a449a413ab35afbc435
Merge: 66c31e0 4b050b6
Author: Kenny Root <kroot@google.com>
Date:   Fri Aug 15 16:23:14 2014 +0000
am 4b050b6f: OpenSSLSocketImpl: Move state checks inside mutex
* commit '4b050b6fb06fbb804557eecc72cc4ff0e0277525':
OpenSSLSocketImpl: Move state checks inside mutex
commit 66c31e0b613ceefc167a2e1fb226a14c78f84537
Merge: f4b895a 0931d51
Author: Kenny Root <kroot@google.com>
Date:   Thu Aug 14 20:46:43 2014 +0000
am 0931d51c: OpenSSLSocketImpl: Move state checks inside mutex
* commit '0931d51c58b2dc2f612298f99fbf0fa6ed4c3706':
OpenSSLSocketImpl: Move state checks inside mutex
commit 0931d51c58b2dc2f612298f99fbf0fa6ed4c3706
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 15:45:32 2014 -0700
OpenSSLSocketImpl: Move state checks inside mutex
Checking the state of the connection is unreliable if SSL_read and
SSL_write are happening in another thread. Move the state checks inside
our application mutex so we don't run into another thread mutating the
state at the same time.
Bug: 15606096
Change-Id: I5ecdeb1551a13098d1b66c5e4009607c9951fa38
commit f4b895ae9c424b5c2d49c744131606adccbc49d7
Merge: a35c400 a260ee6
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 13 15:35:28 2014 +0000
am a260ee6d: Revert ""Revert ""Automatic management of OpenSSL error stack""""
* commit 'a260ee6d0caea43f8010f158a4a35fb712935ae3':
Revert ""Revert ""Automatic management of OpenSSL error stack""""
commit a35c40017c8690f821351d6460dfeaa2738b884c
Merge: 0edc483 30550a8
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 13 15:35:27 2014 +0000
am 30550a8b: Fix debugging with unbundled conscrypt
* commit '30550a8b64bbcd6ca537680a17b8726932a29937':
Fix debugging with unbundled conscrypt
commit a260ee6d0caea43f8010f158a4a35fb712935ae3
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:38:10 2014 -0700
Revert ""Revert ""Automatic management of OpenSSL error stack""""
The ""else"" statement in OpenSslError::reset wasn't properly resetting
the error state which made a second call into sslRead jump into
sslSelect when it should have just returned immediately.
Change-Id: I22e8025c0497a04e78daa07cef78191a6ca1a70c
commit 30550a8b64bbcd6ca537680a17b8726932a29937
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:13:33 2014 -0700
Fix debugging with unbundled conscrypt
When JNI_TRACE was enabled, there were missing defines for the debugging
code since no platform code is included.
Also clang complains about more of the debugging statement formats, so
we have to move some things around to get it to be happy.
Change-Id: I1a6695c2ef2639cc01cfc3d3a8603f010c659844
commit 0edc4833091846d6cb45961fc9458df842fbbad9
Merge: 107a8fb 2411b8b
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:46:12 2014 +0000
am 2411b8bd: Merge ""Revert ""Automatic management of OpenSSL error stack""""
* commit '2411b8bdcde72c956f4150e9a5909b7501f50bad':
Revert ""Automatic management of OpenSSL error stack""
commit 2411b8bdcde72c956f4150e9a5909b7501f50bad
Merge: 3262a8c b514d72
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:39:32 2014 +0000
Merge ""Revert ""Automatic management of OpenSSL error stack""""
commit b514d72b93c3996d97e38eca6db1ad684965fd9b
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:39:17 2014 +0000
Revert ""Automatic management of OpenSSL error stack""
This reverts commit 35666e4cb0fcd063a21d17eebbb571b4e4e822b8.
Change-Id: I926d159c4c4b99250caef750732976c1e601e9ef
commit 107a8fba8be5be57933f2638b76ac1243b578b9e
Merge: 1de007f 3262a8c
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:50:14 2014 +0000
am 3262a8c2: Merge ""Automatic management of OpenSSL error stack""
* commit '3262a8c2741b95103149bcdefe2409c24bfddee9':
Automatic management of OpenSSL error stack
commit 1de007f9f01be8f07a56235dd924c897088a03cb
Merge: 94890ae d1bbcd0
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:50:14 2014 +0000
am d1bbcd0e: Relax checks for key vs cert for wrapped keys
* commit 'd1bbcd0ec973e1b8465c204c13b4925fd86e6484':
Relax checks for key vs cert for wrapped keys
commit 3262a8c2741b95103149bcdefe2409c24bfddee9
Merge: d1bbcd0 35666e4
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:31:02 2014 +0000
Merge ""Automatic management of OpenSSL error stack""
commit d1bbcd0ec973e1b8465c204c13b4925fd86e6484
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 11 14:56:58 2014 -0700
Relax checks for key vs cert for wrapped keys
If a key is a wrapped platform key, we must relax the check. The reason
is that we may not have the public values we need to pass the
EVP_PKEY_cmp checks that this does.
Change-Id: I7ab2be51b0968a9cf771edea01d33fe2367c8185
commit 35666e4cb0fcd063a21d17eebbb571b4e4e822b8
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 11:05:00 2014 -0700
Automatic management of OpenSSL error stack
This removes some complexity in remembering to free the OpenSSL error
stack. If you forget, the error will stick around until you make another
call.
Change-Id: I245a525dcc93077b2bf9909a14a0ef469a2daca4
commit 94890aec5735cde2ea5170fb76cd1b847ea66af8
Merge: 8360485 977f087
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 16:44:42 2014 +0000
am 977f0877: Fix some JNI_TRACE lines
* commit '977f08774c628b4640d5454cde050259856965f8':
Fix some JNI_TRACE lines
commit 977f08774c628b4640d5454cde050259856965f8
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 4 12:15:04 2014 -0700
Fix some JNI_TRACE lines
During debugging these would be enabled, but they were copy-pasta'd to
with the wrong args.
Change-Id: I23f39ff4807e3fa71f3220912aec3c99db6b9454
commit 83604854c5160304cafefc9bd40a72c5ee8506eb
Merge: 7db3524 1ffe43e
Author: Zoltan Szatmary-Ban <szatmz@google.com>
Date:   Thu Jul 31 13:28:57 2014 +0000
am 1ffe43e8: Merge ""Add possibility to get deleted system Certificate Aliases"" into lmp-dev
* commit '1ffe43e8277e883c6663c1fb7cfc5e18ba552c40':
Add possibility to get deleted system Certificate Aliases
commit 7db3524880092126962b7f502af76b4c84da7350
Merge: 5767d63 ad0cd83
Author: Prameet Shah <phshah@google.com>
Date:   Wed Jul 30 17:04:13 2014 +0000
am ad0cd830: Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
* commit 'ad0cd83024f38011043d28d70370a8638b88cd72':
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
commit 5767d63d22e87becab387b3bd6597fe41eb34d7e
Merge: b389e17 26163c2
Author: Prameet Shah <phshah@google.com>
Date:   Wed Jul 30 16:31:08 2014 +0000
am 26163c26: Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
* commit '26163c268a6d2625384b87e907afad8ef19f9a47':
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
commit 26163c268a6d2625384b87e907afad8ef19f9a47
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 29 16:45:31 2014 -0700
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
Bug: https://code.google.com/p/android/issues/detail?id=73745
Change-Id: I5bcaf3ee8910ff75e785baed4c4604fee6c5e700
commit b389e1779651f2c58454a5f98acebd3dd7bc0061
Merge: 5f03b4d e427972
Author: Prameet Shah <phshah@google.com>
Date:   Thu Jul 24 19:46:28 2014 +0000
am e427972e: OpenSSLEngineImpl: fix unwrap behavior with array
* commit 'e427972eb6141cd67e6d4c9607863a8d990e6be6':
OpenSSLEngineImpl: fix unwrap behavior with array
commit 5f03b4d63c7632581b032879de791dc82f05ffa0
Merge: 3d935ee 41eb5b6
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 22 19:26:41 2014 +0000
am 41eb5b65: OpenSSLEngineImpl: fix unwrap behavior with array
* commit '41eb5b65e524d01e28da474bd37e4349b12fb494':
OpenSSLEngineImpl: fix unwrap behavior with array
commit 41eb5b65e524d01e28da474bd37e4349b12fb494
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 22 11:50:18 2014 -0700
OpenSSLEngineImpl: fix unwrap behavior with array
The decrypted bytes should written sequentially into each buffer of
the destination array until it's full before moving to the next
buffer.
Change-Id: I2454249c167deafde6c12134d3c8cd658cd7c21b
commit 3d935eeca25e00b56cfd8d37a657c7b2986889b3
Merge: 0a36f6c affd45a
Author: Alex Klyubin <klyubin@google.com>
Date:   Fri Jul 18 00:32:14 2014 +0000
am affd45a4: Merge ""Improve the Javadoc of PSKKeyManager."" into lmp-dev
* commit 'affd45a413cf844dad797ad4972074efb9de43d8':
Improve the Javadoc of PSKKeyManager.
commit 0a36f6c1f8b2e195c2dd5aea1a386df090c6d470
Merge: 6492180 af4fa68
Author: rich cannings <richc@google.com>
Date:   Thu Jul 17 23:47:33 2014 +0000
am af4fa685: Merge ""Log CCS exceptions do not merge."" into lmp-dev
* commit 'af4fa685f246aaa80c93af62faadbc2fe87dc034':
Log CCS exceptions do not merge.
commit 6492180ce17a3b5ff822cff1783f00e7a4176491
Merge: aac4168 3b7268c
Author: Alex Klyubin <klyubin@google.com>
Date:   Thu Jul 17 18:27:39 2014 +0000
am 3b7268cd: Merge ""Improve the Javadoc of PSKKeyManager.""
* commit '3b7268cde4a4fc59591da8a93691927ebf3add57':
Improve the Javadoc of PSKKeyManager.
commit aac4168d8baef7e12d6fa959c6d6ded9892e9651
Merge: 8573ad0 a749c0d
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 17 17:07:05 2014 +0000
am a749c0d3: Keep enough state to completely reset cipher instances
* commit 'a749c0d351216be38879600ee8ed01c6793aa256':
Keep enough state to completely reset cipher instances
commit 8573ad0ddcf7e2f8b2e5ac84c34b7ffab303155c
Merge: 4ca5b06 70fdb6d
Author: Koushik Dutta <koushd@gmail.com>
Date:   Thu Jul 17 17:06:36 2014 +0000
am 70fdb6d2: OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
* commit '70fdb6d2bfa0c313fe389827f0025288f6aeb947':
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
commit 4ca5b0625e3f5a15ae8adf833ab5a69f9d7d517f
Merge: 119abfb ded66f5
Author: Koushik Dutta <koushd@gmail.com>
Date:   Thu Jul 17 17:06:35 2014 +0000
am ded66f5f: Various fixes in OpenSSLEngineImpl.
* commit 'ded66f5f696994ce7620552e16a4e9124e69e052':
Various fixes in OpenSSLEngineImpl.
commit 119abfba1fcd9c9cfbd15d0a4ca9ed2188fdfab0
Merge: 5713cdf cbe1f28
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 17 15:56:57 2014 +0000
am cbe1f28a: Merge ""Keep enough state to completely reset cipher instances""
* commit 'cbe1f28adf64396561a3b65bf1452dfa9b6e35ae':
Keep enough state to completely reset cipher instances
commit cbe1f28adf64396561a3b65bf1452dfa9b6e35ae
Merge: e08f238 084e308
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 17 15:48:58 2014 +0000
Merge ""Keep enough state to completely reset cipher instances""
commit 3b7268cde4a4fc59591da8a93691927ebf3add57
Merge: cbe1f28 7ac13e0
Author: Alex Klyubin <klyubin@google.com>
Date:   Thu Jul 17 18:20:43 2014 +0000
Merge ""Improve the Javadoc of PSKKeyManager.""
commit 5713cdf71c5c6e5179e8369263c702e9512afdd0
Merge: cf55719 e08f238
Author: Koushik Dutta <koushd@gmail.com>
Date:   Wed Jul 16 22:05:17 2014 +0000
am e08f2385: OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
* commit 'e08f238580e8ee471012bef8240c8d3397c7b780':
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
commit cf557195a9b60d7f51a48500afde38481ddbc91c
Merge: cbbd7d1 986aeb7
Author: Kenny Root <kroot@android.com>
Date:   Wed Jul 16 21:41:12 2014 +0000
am 986aeb78: Merge ""Various fixes in OpenSSLEngineImpl.""
* commit '986aeb78e533540463daf1753e24840f75b25ce6':
Various fixes in OpenSSLEngineImpl.
commit e08f238580e8ee471012bef8240c8d3397c7b780
Author: Koushik Dutta <koushd@gmail.com>
Date:   Tue Jul 15 22:40:23 2014 -0700
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
Change-Id: Idc78204b7077fb367b64e1867c807cd39f596f98
commit 7ac13e03a79d0c99d181b1a28b1b3699ba3d5739
Author: Alex Klyubin <klyubin@google.com>
Date:   Wed Jul 16 08:33:02 2014 -0700
Improve the Javadoc of PSKKeyManager.
This clarifies several points and adds sample code.
Bug: 15073623
Change-Id: I6e8aadc52277e238a998d6cee36795dab1151d58
commit 986aeb78e533540463daf1753e24840f75b25ce6
Merge: 8f9ac1a bdfcc18
Author: Kenny Root <kroot@android.com>
Date:   Wed Jul 16 21:15:30 2014 +0000
Merge ""Various fixes in OpenSSLEngineImpl.""
commit bdfcc189efe41a3f812aeb55ea634bace67d159a
Author: Koushik Dutta <koushd@gmail.com>
Date:   Sat Jun 28 19:19:21 2014 -0700
Various fixes in OpenSSLEngineImpl.
Fix ""Buffers were not large enough"" exception by directly using the
destination buffers.
Corrections around bytesProduced and bytesConsumed behavior.
Return BUFFER_OVERFLOW if a zero length destination is provided to
unwrap.
Change-Id: I1f1e9b72cd6968ed4f3c3c0edccbccebc33d6790
commit cbbd7d10e8e484c44a78e5b27e8fecda195f1692
Merge: ec7f8e6 fdb7d8c
Author: Alex Klyubin <klyubin@google.com>
Date:   Tue Jul 15 18:49:14 2014 +0000
am fdb7d8c5: Enable PSK cipher suites when PSKKeyManager is provided.
* commit 'fdb7d8c53dabac5551e2499d045ba6829bcfc0a0':
Enable PSK cipher suites when PSKKeyManager is provided.
commit ec7f8e6b27330160f88540f4f2ace7bc2a0720a3
Merge: 5b8ccf1 8f9ac1a
Author: Alex Klyubin <klyubin@google.com>
Date:   Tue Jul 15 15:53:46 2014 +0000
am 8f9ac1af: Enable PSK cipher suites when PSKKeyManager is provided.
* commit '8f9ac1af0cbdf00e5e47aee32c132522ebc3bd17':
Enable PSK cipher suites when PSKKeyManager is provided.
commit 5b8ccf1b09df6f35c1709bfc8fd727a291094a5b
Merge: 69a2e46 6e2315f
Author: Ed Heyl <edheyl@google.com>
Date:   Tue Jul 15 13:34:25 2014 +0000
am 6e2315fd: reconcile aosp (e79c25bf33e10da41e489c537823f678e1a1169c) after branching. Please do not merge.
* commit '6e2315fd96c3c4a47450c1a437babacc94bc31a6':
reconcile aosp (e79c25bf33e10da41e489c537823f678e1a1169c) after branching. Please do not merge.
commit 084e3086be1d7a6b9280b64c7c8cdb7b41a13bea
Author: Kenny Root <kroot@google.com>
Date:   Mon Jul 14 13:25:32 2014 -0700
Keep enough state to completely reset cipher instances
OpenSSL's RC4 mutates the given key. AES/CTR mutates the IV. We must
store these values locally to enable ""doFinal"" to cause the Cipher
instance to be reset to what it was right after ""init"".
Note that resetting and encrypting with the same key or IV breaks
semantic security.
Bug: 16298401
Bug: https://code.google.com/p/android/issues/detail?id=73339
Change-Id: Ie7e4dcb6cf6cc33ddad31d6b47066dc1b34e6894
commit 69a2e460cc0a40e1b951e400589b9932609079ec
Merge: 8b7bb32 bca895f
Author: David Benjamin <davidben@chromium.org>
Date:   Mon Jul 14 18:17:28 2014 +0000
am bca895f8: Pass output buffer length into EVP_DigestSignFinal.
* commit 'bca895f809dd2cef7a0834f0bfeb2a06e42b277d':
Pass output buffer length into EVP_DigestSignFinal.
commit 8b7bb32af09a01e80442b70dd23e6997a937f103
Merge: a2404c9 e79c25b
Author: Kenny Root <kroot@google.com>
Date:   Mon Jul 14 18:17:28 2014 +0000
am e79c25bf: Merge ""DHKeyPairGenerator: use provided params""
* commit 'e79c25bf33e10da41e489c537823f678e1a1169c':
DHKeyPairGenerator: use provided params
commit 8f9ac1af0cbdf00e5e47aee32c132522ebc3bd17
Author: Alex Klyubin <klyubin@google.com>
Date:   Thu Jun 19 13:37:24 2014 -0700
Enable PSK cipher suites when PSKKeyManager is provided.
This enables TLS-PSK cipher suites by default iff SSLContext is
initialized with a PSKKeyManager. For consistency, X.509 based
cipher suites are no longer enabled by default at all times -- they
are now only enabled by default iff SSLContext is initialized with a
X509KeyManager or a X509TrustManager.
When both X.509 and PSK cipher suites need to be enabled, PSK cipher
suites are given higher priority in the resulting list of cipher
suites. This is based on the assumption that in most cases users of
TLS/SSL who enable TLS-PSK would prefer TLS-PSK to be used when the
peer supports TLS-PSK.
Bug: 15073623
Change-Id: I8e2bc3e7a1ea8a986e468973b6bad19dc6b7bc3c
commit bca895f809dd2cef7a0834f0bfeb2a06e42b277d
Author: David Benjamin <davidben@chromium.org>
Date:   Thu Jul 10 18:12:08 2014 -0400
Pass output buffer length into EVP_DigestSignFinal.
EVP_DigestSignFinal expects the input buffer length as *siglen on input. In
addition, if sigret is NULL, it returns the buffer size needed. Use this rather
than making assumptions about the EVP_PKEY used to initialize the EVP_MD_CTX.
commit e79c25bf33e10da41e489c537823f678e1a1169c
Merge: a328492 9b226f9
Author: Kenny Root <kroot@google.com>
Date:   Fri Jul 11 16:46:23 2014 +0000
Merge ""DHKeyPairGenerator: use provided params""
commit 9b226f90a992a4a2267b7a813e3b869851945c4d
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 10 14:50:48 2014 -0700
DHKeyPairGenerator: use provided params
If the prime is provided in the DHParameterSpec, then use it to generate
the key.
Bug: 16188130
Change-Id: I42de02c71a58d691ef7ba6e2252367105687b758
Bug: 18388980
Change-Id: I853b02a32db113a5af3f6166e7d61fab58c3ff73/Enable SNI by default in platform-bundled Conscrypt.
The benefit of enabling SNI by default is that is makes it easier to
setup/move to virtual hosting, and also use more specific/restricted
SSL certificates without having to modify clients.
SNI is so widely deployed these days that it is not expected to cause
any significant issues by being on by default. Moreover, it's on by
default in the RI.
Bug: 16658420
Change-Id: I0d5d13152ffcc3cf1e01afe7a45f69e7aaf6d4bc/"
conscrypt,"change NativeCrypto_X509_CRL_get_ext return data type from int to long
root cause: NativeCrypto_X509_CRL_get_ext return the wrong data type.
NativeCrypto_X509_CRL_get_ext return int data type will cut return value
from 8 bytes to 4 bytes in 64 bit system. So change int to long.
NativeCrypto_X509_REVOKED_get_ext may has the same problem.
Change-Id: I97be716f82e846a5dfe3cef77b68faff79235d9b
Signed-off-by: Yong Yao <yong.yao@intel.com>/Use an empty BIO memory buffer with BoringSSL.
de5225d1 mistakenly switched a BIO_s_null to an empty mem-BIO in order
to allow BoringSSL to work. That worked for BoringSSL, but OpenSSL
treats an empty mem-BIO as an error and so that was switched back in
2fe55c8f.
This change uses an empty mem-BIO with BoringSSL again for the same
reasons, but guards the change with the preprocessor so that it doesn't
break OpenSSL.
Change-Id: If90b7a151bf124722d91f150b441e0c9f5b96b03/am 4497fdc7: Treat SSL_ERROR_ZERO_RETURN correctly.
* commit '4497fdc7e8a775eccb882b42a9314de09ee6c67f':
Treat SSL_ERROR_ZERO_RETURN correctly./Treat SSL_ERROR_ZERO_RETURN correctly.
According to ssl_lib.c, this is returned whenever the socket
is being closed (s->shutdown && SSL_RECEIVED_SHUTDOWN &&
s->s3->warn_alert == SSL_AD_CLOSE_NOTIFY).
(cherry picked from commit f6c8f8b4891a91178e45b90f34f9d8c97737044a)
Bug: 18758595
Change-Id: Ied7b3e18f11786351d42a770f4cad11ddae29ff3/am f5709028: am f6c8f8b4: Treat SSL_ERROR_ZERO_RETURN correctly.
* commit 'f57090289ca8f99ebed84f0bf65ff63b4c8c1661':
Treat SSL_ERROR_ZERO_RETURN correctly./am f6c8f8b4: Treat SSL_ERROR_ZERO_RETURN correctly.
* commit 'f6c8f8b4891a91178e45b90f34f9d8c97737044a':
Treat SSL_ERROR_ZERO_RETURN correctly./Treat SSL_ERROR_ZERO_RETURN correctly.
According to ssl_lib.c, this is returned whenever the socket
is being closed (s->shutdown && SSL_RECEIVED_SHUTDOWN &&
s->s3->warn_alert == SSL_AD_CLOSE_NOTIFY).
Change-Id: Ied7b3e18f11786351d42a770f4cad11ddae29ff3/Allow a pubkeyRef to be null
If you're making a private key without the pubkey available, we usually
just set it to null. However, the fromContextObject cannot cope with
NULL being passed in.
Bug: 18870063
Change-Id: I26333b4de146e1072783986333f89fe49d4333e0/Go back to BIO_s_null instead of empty mem buf
If you pass NULL to BIO_new_mem_buf, it adds an error to the stack and
returns NULL instead of an actual BIO. Go back to BIO_s_null instead.
Bug: 18870062
Change-Id: Idba61a90907fbc2ea3528734b8cc9e27eccb1b50/Call EVP_CIPHER_CTX_free instead of EVP_CIPHER_CTX_cleanup.
The latter doesn't OpenSSL_free memory allocated by EVP_CIPHER_CTX_new.
It's worth noting that EVP_CIPHER_CTX_free doesn't check the return
value of EVP_CIPHER_CTX_cleanup so we can't throw if cleanup failed, but
we were only ever calling this method from a finalizer anyway.
(cherry picked from commit c64652932d8e17ccf7e54c0c76c1b38a86841732)
bug: 18617384
Change-Id: Ida65e14ffbed41f56a59e2f5fe77289cac0f5947/Call EVP_CIPHER_CTX_free instead of EVP_CIPHER_CTX_cleanup.
The latter doesn't OpenSSL_free memory allocated by EVP_CIPHER_CTX_new.
It's worth noting that EVP_CIPHER_CTX_free doesn't check the return
value of EVP_CIPHER_CTX_cleanup so we can't throw if cleanup failed, but
we were only ever calling this method from a finalizer anyway.
bug: 18617384
Change-Id: Ida65e14ffbed41f56a59e2f5fe77289cac0f5947/am b31e7642: am 80ac6efc: am 058faf1e: NativeCrypto: throw BadPaddingException if EVP_CipherFinal_ex fails
* commit 'b31e7642abdc913d913c0877f6b7756d9f970033':
NativeCrypto: throw BadPaddingException if EVP_CipherFinal_ex fails/am 9eb44160: am 70f386c2: am 53497d00: OpenSSLCipherRSA: add new reason to exception mapping
* commit '9eb441604b139f12228fa6fd8af09638fc30446f':
OpenSSLCipherRSA: add new reason to exception mapping/NativeCrypto: empty data content for PKCS7 container
The EncapsulatedContentInfo must be present in the output, but OpenSSL
will fill in a zero-length OID if you don't call PKCS7_set_content on the
outer PKCS7 container. So we construct an empty PKCS7 data container and
set it as the content. This fixes the invalid PKCS7 output.
(cherry picked from commit 525df9b12c1eb77db9f1b2b8fa5d41f779b9afa6)
Bug: 18664989
Change-Id: I6f4cf785dd02ee40f1951d098fa987aa25d2421a/NativeCrypto: empty data content for PKCS7 container
The EncapsulatedContentInfo must be present in the output, but OpenSSL
will fill in a zero-length OID if you don't call PKCS7_set_content on the
outer PKCS7 container. So we construct an empty PKCS7 data container and
set it as the content. This fixes the invalid PKCS7 output.
Bug: 18664989
Change-Id: I6f4cf785dd02ee40f1951d098fa987aa25d2421a/am 80ac6efc: am 058faf1e: NativeCrypto: throw BadPaddingException if EVP_CipherFinal_ex fails
* commit '80ac6efc62f72d50e1314da38fed413776490ef7':
NativeCrypto: throw BadPaddingException if EVP_CipherFinal_ex fails/am 70f386c2: am 53497d00: OpenSSLCipherRSA: add new reason to exception mapping
* commit '70f386c285f4913623b234cc8cb794ccce4cfa48':
OpenSSLCipherRSA: add new reason to exception mapping/am 058faf1e: NativeCrypto: throw BadPaddingException if EVP_CipherFinal_ex fails
* commit '058faf1e3a8978cca7c9898ccd692fa5b738a180':
NativeCrypto: throw BadPaddingException if EVP_CipherFinal_ex fails/am 53497d00: OpenSSLCipherRSA: add new reason to exception mapping
* commit '53497d005a470123806d23a5d36e86cee88eafbd':
OpenSSLCipherRSA: add new reason to exception mapping/NativeCrypto: throw BadPaddingException if EVP_CipherFinal_ex fails
Since nothing was being pushed onto the stack, no exception was thrown
in throwExceptionIfNecessary with the constant time fix present in
1.0.1j. The fix is to throw our own error if nothing was thrown.
(cherry picked from commit e74933ecfb7dc7d91ebe6620a91d86fdc735ed58)
Bug: 18621207
Change-Id: I25e653c493e162c5fda46f320117c013a2661aa4/OpenSSLCipherRSA: add new reason to exception mapping
1.0.1j introduced a new error reason for RSA padding checks that wasn't
mapped resulting in a RuntimeException. Add this to the list of reasons
so we throw the correct BadPaddingException.
(cherry picked from commit 70e75e74134d8a2cbd1569565fac7d34df5fe7da)
Bug: 18665649
Change-Id: I96ce13f6dee10ca89e74c558ecb338f9dbd907ba/NativeCrypto: throw BadPaddingException if EVP_CipherFinal_ex fails
Since nothing was being pushed onto the stack, no exception was thrown
in throwExceptionIfNecessary with the constant time fix present in
1.0.1j. The fix is to throw our own error if nothing was thrown.
Bug: 18621207
Change-Id: I25e653c493e162c5fda46f320117c013a2661aa4/OpenSSLCipherRSA: add new reason to exception mapping
1.0.1j introduced a new error reason for RSA padding checks that wasn't
mapped resulting in a RuntimeException. Add this to the list of reasons
so we throw the correct BadPaddingException.
Bug: 18665649
Change-Id: I96ce13f6dee10ca89e74c558ecb338f9dbd907ba/Clear SSL state safely
Since SSL_clear can fail, we should clear the OpenSSL ERR stack if it
does fail. However, to aid in spotting bugs, only clear the stack if the
SSL_clear itself fails.
(cherry picked from commit 86dd832ac26112890b3e815a144ff062ae9b3559)
Bug: 18570895
Change-Id: I053d2e2792e64923c1e128b4fcae23b2e660a992/Clear SSL state safely
Since SSL_clear can fail, we should clear the OpenSSL ERR stack if it
does fail. However, to aid in spotting bugs, only clear the stack if the
SSL_clear itself fails.
(cherry picked from commit 86dd832ac26112890b3e815a144ff062ae9b3559)
Bug: 18570895
Change-Id: I053d2e2792e64923c1e128b4fcae23b2e660a992/Clear SSL state safely
Since SSL_clear can fail, we should clear the OpenSSL ERR stack if it
does fail. However, to aid in spotting bugs, only clear the stack if the
SSL_clear itself fails.
Bug: 18570895
Change-Id: I053d2e2792e64923c1e128b4fcae23b2e660a992/am 56c62b80: am 6c523c0e: Fix JNI_TRACE
* commit '56c62b80c96590bf8c536014fa0a309f68cc8591':
Fix JNI_TRACE/am 6c523c0e: Fix JNI_TRACE
* commit '6c523c0ef8d66b552b4c15cc87fd7f419181a980':
Fix JNI_TRACE/Convert EC_GROUP and EC_POINT to new style
Bug: 16656908
Change-Id: Ie912f376f69327ce634cac50763bf86b418049f5/Switch EVP_CIPHER_CTX to new style
Bug: 16656908
Change-Id: Id519c20474a02c70e72d362bc84d26855a74fa33/Convert EVP_PKEY to new style
To avoid conflicts in the language spec and how Conscrypt does native
calls, we need to wrap all native references in a Java object reference.
Calling NativeCrypto's static native methods with a raw pointer doesn't
guarantee that the calling object won't be finalized during the method
running.
This pass fixes EVP_PKEY references, but more passes are needed.
Bug: 16656908
Change-Id: I5925da40cb37cd328b3a126404944f771732a43e/Fix JNI_TRACE
The update to BoringSSL broke some of the tracing messages, so fix their
formatting to compile correctly with warning on.
Change-Id: I6c7a1e0069b61a787d9e00b929a6c4fa4358a063/Convert EVP_MD_CTX to new style
To avoid conflicts in the language spec and how Conscrypt does native
calls, we need to wrap all native references in a Java object reference.
Calling NativeCrypto's static native methods with a raw pointer doesn't
guarantee that the calling object won't be finalized during the method
running.
Bug: 16656908
Change-Id: I165e041a8fe056770d6ce6d6cd064c411575b7c4/Remove Conscrypt support for DSA
BoringSSL removes support for DSA, so there's no point in maintaining
this now. There have been virtually zero SSL certificates issued using
DSA for many years as well.
Change-Id: Id940643b85ba39b03038aabc6da9ec0285db66c4/am 54cec1d9: am 0beef7d4: Fix indentation for Fix mac build.
* commit '54cec1d9d8a4054f71fb9fa5d800a44ce34971a3':
Fix indentation for Fix mac build./am 0beef7d4: Fix indentation for Fix mac build.
* commit '0beef7d4fab3c8e7e6c181d9f2b64a68de89e18a':
Fix indentation for Fix mac build./Fix indentation for Fix mac build.
Change-Id: Ibb669022449a21bc8f2aa4558fbdc747aa1bff2c/am 51b04a56: am a3a2eba7: Fix mac build.
* commit '51b04a56efb3479d93f05ff7fcac22a4188fb952':
Fix mac build./am a3a2eba7: Fix mac build.
* commit 'a3a2eba7b3785e0b372e2217e01830f09d73e020':
Fix mac build./Fix mac build.
Change-Id: Ib7297bb0631caafed1ff04bcf2d73aea512c01c1/am 1eb3b3db: am 2ba24c83: Preserve errors to get the correct exception
* commit '1eb3b3db9bfb1f0abad08cfcc2ef28dd831ccc17':
Preserve errors to get the correct exception/am 2ba24c83: Preserve errors to get the correct exception
* commit '2ba24c83d9136bccf60f8638130335066a189b95':
Preserve errors to get the correct exception/Preserve errors to get the correct exception
During the switch to BoringSSL, agl noticed the error state wasn't being
preserved correctly. Integrate part of the BoringSSL change to preserve
error states.
(cherry picked from commit 2ba24c83d9136bccf60f8638130335066a189b95)
Bug: 18388980
Change-Id: I9a6fea4f3bf457808a337604290c6bfd1b9ea84e/Preserve errors to get the correct exception
During the switch to BoringSSL, agl noticed the error state wasn't being
preserved correctly. Integrate part of the BoringSSL change to preserve
error states.
Bug: 18388980
Change-Id: I9a6fea4f3bf457808a337604290c6bfd1b9ea84e/Squashed commit of changes from lmp-ub-dev
Contains the following changes:
commit e31d982cdb0f8e6ef05d1e412576888015e1da17
Merge: eaebc54 b73be72
Author: Neil Fuller <nfuller@google.com>
Date:   Wed Oct 22 10:34:23 2014 +0000
am b73be72e: am 3e21a289: (-s ours) TLS_FALLBACK_SCSV CTS fix for klp-modular-dev
* commit 'b73be72ed97da8f36450d95d52f485cc6f451c61':
TLS_FALLBACK_SCSV CTS fix for klp-modular-dev
commit eaebc544f3a10c53d7d2f908514122caba569e14
Merge: 223b5da cd50afa
Author: Kenny Root <kroot@google.com>
Date:   Tue Oct 14 17:30:19 2014 +0000
Merge ""Fix SSLEngine to support session resumption."" into lmp-ub-dev
commit 223b5da5d70e47b1a497e86474493925b568f6d7
Merge: 8737796 cb7a360
Author: Neil Fuller <nfuller@google.com>
Date:   Thu Oct 9 14:52:00 2014 +0000
am cb7a3605: am ea961ada: Apply conscrypt changes from merge commit
* commit 'cb7a36050f34d3c16be00d532411820761eeb276':
Apply conscrypt changes from merge commit
commit cd50afad1567b1311e6e979e94a7167b7bf69c94
Author: Doug Steedman <dougsteed@google.com>
Date:   Mon Oct 6 13:16:15 2014 -0700
Fix SSLEngine to support session resumption.
Bug: 17877118
Change-Id: I388b59cde58fdc506ecac9f536e4bbd9161df6ad
commit 8737796a646eaec94df32827752a71aee74bd46f
Merge: 9564a5f 8d7e23e
Author: Kenny Root <kroot@google.com>
Date:   Mon Oct 6 22:34:20 2014 +0000
am 8d7e23e1: Add support for TLS_FALLBACK_SCSV
* commit '8d7e23e117da591a8d48e6bcda9ed6f58ff1a375':
Add support for TLS_FALLBACK_SCSV
commit 9564a5fb9ed2eecf6299788db35213cb08397212
Merge: 4f58feb 7640613
Author: Kenny Root <kroot@google.com>
Date:   Fri Sep 12 17:27:23 2014 +0000
am 76406135: am 6dcb23fe: am f427ec90: Fix the ENGINE_finish/ENGINE_free mixup
* commit '76406135cf3a3b88afc979fe8e847b9c3d8b93c1':
Fix the ENGINE_finish/ENGINE_free mixup
commit 4f58feb0ea49dc089a95efba196032ef3c960a39
Merge: ddac5c6 984b7ec
Author: Kenny Root <kroot@google.com>
Date:   Wed Sep 10 07:07:16 2014 +0000
am 984b7ec6: Fix the ENGINE_finish/ENGINE_free mixup
* commit '984b7ec6f5aab314117949a48e448ff4f6b65f16':
Fix the ENGINE_finish/ENGINE_free mixup
commit ddac5c6d7e413b0d68b388fbdf70dbeb3eeae865
Merge: 5a8ca5b 36ba60b
Author: Kenny Root <kroot@google.com>
Date:   Thu Sep 4 22:41:38 2014 +0000
Merge ""Reset lmp-ub-dev to lmp-dev-plus-aosp"" into lmp-ub-dev
commit 36ba60b039f1f30ab1ea8f0e2a4da8ae4e3906e5
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 27 12:07:07 2014 -0700
Reset lmp-ub-dev to lmp-dev-plus-aosp
Bug: 17059757
Change-Id: I581963360da47b574e1e2e20c2851485c36fa62c
commit 6a4f2ef9e4ea3ebb321d45ca39b30d634ea3b4ad
Merge: 9b187af f67d784
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:17:38 2014 +0000
am f67d784a: Add pre-Honeycomb literal IP matching
* commit 'f67d784abe5cef700240be02c68cecd899cd8e6d':
Add pre-Honeycomb literal IP matching
commit 9b187af33dcd97915a0371d64fe1ee4aba20d0ba
Merge: 714ebea 966ae8a
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:17:37 2014 +0000
am 966ae8a6: Read property to enable SNI
* commit '966ae8a6e12f3235b1cb041e687bda11b41fe4eb':
Read property to enable SNI
commit 714ebeabcb5e35c6df6a5c21f549cdb6130368c4
Merge: 7724204 54a1ba4
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:06:54 2014 +0000
Merge ""resolved conflicts for merge of 342097db to lmp-dev-plus-aosp"" into lmp-dev-plus-aosp
commit 54a1ba421d23bb6d988688c2662715e509172447
Merge: a20d871 342097d
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 21:03:51 2014 -0700
resolved conflicts for merge of 342097db to lmp-dev-plus-aosp
Change-Id: I853c6b0d3725dafbdc84c4d6d6d1b90529bd949d
commit 7724204abf4431d35787c44c4a22cda5489d4e37
Merge: 20f60ac afb3403
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 00:09:27 2014 +0000
am afb34034: Implement write socket timeouts for unbundled apps
* commit 'afb340348bfc54dbc46964e159fe803f9c93a4dd':
Implement write socket timeouts for unbundled apps
commit f67d784abe5cef700240be02c68cecd899cd8e6d
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 14:14:26 2014 -0700
Add pre-Honeycomb literal IP matching
This will allow us to run this code on Gingerbread devices and others
that don't have the InetAddress#isNumeric API.
Bug: 16658420
Bug: 17059757
Change-Id: I597d539979d58eeaa2677d6f99e911313a550cc1
commit 966ae8a6e12f3235b1cb041e687bda11b41fe4eb
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 18 10:12:20 2014 -0700
Read property to enable SNI
Read the system property ""jsse.enableSNIExtension"" on whether to enable
Server Name Indication (SNI) extension. For unbundled builds, this will
be enabled by default. For platform builds, this will be disabled by
default.
Bug: 16658420
Bug: 17059757
Change-Id: I774f5406bf3fe601a42c4ef5e708b31800147eb9
commit 342097db97a9b2736531033b2c4b4d8ce4998c67
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 12:14:52 2014 -0700
Validate hostname is usable for SNI
According to RFC 6066 section 3, the hostname listed in the Server Name
Indication (SNI) field is a fully qualified domain name and IP
addresses are not permitted.
Bug: 16658420
Bug: 17059757
Change-Id: I804e46b6e66599b2770f0f4f0534467987e51208
commit afb340348bfc54dbc46964e159fe803f9c93a4dd
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 19 16:33:07 2014 -0700
Implement write socket timeouts for unbundled apps
Change-Id: I4fd604f057ba4288d4f31bf6b3b93307376023d5
commit 20f60acea153dfdf0c8f75a53d7bd9edb4c7614c
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 11:52:05 2014 -0700
Tracking change from AOSP
Change-Id: I889af3f7c1de9ef34d9328339e1b421651055ad4
commit 68056b7c9db8a9fb384bbadfc5287730f996896d
Merge: 8239dfd cc2ef2e
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 18:03:27 2014 +0000
am cc2ef2e2: Rename hostname fields and methods to reflect usage
* commit 'cc2ef2e2e9ee64f2e0ac2abc7fdf636e2f81fa5e':
Rename hostname fields and methods to reflect usage
commit 8239dfdcc40a69255d7b2feced960d574ea36321
Merge: e9cf759 076138f
Author: Kenny Root <kroot@google.com>
Date:   Thu Aug 21 16:36:24 2014 +0000
am 076138ff: Use consistent naming for SSLSocket arguments
* commit '076138ff29d805ec5a32d6ad96a18ef08c7f1b11':
Use consistent naming for SSLSocket arguments
commit cc2ef2e2e9ee64f2e0ac2abc7fdf636e2f81fa5e
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 11:26:33 2014 -0700
Rename hostname fields and methods to reflect usage
The hostname that was supplied when the socket was created is stored as
the ""peerHostname""  This is the only one that should be used for Server
Name Indication (SNI) purposes.
The ""peerHostname"" or the resolved IP address may be used for
certificate validation, so keep the use of ""getHostname()"" for
cerificate validation.
Bug: 16658420
Bug: 17059757
Change-Id: Ifd87dead44fb2f00bbfd5eac7e69fb3fc98e94b4
commit 076138ff29d805ec5a32d6ad96a18ef08c7f1b11
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 11:24:41 2014 -0700
Use consistent naming for SSLSocket arguments
This changes all the 'host' to be 'hostname' and anything that takes an
'InetAddress' will have the name of 'address' to avoid confusing it with
a hostname.
Bug: 16658420
Bug: 17059757
Change-Id: Iac0628d2d156023dbb80c2e636af6bfe63f46650
commit e9cf759ac89fb053c01f1db19931beb14a823618
Merge: ababdd1 7ed0fae
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 19 19:32:43 2014 +0000
am 7ed0fae1: OpenSSLEngineImpl: reduce number of copies needed
* commit '7ed0fae1906061766d0042e69ccba20e4a702bbe':
OpenSSLEngineImpl: reduce number of copies needed
commit 7ed0fae1906061766d0042e69ccba20e4a702bbe
Author: Kenny Root <kroot@google.com>
Date:   Tue Jul 22 13:03:09 2014 -0700
OpenSSLEngineImpl: reduce number of copies needed
When the ByteBuffer didn't line up exactly with the backing array, it
would allocate a new buffer to write into. Instead, add the ability for
OpenSSL to read at an offset in the given array so a copy isn't needed.
Change-Id: I149d3f94e4b5cbdc010df80439ae3300cbdc87a5
commit ababdd1ae1272eac174e3a449a413ab35afbc435
Merge: 66c31e0 4b050b6
Author: Kenny Root <kroot@google.com>
Date:   Fri Aug 15 16:23:14 2014 +0000
am 4b050b6f: OpenSSLSocketImpl: Move state checks inside mutex
* commit '4b050b6fb06fbb804557eecc72cc4ff0e0277525':
OpenSSLSocketImpl: Move state checks inside mutex
commit 66c31e0b613ceefc167a2e1fb226a14c78f84537
Merge: f4b895a 0931d51
Author: Kenny Root <kroot@google.com>
Date:   Thu Aug 14 20:46:43 2014 +0000
am 0931d51c: OpenSSLSocketImpl: Move state checks inside mutex
* commit '0931d51c58b2dc2f612298f99fbf0fa6ed4c3706':
OpenSSLSocketImpl: Move state checks inside mutex
commit 0931d51c58b2dc2f612298f99fbf0fa6ed4c3706
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 15:45:32 2014 -0700
OpenSSLSocketImpl: Move state checks inside mutex
Checking the state of the connection is unreliable if SSL_read and
SSL_write are happening in another thread. Move the state checks inside
our application mutex so we don't run into another thread mutating the
state at the same time.
Bug: 15606096
Change-Id: I5ecdeb1551a13098d1b66c5e4009607c9951fa38
commit f4b895ae9c424b5c2d49c744131606adccbc49d7
Merge: a35c400 a260ee6
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 13 15:35:28 2014 +0000
am a260ee6d: Revert ""Revert ""Automatic management of OpenSSL error stack""""
* commit 'a260ee6d0caea43f8010f158a4a35fb712935ae3':
Revert ""Revert ""Automatic management of OpenSSL error stack""""
commit a35c40017c8690f821351d6460dfeaa2738b884c
Merge: 0edc483 30550a8
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 13 15:35:27 2014 +0000
am 30550a8b: Fix debugging with unbundled conscrypt
* commit '30550a8b64bbcd6ca537680a17b8726932a29937':
Fix debugging with unbundled conscrypt
commit a260ee6d0caea43f8010f158a4a35fb712935ae3
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:38:10 2014 -0700
Revert ""Revert ""Automatic management of OpenSSL error stack""""
The ""else"" statement in OpenSslError::reset wasn't properly resetting
the error state which made a second call into sslRead jump into
sslSelect when it should have just returned immediately.
Change-Id: I22e8025c0497a04e78daa07cef78191a6ca1a70c
commit 30550a8b64bbcd6ca537680a17b8726932a29937
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:13:33 2014 -0700
Fix debugging with unbundled conscrypt
When JNI_TRACE was enabled, there were missing defines for the debugging
code since no platform code is included.
Also clang complains about more of the debugging statement formats, so
we have to move some things around to get it to be happy.
Change-Id: I1a6695c2ef2639cc01cfc3d3a8603f010c659844
commit 0edc4833091846d6cb45961fc9458df842fbbad9
Merge: 107a8fb 2411b8b
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:46:12 2014 +0000
am 2411b8bd: Merge ""Revert ""Automatic management of OpenSSL error stack""""
* commit '2411b8bdcde72c956f4150e9a5909b7501f50bad':
Revert ""Automatic management of OpenSSL error stack""
commit 2411b8bdcde72c956f4150e9a5909b7501f50bad
Merge: 3262a8c b514d72
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:39:32 2014 +0000
Merge ""Revert ""Automatic management of OpenSSL error stack""""
commit b514d72b93c3996d97e38eca6db1ad684965fd9b
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:39:17 2014 +0000
Revert ""Automatic management of OpenSSL error stack""
This reverts commit 35666e4cb0fcd063a21d17eebbb571b4e4e822b8.
Change-Id: I926d159c4c4b99250caef750732976c1e601e9ef
commit 107a8fba8be5be57933f2638b76ac1243b578b9e
Merge: 1de007f 3262a8c
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:50:14 2014 +0000
am 3262a8c2: Merge ""Automatic management of OpenSSL error stack""
* commit '3262a8c2741b95103149bcdefe2409c24bfddee9':
Automatic management of OpenSSL error stack
commit 1de007f9f01be8f07a56235dd924c897088a03cb
Merge: 94890ae d1bbcd0
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:50:14 2014 +0000
am d1bbcd0e: Relax checks for key vs cert for wrapped keys
* commit 'd1bbcd0ec973e1b8465c204c13b4925fd86e6484':
Relax checks for key vs cert for wrapped keys
commit 3262a8c2741b95103149bcdefe2409c24bfddee9
Merge: d1bbcd0 35666e4
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:31:02 2014 +0000
Merge ""Automatic management of OpenSSL error stack""
commit d1bbcd0ec973e1b8465c204c13b4925fd86e6484
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 11 14:56:58 2014 -0700
Relax checks for key vs cert for wrapped keys
If a key is a wrapped platform key, we must relax the check. The reason
is that we may not have the public values we need to pass the
EVP_PKEY_cmp checks that this does.
Change-Id: I7ab2be51b0968a9cf771edea01d33fe2367c8185
commit 35666e4cb0fcd063a21d17eebbb571b4e4e822b8
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 11:05:00 2014 -0700
Automatic management of OpenSSL error stack
This removes some complexity in remembering to free the OpenSSL error
stack. If you forget, the error will stick around until you make another
call.
Change-Id: I245a525dcc93077b2bf9909a14a0ef469a2daca4
commit 94890aec5735cde2ea5170fb76cd1b847ea66af8
Merge: 8360485 977f087
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 16:44:42 2014 +0000
am 977f0877: Fix some JNI_TRACE lines
* commit '977f08774c628b4640d5454cde050259856965f8':
Fix some JNI_TRACE lines
commit 977f08774c628b4640d5454cde050259856965f8
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 4 12:15:04 2014 -0700
Fix some JNI_TRACE lines
During debugging these would be enabled, but they were copy-pasta'd to
with the wrong args.
Change-Id: I23f39ff4807e3fa71f3220912aec3c99db6b9454
commit 83604854c5160304cafefc9bd40a72c5ee8506eb
Merge: 7db3524 1ffe43e
Author: Zoltan Szatmary-Ban <szatmz@google.com>
Date:   Thu Jul 31 13:28:57 2014 +0000
am 1ffe43e8: Merge ""Add possibility to get deleted system Certificate Aliases"" into lmp-dev
* commit '1ffe43e8277e883c6663c1fb7cfc5e18ba552c40':
Add possibility to get deleted system Certificate Aliases
commit 7db3524880092126962b7f502af76b4c84da7350
Merge: 5767d63 ad0cd83
Author: Prameet Shah <phshah@google.com>
Date:   Wed Jul 30 17:04:13 2014 +0000
am ad0cd830: Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
* commit 'ad0cd83024f38011043d28d70370a8638b88cd72':
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
commit 5767d63d22e87becab387b3bd6597fe41eb34d7e
Merge: b389e17 26163c2
Author: Prameet Shah <phshah@google.com>
Date:   Wed Jul 30 16:31:08 2014 +0000
am 26163c26: Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
* commit '26163c268a6d2625384b87e907afad8ef19f9a47':
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
commit 26163c268a6d2625384b87e907afad8ef19f9a47
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 29 16:45:31 2014 -0700
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
Bug: https://code.google.com/p/android/issues/detail?id=73745
Change-Id: I5bcaf3ee8910ff75e785baed4c4604fee6c5e700
commit b389e1779651f2c58454a5f98acebd3dd7bc0061
Merge: 5f03b4d e427972
Author: Prameet Shah <phshah@google.com>
Date:   Thu Jul 24 19:46:28 2014 +0000
am e427972e: OpenSSLEngineImpl: fix unwrap behavior with array
* commit 'e427972eb6141cd67e6d4c9607863a8d990e6be6':
OpenSSLEngineImpl: fix unwrap behavior with array
commit 5f03b4d63c7632581b032879de791dc82f05ffa0
Merge: 3d935ee 41eb5b6
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 22 19:26:41 2014 +0000
am 41eb5b65: OpenSSLEngineImpl: fix unwrap behavior with array
* commit '41eb5b65e524d01e28da474bd37e4349b12fb494':
OpenSSLEngineImpl: fix unwrap behavior with array
commit 41eb5b65e524d01e28da474bd37e4349b12fb494
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 22 11:50:18 2014 -0700
OpenSSLEngineImpl: fix unwrap behavior with array
The decrypted bytes should written sequentially into each buffer of
the destination array until it's full before moving to the next
buffer.
Change-Id: I2454249c167deafde6c12134d3c8cd658cd7c21b
commit 3d935eeca25e00b56cfd8d37a657c7b2986889b3
Merge: 0a36f6c affd45a
Author: Alex Klyubin <klyubin@google.com>
Date:   Fri Jul 18 00:32:14 2014 +0000
am affd45a4: Merge ""Improve the Javadoc of PSKKeyManager."" into lmp-dev
* commit 'affd45a413cf844dad797ad4972074efb9de43d8':
Improve the Javadoc of PSKKeyManager.
commit 0a36f6c1f8b2e195c2dd5aea1a386df090c6d470
Merge: 6492180 af4fa68
Author: rich cannings <richc@google.com>
Date:   Thu Jul 17 23:47:33 2014 +0000"
conscrypt,"Time out TLS/SSL sessions after 8 hours by default.
Prior to this change TLS/SSL sessions did not time out.
(cherry picked from commit e5992c842c07c472f7ea3efbcc7f133fcc022592)
Bug: 18369043
Bug: 18370076
Change-Id: I596423b9c56bfc5f337a17aba02fbb9a9f2ded36/Time out TLS/SSL sessions after 8 hours by default.
Prior to this change TLS/SSL sessions did not time out.
Bug: 18370076
Change-Id: I596423b9c56bfc5f337a17aba02fbb9a9f2ded36/"
conscrypt,"Convert EVP_PKEY to new style
To avoid conflicts in the language spec and how Conscrypt does native
calls, we need to wrap all native references in a Java object reference.
Calling NativeCrypto's static native methods with a raw pointer doesn't
guarantee that the calling object won't be finalized during the method
running.
This pass fixes EVP_PKEY references, but more passes are needed.
Bug: 16656908
Change-Id: I5925da40cb37cd328b3a126404944f771732a43e/"
conscrypt,"Convert EC_GROUP and EC_POINT to new style
Bug: 16656908
Change-Id: Ie912f376f69327ce634cac50763bf86b418049f5/"
conscrypt,"Convert EVP_PKEY to new style
To avoid conflicts in the language spec and how Conscrypt does native
calls, we need to wrap all native references in a Java object reference.
Calling NativeCrypto's static native methods with a raw pointer doesn't
guarantee that the calling object won't be finalized during the method
running.
This pass fixes EVP_PKEY references, but more passes are needed.
Bug: 16656908
Change-Id: I5925da40cb37cd328b3a126404944f771732a43e/Convert EVP_MD_CTX to new style
To avoid conflicts in the language spec and how Conscrypt does native
calls, we need to wrap all native references in a Java object reference.
Calling NativeCrypto's static native methods with a raw pointer doesn't
guarantee that the calling object won't be finalized during the method
running.
Bug: 16656908
Change-Id: I165e041a8fe056770d6ce6d6cd064c411575b7c4/"
conscrypt,"Convert EVP_PKEY to new style
To avoid conflicts in the language spec and how Conscrypt does native
calls, we need to wrap all native references in a Java object reference.
Calling NativeCrypto's static native methods with a raw pointer doesn't
guarantee that the calling object won't be finalized during the method
running.
This pass fixes EVP_PKEY references, but more passes are needed.
Bug: 16656908
Change-Id: I5925da40cb37cd328b3a126404944f771732a43e/"
conscrypt,"Remove SSLv3 from default protocols list for TLS
SSLv3 has some systemic problems demonstrated by the POODLE attack.
Disable it by default when ""TLS"" is requested since the documentation
in Java Standard Names allows us to not support SSL when TLS is
requested.
Bug: 17136008
Change-Id: Icad1639c7e33b6e495f452a5289b0d20b819d679/"
conscrypt,"Convert EC_GROUP and EC_POINT to new style
Bug: 16656908
Change-Id: Ie912f376f69327ce634cac50763bf86b418049f5/Convert EVP_PKEY to new style
To avoid conflicts in the language spec and how Conscrypt does native
calls, we need to wrap all native references in a Java object reference.
Calling NativeCrypto's static native methods with a raw pointer doesn't
guarantee that the calling object won't be finalized during the method
running.
This pass fixes EVP_PKEY references, but more passes are needed.
Bug: 16656908
Change-Id: I5925da40cb37cd328b3a126404944f771732a43e/"
conscrypt,"Call EVP_CIPHER_CTX_free instead of EVP_CIPHER_CTX_cleanup.
The latter doesn't OpenSSL_free memory allocated by EVP_CIPHER_CTX_new.
It's worth noting that EVP_CIPHER_CTX_free doesn't check the return
value of EVP_CIPHER_CTX_cleanup so we can't throw if cleanup failed, but
we were only ever calling this method from a finalizer anyway.
(cherry picked from commit c64652932d8e17ccf7e54c0c76c1b38a86841732)
bug: 18617384
Change-Id: Ida65e14ffbed41f56a59e2f5fe77289cac0f5947/Call EVP_CIPHER_CTX_free instead of EVP_CIPHER_CTX_cleanup.
The latter doesn't OpenSSL_free memory allocated by EVP_CIPHER_CTX_new.
It's worth noting that EVP_CIPHER_CTX_free doesn't check the return
value of EVP_CIPHER_CTX_cleanup so we can't throw if cleanup failed, but
we were only ever calling this method from a finalizer anyway.
bug: 18617384
Change-Id: Ida65e14ffbed41f56a59e2f5fe77289cac0f5947/Convert EC_GROUP and EC_POINT to new style
Bug: 16656908
Change-Id: Ie912f376f69327ce634cac50763bf86b418049f5/Switch EVP_CIPHER_CTX to new style
Bug: 16656908
Change-Id: Id519c20474a02c70e72d362bc84d26855a74fa33/Convert EVP_PKEY to new style
To avoid conflicts in the language spec and how Conscrypt does native
calls, we need to wrap all native references in a Java object reference.
Calling NativeCrypto's static native methods with a raw pointer doesn't
guarantee that the calling object won't be finalized during the method
running.
This pass fixes EVP_PKEY references, but more passes are needed.
Bug: 16656908
Change-Id: I5925da40cb37cd328b3a126404944f771732a43e/Convert EVP_MD_CTX to new style
To avoid conflicts in the language spec and how Conscrypt does native
calls, we need to wrap all native references in a Java object reference.
Calling NativeCrypto's static native methods with a raw pointer doesn't
guarantee that the calling object won't be finalized during the method
running.
Bug: 16656908
Change-Id: I165e041a8fe056770d6ce6d6cd064c411575b7c4/Remove Conscrypt support for DSA
BoringSSL removes support for DSA, so there's no point in maintaining
this now. There have been virtually zero SSL certificates issued using
DSA for many years as well.
Change-Id: Id940643b85ba39b03038aabc6da9ec0285db66c4/Remove support for DSS TLS/SSL cipher suites.
This is in preparation for migration from OpenSSL to BoringSSL.
BoringSSL does not support DSS.
DSS cipher suites are used by a vanishingly tiny fraction of the
Android ecosystem. In all cases, the server's SSL certificate is
self-signed (rather than CA issued), making it easy to switch to
a new self-signed certificate which is based on RSA or ECDSA.
Bug: 17409664
Change-Id: I91067ca9df764edd2b7820e5dec995f24f3910a1/Track upgrade to OpenSSL 1.0.1j
(cherry picked from commit 8ae86f7662a6330f58df6bdf3fd06af8e1dc281f)
Bug: 18018599
Change-Id: I2b8c62190a9dd5e5fdc6894334cf1d3edfce0a06/Track upgrade to OpenSSL 1.0.1j
Bug: 18018599
Change-Id: I2b8c62190a9dd5e5fdc6894334cf1d3edfce0a06/Remove SSLv3 from default protocols list for TLS
SSLv3 has some systemic problems demonstrated by the POODLE attack.
Disable it by default when ""TLS"" is requested since the documentation
in Java Standard Names allows us to not support SSL when TLS is
requested.
Bug: 17136008
Change-Id: Icad1639c7e33b6e495f452a5289b0d20b819d679/"
conscrypt,"Convert EC_GROUP and EC_POINT to new style
Bug: 16656908
Change-Id: Ie912f376f69327ce634cac50763bf86b418049f5/"
conscrypt,"Switch EVP_CIPHER_CTX to new style
Bug: 16656908
Change-Id: Id519c20474a02c70e72d362bc84d26855a74fa33/"
conscrypt,"Squashed commit of changes from lmp-ub-dev
Contains the following changes:
commit e31d982cdb0f8e6ef05d1e412576888015e1da17
Merge: eaebc54 b73be72
Author: Neil Fuller <nfuller@google.com>
Date:   Wed Oct 22 10:34:23 2014 +0000
am b73be72e: am 3e21a289: (-s ours) TLS_FALLBACK_SCSV CTS fix for klp-modular-dev
* commit 'b73be72ed97da8f36450d95d52f485cc6f451c61':
TLS_FALLBACK_SCSV CTS fix for klp-modular-dev
commit eaebc544f3a10c53d7d2f908514122caba569e14
Merge: 223b5da cd50afa
Author: Kenny Root <kroot@google.com>
Date:   Tue Oct 14 17:30:19 2014 +0000
Merge ""Fix SSLEngine to support session resumption."" into lmp-ub-dev
commit 223b5da5d70e47b1a497e86474493925b568f6d7
Merge: 8737796 cb7a360
Author: Neil Fuller <nfuller@google.com>
Date:   Thu Oct 9 14:52:00 2014 +0000
am cb7a3605: am ea961ada: Apply conscrypt changes from merge commit
* commit 'cb7a36050f34d3c16be00d532411820761eeb276':
Apply conscrypt changes from merge commit
commit cd50afad1567b1311e6e979e94a7167b7bf69c94
Author: Doug Steedman <dougsteed@google.com>
Date:   Mon Oct 6 13:16:15 2014 -0700
Fix SSLEngine to support session resumption.
Bug: 17877118
Change-Id: I388b59cde58fdc506ecac9f536e4bbd9161df6ad
commit 8737796a646eaec94df32827752a71aee74bd46f
Merge: 9564a5f 8d7e23e
Author: Kenny Root <kroot@google.com>
Date:   Mon Oct 6 22:34:20 2014 +0000
am 8d7e23e1: Add support for TLS_FALLBACK_SCSV
* commit '8d7e23e117da591a8d48e6bcda9ed6f58ff1a375':
Add support for TLS_FALLBACK_SCSV
commit 9564a5fb9ed2eecf6299788db35213cb08397212
Merge: 4f58feb 7640613
Author: Kenny Root <kroot@google.com>
Date:   Fri Sep 12 17:27:23 2014 +0000
am 76406135: am 6dcb23fe: am f427ec90: Fix the ENGINE_finish/ENGINE_free mixup
* commit '76406135cf3a3b88afc979fe8e847b9c3d8b93c1':
Fix the ENGINE_finish/ENGINE_free mixup
commit 4f58feb0ea49dc089a95efba196032ef3c960a39
Merge: ddac5c6 984b7ec
Author: Kenny Root <kroot@google.com>
Date:   Wed Sep 10 07:07:16 2014 +0000
am 984b7ec6: Fix the ENGINE_finish/ENGINE_free mixup
* commit '984b7ec6f5aab314117949a48e448ff4f6b65f16':
Fix the ENGINE_finish/ENGINE_free mixup
commit ddac5c6d7e413b0d68b388fbdf70dbeb3eeae865
Merge: 5a8ca5b 36ba60b
Author: Kenny Root <kroot@google.com>
Date:   Thu Sep 4 22:41:38 2014 +0000
Merge ""Reset lmp-ub-dev to lmp-dev-plus-aosp"" into lmp-ub-dev
commit 36ba60b039f1f30ab1ea8f0e2a4da8ae4e3906e5
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 27 12:07:07 2014 -0700
Reset lmp-ub-dev to lmp-dev-plus-aosp
Bug: 17059757
Change-Id: I581963360da47b574e1e2e20c2851485c36fa62c
commit 6a4f2ef9e4ea3ebb321d45ca39b30d634ea3b4ad
Merge: 9b187af f67d784
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:17:38 2014 +0000
am f67d784a: Add pre-Honeycomb literal IP matching
* commit 'f67d784abe5cef700240be02c68cecd899cd8e6d':
Add pre-Honeycomb literal IP matching
commit 9b187af33dcd97915a0371d64fe1ee4aba20d0ba
Merge: 714ebea 966ae8a
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:17:37 2014 +0000
am 966ae8a6: Read property to enable SNI
* commit '966ae8a6e12f3235b1cb041e687bda11b41fe4eb':
Read property to enable SNI
commit 714ebeabcb5e35c6df6a5c21f549cdb6130368c4
Merge: 7724204 54a1ba4
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:06:54 2014 +0000
Merge ""resolved conflicts for merge of 342097db to lmp-dev-plus-aosp"" into lmp-dev-plus-aosp
commit 54a1ba421d23bb6d988688c2662715e509172447
Merge: a20d871 342097d
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 21:03:51 2014 -0700
resolved conflicts for merge of 342097db to lmp-dev-plus-aosp
Change-Id: I853c6b0d3725dafbdc84c4d6d6d1b90529bd949d
commit 7724204abf4431d35787c44c4a22cda5489d4e37
Merge: 20f60ac afb3403
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 00:09:27 2014 +0000
am afb34034: Implement write socket timeouts for unbundled apps
* commit 'afb340348bfc54dbc46964e159fe803f9c93a4dd':
Implement write socket timeouts for unbundled apps
commit f67d784abe5cef700240be02c68cecd899cd8e6d
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 14:14:26 2014 -0700
Add pre-Honeycomb literal IP matching
This will allow us to run this code on Gingerbread devices and others
that don't have the InetAddress#isNumeric API.
Bug: 16658420
Bug: 17059757
Change-Id: I597d539979d58eeaa2677d6f99e911313a550cc1
commit 966ae8a6e12f3235b1cb041e687bda11b41fe4eb
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 18 10:12:20 2014 -0700
Read property to enable SNI
Read the system property ""jsse.enableSNIExtension"" on whether to enable
Server Name Indication (SNI) extension. For unbundled builds, this will
be enabled by default. For platform builds, this will be disabled by
default.
Bug: 16658420
Bug: 17059757
Change-Id: I774f5406bf3fe601a42c4ef5e708b31800147eb9
commit 342097db97a9b2736531033b2c4b4d8ce4998c67
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 12:14:52 2014 -0700
Validate hostname is usable for SNI
According to RFC 6066 section 3, the hostname listed in the Server Name
Indication (SNI) field is a fully qualified domain name and IP
addresses are not permitted.
Bug: 16658420
Bug: 17059757
Change-Id: I804e46b6e66599b2770f0f4f0534467987e51208
commit afb340348bfc54dbc46964e159fe803f9c93a4dd
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 19 16:33:07 2014 -0700
Implement write socket timeouts for unbundled apps
Change-Id: I4fd604f057ba4288d4f31bf6b3b93307376023d5
commit 20f60acea153dfdf0c8f75a53d7bd9edb4c7614c
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 11:52:05 2014 -0700
Tracking change from AOSP
Change-Id: I889af3f7c1de9ef34d9328339e1b421651055ad4
commit 68056b7c9db8a9fb384bbadfc5287730f996896d
Merge: 8239dfd cc2ef2e
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 18:03:27 2014 +0000
am cc2ef2e2: Rename hostname fields and methods to reflect usage
* commit 'cc2ef2e2e9ee64f2e0ac2abc7fdf636e2f81fa5e':
Rename hostname fields and methods to reflect usage
commit 8239dfdcc40a69255d7b2feced960d574ea36321
Merge: e9cf759 076138f
Author: Kenny Root <kroot@google.com>
Date:   Thu Aug 21 16:36:24 2014 +0000
am 076138ff: Use consistent naming for SSLSocket arguments
* commit '076138ff29d805ec5a32d6ad96a18ef08c7f1b11':
Use consistent naming for SSLSocket arguments
commit cc2ef2e2e9ee64f2e0ac2abc7fdf636e2f81fa5e
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 11:26:33 2014 -0700
Rename hostname fields and methods to reflect usage
The hostname that was supplied when the socket was created is stored as
the ""peerHostname""  This is the only one that should be used for Server
Name Indication (SNI) purposes.
The ""peerHostname"" or the resolved IP address may be used for
certificate validation, so keep the use of ""getHostname()"" for
cerificate validation.
Bug: 16658420
Bug: 17059757
Change-Id: Ifd87dead44fb2f00bbfd5eac7e69fb3fc98e94b4
commit 076138ff29d805ec5a32d6ad96a18ef08c7f1b11
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 11:24:41 2014 -0700
Use consistent naming for SSLSocket arguments
This changes all the 'host' to be 'hostname' and anything that takes an
'InetAddress' will have the name of 'address' to avoid confusing it with
a hostname.
Bug: 16658420
Bug: 17059757
Change-Id: Iac0628d2d156023dbb80c2e636af6bfe63f46650
commit e9cf759ac89fb053c01f1db19931beb14a823618
Merge: ababdd1 7ed0fae
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 19 19:32:43 2014 +0000
am 7ed0fae1: OpenSSLEngineImpl: reduce number of copies needed
* commit '7ed0fae1906061766d0042e69ccba20e4a702bbe':
OpenSSLEngineImpl: reduce number of copies needed
commit 7ed0fae1906061766d0042e69ccba20e4a702bbe
Author: Kenny Root <kroot@google.com>
Date:   Tue Jul 22 13:03:09 2014 -0700
OpenSSLEngineImpl: reduce number of copies needed
When the ByteBuffer didn't line up exactly with the backing array, it
would allocate a new buffer to write into. Instead, add the ability for
OpenSSL to read at an offset in the given array so a copy isn't needed.
Change-Id: I149d3f94e4b5cbdc010df80439ae3300cbdc87a5
commit ababdd1ae1272eac174e3a449a413ab35afbc435
Merge: 66c31e0 4b050b6
Author: Kenny Root <kroot@google.com>
Date:   Fri Aug 15 16:23:14 2014 +0000
am 4b050b6f: OpenSSLSocketImpl: Move state checks inside mutex
* commit '4b050b6fb06fbb804557eecc72cc4ff0e0277525':
OpenSSLSocketImpl: Move state checks inside mutex
commit 66c31e0b613ceefc167a2e1fb226a14c78f84537
Merge: f4b895a 0931d51
Author: Kenny Root <kroot@google.com>
Date:   Thu Aug 14 20:46:43 2014 +0000
am 0931d51c: OpenSSLSocketImpl: Move state checks inside mutex
* commit '0931d51c58b2dc2f612298f99fbf0fa6ed4c3706':
OpenSSLSocketImpl: Move state checks inside mutex
commit 0931d51c58b2dc2f612298f99fbf0fa6ed4c3706
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 15:45:32 2014 -0700
OpenSSLSocketImpl: Move state checks inside mutex
Checking the state of the connection is unreliable if SSL_read and
SSL_write are happening in another thread. Move the state checks inside
our application mutex so we don't run into another thread mutating the
state at the same time.
Bug: 15606096
Change-Id: I5ecdeb1551a13098d1b66c5e4009607c9951fa38
commit f4b895ae9c424b5c2d49c744131606adccbc49d7
Merge: a35c400 a260ee6
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 13 15:35:28 2014 +0000
am a260ee6d: Revert ""Revert ""Automatic management of OpenSSL error stack""""
* commit 'a260ee6d0caea43f8010f158a4a35fb712935ae3':
Revert ""Revert ""Automatic management of OpenSSL error stack""""
commit a35c40017c8690f821351d6460dfeaa2738b884c
Merge: 0edc483 30550a8
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 13 15:35:27 2014 +0000
am 30550a8b: Fix debugging with unbundled conscrypt
* commit '30550a8b64bbcd6ca537680a17b8726932a29937':
Fix debugging with unbundled conscrypt
commit a260ee6d0caea43f8010f158a4a35fb712935ae3
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:38:10 2014 -0700
Revert ""Revert ""Automatic management of OpenSSL error stack""""
The ""else"" statement in OpenSslError::reset wasn't properly resetting
the error state which made a second call into sslRead jump into
sslSelect when it should have just returned immediately.
Change-Id: I22e8025c0497a04e78daa07cef78191a6ca1a70c
commit 30550a8b64bbcd6ca537680a17b8726932a29937
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:13:33 2014 -0700
Fix debugging with unbundled conscrypt
When JNI_TRACE was enabled, there were missing defines for the debugging
code since no platform code is included.
Also clang complains about more of the debugging statement formats, so
we have to move some things around to get it to be happy.
Change-Id: I1a6695c2ef2639cc01cfc3d3a8603f010c659844
commit 0edc4833091846d6cb45961fc9458df842fbbad9
Merge: 107a8fb 2411b8b
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:46:12 2014 +0000
am 2411b8bd: Merge ""Revert ""Automatic management of OpenSSL error stack""""
* commit '2411b8bdcde72c956f4150e9a5909b7501f50bad':
Revert ""Automatic management of OpenSSL error stack""
commit 2411b8bdcde72c956f4150e9a5909b7501f50bad
Merge: 3262a8c b514d72
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:39:32 2014 +0000
Merge ""Revert ""Automatic management of OpenSSL error stack""""
commit b514d72b93c3996d97e38eca6db1ad684965fd9b
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:39:17 2014 +0000
Revert ""Automatic management of OpenSSL error stack""
This reverts commit 35666e4cb0fcd063a21d17eebbb571b4e4e822b8.
Change-Id: I926d159c4c4b99250caef750732976c1e601e9ef
commit 107a8fba8be5be57933f2638b76ac1243b578b9e
Merge: 1de007f 3262a8c
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:50:14 2014 +0000
am 3262a8c2: Merge ""Automatic management of OpenSSL error stack""
* commit '3262a8c2741b95103149bcdefe2409c24bfddee9':
Automatic management of OpenSSL error stack
commit 1de007f9f01be8f07a56235dd924c897088a03cb
Merge: 94890ae d1bbcd0
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:50:14 2014 +0000
am d1bbcd0e: Relax checks for key vs cert for wrapped keys
* commit 'd1bbcd0ec973e1b8465c204c13b4925fd86e6484':
Relax checks for key vs cert for wrapped keys
commit 3262a8c2741b95103149bcdefe2409c24bfddee9
Merge: d1bbcd0 35666e4
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:31:02 2014 +0000
Merge ""Automatic management of OpenSSL error stack""
commit d1bbcd0ec973e1b8465c204c13b4925fd86e6484
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 11 14:56:58 2014 -0700
Relax checks for key vs cert for wrapped keys
If a key is a wrapped platform key, we must relax the check. The reason
is that we may not have the public values we need to pass the
EVP_PKEY_cmp checks that this does.
Change-Id: I7ab2be51b0968a9cf771edea01d33fe2367c8185
commit 35666e4cb0fcd063a21d17eebbb571b4e4e822b8
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 11:05:00 2014 -0700
Automatic management of OpenSSL error stack
This removes some complexity in remembering to free the OpenSSL error
stack. If you forget, the error will stick around until you make another
call.
Change-Id: I245a525dcc93077b2bf9909a14a0ef469a2daca4
commit 94890aec5735cde2ea5170fb76cd1b847ea66af8
Merge: 8360485 977f087
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 16:44:42 2014 +0000
am 977f0877: Fix some JNI_TRACE lines
* commit '977f08774c628b4640d5454cde050259856965f8':
Fix some JNI_TRACE lines
commit 977f08774c628b4640d5454cde050259856965f8
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 4 12:15:04 2014 -0700
Fix some JNI_TRACE lines
During debugging these would be enabled, but they were copy-pasta'd to
with the wrong args.
Change-Id: I23f39ff4807e3fa71f3220912aec3c99db6b9454
commit 83604854c5160304cafefc9bd40a72c5ee8506eb
Merge: 7db3524 1ffe43e
Author: Zoltan Szatmary-Ban <szatmz@google.com>
Date:   Thu Jul 31 13:28:57 2014 +0000
am 1ffe43e8: Merge ""Add possibility to get deleted system Certificate Aliases"" into lmp-dev
* commit '1ffe43e8277e883c6663c1fb7cfc5e18ba552c40':
Add possibility to get deleted system Certificate Aliases
commit 7db3524880092126962b7f502af76b4c84da7350
Merge: 5767d63 ad0cd83
Author: Prameet Shah <phshah@google.com>
Date:   Wed Jul 30 17:04:13 2014 +0000
am ad0cd830: Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
* commit 'ad0cd83024f38011043d28d70370a8638b88cd72':
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
commit 5767d63d22e87becab387b3bd6597fe41eb34d7e
Merge: b389e17 26163c2
Author: Prameet Shah <phshah@google.com>
Date:   Wed Jul 30 16:31:08 2014 +0000
am 26163c26: Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
* commit '26163c268a6d2625384b87e907afad8ef19f9a47':
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
commit 26163c268a6d2625384b87e907afad8ef19f9a47
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 29 16:45:31 2014 -0700
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
Bug: https://code.google.com/p/android/issues/detail?id=73745
Change-Id: I5bcaf3ee8910ff75e785baed4c4604fee6c5e700
commit b389e1779651f2c58454a5f98acebd3dd7bc0061
Merge: 5f03b4d e427972
Author: Prameet Shah <phshah@google.com>
Date:   Thu Jul 24 19:46:28 2014 +0000
am e427972e: OpenSSLEngineImpl: fix unwrap behavior with array
* commit 'e427972eb6141cd67e6d4c9607863a8d990e6be6':
OpenSSLEngineImpl: fix unwrap behavior with array
commit 5f03b4d63c7632581b032879de791dc82f05ffa0
Merge: 3d935ee 41eb5b6
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 22 19:26:41 2014 +0000
am 41eb5b65: OpenSSLEngineImpl: fix unwrap behavior with array
* commit '41eb5b65e524d01e28da474bd37e4349b12fb494':
OpenSSLEngineImpl: fix unwrap behavior with array
commit 41eb5b65e524d01e28da474bd37e4349b12fb494
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 22 11:50:18 2014 -0700
OpenSSLEngineImpl: fix unwrap behavior with array
The decrypted bytes should written sequentially into each buffer of
the destination array until it's full before moving to the next
buffer.
Change-Id: I2454249c167deafde6c12134d3c8cd658cd7c21b
commit 3d935eeca25e00b56cfd8d37a657c7b2986889b3
Merge: 0a36f6c affd45a
Author: Alex Klyubin <klyubin@google.com>
Date:   Fri Jul 18 00:32:14 2014 +0000
am affd45a4: Merge ""Improve the Javadoc of PSKKeyManager."" into lmp-dev
* commit 'affd45a413cf844dad797ad4972074efb9de43d8':
Improve the Javadoc of PSKKeyManager.
commit 0a36f6c1f8b2e195c2dd5aea1a386df090c6d470
Merge: 6492180 af4fa68
Author: rich cannings <richc@google.com>
Date:   Thu Jul 17 23:47:33 2014 +0000
am af4fa685: Merge ""Log CCS exceptions do not merge."" into lmp-dev
* commit 'af4fa685f246aaa80c93af62faadbc2fe87dc034':
Log CCS exceptions do not merge.
commit 6492180ce17a3b5ff822cff1783f00e7a4176491
Merge: aac4168 3b7268c
Author: Alex Klyubin <klyubin@google.com>
Date:   Thu Jul 17 18:27:39 2014 +0000
am 3b7268cd: Merge ""Improve the Javadoc of PSKKeyManager.""
* commit '3b7268cde4a4fc59591da8a93691927ebf3add57':
Improve the Javadoc of PSKKeyManager.
commit aac4168d8baef7e12d6fa959c6d6ded9892e9651
Merge: 8573ad0 a749c0d
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 17 17:07:05 2014 +0000
am a749c0d3: Keep enough state to completely reset cipher instances
* commit 'a749c0d351216be38879600ee8ed01c6793aa256':
Keep enough state to completely reset cipher instances
commit 8573ad0ddcf7e2f8b2e5ac84c34b7ffab303155c
Merge: 4ca5b06 70fdb6d
Author: Koushik Dutta <koushd@gmail.com>
Date:   Thu Jul 17 17:06:36 2014 +0000
am 70fdb6d2: OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
* commit '70fdb6d2bfa0c313fe389827f0025288f6aeb947':
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
commit 4ca5b0625e3f5a15ae8adf833ab5a69f9d7d517f
Merge: 119abfb ded66f5
Author: Koushik Dutta <koushd@gmail.com>
Date:   Thu Jul 17 17:06:35 2014 +0000
am ded66f5f: Various fixes in OpenSSLEngineImpl.
* commit 'ded66f5f696994ce7620552e16a4e9124e69e052':
Various fixes in OpenSSLEngineImpl.
commit 119abfba1fcd9c9cfbd15d0a4ca9ed2188fdfab0
Merge: 5713cdf cbe1f28
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 17 15:56:57 2014 +0000
am cbe1f28a: Merge ""Keep enough state to completely reset cipher instances""
* commit 'cbe1f28adf64396561a3b65bf1452dfa9b6e35ae':
Keep enough state to completely reset cipher instances
commit cbe1f28adf64396561a3b65bf1452dfa9b6e35ae
Merge: e08f238 084e308
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 17 15:48:58 2014 +0000
Merge ""Keep enough state to completely reset cipher instances""
commit 3b7268cde4a4fc59591da8a93691927ebf3add57
Merge: cbe1f28 7ac13e0
Author: Alex Klyubin <klyubin@google.com>
Date:   Thu Jul 17 18:20:43 2014 +0000
Merge ""Improve the Javadoc of PSKKeyManager.""
commit 5713cdf71c5c6e5179e8369263c702e9512afdd0
Merge: cf55719 e08f238
Author: Koushik Dutta <koushd@gmail.com>
Date:   Wed Jul 16 22:05:17 2014 +0000
am e08f2385: OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
* commit 'e08f238580e8ee471012bef8240c8d3397c7b780':
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
commit cf557195a9b60d7f51a48500afde38481ddbc91c
Merge: cbbd7d1 986aeb7
Author: Kenny Root <kroot@android.com>
Date:   Wed Jul 16 21:41:12 2014 +0000
am 986aeb78: Merge ""Various fixes in OpenSSLEngineImpl.""
* commit '986aeb78e533540463daf1753e24840f75b25ce6':
Various fixes in OpenSSLEngineImpl.
commit e08f238580e8ee471012bef8240c8d3397c7b780
Author: Koushik Dutta <koushd@gmail.com>
Date:   Tue Jul 15 22:40:23 2014 -0700
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
Change-Id: Idc78204b7077fb367b64e1867c807cd39f596f98
commit 7ac13e03a79d0c99d181b1a28b1b3699ba3d5739
Author: Alex Klyubin <klyubin@google.com>
Date:   Wed Jul 16 08:33:02 2014 -0700
Improve the Javadoc of PSKKeyManager.
This clarifies several points and adds sample code.
Bug: 15073623
Change-Id: I6e8aadc52277e238a998d6cee36795dab1151d58
commit 986aeb78e533540463daf1753e24840f75b25ce6
Merge: 8f9ac1a bdfcc18
Author: Kenny Root <kroot@android.com>
Date:   Wed Jul 16 21:15:30 2014 +0000
Merge ""Various fixes in OpenSSLEngineImpl.""
commit bdfcc189efe41a3f812aeb55ea634bace67d159a
Author: Koushik Dutta <koushd@gmail.com>
Date:   Sat Jun 28 19:19:21 2014 -0700
Various fixes in OpenSSLEngineImpl.
Fix ""Buffers were not large enough"" exception by directly using the
destination buffers.
Corrections around bytesProduced and bytesConsumed behavior.
Return BUFFER_OVERFLOW if a zero length destination is provided to
unwrap.
Change-Id: I1f1e9b72cd6968ed4f3c3c0edccbccebc33d6790
commit cbbd7d10e8e484c44a78e5b27e8fecda195f1692
Merge: ec7f8e6 fdb7d8c
Author: Alex Klyubin <klyubin@google.com>
Date:   Tue Jul 15 18:49:14 2014 +0000
am fdb7d8c5: Enable PSK cipher suites when PSKKeyManager is provided.
* commit 'fdb7d8c53dabac5551e2499d045ba6829bcfc0a0':
Enable PSK cipher suites when PSKKeyManager is provided.
commit ec7f8e6b27330160f88540f4f2ace7bc2a0720a3
Merge: 5b8ccf1 8f9ac1a
Author: Alex Klyubin <klyubin@google.com>
Date:   Tue Jul 15 15:53:46 2014 +0000
am 8f9ac1af: Enable PSK cipher suites when PSKKeyManager is provided.
* commit '8f9ac1af0cbdf00e5e47aee32c132522ebc3bd17':
Enable PSK cipher suites when PSKKeyManager is provided.
commit 5b8ccf1b09df6f35c1709bfc8fd727a291094a5b
Merge: 69a2e46 6e2315f
Author: Ed Heyl <edheyl@google.com>
Date:   Tue Jul 15 13:34:25 2014 +0000
am 6e2315fd: reconcile aosp (e79c25bf33e10da41e489c537823f678e1a1169c) after branching. Please do not merge.
* commit '6e2315fd96c3c4a47450c1a437babacc94bc31a6':
reconcile aosp (e79c25bf33e10da41e489c537823f678e1a1169c) after branching. Please do not merge.
commit 084e3086be1d7a6b9280b64c7c8cdb7b41a13bea
Author: Kenny Root <kroot@google.com>
Date:   Mon Jul 14 13:25:32 2014 -0700
Keep enough state to completely reset cipher instances
OpenSSL's RC4 mutates the given key. AES/CTR mutates the IV. We must
store these values locally to enable ""doFinal"" to cause the Cipher
instance to be reset to what it was right after ""init"".
Note that resetting and encrypting with the same key or IV breaks
semantic security.
Bug: 16298401
Bug: https://code.google.com/p/android/issues/detail?id=73339
Change-Id: Ie7e4dcb6cf6cc33ddad31d6b47066dc1b34e6894
commit 69a2e460cc0a40e1b951e400589b9932609079ec
Merge: 8b7bb32 bca895f
Author: David Benjamin <davidben@chromium.org>
Date:   Mon Jul 14 18:17:28 2014 +0000
am bca895f8: Pass output buffer length into EVP_DigestSignFinal.
* commit 'bca895f809dd2cef7a0834f0bfeb2a06e42b277d':
Pass output buffer length into EVP_DigestSignFinal.
commit 8b7bb32af09a01e80442b70dd23e6997a937f103
Merge: a2404c9 e79c25b
Author: Kenny Root <kroot@google.com>
Date:   Mon Jul 14 18:17:28 2014 +0000
am e79c25bf: Merge ""DHKeyPairGenerator: use provided params""
* commit 'e79c25bf33e10da41e489c537823f678e1a1169c':
DHKeyPairGenerator: use provided params
commit 8f9ac1af0cbdf00e5e47aee32c132522ebc3bd17
Author: Alex Klyubin <klyubin@google.com>
Date:   Thu Jun 19 13:37:24 2014 -0700
Enable PSK cipher suites when PSKKeyManager is provided.
This enables TLS-PSK cipher suites by default iff SSLContext is
initialized with a PSKKeyManager. For consistency, X.509 based
cipher suites are no longer enabled by default at all times -- they
are now only enabled by default iff SSLContext is initialized with a
X509KeyManager or a X509TrustManager.
When both X.509 and PSK cipher suites need to be enabled, PSK cipher
suites are given higher priority in the resulting list of cipher
suites. This is based on the assumption that in most cases users of
TLS/SSL who enable TLS-PSK would prefer TLS-PSK to be used when the
peer supports TLS-PSK.
Bug: 15073623
Change-Id: I8e2bc3e7a1ea8a986e468973b6bad19dc6b7bc3c
commit bca895f809dd2cef7a0834f0bfeb2a06e42b277d
Author: David Benjamin <davidben@chromium.org>
Date:   Thu Jul 10 18:12:08 2014 -0400
Pass output buffer length into EVP_DigestSignFinal.
EVP_DigestSignFinal expects the input buffer length as *siglen on input. In
addition, if sigret is NULL, it returns the buffer size needed. Use this rather
than making assumptions about the EVP_PKEY used to initialize the EVP_MD_CTX.
commit e79c25bf33e10da41e489c537823f678e1a1169c
Merge: a328492 9b226f9
Author: Kenny Root <kroot@google.com>
Date:   Fri Jul 11 16:46:23 2014 +0000
Merge ""DHKeyPairGenerator: use provided params""
commit 9b226f90a992a4a2267b7a813e3b869851945c4d
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 10 14:50:48 2014 -0700
DHKeyPairGenerator: use provided params
If the prime is provided in the DHParameterSpec, then use it to generate
the key.
Bug: 16188130
Change-Id: I42de02c71a58d691ef7ba6e2252367105687b758
Bug: 18388980
Change-Id: I853b02a32db113a5af3f6166e7d61fab58c3ff73/"
conscrypt,"Convert EVP_PKEY to new style
To avoid conflicts in the language spec and how Conscrypt does native
calls, we need to wrap all native references in a Java object reference.
Calling NativeCrypto's static native methods with a raw pointer doesn't
guarantee that the calling object won't be finalized during the method
running.
This pass fixes EVP_PKEY references, but more passes are needed.
Bug: 16656908
Change-Id: I5925da40cb37cd328b3a126404944f771732a43e/"
conscrypt,"OpenSSLEngineImpl: return bytes consumed for unwrap
During a handshake, unwrap should return the number of bytes consumed by
the SSL implementation in addition to changing the source buffer
position so that the client can alter its state based on either.
(cherry picked from commit 8e68a40dea765a9769de454f51c877ad80d670bb)
Bug: 18921387
Bug: https://code.google.com/p/android/issues/detail?id=93740
Change-Id: Idf5a3b24c8ad053ef2970bfb66d142a7c2685c02/OpenSSLEngineImpl: return bytes consumed for unwrap
During a handshake, unwrap should return the number of bytes consumed by
the SSL implementation in addition to changing the source buffer
position so that the client can alter its state based on either.
Bug: 18921387
Bug: https://code.google.com/p/android/issues/detail?id=93740
Change-Id: Idf5a3b24c8ad053ef2970bfb66d142a7c2685c02/Return BUFFER_UNDERFLOW if no source bytes were consumed.
... either during the handshake or after. With this change, we're
backward compatible with older versions of android. Note that newer
versions of apache-http rely on this behaviour.
bug: 18554122
(cherry picked from commit 6a1b7a85dcdeb19305ad5153579bd11c1eb0bfad)
Change-Id: I741d2585548b3d72abae2b696eee2a186e58414c/Return BUFFER_UNDERFLOW if no source bytes were consumed.
... either during the handshake or after. With this change, we're
backward compatible with older versions of android. Note that newer
versions of apache-http rely on this behaviour.
bug: 18554122
Change-Id: I574c263e8df4a5f2396ac860608fe85cdbcdbb49/am 712d3b1e: am af49a8e2: Fix SSLEngine to support session resumption.
* commit '712d3b1e064c167899b115320ccc28c5c2fda78d':
Fix SSLEngine to support session resumption./am af49a8e2: Fix SSLEngine to support session resumption.
* commit 'af49a8e2568b5a561703d93b7c872ba3a807fb3b':
Fix SSLEngine to support session resumption./Fix SSLEngine to support session resumption.
(cherry picked from commit cd50afad1567b1311e6e979e94a7167b7bf69c94)
Bug: 17877118
Change-Id: I388b59cde58fdc506ecac9f536e4bbd9161df6ad/Squashed commit of changes from lmp-ub-dev
Contains the following changes:
commit e31d982cdb0f8e6ef05d1e412576888015e1da17
Merge: eaebc54 b73be72
Author: Neil Fuller <nfuller@google.com>
Date:   Wed Oct 22 10:34:23 2014 +0000
am b73be72e: am 3e21a289: (-s ours) TLS_FALLBACK_SCSV CTS fix for klp-modular-dev
* commit 'b73be72ed97da8f36450d95d52f485cc6f451c61':
TLS_FALLBACK_SCSV CTS fix for klp-modular-dev
commit eaebc544f3a10c53d7d2f908514122caba569e14
Merge: 223b5da cd50afa
Author: Kenny Root <kroot@google.com>
Date:   Tue Oct 14 17:30:19 2014 +0000
Merge ""Fix SSLEngine to support session resumption."" into lmp-ub-dev
commit 223b5da5d70e47b1a497e86474493925b568f6d7
Merge: 8737796 cb7a360
Author: Neil Fuller <nfuller@google.com>
Date:   Thu Oct 9 14:52:00 2014 +0000
am cb7a3605: am ea961ada: Apply conscrypt changes from merge commit
* commit 'cb7a36050f34d3c16be00d532411820761eeb276':
Apply conscrypt changes from merge commit
commit cd50afad1567b1311e6e979e94a7167b7bf69c94
Author: Doug Steedman <dougsteed@google.com>
Date:   Mon Oct 6 13:16:15 2014 -0700
Fix SSLEngine to support session resumption.
Bug: 17877118
Change-Id: I388b59cde58fdc506ecac9f536e4bbd9161df6ad
commit 8737796a646eaec94df32827752a71aee74bd46f
Merge: 9564a5f 8d7e23e
Author: Kenny Root <kroot@google.com>
Date:   Mon Oct 6 22:34:20 2014 +0000
am 8d7e23e1: Add support for TLS_FALLBACK_SCSV
* commit '8d7e23e117da591a8d48e6bcda9ed6f58ff1a375':
Add support for TLS_FALLBACK_SCSV
commit 9564a5fb9ed2eecf6299788db35213cb08397212
Merge: 4f58feb 7640613
Author: Kenny Root <kroot@google.com>
Date:   Fri Sep 12 17:27:23 2014 +0000
am 76406135: am 6dcb23fe: am f427ec90: Fix the ENGINE_finish/ENGINE_free mixup
* commit '76406135cf3a3b88afc979fe8e847b9c3d8b93c1':
Fix the ENGINE_finish/ENGINE_free mixup
commit 4f58feb0ea49dc089a95efba196032ef3c960a39
Merge: ddac5c6 984b7ec
Author: Kenny Root <kroot@google.com>
Date:   Wed Sep 10 07:07:16 2014 +0000
am 984b7ec6: Fix the ENGINE_finish/ENGINE_free mixup
* commit '984b7ec6f5aab314117949a48e448ff4f6b65f16':
Fix the ENGINE_finish/ENGINE_free mixup
commit ddac5c6d7e413b0d68b388fbdf70dbeb3eeae865
Merge: 5a8ca5b 36ba60b
Author: Kenny Root <kroot@google.com>
Date:   Thu Sep 4 22:41:38 2014 +0000
Merge ""Reset lmp-ub-dev to lmp-dev-plus-aosp"" into lmp-ub-dev
commit 36ba60b039f1f30ab1ea8f0e2a4da8ae4e3906e5
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 27 12:07:07 2014 -0700
Reset lmp-ub-dev to lmp-dev-plus-aosp
Bug: 17059757
Change-Id: I581963360da47b574e1e2e20c2851485c36fa62c
commit 6a4f2ef9e4ea3ebb321d45ca39b30d634ea3b4ad
Merge: 9b187af f67d784
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:17:38 2014 +0000
am f67d784a: Add pre-Honeycomb literal IP matching
* commit 'f67d784abe5cef700240be02c68cecd899cd8e6d':
Add pre-Honeycomb literal IP matching
commit 9b187af33dcd97915a0371d64fe1ee4aba20d0ba
Merge: 714ebea 966ae8a
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:17:37 2014 +0000
am 966ae8a6: Read property to enable SNI
* commit '966ae8a6e12f3235b1cb041e687bda11b41fe4eb':
Read property to enable SNI
commit 714ebeabcb5e35c6df6a5c21f549cdb6130368c4
Merge: 7724204 54a1ba4
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:06:54 2014 +0000
Merge ""resolved conflicts for merge of 342097db to lmp-dev-plus-aosp"" into lmp-dev-plus-aosp
commit 54a1ba421d23bb6d988688c2662715e509172447
Merge: a20d871 342097d
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 21:03:51 2014 -0700
resolved conflicts for merge of 342097db to lmp-dev-plus-aosp
Change-Id: I853c6b0d3725dafbdc84c4d6d6d1b90529bd949d
commit 7724204abf4431d35787c44c4a22cda5489d4e37
Merge: 20f60ac afb3403
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 00:09:27 2014 +0000
am afb34034: Implement write socket timeouts for unbundled apps
* commit 'afb340348bfc54dbc46964e159fe803f9c93a4dd':
Implement write socket timeouts for unbundled apps
commit f67d784abe5cef700240be02c68cecd899cd8e6d
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 14:14:26 2014 -0700
Add pre-Honeycomb literal IP matching
This will allow us to run this code on Gingerbread devices and others
that don't have the InetAddress#isNumeric API.
Bug: 16658420
Bug: 17059757
Change-Id: I597d539979d58eeaa2677d6f99e911313a550cc1
commit 966ae8a6e12f3235b1cb041e687bda11b41fe4eb
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 18 10:12:20 2014 -0700
Read property to enable SNI
Read the system property ""jsse.enableSNIExtension"" on whether to enable
Server Name Indication (SNI) extension. For unbundled builds, this will
be enabled by default. For platform builds, this will be disabled by
default.
Bug: 16658420
Bug: 17059757
Change-Id: I774f5406bf3fe601a42c4ef5e708b31800147eb9
commit 342097db97a9b2736531033b2c4b4d8ce4998c67
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 12:14:52 2014 -0700
Validate hostname is usable for SNI
According to RFC 6066 section 3, the hostname listed in the Server Name
Indication (SNI) field is a fully qualified domain name and IP
addresses are not permitted.
Bug: 16658420
Bug: 17059757
Change-Id: I804e46b6e66599b2770f0f4f0534467987e51208
commit afb340348bfc54dbc46964e159fe803f9c93a4dd
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 19 16:33:07 2014 -0700
Implement write socket timeouts for unbundled apps
Change-Id: I4fd604f057ba4288d4f31bf6b3b93307376023d5
commit 20f60acea153dfdf0c8f75a53d7bd9edb4c7614c
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 11:52:05 2014 -0700
Tracking change from AOSP
Change-Id: I889af3f7c1de9ef34d9328339e1b421651055ad4
commit 68056b7c9db8a9fb384bbadfc5287730f996896d
Merge: 8239dfd cc2ef2e
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 18:03:27 2014 +0000
am cc2ef2e2: Rename hostname fields and methods to reflect usage
* commit 'cc2ef2e2e9ee64f2e0ac2abc7fdf636e2f81fa5e':
Rename hostname fields and methods to reflect usage
commit 8239dfdcc40a69255d7b2feced960d574ea36321
Merge: e9cf759 076138f
Author: Kenny Root <kroot@google.com>
Date:   Thu Aug 21 16:36:24 2014 +0000
am 076138ff: Use consistent naming for SSLSocket arguments
* commit '076138ff29d805ec5a32d6ad96a18ef08c7f1b11':
Use consistent naming for SSLSocket arguments
commit cc2ef2e2e9ee64f2e0ac2abc7fdf636e2f81fa5e
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 11:26:33 2014 -0700
Rename hostname fields and methods to reflect usage
The hostname that was supplied when the socket was created is stored as
the ""peerHostname""  This is the only one that should be used for Server
Name Indication (SNI) purposes.
The ""peerHostname"" or the resolved IP address may be used for
certificate validation, so keep the use of ""getHostname()"" for
cerificate validation.
Bug: 16658420
Bug: 17059757
Change-Id: Ifd87dead44fb2f00bbfd5eac7e69fb3fc98e94b4
commit 076138ff29d805ec5a32d6ad96a18ef08c7f1b11
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 11:24:41 2014 -0700
Use consistent naming for SSLSocket arguments
This changes all the 'host' to be 'hostname' and anything that takes an
'InetAddress' will have the name of 'address' to avoid confusing it with
a hostname.
Bug: 16658420
Bug: 17059757
Change-Id: Iac0628d2d156023dbb80c2e636af6bfe63f46650
commit e9cf759ac89fb053c01f1db19931beb14a823618
Merge: ababdd1 7ed0fae
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 19 19:32:43 2014 +0000
am 7ed0fae1: OpenSSLEngineImpl: reduce number of copies needed
* commit '7ed0fae1906061766d0042e69ccba20e4a702bbe':
OpenSSLEngineImpl: reduce number of copies needed
commit 7ed0fae1906061766d0042e69ccba20e4a702bbe
Author: Kenny Root <kroot@google.com>
Date:   Tue Jul 22 13:03:09 2014 -0700
OpenSSLEngineImpl: reduce number of copies needed
When the ByteBuffer didn't line up exactly with the backing array, it
would allocate a new buffer to write into. Instead, add the ability for
OpenSSL to read at an offset in the given array so a copy isn't needed.
Change-Id: I149d3f94e4b5cbdc010df80439ae3300cbdc87a5
commit ababdd1ae1272eac174e3a449a413ab35afbc435
Merge: 66c31e0 4b050b6
Author: Kenny Root <kroot@google.com>
Date:   Fri Aug 15 16:23:14 2014 +0000
am 4b050b6f: OpenSSLSocketImpl: Move state checks inside mutex
* commit '4b050b6fb06fbb804557eecc72cc4ff0e0277525':
OpenSSLSocketImpl: Move state checks inside mutex
commit 66c31e0b613ceefc167a2e1fb226a14c78f84537
Merge: f4b895a 0931d51
Author: Kenny Root <kroot@google.com>
Date:   Thu Aug 14 20:46:43 2014 +0000
am 0931d51c: OpenSSLSocketImpl: Move state checks inside mutex
* commit '0931d51c58b2dc2f612298f99fbf0fa6ed4c3706':
OpenSSLSocketImpl: Move state checks inside mutex
commit 0931d51c58b2dc2f612298f99fbf0fa6ed4c3706
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 15:45:32 2014 -0700
OpenSSLSocketImpl: Move state checks inside mutex
Checking the state of the connection is unreliable if SSL_read and
SSL_write are happening in another thread. Move the state checks inside
our application mutex so we don't run into another thread mutating the
state at the same time.
Bug: 15606096
Change-Id: I5ecdeb1551a13098d1b66c5e4009607c9951fa38
commit f4b895ae9c424b5c2d49c744131606adccbc49d7
Merge: a35c400 a260ee6
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 13 15:35:28 2014 +0000
am a260ee6d: Revert ""Revert ""Automatic management of OpenSSL error stack""""
* commit 'a260ee6d0caea43f8010f158a4a35fb712935ae3':
Revert ""Revert ""Automatic management of OpenSSL error stack""""
commit a35c40017c8690f821351d6460dfeaa2738b884c
Merge: 0edc483 30550a8
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 13 15:35:27 2014 +0000
am 30550a8b: Fix debugging with unbundled conscrypt
* commit '30550a8b64bbcd6ca537680a17b8726932a29937':
Fix debugging with unbundled conscrypt
commit a260ee6d0caea43f8010f158a4a35fb712935ae3
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:38:10 2014 -0700
Revert ""Revert ""Automatic management of OpenSSL error stack""""
The ""else"" statement in OpenSslError::reset wasn't properly resetting
the error state which made a second call into sslRead jump into
sslSelect when it should have just returned immediately.
Change-Id: I22e8025c0497a04e78daa07cef78191a6ca1a70c
commit 30550a8b64bbcd6ca537680a17b8726932a29937
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:13:33 2014 -0700
Fix debugging with unbundled conscrypt
When JNI_TRACE was enabled, there were missing defines for the debugging
code since no platform code is included.
Also clang complains about more of the debugging statement formats, so
we have to move some things around to get it to be happy.
Change-Id: I1a6695c2ef2639cc01cfc3d3a8603f010c659844
commit 0edc4833091846d6cb45961fc9458df842fbbad9
Merge: 107a8fb 2411b8b
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:46:12 2014 +0000
am 2411b8bd: Merge ""Revert ""Automatic management of OpenSSL error stack""""
* commit '2411b8bdcde72c956f4150e9a5909b7501f50bad':
Revert ""Automatic management of OpenSSL error stack""
commit 2411b8bdcde72c956f4150e9a5909b7501f50bad
Merge: 3262a8c b514d72
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:39:32 2014 +0000
Merge ""Revert ""Automatic management of OpenSSL error stack""""
commit b514d72b93c3996d97e38eca6db1ad684965fd9b
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:39:17 2014 +0000
Revert ""Automatic management of OpenSSL error stack""
This reverts commit 35666e4cb0fcd063a21d17eebbb571b4e4e822b8.
Change-Id: I926d159c4c4b99250caef750732976c1e601e9ef
commit 107a8fba8be5be57933f2638b76ac1243b578b9e
Merge: 1de007f 3262a8c
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:50:14 2014 +0000
am 3262a8c2: Merge ""Automatic management of OpenSSL error stack""
* commit '3262a8c2741b95103149bcdefe2409c24bfddee9':
Automatic management of OpenSSL error stack
commit 1de007f9f01be8f07a56235dd924c897088a03cb
Merge: 94890ae d1bbcd0
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:50:14 2014 +0000
am d1bbcd0e: Relax checks for key vs cert for wrapped keys
* commit 'd1bbcd0ec973e1b8465c204c13b4925fd86e6484':
Relax checks for key vs cert for wrapped keys
commit 3262a8c2741b95103149bcdefe2409c24bfddee9
Merge: d1bbcd0 35666e4
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:31:02 2014 +0000
Merge ""Automatic management of OpenSSL error stack""
commit d1bbcd0ec973e1b8465c204c13b4925fd86e6484
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 11 14:56:58 2014 -0700
Relax checks for key vs cert for wrapped keys
If a key is a wrapped platform key, we must relax the check. The reason
is that we may not have the public values we need to pass the
EVP_PKEY_cmp checks that this does.
Change-Id: I7ab2be51b0968a9cf771edea01d33fe2367c8185
commit 35666e4cb0fcd063a21d17eebbb571b4e4e822b8
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 11:05:00 2014 -0700
Automatic management of OpenSSL error stack
This removes some complexity in remembering to free the OpenSSL error
stack. If you forget, the error will stick around until you make another
call.
Change-Id: I245a525dcc93077b2bf9909a14a0ef469a2daca4
commit 94890aec5735cde2ea5170fb76cd1b847ea66af8
Merge: 8360485 977f087
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 16:44:42 2014 +0000
am 977f0877: Fix some JNI_TRACE lines
* commit '977f08774c628b4640d5454cde050259856965f8':
Fix some JNI_TRACE lines
commit 977f08774c628b4640d5454cde050259856965f8
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 4 12:15:04 2014 -0700
Fix some JNI_TRACE lines
During debugging these would be enabled, but they were copy-pasta'd to
with the wrong args.
Change-Id: I23f39ff4807e3fa71f3220912aec3c99db6b9454
commit 83604854c5160304cafefc9bd40a72c5ee8506eb
Merge: 7db3524 1ffe43e
Author: Zoltan Szatmary-Ban <szatmz@google.com>
Date:   Thu Jul 31 13:28:57 2014 +0000
am 1ffe43e8: Merge ""Add possibility to get deleted system Certificate Aliases"" into lmp-dev
* commit '1ffe43e8277e883c6663c1fb7cfc5e18ba552c40':
Add possibility to get deleted system Certificate Aliases
commit 7db3524880092126962b7f502af76b4c84da7350
Merge: 5767d63 ad0cd83
Author: Prameet Shah <phshah@google.com>
Date:   Wed Jul 30 17:04:13 2014 +0000
am ad0cd830: Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
* commit 'ad0cd83024f38011043d28d70370a8638b88cd72':
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
commit 5767d63d22e87becab387b3bd6597fe41eb34d7e
Merge: b389e17 26163c2
Author: Prameet Shah <phshah@google.com>
Date:   Wed Jul 30 16:31:08 2014 +0000
am 26163c26: Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
* commit '26163c268a6d2625384b87e907afad8ef19f9a47':
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
commit 26163c268a6d2625384b87e907afad8ef19f9a47
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 29 16:45:31 2014 -0700
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
Bug: https://code.google.com/p/android/issues/detail?id=73745
Change-Id: I5bcaf3ee8910ff75e785baed4c4604fee6c5e700
commit b389e1779651f2c58454a5f98acebd3dd7bc0061
Merge: 5f03b4d e427972
Author: Prameet Shah <phshah@google.com>
Date:   Thu Jul 24 19:46:28 2014 +0000
am e427972e: OpenSSLEngineImpl: fix unwrap behavior with array
* commit 'e427972eb6141cd67e6d4c9607863a8d990e6be6':
OpenSSLEngineImpl: fix unwrap behavior with array
commit 5f03b4d63c7632581b032879de791dc82f05ffa0
Merge: 3d935ee 41eb5b6
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 22 19:26:41 2014 +0000
am 41eb5b65: OpenSSLEngineImpl: fix unwrap behavior with array
* commit '41eb5b65e524d01e28da474bd37e4349b12fb494':
OpenSSLEngineImpl: fix unwrap behavior with array
commit 41eb5b65e524d01e28da474bd37e4349b12fb494
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 22 11:50:18 2014 -0700
OpenSSLEngineImpl: fix unwrap behavior with array
The decrypted bytes should written sequentially into each buffer of
the destination array until it's full before moving to the next
buffer.
Change-Id: I2454249c167deafde6c12134d3c8cd658cd7c21b
commit 3d935eeca25e00b56cfd8d37a657c7b2986889b3
Merge: 0a36f6c affd45a
Author: Alex Klyubin <klyubin@google.com>
Date:   Fri Jul 18 00:32:14 2014 +0000
am affd45a4: Merge ""Improve the Javadoc of PSKKeyManager."" into lmp-dev
* commit 'affd45a413cf844dad797ad4972074efb9de43d8':
Improve the Javadoc of PSKKeyManager.
commit 0a36f6c1f8b2e195c2dd5aea1a386df090c6d470
Merge: 6492180 af4fa68
Author: rich cannings <richc@google.com>
Date:   Thu Jul 17 23:47:33 2014 +0000
am af4fa685: Merge ""Log CCS exceptions do not merge."" into lmp-dev
* commit 'af4fa685f246aaa80c93af62faadbc2fe87dc034':
Log CCS exceptions do not merge.
commit 6492180ce17a3b5ff822cff1783f00e7a4176491
Merge: aac4168 3b7268c
Author: Alex Klyubin <klyubin@google.com>
Date:   Thu Jul 17 18:27:39 2014 +0000
am 3b7268cd: Merge ""Improve the Javadoc of PSKKeyManager.""
* commit '3b7268cde4a4fc59591da8a93691927ebf3add57':
Improve the Javadoc of PSKKeyManager.
commit aac4168d8baef7e12d6fa959c6d6ded9892e9651
Merge: 8573ad0 a749c0d
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 17 17:07:05 2014 +0000
am a749c0d3: Keep enough state to completely reset cipher instances
* commit 'a749c0d351216be38879600ee8ed01c6793aa256':
Keep enough state to completely reset cipher instances
commit 8573ad0ddcf7e2f8b2e5ac84c34b7ffab303155c
Merge: 4ca5b06 70fdb6d
Author: Koushik Dutta <koushd@gmail.com>
Date:   Thu Jul 17 17:06:36 2014 +0000
am 70fdb6d2: OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
* commit '70fdb6d2bfa0c313fe389827f0025288f6aeb947':
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
commit 4ca5b0625e3f5a15ae8adf833ab5a69f9d7d517f
Merge: 119abfb ded66f5
Author: Koushik Dutta <koushd@gmail.com>
Date:   Thu Jul 17 17:06:35 2014 +0000
am ded66f5f: Various fixes in OpenSSLEngineImpl.
* commit 'ded66f5f696994ce7620552e16a4e9124e69e052':
Various fixes in OpenSSLEngineImpl.
commit 119abfba1fcd9c9cfbd15d0a4ca9ed2188fdfab0
Merge: 5713cdf cbe1f28
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 17 15:56:57 2014 +0000
am cbe1f28a: Merge ""Keep enough state to completely reset cipher instances""
* commit 'cbe1f28adf64396561a3b65bf1452dfa9b6e35ae':
Keep enough state to completely reset cipher instances
commit cbe1f28adf64396561a3b65bf1452dfa9b6e35ae
Merge: e08f238 084e308
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 17 15:48:58 2014 +0000
Merge ""Keep enough state to completely reset cipher instances""
commit 3b7268cde4a4fc59591da8a93691927ebf3add57
Merge: cbe1f28 7ac13e0
Author: Alex Klyubin <klyubin@google.com>
Date:   Thu Jul 17 18:20:43 2014 +0000
Merge ""Improve the Javadoc of PSKKeyManager.""
commit 5713cdf71c5c6e5179e8369263c702e9512afdd0
Merge: cf55719 e08f238
Author: Koushik Dutta <koushd@gmail.com>
Date:   Wed Jul 16 22:05:17 2014 +0000
am e08f2385: OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
* commit 'e08f238580e8ee471012bef8240c8d3397c7b780':
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
commit cf557195a9b60d7f51a48500afde38481ddbc91c
Merge: cbbd7d1 986aeb7
Author: Kenny Root <kroot@android.com>
Date:   Wed Jul 16 21:41:12 2014 +0000
am 986aeb78: Merge ""Various fixes in OpenSSLEngineImpl.""
* commit '986aeb78e533540463daf1753e24840f75b25ce6':
Various fixes in OpenSSLEngineImpl.
commit e08f238580e8ee471012bef8240c8d3397c7b780
Author: Koushik Dutta <koushd@gmail.com>
Date:   Tue Jul 15 22:40:23 2014 -0700
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
Change-Id: Idc78204b7077fb367b64e1867c807cd39f596f98
commit 7ac13e03a79d0c99d181b1a28b1b3699ba3d5739
Author: Alex Klyubin <klyubin@google.com>
Date:   Wed Jul 16 08:33:02 2014 -0700
Improve the Javadoc of PSKKeyManager.
This clarifies several points and adds sample code.
Bug: 15073623
Change-Id: I6e8aadc52277e238a998d6cee36795dab1151d58
commit 986aeb78e533540463daf1753e24840f75b25ce6
Merge: 8f9ac1a bdfcc18
Author: Kenny Root <kroot@android.com>
Date:   Wed Jul 16 21:15:30 2014 +0000
Merge ""Various fixes in OpenSSLEngineImpl.""
commit bdfcc189efe41a3f812aeb55ea634bace67d159a
Author: Koushik Dutta <koushd@gmail.com>
Date:   Sat Jun 28 19:19:21 2014 -0700
Various fixes in OpenSSLEngineImpl.
Fix ""Buffers were not large enough"" exception by directly using the
destination buffers.
Corrections around bytesProduced and bytesConsumed behavior.
Return BUFFER_OVERFLOW if a zero length destination is provided to
unwrap.
Change-Id: I1f1e9b72cd6968ed4f3c3c0edccbccebc33d6790
commit cbbd7d10e8e484c44a78e5b27e8fecda195f1692
Merge: ec7f8e6 fdb7d8c
Author: Alex Klyubin <klyubin@google.com>
Date:   Tue Jul 15 18:49:14 2014 +0000
am fdb7d8c5: Enable PSK cipher suites when PSKKeyManager is provided.
* commit 'fdb7d8c53dabac5551e2499d045ba6829bcfc0a0':
Enable PSK cipher suites when PSKKeyManager is provided.
commit ec7f8e6b27330160f88540f4f2ace7bc2a0720a3
Merge: 5b8ccf1 8f9ac1a
Author: Alex Klyubin <klyubin@google.com>
Date:   Tue Jul 15 15:53:46 2014 +0000
am 8f9ac1af: Enable PSK cipher suites when PSKKeyManager is provided.
* commit '8f9ac1af0cbdf00e5e47aee32c132522ebc3bd17':
Enable PSK cipher suites when PSKKeyManager is provided.
commit 5b8ccf1b09df6f35c1709bfc8fd727a291094a5b
Merge: 69a2e46 6e2315f
Author: Ed Heyl <edheyl@google.com>
Date:   Tue Jul 15 13:34:25 2014 +0000
am 6e2315fd: reconcile aosp (e79c25bf33e10da41e489c537823f678e1a1169c) after branching. Please do not merge.
* commit '6e2315fd96c3c4a47450c1a437babacc94bc31a6':
reconcile aosp (e79c25bf33e10da41e489c537823f678e1a1169c) after branching. Please do not merge.
commit 084e3086be1d7a6b9280b64c7c8cdb7b41a13bea
Author: Kenny Root <kroot@google.com>
Date:   Mon Jul 14 13:25:32 2014 -0700
Keep enough state to completely reset cipher instances
OpenSSL's RC4 mutates the given key. AES/CTR mutates the IV. We must
store these values locally to enable ""doFinal"" to cause the Cipher
instance to be reset to what it was right after ""init"".
Note that resetting and encrypting with the same key or IV breaks
semantic security.
Bug: 16298401
Bug: https://code.google.com/p/android/issues/detail?id=73339
Change-Id: Ie7e4dcb6cf6cc33ddad31d6b47066dc1b34e6894
commit 69a2e460cc0a40e1b951e400589b9932609079ec
Merge: 8b7bb32 bca895f
Author: David Benjamin <davidben@chromium.org>
Date:   Mon Jul 14 18:17:28 2014 +0000
am bca895f8: Pass output buffer length into EVP_DigestSignFinal.
* commit 'bca895f809dd2cef7a0834f0bfeb2a06e42b277d':
Pass output buffer length into EVP_DigestSignFinal.
commit 8b7bb32af09a01e80442b70dd23e6997a937f103
Merge: a2404c9 e79c25b
Author: Kenny Root <kroot@google.com>
Date:   Mon Jul 14 18:17:28 2014 +0000
am e79c25bf: Merge ""DHKeyPairGenerator: use provided params""
* commit 'e79c25bf33e10da41e489c537823f678e1a1169c':
DHKeyPairGenerator: use provided params
commit 8f9ac1af0cbdf00e5e47aee32c132522ebc3bd17
Author: Alex Klyubin <klyubin@google.com>
Date:   Thu Jun 19 13:37:24 2014 -0700
Enable PSK cipher suites when PSKKeyManager is provided.
This enables TLS-PSK cipher suites by default iff SSLContext is
initialized with a PSKKeyManager. For consistency, X.509 based
cipher suites are no longer enabled by default at all times -- they
are now only enabled by default iff SSLContext is initialized with a
X509KeyManager or a X509TrustManager.
When both X.509 and PSK cipher suites need to be enabled, PSK cipher
suites are given higher priority in the resulting list of cipher
suites. This is based on the assumption that in most cases users of
TLS/SSL who enable TLS-PSK would prefer TLS-PSK to be used when the
peer supports TLS-PSK.
Bug: 15073623
Change-Id: I8e2bc3e7a1ea8a986e468973b6bad19dc6b7bc3c
commit bca895f809dd2cef7a0834f0bfeb2a06e42b277d
Author: David Benjamin <davidben@chromium.org>
Date:   Thu Jul 10 18:12:08 2014 -0400
Pass output buffer length into EVP_DigestSignFinal.
EVP_DigestSignFinal expects the input buffer length as *siglen on input. In
addition, if sigret is NULL, it returns the buffer size needed. Use this rather
than making assumptions about the EVP_PKEY used to initialize the EVP_MD_CTX.
commit e79c25bf33e10da41e489c537823f678e1a1169c
Merge: a328492 9b226f9
Author: Kenny Root <kroot@google.com>
Date:   Fri Jul 11 16:46:23 2014 +0000
Merge ""DHKeyPairGenerator: use provided params""
commit 9b226f90a992a4a2267b7a813e3b869851945c4d
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 10 14:50:48 2014 -0700
DHKeyPairGenerator: use provided params
If the prime is provided in the DHParam"
conscrypt,"Fix OpenSSLSocketImpl.getPort when SNI is used.
We were using a non-null hostname as a hint that the socket was
constructed with an explicit host and port. This is no longer true
because the hostname can be non-null when SNI is used (i.e setHostname
is called with a non-null hostname).
bug: 18428603
(cherry picked from commit 131640979c0ba3f18581cee9bf5c925ec8a7372b)
Change-Id: I5a76a17259e4f50a0b8a29b37a647265a755e326/am 1afaf2bb: am 13164097: Fix OpenSSLSocketImpl.getPort when SNI is used.
* commit '1afaf2bb33a3451c16d7d9e820afbc031229a7ea':
Fix OpenSSLSocketImpl.getPort when SNI is used./am 13164097: Fix OpenSSLSocketImpl.getPort when SNI is used.
* commit '131640979c0ba3f18581cee9bf5c925ec8a7372b':
Fix OpenSSLSocketImpl.getPort when SNI is used./Fix OpenSSLSocketImpl.getPort when SNI is used.
We were using a non-null hostname as a hint that the socket was
constructed with an explicit host and port. This is no longer true
because the hostname can be non-null when SNI is used (i.e setHostname
is called with a non-null hostname).
bug: 18428603
Change-Id: I1dba81f7853e6871989e114dc77f3956621c77fa/Squashed commit of changes from lmp-ub-dev
Contains the following changes:
commit e31d982cdb0f8e6ef05d1e412576888015e1da17
Merge: eaebc54 b73be72
Author: Neil Fuller <nfuller@google.com>
Date:   Wed Oct 22 10:34:23 2014 +0000
am b73be72e: am 3e21a289: (-s ours) TLS_FALLBACK_SCSV CTS fix for klp-modular-dev
* commit 'b73be72ed97da8f36450d95d52f485cc6f451c61':
TLS_FALLBACK_SCSV CTS fix for klp-modular-dev
commit eaebc544f3a10c53d7d2f908514122caba569e14
Merge: 223b5da cd50afa
Author: Kenny Root <kroot@google.com>
Date:   Tue Oct 14 17:30:19 2014 +0000
Merge ""Fix SSLEngine to support session resumption."" into lmp-ub-dev
commit 223b5da5d70e47b1a497e86474493925b568f6d7
Merge: 8737796 cb7a360
Author: Neil Fuller <nfuller@google.com>
Date:   Thu Oct 9 14:52:00 2014 +0000
am cb7a3605: am ea961ada: Apply conscrypt changes from merge commit
* commit 'cb7a36050f34d3c16be00d532411820761eeb276':
Apply conscrypt changes from merge commit
commit cd50afad1567b1311e6e979e94a7167b7bf69c94
Author: Doug Steedman <dougsteed@google.com>
Date:   Mon Oct 6 13:16:15 2014 -0700
Fix SSLEngine to support session resumption.
Bug: 17877118
Change-Id: I388b59cde58fdc506ecac9f536e4bbd9161df6ad
commit 8737796a646eaec94df32827752a71aee74bd46f
Merge: 9564a5f 8d7e23e
Author: Kenny Root <kroot@google.com>
Date:   Mon Oct 6 22:34:20 2014 +0000
am 8d7e23e1: Add support for TLS_FALLBACK_SCSV
* commit '8d7e23e117da591a8d48e6bcda9ed6f58ff1a375':
Add support for TLS_FALLBACK_SCSV
commit 9564a5fb9ed2eecf6299788db35213cb08397212
Merge: 4f58feb 7640613
Author: Kenny Root <kroot@google.com>
Date:   Fri Sep 12 17:27:23 2014 +0000
am 76406135: am 6dcb23fe: am f427ec90: Fix the ENGINE_finish/ENGINE_free mixup
* commit '76406135cf3a3b88afc979fe8e847b9c3d8b93c1':
Fix the ENGINE_finish/ENGINE_free mixup
commit 4f58feb0ea49dc089a95efba196032ef3c960a39
Merge: ddac5c6 984b7ec
Author: Kenny Root <kroot@google.com>
Date:   Wed Sep 10 07:07:16 2014 +0000
am 984b7ec6: Fix the ENGINE_finish/ENGINE_free mixup
* commit '984b7ec6f5aab314117949a48e448ff4f6b65f16':
Fix the ENGINE_finish/ENGINE_free mixup
commit ddac5c6d7e413b0d68b388fbdf70dbeb3eeae865
Merge: 5a8ca5b 36ba60b
Author: Kenny Root <kroot@google.com>
Date:   Thu Sep 4 22:41:38 2014 +0000
Merge ""Reset lmp-ub-dev to lmp-dev-plus-aosp"" into lmp-ub-dev
commit 36ba60b039f1f30ab1ea8f0e2a4da8ae4e3906e5
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 27 12:07:07 2014 -0700
Reset lmp-ub-dev to lmp-dev-plus-aosp
Bug: 17059757
Change-Id: I581963360da47b574e1e2e20c2851485c36fa62c
commit 6a4f2ef9e4ea3ebb321d45ca39b30d634ea3b4ad
Merge: 9b187af f67d784
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:17:38 2014 +0000
am f67d784a: Add pre-Honeycomb literal IP matching
* commit 'f67d784abe5cef700240be02c68cecd899cd8e6d':
Add pre-Honeycomb literal IP matching
commit 9b187af33dcd97915a0371d64fe1ee4aba20d0ba
Merge: 714ebea 966ae8a
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:17:37 2014 +0000
am 966ae8a6: Read property to enable SNI
* commit '966ae8a6e12f3235b1cb041e687bda11b41fe4eb':
Read property to enable SNI
commit 714ebeabcb5e35c6df6a5c21f549cdb6130368c4
Merge: 7724204 54a1ba4
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 04:06:54 2014 +0000
Merge ""resolved conflicts for merge of 342097db to lmp-dev-plus-aosp"" into lmp-dev-plus-aosp
commit 54a1ba421d23bb6d988688c2662715e509172447
Merge: a20d871 342097d
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 21:03:51 2014 -0700
resolved conflicts for merge of 342097db to lmp-dev-plus-aosp
Change-Id: I853c6b0d3725dafbdc84c4d6d6d1b90529bd949d
commit 7724204abf4431d35787c44c4a22cda5489d4e37
Merge: 20f60ac afb3403
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 26 00:09:27 2014 +0000
am afb34034: Implement write socket timeouts for unbundled apps
* commit 'afb340348bfc54dbc46964e159fe803f9c93a4dd':
Implement write socket timeouts for unbundled apps
commit f67d784abe5cef700240be02c68cecd899cd8e6d
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 14:14:26 2014 -0700
Add pre-Honeycomb literal IP matching
This will allow us to run this code on Gingerbread devices and others
that don't have the InetAddress#isNumeric API.
Bug: 16658420
Bug: 17059757
Change-Id: I597d539979d58eeaa2677d6f99e911313a550cc1
commit 966ae8a6e12f3235b1cb041e687bda11b41fe4eb
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 18 10:12:20 2014 -0700
Read property to enable SNI
Read the system property ""jsse.enableSNIExtension"" on whether to enable
Server Name Indication (SNI) extension. For unbundled builds, this will
be enabled by default. For platform builds, this will be disabled by
default.
Bug: 16658420
Bug: 17059757
Change-Id: I774f5406bf3fe601a42c4ef5e708b31800147eb9
commit 342097db97a9b2736531033b2c4b4d8ce4998c67
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 12:14:52 2014 -0700
Validate hostname is usable for SNI
According to RFC 6066 section 3, the hostname listed in the Server Name
Indication (SNI) field is a fully qualified domain name and IP
addresses are not permitted.
Bug: 16658420
Bug: 17059757
Change-Id: I804e46b6e66599b2770f0f4f0534467987e51208
commit afb340348bfc54dbc46964e159fe803f9c93a4dd
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 19 16:33:07 2014 -0700
Implement write socket timeouts for unbundled apps
Change-Id: I4fd604f057ba4288d4f31bf6b3b93307376023d5
commit 20f60acea153dfdf0c8f75a53d7bd9edb4c7614c
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 11:52:05 2014 -0700
Tracking change from AOSP
Change-Id: I889af3f7c1de9ef34d9328339e1b421651055ad4
commit 68056b7c9db8a9fb384bbadfc5287730f996896d
Merge: 8239dfd cc2ef2e
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 25 18:03:27 2014 +0000
am cc2ef2e2: Rename hostname fields and methods to reflect usage
* commit 'cc2ef2e2e9ee64f2e0ac2abc7fdf636e2f81fa5e':
Rename hostname fields and methods to reflect usage
commit 8239dfdcc40a69255d7b2feced960d574ea36321
Merge: e9cf759 076138f
Author: Kenny Root <kroot@google.com>
Date:   Thu Aug 21 16:36:24 2014 +0000
am 076138ff: Use consistent naming for SSLSocket arguments
* commit '076138ff29d805ec5a32d6ad96a18ef08c7f1b11':
Use consistent naming for SSLSocket arguments
commit cc2ef2e2e9ee64f2e0ac2abc7fdf636e2f81fa5e
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 11:26:33 2014 -0700
Rename hostname fields and methods to reflect usage
The hostname that was supplied when the socket was created is stored as
the ""peerHostname""  This is the only one that should be used for Server
Name Indication (SNI) purposes.
The ""peerHostname"" or the resolved IP address may be used for
certificate validation, so keep the use of ""getHostname()"" for
cerificate validation.
Bug: 16658420
Bug: 17059757
Change-Id: Ifd87dead44fb2f00bbfd5eac7e69fb3fc98e94b4
commit 076138ff29d805ec5a32d6ad96a18ef08c7f1b11
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 20 11:24:41 2014 -0700
Use consistent naming for SSLSocket arguments
This changes all the 'host' to be 'hostname' and anything that takes an
'InetAddress' will have the name of 'address' to avoid confusing it with
a hostname.
Bug: 16658420
Bug: 17059757
Change-Id: Iac0628d2d156023dbb80c2e636af6bfe63f46650
commit e9cf759ac89fb053c01f1db19931beb14a823618
Merge: ababdd1 7ed0fae
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 19 19:32:43 2014 +0000
am 7ed0fae1: OpenSSLEngineImpl: reduce number of copies needed
* commit '7ed0fae1906061766d0042e69ccba20e4a702bbe':
OpenSSLEngineImpl: reduce number of copies needed
commit 7ed0fae1906061766d0042e69ccba20e4a702bbe
Author: Kenny Root <kroot@google.com>
Date:   Tue Jul 22 13:03:09 2014 -0700
OpenSSLEngineImpl: reduce number of copies needed
When the ByteBuffer didn't line up exactly with the backing array, it
would allocate a new buffer to write into. Instead, add the ability for
OpenSSL to read at an offset in the given array so a copy isn't needed.
Change-Id: I149d3f94e4b5cbdc010df80439ae3300cbdc87a5
commit ababdd1ae1272eac174e3a449a413ab35afbc435
Merge: 66c31e0 4b050b6
Author: Kenny Root <kroot@google.com>
Date:   Fri Aug 15 16:23:14 2014 +0000
am 4b050b6f: OpenSSLSocketImpl: Move state checks inside mutex
* commit '4b050b6fb06fbb804557eecc72cc4ff0e0277525':
OpenSSLSocketImpl: Move state checks inside mutex
commit 66c31e0b613ceefc167a2e1fb226a14c78f84537
Merge: f4b895a 0931d51
Author: Kenny Root <kroot@google.com>
Date:   Thu Aug 14 20:46:43 2014 +0000
am 0931d51c: OpenSSLSocketImpl: Move state checks inside mutex
* commit '0931d51c58b2dc2f612298f99fbf0fa6ed4c3706':
OpenSSLSocketImpl: Move state checks inside mutex
commit 0931d51c58b2dc2f612298f99fbf0fa6ed4c3706
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 15:45:32 2014 -0700
OpenSSLSocketImpl: Move state checks inside mutex
Checking the state of the connection is unreliable if SSL_read and
SSL_write are happening in another thread. Move the state checks inside
our application mutex so we don't run into another thread mutating the
state at the same time.
Bug: 15606096
Change-Id: I5ecdeb1551a13098d1b66c5e4009607c9951fa38
commit f4b895ae9c424b5c2d49c744131606adccbc49d7
Merge: a35c400 a260ee6
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 13 15:35:28 2014 +0000
am a260ee6d: Revert ""Revert ""Automatic management of OpenSSL error stack""""
* commit 'a260ee6d0caea43f8010f158a4a35fb712935ae3':
Revert ""Revert ""Automatic management of OpenSSL error stack""""
commit a35c40017c8690f821351d6460dfeaa2738b884c
Merge: 0edc483 30550a8
Author: Kenny Root <kroot@google.com>
Date:   Wed Aug 13 15:35:27 2014 +0000
am 30550a8b: Fix debugging with unbundled conscrypt
* commit '30550a8b64bbcd6ca537680a17b8726932a29937':
Fix debugging with unbundled conscrypt
commit a260ee6d0caea43f8010f158a4a35fb712935ae3
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:38:10 2014 -0700
Revert ""Revert ""Automatic management of OpenSSL error stack""""
The ""else"" statement in OpenSslError::reset wasn't properly resetting
the error state which made a second call into sslRead jump into
sslSelect when it should have just returned immediately.
Change-Id: I22e8025c0497a04e78daa07cef78191a6ca1a70c
commit 30550a8b64bbcd6ca537680a17b8726932a29937
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:13:33 2014 -0700
Fix debugging with unbundled conscrypt
When JNI_TRACE was enabled, there were missing defines for the debugging
code since no platform code is included.
Also clang complains about more of the debugging statement formats, so
we have to move some things around to get it to be happy.
Change-Id: I1a6695c2ef2639cc01cfc3d3a8603f010c659844
commit 0edc4833091846d6cb45961fc9458df842fbbad9
Merge: 107a8fb 2411b8b
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:46:12 2014 +0000
am 2411b8bd: Merge ""Revert ""Automatic management of OpenSSL error stack""""
* commit '2411b8bdcde72c956f4150e9a5909b7501f50bad':
Revert ""Automatic management of OpenSSL error stack""
commit 2411b8bdcde72c956f4150e9a5909b7501f50bad
Merge: 3262a8c b514d72
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:39:32 2014 +0000
Merge ""Revert ""Automatic management of OpenSSL error stack""""
commit b514d72b93c3996d97e38eca6db1ad684965fd9b
Author: Kenny Root <kroot@android.com>
Date:   Tue Aug 12 21:39:17 2014 +0000
Revert ""Automatic management of OpenSSL error stack""
This reverts commit 35666e4cb0fcd063a21d17eebbb571b4e4e822b8.
Change-Id: I926d159c4c4b99250caef750732976c1e601e9ef
commit 107a8fba8be5be57933f2638b76ac1243b578b9e
Merge: 1de007f 3262a8c
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:50:14 2014 +0000
am 3262a8c2: Merge ""Automatic management of OpenSSL error stack""
* commit '3262a8c2741b95103149bcdefe2409c24bfddee9':
Automatic management of OpenSSL error stack
commit 1de007f9f01be8f07a56235dd924c897088a03cb
Merge: 94890ae d1bbcd0
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:50:14 2014 +0000
am d1bbcd0e: Relax checks for key vs cert for wrapped keys
* commit 'd1bbcd0ec973e1b8465c204c13b4925fd86e6484':
Relax checks for key vs cert for wrapped keys
commit 3262a8c2741b95103149bcdefe2409c24bfddee9
Merge: d1bbcd0 35666e4
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 12 15:31:02 2014 +0000
Merge ""Automatic management of OpenSSL error stack""
commit d1bbcd0ec973e1b8465c204c13b4925fd86e6484
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 11 14:56:58 2014 -0700
Relax checks for key vs cert for wrapped keys
If a key is a wrapped platform key, we must relax the check. The reason
is that we may not have the public values we need to pass the
EVP_PKEY_cmp checks that this does.
Change-Id: I7ab2be51b0968a9cf771edea01d33fe2367c8185
commit 35666e4cb0fcd063a21d17eebbb571b4e4e822b8
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 11:05:00 2014 -0700
Automatic management of OpenSSL error stack
This removes some complexity in remembering to free the OpenSSL error
stack. If you forget, the error will stick around until you make another
call.
Change-Id: I245a525dcc93077b2bf9909a14a0ef469a2daca4
commit 94890aec5735cde2ea5170fb76cd1b847ea66af8
Merge: 8360485 977f087
Author: Kenny Root <kroot@google.com>
Date:   Tue Aug 5 16:44:42 2014 +0000
am 977f0877: Fix some JNI_TRACE lines
* commit '977f08774c628b4640d5454cde050259856965f8':
Fix some JNI_TRACE lines
commit 977f08774c628b4640d5454cde050259856965f8
Author: Kenny Root <kroot@google.com>
Date:   Mon Aug 4 12:15:04 2014 -0700
Fix some JNI_TRACE lines
During debugging these would be enabled, but they were copy-pasta'd to
with the wrong args.
Change-Id: I23f39ff4807e3fa71f3220912aec3c99db6b9454
commit 83604854c5160304cafefc9bd40a72c5ee8506eb
Merge: 7db3524 1ffe43e
Author: Zoltan Szatmary-Ban <szatmz@google.com>
Date:   Thu Jul 31 13:28:57 2014 +0000
am 1ffe43e8: Merge ""Add possibility to get deleted system Certificate Aliases"" into lmp-dev
* commit '1ffe43e8277e883c6663c1fb7cfc5e18ba552c40':
Add possibility to get deleted system Certificate Aliases
commit 7db3524880092126962b7f502af76b4c84da7350
Merge: 5767d63 ad0cd83
Author: Prameet Shah <phshah@google.com>
Date:   Wed Jul 30 17:04:13 2014 +0000
am ad0cd830: Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
* commit 'ad0cd83024f38011043d28d70370a8638b88cd72':
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
commit 5767d63d22e87becab387b3bd6597fe41eb34d7e
Merge: b389e17 26163c2
Author: Prameet Shah <phshah@google.com>
Date:   Wed Jul 30 16:31:08 2014 +0000
am 26163c26: Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
* commit '26163c268a6d2625384b87e907afad8ef19f9a47':
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
commit 26163c268a6d2625384b87e907afad8ef19f9a47
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 29 16:45:31 2014 -0700
Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()
Bug: https://code.google.com/p/android/issues/detail?id=73745
Change-Id: I5bcaf3ee8910ff75e785baed4c4604fee6c5e700
commit b389e1779651f2c58454a5f98acebd3dd7bc0061
Merge: 5f03b4d e427972
Author: Prameet Shah <phshah@google.com>
Date:   Thu Jul 24 19:46:28 2014 +0000
am e427972e: OpenSSLEngineImpl: fix unwrap behavior with array
* commit 'e427972eb6141cd67e6d4c9607863a8d990e6be6':
OpenSSLEngineImpl: fix unwrap behavior with array
commit 5f03b4d63c7632581b032879de791dc82f05ffa0
Merge: 3d935ee 41eb5b6
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 22 19:26:41 2014 +0000
am 41eb5b65: OpenSSLEngineImpl: fix unwrap behavior with array
* commit '41eb5b65e524d01e28da474bd37e4349b12fb494':
OpenSSLEngineImpl: fix unwrap behavior with array
commit 41eb5b65e524d01e28da474bd37e4349b12fb494
Author: Prameet Shah <phshah@google.com>
Date:   Tue Jul 22 11:50:18 2014 -0700
OpenSSLEngineImpl: fix unwrap behavior with array
The decrypted bytes should written sequentially into each buffer of
the destination array until it's full before moving to the next
buffer.
Change-Id: I2454249c167deafde6c12134d3c8cd658cd7c21b
commit 3d935eeca25e00b56cfd8d37a657c7b2986889b3
Merge: 0a36f6c affd45a
Author: Alex Klyubin <klyubin@google.com>
Date:   Fri Jul 18 00:32:14 2014 +0000
am affd45a4: Merge ""Improve the Javadoc of PSKKeyManager."" into lmp-dev
* commit 'affd45a413cf844dad797ad4972074efb9de43d8':
Improve the Javadoc of PSKKeyManager.
commit 0a36f6c1f8b2e195c2dd5aea1a386df090c6d470
Merge: 6492180 af4fa68
Author: rich cannings <richc@google.com>
Date:   Thu Jul 17 23:47:33 2014 +0000
am af4fa685: Merge ""Log CCS exceptions do not merge."" into lmp-dev
* commit 'af4fa685f246aaa80c93af62faadbc2fe87dc034':
Log CCS exceptions do not merge.
commit 6492180ce17a3b5ff822cff1783f00e7a4176491
Merge: aac4168 3b7268c
Author: Alex Klyubin <klyubin@google.com>
Date:   Thu Jul 17 18:27:39 2014 +0000
am 3b7268cd: Merge ""Improve the Javadoc of PSKKeyManager.""
* commit '3b7268cde4a4fc59591da8a93691927ebf3add57':
Improve the Javadoc of PSKKeyManager.
commit aac4168d8baef7e12d6fa959c6d6ded9892e9651
Merge: 8573ad0 a749c0d
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 17 17:07:05 2014 +0000
am a749c0d3: Keep enough state to completely reset cipher instances
* commit 'a749c0d351216be38879600ee8ed01c6793aa256':
Keep enough state to completely reset cipher instances
commit 8573ad0ddcf7e2f8b2e5ac84c34b7ffab303155c
Merge: 4ca5b06 70fdb6d
Author: Koushik Dutta <koushd@gmail.com>
Date:   Thu Jul 17 17:06:36 2014 +0000
am 70fdb6d2: OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
* commit '70fdb6d2bfa0c313fe389827f0025288f6aeb947':
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
commit 4ca5b0625e3f5a15ae8adf833ab5a69f9d7d517f
Merge: 119abfb ded66f5
Author: Koushik Dutta <koushd@gmail.com>
Date:   Thu Jul 17 17:06:35 2014 +0000
am ded66f5f: Various fixes in OpenSSLEngineImpl.
* commit 'ded66f5f696994ce7620552e16a4e9124e69e052':
Various fixes in OpenSSLEngineImpl.
commit 119abfba1fcd9c9cfbd15d0a4ca9ed2188fdfab0
Merge: 5713cdf cbe1f28
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 17 15:56:57 2014 +0000
am cbe1f28a: Merge ""Keep enough state to completely reset cipher instances""
* commit 'cbe1f28adf64396561a3b65bf1452dfa9b6e35ae':
Keep enough state to completely reset cipher instances
commit cbe1f28adf64396561a3b65bf1452dfa9b6e35ae
Merge: e08f238 084e308
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 17 15:48:58 2014 +0000
Merge ""Keep enough state to completely reset cipher instances""
commit 3b7268cde4a4fc59591da8a93691927ebf3add57
Merge: cbe1f28 7ac13e0
Author: Alex Klyubin <klyubin@google.com>
Date:   Thu Jul 17 18:20:43 2014 +0000
Merge ""Improve the Javadoc of PSKKeyManager.""
commit 5713cdf71c5c6e5179e8369263c702e9512afdd0
Merge: cf55719 e08f238
Author: Koushik Dutta <koushd@gmail.com>
Date:   Wed Jul 16 22:05:17 2014 +0000
am e08f2385: OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
* commit 'e08f238580e8ee471012bef8240c8d3397c7b780':
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
commit cf557195a9b60d7f51a48500afde38481ddbc91c
Merge: cbbd7d1 986aeb7
Author: Kenny Root <kroot@android.com>
Date:   Wed Jul 16 21:41:12 2014 +0000
am 986aeb78: Merge ""Various fixes in OpenSSLEngineImpl.""
* commit '986aeb78e533540463daf1753e24840f75b25ce6':
Various fixes in OpenSSLEngineImpl.
commit e08f238580e8ee471012bef8240c8d3397c7b780
Author: Koushik Dutta <koushd@gmail.com>
Date:   Tue Jul 15 22:40:23 2014 -0700
OpenSSLEngine Impl: Fix bug where SSL Handshake never completes when using NPN.
Change-Id: Idc78204b7077fb367b64e1867c807cd39f596f98
commit 7ac13e03a79d0c99d181b1a28b1b3699ba3d5739
Author: Alex Klyubin <klyubin@google.com>
Date:   Wed Jul 16 08:33:02 2014 -0700
Improve the Javadoc of PSKKeyManager.
This clarifies several points and adds sample code.
Bug: 15073623
Change-Id: I6e8aadc52277e238a998d6cee36795dab1151d58
commit 986aeb78e533540463daf1753e24840f75b25ce6
Merge: 8f9ac1a bdfcc18
Author: Kenny Root <kroot@android.com>
Date:   Wed Jul 16 21:15:30 2014 +0000
Merge ""Various fixes in OpenSSLEngineImpl.""
commit bdfcc189efe41a3f812aeb55ea634bace67d159a
Author: Koushik Dutta <koushd@gmail.com>
Date:   Sat Jun 28 19:19:21 2014 -0700
Various fixes in OpenSSLEngineImpl.
Fix ""Buffers were not large enough"" exception by directly using the
destination buffers.
Corrections around bytesProduced and bytesConsumed behavior.
Return BUFFER_OVERFLOW if a zero length destination is provided to
unwrap.
Change-Id: I1f1e9b72cd6968ed4f3c3c0edccbccebc33d6790
commit cbbd7d10e8e484c44a78e5b27e8fecda195f1692
Merge: ec7f8e6 fdb7d8c
Author: Alex Klyubin <klyubin@google.com>
Date:   Tue Jul 15 18:49:14 2014 +0000
am fdb7d8c5: Enable PSK cipher suites when PSKKeyManager is provided.
* commit 'fdb7d8c53dabac5551e2499d045ba6829bcfc0a0':
Enable PSK cipher suites when PSKKeyManager is provided.
commit ec7f8e6b27330160f88540f4f2ace7bc2a0720a3
Merge: 5b8ccf1 8f9ac1a
Author: Alex Klyubin <klyubin@google.com>
Date:   Tue Jul 15 15:53:46 2014 +0000
am 8f9ac1af: Enable PSK cipher suites when PSKKeyManager is provided.
* commit '8f9ac1af0cbdf00e5e47aee32c132522ebc3bd17':
Enable PSK cipher suites when PSKKeyManager is provided.
commit 5b8ccf1b09df6f35c1709bfc8fd727a291094a5b
Merge: 69a2e46 6e2315f
Author: Ed Heyl <edheyl@google.com>
Date:   Tue Jul 15 13:34:25 2014 +0000
am 6e2315fd: reconcile aosp (e79c25bf33e10da41e489c537823f678e1a1169c) after branching. Please do not merge.
* commit '6e2315fd96c3c4a47450c1a437babacc94bc31a6':
reconcile aosp (e79c25bf33e10da41e489c537823f678e1a1169c) after branching. Please do not merge.
commit 084e3086be1d7a6b9280b64c7c8cdb7b41a13bea
Author: Kenny Root <kroot@google.com>
Date:   Mon Jul 14 13:25:32 2014 -0700
Keep enough state to completely reset cipher instances
OpenSSL's RC4 mutates the given key. AES/CTR mutates the IV. We must
store these values locally to enable ""doFinal"" to cause the Cipher
instance to be reset to what it was right after ""init"".
Note that resetting and encrypting with the same key or IV breaks
semantic security.
Bug: 16298401
Bug: https://code.google.com/p/android/issues/detail?id=73339
Change-Id: Ie7e4dcb6cf6cc33ddad31d6b47066dc1b34e6894
commit 69a2e460cc0a40e1b951e400589b9932609079ec
Merge: 8b7bb32 bca895f
Author: David Benjamin <davidben@chromium.org>
Date:   Mon Jul 14 18:17:28 2014 +0000
am bca895f8: Pass output buffer length into EVP_DigestSignFinal.
* commit 'bca895f809dd2cef7a0834f0bfeb2a06e42b277d':
Pass output buffer length into EVP_DigestSignFinal.
commit 8b7bb32af09a01e80442b70dd23e6997a937f103
Merge: a2404c9 e79c25b
Author: Kenny Root <kroot@google.com>
Date:   Mon Jul 14 18:17:28 2014 +0000
am e79c25bf: Merge ""DHKeyPairGenerator: use provided params""
* commit 'e79c25bf33e10da41e489c537823f678e1a1169c':
DHKeyPairGenerator: use provided params
commit 8f9ac1af0cbdf00e5e47aee32c132522ebc3bd17
Author: Alex Klyubin <klyubin@google.com>
Date:   Thu Jun 19 13:37:24 2014 -0700
Enable PSK cipher suites when PSKKeyManager is provided.
This enables TLS-PSK cipher suites by default iff SSLContext is
initialized with a PSKKeyManager. For consistency, X.509 based
cipher suites are no longer enabled by default at all times -- they
are now only enabled by default iff SSLContext is initialized with a
X509KeyManager or a X509TrustManager.
When both X.509 and PSK cipher suites need to be enabled, PSK cipher
suites are given higher priority in the resulting list of cipher
suites. This is based on the assumption that in most cases users of
TLS/SSL who enable TLS-PSK would prefer TLS-PSK to be used when the
peer supports TLS-PSK.
Bug: 15073623
Change-Id: I8e2bc3e7a1ea8a986e468973b6bad19dc6b7bc3c
commit bca895f809dd2cef7a0834f0bfeb2a06e42b277d
Author: David Benjamin <davidben@chromium.org>
Date:   Thu Jul 10 18:12:08 2014 -0400
Pass output buffer length into EVP_DigestSignFinal.
EVP_DigestSignFinal expects the input buffer length as *siglen on input. In
addition, if sigret is NULL, it returns the buffer size needed. Use this rather
than making assumptions about the EVP_PKEY used to initialize the EVP_MD_CTX.
commit e79c25bf33e10da41e489c537823f678e1a1169c
Merge: a328492 9b226f9
Author: Kenny Root <kroot@google.com>
Date:   Fri Jul 11 16:46:23 2014 +0000
Merge ""DHKeyPairGenerator: use provided params""
commit 9b226f90a992a4a2267b7a813e3b869851945c4d
Author: Kenny Root <kroot@google.com>
Date:   Thu Jul 10 14:50:48 2014 -0700
DHKeyPairGenerator: use provided params
If the prime is provided in the DHParameterSpec, then use it to generate
the key.
Bug: 16188130
Change-Id: I42de02c71a58d691ef7ba6e2252367105687b758
Bug: 18388980
Change-Id: I853b02a32db113a5af3f6166e7d61fab58c3ff73/"
conscrypt,"Enable any opaque private keys to be used with TLS/SSL stack.
Prior to this CL, opaque private keys -- those that do not
expose/export their key material -- were not supported by Conscrypt's
SSLSocket, SSLServerSocket and SSLEngine implementations if the keys
were backed by other providers.
This CL fixes this issue. Conscrypt's TLS/SSL stack now works with
arbitrary opaque private keys provided that:
* for EC private key: an installed implementation of NONEwithECDSA
Signature accepts the key for signing; and
* for RSA private key: an installed implementation of NONEwithRSA
Signature accepts the key for signing and an installed
implementation of RSA/ECB/PKCS1Padding Cipher accepts the key for
decryption.
This normally requires that the JCA Provider which produced the
PrivateKey instance expose the above Cipher transformation and
Signature algorithms.
HOW THIS WORKS
The underlying OpenSSL TLS/SSL stack uses the provided private keys
only to decrypt and sign. For opaque private keys these requests are
delegated (same as before, via CryptoUpcalls) to corresponding Cipher
(RSA/ECB/PKCS1Padding) and Signature (NONEwithRSA or NONEwithECDSA)
implementations.
Even when signing and decryption is outsourced, OpenSSL still needs
the modulus (for RSA) and order (for EC), supposedly to estimate
output size of signing or decryption operations. This information is
not available via the PrivateKey interface. However, an opaque private
key may still implement the RSAKey or ECKey interface which provides
access to modulus or order but does not provide access to key
material. Moreover, in all use cases of private keys with Conscrypt's
TLS/SSL stack the modulus or order can be obtained and provided to
OpenSSL. In the case of private keys used for client or server
authentication, the public key of the certificate is used as the
source of the information. In the case of TLS Channel ID, the order is
currently fixed and known (only NIST P-256 is supported).
Bug: 19284418
Change-Id: I8fea2492f9cf48cfc29c3e7d2ee99a68e84e82ec/"
conscrypt,"external/conscrypt: add NativeConstants.
NativeConstants.java is generated by a C program and thus the values
will automatically be kept in sync with the contents of the OpenSSL
headers.
Bug: 20521989
Change-Id: Ib5a97bf6ace05988e3eef4a9c8e02d0f707d46ad/am ba57c056: am 796ed069: conscrypt: throw exception for null references in NativeCrypto
* commit 'ba57c05662c226fc0ef315ab025454dc10248010':
conscrypt: throw exception for null references in NativeCrypto/am 796ed069: conscrypt: throw exception for null references in NativeCrypto
* commit '796ed069bc90d1de9f45ea1f746edaeec8081ed3':
conscrypt: throw exception for null references in NativeCrypto/conscrypt: throw exception for null references in NativeCrypto
Adapted tests to use ""null"" instead of an Object with a null
context, as null contexts are now rejected by constructors.
bug: 19657430
Change-Id: I47ebfde7170e1818afd64a75a8e4bc1e1d588aea/"
conscrypt,"am 066b2017: am 8d18c8a7: external/conscrypt: fix WITH_JNI_TRACE in light of BoringSSL update.
* commit '066b2017250f6e880b8d9011cdf8618157d3d129':
external/conscrypt: fix WITH_JNI_TRACE in light of BoringSSL update./am c1967b3c: am 7c0a4c86: Fix OpenSSL build for new AEAD changes
* commit 'c1967b3cf71a1f4a2a277b7185ea7c6baf8e1106':
Fix OpenSSL build for new AEAD changes/am 9d84edba: am 09b021a5: conscrypt: guard some error values that will be removed in BoringSSL.
* commit '9d84edba7fe8109810f98d7af9fff56970b97ef7':
conscrypt: guard some error values that will be removed in BoringSSL./Update to latest Conscrypt
This includes AES/GCM/NoPadding support, changes for the latest
BoringSSL revision, and some fixes while compiling with debugging
flags fixes.
Bug: 21085702
Change-Id: I0de7b15a32f532e625d74729fc6ff20809af6c78/am 066b2017: am 8d18c8a7: external/conscrypt: fix WITH_JNI_TRACE in light of BoringSSL update.
* commit '066b2017250f6e880b8d9011cdf8618157d3d129':
external/conscrypt: fix WITH_JNI_TRACE in light of BoringSSL update./am c1967b3c: am 7c0a4c86: Fix OpenSSL build for new AEAD changes
* commit 'c1967b3cf71a1f4a2a277b7185ea7c6baf8e1106':
Fix OpenSSL build for new AEAD changes/am 8d18c8a7: external/conscrypt: fix WITH_JNI_TRACE in light of BoringSSL update.
* commit '8d18c8a7764a2f07f91db7340a3faab6e8242b5c':
external/conscrypt: fix WITH_JNI_TRACE in light of BoringSSL update./am 7c0a4c86: Fix OpenSSL build for new AEAD changes
* commit '7c0a4c86e6292b5bce675b4c6db2b8c6d2608be7':
Fix OpenSSL build for new AEAD changes/Silence unused result warnings in conscrypt.
So we can turn on _FORTIFY_SOURCE=2 for the host.
Bug: http://b/20558757
Change-Id: Ie2b3eb7efb69a3def64be2c35bd8cc5fe3a8d85e/external/conscrypt: fix WITH_JNI_TRACE in light of BoringSSL update.
These values in BoringSSL are now uint32_t's, which upsets the compiler
when printing them as longs.
This change casts the values to longs so that it continues to work with
OpenSSL.
Change-Id: I35af51d765d67b3c8c30e55b80eac24dda420a88/Fix OpenSSL build for new AEAD changes
Change-Id: I06304121d29d6fdcc7dab7a2c8e9d208a394e0a8/OpenSSLCipher: add AEAD cipher
This allows us to provide an implementation of AES-GCM using the new
EVP_AEAD interface in BoringSSL. It simply buffers up the input until
doFinal(...) is called which makes it much safer than any streaming
interfaces, because the caller can't use the plaintext until it's
authenticated by the GHASH (or whatever other AEAD you happen to use).
Bug: 20636336
Change-Id: I6e4b063a8137a16102b1f6ac15687a38ddfe1691/am 9d84edba: am 09b021a5: conscrypt: guard some error values that will be removed in BoringSSL.
* commit '9d84edba7fe8109810f98d7af9fff56970b97ef7':
conscrypt: guard some error values that will be removed in BoringSSL./am 09b021a5: conscrypt: guard some error values that will be removed in BoringSSL.
* commit '09b021a5906c5a8ffa81a8709a029baa3576fbb5':
conscrypt: guard some error values that will be removed in BoringSSL./conscrypt: guard some error values that will be removed in BoringSSL.
The next BoringSSL update will further prune the error reasons that it
defines. This change allows Conscrypt to continue to compile.
Change-Id: I0d8681578c6635daedccdb11177d2b3a5e88485d/Disable RSA blinding for BoringSSL with no public exponent
Switch to using the RSA_FLAG_NO_BLINDING for both OpenSSL and BoringSSL.
The RSAPrivateKey constructor in the Java language only takes the
modulus and private exponent, so we have to support no blinding.
(cherry picked from commit fbb754fc646d109d9c0d42d94a7dced5eaa6b5d7)
Bug: 20563652
Change-Id: I6264ffce428bf9847eb83dafb9119ccfe184d7f5/Disable RSA blinding for BoringSSL with no public exponent
Switch to using the RSA_FLAG_NO_BLINDING for both OpenSSL and BoringSSL.
The RSAPrivateKey constructor in the Java language only takes the
modulus and private exponent, so we have to support no blinding.
Bug: 20563652
Change-Id: I3ccd600d0e4f12ff154f816ab5efb0da38123e39/am f327f460: am dc77a71e: Fix method by which the EC curve type is determined
* commit 'f327f4607c67c4d399abcbf00545a06605a44e4c':
Fix method by which the EC curve type is determined/am dc77a71e: Fix method by which the EC curve type is determined
* commit 'dc77a71ed6ce02fe2b4e78982825ec467598dbd7':
Fix method by which the EC curve type is determined/Fix method by which the EC curve type is determined
The way the curve type was determined was fragile when moving between
processor types. Change it to a more explicit curve type check.
Change-Id: I3fe1d6c38bd0e360ba3ec4f688b44485b5a1c7ab/external/conscrypt: ask OpenSSL for supported cipher suites.
Rather than enumerate the list of supported cipher suites in conscrypt,
ask OpenSSL for the list and just maintain a mapping from OpenSSL's
names to the standard, external name.
(The mapping could also be removed with BoringSSL since it can return
the standard name for an SSL_CIPHER*. But in order to keep OpenSSL
compat this change doesn't depend on that.)
(cherry picked from commit d9a68f656782ee2fa0ca918e00522cdd25d33fdf)
Bug: 20531880
Change-Id: Ib541c9787093e7b900052fdf12dd2a2029b4b020/external/conscrypt: ask OpenSSL for supported cipher suites.
Rather than enumerate the list of supported cipher suites in conscrypt,
ask OpenSSL for the list and just maintain a mapping from OpenSSL's
names to the standard, external name.
(The mapping could also be removed with BoringSSL since it can return
the standard name for an SSL_CIPHER*. But in order to keep OpenSSL
compat this change doesn't depend on that.)
Bug: 20531880
Change-Id: Ib541c9787093e7b900052fdf12dd2a2029b4b020/am cad5f50c: am d12c5671: Throw InvalidKeyException when keystore key malformed
* commit 'cad5f50cc98225895e149adffa551b3a7f5bedae':
Throw InvalidKeyException when keystore key malformed/am 9ce87ac7: am 48d7b0a9: NativeCrypto: allow default exceptions
* commit '9ce87ac75ebd3b250b5e17a3e51c13faacd381c8':
NativeCrypto: allow default exceptions/am d12c5671: Throw InvalidKeyException when keystore key malformed
* commit 'd12c56715e2c8fa8d5da69b5892eeab7373d1773':
Throw InvalidKeyException when keystore key malformed/am 48d7b0a9: NativeCrypto: allow default exceptions
* commit '48d7b0a992fc4c4556bf753932fc4098c9c4ca71':
NativeCrypto: allow default exceptions/Throw InvalidKeyException when keystore key malformed
When a keystore implementation can't decode a key for some reason, throw
InvalidKeyException instead of RuntimeException. This will allow
applications to handle the error instead of crashing.
Bug: 20488918
Change-Id: I89215b5bc728ad1c266031bead940268025018a8
(cherry picked from commit 4415aa6cf61ea5443f88301c9ad921f8c840a4ad)/NativeCrypto: allow default exceptions
Re-arrange the exception-throwing code to allow functions to pass in a
default exception type instead of always throwing RuntimeException when
a reason code doesn't match exactly with an exception type.
(cherry picked from commit f2d30c9a2f73a21225728e4ba39467275dfddc01)
Bug: 20488918
Change-Id: I557def7bbcfb164d2c781e0303431ff7a7793086/Throw InvalidKeyException when keystore key malformed
When a keystore implementation can't decode a key for some reason, throw
InvalidKeyException instead of RuntimeException. This will allow
applications to handle the error instead of crashing.
Bug: 20488918
Change-Id: I89215b5bc728ad1c266031bead940268025018a8/NativeCrypto: allow default exceptions
Re-arrange the exception-throwing code to allow functions to pass in a
default exception type instead of always throwing RuntimeException when
a reason code doesn't match exactly with an exception type.
Bug: 20488918
Change-Id: I557def7bbcfb164d2c781e0303431ff7a7793086/NativeCrypto: compatibility with OpenSSL
OpenSSL has different definitions for the ECDSA functions which causes
compilation errors when we're being strict. Sprinkle in some more #ifdef
to allow compilation for both.
Change-Id: Iafe3799289980fdf7862a861b2aee4517dbd869a/RI: cast to char* for JNI registration
The RI has a different type that causing compilation errors if you don't
do this cast.
Change-Id: I5961d79c88bef6cba2dc0de9c81e310005e4712c/NativeCrypto: not finding a key is not fatal
If we don't find a key in the keystore, we should just return null
reference. The only time we should throw exceptions is when the key
decoding failed or something else like that.
Bug: 20488918
(cherry picked from commit 8098cbbc7fbf2d22402da487465a153734f9f9b6)
Change-Id: I621b39257bc98d888f7ad390fb8648326c67dfc4/NativeCrypto: not finding a key is not fatal
If we don't find a key in the keystore, we should just return null
reference. The only time we should throw exceptions is when the key
decoding failed or something else like that.
Bug: 20488918
Change-Id: I85408615a9c7a63242178908f309f93a2972033c/am 5f20896e: am cac31e4e: am 8a77c208: NativeCrypto: do not discard pending exceptions
* commit '5f20896e0106ac2e9784490effcec08a8c51c681':
NativeCrypto: do not discard pending exceptions/external/conscrypt: add SSL_CIPHER_get_kx_name
This will be used by a future change to avoid needing to know the
OpenSSL-internal SSL_aRSA (etc) constants.
Bug: 20521989
Change-Id: I99d83005530f81956d102426fe28beeaed058cea/am cac31e4e: am 8a77c208: NativeCrypto: do not discard pending exceptions
* commit 'cac31e4e4af4c72617cec0fc0373814492f3fb0e':
NativeCrypto: do not discard pending exceptions/am 8a77c208: NativeCrypto: do not discard pending exceptions
* commit '8a77c20803591434b49dc1fb81414b9ce1f4083f':
NativeCrypto: do not discard pending exceptions/NativeCrypto: do not discard pending exceptions
The switch to native reference objects left some duplicate
NullPointerException creation that led to some JNI warnings. Simply get
rid of the redundant NullPointerException throws.
Bug: 19657430
Change-Id: I7e6bcb74154078cf019bfdea5d2721f6e6cb8524/external/conscrypt: recognise des-ede-cbc as an alias for des-cbc.
Bug: 20518919
Change-Id: I2b697529420a5c3fd9f96887a11977d261b3d1aa/OpenSSLEngine: do not try to load ENGINE for BoringSSL
Since BoringSSL doesn't use ENGINE instances, we should not fail when
the native code returns the equivalent of a NULL instance. This change
propagates the knowledge of whether we're using BoringSSL or OpenSSL up
to the Java layer.
Change-Id: Ib8c2224a909564ae6f0c6d5984020c44517f6c29/external/conscrypt: don't throw in native code if missing cipher.
The calling Java code throws a more helpful exception which will aid in
debugging.
Bug: 20451412
Change-Id: I7dde46d5f0d5903ba2994d92bf22d78ee2e799a3/external/conscrypt: align registered modes with BoringSSL.
Some of the more obscure modes BoringSSL doesn't support anymore, so
just let Bouncycastle implement them.
Bug: 20451412
Change-Id: I966e08493b1df741ffc114d3189b301456011a4e/am ba57c056: am 796ed069: conscrypt: throw exception for null references in NativeCrypto
* commit 'ba57c05662c226fc0ef315ab025454dc10248010':
conscrypt: throw exception for null references in NativeCrypto/am 796ed069: conscrypt: throw exception for null references in NativeCrypto
* commit '796ed069bc90d1de9f45ea1f746edaeec8081ed3':
conscrypt: throw exception for null references in NativeCrypto/conscrypt: throw exception for null references in NativeCrypto
Adapted tests to use ""null"" instead of an Object with a null
context, as null contexts are now rejected by constructors.
bug: 19657430
Change-Id: I47ebfde7170e1818afd64a75a8e4bc1e1d588aea/Enable any opaque private keys to be used with TLS/SSL stack.
Prior to this CL, opaque private keys -- those that do not
expose/export their key material -- were not supported by Conscrypt's
SSLSocket, SSLServerSocket and SSLEngine implementations if the keys
were backed by other providers.
This CL fixes this issue. Conscrypt's TLS/SSL stack now works with
arbitrary opaque private keys provided that:
* for EC private key: an installed implementation of NONEwithECDSA
Signature accepts the key for signing; and
* for RSA private key: an installed implementation of NONEwithRSA
Signature accepts the key for signing and an installed
implementation of RSA/ECB/PKCS1Padding Cipher accepts the key for
decryption.
This normally requires that the JCA Provider which produced the
PrivateKey instance expose the above Cipher transformation and
Signature algorithms.
HOW THIS WORKS
The underlying OpenSSL TLS/SSL stack uses the provided private keys
only to decrypt and sign. For opaque private keys these requests are
delegated (same as before, via CryptoUpcalls) to corresponding Cipher
(RSA/ECB/PKCS1Padding) and Signature (NONEwithRSA or NONEwithECDSA)
implementations.
Even when signing and decryption is outsourced, OpenSSL still needs
the modulus (for RSA) and order (for EC), supposedly to estimate
output size of signing or decryption operations. This information is
not available via the PrivateKey interface. However, an opaque private
key may still implement the RSAKey or ECKey interface which provides
access to modulus or order but does not provide access to key
material. Moreover, in all use cases of private keys with Conscrypt's
TLS/SSL stack the modulus or order can be obtained and provided to
OpenSSL. In the case of private keys used for client or server
authentication, the public key of the certificate is used as the
source of the information. In the case of TLS Channel ID, the order is
currently fixed and known (only NIST P-256 is supported).
Bug: 19284418
Change-Id: I8fea2492f9cf48cfc29c3e7d2ee99a68e84e82ec/Add back d2i_PKCS7_bio and PEM_read_bio_PKCS7.
For the moment, the BoringSSL version is going to be broken until I get
the needed changes into BoringSSL to support this.
Change-Id: Id2c3f179c6f9fc4f4385d2274884e69530fabff0/am eb322309: am 0ccc17a0: external/conscrypt: a couple more BoringSSL build fixes.
* commit 'eb32230947680c9aa461dc496904f4c8fd66ab39':
external/conscrypt: a couple more BoringSSL build fixes./am 0ccc17a0: external/conscrypt: a couple more BoringSSL build fixes.
* commit '0ccc17a0c3d05be22a357849ddc5f93bf431d4ec':
external/conscrypt: a couple more BoringSSL build fixes./external/conscrypt: a couple more BoringSSL build fixes.
I had these in my local client and didn't notice until now.
Change-Id: I9c61447691d358acbaadb9b9a2f068b4106d266c/"
conscrypt,"OpenSSLCipherRSA: reset bufferOffset on init
Repeatedly using the Cipher instance caused failures since the offset is
not reset the same time that a new buffer is allocated.
Change-Id: Iadc4905a61b5909b911c48c29c11fb0bc52f78c6/external/conscrypt: add NativeConstants.
NativeConstants.java is generated by a C program and thus the values
will automatically be kept in sync with the contents of the OpenSSL
headers.
Bug: 20521989
Change-Id: Ib5a97bf6ace05988e3eef4a9c8e02d0f707d46ad/"
conscrypt,"external/conscrypt: add NativeConstants.
NativeConstants.java is generated by a C program and thus the values
will automatically be kept in sync with the contents of the OpenSSL
headers.
Bug: 20521989
Change-Id: Ib5a97bf6ace05988e3eef4a9c8e02d0f707d46ad/"
conscrypt,"external/conscrypt: remove DHKey.
BoringSSL has DH, but it's not wired up to EVP any longer. It would be
possible to get DHKey working directly using DH because it doesn't use
anything non-standard, but it's probably not worth worrying about.
Bug: 20518803
Bug: 20522271
Change-Id: I7167ba5ae96b0ba914c5759b6293236e4a3302da/"
conscrypt,"Update to latest Conscrypt
This includes AES/GCM/NoPadding support, changes for the latest
BoringSSL revision, and some fixes while compiling with debugging
flags fixes.
Bug: 21085702
Change-Id: I0de7b15a32f532e625d74729fc6ff20809af6c78/OpenSSLCipher: add AEAD cipher
This allows us to provide an implementation of AES-GCM using the new
EVP_AEAD interface in BoringSSL. It simply buffers up the input until
doFinal(...) is called which makes it much safer than any streaming
interfaces, because the caller can't use the plaintext until it's
authenticated by the GHASH (or whatever other AEAD you happen to use).
Bug: 20636336
Change-Id: I6e4b063a8137a16102b1f6ac15687a38ddfe1691/external/conscrypt: ask OpenSSL for supported cipher suites.
Rather than enumerate the list of supported cipher suites in conscrypt,
ask OpenSSL for the list and just maintain a mapping from OpenSSL's
names to the standard, external name.
(The mapping could also be removed with BoringSSL since it can return
the standard name for an SSL_CIPHER*. But in order to keep OpenSSL
compat this change doesn't depend on that.)
(cherry picked from commit d9a68f656782ee2fa0ca918e00522cdd25d33fdf)
Bug: 20531880
Change-Id: Ib541c9787093e7b900052fdf12dd2a2029b4b020/external/conscrypt: ask OpenSSL for supported cipher suites.
Rather than enumerate the list of supported cipher suites in conscrypt,
ask OpenSSL for the list and just maintain a mapping from OpenSSL's
names to the standard, external name.
(The mapping could also be removed with BoringSSL since it can return
the standard name for an SSL_CIPHER*. But in order to keep OpenSSL
compat this change doesn't depend on that.)
Bug: 20531880
Change-Id: Ib541c9787093e7b900052fdf12dd2a2029b4b020/am cad5f50c: am d12c5671: Throw InvalidKeyException when keystore key malformed
* commit 'cad5f50cc98225895e149adffa551b3a7f5bedae':
Throw InvalidKeyException when keystore key malformed/am d12c5671: Throw InvalidKeyException when keystore key malformed
* commit 'd12c56715e2c8fa8d5da69b5892eeab7373d1773':
Throw InvalidKeyException when keystore key malformed/Throw InvalidKeyException when keystore key malformed
When a keystore implementation can't decode a key for some reason, throw
InvalidKeyException instead of RuntimeException. This will allow
applications to handle the error instead of crashing.
Bug: 20488918
Change-Id: I89215b5bc728ad1c266031bead940268025018a8
(cherry picked from commit 4415aa6cf61ea5443f88301c9ad921f8c840a4ad)/Throw InvalidKeyException when keystore key malformed
When a keystore implementation can't decode a key for some reason, throw
InvalidKeyException instead of RuntimeException. This will allow
applications to handle the error instead of crashing.
Bug: 20488918
Change-Id: I89215b5bc728ad1c266031bead940268025018a8/external/conscrypt: switch NativeCrypto itself to use NativeConstants.
Now that other users of the constants in NativeCrypto have been switched
over, those constants can be removed.
Bug: 20521989
Change-Id: I276a1c8daeb3501b6924ff68cf9f1e9f6fbd63a9/external/conscrypt: add SSL_CIPHER_get_kx_name
This will be used by a future change to avoid needing to know the
OpenSSL-internal SSL_aRSA (etc) constants.
Bug: 20521989
Change-Id: I99d83005530f81956d102426fe28beeaed058cea/OpenSSLEngine: do not try to load ENGINE for BoringSSL
Since BoringSSL doesn't use ENGINE instances, we should not fail when
the native code returns the equivalent of a NULL instance. This change
propagates the knowledge of whether we're using BoringSSL or OpenSSL up
to the Java layer.
Change-Id: Ib8c2224a909564ae6f0c6d5984020c44517f6c29/Enable any opaque private keys to be used with TLS/SSL stack.
Prior to this CL, opaque private keys -- those that do not
expose/export their key material -- were not supported by Conscrypt's
SSLSocket, SSLServerSocket and SSLEngine implementations if the keys
were backed by other providers.
This CL fixes this issue. Conscrypt's TLS/SSL stack now works with
arbitrary opaque private keys provided that:
* for EC private key: an installed implementation of NONEwithECDSA
Signature accepts the key for signing; and
* for RSA private key: an installed implementation of NONEwithRSA
Signature accepts the key for signing and an installed
implementation of RSA/ECB/PKCS1Padding Cipher accepts the key for
decryption.
This normally requires that the JCA Provider which produced the
PrivateKey instance expose the above Cipher transformation and
Signature algorithms.
HOW THIS WORKS
The underlying OpenSSL TLS/SSL stack uses the provided private keys
only to decrypt and sign. For opaque private keys these requests are
delegated (same as before, via CryptoUpcalls) to corresponding Cipher
(RSA/ECB/PKCS1Padding) and Signature (NONEwithRSA or NONEwithECDSA)
implementations.
Even when signing and decryption is outsourced, OpenSSL still needs
the modulus (for RSA) and order (for EC), supposedly to estimate
output size of signing or decryption operations. This information is
not available via the PrivateKey interface. However, an opaque private
key may still implement the RSAKey or ECKey interface which provides
access to modulus or order but does not provide access to key
material. Moreover, in all use cases of private keys with Conscrypt's
TLS/SSL stack the modulus or order can be obtained and provided to
OpenSSL. In the case of private keys used for client or server
authentication, the public key of the certificate is used as the
source of the information. In the case of TLS Channel ID, the order is
currently fixed and known (only NIST P-256 is supported).
Bug: 19284418
Change-Id: I8fea2492f9cf48cfc29c3e7d2ee99a68e84e82ec/"
conscrypt,"OpenSSLCipher: add AEAD cipher
This allows us to provide an implementation of AES-GCM using the new
EVP_AEAD interface in BoringSSL. It simply buffers up the input until
doFinal(...) is called which makes it much safer than any streaming
interfaces, because the caller can't use the plaintext until it's
authenticated by the GHASH (or whatever other AEAD you happen to use).
Bug: 20636336
Change-Id: I6e4b063a8137a16102b1f6ac15687a38ddfe1691/OpenSSLCipher: refactor in preparation for AEAD
BoringSSL uses a different interface for AEAD that is much simplier
called EVP_AEAD. Separate out the EVP_CIPHER usage so that we can have
another subclass with the EVP_AEAD usage.
Bug: 20636336
Change-Id: I661d92bd449f2fcc3c4a6e511155490917ecef0c/am 1f186d47: am c2290a4b: am d4cca77f: OpenSSLCipher: exception when IV not specified
* commit '1f186d47db651c2c8bdbd27d7c8c7eb12ee00868':
OpenSSLCipher: exception when IV not specified/am c2290a4b: am d4cca77f: OpenSSLCipher: exception when IV not specified
* commit 'c2290a4ba90b080cce06c93cad292f39e6049a9c':
OpenSSLCipher: exception when IV not specified/am d4cca77f: OpenSSLCipher: exception when IV not specified
* commit 'd4cca77f58721f32082a06b4c16631a3730844ca':
OpenSSLCipher: exception when IV not specified/OpenSSLCipher: exception when IV not specified
If you're decrypting with a mode that requires an IV, init should throw
an exception indicating as much. Add the checks to make sure this
happens.
Bug: 19201819
Change-Id: I2d3481da4f63bffb340dc1197f6b5cb29360fbff/external/conscrypt: align registered modes with BoringSSL.
Some of the more obscure modes BoringSSL doesn't support anymore, so
just let Bouncycastle implement them.
Bug: 20451412
Change-Id: I966e08493b1df741ffc114d3189b301456011a4e/"
conscrypt,"external/conscrypt: add NativeConstants.
NativeConstants.java is generated by a C program and thus the values
will automatically be kept in sync with the contents of the OpenSSL
headers.
Bug: 20521989
Change-Id: Ib5a97bf6ace05988e3eef4a9c8e02d0f707d46ad/"
conscrypt,"external/conscrypt: add NativeConstants.
NativeConstants.java is generated by a C program and thus the values
will automatically be kept in sync with the contents of the OpenSSL
headers.
Bug: 20521989
Change-Id: Ib5a97bf6ace05988e3eef4a9c8e02d0f707d46ad/"
conscrypt,"Rename Arrays to ArrayUtils
To avoid conflict with the java.util.Arrays class, rename our own
internal compatibility class to ArrayUtils.
Change-Id: Iae79a4d37749e16e62712f3bb5038d870b78d999/external/conscrypt: add NativeConstants.
NativeConstants.java is generated by a C program and thus the values
will automatically be kept in sync with the contents of the OpenSSL
headers.
Bug: 20521989
Change-Id: Ib5a97bf6ace05988e3eef4a9c8e02d0f707d46ad/Enable any opaque private keys to be used with TLS/SSL stack.
Prior to this CL, opaque private keys -- those that do not
expose/export their key material -- were not supported by Conscrypt's
SSLSocket, SSLServerSocket and SSLEngine implementations if the keys
were backed by other providers.
This CL fixes this issue. Conscrypt's TLS/SSL stack now works with
arbitrary opaque private keys provided that:
* for EC private key: an installed implementation of NONEwithECDSA
Signature accepts the key for signing; and
* for RSA private key: an installed implementation of NONEwithRSA
Signature accepts the key for signing and an installed
implementation of RSA/ECB/PKCS1Padding Cipher accepts the key for
decryption.
This normally requires that the JCA Provider which produced the
PrivateKey instance expose the above Cipher transformation and
Signature algorithms.
HOW THIS WORKS
The underlying OpenSSL TLS/SSL stack uses the provided private keys
only to decrypt and sign. For opaque private keys these requests are
delegated (same as before, via CryptoUpcalls) to corresponding Cipher
(RSA/ECB/PKCS1Padding) and Signature (NONEwithRSA or NONEwithECDSA)
implementations.
Even when signing and decryption is outsourced, OpenSSL still needs
the modulus (for RSA) and order (for EC), supposedly to estimate
output size of signing or decryption operations. This information is
not available via the PrivateKey interface. However, an opaque private
key may still implement the RSAKey or ECKey interface which provides
access to modulus or order but does not provide access to key
material. Moreover, in all use cases of private keys with Conscrypt's
TLS/SSL stack the modulus or order can be obtained and provided to
OpenSSL. In the case of private keys used for client or server
authentication, the public key of the certificate is used as the
source of the information. In the case of TLS Channel ID, the order is
currently fixed and known (only NIST P-256 is supported).
Bug: 19284418
Change-Id: I8fea2492f9cf48cfc29c3e7d2ee99a68e84e82ec/"
conscrypt,"GCM: return the correct AlgorithmParameters
Instead of the correct AlgorithmParameters of type ""GCM,"" we were
returning the generic ""AES"" version that basically only converts to an
IvParameterSpec.
Bug: 22319986
Change-Id: Ib42905c3ad31e44b72e8066192bd26981c8351ba/"
conscrypt,"Update NativeCryptoTest
Test both client and server. Also we expect a SSLHandshakeException
instead of an SSLProtocolException in one case.
Bug: 21207627
(cherry picked from commit 5429f72d9c1e7bc6379e917e9b9116f1b0292b28)
Change-Id: If895b03e2cece3a1a8d2f074a557c68f55a7021e/Update NativeCryptoTest
Test both client and server. Also we expect a SSLHandshakeException
instead of an SSLProtocolException in one case.
Bug: 21207627
Change-Id: I717c88fe61e784f3cbfe983d6cbd52ab1e5f1631/am f7ab43f5: Merge ""external/conscrypt: remove assertion SSL_OP_NO_SSLv2 is set"" into mnc-dev
* commit 'f7ab43f5e5861ddcc2549eae1fcb38c4a7eed54f':
external/conscrypt: remove assertion SSL_OP_NO_SSLv2 is set/Merge ""external/conscrypt: remove assertion SSL_OP_NO_SSLv2 is set"" into mnc-dev/external/conscrypt: remove assertion SSL_OP_NO_SSLv2 is set
SSL_OP_NO_SSLv2 is not a flag anymore (defined as 0 in ssh.h)
Bug: 21875962
(cherry picked from commit 97e54bdde00eae7ffe4eb382e3f2702af4a2197b)
Change-Id: I52004b893768b087577c078dcd1ba0ae1bdea911/am 2eb52794: am 97e54bdd: external/conscrypt: remove assertion SSL_OP_NO_SSLv2 is set
* commit '2eb527946991afab9da5b87c2329c60f23042b88':
external/conscrypt: remove assertion SSL_OP_NO_SSLv2 is set/am 97e54bdd: external/conscrypt: remove assertion SSL_OP_NO_SSLv2 is set
* commit '97e54bdde00eae7ffe4eb382e3f2702af4a2197b':
external/conscrypt: remove assertion SSL_OP_NO_SSLv2 is set/external/conscrypt: remove assertion SSL_OP_NO_SSLv2 is set
SSL_OP_NO_SSLv2 is not a flag anymore (defined as 0 in ssh.h)
Bug: 21875962
Change-Id: Ib8c2512c93f3aeb578bf49c8983e9467083b44df/conscrypt: change test of SSL_set_cipher_lists
NativeCrypto.SSL_set_cipher_lists can accept the empty list as
per c/154191
Bug: 21816861
(cherry picked from commit c0010ca585f9cdc1f09846e2d75a0a8f82420476)
Change-Id: I6cf7563417d8b6fb9edbeade0947726275a76c18/conscrypt: change test of SSL_set_cipher_lists
NativeCrypto.SSL_set_cipher_lists can accept the empty list as
per c/154191
Bug: 21816861
Change-Id: I96f6d2f7733c5316179bc26a63c9fd3b28451b26/Add isFinite flag to OpenSSLBIOInputStream.
The BIO created by OpenSSLBIOInputStream currently returns -1 and sets
the retry flag when read() returns zero on the underlying InputStream.
This is correct for infinite streams (like a socket), but isn't
correct for streams that have a definitive EOF.
This change adds a flag to OpenSSLBIOInputStream so that cases where the
input is finite (i.e. when parsing a PKCS#7 or X.509 block) can
correctly return 0 at EOF from |BIO_read|.
(cherry picked from commit 66537ee0121bdd14737191d14927da223f0809ee)
Bug: 21396526
Bug: 21209493
Change-Id: Iaad5845621ab8b89b42d5d3ca8e67e297278ca55/Add isFinite flag to OpenSSLBIOInputStream.
The BIO created by OpenSSLBIOInputStream currently returns -1 and sets
the retry flag when read() returns zero on the underlying InputStream.
This is correct for infinite streams (like a socket), but isn't
correct for streams that have a definitive EOF.
This change adds a flag to OpenSSLBIOInputStream so that cases where the
input is finite (i.e. when parsing a PKCS#7 or X.509 block) can
correctly return 0 at EOF from |BIO_read|.
Bug: 21396526
Bug: 21209493
Change-Id: Iaad5845621ab8b89b42d5d3ca8e67e297278ca55/"
conscrypt,"GCM: return the correct AlgorithmParameters
Instead of the correct AlgorithmParameters of type ""GCM,"" we were
returning the generic ""AES"" version that basically only converts to an
IvParameterSpec.
Bug: 22319986
Change-Id: Ib42905c3ad31e44b72e8066192bd26981c8351ba/"
conscrypt,"Adjust Signature interface for BoringSSL
BoringSSL will push the BAD_SIGNATURE error onto the stack for every
signature error. In Java it just returns false from the Signature#verify
call when the signature is incorrect.  However, we still want to throw
an exception for raw RSA when the number of signature bytes is larger
than the modulus can express.
Bug: 21209646
(cherry picked from commit 089b401856a4da378875e94108fe742d1cdf0db2)
Change-Id: I96ada8762817a99df11da2f7e7b7310bb31d5cba/Adjust Signature interface for BoringSSL
BoringSSL will push the BAD_SIGNATURE error onto the stack for every
signature error. In Java it just returns false from the Signature#verify
call when the signature is incorrect.  However, we still want to throw
an exception for raw RSA when the number of signature bytes is larger
than the modulus can express.
Bug: 21209646
Change-Id: Ie29eba8b12bb8d3220b7b29146c45b8dd416e338/Consistently use ARRAY_OFFSET_*INVALID macros.
Not all the ad-hoc ones check for integer overflow correctly. Consistently use
the same check everywhere.
Change-Id: I913b7de792406d9819a6830cc21ec500ddceff6e/am 199a1346: Fix compilation with OpenSSL
* commit '199a134656110b0d75c4ead3606051a7d16b808b':
Fix compilation with OpenSSL/am d7f7dd22: am d9a48aa4: Fix compilation with OpenSSL
* commit 'd7f7dd221ec7c3bb5ffc14227a31f18bb89fa134':
Fix compilation with OpenSSL/am d9a48aa4: Fix compilation with OpenSSL
* commit 'd9a48aa43efd90926bf3457e3fd6efde9804f9c5':
Fix compilation with OpenSSL/am f071d985: am 79f05f46: Fix error conditions in certificate/PKCS#7 reading
* commit 'f071d985494081013f9f3fe8498fa630a1d656f5':
Fix error conditions in certificate/PKCS#7 reading/Fix compilation with OpenSSL
(cherry picked from commit d9a48aa43efd90926bf3457e3fd6efde9804f9c5)
Bug: 21034231
Change-Id: I1efd062a6608111e6ab468f4e362291895dd166d/am 79f05f46: Fix error conditions in certificate/PKCS#7 reading
* commit '79f05f46c8fb2f19c8d11564ef93ef332f79fdc9':
Fix error conditions in certificate/PKCS#7 reading/Fix compilation with OpenSSL
Bug: 21034231
Change-Id: I1efd062a6608111e6ab468f4e362291895dd166d/am ccb8225a: Fix error conditions in certificate/PKCS#7 reading
* commit 'ccb8225a5c0c8a1d08b9a76a33857e853317a8f5':
Fix error conditions in certificate/PKCS#7 reading/Fix error conditions in certificate/PKCS#7 reading
When an error condition is encountered in BoringSSL, sometimes it
deliberately does not put something on the ERR stack to prevent abuse of
that knowledge. Instead we need to throw an exception explicitly when no
error is pushed onto the stack.
(cherry picked from commit 79f05f46c8fb2f19c8d11564ef93ef332f79fdc9)
Bug: 21034231
Change-Id: Ia06347c5653672c982ecff2c26be9b091d03009f/Fix error conditions in certificate/PKCS#7 reading
When an error condition is encountered in BoringSSL, sometimes it
deliberately does not put something on the ERR stack to prevent abuse of
that knowledge. Instead we need to throw an exception explicitly when no
error is pushed onto the stack.
Bug: 21034231
Change-Id: Ia06347c5653672c982ecff2c26be9b091d03009f/am d6828c47: Merge ""Fix up JNI_TRACE for AEAD"" into mnc-dev
* commit 'd6828c474d70cae8a3390523f2f75994fef7bb73':
Fix up JNI_TRACE for AEAD/Merge ""Fix up JNI_TRACE for AEAD"" into mnc-dev/Fix up JNI_TRACE for AEAD
(cherry picked from commit edc4f273c9c1c862119cdce3e4c9ca15110b2e1f)
Bug: 21762837
Change-Id: I11042be8fe1e046ac96759b4554ce9229e1cf6f3/OpenSSLCipher: adjust expected length with padding in decrypt mode
- Consider the |final| buffer when computing the expected length
- Should not expect an extra block when using padding in decrypting
mode
Bug: 19186852
Change-Id: I8c51b309ca98030ab1eda5b2a0201a97a5758072
(cherry-pick from 8fa4acdcf1e47a2745940694179fa34e95825a24)/am 7e63460a: am edc4f273: Fix up JNI_TRACE for AEAD
* commit '7e63460ae75b371fcfa97f29b3be7eaafd1ff673':
Fix up JNI_TRACE for AEAD/am edc4f273: Fix up JNI_TRACE for AEAD
* commit 'edc4f273c9c1c862119cdce3e4c9ca15110b2e1f':
Fix up JNI_TRACE for AEAD/am e90640d7: Merge ""Fix RSA upcalls from TLS/SSL into JCA."" into mnc-dev
* commit 'e90640d772b9c123b8f1ed2cbf30be4d693a30e7':
Fix RSA upcalls from TLS/SSL into JCA./am 9bca53ce: Fix ECDSA upcalls from TLS/SSL into JCA.
* commit '9bca53ce2dc30a2a4d4575b70ed39c81a35352d0':
Fix ECDSA upcalls from TLS/SSL into JCA./Merge ""Fix RSA upcalls from TLS/SSL into JCA."" into mnc-dev/Fix ECDSA upcalls from TLS/SSL into JCA.
When BoringSSL/OpenSSL TLS/SSL stack operates on opaque private keys
(those that don't expose their key material) it upcalls (via
Conscrypt's NativeCrypto) into corresponding JCA Signature and Cipher
primitives.
This fixes a crash in the ECDSA upcall when Conscrypt is used with
BoringSSL.
(cherry-picked from commit 61c66eb9842dd689dea2701124147c4197c95c90)
Bug: 21738458
Change-Id: I6def1bce62f20b2ec39fe88251975458e8813362/Fix RSA upcalls from TLS/SSL into JCA.
When BoringSSL/OpenSSL TLS/SSL stack operates on opaque private keys
(those that don't expose their key material) it upcalls (via
Conscrypt's NativeCrypto) into corresponding JCA Signature and Cipher
primitives.
This CL fixes two issues with RSA-related upcalls, which prevented
the use of opaque RSA private keys for TLS/SSL with Conscrypt backed
by BoringSSL:
* RSA sign was upcalled into RSA Cipher decrypt using private key.
In JCA, the correct upcall is RSA Signature sign. This is now
invoked instead of RSA Cipher decrypt.
* RSA decrypt was not implemented. It's now implemented.
As part of implementing RSA decrypt upcall from BoringSSL, it
transpired that BoringSSL requests no padding as opposed to OpenSSL
which requests PKCS#1 padding. As a result, this CL modifies the
decrypt upcall to take a padding parameter. The implementation of
the upcall (see CryptoUpcalls.java) now supports PKCS#1 padding
scheme, OAEP padding scheme, and no padding.
This CL also drops the encrypt/decrypt flag from the RSA
encrypt/decrypt upcall and simplies it into an RSA decrypt upcall. RSA
encrypt upcall is not needed at all.
(cherry-picked from commit 279e98451390d0a90c5fc04eac7ddd4045180465)
Bug: 21738458
Change-Id: I075aa74e4cd89dd3ceab99f728ce371c7bc89cf0/am 79a9e89f: am 279e9845: Fix RSA upcalls from TLS/SSL into JCA.
* commit '79a9e89fa34f1ea96be9dc4bf742ca2884eaf858':
Fix RSA upcalls from TLS/SSL into JCA./am ffae81d4: am 61c66eb9: Fix ECDSA upcalls from TLS/SSL into JCA.
* commit 'ffae81d439b0f5f8835862bcdfc9c0e8710889da':
Fix ECDSA upcalls from TLS/SSL into JCA./Fix up JNI_TRACE for AEAD
Bug: 21762837
Change-Id: I11042be8fe1e046ac96759b4554ce9229e1cf6f3/am 279e9845: Fix RSA upcalls from TLS/SSL into JCA.
* commit '279e98451390d0a90c5fc04eac7ddd4045180465':
Fix RSA upcalls from TLS/SSL into JCA./am 61c66eb9: Fix ECDSA upcalls from TLS/SSL into JCA.
* commit '61c66eb9842dd689dea2701124147c4197c95c90':
Fix ECDSA upcalls from TLS/SSL into JCA./Fix RSA upcalls from TLS/SSL into JCA.
When BoringSSL/OpenSSL TLS/SSL stack operates on opaque private keys
(those that don't expose their key material) it upcalls (via
Conscrypt's NativeCrypto) into corresponding JCA Signature and Cipher
primitives.
This CL fixes two issues with RSA-related upcalls, which prevented
the use of opaque RSA private keys for TLS/SSL with Conscrypt backed
by BoringSSL:
* RSA sign was upcalled into RSA Cipher decrypt using private key.
In JCA, the correct upcall is RSA Signature sign. This is now
invoked instead of RSA Cipher decrypt.
* RSA decrypt was not implemented. It's now implemented.
As part of implementing RSA decrypt upcall from BoringSSL, it
transpired that BoringSSL requests no padding as opposed to OpenSSL
which requests PKCS#1 padding. As a result, this CL modifies the
decrypt upcall to take a padding parameter. The implementation of
the upcall (see CryptoUpcalls.java) now supports PKCS#1 padding
scheme, OAEP padding scheme, and no padding.
This CL also drops the encrypt/decrypt flag from the RSA
encrypt/decrypt upcall and simplies it into an RSA decrypt upcall. RSA
encrypt upcall is not needed at all.
Bug: 21738458
Change-Id: I2a4610890ea1ed1a2e99eb1d5c34348fbf406e54/Fix ECDSA upcalls from TLS/SSL into JCA.
When BoringSSL/OpenSSL TLS/SSL stack operates on opaque private keys
(those that don't expose their key material) it upcalls (via
Conscrypt's NativeCrypto) into corresponding JCA Signature and Cipher
primitives.
This fixes a crash in the ECDSA upcall when Conscrypt is used with
BoringSSL.
Bug: 21738458
Change-Id: I51645bd93f965fe7fcabe45e87276d533513b378/NativeCrypto: special case for empty cipher list
For the Java language, setting an empty cipher list is not an error but
it's an error in OpenSSL. However, the underlying API actually updates
the cipher list to an empty string as intended. So we need to handle
this special case by clearing the error stack and making sure that our
expectation is satisfied.
(cherry picked from commit 5b6a5ecc98d1798d806024160fe97738527980d1)
Bug: 21195269
Change-Id: Id21792215513f4e0d6e051160f69e5f830d39015/NativeCrypto: special case for empty cipher list
For the Java language, setting an empty cipher list is not an error but
it's an error in OpenSSL. However, the underlying API actually updates
the cipher list to an empty string as intended. So we need to handle
this special case by clearing the error stack and making sure that our
expectation is satisfied.
Bug: 21195269
Change-Id: Id21792215513f4e0d6e051160f69e5f830d39015/OpenSSLCipher: adjust expected length with padding in decrypt mode
- Consider the |final| buffer when computing the expected length
- Should not expect an extra block when using padding in decrypting
mode
Bug: 19186852
Change-Id: I206442d45c4cf68363201738ba9d0b035f19c436/am 497e87d4: Merge ""NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal"" into mnc-dev
* commit '497e87d447e201ccb142a603c194d6dfb2a33d75':
NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal/Merge ""NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal"" into mnc-dev/am c8d75747: am 49854878: NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal
* commit 'c8d7574776a9b4a6b23372494ef1e520c18fa9e1':
NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal/am 49854878: NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal
* commit '49854878b83114e3e15c7ad3ca030352b786b5df':
NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal/NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal
We need to check the ERR stack on a return code of 0. Previously there
was a comment indicating the weird behavior about DSA keys throwing
after a check for a return value of -1, but this API is never supposed
to return anything other than 1 for success or 0 for failure.
(cherry picked from commit 49854878b83114e3e15c7ad3ca030352b786b5df)
Bug: 18869265
Change-Id: Ic871c63b6d65949053819950ed8053f47501bd60/NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal
We need to check the ERR stack on a return code of 0. Previously there
was a comment indicating the weird behavior about DSA keys throwing
after a check for a return value of -1, but this API is never supposed
to return anything other than 1 for success or 0 for failure.
Bug: 18869265
Change-Id: Ic871c63b6d65949053819950ed8053f47501bd60/am d5d7063d: NativeCrypto: throw exception on RSA op failure
* commit 'd5d7063db8a1f087e07121da667152929daba261':
NativeCrypto: throw exception on RSA op failure/am a6aaa7d8: am 6a1e7070: NativeCrypto: throw exception on RSA op failure
* commit 'a6aaa7d8de93f0b9dc0f6eec03d5613074eb6727':
NativeCrypto: throw exception on RSA op failure/am 6a1e7070: NativeCrypto: throw exception on RSA op failure
* commit '6a1e7070c1cdf23cbce46a8be7b974141028c29a':
NativeCrypto: throw exception on RSA op failure/NativeCrypto: throw exception on RSA op failure
A -1 error code should have an error on the stack that explains what the
problem was, but if we call through to an ENGINE that fails we seem to
end up with no error on the stack. Ensure we throw BadPaddingException
in that case.
(cherry picked from commit 6a1e7070c1cdf23cbce46a8be7b974141028c29a)
Bug: 19863798
Change-Id: Idecd9072c1e6636351bc90f16037852bdc55e4a0/NativeCrypto: throw exception on RSA op failure
A -1 error code should have an error on the stack that explains what the
problem was, but if we call through to an ENGINE that fails we seem to
end up with no error on the stack. Ensure we throw BadPaddingException
in that case.
Bug: 19863798
Change-Id: Idecd9072c1e6636351bc90f16037852bdc55e4a0/Use |BIO_read_asn1| when parsing PKCS#7.
Previously the code read the whole of the BIO and parsed any PKCS#7
blobs that were found. However, X509CertificateTest specifically tests
that trailing data is retained when parsing PKCS#7 so this change makes
it so.
This depends on https://android-review.googlesource.com/#/c/151205/.
(cherry picked from commit 0f84dc6107927c2c5ba15ce5254c93f122837602)
Bug: 21396526
Bug: 21209493
Change-Id: I4e07cebf599f52aedbea9b0a3f66d9a052c86aaa/Add isFinite flag to OpenSSLBIOInputStream.
The BIO created by OpenSSLBIOInputStream currently returns -1 and sets
the retry flag when read() returns zero on the underlying InputStream.
This is correct for infinite streams (like a socket), but isn't
correct for streams that have a definitive EOF.
This change adds a flag to OpenSSLBIOInputStream so that cases where the
input is finite (i.e. when parsing a PKCS#7 or X.509 block) can
correctly return 0 at EOF from |BIO_read|.
(cherry picked from commit 66537ee0121bdd14737191d14927da223f0809ee)
Bug: 21396526
Bug: 21209493
Change-Id: Iaad5845621ab8b89b42d5d3ca8e67e297278ca55/Use |BIO_read_asn1| when parsing PKCS#7.
Previously the code read the whole of the BIO and parsed any PKCS#7
blobs that were found. However, X509CertificateTest specifically tests
that trailing data is retained when parsing PKCS#7 so this change makes
it so.
This depends on https://android-review.googlesource.com/#/c/151205/.
Bug: 21396526
Bug: 21209493
Change-Id: I4e07cebf599f52aedbea9b0a3f66d9a052c86aaa/Add isFinite flag to OpenSSLBIOInputStream.
The BIO created by OpenSSLBIOInputStream currently returns -1 and sets
the retry flag when read() returns zero on the underlying InputStream.
This is correct for infinite streams (like a socket), but isn't
correct for streams that have a definitive EOF.
This change adds a flag to OpenSSLBIOInputStream so that cases where the
input is finite (i.e. when parsing a PKCS#7 or X.509 block) can
correctly return 0 at EOF from |BIO_read|.
Bug: 21396526
Bug: 21209493
Change-Id: Iaad5845621ab8b89b42d5d3ca8e67e297278ca55/am 14a85a16: am bcb2285a: Merge ""Throw InvalidKeyException from ECDH_compute_key""
* commit '14a85a16372ccee423bf28000812b6a8e641f9d8':
Throw InvalidKeyException from ECDH_compute_key/am bcb2285a: Merge ""Throw InvalidKeyException from ECDH_compute_key""
* commit 'bcb2285aa86e7b479f8f224e57a0cb16cfec74d7':
Throw InvalidKeyException from ECDH_compute_key/Merge ""Throw InvalidKeyException from ECDH_compute_key""/Throw InvalidKeyException from ECDH_compute_key
Instead of throwing RuntimeException for ECDH_compute_key failures just
throw an InvalidKeyException since the higher-level API declares that as
a checked exception.
Bug: 21277055
Change-Id: Ieed26ad4f6cb76a49a7edb77bb3b1da7ae88043b/am 1eec6164: am 7c5b76c9: Stop printing out private key parameters
* commit '1eec6164e015c1b25897007d967e3a5adaae1ffa':
Stop printing out private key parameters/am 7c5b76c9: Stop printing out private key parameters
* commit '7c5b76c986eb699e57c2018b3f86541333a3d2cb':
Stop printing out private key parameters/Stop printing out private key parameters
This could lead to an inadvertent leak of the private key parameters and
is only useful for debugging, so just remove it.
Bug: 21277110
Change-Id: Id7bfa376935e610cc58e8c7882d4634cfda8f7ce/"
conscrypt,"am 497e87d4: Merge ""NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal"" into mnc-dev
* commit '497e87d447e201ccb142a603c194d6dfb2a33d75':
NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal/Merge ""NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal"" into mnc-dev/am c8d75747: am 49854878: NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal
* commit 'c8d7574776a9b4a6b23372494ef1e520c18fa9e1':
NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal/am 49854878: NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal
* commit '49854878b83114e3e15c7ad3ca030352b786b5df':
NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal/NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal
We need to check the ERR stack on a return code of 0. Previously there
was a comment indicating the weird behavior about DSA keys throwing
after a check for a return value of -1, but this API is never supposed
to return anything other than 1 for success or 0 for failure.
(cherry picked from commit 49854878b83114e3e15c7ad3ca030352b786b5df)
Bug: 18869265
Change-Id: Ic871c63b6d65949053819950ed8053f47501bd60/NativeCrypto: return of 0 is error for EVP_Sign/VerifyFinal
We need to check the ERR stack on a return code of 0. Previously there
was a comment indicating the weird behavior about DSA keys throwing
after a check for a return value of -1, but this API is never supposed
to return anything other than 1 for success or 0 for failure.
Bug: 18869265
Change-Id: Ic871c63b6d65949053819950ed8053f47501bd60/"
conscrypt,"am 6fd6f862: am 05b39385: Merge changes I960960c3,Ifc556ba6,I34b9d839
* commit '6fd6f8620f883387f2b24c9654dfbabf76c3c591':
Update CryptoUpcalls documentation
Documentation fixes
OpenSSLCipher: remove unused variable/am 05b39385: Merge changes I960960c3,Ifc556ba6,I34b9d839
* commit '05b393852f1f6f5529ee454503dfd2c795e64330':
Update CryptoUpcalls documentation
Documentation fixes
OpenSSLCipher: remove unused variable/Merge changes I960960c3,Ifc556ba6,I34b9d839
* changes:
Update CryptoUpcalls documentation
Documentation fixes
OpenSSLCipher: remove unused variable/Documentation fixes
Although we don't currently publish this to javadoc, we should keep
javadoc conventions by inserting paragraph separators here.
Change-Id: Ifc556ba6da74f32dafe3e4891ce3a34eccb59ae6/OpenSSLCipher: adjust expected length with padding in decrypt mode
- Consider the |final| buffer when computing the expected length
- Should not expect an extra block when using padding in decrypting
mode
Bug: 19186852
Change-Id: I8c51b309ca98030ab1eda5b2a0201a97a5758072
(cherry-pick from 8fa4acdcf1e47a2745940694179fa34e95825a24)/OpenSSLCipher: adjust expected length with padding in decrypt mode
- Consider the |final| buffer when computing the expected length
- Should not expect an extra block when using padding in decrypting
mode
Bug: 19186852
Change-Id: I206442d45c4cf68363201738ba9d0b035f19c436/Add isFinite flag to OpenSSLBIOInputStream.
The BIO created by OpenSSLBIOInputStream currently returns -1 and sets
the retry flag when read() returns zero on the underlying InputStream.
This is correct for infinite streams (like a socket), but isn't
correct for streams that have a definitive EOF.
This change adds a flag to OpenSSLBIOInputStream so that cases where the
input is finite (i.e. when parsing a PKCS#7 or X.509 block) can
correctly return 0 at EOF from |BIO_read|.
(cherry picked from commit 66537ee0121bdd14737191d14927da223f0809ee)
Bug: 21396526
Bug: 21209493
Change-Id: Iaad5845621ab8b89b42d5d3ca8e67e297278ca55/Add isFinite flag to OpenSSLBIOInputStream.
The BIO created by OpenSSLBIOInputStream currently returns -1 and sets
the retry flag when read() returns zero on the underlying InputStream.
This is correct for infinite streams (like a socket), but isn't
correct for streams that have a definitive EOF.
This change adds a flag to OpenSSLBIOInputStream so that cases where the
input is finite (i.e. when parsing a PKCS#7 or X.509 block) can
correctly return 0 at EOF from |BIO_read|.
Bug: 21396526
Bug: 21209493
Change-Id: Iaad5845621ab8b89b42d5d3ca8e67e297278ca55/am 14a85a16: am bcb2285a: Merge ""Throw InvalidKeyException from ECDH_compute_key""
* commit '14a85a16372ccee423bf28000812b6a8e641f9d8':
Throw InvalidKeyException from ECDH_compute_key/am bcb2285a: Merge ""Throw InvalidKeyException from ECDH_compute_key""
* commit 'bcb2285aa86e7b479f8f224e57a0cb16cfec74d7':
Throw InvalidKeyException from ECDH_compute_key/Merge ""Throw InvalidKeyException from ECDH_compute_key""/Throw InvalidKeyException from ECDH_compute_key
Instead of throwing RuntimeException for ECDH_compute_key failures just
throw an InvalidKeyException since the higher-level API declares that as
a checked exception.
Bug: 21277055
Change-Id: Ieed26ad4f6cb76a49a7edb77bb3b1da7ae88043b/am 1eec6164: am 7c5b76c9: Stop printing out private key parameters
* commit '1eec6164e015c1b25897007d967e3a5adaae1ffa':
Stop printing out private key parameters/am 7c5b76c9: Stop printing out private key parameters
* commit '7c5b76c986eb699e57c2018b3f86541333a3d2cb':
Stop printing out private key parameters/Stop printing out private key parameters
This could lead to an inadvertent leak of the private key parameters and
is only useful for debugging, so just remove it.
Bug: 21277110
Change-Id: Id7bfa376935e610cc58e8c7882d4634cfda8f7ce/"
conscrypt,"GCM: set default tag size to 12 bytes
According to RFC 5084, the default value of the GCM tag should be 12
octets (bytes). Change the default tag length from 0 to 12 to honor
this.
Bug: 22855843
Change-Id: I1ed16df24d0cfa9fff2593a3402c97faf913e05e/GCM: return the correct AlgorithmParameters
Instead of the correct AlgorithmParameters of type ""GCM,"" we were
returning the generic ""AES"" version that basically only converts to an
IvParameterSpec.
Bug: 22319986
Change-Id: Ib42905c3ad31e44b72e8066192bd26981c8351ba/am 6fd6f862: am 05b39385: Merge changes I960960c3,Ifc556ba6,I34b9d839
* commit '6fd6f8620f883387f2b24c9654dfbabf76c3c591':
Update CryptoUpcalls documentation
Documentation fixes
OpenSSLCipher: remove unused variable/am 05b39385: Merge changes I960960c3,Ifc556ba6,I34b9d839
* commit '05b393852f1f6f5529ee454503dfd2c795e64330':
Update CryptoUpcalls documentation
Documentation fixes
OpenSSLCipher: remove unused variable/Merge changes I960960c3,Ifc556ba6,I34b9d839
* changes:
Update CryptoUpcalls documentation
Documentation fixes
OpenSSLCipher: remove unused variable/OpenSSLCipher: adjust expected length with padding in decrypt mode
- Consider the |final| buffer when computing the expected length
- Should not expect an extra block when using padding in decrypting
mode
Bug: 19186852
Change-Id: I8c51b309ca98030ab1eda5b2a0201a97a5758072
(cherry-pick from 8fa4acdcf1e47a2745940694179fa34e95825a24)/OpenSSLCipher: adjust expected length with padding in decrypt mode
- Consider the |final| buffer when computing the expected length
- Should not expect an extra block when using padding in decrypting
mode
Bug: 19186852
Change-Id: I206442d45c4cf68363201738ba9d0b035f19c436/OpenSSLCipher: adjust expected length with padding in decrypt mode
Should not expect an extra block when using padding in decrypting
mode
Bug: 19186852
Change-Id: Ife346931e4ba2c8e3a99e066caee91267b1d138f/"
conscrypt,"Adjust Signature interface for BoringSSL
BoringSSL will push the BAD_SIGNATURE error onto the stack for every
signature error. In Java it just returns false from the Signature#verify
call when the signature is incorrect.  However, we still want to throw
an exception for raw RSA when the number of signature bytes is larger
than the modulus can express.
Bug: 21209646
(cherry picked from commit 089b401856a4da378875e94108fe742d1cdf0db2)
Change-Id: I96ada8762817a99df11da2f7e7b7310bb31d5cba/Adjust Signature interface for BoringSSL
BoringSSL will push the BAD_SIGNATURE error onto the stack for every
signature error. In Java it just returns false from the Signature#verify
call when the signature is incorrect.  However, we still want to throw
an exception for raw RSA when the number of signature bytes is larger
than the modulus can express.
Bug: 21209646
Change-Id: Ie29eba8b12bb8d3220b7b29146c45b8dd416e338/"
conscrypt,"Use duck typing for checkServerTrusted
Instead of casting to the platform TrustManagerImpl to call
checkServerTrusted(X509Certificate[], String, String) use reflection to
instead lookup the method on the X509TrustManager and use it if present
otherwise fall back to checkServerTrusted(X509Certificate[], String).
Change-Id: Ia9893cc4ac0e9f844246624723ae9cb33101e85b/Merge AOSP version of Conscrypt into mnc-ub-dev
This adds support for the latest BoringSSL revision and fixes quite a
few bugs.
Change-Id: I6eafb04d7c15d3b365191d1fe2fe107308cea894/Move BlockGuard and CloseGuard to Platform
This was causing issues on Gingerbread devices since CloseGuard was not
in that release yet. Move them out to Platform so we can filter on
release when we decide whether to instantiate or not.
(cherry picked from commit 126ec77aacd58c8b5d62d433af65386fa3dd3fc1)
Bug: 24607028
Change-Id: Iba0bbb0b878076319ace40f848aa5e307e2c3ad8/Move BlockGuard and CloseGuard to Platform
This was causing issues on Gingerbread devices since CloseGuard was not
in that release yet. Move them out to Platform so we can filter on
release when we decide whether to instantiate or not.
Bug: 24607028
Change-Id: Iba0bbb0b878076319ace40f848aa5e307e2c3ad8/"
conscrypt,"Merge AOSP version of Conscrypt into mnc-ub-dev
This adds support for the latest BoringSSL revision and fixes quite a
few bugs.
Change-Id: I6eafb04d7c15d3b365191d1fe2fe107308cea894/"
conscrypt,"Use duck typing for checkServerTrusted
Instead of casting to the platform TrustManagerImpl to call
checkServerTrusted(X509Certificate[], String, String) use reflection to
instead lookup the method on the X509TrustManager and use it if present
otherwise fall back to checkServerTrusted(X509Certificate[], String).
Change-Id: Ia9893cc4ac0e9f844246624723ae9cb33101e85b/Merge AOSP version of Conscrypt into mnc-ub-dev
This adds support for the latest BoringSSL revision and fixes quite a
few bugs.
Change-Id: I6eafb04d7c15d3b365191d1fe2fe107308cea894/Move BlockGuard and CloseGuard to Platform
This was causing issues on Gingerbread devices since CloseGuard was not
in that release yet. Move them out to Platform so we can filter on
release when we decide whether to instantiate or not.
(cherry picked from commit 126ec77aacd58c8b5d62d433af65386fa3dd3fc1)
Bug: 24607028
Change-Id: Iba0bbb0b878076319ace40f848aa5e307e2c3ad8/Move BlockGuard and CloseGuard to Platform
This was causing issues on Gingerbread devices since CloseGuard was not
in that release yet. Move them out to Platform so we can filter on
release when we decide whether to instantiate or not.
Bug: 24607028
Change-Id: Iba0bbb0b878076319ace40f848aa5e307e2c3ad8/"
conscrypt,"Unbreak Conscrypt when it's built against OpenSSL.
(cherry picked from commit 179e1d5f63fdc69f35e755d3fe34f9e93168a71f)
Change-Id: I28c6f123fa3bbe084bdee4a4615a67ca7319234e/Make EVP_DigestSignFinal throw when signature too big.
This fixes NativeCrypto.EVP_DigestSignFinal to unconditionally throw a
RuntimeException when the generated signature is larger than expected.
Change-Id: I56d77adbb0cbc004d941a2cfcb30482450a1ddbf/Unbreak Conscrypt when it's built against OpenSSL.
Change-Id: I28c6f123fa3bbe084bdee4a4615a67ca7319234e/Revert ""external/conscrypt: drop BORINGSSL_201510 ifdefs.""
This breaks the unbundled build with OpenSSL.
This reverts commit f1754f30b818d8e67800322f24e8f6c623890861.
(cherry picked from commit da909c2a58445e7a9b623196ad5f7bc88ad7c0e8)
Change-Id: I2f3098414004aeb3f019c28bf0a0085a9d7eb3cc/Clear BoringSSL error queue in NativeCrypto.EVP_DigestVerifyFinal.
am: 881c0953d7
* commit '881c0953d7166a5020ba2ec2b6f8c39371a6ded6':
Clear BoringSSL error queue in NativeCrypto.EVP_DigestVerifyFinal./Revert ""external/conscrypt: drop BORINGSSL_201510 ifdefs.""
This breaks the unbundled build with OpenSSL.
This reverts commit f1754f30b818d8e67800322f24e8f6c623890861.
Change-Id: I2f3098414004aeb3f019c28bf0a0085a9d7eb3cc/Clear BoringSSL error queue in NativeCrypto.EVP_DigestVerifyFinal.
This fixes a bug introduced in
b4345a619c1f34e2390210d11476a8619cebd695 where
NativeCrypto.EVP_DigestVerifyFinal left the BAD_SIGNATURE error in the
BoringSSL error queue when a signature did not verify. Some of the
following NativeCrypto operations would then fail because they assumed
that it was their BoringSSL calls that generated the BAD_SIGNATURE
error.
The fix is to unconditionally clear the BoringSSL error queue at the
end of NativeCrypto.EVP_DigestVerifyFinal, same as its predecessor
NativeCrypto.EVP_VerifyFinal did.
Change-Id: I0d092b1b39afa3c6d19a785cbf7dd311ffcd4c04/Merge ""Speed up digesting by avoiding unnecessary operations.""
am: 22324dd963
* commit '22324dd9635b9a7fa0b0e524a9313bba524db3ad':
Speed up digesting by avoiding unnecessary operations./Merge ""Speed up digesting by avoiding unnecessary operations.""/Speed up digesting by avoiding unnecessary operations.
Conscrypt's MessageDigest implementations at the end of computing a
digest create and initialize a new EVP_MD_CTX and then also intialize
the digest struct there. This is done because the MessageDigest
instance could be reused for a new digesting session.
This change implements three optimizations:
1. MessageDigestSpi now reuses its EVP_MD_CTX instead of creating a
new one for each new digesting session.
2. MessageDigestSpi now defers the initialization of the digest struct
in EVP_MD_CTX till the first invocation of
engineUpdate/engineDigest.
3. MessagDigestSpi (and SignatureSpi) no longer invoke EVP_MD_CTX_init
after EVP_MD_CTX_create because EVP_MD_CTX_create initializes the
EVP_MD_CTX it creates.
libcore's MessageDigestBenchmark on Nexus 5 shows:
* 10-15% faster performance for a single digest of 8192 bytes.
* 15-20% faster performance for reusing a MessageDigest instance to
compute a digest of 8192 bytes ten times.
Change-Id: I8a0697310ef7efcd4db6870e54eb46102fd4a941/Use poll() instead of select()
Since select() has a limit of FD_SETSIZE (typically 1024 on Linux
systems) for the highest fd number it will accept, switch to poll()
instead to avoid these problems when the app Conscrypt is running under
is opening a large amount of file descriptors.
Bug: 25390062
Change-Id: Id54a9cc9379e8db8facd2136e84e9e6fd1f5b0f9/Zero-copy HMAC and signing/verification for direct ByteBuffer.
Prior to this change, Conscrypt's Mac and Signature implementations
copied the contents of direct ByteBuffer inputs. This change
implements an optimization which avoids the allocation and copying of
contents of direct ByteBuffer inputs.
Bug: 24674857
Change-Id: I1436839182483fd42318d4b0af4d633283e3453d/Zero-copy digesting for direct ByteBuffer input.
Prior to this change, Conscrypt's MessageDigest.update(ByteBuffer)
invoked for a direct ByteBuffer resulted in the creation of a new
byte[] of size ByteBuffer.remaining() and the copying of the
ByteBuffer's contents into that array.
This change implements an optimization which avoids the allocation
and copying, by making BoringSSL EVP_DigestUpdate read directly from
the memory region represented by the direct ByteBuffer.
Change-Id: I112d318128402d1d78e226df9dfe54af55955953/Merge AOSP version of Conscrypt into mnc-ub-dev
This adds support for the latest BoringSSL revision and fixes quite a
few bugs.
Change-Id: I6eafb04d7c15d3b365191d1fe2fe107308cea894/Prepare for BoringSSL update.
This change tweaks things as needed so that the code will compile
against both the BoringSSL that's currently in Android and a version
from upstream. The BORINGSSL_201509 define is temporary to allow the
switch to happen without breaking the build and a followup change will
remove it.
(cherry picked from commit f417aca8ffd57b3817bb24d5a58e01873eecfbde)
Change-Id: Ie60d8fc4d88154feaca8ab5ea85645b78a85640f/am d593e6ca: am 79309ee8: am 8acb72c0: Fix typo in previous checkin
* commit 'd593e6ca603fa3a073e9613367dd5ab90d5c5876':
Fix typo in previous checkin/am 79309ee8: am 8acb72c0: Fix typo in previous checkin
* commit '79309ee8b8d071713d7464f513898a33221b6b31':
Fix typo in previous checkin/am 8acb72c0: Fix typo in previous checkin
* commit '8acb72c0bdfdf3a19245f85cfb61d122c4d418b3':
Fix typo in previous checkin/Fix typo in previous checkin
There are still a few builds that use OpenSSL, but it's only tested on
BoringSSL by default. A character transposition caused this to fail on
OpenSSL only.
Change-Id: I1b07211a4dbe7dc2e134ce8ddba4b1cfdf627b71/Prepare for BoringSSL update.
This change tweaks things as needed so that the code will compile
against both the BoringSSL that's currently in Android and a version
from upstream. The BORINGSSL_201509 define is temporary to allow the
switch to happen without breaking the build and a followup change will
remove it.
Change-Id: Ie60d8fc4d88154feaca8ab5ea85645b78a85640f/external/conscrypt: allow server-initiated renegotiations.
BoringSSL disables server-initiated renegotiations by default. However,
it's unclear what the impact of this will be. On the other hand,
rejecting renegotiations certainly makes things simplier.
(cherry picked from commit ed628f94df430278a203da28055b309346b0bce2)
Bug: 23189319
Change-Id: I0cd3f04838c0afea665a88d4f0cd0a16c1e811de/"
conscrypt,"Merge AOSP version of Conscrypt into mnc-ub-dev
This adds support for the latest BoringSSL revision and fixes quite a
few bugs.
Change-Id: I6eafb04d7c15d3b365191d1fe2fe107308cea894/"
conscrypt,"Merge ""Speed up digesting by avoiding unnecessary operations.""
am: 22324dd963
* commit '22324dd9635b9a7fa0b0e524a9313bba524db3ad':
Speed up digesting by avoiding unnecessary operations./Merge ""Speed up digesting by avoiding unnecessary operations.""/Speed up digesting by avoiding unnecessary operations.
Conscrypt's MessageDigest implementations at the end of computing a
digest create and initialize a new EVP_MD_CTX and then also intialize
the digest struct there. This is done because the MessageDigest
instance could be reused for a new digesting session.
This change implements three optimizations:
1. MessageDigestSpi now reuses its EVP_MD_CTX instead of creating a
new one for each new digesting session.
2. MessageDigestSpi now defers the initialization of the digest struct
in EVP_MD_CTX till the first invocation of
engineUpdate/engineDigest.
3. MessagDigestSpi (and SignatureSpi) no longer invoke EVP_MD_CTX_init
after EVP_MD_CTX_create because EVP_MD_CTX_create initializes the
EVP_MD_CTX it creates.
libcore's MessageDigestBenchmark on Nexus 5 shows:
* 10-15% faster performance for a single digest of 8192 bytes.
* 15-20% faster performance for reusing a MessageDigest instance to
compute a digest of 8192 bytes ten times.
Change-Id: I8a0697310ef7efcd4db6870e54eb46102fd4a941/Zero-copy HMAC and signing/verification for direct ByteBuffer.
Prior to this change, Conscrypt's Mac and Signature implementations
copied the contents of direct ByteBuffer inputs. This change
implements an optimization which avoids the allocation and copying of
contents of direct ByteBuffer inputs.
Bug: 24674857
Change-Id: I1436839182483fd42318d4b0af4d633283e3453d/"
conscrypt,"Merge ""Speed up digesting by avoiding unnecessary operations.""
am: 22324dd963
* commit '22324dd9635b9a7fa0b0e524a9313bba524db3ad':
Speed up digesting by avoiding unnecessary operations./Merge ""Speed up digesting by avoiding unnecessary operations.""/Speed up digesting by avoiding unnecessary operations.
Conscrypt's MessageDigest implementations at the end of computing a
digest create and initialize a new EVP_MD_CTX and then also intialize
the digest struct there. This is done because the MessageDigest
instance could be reused for a new digesting session.
This change implements three optimizations:
1. MessageDigestSpi now reuses its EVP_MD_CTX instead of creating a
new one for each new digesting session.
2. MessageDigestSpi now defers the initialization of the digest struct
in EVP_MD_CTX till the first invocation of
engineUpdate/engineDigest.
3. MessagDigestSpi (and SignatureSpi) no longer invoke EVP_MD_CTX_init
after EVP_MD_CTX_create because EVP_MD_CTX_create initializes the
EVP_MD_CTX it creates.
libcore's MessageDigestBenchmark on Nexus 5 shows:
* 10-15% faster performance for a single digest of 8192 bytes.
* 15-20% faster performance for reusing a MessageDigest instance to
compute a digest of 8192 bytes ten times.
Change-Id: I8a0697310ef7efcd4db6870e54eb46102fd4a941/Zero-copy HMAC and signing/verification for direct ByteBuffer.
Prior to this change, Conscrypt's Mac and Signature implementations
copied the contents of direct ByteBuffer inputs. This change
implements an optimization which avoids the allocation and copying of
contents of direct ByteBuffer inputs.
Bug: 24674857
Change-Id: I1436839182483fd42318d4b0af4d633283e3453d/Zero-copy digesting for direct ByteBuffer input.
Prior to this change, Conscrypt's MessageDigest.update(ByteBuffer)
invoked for a direct ByteBuffer resulted in the creation of a new
byte[] of size ByteBuffer.remaining() and the copying of the
ByteBuffer's contents into that array.
This change implements an optimization which avoids the allocation
and copying, by making BoringSSL EVP_DigestUpdate read directly from
the memory region represented by the direct ByteBuffer.
Change-Id: I112d318128402d1d78e226df9dfe54af55955953/Merge AOSP version of Conscrypt into mnc-ub-dev
This adds support for the latest BoringSSL revision and fixes quite a
few bugs.
Change-Id: I6eafb04d7c15d3b365191d1fe2fe107308cea894/external/conscrypt: allow server-initiated renegotiations.
BoringSSL disables server-initiated renegotiations by default. However,
it's unclear what the impact of this will be. On the other hand,
rejecting renegotiations certainly makes things simplier.
(cherry picked from commit ed628f94df430278a203da28055b309346b0bce2)
Bug: 23189319
Change-Id: I0cd3f04838c0afea665a88d4f0cd0a16c1e811de/"
conscrypt,"Merge AOSP version of Conscrypt into mnc-ub-dev
This adds support for the latest BoringSSL revision and fixes quite a
few bugs.
Change-Id: I6eafb04d7c15d3b365191d1fe2fe107308cea894/"
conscrypt,"Merge AOSP version of Conscrypt into mnc-ub-dev
This adds support for the latest BoringSSL revision and fixes quite a
few bugs.
Change-Id: I6eafb04d7c15d3b365191d1fe2fe107308cea894/"
conscrypt,"Merge AOSP version of Conscrypt into mnc-ub-dev
This adds support for the latest BoringSSL revision and fixes quite a
few bugs.
Change-Id: I6eafb04d7c15d3b365191d1fe2fe107308cea894/Move BlockGuard and CloseGuard to Platform
This was causing issues on Gingerbread devices since CloseGuard was not
in that release yet. Move them out to Platform so we can filter on
release when we decide whether to instantiate or not.
(cherry picked from commit 126ec77aacd58c8b5d62d433af65386fa3dd3fc1)
Bug: 24607028
Change-Id: Iba0bbb0b878076319ace40f848aa5e307e2c3ad8/Move BlockGuard and CloseGuard to Platform
This was causing issues on Gingerbread devices since CloseGuard was not
in that release yet. Move them out to Platform so we can filter on
release when we decide whether to instantiate or not.
Bug: 24607028
Change-Id: Iba0bbb0b878076319ace40f848aa5e307e2c3ad8/external/conscrypt: allow server-initiated renegotiations.
BoringSSL disables server-initiated renegotiations by default. However,
it's unclear what the impact of this will be. On the other hand,
rejecting renegotiations certainly makes things simplier.
(cherry picked from commit ed628f94df430278a203da28055b309346b0bce2)
Bug: 23189319
Change-Id: I0cd3f04838c0afea665a88d4f0cd0a16c1e811de/"
conscrypt,"Add getFileDescriptor$ call for compat
Newer Android versions have implemented getFileDescriptor$ to fix a bug
in Conscrypt since libcore commit
5d3f5200f3511c9a7107bcc0a996c7afa1b39aaf which has continued to do the
right thing. Use this method instead since newer versions don't
necessarily set the ""impl"" field on Socket instances.
Bug: 25857624
Change-Id: I64fbda844ea3b632023822f1436bd674852e327a/Revert ""Add ExtendedSSLSession, et al.""
This reverts commit 38d12ed4a7f6f7628120d0ef45ff29d472337102.
This breaks the unbundled build because of OpenSSLExtendedSessionImpl.
Change-Id: I73951a6f1d5cb14c70cd807c2c895bbbdc4c8e40/Revert ""Fix for OpenJdk SocketImpl.""
This reverts commit da2733a716be6ef2325229dd372d17744daa6311.
The OpenJdk implementation has been changed.
Bug: 25805791/Fix for OpenJdk SocketImpl.
OpenJdk sockets start their life with a null FileDescriptor.
b/25805791 tracks fixing the SocketImpl
Change-Id: Ia14afda04aa0a109f944c549719ad50bb3aeadab/"
conscrypt,"TrustManagerImplTest: instantiate TrustManagerImpl directly instead of using factory
The TrustManagerFactory is returning a RootTrustManager now instead of a TrustManagerImpl,
thus breaking the test.
Bug: 25992791
Change-Id: I5924b684a9c3f8c49818ceefb038886035a17f68/Remove java.lang.IntegralToString usage.
java.lang.IntegralToString is going away, replaced
its usage by small helper class, Hex.
+
Fixes the ""Illegal class access"" exception from
TrustedCertificateStoreTest & TrustManagerImplTest.
(cherry-picked from 61e984f441b9194f0ae907e6fc28502858df6852 +
61e984f441b9194f0ae907e6fc28502858df6852)
Bug: 24932279
(cherry picked from commit e279a9854d15d20a0b3807fe96f0805b43cd4dae)
Change-Id: Id48cd9c2dfade328f01c669afa20fe2e7a630fc2/Remove java.lang.IntegralToString usage.
java.lang.IntegralToString is going away, replaced
its usage by small helper class, Hex.
+
Fixes the ""Illegal class access"" exception from
TrustedCertificateStoreTest & TrustManagerImplTest.
(cherry-picked from 61e984f441b9194f0ae907e6fc28502858df6852 +
61e984f441b9194f0ae907e6fc28502858df6852)
Bug: 24932279
Change-Id: I83bc9543e44e3d1026fa5b0a31b8097bb3838ab3/"
conscrypt,"Track False Start change in tests
In BoringSSL, the SSL_MODE_ENABLE_FALSE_START (aka
SSL_MODE_HANDSHAKE_CUTTHROUGH) is unconditionally enabled because
BoringSSL does the appropriate checks internally. Make sure our tests
also reflect this fact by testing the appropriate settings.
Bug: 26139262
Bug: 26139500
Change-Id: I125aa440cdb76d2efbfee2be7387b47d22446950/"
conscrypt,"Cache intermediate CA separately
Intermediate CAs are cached in order to support servers that fail to
sent a complete chain to a root. These certificates should be cached to
support these servers but these certificates must not be trusted as
trust anchors. Store them separately to prevent confusion between
trusted roots and cached intermediates.
(cherry-picked from commit 198aca1fb638a2a98e89fb9f284108ad576d0c3b)
Bug: 26232830
Change-Id: I520f50729b55fc7412c7d133335bc9e3c190bbf6/Cache intermediate CA separately
Intermediate CAs are cached in order to support servers that fail to
sent a complete chain to a root. These certificates should be cached to
support these servers but these certificates must not be trusted as
trust anchors. Store them separately to prevent confusion between
trusted roots and cached intermediates.
Bug: 26232830
Change-Id: I520f50729b55fc7412c7d133335bc9e3c190bbf6/"
conscrypt,"Revert ""Add ExtendedSSLSession, et al.""
This reverts commit 38d12ed4a7f6f7628120d0ef45ff29d472337102.
This breaks the unbundled build because of OpenSSLExtendedSessionImpl.
Change-Id: I73951a6f1d5cb14c70cd807c2c895bbbdc4c8e40/Revert ""Fix for OpenJdk SocketImpl.""
This reverts commit da2733a716be6ef2325229dd372d17744daa6311.
The OpenJdk implementation has been changed.
Bug: 25805791/Fix for OpenJdk SocketImpl.
OpenJdk sockets start their life with a null FileDescriptor.
b/25805791 tracks fixing the SocketImpl
Change-Id: Ia14afda04aa0a109f944c549719ad50bb3aeadab/"
conscrypt,"Make OpenSSLX509Certificate.hashCode match the RI
Use super.hashCode to make sure that hashCode matches the RI. Since the
underlying certificate (and therefore the hashcode) is immutable the
value is cached after the first call to avoid needlessly recomputing the
hash.
Bug:26386620
Change-Id: Ic480b48e57144ac730a33dcc313cdff57fe71157/Fix unneccessary access of BoringSSL SSL structs. am: 883eeb452d
am: 3907bf0602
* commit '3907bf06025a27856f83fa377f57c28f60738e45':
Fix unneccessary access of BoringSSL SSL structs./Fix unneccessary access of BoringSSL SSL structs.
am: 883eeb452d
* commit '883eeb452dc0aa01f74a426e8084e2af66daaad4':
Fix unneccessary access of BoringSSL SSL structs./Fix unneccessary access of BoringSSL SSL structs.
get_SSL_CIPHER_algorithm_mkey and get_SSL_CIPHER_algorithm_auth are never used.
There are also some struct accesses that have public API variants. Finally,
requiring ssl->server be set to 0 before SSL_set1_tls_channel_id was a bug that
has been fixed in BoringSSL. (See
https://boringssl.googlesource.com/boringssl/+/a3d9de05fb6df2c0dffab83717139e6c71d3d329/ssl/s3_lib.c#337)
Change-Id: If68efce2901f3ef89bdf5bb47cbc7d5fddaa6ef6/Fix Signature.sign broken on x86_64.
am: 273e944b63
* commit '273e944b63ee54f13fd96322313e7c98a9c375d2':
Fix Signature.sign broken on x86_64./Fix compilation with JNI_TRACE_**
am: 4d1b7f23cb
* commit '4d1b7f23cb6b1480efd31de731e92363d86329f0':
Fix compilation with JNI_TRACE_**/Unbreak Conscrypt when it\'s built against OpenSSL.
am: 179e1d5f63
* commit '179e1d5f63fdc69f35e755d3fe34f9e93168a71f':
Unbreak Conscrypt when it's built against OpenSSL./Clear BoringSSL error queue in NativeCrypto.EVP_DigestVerifyFinal.
am: 881c0953d7
* commit '881c0953d7166a5020ba2ec2b6f8c39371a6ded6':
Clear BoringSSL error queue in NativeCrypto.EVP_DigestVerifyFinal./Merge ""Speed up digesting by avoiding unnecessary operations.""
am: 22324dd963
* commit '22324dd9635b9a7fa0b0e524a9313bba524db3ad':
Speed up digesting by avoiding unnecessary operations./Fix Signature.sign broken on x86_64.
am: 273e944b63
* commit '273e944b63ee54f13fd96322313e7c98a9c375d2':
Fix Signature.sign broken on x86_64./Fix Signature.sign broken on x86_64.
Conscrypt's Signature impl's sign() method invoked EVP_DigestSignFinal
with an uninitialized length of the output buffer. I misread the
method's documentation and assumed that the output buffer length does
not need to be initialized because it's an output-only parameter.
However, the parameter is an in-out parameter. This change fixes the
issue by initializing the parameter to the correct value.
Change-Id: Id5e205f185b9edf7189c26d0dd2f5a7c84e7c1c1/Fix compilation with JNI_TRACE_**
am: 4d1b7f23cb
* commit '4d1b7f23cb6b1480efd31de731e92363d86329f0':
Fix compilation with JNI_TRACE_**/Fix compilation with JNI_TRACE_**
Change-Id: I8417daea4b10f8c02642fe6c9be170312461139c/Remove remnants of DH key support.
7a1929018f423157f9e85dbf368e0b30561c5915 removed most of it, but remnants in
NativeCrypto remained with no callers. Although the APIs are still present in
BoringSSL, they always fail.
Change-Id: Iaff8a142774095e24f08a512956e05272b681b70/Basic implementation of RSASSA-PSS Signature.
This makes Conscrypt provide RSASSA-PSS Signature implementations.
These implementations currently do not support changing their
parameters (e.g., via Signature.setParameter(PSSParameterSpec)) and
returning their current parameters (e.g., via
Signature.getParameters()). This will be added in a follow-up change.
Bug: 25794302
Change-Id: I1488e0e9592f92a9e15365131c76ce2902ad4607/"
conscrypt,"Merge ""Fix sanity checks around direct ByteBuffer memory access.""
am: 4a41ff4a4e
* commit '4a41ff4a4e7d07be60fcf2357a3df6ce8f2f3724':
Fix sanity checks around direct ByteBuffer memory access./Merge ""Speed up digesting by avoiding unnecessary operations.""
am: 22324dd963
* commit '22324dd9635b9a7fa0b0e524a9313bba524db3ad':
Speed up digesting by avoiding unnecessary operations./Merge ""Fix sanity checks around direct ByteBuffer memory access.""
am: 4a41ff4a4e
* commit '4a41ff4a4e7d07be60fcf2357a3df6ce8f2f3724':
Fix sanity checks around direct ByteBuffer memory access./Merge ""Fix sanity checks around direct ByteBuffer memory access.""/Fix sanity checks around direct ByteBuffer memory access.
This fixes the sanity checks around access to memory backing direct
BytBuffer instances. The previous checks would've erronously failed
if pointers crossed the 2^63 boundary. There is no need for check for
pointer overflow.
Bug: 24674857
Change-Id: Ic8b5a651418c401d32eb0c8053217988963cd326/Support for PSS Signature configuration via PSSParameterSpec.
This adds support for configuring the PSS Signature implementation
via java.security.spec.PSSParameterSpec. This also makes the
signature implementation return its current configuration as
AlgorithmParameters of algorithm ""PSS"" from which a PSSParameterSpec
can be obtained.
Bug: 25794302
Change-Id: Ib7e087cdc75a6b02898afafdfc4308802d6eb5d5/Basic implementation of RSASSA-PSS Signature.
This makes Conscrypt provide RSASSA-PSS Signature implementations.
These implementations currently do not support changing their
parameters (e.g., via Signature.setParameter(PSSParameterSpec)) and
returning their current parameters (e.g., via
Signature.getParameters()). This will be added in a follow-up change.
Bug: 25794302
Change-Id: I1488e0e9592f92a9e15365131c76ce2902ad4607/"
conscrypt,"Make OpenSSLX509Certificate.hashCode match the RI
Use super.hashCode to make sure that hashCode matches the RI. Since the
underlying certificate (and therefore the hashcode) is immutable the
value is cached after the first call to avoid needlessly recomputing the
hash.
Bug:26386620
Change-Id: Ic480b48e57144ac730a33dcc313cdff57fe71157/Fix unneccessary access of BoringSSL SSL structs. am: 883eeb452d
am: 3907bf0602
* commit '3907bf06025a27856f83fa377f57c28f60738e45':
Fix unneccessary access of BoringSSL SSL structs./Fix unneccessary access of BoringSSL SSL structs.
am: 883eeb452d
* commit '883eeb452dc0aa01f74a426e8084e2af66daaad4':
Fix unneccessary access of BoringSSL SSL structs./Fix unneccessary access of BoringSSL SSL structs.
get_SSL_CIPHER_algorithm_mkey and get_SSL_CIPHER_algorithm_auth are never used.
There are also some struct accesses that have public API variants. Finally,
requiring ssl->server be set to 0 before SSL_set1_tls_channel_id was a bug that
has been fixed in BoringSSL. (See
https://boringssl.googlesource.com/boringssl/+/a3d9de05fb6df2c0dffab83717139e6c71d3d329/ssl/s3_lib.c#337)
Change-Id: If68efce2901f3ef89bdf5bb47cbc7d5fddaa6ef6/Merge ""Speed up digesting by avoiding unnecessary operations.""
am: 22324dd963
* commit '22324dd9635b9a7fa0b0e524a9313bba524db3ad':
Speed up digesting by avoiding unnecessary operations./Remove remnants of DH key support.
7a1929018f423157f9e85dbf368e0b30561c5915 removed most of it, but remnants in
NativeCrypto remained with no callers. Although the APIs are still present in
BoringSSL, they always fail.
Change-Id: Iaff8a142774095e24f08a512956e05272b681b70/Basic implementation of RSASSA-PSS Signature.
This makes Conscrypt provide RSASSA-PSS Signature implementations.
These implementations currently do not support changing their
parameters (e.g., via Signature.setParameter(PSSParameterSpec)) and
returning their current parameters (e.g., via
Signature.getParameters()). This will be added in a follow-up change.
Bug: 25794302
Change-Id: I1488e0e9592f92a9e15365131c76ce2902ad4607/"
conscrypt,"OpenSSLCipher: use 128 bit tags in GCM by default
Bug: 26186727
Change-Id: Id74b0d89742dd23f506c6f0165c1dfc49bd586a6/"
conscrypt,"Revert ""Add ExtendedSSLSession, et al.""
This reverts commit 38d12ed4a7f6f7628120d0ef45ff29d472337102.
This breaks the unbundled build because of OpenSSLExtendedSessionImpl.
Change-Id: I73951a6f1d5cb14c70cd807c2c895bbbdc4c8e40/Pass peerHostname into checkServerTrusted
Avoid using getHostname() because it can fallback to a reverse DNS
lookup if peerHostname is not available.
Change-Id: Id89f04103b15a02afc349fb2f28d80aa95cefe35/"
conscrypt,"Try to get peer hostname from SocketAddress
Java 7 added a new method to InetSocketAddress called getHostString()
which returns the unresolved host for a given address. This should be
suitable for use with SNI as long as it isn't an IP address.
This also helps with testing because we can use serialization tricks to
rewrite the ""hostname"" field of an already-serialized loopback address.
(cherry picked from commit bc8a290f2a0a0e16f078d7c9cf2b2d97edf4d0f2)
Bug: 27271561
Change-Id: I9845e57d505712cdfee87d18246a1a3b021deea3/Try to get peer hostname from SocketAddress
Java 7 added a new method to InetSocketAddress called getHostString()
which returns the unresolved host for a given address. This should be
suitable for use with SNI as long as it isn't an IP address.
This also helps with testing because we can use serialization tricks to
rewrite the ""hostname"" field of an already-serialized loopback address.
Bug: 27271561
Change-Id: I9845e57d505712cdfee87d18246a1a3b021deea3/"
conscrypt,"OpenSSLSocketImpl: Don't accidentally create a SocketImpl.
We don't call super.close() when we're wrapping a socket, so we'll
have to be careful not to call any superclass methods that might
end up creating a SocketImpl.
bug: 27250522
(cherry picked from commit edae6d2b2efbd85646fea384ec76b11f099a8fca)
Change-Id: Iabeade852e6a5c3bc923c7b3601f3edf3322fee2/OpenSSLSocketImpl: Don't accidentally create a SocketImpl.
We don't call super.close() when we're wrapping a socket, so we'll
have to be careful not to call any superclass methods that might
end up creating a SocketImpl.
bug: 27250522
Change-Id: Ie98127d002cc3b3dd3dd419b62adcfec47817479/"
conscrypt,"Update d2i_SSL_SESSION test expectations
Update d2i_SSL_SESSION to only throw IOException and change tests to
expect that to happen. Since IOException is declared as a thrown
exception, non-test code should already be expecting this.
(cherry picked from commit c12c046e706de374276e3f9785cb4afc2e3a02fa)
Bug: 27526112
Change-Id: Ic8c1a47debce9cb76221150d050be86d010c6ec3/Update d2i_SSL_SESSION test expectations
Update d2i_SSL_SESSION to only throw IOException and change tests to
expect that to happen. Since IOException is declared as a thrown
exception, non-test code should already be expecting this.
Bug: 27526112
Change-Id: Ic8c1a47debce9cb76221150d050be86d010c6ec3/"
conscrypt,"Add getTrustedChainForServer
This adds versions of the new checkServerTrusted methods that return the
built chain.
Bug: 27271561
Change-Id: Id03500dab962c949430ee217407bf64fec28adb7
(cherry picked from commit 8fa0aeece0084290735f81bfcce6c178568ab157)/Add getTrustedChainForServer
This adds versions of the new checkServerTrusted methods that return the
built chain.
Bug: 27271561
Change-Id: Id03500dab962c949430ee217407bf64fec28adb7/Cache intermediate CA separately
Intermediate CAs are cached in order to support servers that fail to
sent a complete chain to a root. These certificates should be cached to
support these servers but these certificates must not be trusted as
trust anchors. Store them separately to prevent confusion between
trusted roots and cached intermediates.
(cherry-picked from commit 198aca1fb638a2a98e89fb9f284108ad576d0c3b)
Bug: 26232830
Change-Id: I520f50729b55fc7412c7d133335bc9e3c190bbf6/"
conscrypt,"Try to get peer hostname from SocketAddress
Java 7 added a new method to InetSocketAddress called getHostString()
which returns the unresolved host for a given address. This should be
suitable for use with SNI as long as it isn't an IP address.
This also helps with testing because we can use serialization tricks to
rewrite the ""hostname"" field of an already-serialized loopback address.
(cherry picked from commit bc8a290f2a0a0e16f078d7c9cf2b2d97edf4d0f2)
Bug: 27271561
Change-Id: I9845e57d505712cdfee87d18246a1a3b021deea3/Try to get peer hostname from SocketAddress
Java 7 added a new method to InetSocketAddress called getHostString()
which returns the unresolved host for a given address. This should be
suitable for use with SNI as long as it isn't an IP address.
This also helps with testing because we can use serialization tricks to
rewrite the ""hostname"" field of an already-serialized loopback address.
Bug: 27271561
Change-Id: I9845e57d505712cdfee87d18246a1a3b021deea3/"
conscrypt,"Try to get peer hostname from SocketAddress
Java 7 added a new method to InetSocketAddress called getHostString()
which returns the unresolved host for a given address. This should be
suitable for use with SNI as long as it isn't an IP address.
This also helps with testing because we can use serialization tricks to
rewrite the ""hostname"" field of an already-serialized loopback address.
(cherry picked from commit bc8a290f2a0a0e16f078d7c9cf2b2d97edf4d0f2)
Bug: 27271561
Change-Id: I9845e57d505712cdfee87d18246a1a3b021deea3/Try to get peer hostname from SocketAddress
Java 7 added a new method to InetSocketAddress called getHostString()
which returns the unresolved host for a given address. This should be
suitable for use with SNI as long as it isn't an IP address.
This also helps with testing because we can use serialization tricks to
rewrite the ""hostname"" field of an already-serialized loopback address.
Bug: 27271561
Change-Id: I9845e57d505712cdfee87d18246a1a3b021deea3/"
conscrypt,"Use SSL_session_reused to check when a session was reused
The returned session_id could be exactly the same in the case of TLS
session tickets, so use the SSL_session_reused API to determine exactly
when a session was reused.
(cherry picked from commit 1115fa0f6dbbff3a913fbce39ca98f9a78425c72)
Bug: 28751153
Change-Id: Ie82e4d1bb326d7e7deb7981a1e57df393f6c0e1f/Use SSL_session_reused to check when a session was reused
The returned session_id could be exactly the same in the case of TLS
session tickets, so use the SSL_session_reused API to determine exactly
when a session was reused.
(cherry picked from commit 1115fa0f6dbbff3a913fbce39ca98f9a78425c72)
Bug: 28751153
Change-Id: Ie82e4d1bb326d7e7deb7981a1e57df393f6c0e1f/Use SSL_session_reused to check when a session was reused
The returned session_id could be exactly the same in the case of TLS
session tickets, so use the SSL_session_reused API to determine exactly
when a session was reused.
Bug: 28751153
Change-Id: Ie82e4d1bb326d7e7deb7981a1e57df393f6c0e1f/X509_get_pubkey should default to checked exception am: b1fc23213e am: c3c6567dbd
am: 6d607ca682
* commit '6d607ca6821b66f4aa91de47704af66a6176f9c7':
X509_get_pubkey should default to checked exception
Change-Id: I5bd04385b698e430b910eddc7e5f9ff97ba1c9b5/X509_get_pubkey should default to checked exception am: b1fc23213e
am: c3c6567dbd
* commit 'c3c6567dbd7e09ceda2fd6469ac548de837e09e1':
X509_get_pubkey should default to checked exception
Change-Id: Ibd051f3c1f352f7d242f9c399e76452b04886580/X509_get_pubkey should default to checked exception
am: b1fc23213e
* commit 'b1fc23213ee8cb2ee86dfb6e97fd34572c7b784c':
X509_get_pubkey should default to checked exception
Change-Id: I57238a705fad3acc08abdf90fd708173ef363ff8/X509_get_pubkey should default to checked exception
An invalid certificate would cause a RuntimeException to crop up instead
of a checked exception. Instead throw an InvalidKeyException by default
which can be caught and handled.
Bug: 28574453
Change-Id: Ib9e92c96a35d2d330a4870175a4eb5fb24fc4026/UniqueMutex for explicit ordering with ScopedSslBio
The MUTEX_LOCK / MUTEX_UNLOCK semantics work if you also explicitly
clear out resources that were supposed to be cleared before the lock is
released. However, with wrapper classes that do it automatically, you
can't get the correct ordering. Instead of converting these all to
manual acquire and release, convert the mutex handling to use automatic
release via UniqueMutex so that ordering is correct with resources that
should be protected by the mutex.
Thanks to Zhen Song for finding these issues.
(cherry picked from commit cdc9e2f091bf353e0bda9195f7fd8a7f1505ccc0)
Bug: 28473706
Change-Id: I4b63ce674e0fc343fe156936df7e8f6e3130722f/UniqueMutex for explicit ordering with ScopedSslBio
The MUTEX_LOCK / MUTEX_UNLOCK semantics work if you also explicitly
clear out resources that were supposed to be cleared before the lock is
released. However, with wrapper classes that do it automatically, you
can't get the correct ordering. Instead of converting these all to
manual acquire and release, convert the mutex handling to use automatic
release via UniqueMutex so that ordering is correct with resources that
should be protected by the mutex.
Thanks to Zhen Song for finding these issues.
Bug: 28473706
Change-Id: I4b63ce674e0fc343fe156936df7e8f6e3130722f/Do not dlopen libjavacore from libconscrypt_openjdk_jni
Conscrypt JNI library for host OpenJDK should never attempt
to dlopen libjavacore.so.
Bug: 27954979
Change-Id: Ib8a5795ca22edde4b22576f1bd8eab182df1349d/Prefer AES when hardware acceleration is available
ChaCha20-Poly1305 is more efficient in software, but many modern CPUs
have acceleration for AES which makes AES-GCM the more preferable choice
in terms of throughput and battery consumption (i.e., less CPU cycles
per byte).
Use the CPU features as reported by BoringSSL to determine when to
prioritize AES-GCM over ChaCha20-Poly1305. This should be good enough to
say when the trade-off should be made.
(cherry picked from commit 4209803a99fe1c26e5ef66c16dc70e302a428e8a)
Bug: 26945889
Change-Id: I7ae2f3e422e30e83324c08514509cb3e9a506d97/Prefer AES when hardware acceleration is available
ChaCha20-Poly1305 is more efficient in software, but many modern CPUs
have acceleration for AES which makes AES-GCM the more preferable choice
in terms of throughput and battery consumption (i.e., less CPU cycles
per byte).
Use the CPU features as reported by BoringSSL to determine when to
prioritize AES-GCM over ChaCha20-Poly1305. This should be good enough to
say when the trade-off should be made.
Bug: 26945889
Change-Id: I7ae2f3e422e30e83324c08514509cb3e9a506d97/Update d2i_SSL_SESSION test expectations
Update d2i_SSL_SESSION to only throw IOException and change tests to
expect that to happen. Since IOException is declared as a thrown
exception, non-test code should already be expecting this.
(cherry picked from commit c12c046e706de374276e3f9785cb4afc2e3a02fa)
Bug: 27526112
Change-Id: Ic8c1a47debce9cb76221150d050be86d010c6ec3/Update d2i_SSL_SESSION test expectations
Update d2i_SSL_SESSION to only throw IOException and change tests to
expect that to happen. Since IOException is declared as a thrown
exception, non-test code should already be expecting this.
Bug: 27526112
Change-Id: Ic8c1a47debce9cb76221150d050be86d010c6ec3/OpenSSLSessionImpl: add better errors when converting
am: de8236f4bb
* commit 'de8236f4bb9d70fa4e6a52679b4bf40b04c44f9b':
OpenSSLSessionImpl: add better errors when converting/OpenSSLSessionImpl: add better errors when converting
Frequently an old SSLSession cache from a different version of OpenSSL
or BoringSSL will cause the de-serialization of the SSLSession
information to fail. This will spam the logs and happens Frequently
when GmsCore's ProviderInstaller is used. For now try to extract a bit
more useful information from the error thrown by native code and don't
bother to print the stack trace since it's not fatal.
(cherry picked from commit de8236f4bb9d70fa4e6a52679b4bf40b04c44f9b)
Bug: 25328662
Change-Id: I0a396a52418e7911b98133b45bbfafcc6651e863/OpenSSLSessionImpl: add better errors when converting
Frequently an old SSLSession cache from a different version of OpenSSL
or BoringSSL will cause the de-serialization of the SSLSession
information to fail. This will spam the logs and happens Frequently
when GmsCore's ProviderInstaller is used. For now try to extract a bit
more useful information from the error thrown by native code and don't
bother to print the stack trace since it's not fatal.
Bug: 25328662
Change-Id: I0a396a52418e7911b98133b45bbfafcc6651e863/"
conscrypt,"Wrap cached sessions before returning
SSLSession should be wrapped so that cached sessions might have the
functionality that ExtendedSSLSession offers. This also made the
SSLSessionTest fail because the pre-cached instance would be
ExtendedSSLSession and the post-cached session would be a regular
SSLSession.
To keep compatibility with older versions of the platform, it was
impossible to directly switch OpenSSLSessionImpl over to
ExtendedSSLSession. So the use of a delegate in the case when the
platform does have ExtendedSSLSession was required. Since older platform
versions still use OpenSSLSessionImpl that extends SSLSession, we just
directly inflate the serialized sessions to that.
The SSLSessionTest was changed to accomodate the delegate scheme since
SSLSession does not have an equals method, the tests for SSLSessionTest
were directly comparing object instance equality which fails when the
sessions are wrapped in a delegate like this.
(cherry picked from commit 710c0817a2a13135b35f14faaef5ca069daf7b6c)
Bug: 27123298
Change-Id: Iefbea03a72dbcc76ae0b439cfdcecd817926b7d0/Wrap cached sessions before returning
SSLSession should be wrapped so that cached sessions might have the
functionality that ExtendedSSLSession offers. This also made the
SSLSessionTest fail because the pre-cached instance would be
ExtendedSSLSession and the post-cached session would be a regular
SSLSession.
To keep compatibility with older versions of the platform, it was
impossible to directly switch OpenSSLSessionImpl over to
ExtendedSSLSession. So the use of a delegate in the case when the
platform does have ExtendedSSLSession was required. Since older platform
versions still use OpenSSLSessionImpl that extends SSLSession, we just
directly inflate the serialized sessions to that.
The SSLSessionTest was changed to accomodate the delegate scheme since
SSLSession does not have an equals method, the tests for SSLSessionTest
were directly comparing object instance equality which fails when the
sessions are wrapped in a delegate like this.
Bug: 27123298
Change-Id: Iefbea03a72dbcc76ae0b439cfdcecd817926b7d0/"
conscrypt,"Use SSL_session_reused to check when a session was reused
The returned session_id could be exactly the same in the case of TLS
session tickets, so use the SSL_session_reused API to determine exactly
when a session was reused.
(cherry picked from commit 1115fa0f6dbbff3a913fbce39ca98f9a78425c72)
Bug: 28751153
Change-Id: Ie82e4d1bb326d7e7deb7981a1e57df393f6c0e1f/Use SSL_session_reused to check when a session was reused
The returned session_id could be exactly the same in the case of TLS
session tickets, so use the SSL_session_reused API to determine exactly
when a session was reused.
(cherry picked from commit 1115fa0f6dbbff3a913fbce39ca98f9a78425c72)
Bug: 28751153
Change-Id: Ie82e4d1bb326d7e7deb7981a1e57df393f6c0e1f/Use SSL_session_reused to check when a session was reused
The returned session_id could be exactly the same in the case of TLS
session tickets, so use the SSL_session_reused API to determine exactly
when a session was reused.
Bug: 28751153
Change-Id: Ie82e4d1bb326d7e7deb7981a1e57df393f6c0e1f/X509_get_pubkey should default to checked exception am: b1fc23213e am: c3c6567dbd
am: 6d607ca682
* commit '6d607ca6821b66f4aa91de47704af66a6176f9c7':
X509_get_pubkey should default to checked exception
Change-Id: I5bd04385b698e430b910eddc7e5f9ff97ba1c9b5/X509_get_pubkey should default to checked exception am: b1fc23213e
am: c3c6567dbd
* commit 'c3c6567dbd7e09ceda2fd6469ac548de837e09e1':
X509_get_pubkey should default to checked exception
Change-Id: Ibd051f3c1f352f7d242f9c399e76452b04886580/X509_get_pubkey should default to checked exception
am: b1fc23213e
* commit 'b1fc23213ee8cb2ee86dfb6e97fd34572c7b784c':
X509_get_pubkey should default to checked exception
Change-Id: I57238a705fad3acc08abdf90fd708173ef363ff8/X509_get_pubkey should default to checked exception
An invalid certificate would cause a RuntimeException to crop up instead
of a checked exception. Instead throw an InvalidKeyException by default
which can be caught and handled.
Bug: 28574453
Change-Id: Ib9e92c96a35d2d330a4870175a4eb5fb24fc4026/Prefer AES when hardware acceleration is available
ChaCha20-Poly1305 is more efficient in software, but many modern CPUs
have acceleration for AES which makes AES-GCM the more preferable choice
in terms of throughput and battery consumption (i.e., less CPU cycles
per byte).
Use the CPU features as reported by BoringSSL to determine when to
prioritize AES-GCM over ChaCha20-Poly1305. This should be good enough to
say when the trade-off should be made.
(cherry picked from commit 4209803a99fe1c26e5ef66c16dc70e302a428e8a)
Bug: 26945889
Change-Id: I7ae2f3e422e30e83324c08514509cb3e9a506d97/Prefer AES when hardware acceleration is available
ChaCha20-Poly1305 is more efficient in software, but many modern CPUs
have acceleration for AES which makes AES-GCM the more preferable choice
in terms of throughput and battery consumption (i.e., less CPU cycles
per byte).
Use the CPU features as reported by BoringSSL to determine when to
prioritize AES-GCM over ChaCha20-Poly1305. This should be good enough to
say when the trade-off should be made.
Bug: 26945889
Change-Id: I7ae2f3e422e30e83324c08514509cb3e9a506d97/Disable the two remaining RC4 cipher suites.
RC4 has been deprecated for a while. It's now time to no longer use it
by default. Mozilla Firefox and Chrome web browsers have already made
the leap.
This is a follow-up to 751965bdf66f6ec1ff93b79857cffdeac7756dfd
where TLS_RSA_WITH_RC4_128_SHA was disabled for the same reasons.
Bug: 24898327
(cherry picked from commit bbe63d5d1d007d7c55c8993c70fc36c78969a2ee)
Change-Id: Id13d3ba280139b25fdef057d9afb17ef3edf30cf/Disable the two remaining RC4 cipher suites.
RC4 has been deprecated for a while. It's now time to no longer use it
by default. Mozilla Firefox and Chrome web browsers have already made
the leap.
This is a follow-up to 751965bdf66f6ec1ff93b79857cffdeac7756dfd
where TLS_RSA_WITH_RC4_128_SHA was disabled for the same reasons.
Bug: 24898327
Change-Id: Id716f83b97381aabe69ae982508d9d48e368dc5a/OpenSSLSessionImpl: add better errors when converting
am: de8236f4bb
* commit 'de8236f4bb9d70fa4e6a52679b4bf40b04c44f9b':
OpenSSLSessionImpl: add better errors when converting/OpenSSLSessionImpl: add better errors when converting
Frequently an old SSLSession cache from a different version of OpenSSL
or BoringSSL will cause the de-serialization of the SSLSession
information to fail. This will spam the logs and happens Frequently
when GmsCore's ProviderInstaller is used. For now try to extract a bit
more useful information from the error thrown by native code and don't
bother to print the stack trace since it's not fatal.
(cherry picked from commit de8236f4bb9d70fa4e6a52679b4bf40b04c44f9b)
Bug: 25328662
Change-Id: I0a396a52418e7911b98133b45bbfafcc6651e863/OpenSSLSessionImpl: add better errors when converting
Frequently an old SSLSession cache from a different version of OpenSSL
or BoringSSL will cause the de-serialization of the SSLSession
information to fail. This will spam the logs and happens Frequently
when GmsCore's ProviderInstaller is used. For now try to extract a bit
more useful information from the error thrown by native code and don't
bother to print the stack trace since it's not fatal.
Bug: 25328662
Change-Id: I0a396a52418e7911b98133b45bbfafcc6651e863/Do not use RC4 TLS/SSL cipher suites by default.
RC4 has been deprecated for a while. It's now time to no longer use it
by default. Mozilla Firefox and Chrome web browsers have already made
the leap.
Bug: 24898327
(cherry picked from commit 751965bdf66f6ec1ff93b79857cffdeac7756dfd)
Change-Id: I63fb45fe62b594ba6311d42be26e214adbab5c20/Do not use RC4 TLS/SSL cipher suites by default.
RC4 has been deprecated for a while. It's now time to no longer use it
by default. Mozilla Firefox and Chrome web browsers have already made
the leap.
Bug: 24898327
Change-Id: I65c241d7a30569728d6637a4182371eb066e48e0/"
conscrypt,"Merge ""Fix updateAAD when offset is not 0"" into mnc-dev
am: 5ad20a9
* commit '5ad20a9d95b6ec2e0c8a21f810b1eccc57226283':
Fix updateAAD when offset is not 0/Merge ""Fix updateAAD when offset is not 0"" into mnc-dev/Fix updateAAD when offset is not 0
am: 95cf7b9
* commit '95cf7b9b7fbabb77cd341f17da79c947bcc934ab':
Fix updateAAD when offset is not 0/Fix updateAAD when offset is not 0
Due to AAD data not being reset when a Cipher instance was re-used, this
bug was never uncovered by tests that actually exercise this case.
(cherry picked from commit 95cf7b9b7fbabb77cd341f17da79c947bcc934ab)
Bug: 27696681
Bug: 27324690
Change-Id: Iae9b5794f212a8fc4eeff2a651332e7490f5cada/Fix updateAAD when offset is not 0
Due to AAD data not being reset when a Cipher instance was re-used, this
bug was never uncovered by tests that actually exercise this case.
Bug: 27696681
Bug: 27324690
Change-Id: Iae9b5794f212a8fc4eeff2a651332e7490f5cada/OpenSSLCipher: multiple calls to updateAAD were ignored
Do to a missing assignment statement, only the first call to updateAAD
was honored and the rest were discarded.
(cherry picked from commit a23b05b327b9d8fefc44276c2fa80278ef210c0f)
Bug: 27371173
Change-Id: I77ad7800b0905f72d5abe76b56352a94056ceb9c/OpenSSLCipher: reset AAD when necessary
AAD was not being reset correctly during init or doFinal calls thus
leading to incorrect output.
(cherry picked from commit 0bab7f3b89ea13eb0d0c39d9c7b60c6112f0d6a8)
Bug: 27324690
Change-Id: If7806a9d7847814b60719637abceb94d8fbc8831/OpenSSLCipher: multiple calls to updateAAD were ignored
Do to a missing assignment statement, only the first call to updateAAD
was honored and the rest were discarded.
Bug: 27371173
Change-Id: I77ad7800b0905f72d5abe76b56352a94056ceb9c/OpenSSLCipher: reset AAD when necessary
AAD was not being reset correctly during init or doFinal calls thus
leading to incorrect output.
Bug: 27324690
Change-Id: If7806a9d7847814b60719637abceb94d8fbc8831/"
conscrypt,"Fix static analysis findings am: ee3b1694a2 am: f2b103a611
am: dee8b5219a
* commit 'dee8b5219ab1d862a8688d8139981fc517bfc1e3':
Fix static analysis findings
Change-Id: I80b2be8dc827a127aa6ea24eb5bfe18307866941/Fix static analysis findings am: ee3b1694a2
am: f2b103a611
* commit 'f2b103a6116d87b3996b158b6b38079328dbb29d':
Fix static analysis findings
Change-Id: Ie3bd3ad86d5d5c461711f576d60411b7cb04c8ad/Fix static analysis findings
am: ee3b1694a2
* commit 'ee3b1694a206350e87a70cc83dd35a1ec2053fd6':
Fix static analysis findings
Change-Id: If45ad8d307b61162749a390741566ea95e680f57/Fix static analysis findings
Add annotations where we intentionally left out @Override and a brief
explanation.
Add synchronized keyword where needed by overriding methods so they
match the parent class.
Change-Id: I55591a5902530f1c2fb8cc89260c3df09648ec8e/OpenSSLSocketImpl: Don't accidentally create a SocketImpl.
We don't call super.close() when we're wrapping a socket, so we'll
have to be careful not to call any superclass methods that might
end up creating a SocketImpl.
bug: 27250522
(cherry picked from commit edae6d2b2efbd85646fea384ec76b11f099a8fca)
Change-Id: Iabeade852e6a5c3bc923c7b3601f3edf3322fee2/OpenSSLSocketImpl: Don't accidentally create a SocketImpl.
We don't call super.close() when we're wrapping a socket, so we'll
have to be careful not to call any superclass methods that might
end up creating a SocketImpl.
bug: 27250522
Change-Id: Ie98127d002cc3b3dd3dd419b62adcfec47817479/"
conscrypt,"Fix static analysis findings am: ee3b1694a2 am: f2b103a611
am: dee8b5219a
* commit 'dee8b5219ab1d862a8688d8139981fc517bfc1e3':
Fix static analysis findings
Change-Id: I80b2be8dc827a127aa6ea24eb5bfe18307866941/Fix static analysis findings am: ee3b1694a2
am: f2b103a611
* commit 'f2b103a6116d87b3996b158b6b38079328dbb29d':
Fix static analysis findings
Change-Id: Ie3bd3ad86d5d5c461711f576d60411b7cb04c8ad/Fix static analysis findings
am: ee3b1694a2
* commit 'ee3b1694a206350e87a70cc83dd35a1ec2053fd6':
Fix static analysis findings
Change-Id: If45ad8d307b61162749a390741566ea95e680f57/Fix static analysis findings
Add annotations where we intentionally left out @Override and a brief
explanation.
Add synchronized keyword where needed by overriding methods so they
match the parent class.
Change-Id: I55591a5902530f1c2fb8cc89260c3df09648ec8e/"
conscrypt,"Fix static analysis findings am: ee3b1694a2 am: f2b103a611
am: dee8b5219a
* commit 'dee8b5219ab1d862a8688d8139981fc517bfc1e3':
Fix static analysis findings
Change-Id: I80b2be8dc827a127aa6ea24eb5bfe18307866941/Fix static analysis findings am: ee3b1694a2
am: f2b103a611
* commit 'f2b103a6116d87b3996b158b6b38079328dbb29d':
Fix static analysis findings
Change-Id: Ie3bd3ad86d5d5c461711f576d60411b7cb04c8ad/Fix static analysis findings
am: ee3b1694a2
* commit 'ee3b1694a206350e87a70cc83dd35a1ec2053fd6':
Fix static analysis findings
Change-Id: If45ad8d307b61162749a390741566ea95e680f57/Fix static analysis findings
Add annotations where we intentionally left out @Override and a brief
explanation.
Add synchronized keyword where needed by overriding methods so they
match the parent class.
Change-Id: I55591a5902530f1c2fb8cc89260c3df09648ec8e/Allow SSLSession to return IP address
In an effort to not use reverse DNS, we no longer return hostnames from
sockets created via IP addresses. However, this also made the SSLSession
return null when a Socket is created to an IP address instead of an
FQDN.
While being careful not to trigger another DNS lookup, simply return a
textual representation of the IP address connected when the SSLSocket has
no knowledge of what the actual FQDN is supposed to be.
(cherry picked from commit ee1a154153a1b20d55fc4b0dd9752277f0cd6451)
Bug: 27123298
Change-Id: Ie37e214f91e4f005f90da0d4a2aba1cd604d60b7/Allow SSLSession to return IP address
In an effort to not use reverse DNS, we no longer return hostnames from
sockets created via IP addresses. However, this also made the SSLSession
return null when a Socket is created to an IP address instead of an
FQDN.
While being careful not to trigger another DNS lookup, simply return a
textual representation of the IP address connected when the SSLSocket has
no knowledge of what the actual FQDN is supposed to be.
Bug: 27123298
Change-Id: Ie37e214f91e4f005f90da0d4a2aba1cd604d60b7/Try to get peer hostname from SocketAddress
Java 7 added a new method to InetSocketAddress called getHostString()
which returns the unresolved host for a given address. This should be
suitable for use with SNI as long as it isn't an IP address.
This also helps with testing because we can use serialization tricks to
rewrite the ""hostname"" field of an already-serialized loopback address.
(cherry picked from commit bc8a290f2a0a0e16f078d7c9cf2b2d97edf4d0f2)
Bug: 27271561
Change-Id: I9845e57d505712cdfee87d18246a1a3b021deea3/Try to get peer hostname from SocketAddress
Java 7 added a new method to InetSocketAddress called getHostString()
which returns the unresolved host for a given address. This should be
suitable for use with SNI as long as it isn't an IP address.
This also helps with testing because we can use serialization tricks to
rewrite the ""hostname"" field of an already-serialized loopback address.
Bug: 27271561
Change-Id: I9845e57d505712cdfee87d18246a1a3b021deea3/OpenSSLSocketImpl: Don't accidentally create a SocketImpl.
We don't call super.close() when we're wrapping a socket, so we'll
have to be careful not to call any superclass methods that might
end up creating a SocketImpl.
bug: 27250522
(cherry picked from commit edae6d2b2efbd85646fea384ec76b11f099a8fca)
Change-Id: Iabeade852e6a5c3bc923c7b3601f3edf3322fee2/OpenSSLSocketImpl: Don't accidentally create a SocketImpl.
We don't call super.close() when we're wrapping a socket, so we'll
have to be careful not to call any superclass methods that might
end up creating a SocketImpl.
bug: 27250522
Change-Id: Ie98127d002cc3b3dd3dd419b62adcfec47817479/"
conscrypt,"Make sure we get the right strerror_r. am: d649eeefe7 am: c6a0cd20a1
am: baec13c047
Change-Id: I9d3381e7af94ca29406d84c4d4895c247c68ea2c/Make sure we get the right strerror_r. am: d649eeefe7
am: c6a0cd20a1
Change-Id: Ia32056d81cce3537aac88d2c83d2bd0669d9827a/Make sure we get the right strerror_r.
am: d649eeefe7
Change-Id: I27fa8a494326d64a9069880aa04b0acc1c0a6f61/Make sure we get the right strerror_r.
We want the XSI-compliant strerror_r, not the GNU one. We haven't
actually defined _GNU_SOURCE ourselves, but the compiler adds it
automatically when building C++.
This has been fine so far because the NDK headers don't have
strerror_r. With updated headers, this is needed.
Test: mma
Change-Id: I0461ce24e5cf85f20dc087c3712f3fc579941192/"
conscrypt,"Expose CT through libcore NetworkSecurityPolicy
Bug: 28746284
Change-Id: I6549a997823b38dc256911a66ac558c90bf6f762/"
conscrypt,"Remove BoringSSL conditionals
OpenSSL is no longer supported, so this will always take the BoringSSL
path.
Test: lunch aosp_bullhead-userdebug; make
Change-Id: Iee7e0a11ae40bfc8649aed7d5c11768ba06cd726/"
conscrypt,"Return an empty list when no OCSP reponses received
Change OpenSSLSessionImpl#getStatusResponses() to return an empty list
instead of null. This matches the assumption of the serializing code in
AbstractSessionContext.
Add a test to make sure that serializing a trivial OpenSSLSessionImpl
instance completes without throwing an exception.
Test: cts-tradefed run cts -d -p android.core.tests.libcore.package.conscrypt
Bug: 30751283
Change-Id: If4c3e6a99c080fb3a0fd527c86a5ee8972475718/Fix merge error
Somehow the name was changed from ""chain"" to ""certs"" in different versions
of the tree, so switch to the ""certs"" designation since it is more
accurate.
Change-Id: I603dc31d58033351b75a3c9e16906d2074496344/Add getTrustedChainForServer
This adds versions of the new checkServerTrusted methods that return the
built chain.
(cherry picked from commit 8fa0aeece0084290735f81bfcce6c178568ab157)
Bug: 27271561
Change-Id: Id03500dab962c949430ee217407bf64fec28adb7/Add end to end tests for CertBlacklist functionality
This adds a test public key to the default list of blacklisted CAs
(private key in src/test/resources/blacklist_ca_key.pem) and adds a
number of end to end tests that TrustManagerImpl enforces blacklists in
chains. This test key will also be used by CTS to ensure that the
default X509TrustManager properly enforces the blacklist.
(cherry picked from commit 1c4c0a23e4cd4f99e87ee770ea462c6351152c13)
Bug: 29443053
Change-Id: I67dcb7ef8da490544791a4c90c74ffa7582a1826/Move CertBlacklist to conscrypt
CertBlacklist is mostly unchanged from bouncycastle except removing the
bouncycastle Digest and Hex dependencies in isPublicKeyBlackListed.
(cherry picked from commit ce5bdd0391d93d9a4b1fe7005041271341eb69b2)
Bug: 29397721
Change-Id: Icccdcc0e108e8b0c60c47522114749518247a598/Move CertBlacklist to conscrypt
CertBlacklist was previously in bouncycastle, but with the enso switch
we no longer use their CertPathValidator and so blacklist checking
wasn't being done.
CertBlacklist is mostly unchanged from bouncycastle except removing the
bouncycastle Digest and Hex dependencies in isPublicKeyBlackListed.
Bug: 29397721
Change-Id: Icccdcc0e108e8b0c60c47522114749518247a598/"
conscrypt,"Expose CT through libcore NetworkSecurityPolicy
Bug: 28746284
Change-Id: I6549a997823b38dc256911a66ac558c90bf6f762/"
conscrypt,"Use built-in key debugging mechanism am: 599c8fe853 am: b3a7930bfc
am: 9462bb74c0
Change-Id: Ib73580f61a5159e04654ef9b7586fc7f3b05466b/Use built-in key debugging mechanism am: 599c8fe853
am: b3a7930bfc
Change-Id: I6d5094f0bfcb5fe45e686c37c51820802f47c5da/Use built-in key debugging mechanism
am: 599c8fe853
Change-Id: I48b78672b8e8e5aad31e05c552218c6baddb0aa9/Use built-in key debugging mechanism
When debugging a network flow it's useful to log the negotiated keys to
see what is happening inside the session. Previously this was
implemented in Conscrypt, but BoringSSL has this capability built-in
now.
Documentation at
https://commondatastorage.googleapis.com/chromium-boringssl-docs/ssl.h.html#SSL_CTX_set_keylog_callback
Test:
vogar --mode host \
--classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack \
--classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-hostdex_intermediates/classes.jack \
libcore/luni/src/test/java/libcore/javax/net/ssl/*Test.java
Change-Id: I50a5b315d302492667a28926161836e34b9dd357/Don't use X509_up_ref's return value.
OpenSSL 1.1.0 is also adding FOO_up_ref functions, but theirs return int
rather than the type. In preparation for making BoringSSL match, stop
using the return value.
(Our up_ref functions never fail, so there's no need to check the
return value. It's just there for source compatibility with OpenSSL.)
Change-Id: If92b3a967a31dbaf2e1a4176961ee66179cae8bf/Remove BoringSSL conditionals
OpenSSL is no longer supported, so this will always take the BoringSSL
path.
Test: lunch aosp_bullhead-userdebug; make
Change-Id: Iee7e0a11ae40bfc8649aed7d5c11768ba06cd726/Fix JNI_TRACE debugging am: b8bff45abd am: 5df1619256
am: 65fd24c7ad
Change-Id: Ia83a9c4d66033ae055d7f4635c40329fb5a315af/Fix JNI_TRACE debugging am: b8bff45abd
am: 5df1619256
Change-Id: Idd3a8bbbfe9f8f6c1aabb262df5115ef47162440/Fix JNI_TRACE debugging
am: b8bff45abd
Change-Id: I2fb619300f702fe59a82e7c0ca7d3fce74c5aa96/Fix JNI_TRACE debugging
A change to a variable type broke the printing of debug information. Fix
that so it doesn't cause a compiler error.
Change-Id: I82d4287e5f59954f808709372a140b5ec4151098/Faster evpUpdate for small region of large byte[].
This improves the speed of computing a digest, a MAC, or a signature
over a small region of a large byte[] on OpenJDK based VMs.
Conscrypt's code prior to this CL obtained the reference to the native
bytes by indexing into the result of JNI GetByteArrayElements. On
ART/Davlik this avoids creating copies (for 12 kB and larger arrays)
whereas on OpenJDK based VMs this always creates a copy of all the
elements of the array, which is not efficient and leads to noticeable
slowdowns when processing small fractions of the byte array as input.
This commit makes Conscrypt's evpUpdate choose a strategy (
GetByteArrayElements vs GetByteArrayRegion) based on whether the VM's
GetByteArrayElements is expected to create a copy of the array. This
guess is hard-coded for each target: platform, compat, and OpenJDK.
Bug: 27461702
Change-Id: I4ac1013b29e3d166a3f13fffebf662b02351684f/Fix misc-macro-parentheses warnings in conscrypt. am: 792eec0172 am: dade10e084
am: 51c9ba35f7
Change-Id: If92c3ad2daacf3c631b3a9b1527591510ef56e00/Fix misc-macro-parentheses warnings in conscrypt. am: 792eec0172
am: dade10e084
Change-Id: I7f82dce8e6452876b6c09cb5b766bcadd038832e/Fix misc-macro-parentheses warnings in conscrypt.
am: 792eec0172
Change-Id: I9e5fccceb1c58cef535b604ab38ab998d0b1b96a/Fix misc-macro-parentheses warnings in conscrypt.
Add parentheses around macro arguments used beside operators.
Bug: 28705665
Change-Id: Ifb34004969a344eeeb5350256b7f5888ca21665f/"
conscrypt,"Remove BoringSSL conditionals
OpenSSL is no longer supported, so this will always take the BoringSSL
path.
Test: lunch aosp_bullhead-userdebug; make
Change-Id: Iee7e0a11ae40bfc8649aed7d5c11768ba06cd726/"
conscrypt,"Remove unused imports left over from removing OpenSSL code
Test: lunch aosp_bullhead-userdebug; make
Change-Id: I5b8cdcfbe45a866005209ed2e6f365a1378d46d5/"
conscrypt,"Substitute NULL for nullptr
Since we don't actually rely on a STL, we don't have <cstdlib> to get
NULL from, but since we're compiling C++11 we get nullptr for free.
This also fixes builds against MacOS SDK since it doesn't have <cstdlib>
available when you explicitly opt out of an STL in the Android.mk module.
Test: mmma -j32 external/conscrypt; make -j29 PRODUCT-sdk_phone_armv7-sdk
Change-Id: I54929c7e5c05ec271925f5f3d1896df1661e9b59/"
conscrypt,"Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"Remove legacy certificate pinning code
This removes the old CertPinManager code and moves CertPinManager to
being an interface that the platform can use to have certificate pinning
for the network security config done as part of chain building instead
of after a valid chain has been found.
Bug: 30829862
Bug: 22666360
Test: Ran CertPinManagerTest
Change-Id: Ib4f5100096f7eead3a51533cff44f68093034bb1/Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"Strip out SSLv3 from enabled protocols for app compat
HttpsURLConnection on Android before Marshmallow tried to
setEnabledProtocols with just ""SSLv3"" without checking if it was a
supported protocol. Instead of throwing IllegalArgumentException when
the unsupported protocol is encountered, strip it out and later throw an
SSLHandshakeException if no protocols are enabled.
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Bug: 32053327
Bug: 30977793
Change-Id: I2f2008d85fcc5b5fbdc71722a3d6e0a9c22bfbc2/Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"NativeCryptoTest: make SCT test data look more legitimate
The SCT test data used to be unchecked by BoringSSL, but now there is
some shallow parsing done to make sure it's not empty. Add some length
prefixes to the data to pass the parsing.
Test: mmma -j32 external/conscrypt && vogar --mode host --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack --classpath out/host/common/obj/JAVA_LIBRARIES/conscrypt-hostdex_intermediates/classes.jack --classpath out/host/common/obj/JAVA_LIBRARIES/conscrypt-tests-hostdex_intermediates/classes.jack com.android.org.conscrypt.NativeCryptoTest
Bug: 33101752
Change-Id: I6bdf6a8e7062a13a5ea98b6239663c279e0d46c0/Improve performance of OpenSSLEngine
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Change-Id: I947bd3701e90bd65104f8f5c07ba218c4e051944/Convert NullPointerException tests to more JUnit4-like am: 4f6364860a am: 767f667a5f
am: a7986062c1
Change-Id: Ie1b269171d0b189a6aaf418f5448671bd15b924b/Convert NullPointerException tests to more JUnit4-like am: 4f6364860a
am: 767f667a5f
Change-Id: Ic37f70ef45da8ff8d2b20c42da72bacad82a05e0/Convert NullPointerException tests to more JUnit4-like
am: 4f6364860a
Change-Id: I0e18f60814471db19e797f6cb39cef3dac33b905/Merge changes I3af9fbc3,Icb6aedc3
* changes:
Convert NullPointerException tests to more JUnit4-like
Convert NativeCryptoTest to JUnit4/Convert NullPointerException tests to more JUnit4-like
Be a bit more explicit and cut down on the
fail-or-catch-expected-exception mistake possibilities.
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a -t com.android.org.conscrypt.NativeCryptoTest
Change-Id: I3af9fbc3b1fda5f01a05965b288f69dcd0eda9a9/Convert NativeCryptoTest to JUnit4
This is basically a regex substitution change with minimnal renames just
to convert to JUnit4. Further JUnit4-isms will come in subsequent
changes.
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: Icb6aedc3acee31d62750132bbe8eeaf9150bd3c0/Update NativeCryptoTest ciphers
The removal of RC4 caused some tests to fail because the other cipher
listed appears to have not existed for a while. Update the regular
cipher to something that will be supported a while longer.
Test: make -j32 && make -j32 cts && adb reboot-bootloader && fastboot flashall
Test: cts-tradefed run cts -d -m CtsLibcoreTestCases -t com.android.org.conscrypt.NativeCryptoTest
Bug: 30977793
Change-Id: I3ba576afcfe7c4abf36054ac625fd6d00dab3c7c/Remove NPN support
NPN is deprecated and clients should use ALPN instead for now. In the
interest of removing support for it in BoringSSL, we will remove NPN
support from Conscrypt as well.
For now keep around the NPN setters and getters in OpenSSLSocketImpl and
OpenSSLEngineImpl to help with backward compatibility for users that may
be using reflection.
Test: make -j32 && make -j32 cts && cts-tradefed run cts -d -m CtsLibcoreTestCases
Change-Id: Ia4edb21412d9c4b2440291ae0a8a97d2217bf5b5/Drop RC4 cipher suite support from TLS
Bug: 30977793
Test: libcore/run-libcore-tests libcore/luni/src/test/java/libcore/javax/net/ssl/* and running NativeCryptoTest.
Change-Id: I04b91a6d3bf75a757d2c74bd1a39aea2709a9199/Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"TrustManagerImpl: fix misnaming of ctPolicy arg
am: a2b5cc43f5
Change-Id: Ib59afa5061d65b416b3c70a3c09cf4ae899810df/TrustManagerImpl: fix misnaming of ctPolicy arg
ErrorProne pointed out that ""this.ctPolicy = ctPolicy;"" was
self-assignment which led to the discover of the argument being named
""policy"" instead of the intended ""ctPolicy"".
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: If07feeb3ad216b243648ad334804520f6c6e9f13/Merge ""Fix missing CTPolicy argument to TrustManagerImpl()""
am: d2aba51b7d
Change-Id: Icad7d88943141214c93cdf156b809e472909c1aa/Merge ""Fix missing CTPolicy argument to TrustManagerImpl()""/Fix missing CTPolicy argument to TrustManagerImpl()
Incorrect merge resolution on my part dropped the constructor argument.
Test: run OpenSSLSocketImplTest
Change-Id: I9b71782050a59558d49223d398c3ad22847e89a5/Merge ""Fix CertPinManagerTest"" am: b0ef629af3 am: 2561cb4194
am: 455331d90c
Change-Id: Ibc2276cc669ad2a3e8d15f5481844bdee2d6cdc6/Merge ""Fix CertPinManagerTest"" am: b0ef629af3
am: 2561cb4194
Change-Id: If6c8196d8d64df0a2dc6b872b0581d31b669067c/Merge ""Fix CertPinManagerTest""
am: b0ef629af3
Change-Id: Ic963b67de1f3238f1c8120771ff7d3c9b2f3a867/Merge ""Fix CertPinManagerTest""/Fix CertPinManagerTest
The rebase of the CT change mistakenly removed setting this.pinManager
in TrustManagerImpl's constructor.
Bug: 31958917
Test: run CertPinManagerTest
Change-Id: I94f10392c56bd8ba10e5ac6b4e82cf6a83ea34c6/Remove legacy certificate pinning code
This removes the old CertPinManager code and moves CertPinManager to
being an interface that the platform can use to have certificate pinning
for the network security config done as part of chain building instead
of after a valid chain has been found.
Bug: 30829862
Bug: 22666360
Test: Ran CertPinManagerTest
Change-Id: Ib4f5100096f7eead3a51533cff44f68093034bb1/TrustManagerImpl: fallback for missing revocation checker
Only newer implementations of the CertPathValidatorSpi will have the
PKIXRevocationChecker stuff available, so make sure we don't explode
when it's not supported. It's not totally necessary.
Bug: 31611933
Test: make -j32 build-art-host vogar && vogar --mode host --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-hostdex_intermediates/classes.jack libcore/luni/src/test/java/libcore/javax/net/ssl/SSLSocketTest.java
Change-Id: I5dd354a494e94aeb2788be8a502b114dd525cbaa/Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"Substitute NULL for nullptr
Since we don't actually rely on a STL, we don't have <cstdlib> to get
NULL from, but since we're compiling C++11 we get nullptr for free.
This also fixes builds against MacOS SDK since it doesn't have <cstdlib>
available when you explicitly opt out of an STL in the Android.mk module.
Test: mmma -j32 external/conscrypt; make -j29 PRODUCT-sdk_phone_armv7-sdk
Change-Id: I54929c7e5c05ec271925f5f3d1896df1661e9b59/"
conscrypt,"Improve performance of OpenSSLEngine
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Change-Id: I947bd3701e90bd65104f8f5c07ba218c4e051944/Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"Remove NPN support
NPN is deprecated and clients should use ALPN instead for now. In the
interest of removing support for it in BoringSSL, we will remove NPN
support from Conscrypt as well.
For now keep around the NPN setters and getters in OpenSSLSocketImpl and
OpenSSLEngineImpl to help with backward compatibility for users that may
be using reflection.
Test: make -j32 && make -j32 cts && cts-tradefed run cts -d -m CtsLibcoreTestCases
Change-Id: Ia4edb21412d9c4b2440291ae0a8a97d2217bf5b5/Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"Remove NPN support
NPN is deprecated and clients should use ALPN instead for now. In the
interest of removing support for it in BoringSSL, we will remove NPN
support from Conscrypt as well.
For now keep around the NPN setters and getters in OpenSSLSocketImpl and
OpenSSLEngineImpl to help with backward compatibility for users that may
be using reflection.
Test: make -j32 && make -j32 cts && cts-tradefed run cts -d -m CtsLibcoreTestCases
Change-Id: Ia4edb21412d9c4b2440291ae0a8a97d2217bf5b5/Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"Improve performance of OpenSSLEngine
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Change-Id: I947bd3701e90bd65104f8f5c07ba218c4e051944/Don't use asn1t.h to parse PKIPATH.
The structure is purely a SEQUENCE of certificates. Parse it with CBS.
This removes a dependency on asn1t.h, so BoringSSL may unexport it
someday and reimplement parsers for in-library types with a higher
quality ASN.1 stack.
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: Iaa74c832b333d1eb4906fb309c8715e627aa97a1/Set group on wrapped EC private keys
BoringSSL wants to know what group the private keys are in for TLS, so
set that when wrapping Java keys to avoid crashing when
EC_KEY_get0_group is called on it later.
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Change-Id: I01897c58c1c3026df0ebde66830f7b9959e4b2e2/Revise TLS signing algorithm preferences
In order to match the change in
https://boringssl.googlesource.com/boringssl/+/3a322f5e4837a0c761d1a64f1bfea82a19f44e45
we are rearranging our signing algorithm preferences. This also appears
to work around a bug in iOS 8 where SSL_SIGN_RSA_PKCS1_SHA384 is
advertised but the handshake fails when it's used.
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Bug: 29973214
Change-Id: I9dad16c59f83e815133aea60ed626c7b2556e304/Fix leak in NativeCrypto_SSL_get_peer_cert_chain.
am: 91292722c9
Change-Id: Iff5d4830a6afee87684cbca3bb903d23a90f2e00/Fix leak in NativeCrypto_SSL_get_peer_cert_chain.
SSL_get_peer_certificate returns a reference. (But
SSL_get_peer_cert_chain does not, because OpenSSL's API is confusing
like that.)
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: Id33169c98264cd41e7d7bc25e9bb6a5482eb8a64/Fix some leaks on sk_push error.
am: 8eaad4ede1
Change-Id: Ia097679349b5d097be844e6795eb38d7e8f70efe/Fix reference counting.
am: fb70e2c7b0
Change-Id: Iad0c97d843356e801db399f3241a673fd638300f/Fix some leaks on sk_push error.
sk_push only takes ownership of the pointer on success, so the pattern
needs to be slightly different.
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: Ic1b10b9aae5addf20bf770c334ada9bc461c97b8/Switch from client_cert_cb to cert_cb.
cert_cb is the newer, less confusing one. The way Conscrypt uses these
callbacks aligns better with cert_cb anyway since Conscrypt expects to
call SSL_use_certificate, etc., itself.
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I68a677e88924d7c3c70a810f21e52abf943cdb1a/Fix reference counting.
SSL_use_certificate and friends were leaking and client_cert_cb was
failing to give refcounts for objects it returns. The two cancelled each
other out.
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Change-Id: I9e9e75902054f59be12f68fb14cf9f3f75a7a46e/Throw IllegalBlockSize when data too large for RSA
Tests are written that expect to get IllegalBlockSize instead of
BadPaddingException when the data is too large for the given RSA
modulus.
Test: cts-tradefed run cts -m CtsKeystoreTestCases -a arm64-v8a
Change-Id: I04b51ec64b66f4339ce45c19cef57ee470d85634/Restrict TLS signing to non-RSA-PSS algorithms
A recent change in BoringSSL allowed connections to use RSA-PSS as the
signing algorithm for TLSv1.2 connections. However, the CryptoUpcalls
interface is not ready for this and it cannot currently make the
upcall correctly to have these signed.
Temporarily disable RSA-PSS signatures with TLS by explicitly setting
the list of signature algorithms.
Test:cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Test:cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Bug: 31714503
Change-Id: Ie1c23b7231b5673816946a6c06030e1e25752415/Fix various post-submit comments
am: f5d5953b62
Change-Id: Idfaf05bab9b68c75ab066899eb190e30e120c779/Fix various post-submit comments
These are various suggestions made after TreeHugger already
auto-submitted changes.
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I88af938fa46f8cd925526709ac4db20d66b8d608/Remove ""unused"" markers
Since the change of the debug logging code to use constexpr, we do not
have as many unused parameters in function signatures since they are
being used in the debug parts that are compiled out. Remove the
unnecessary __attribute__ ((unused)) markers next to them.
Test: No warnings or errors from mmma -j32 external/conscrypt
Change-Id: I920f11e0a3c0ade1f98cc489de40b7bdfc948842/conscrypt: Replace cutils/log.h with android/log.h
Test: compile
Bug: 26552300
Bug: 31289077
Change-Id: Ic2e2d84c2e70ee79f6ee0a8acd7d0b3f08f0b0d8/NativeCrypto: add debugging format checking when debug off am: e6edfeb754 am: ad1a04b89c
am: 662d7c8d98
Change-Id: I40ddbde609a496eb85c9fa9a060d1477756ea5aa/NativeCrypto: fix up debug statements for EVP_AEAD am: abada5b295 am: c5cad79482
am: 7645d8f889
Change-Id: Iaa7791812da87420d15f301cc8b45d0c88fb73dc/NativeCrypto: add debugging format checking when debug off am: e6edfeb754
am: ad1a04b89c
Change-Id: I640dafdf7b1731b1ef627058dc50306ada1c42d5/NativeCrypto: fix up debug statements for EVP_AEAD am: abada5b295
am: c5cad79482
Change-Id: I6b8e11edbee269339b53028271483fd51da153d0/NativeCrypto: add debugging format checking when debug off
am: e6edfeb754
Change-Id: I2f6266735a1fab539edf960d0a742e929b0bd723/NativeCrypto: fix up debug statements for EVP_AEAD
am: abada5b295
Change-Id: I3712d68ce17eeb00604f84e67f1e8c72eb1114ee/NativeCrypto: add debugging format checking when debug off
Before if you enabled WITH_JNI_TRACE you might get some formatting
errors because format is not checked when debugging is enabled. Switch
to constexpr to enable debugging and rely on Dead Code Elimination pass
in the compiler to remove all the debug code when it's not in use. This
allows the compiler to properly check printf-style formatting for debug
statements instead of the preprocessor removing the code.
Test: compile with kWithJniTrace = true and run vogar tests
Change-Id: Ief3fe1c099a38d802db32deb7ffa91e4c8d4a572/NativeCrypto: fix up debug statements for EVP_AEAD
A recent rewrite of EVP_AEAD calls made this deug code go stale.
Test: define WITH_JNI_DEBUG and mmma -j32 external/conscrypt
Change-Id: Ief7461c91c44f99b34cbf2737c833ec142611092/No need to call ERR_remove_thread_state.
In BoringSSL, error data is maintained in thread-locals and
automatically released via thread-local destructors.
ERR_remove_thread_state just calls ERR_clear_error now anyway.
https://commondatastorage.googleapis.com/chromium-boringssl-docs/err.h.html#ERR_remove_thread_state
Change-Id: Ie4b54ec0573f58076eba3102079f773425debcdc
Test: mma/OpenSSLSignature: always throw on setting context
Most of the EVP_PKEY_CTX_ctrl error codes are not handled by Conscrypt
so make sure we have a default exception in case something goes awry
during setup.
Test: vogar --mode host --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-hostdex_intermediates/classes.jack --classpath out/host/common/obj/JAVA_LIBRARIES/mockito-api-hostdex_intermediates/classes.jack libcore/luni/src/test/java/libcore/java/security/SignatureTest.java
Change-Id: I1f5a753242b6bc31cca9feb96486bbc86ad8af54/Remove NPN support
NPN is deprecated and clients should use ALPN instead for now. In the
interest of removing support for it in BoringSSL, we will remove NPN
support from Conscrypt as well.
For now keep around the NPN setters and getters in OpenSSLSocketImpl and
OpenSSLEngineImpl to help with backward compatibility for users that may
be using reflection.
Test: make -j32 && make -j32 cts && cts-tradefed run cts -d -m CtsLibcoreTestCases
Change-Id: Ia4edb21412d9c4b2440291ae0a8a97d2217bf5b5/Fix typo in name of des-ede mapping am: 0af37f8ed6 am: a31bc9eed5
am: 74fe0c16fe
Change-Id: I5b714850306362bbbf1750d89fa398f1ac033ad6/Fix typo in name of des-ede mapping am: 0af37f8ed6
am: a31bc9eed5
Change-Id: Ieabf25289af85daeb7d6cdec0e67910eeb3a6d12/Fix typo in name of des-ede mapping
am: 0af37f8ed6
Change-Id: I1c2ca17759368d1c2203833fc539c713a7344f67/Fix typo in name of des-ede mapping
am: 3209baf397
Change-Id: Id3cf860a111e2d404037d154498d65e0a3a58e01/Stop using malloc in native code am: b14d575175 am: f540393d17
am: 99191daf61
Change-Id: I4f19fecf0cf3a218e9ad48f3abea66e8cd500d4b/Stop using malloc in native code am: b14d575175
am: f540393d17
Change-Id: Ia3884eeaabb964d3e58876d17973c50b6fb8bf79/Stop using malloc in native code
am: b14d575175
Change-Id: I732328ba619359680d5c76dac3f3d35f082d842b/Fix typo in name of des-ede mapping
This was mapping 2-key 3DES to regular DES thus resulting in all
encryption using 2-key 3DES having the wrong answers.
(cherry picked from commit 55caed999846897bcf949828e6e367bf8d7d9909)
Bug: 31081987
Change-Id: I44ba12dcf51d57952cf3ba501381d144d271a2a6/Fix typo in name of des-ede mapping
This was mapping 2-key 3DES to regular DES thus resulting in all
encryption using 2-key 3DES having the wrong answers.
(cherry picked from commit 55caed999846897bcf949828e6e367bf8d7d9909)
Bug: 31081987
Change-Id: I44ba12dcf51d57952cf3ba501381d144d271a2a6/Stop using malloc in native code
Switch the last few stragglers to new/delete since malloc needs casting.
Test: mmma -j32 external/conscrypt && make -j32 build-art-host vogar && vogar --mode host --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-hostdex_intermediates/classes.jack libcore/luni/src/test/java/libcore/javax/crypto/CipherTest.java libcore/luni/src/test/java/libcore/javax/crypto/MacTest.java
Change-Id: I30fb126c5c7a110ae2654ec7f558427d55f0405a/Remove SSL_CTX_set_tmp_ecdh call
This now has the undesired effect of making a client only support this
curve for ECDHE. This used to be needed to allow a server to handshake
with ECDHE, but is now unnecessary for BoringSSL. The client doesn't
want this call and the server no longer needs this call, so delete it.
(cherry picked from commit 1ba6bcf113085c493ccd4574ed685cd0efad4aeb)
Test: mmma -j32 external/conscrypt && make -j32 build-art-host vogar && vogar --mode host --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-hostdex_intermediates/classes.jack libcore/luni/src/test/java/libcore/javax/net/ssl/SSLSocketTest.java
Bug: 31393711
Change-Id: Ib7afdcc3ea7ee3d2222a262f3c57abd065a4b4e1/Substitute NULL for nullptr
Since we don't actually rely on a STL, we don't have <cstdlib> to get
NULL from, but since we're compiling C++11 we get nullptr for free.
This also fixes builds against MacOS SDK since it doesn't have <cstdlib>
available when you explicitly opt out of an STL in the Android.mk module.
Test: mmma -j32 external/conscrypt; make -j29 PRODUCT-sdk_phone_armv7-sdk
Change-Id: I54929c7e5c05ec271925f5f3d1896df1661e9b59/Fix typo in name of des-ede mapping
am: 93838326de
Change-Id: I83e7972190b7bdf33477fe84a85e9de66d2126bd/Fix typo in name of des-ede mapping am: 55caed9998 am: d8a2454005
am: 74ef0c0052
Change-Id: Ic8bc4d1c3da3d143e0bef2948a557217f9210847/Fix typo in name of des-ede mapping am: 55caed9998
am: d8a2454005
Change-Id: I4ac6345ba44f152fc86270a35fd674447d76cbda/Fix typo in name of des-ede mapping
am: 55caed9998
Change-Id: I295541c59a001f5c42fc1b9354e861190e0ffcb9/Fix typo in name of des-ede mapping
This was mapping 2-key 3DES to regular DES thus resulting in all
encryption using 2-key 3DES having the wrong answers.
Bug: 31081987
(cherry picked from commit 55caed999846897bcf949828e6e367bf8d7d9909)
Change-Id: Id06d6c5b5a81142a06451f8ab8bf1c608bff7b6f/Fix typo in name of des-ede mapping
This was mapping 2-key 3DES to regular DES thus resulting in all
encryption using 2-key 3DES having the wrong answers.
Bug: 31081987
Change-Id: I44ba12dcf51d57952cf3ba501381d144d271a2a6/"
conscrypt,"Fix various post-submit comments
am: f5d5953b62
Change-Id: Idfaf05bab9b68c75ab066899eb190e30e120c779/Fix various post-submit comments
These are various suggestions made after TreeHugger already
auto-submitted changes.
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I88af938fa46f8cd925526709ac4db20d66b8d608/OpenSSLCipherRSA: add OAEP implementation
This adds an RSA OAEP implementation for encryption of secrets using the
RSA algorithm and the OAEP padding method as described by RFC 2437
section 7.1.
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: Ifcdeee408b1ab1ce7903152167de9d40acd2efa2/"
conscrypt,"Move MGF1 algorithm name and OID to EvpMdRef
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: Ia3bbceb2a6022ebfbbd7ce1b4c2bb8d8c5ca956b/EvpMdRef: rename SIZE to SIZE_BYTES
This should end confusion about whether EVP_MD_size is measured in bits
or bytes.
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: Iae3dab037dd0bc37313f7cdde643cb140545ccaa/Move JCA names and OIDs to constants
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I2fb67d6e9aa812b3b2ea26e14d18fbe752c70fc3/Use EvpMdRef for size calculation
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I9c909e401d6224f626b69dae3ac21e16a7a9b03c/Move digest name resolution to EvpMdRef
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: Iba6c993fd6721f3fc97e0ccc968e2f9f6ffc22a2/Consolidate EVP_MD references to one place
There were several places where EVP_get_digestbyname was being called
for the same data. Consolidate these all down to one place so there is
no need to call it several times in the same program.
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: Ib3f8b678c775e74eb5edaabde42f042d7b4eac95/OpenSSLSignature: always throw on setting context
Most of the EVP_PKEY_CTX_ctrl error codes are not handled by Conscrypt
so make sure we have a default exception in case something goes awry
during setup.
Test: vogar --mode host --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-hostdex_intermediates/classes.jack --classpath out/host/common/obj/JAVA_LIBRARIES/mockito-api-hostdex_intermediates/classes.jack libcore/luni/src/test/java/libcore/java/security/SignatureTest.java
Change-Id: I1f5a753242b6bc31cca9feb96486bbc86ad8af54/"
conscrypt,"Improve performance of OpenSSLEngine
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Change-Id: I947bd3701e90bd65104f8f5c07ba218c4e051944/Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"Improve performance of OpenSSLEngine
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Change-Id: I947bd3701e90bd65104f8f5c07ba218c4e051944/Strip out SSLv3 from enabled protocols for app compat
HttpsURLConnection on Android before Marshmallow tried to
setEnabledProtocols with just ""SSLv3"" without checking if it was a
supported protocol. Instead of throwing IllegalArgumentException when
the unsupported protocol is encountered, strip it out and later throw an
SSLHandshakeException if no protocols are enabled.
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Bug: 32053327
Bug: 30977793
Change-Id: I2f2008d85fcc5b5fbdc71722a3d6e0a9c22bfbc2/Blacklisting TLS 1.3 ciphersuites from Android
TLS 1.3 adds a new set of AEAD-only ciphers, which will be exposed by
BoringSSL's draft TLS 1.3 implementation. We're not ready to ship TLS 1.3
in Conscrypt yet, but get_cipher_names returns the new ciphers by default
(cipher/version filtering happens much later). Suppress those ciphers for
now.
Test: cts-tradefed run cts -m CtsLibcoreTestCases -m
CtsLibcoreOkHttpTestCases -a arm64-v8a
Change-Id: I14421aec8dceb4b0eb7347b8ebf88a87a10ba856/Drop SSLv3 support
Bug: 30977793
Test: libcore/run-libcore-tests libcore/luni/src/test/java/libcore/javax/net/ssl/*
Change-Id: Ic88ff61bb16017e213a017ecdb16a1ac5b9baa48/OpenSSLSignature: always throw on setting context
Most of the EVP_PKEY_CTX_ctrl error codes are not handled by Conscrypt
so make sure we have a default exception in case something goes awry
during setup.
Test: vogar --mode host --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-hostdex_intermediates/classes.jack --classpath out/host/common/obj/JAVA_LIBRARIES/mockito-api-hostdex_intermediates/classes.jack libcore/luni/src/test/java/libcore/java/security/SignatureTest.java
Change-Id: I1f5a753242b6bc31cca9feb96486bbc86ad8af54/Remove NPN support
NPN is deprecated and clients should use ALPN instead for now. In the
interest of removing support for it in BoringSSL, we will remove NPN
support from Conscrypt as well.
For now keep around the NPN setters and getters in OpenSSLSocketImpl and
OpenSSLEngineImpl to help with backward compatibility for users that may
be using reflection.
Test: make -j32 && make -j32 cts && cts-tradefed run cts -d -m CtsLibcoreTestCases
Change-Id: Ia4edb21412d9c4b2440291ae0a8a97d2217bf5b5/Drop RC4 cipher suite support from TLS
Bug: 30977793
Test: libcore/run-libcore-tests libcore/luni/src/test/java/libcore/javax/net/ssl/* and running NativeCryptoTest.
Change-Id: I04b91a6d3bf75a757d2c74bd1a39aea2709a9199/"
conscrypt,"OpenSSLCipher: try to prevent key and nonce reuse in GCM
Cache the previously used key and IV to try and prevent re-use. This
will not stop people determined to reuse the same key and IV, but it
should help accidentally doing this or doing it out of ignorance
Test: wycheproof tests
Test: make -j32 build-art-host vogar && vogar --mode host --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-hostdex_intermediates/classes.jack libcore/luni/src/test/java/libcore/javax/crypto/CipherTest.java
Bug: 30231101
Change-Id: I4619f9216d490eceb8d14727ce2b5b141877d2b7/Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"Partial revert of ""Fix static analysis findings"" am: 0a94f01997 am: 1775b34aa9
am: 7859000d51
Change-Id: I8d7270b8ac5e35701167b038a7b77f7f3b8405d7/Partial revert of ""Fix static analysis findings"" am: 0a94f01997
am: 1775b34aa9
Change-Id: Iccb82c44eb83ac95f5b430c78e1d0e2a00277733/Partial revert of ""Fix static analysis findings""
am: 0a94f01997
Change-Id: Ifb3950135033c352af6ee576ffe9898c82521e3c/Partial revert of ""Fix static analysis findings""
This reverts commit ee3b1694a206350e87a70cc83dd35a1ec2053fd6.
This causes deadlocks for wrapped sockets.
Bug: 31449904
Test: make -j32 build-art-host vogar && vogar --mode host --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-hostdex_intermediates/classes.jack libcore/luni/src/test/java/libcore/javax/net/ssl/SSLSocketTest.java
Change-Id: Iedf2244ae4ed8bd79dae996406c7668ebadc832e/"
conscrypt,"Improve performance of OpenSSLEngine
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Change-Id: I947bd3701e90bd65104f8f5c07ba218c4e051944/OpenSSLEngineImpl: throw ISE if client/server mode not set
According to SSLEngine documentation, IllegalStateException will be
thrown if #wrap or #unwrap is called before setting the client/server
mode. When OpenSSLEngineImpl was written, it was written against the
existing tests which did not fail in this scenario due to a missing
fail() call in the try/catch.
The existing test calls #wrap with a 10 byte buffer which immediatly
hits the BUFFER_OVERFLOW condition. To avoid this the ByteBuffer check
was moved below the state check which means calling #wrap with a
too-small buffer without starting the handshake first will fail on the
buffer size check only after the first call. This should not affect
callers as they have to handle this condition during the normal
operation of the SSLEngine anyway.
Test: vogar --mode host --classpath out/target/common/obj/JAVA_LIBRARIES/bouncycastle_intermediates/classes.jack --classpath out/target/common/obj/JAVA_LIBRARIES/bouncycastle-ocsp_intermediates/classes.jack --classpath out/target/common/obj/JAVA_LIBRARIES/bouncycastle-bcpkix_intermediates/classes.jack --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-hostdex_intermediates/classes.jack libcore/harmony-tests/src/test/java/org/apache/harmony/tests/javax/net/ssl/SSLEngineTest.java
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Bug: 31301555
Change-Id: I6f4c36d5abcc71e020ce40c7f61df2ed01b1a53e/Remove NPN support
NPN is deprecated and clients should use ALPN instead for now. In the
interest of removing support for it in BoringSSL, we will remove NPN
support from Conscrypt as well.
For now keep around the NPN setters and getters in OpenSSLSocketImpl and
OpenSSLEngineImpl to help with backward compatibility for users that may
be using reflection.
Test: make -j32 && make -j32 cts && cts-tradefed run cts -d -m CtsLibcoreTestCases
Change-Id: Ia4edb21412d9c4b2440291ae0a8a97d2217bf5b5/"
conscrypt,"Improve performance of OpenSSLEngine
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Change-Id: I947bd3701e90bd65104f8f5c07ba218c4e051944/Partial revert of ""Fix static analysis findings"" am: 0a94f01997 am: 1775b34aa9
am: 7859000d51
Change-Id: I8d7270b8ac5e35701167b038a7b77f7f3b8405d7/Partial revert of ""Fix static analysis findings"" am: 0a94f01997
am: 1775b34aa9
Change-Id: Iccb82c44eb83ac95f5b430c78e1d0e2a00277733/Partial revert of ""Fix static analysis findings""
am: 0a94f01997
Change-Id: Ifb3950135033c352af6ee576ffe9898c82521e3c/Partial revert of ""Fix static analysis findings""
This reverts commit ee3b1694a206350e87a70cc83dd35a1ec2053fd6.
This causes deadlocks for wrapped sockets.
Bug: 31449904
Test: make -j32 build-art-host vogar && vogar --mode host --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-support-hostdex_intermediates/classes.jack --classpath out/host/common/obj/JAVA_LIBRARIES/core-tests-hostdex_intermediates/classes.jack libcore/luni/src/test/java/libcore/javax/net/ssl/SSLSocketTest.java
Change-Id: Iedf2244ae4ed8bd79dae996406c7668ebadc832e/Remove NPN support
NPN is deprecated and clients should use ALPN instead for now. In the
interest of removing support for it in BoringSSL, we will remove NPN
support from Conscrypt as well.
For now keep around the NPN setters and getters in OpenSSLSocketImpl and
OpenSSLEngineImpl to help with backward compatibility for users that may
be using reflection.
Test: make -j32 && make -j32 cts && cts-tradefed run cts -d -m CtsLibcoreTestCases
Change-Id: Ia4edb21412d9c4b2440291ae0a8a97d2217bf5b5/Fix imports globally am: d0687b8c0d am: 967b0b11a3
am: be78c56078
Change-Id: Id8c38445063db7effaaacd3671a9c43eb4b3271a/Fix imports globally am: d0687b8c0d
am: 967b0b11a3
Change-Id: I0ec9a42c2209792fd28913ee8eb7890091a4d444/Fix imports globally
am: d0687b8c0d
Change-Id: I2680d85a6655bbe2ada4c34fa6ff6d1bda332856/Fix imports globally
Ran script to fix imports globally on all .java files. Committing
results.
Test: mmma -j32 external/conscrypt
Change-Id: I6cd19c0f3dc66c8dcaec3c92a6019b4c0154e9e4/"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/"
conscrypt,"Fix test imports
Apparently these out-of-order and unused imports snuck in to the Android
tree. Fix them up.
Test: mmma -j32 external/conscrypt
Change-Id: Ibd1abc5ce672609bf483f10fe5f3c697e0d51a05/"
conscrypt,"Configure OCSP and SCTs on the SSL, not SSL_CTX.
As Conscrypt is currently set up, one SSL_CTX (owned, ultimately, by the
SSLContext) may correspond to multiple SSLParameters which, in the Java
API, are configured on the SSLSocket or SSLEngine directly. Thus we
should use the SSL versions of the APIs which now exist. This avoids
mutating an SSL_CTX which may be shared by multiple SSLs with different
configurations.
Change-Id: I19485c316087004c6050d85520b0169f2ca0d493/Fix renegotiation-based tests
BoringSSL no longer supports on-demand renegotiation, so tests that
are based on that cannot pass.  Change one test to confirm that,
and remove the other./Conscrypt: Fix renegotiation-based tests
BoringSSL no longer supports on-demand renegotiation, so tests that
are based on that cannot pass.  Change one test to confirm that,
and remove the other.
Bug: 21876068
Bug: 21875889
Test: cts -m CtsLibcoreTestCases -t com.android.org.conscrypt.NativeCryptoTest
Change-Id: Ia7596e773e855edf38a4e0b94dbef7f11795ad87/"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/Fix test imports
Apparently these out-of-order and unused imports snuck in to the Android
tree. Fix them up.
Test: mmma -j32 external/conscrypt
Change-Id: Ibd1abc5ce672609bf483f10fe5f3c697e0d51a05/"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/Add Java 8 style SNI hostname to OpenSSLEngineImpl (#155)
The SNIHostName, et al., support was lacking from OpenSSLEngineImpl
causing endpoint protocol identification to fail in Netty tests./"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/Merge upstream master
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I2c0020c76b48f549b898e09be0612710616ea602/"
conscrypt,"Merge upstream master
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I2c0020c76b48f549b898e09be0612710616ea602/"
conscrypt,"Benchmark fixes and various cleanup. (#188)/Add Java 8 style SNI hostname to OpenSSLEngineImpl (#155)
The SNIHostName, et al., support was lacking from OpenSSLEngineImpl
causing endpoint protocol identification to fail in Netty tests./Add error-prone and fix all the errors (#146)/"
conscrypt,"Move Netty-specific things to the benchmark dir
Netty is not in the Android tree, so adding dependencies on it breaks
the build. Since we currently don't run the SslEngineBenchmark, stick
the methods that it needs there.
Nothing else currently uses those methods. Additionally nothing is left
that uses the NettyServer class as well./"
conscrypt,"Merge upstream master
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I2c0020c76b48f549b898e09be0612710616ea602/"
conscrypt,"Merge upstream master
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I2c0020c76b48f549b898e09be0612710616ea602/"
conscrypt,"Merge upstream master
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I2c0020c76b48f549b898e09be0612710616ea602/"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/Merge upstream master
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I2c0020c76b48f549b898e09be0612710616ea602/Fixing various javadoc issues. (#124)
Also locking down access to a couple utility classes./"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/Merge upstream master
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I2c0020c76b48f549b898e09be0612710616ea602/Fixing various javadoc issues. (#124)
Also locking down access to a couple utility classes./"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/Suppress Error-Prone warnings
These warnings are not useful here, so suppress them./"
conscrypt,"Adding all factory methods for engine socket. (#192)
Also properly throwing SSLHandshakeException in some cases.
Fixes #191/Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/Merge upstream master
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I2c0020c76b48f549b898e09be0612710616ea602/Add handshake listener to engine. (#136)
Fixes #60/Fixing various javadoc issues. (#124)
Also locking down access to a couple utility classes./"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/Configure OCSP and SCTs on the SSL, not SSL_CTX.
As Conscrypt is currently set up, one SSL_CTX (owned, ultimately, by the
SSLContext) may correspond to multiple SSLParameters which, in the Java
API, are configured on the SSLSocket or SSLEngine directly. Thus we
should use the SSL versions of the APIs which now exist. This avoids
mutating an SSL_CTX which may be shared by multiple SSLs with different
configurations.
Change-Id: I19485c316087004c6050d85520b0169f2ca0d493/Merge upstream master
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I2c0020c76b48f549b898e09be0612710616ea602/Fixing various javadoc issues. (#124)
Also locking down access to a couple utility classes./"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/Extract AEADBadTagException throwing to method
This is not available on all Android versions, so we access it via
reflection here. Extract it to its own method so we can suppress the
Error-Prone warning more precisely./Merge upstream master
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I2c0020c76b48f549b898e09be0612710616ea602/Fixing various javadoc issues. (#124)
Also locking down access to a couple utility classes./"
conscrypt,"Adding all factory methods for engine socket. (#192)
Also properly throwing SSLHandshakeException in some cases.
Fixes #191/Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/Suppress Error-Prone warnings
These warnings are not useful here, so suppress them./"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/Merge upstream master
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I2c0020c76b48f549b898e09be0612710616ea602/"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/"
conscrypt,"Adding all factory methods for engine socket. (#192)
Also properly throwing SSLHandshakeException in some cases.
Fixes #191/Fix unwrap bug for large messages. (#189)
If you write a record and don't have enough destination buffer space to read all the plaintext, the plaintext gets left in the plaintext buffer and the next record you write ends up in the ciphertext buffer (and you read the leftover plaintext from the last record), and you continue to have a record sitting in the ciphertext buffer until you get two records that don't fit in the buffer together, at which point you get the short write and subsequent exception.
Also added a test to verify the bug./Add Java 8 style SNI hostname to OpenSSLEngineImpl (#155)
The SNIHostName, et al., support was lacking from OpenSSLEngineImpl
causing endpoint protocol identification to fail in Netty tests./Add error-prone and fix all the errors (#146)/Throw SSLHandshakeException for bad certs. (#147)
Also expanding some of the test coverage in OpenSSLEngineImplTest./Configure OCSP and SCTs on the SSL, not SSL_CTX.
As Conscrypt is currently set up, one SSL_CTX (owned, ultimately, by the
SSLContext) may correspond to multiple SSLParameters which, in the Java
API, are configured on the SSLSocket or SSLEngine directly. Thus we
should use the SSL versions of the APIs which now exist. This avoids
mutating an SSL_CTX which may be shared by multiple SSLs with different
configurations.
Change-Id: I19485c316087004c6050d85520b0169f2ca0d493/Merge upstream master
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I2c0020c76b48f549b898e09be0612710616ea602/Add handshake listener to engine. (#136)
Fixes #60/Less restrictive output buffer size in wrap() (#114)
We currently require that the output buffer be >= MAX_PACKET_SIZE. This is needlessly strict and causes the Netty tests to fail, since they only use 2k buffers.
This PR copies over some of the recent changes from Netty to handle this properly./"
conscrypt,"Locking down public APIs (#157)
Tried to be as aggressive as I could, so this probably deserves a fairly thorough review.  I left most of OpenSSLSocketImpl public, because I think it's needed by a few external projects.
I also did some cleanup work to get rid of a bunch of compiler warnings that we seem to have accumulated.
Fixes #142/Configure OCSP and SCTs on the SSL, not SSL_CTX.
As Conscrypt is currently set up, one SSL_CTX (owned, ultimately, by the
SSLContext) may correspond to multiple SSLParameters which, in the Java
API, are configured on the SSLSocket or SSLEngine directly. Thus we
should use the SSL versions of the APIs which now exist. This avoids
mutating an SSL_CTX which may be shared by multiple SSLs with different
configurations.
Change-Id: I19485c316087004c6050d85520b0169f2ca0d493/Merge upstream master
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I2c0020c76b48f549b898e09be0612710616ea602/Fixing various javadoc issues. (#124)
Also locking down access to a couple utility classes./"
conscrypt,"Add Java 8 style SNI hostname to OpenSSLEngineImpl (#155)
The SNIHostName, et al., support was lacking from OpenSSLEngineImpl
causing endpoint protocol identification to fail in Netty tests./Suppress Error-Prone warnings
These warnings are not useful here, so suppress them./Use getDeclaredConstructor().newInstance()
This allows some compile-time checks to be performed by the compiler. In
this instance we don't do anything with the failure.
See http://errorprone.info/bugpattern/ClassNewInstance for more info./"
conscrypt,"Suppress Error-Prone warnings
These warnings are not useful here, so suppress them./"
conscrypt,"Suppress Error-Prone warnings
These warnings are not useful here, so suppress them./"
conscrypt,"Merge upstream master
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I2c0020c76b48f549b898e09be0612710616ea602/"
conscrypt,"Merge upstream master
Test: cts-tradefed run cts -m CtsLibcoreOkHttpTestCases -a arm64-v8a
Test: cts-tradefed run cts -m CtsLibcoreTestCases -a arm64-v8a
Change-Id: I2c0020c76b48f549b898e09be0612710616ea602/"
conscrypt,"Refactoring session management (#172)
This change breaks session management into two distinct types:
- SslSessionWrapper: These are created as BoringSSL calls back the new session handler, allowing the application to cache sessions. Clients will also offer these to BoringSSL for reuse if a compatible session was found. BoringSSL is free to use it or not, but the Conscrypt code no longer makes assumptions here. Instead, it always uses the ActiveSession.
- ActiveSession: This is a session that wraps the SSL instance (rather than the SSL_SESSION wherever possible). That way no concern has to be paid to what BoringSSL is doing with sessions under the covers.
Fixes #98/"
conscrypt,"Customize default provider name based on platform (#314)
Fixes #312/Use InetAddress originalHostName (if present) for getHostnameOrIP (#303)
* Use InetAddress originalHostName (is present) for getHostnameOrIP
Test: CtsLibcoreTestCases
Bug: 35942385
Bug: 31028374
Change-Id: Ie1acc2dd23fadbbc48de1a5845146e9a5953e9cf
* Fix lint problems and remove class introduced in API 19./Support Java 6 Runtime (#299)
Various fixes to support Java 6, 7, and 8. Separating out
utility classes (for openjdk) to be explicit as to which methods are
supported by particular Java version.
Adding the ability to specify the test JVM to use on the command-line.
For example, the following will build with the default Java
installation, but will run the openjdk and integ-tests with Java 6:
./gradlew build -DjavaExecutable64=${JAVA6_HOME}/bin/java
Fixes #298/Refactoring session management (#172)
This change breaks session management into two distinct types:
- SslSessionWrapper: These are created as BoringSSL calls back the new session handler, allowing the application to cache sessions. Clients will also offer these to BoringSSL for reuse if a compatible session was found. BoringSSL is free to use it or not, but the Conscrypt code no longer makes assumptions here. Instead, it always uses the ActiveSession.
- ActiveSession: This is a session that wraps the SSL instance (rather than the SSL_SESSION wherever possible). That way no concern has to be paid to what BoringSSL is doing with sessions under the covers.
Fixes #98/Conformance fixes for the engine-based socket. (#202)
This allows the SSLSocketTest to pass with the engine-based socket
enabled.
Also restructuring the inheritance hierarchy so that the FD and engine
sockets both behave the same way (both either wrappers or not). The
restructure involves the following:
- AbstractConscryptSocket: New base class for both sockets. It handles
the wrap/no-wrap logic.
- OpenSSLSocketImplWrapper: deleted and replaced by
AbstractConscryptSocket.
- OpenSSLSocketImpl: reduced to a public shim class between
AbstractConscryptSocket and the implementations. For backward-compat
only.
- ConscryptFileDescriptorSocket: Renamed from OpenSSLSocketImpl. The
old FD socket./Various fixes to the Conscrypt engine. (#201)/"
conscrypt,"Conformance fixes for the engine-based socket. (#202)
This allows the SSLSocketTest to pass with the engine-based socket
enabled.
Also restructuring the inheritance hierarchy so that the FD and engine
sockets both behave the same way (both either wrappers or not). The
restructure involves the following:
- AbstractConscryptSocket: New base class for both sockets. It handles
the wrap/no-wrap logic.
- OpenSSLSocketImplWrapper: deleted and replaced by
AbstractConscryptSocket.
- OpenSSLSocketImpl: reduced to a public shim class between
AbstractConscryptSocket and the implementations. For backward-compat
only.
- ConscryptFileDescriptorSocket: Renamed from OpenSSLSocketImpl. The
old FD socket./"
conscrypt,"Support Java 6 Runtime (#299)
Various fixes to support Java 6, 7, and 8. Separating out
utility classes (for openjdk) to be explicit as to which methods are
supported by particular Java version.
Adding the ability to specify the test JVM to use on the command-line.
For example, the following will build with the default Java
installation, but will run the openjdk and integ-tests with Java 6:
./gradlew build -DjavaExecutable64=${JAVA6_HOME}/bin/java
Fixes #298/Use Java logging consistently (#294)
There are many places in the code that print to System.out/err. We
should use the standard Java logging facilities.
Fixes #212/Switch to SSL_get0_peer_certificates.
This works towards issue #258. So the exception can be routed out
properly, this moves the SSL_get0_peer_certificates call to after
doHandshake completes in ConscryptFileDescriptorSocket.
Although, due to False Start (the ""cut-through"" logic in that class),
the handshake may not be fully complete at the time, BoringSSL's API is
such that the certificates and other properties will be available once
SSL_do_handshake first completes./Cleaning up JNI exceptions (#252)
There were a bunch of exceptions that are being thrown from JNI methods that aren't currently declared.
Also removed a few unused JNI methods and duplicate constants, preferring those from NativeConstants./Avoid reprocessing the local certificates. (#250)
We were needlessly querying the SSL for the local certificates
during the handshake. Avoiding this shows a minor bump in
handshake performance
See #247/Remove Java <-> OpenSSL name mapping. (#227)
As of [0], BoringSSL supports the standard cipher suite names. The Java
names are the same, with the exception of
TLS_RSA_WITH_3DES_EDE_CBC_SHA/SSL_RSA_WITH_3DES_EDE_CBC_SHA for
historical reasons. Add code to map between that exception but otherwise
rely on the native support.
[0] https://boringssl.googlesource.com/boringssl/+/6fff386492d9f316f5f780ff9d0ddaf1700f98a9,/Remove remnants of broken SSL_renegotiate tests. (#229)
See issue #228. These don't work anymore and will need to be rewritten,
probably against a test implementation./Refactoring session management (#172)
This change breaks session management into two distinct types:
- SslSessionWrapper: These are created as BoringSSL calls back the new session handler, allowing the application to cache sessions. Clients will also offer these to BoringSSL for reuse if a compatible session was found. BoringSSL is free to use it or not, but the Conscrypt code no longer makes assumptions here. Instead, it always uses the ActiveSession.
- ActiveSession: This is a session that wraps the SSL instance (rather than the SSL_SESSION wherever possible). That way no concern has to be paid to what BoringSSL is doing with sessions under the covers.
Fixes #98/"
conscrypt,"User-friendly errors when native library fails to load (#295)
Currently, we throw in static initialization of NativeCryptoJni, which
leads to ClassNotFoundException whenever we try to access the native
code at runtime. The user has no way of knowing that the library failed
to load, or why. This PR attempts to make it more clear as to what
went wrong, by doing the following:
- Log each load error, in the order attempted.
- Select the ""best"" load error to be thrown
- Don't throw from the NativeCrypto static initializer. Rather, save
the best error and throw when attempting to access top-level conscrypt
classes./"
conscrypt,"Customize default provider name based on platform (#314)
Fixes #312/Use InetAddress originalHostName (if present) for getHostnameOrIP (#303)
* Use InetAddress originalHostName (is present) for getHostnameOrIP
Test: CtsLibcoreTestCases
Bug: 35942385
Bug: 31028374
Change-Id: Ie1acc2dd23fadbbc48de1a5845146e9a5953e9cf
* Fix lint problems and remove class introduced in API 19./User-friendly errors when native library fails to load (#295)
Currently, we throw in static initialization of NativeCryptoJni, which
leads to ClassNotFoundException whenever we try to access the native
code at runtime. The user has no way of knowing that the library failed
to load, or why. This PR attempts to make it more clear as to what
went wrong, by doing the following:
- Log each load error, in the order attempted.
- Select the ""best"" load error to be thrown
- Don't throw from the NativeCrypto static initializer. Rather, save
the best error and throw when attempting to access top-level conscrypt
classes./Support Java 6 Runtime (#299)
Various fixes to support Java 6, 7, and 8. Separating out
utility classes (for openjdk) to be explicit as to which methods are
supported by particular Java version.
Adding the ability to specify the test JVM to use on the command-line.
For example, the following will build with the default Java
installation, but will run the openjdk and integ-tests with Java 6:
./gradlew build -DjavaExecutable64=${JAVA6_HOME}/bin/java
Fixes #298/Refactoring session management (#172)
This change breaks session management into two distinct types:
- SslSessionWrapper: These are created as BoringSSL calls back the new session handler, allowing the application to cache sessions. Clients will also offer these to BoringSSL for reuse if a compatible session was found. BoringSSL is free to use it or not, but the Conscrypt code no longer makes assumptions here. Instead, it always uses the ActiveSession.
- ActiveSession: This is a session that wraps the SSL instance (rather than the SSL_SESSION wherever possible). That way no concern has to be paid to what BoringSSL is doing with sessions under the covers.
Fixes #98/Conformance fixes for the engine-based socket. (#202)
This allows the SSLSocketTest to pass with the engine-based socket
enabled.
Also restructuring the inheritance hierarchy so that the FD and engine
sockets both behave the same way (both either wrappers or not). The
restructure involves the following:
- AbstractConscryptSocket: New base class for both sockets. It handles
the wrap/no-wrap logic.
- OpenSSLSocketImplWrapper: deleted and replaced by
AbstractConscryptSocket.
- OpenSSLSocketImpl: reduced to a public shim class between
AbstractConscryptSocket and the implementations. For backward-compat
only.
- ConscryptFileDescriptorSocket: Renamed from OpenSSLSocketImpl. The
old FD socket./Various fixes to the Conscrypt engine. (#201)/"
conscrypt,"Support Java 6 Runtime (#299)
Various fixes to support Java 6, 7, and 8. Separating out
utility classes (for openjdk) to be explicit as to which methods are
supported by particular Java version.
Adding the ability to specify the test JVM to use on the command-line.
For example, the following will build with the default Java
installation, but will run the openjdk and integ-tests with Java 6:
./gradlew build -DjavaExecutable64=${JAVA6_HOME}/bin/java
Fixes #298/"
conscrypt,"Refactoring session management (#172)
This change breaks session management into two distinct types:
- SslSessionWrapper: These are created as BoringSSL calls back the new session handler, allowing the application to cache sessions. Clients will also offer these to BoringSSL for reuse if a compatible session was found. BoringSSL is free to use it or not, but the Conscrypt code no longer makes assumptions here. Instead, it always uses the ActiveSession.
- ActiveSession: This is a session that wraps the SSL instance (rather than the SSL_SESSION wherever possible). That way no concern has to be paid to what BoringSSL is doing with sessions under the covers.
Fixes #98/"
conscrypt,"Support Java 6 Runtime (#299)
Various fixes to support Java 6, 7, and 8. Separating out
utility classes (for openjdk) to be explicit as to which methods are
supported by particular Java version.
Adding the ability to specify the test JVM to use on the command-line.
For example, the following will build with the default Java
installation, but will run the openjdk and integ-tests with Java 6:
./gradlew build -DjavaExecutable64=${JAVA6_HOME}/bin/java
Fixes #298/Cleaning up JNI exceptions (#252)
There were a bunch of exceptions that are being thrown from JNI methods that aren't currently declared.
Also removed a few unused JNI methods and duplicate constants, preferring those from NativeConstants./Only allow the use of the proper key in RSA with OAEP. (#222)
BoringSSL only supports using public keys for encryption and private keys
for decryption (which are the proper combinations) in the interface
we use for RSA with OAEP.  Throw an exception on initialization instead
of waiting until the crypto operation fails inside BoringSSL./"
conscrypt,"Support Java 6 Runtime (#299)
Various fixes to support Java 6, 7, and 8. Separating out
utility classes (for openjdk) to be explicit as to which methods are
supported by particular Java version.
Adding the ability to specify the test JVM to use on the command-line.
For example, the following will build with the default Java
installation, but will run the openjdk and integ-tests with Java 6:
./gradlew build -DjavaExecutable64=${JAVA6_HOME}/bin/java
Fixes #298/"
conscrypt,"Conformance fixes for the engine-based socket. (#202)
This allows the SSLSocketTest to pass with the engine-based socket
enabled.
Also restructuring the inheritance hierarchy so that the FD and engine
sockets both behave the same way (both either wrappers or not). The
restructure involves the following:
- AbstractConscryptSocket: New base class for both sockets. It handles
the wrap/no-wrap logic.
- OpenSSLSocketImplWrapper: deleted and replaced by
AbstractConscryptSocket.
- OpenSSLSocketImpl: reduced to a public shim class between
AbstractConscryptSocket and the implementations. For backward-compat
only.
- ConscryptFileDescriptorSocket: Renamed from OpenSSLSocketImpl. The
old FD socket./Various fixes to the Conscrypt engine. (#201)/"
conscrypt,"User-friendly errors when native library fails to load (#295)
Currently, we throw in static initialization of NativeCryptoJni, which
leads to ClassNotFoundException whenever we try to access the native
code at runtime. The user has no way of knowing that the library failed
to load, or why. This PR attempts to make it more clear as to what
went wrong, by doing the following:
- Log each load error, in the order attempted.
- Select the ""best"" load error to be thrown
- Don't throw from the NativeCrypto static initializer. Rather, save
the best error and throw when attempting to access top-level conscrypt
classes./Switch to SSL_get0_peer_certificates.
This works towards issue #258. So the exception can be routed out
properly, this moves the SSL_get0_peer_certificates call to after
doHandshake completes in ConscryptFileDescriptorSocket.
Although, due to False Start (the ""cut-through"" logic in that class),
the handshake may not be fully complete at the time, BoringSSL's API is
such that the certificates and other properties will be available once
SSL_do_handshake first completes./Cleaning up JNI exceptions (#252)
There were a bunch of exceptions that are being thrown from JNI methods that aren't currently declared.
Also removed a few unused JNI methods and duplicate constants, preferring those from NativeConstants./Avoid reprocessing the local certificates. (#250)
We were needlessly querying the SSL for the local certificates
during the handshake. Avoiding this shows a minor bump in
handshake performance
See #247/Add IvParameters and ECParameters to Conscrypt. (#251)
IvParameters is used as the AlgorithmParameters implementation for AES
and DESEDE.  ECParameters only supports named curves, since BoringSSL
provides functions for marshalling curve names but not arbitrary curves
and generally discourages the use of arbitrary curves (eg, ec.h says
""Avoid using arbitrary curves and use EC_GROUP_new_by_curve_name
instead."")/Implement AlgorithmParameters.OAEP in Conscrypt. (#240)
* Implement AlgorithmParameters.OAEP in Conscrypt.
* Use JNI_TRUE and JNI_FALSE as return values, and clarify some exception messages./Remove Java <-> OpenSSL name mapping. (#227)
As of [0], BoringSSL supports the standard cipher suite names. The Java
names are the same, with the exception of
TLS_RSA_WITH_3DES_EDE_CBC_SHA/SSL_RSA_WITH_3DES_EDE_CBC_SHA for
historical reasons. Add code to map between that exception but otherwise
rely on the native support.
[0] https://boringssl.googlesource.com/boringssl/+/6fff386492d9f316f5f780ff9d0ddaf1700f98a9,/Implement AlgorithmParameters.GCM in Conscrypt. (#217)
* Implement AlgorithmParameters.GCM in Conscrypt.
In order to handle the ASN.1 encoding, exposes a subset of the ASN.1
encoding API from BoringSSL in NativeCrypto.
* Rename {write,read}_integer to {write,read}_uint64.
Add a UniquePtr to ensure exceptions don't cause a memory leak./Some parsing and serializing fixes. (#219)
This fixes a memory leak in NativeCrypto_i2d_PKCS7. It never frees
derBytes. Also removing a dependency on the legacy ASN.1 stack./Remove remnants of broken SSL_renegotiate tests. (#229)
See issue #228. These don't work anymore and will need to be rewritten,
probably against a test implementation./Add availability checks (#216)
Fixes #211/Refactoring session management (#172)
This change breaks session management into two distinct types:
- SslSessionWrapper: These are created as BoringSSL calls back the new session handler, allowing the application to cache sessions. Clients will also offer these to BoringSSL for reuse if a compatible session was found. BoringSSL is free to use it or not, but the Conscrypt code no longer makes assumptions here. Instead, it always uses the ActiveSession.
- ActiveSession: This is a session that wraps the SSL instance (rather than the SSL_SESSION wherever possible). That way no concern has to be paid to what BoringSSL is doing with sessions under the covers.
Fixes #98/Various fixes to the Conscrypt engine. (#201)/"
conscrypt,"Support Java 6 Runtime (#299)
Various fixes to support Java 6, 7, and 8. Separating out
utility classes (for openjdk) to be explicit as to which methods are
supported by particular Java version.
Adding the ability to specify the test JVM to use on the command-line.
For example, the following will build with the default Java
installation, but will run the openjdk and integ-tests with Java 6:
./gradlew build -DjavaExecutable64=${JAVA6_HOME}/bin/java
Fixes #298/"
conscrypt,"Support Java 6 Runtime (#299)
Various fixes to support Java 6, 7, and 8. Separating out
utility classes (for openjdk) to be explicit as to which methods are
supported by particular Java version.
Adding the ability to specify the test JVM to use on the command-line.
For example, the following will build with the default Java
installation, but will run the openjdk and integ-tests with Java 6:
./gradlew build -DjavaExecutable64=${JAVA6_HOME}/bin/java
Fixes #298/getOutputSize should consider update() as well as doFinal() (#288)
Fixes #267./Add IvParameters and ECParameters to Conscrypt. (#251)
IvParameters is used as the AlgorithmParameters implementation for AES
and DESEDE.  ECParameters only supports named curves, since BoringSSL
provides functions for marshalling curve names but not arbitrary curves
and generally discourages the use of arbitrary curves (eg, ec.h says
""Avoid using arbitrary curves and use EC_GROUP_new_by_curve_name
instead."")/"
conscrypt,"Conformance fixes for the engine-based socket. (#202)
This allows the SSLSocketTest to pass with the engine-based socket
enabled.
Also restructuring the inheritance hierarchy so that the FD and engine
sockets both behave the same way (both either wrappers or not). The
restructure involves the following:
- AbstractConscryptSocket: New base class for both sockets. It handles
the wrap/no-wrap logic.
- OpenSSLSocketImplWrapper: deleted and replaced by
AbstractConscryptSocket.
- OpenSSLSocketImpl: reduced to a public shim class between
AbstractConscryptSocket and the implementations. For backward-compat
only.
- ConscryptFileDescriptorSocket: Renamed from OpenSSLSocketImpl. The
old FD socket./Various fixes to the Conscrypt engine. (#201)/"
conscrypt,"Support Java 6 Runtime (#299)
Various fixes to support Java 6, 7, and 8. Separating out
utility classes (for openjdk) to be explicit as to which methods are
supported by particular Java version.
Adding the ability to specify the test JVM to use on the command-line.
For example, the following will build with the default Java
installation, but will run the openjdk and integ-tests with Java 6:
./gradlew build -DjavaExecutable64=${JAVA6_HOME}/bin/java
Fixes #298/Refactoring session management (#172)
This change breaks session management into two distinct types:
- SslSessionWrapper: These are created as BoringSSL calls back the new session handler, allowing the application to cache sessions. Clients will also offer these to BoringSSL for reuse if a compatible session was found. BoringSSL is free to use it or not, but the Conscrypt code no longer makes assumptions here. Instead, it always uses the ActiveSession.
- ActiveSession: This is a session that wraps the SSL instance (rather than the SSL_SESSION wherever possible). That way no concern has to be paid to what BoringSSL is doing with sessions under the covers.
Fixes #98/Move closer to the old test version
The original test never called shutdownInput() since the Javadoc
indicates it will make the socket behave in a different manner than
expected in this test.
Also assert that we're not using the type of socket that we expect to
return -1 if we get a SocketException. This will indicate when this
difference is fixed and the test can be changed to reflect the
expectation./Conformance fixes for the engine-based socket. (#202)
This allows the SSLSocketTest to pass with the engine-based socket
enabled.
Also restructuring the inheritance hierarchy so that the FD and engine
sockets both behave the same way (both either wrappers or not). The
restructure involves the following:
- AbstractConscryptSocket: New base class for both sockets. It handles
the wrap/no-wrap logic.
- OpenSSLSocketImplWrapper: deleted and replaced by
AbstractConscryptSocket.
- OpenSSLSocketImpl: reduced to a public shim class between
AbstractConscryptSocket and the implementations. For backward-compat
only.
- ConscryptFileDescriptorSocket: Renamed from OpenSSLSocketImpl. The
old FD socket./Various fixes to the Conscrypt engine. (#201)/"
conscrypt,"Support Java 6 Runtime (#299)
Various fixes to support Java 6, 7, and 8. Separating out
utility classes (for openjdk) to be explicit as to which methods are
supported by particular Java version.
Adding the ability to specify the test JVM to use on the command-line.
For example, the following will build with the default Java
installation, but will run the openjdk and integ-tests with Java 6:
./gradlew build -DjavaExecutable64=${JAVA6_HOME}/bin/java
Fixes #298/"
conscrypt,"Customize default provider name based on platform (#314)
Fixes #312/Use InetAddress originalHostName (if present) for getHostnameOrIP (#303)
* Use InetAddress originalHostName (is present) for getHostnameOrIP
Test: CtsLibcoreTestCases
Bug: 35942385
Bug: 31028374
Change-Id: Ie1acc2dd23fadbbc48de1a5845146e9a5953e9cf
* Fix lint problems and remove class introduced in API 19./Support Java 6 Runtime (#299)
Various fixes to support Java 6, 7, and 8. Separating out
utility classes (for openjdk) to be explicit as to which methods are
supported by particular Java version.
Adding the ability to specify the test JVM to use on the command-line.
For example, the following will build with the default Java
installation, but will run the openjdk and integ-tests with Java 6:
./gradlew build -DjavaExecutable64=${JAVA6_HOME}/bin/java
Fixes #298/Refactoring session management (#172)
This change breaks session management into two distinct types:
- SslSessionWrapper: These are created as BoringSSL calls back the new session handler, allowing the application to cache sessions. Clients will also offer these to BoringSSL for reuse if a compatible session was found. BoringSSL is free to use it or not, but the Conscrypt code no longer makes assumptions here. Instead, it always uses the ActiveSession.
- ActiveSession: This is a session that wraps the SSL instance (rather than the SSL_SESSION wherever possible). That way no concern has to be paid to what BoringSSL is doing with sessions under the covers.
Fixes #98/Conformance fixes for the engine-based socket. (#202)
This allows the SSLSocketTest to pass with the engine-based socket
enabled.
Also restructuring the inheritance hierarchy so that the FD and engine
sockets both behave the same way (both either wrappers or not). The
restructure involves the following:
- AbstractConscryptSocket: New base class for both sockets. It handles
the wrap/no-wrap logic.
- OpenSSLSocketImplWrapper: deleted and replaced by
AbstractConscryptSocket.
- OpenSSLSocketImpl: reduced to a public shim class between
AbstractConscryptSocket and the implementations. For backward-compat
only.
- ConscryptFileDescriptorSocket: Renamed from OpenSSLSocketImpl. The
old FD socket./Various fixes to the Conscrypt engine. (#201)/"
conscrypt,"Conformance fixes for the engine-based socket. (#202)
This allows the SSLSocketTest to pass with the engine-based socket
enabled.
Also restructuring the inheritance hierarchy so that the FD and engine
sockets both behave the same way (both either wrappers or not). The
restructure involves the following:
- AbstractConscryptSocket: New base class for both sockets. It handles
the wrap/no-wrap logic.
- OpenSSLSocketImplWrapper: deleted and replaced by
AbstractConscryptSocket.
- OpenSSLSocketImpl: reduced to a public shim class between
AbstractConscryptSocket and the implementations. For backward-compat
only.
- ConscryptFileDescriptorSocket: Renamed from OpenSSLSocketImpl. The
old FD socket./"
conscrypt,"Conformance fixes for the engine-based socket. (#202)
This allows the SSLSocketTest to pass with the engine-based socket
enabled.
Also restructuring the inheritance hierarchy so that the FD and engine
sockets both behave the same way (both either wrappers or not). The
restructure involves the following:
- AbstractConscryptSocket: New base class for both sockets. It handles
the wrap/no-wrap logic.
- OpenSSLSocketImplWrapper: deleted and replaced by
AbstractConscryptSocket.
- OpenSSLSocketImpl: reduced to a public shim class between
AbstractConscryptSocket and the implementations. For backward-compat
only.
- ConscryptFileDescriptorSocket: Renamed from OpenSSLSocketImpl. The
old FD socket./"
conscrypt,"Add missing Java 9 methods for ALPN (#339)
Fixes #316/Fix benchmarks broken by #321 (#334)
The cipher used in the benchmarks requires TLS 1.2./Support renegotiation with sockets (#321)
Fixes #228
Fixes #310/"
conscrypt,"Switch from wrapping to subclassing for Java 9 methods. (#359)
Older Android apps rely on OpenSSLSocketImpl being in the superclass
chain of sockets, which means wrapping them can cause problems.  Instead,
use a subclass to add the appropriate methods.  This also makes the
subclass implementation quite clean, but it pollutes the Platform classes
with a bunch of methods and means we have to remember not to use the
constructors directly./Adding support for Java 9 server-side ALPN protocol selection. (#319)
Java 9 adds a setHandshakeApplicationProtocolSelector method to both
SSLEngine and SSLSocket that allows the application to provide a
BiFunction to choose the protocol. This PR attempts to provide
support for this method while still maintaining backward compatibility
with ealier versions of Java.
Fixes #316/Fix back-compat issue from recent import. (#318)
Also fixing a couple of new compiler warnings./"
conscrypt,"Add missing Java 9 methods for ALPN (#339)
Fixes #316/Adding support for Java 9 server-side ALPN protocol selection. (#319)
Java 9 adds a setHandshakeApplicationProtocolSelector method to both
SSLEngine and SSLSocket that allows the application to provide a
BiFunction to choose the protocol. This PR attempts to provide
support for this method while still maintaining backward compatibility
with ealier versions of Java.
Fixes #316/"
conscrypt,"Switch from wrapping to subclassing for Java 9 methods. (#359)
Older Android apps rely on OpenSSLSocketImpl being in the superclass
chain of sockets, which means wrapping them can cause problems.  Instead,
use a subclass to add the appropriate methods.  This also makes the
subclass implementation quite clean, but it pollutes the Platform classes
with a bunch of methods and means we have to remember not to use the
constructors directly./Add missing Java 9 methods for ALPN (#339)
Fixes #316/Adding support for Java 9 server-side ALPN protocol selection. (#319)
Java 9 adds a setHandshakeApplicationProtocolSelector method to both
SSLEngine and SSLSocket that allows the application to provide a
BiFunction to choose the protocol. This PR attempts to provide
support for this method while still maintaining backward compatibility
with ealier versions of Java.
Fixes #316/"
conscrypt,"Switch from wrapping to subclassing for Java 9 methods. (#359)
Older Android apps rely on OpenSSLSocketImpl being in the superclass
chain of sockets, which means wrapping them can cause problems.  Instead,
use a subclass to add the appropriate methods.  This also makes the
subclass implementation quite clean, but it pollutes the Platform classes
with a bunch of methods and means we have to remember not to use the
constructors directly./Add missing Java 9 methods for ALPN (#339)
Fixes #316/Adding support for Java 9 server-side ALPN protocol selection. (#319)
Java 9 adds a setHandshakeApplicationProtocolSelector method to both
SSLEngine and SSLSocket that allows the application to provide a
BiFunction to choose the protocol. This PR attempts to provide
support for this method while still maintaining backward compatibility
with ealier versions of Java.
Fixes #316/Add Java 6 testing to Travis for Linux (#307)
Fixes #302/Fix back-compat issue from recent import. (#318)
Also fixing a couple of new compiler warnings./"
conscrypt,"Add missing Java 9 methods for ALPN (#339)
Fixes #316/Adding support for Java 9 server-side ALPN protocol selection. (#319)
Java 9 adds a setHandshakeApplicationProtocolSelector method to both
SSLEngine and SSLSocket that allows the application to provide a
BiFunction to choose the protocol. This PR attempts to provide
support for this method while still maintaining backward compatibility
with ealier versions of Java.
Fixes #316/"
conscrypt,"Fix some issues with the ChaCha20 implementation. (#369)
First, ScopedByteArray* already throws NullPointerException if it can't
load the array, so throwing it again actually causes problems, because
you're not allowed to throw an exception while a different exception
is pending.  Just log that the exception was thrown and why.
Second, use OpenSSLCipher's key storage instead of keeping our own copy.
There's no need to keep redundant copies.
Third, implement reset() properly.  Only reset on final(), not on init(),
and don't clear the data from init() when resetting, only the
per-operation values./Add missing Java 9 methods for ALPN (#339)
Fixes #316/Adding support for Java 9 server-side ALPN protocol selection. (#319)
Java 9 adds a setHandshakeApplicationProtocolSelector method to both
SSLEngine and SSLSocket that allows the application to provide a
BiFunction to choose the protocol. This PR attempts to provide
support for this method while still maintaining backward compatibility
with ealier versions of Java.
Fixes #316/Support renegotiation with sockets (#321)
Fixes #228
Fixes #310/Cleanly send and receive close_notify alerts (#325)
As part:
* Don't call SSL_clear() when shutting down an SSL, because we need
to be able to hand it close_notify messages still.  Since both SSLEngine
and SSLSocket aren't reusable, this is safe.
* Return SSL_ERROR_ZERO_RETURN explicitly when it happens, so that we
can properly adjust our state in response to a close_notify being received.
* Check if there are pending bytes to be sent when wrap() is called, even if
the SSLEngine is closed./"
conscrypt,"Switch R_RSA_DATA_TOO_LARGE{,_FOR_MODULUS} exception (#328)
These error codes can be generated by the methods used in both raw RSA
signatures and RSA ciphers, but the Java API for Cipher and Signature
has disjoint declared exceptions.  Luckily, in our Signature
implementations we catch any Exception and wrap it in a SignatureException,
so we can safely turn these into the appropriate exceptions for Cipher
and they'll be thrown as SignatureException from Signature anyway./"
conscrypt,"Implement engineGetKeySize() in Ciphers. (#327)
* Implement engineGetKeySize() in Ciphers.
This method is only called when the unlimited strength policy files aren't
installed, and thus the JDK needs to check whether the key sizes being
used are allowed, but it causes an UnsupportedOperationException if it's
missing in that situation.
Fixes #324.
* Simplify chained if statements./"
conscrypt,"Switch from wrapping to subclassing for Java 9 methods. (#359)
Older Android apps rely on OpenSSLSocketImpl being in the superclass
chain of sockets, which means wrapping them can cause problems.  Instead,
use a subclass to add the appropriate methods.  This also makes the
subclass implementation quite clean, but it pollutes the Platform classes
with a bunch of methods and means we have to remember not to use the
constructors directly./Provide the issuers when calling chooseClientAlias. (#344)
I can't see any reason why the issuers shouldn't be provided, and this
method hasn't been changed in at least 4 years, so I expect it was
just an oversight.
Fixes #323./Add missing Java 9 methods for ALPN (#339)
Fixes #316/Adding support for Java 9 server-side ALPN protocol selection. (#319)
Java 9 adds a setHandshakeApplicationProtocolSelector method to both
SSLEngine and SSLSocket that allows the application to provide a
BiFunction to choose the protocol. This PR attempts to provide
support for this method while still maintaining backward compatibility
with ealier versions of Java.
Fixes #316/"
conscrypt,"Add missing Java 9 methods for ALPN (#339)
Fixes #316/Adding support for Java 9 server-side ALPN protocol selection. (#319)
Java 9 adds a setHandshakeApplicationProtocolSelector method to both
SSLEngine and SSLSocket that allows the application to provide a
BiFunction to choose the protocol. This PR attempts to provide
support for this method while still maintaining backward compatibility
with ealier versions of Java.
Fixes #316/"
conscrypt,"Add missing Java 9 methods for ALPN (#339)
Fixes #316/Adding support for Java 9 server-side ALPN protocol selection. (#319)
Java 9 adds a setHandshakeApplicationProtocolSelector method to both
SSLEngine and SSLSocket that allows the application to provide a
BiFunction to choose the protocol. This PR attempts to provide
support for this method while still maintaining backward compatibility
with ealier versions of Java.
Fixes #316/Support renegotiation with sockets (#321)
Fixes #228
Fixes #310/Cleanly send and receive close_notify alerts (#325)
As part:
* Don't call SSL_clear() when shutting down an SSL, because we need
to be able to hand it close_notify messages still.  Since both SSLEngine
and SSLSocket aren't reusable, this is safe.
* Return SSL_ERROR_ZERO_RETURN explicitly when it happens, so that we
can properly adjust our state in response to a close_notify being received.
* Check if there are pending bytes to be sent when wrap() is called, even if
the SSLEngine is closed./"
conscrypt,"Add missing Java 9 methods for ALPN (#339)
Fixes #316/Adding support for Java 9 server-side ALPN protocol selection. (#319)
Java 9 adds a setHandshakeApplicationProtocolSelector method to both
SSLEngine and SSLSocket that allows the application to provide a
BiFunction to choose the protocol. This PR attempts to provide
support for this method while still maintaining backward compatibility
with ealier versions of Java.
Fixes #316/"
conscrypt,"Implement engineGetKeySize() in Ciphers. (#327)
* Implement engineGetKeySize() in Ciphers.
This method is only called when the unlimited strength policy files aren't
installed, and thus the JDK needs to check whether the key sizes being
used are allowed, but it causes an UnsupportedOperationException if it's
missing in that situation.
Fixes #324.
* Simplify chained if statements./"
conscrypt,"Switch from wrapping to subclassing for Java 9 methods. (#359)
Older Android apps rely on OpenSSLSocketImpl being in the superclass
chain of sockets, which means wrapping them can cause problems.  Instead,
use a subclass to add the appropriate methods.  This also makes the
subclass implementation quite clean, but it pollutes the Platform classes
with a bunch of methods and means we have to remember not to use the
constructors directly./Throw SocketException if the FD socket has had its SSL freed (#343)
Under some circumstances (which are repeatable, but I haven't been able
to lock down), the HTTP connection reuse system in the JDK will attempt to
reuse a finalized ConscryptFileDescriptorSocket.  When this happens, the
socket throws a NullPointerException from the native code when methods
are called, because the native SSL object has been freed, which causes
a lot of problems.  Instead, have the socket throw SocketException instead,
which everything understands and responds properly to.
As best as I can tell, this is happening because the finalizer of some
object that's not ours but has a strong reference to our socket adds
a new strong reference, but our finalizer has already been enqueued
and thus is run even though the object then can later be reused.  I haven't
been able to find this finalizer, but everything tolerates the code as
written and responds properly to the SocketException, so it seems like a
good solution until we get rid of the FD socket entirely.
Fixes #331./Adding support for Java 9 server-side ALPN protocol selection. (#319)
Java 9 adds a setHandshakeApplicationProtocolSelector method to both
SSLEngine and SSLSocket that allows the application to provide a
BiFunction to choose the protocol. This PR attempts to provide
support for this method while still maintaining backward compatibility
with ealier versions of Java.
Fixes #316/"
conscrypt,"Add missing Java 9 methods for ALPN (#339)
Fixes #316/Support renegotiation with sockets (#321)
Fixes #228
Fixes #310/"
conscrypt,"Switch from wrapping to subclassing for Java 9 methods. (#359)
Older Android apps rely on OpenSSLSocketImpl being in the superclass
chain of sockets, which means wrapping them can cause problems.  Instead,
use a subclass to add the appropriate methods.  This also makes the
subclass implementation quite clean, but it pollutes the Platform classes
with a bunch of methods and means we have to remember not to use the
constructors directly./setSocketWriteTimeout(): Log more details in case of failure. (#345)
In response to a previous hard-to-diagnose bug, this method logged
a couple of stacktaces from the caught exception; but it didn't
log the exception type (e.g. InvocationTargetException), exception
message or causes. This CL expands this to also log the cause chain,
providing the exception type, message, and the first two
StackTraceElements for each Throwable in the chain./Adding support for Java 9 server-side ALPN protocol selection. (#319)
Java 9 adds a setHandshakeApplicationProtocolSelector method to both
SSLEngine and SSLSocket that allows the application to provide a
BiFunction to choose the protocol. This PR attempts to provide
support for this method while still maintaining backward compatibility
with ealier versions of Java.
Fixes #316/"
conscrypt,"Update more testing infrastructure. (#395)
* Update testing build rules.
* Move TestKeyStore to org.conscrypt.
* Fix up a couple tests so they work in AOSP./"
conscrypt,"Update more testing infrastructure. (#395)
* Update testing build rules.
* Move TestKeyStore to org.conscrypt.
* Fix up a couple tests so they work in AOSP./"
conscrypt,"Refactoring externalization of SSLSessions (#383)
This is an implementation to #381. This change attempts to provide more
consistency to the session that is returned to the caller by `ConscryptEngine`/`ConscryptFileDescriptorSocket`.
Main changes:
- New interface ConscryptSession adds a few methods currently only defined by ActiveSession
- New interface SessionDecorator that defines getDelegate()
- New class ProvidedSessionDecorator delegates to an external provider of the ""current"" session. The provider implementations are in ConscryptEngine and ConscryptFileDescriptorSocket.
- New class SessionSnapshot that takes a snapshot of any ConscryptSession.
- Changed ActiveSession and SSLNullSession to implement ConscryptSession.
- Updated ConscryptEngine/ConscryptFileDescriptorSocket to create a SessionSnapshot when closing.
Additional cleanup:
- Split out Java7SessionWrapper into two classes: Java7ExtendedSSLSession and Java8ExtendedSSLSession. The Java 8 version no longer requires reflection and is more consistent with platform-specific code elsewhere. Both classes implement SessionDecorator.
- Renamed SslWrapper->NativeSsl and SslSessionWrapper->NativeSslSession for clarity, since the term ""wrapper"" was being overloaded.
Fixes #379/"
conscrypt,"Refactoring externalization of SSLSessions (#383)
This is an implementation to #381. This change attempts to provide more
consistency to the session that is returned to the caller by `ConscryptEngine`/`ConscryptFileDescriptorSocket`.
Main changes:
- New interface ConscryptSession adds a few methods currently only defined by ActiveSession
- New interface SessionDecorator that defines getDelegate()
- New class ProvidedSessionDecorator delegates to an external provider of the ""current"" session. The provider implementations are in ConscryptEngine and ConscryptFileDescriptorSocket.
- New class SessionSnapshot that takes a snapshot of any ConscryptSession.
- Changed ActiveSession and SSLNullSession to implement ConscryptSession.
- Updated ConscryptEngine/ConscryptFileDescriptorSocket to create a SessionSnapshot when closing.
Additional cleanup:
- Split out Java7SessionWrapper into two classes: Java7ExtendedSSLSession and Java8ExtendedSSLSession. The Java 8 version no longer requires reflection and is more consistent with platform-specific code elsewhere. Both classes implement SessionDecorator.
- Renamed SslWrapper->NativeSsl and SslSessionWrapper->NativeSslSession for clarity, since the term ""wrapper"" was being overloaded.
Fixes #379/"
conscrypt,"Pass NativeSsl references to NativeCrypto (#408)
* Pass NativeSsl references to NativeCrypto
The existing implementation of passing raw addresses to NativeCrypto
can cause issues where the native code may still be executing when the
finalizer runs and frees the underlying native resources.  A call to
NativeSsl.read(), for instance, is not enough to keep the NativeSsl or
its owning socket alive, so if it's waiting for input the finalizer
can run.  Switching to passing the Java object to native code keeps
the Java object alive for GC purposes, preventing its finalizer from
running.
As part of this, also move the freeing of NativeSsl instances into a
finalizer on NativeSsl instead of on the sockets.  The sockets can
still become garbage even if the NativeSsl is kept alive, so we only
want to free it when the NativeSsl itself is garbage.
We will also want to do this for other native objects, but SSL*
instances are by far the most-used native objects and the most likely
to be used in a long-running I/O operation, so starting here gives us
a lot of benefit.
* Reliably close objects in tests.
* Pass both pointer and Java reference.
This allows us to access the SSL* pointer without having to indirect
through the Java object's fields, but still prevents the NativeSsl
from being GCed while the method is being run.
* Explain unsafe finalization fix in NativeCrypto Javadoc./Update more testing infrastructure. (#395)
* Update testing build rules.
* Move TestKeyStore to org.conscrypt.
* Fix up a couple tests so they work in AOSP./"
conscrypt,"Refactoring externalization of SSLSessions (#383)
This is an implementation to #381. This change attempts to provide more
consistency to the session that is returned to the caller by `ConscryptEngine`/`ConscryptFileDescriptorSocket`.
Main changes:
- New interface ConscryptSession adds a few methods currently only defined by ActiveSession
- New interface SessionDecorator that defines getDelegate()
- New class ProvidedSessionDecorator delegates to an external provider of the ""current"" session. The provider implementations are in ConscryptEngine and ConscryptFileDescriptorSocket.
- New class SessionSnapshot that takes a snapshot of any ConscryptSession.
- Changed ActiveSession and SSLNullSession to implement ConscryptSession.
- Updated ConscryptEngine/ConscryptFileDescriptorSocket to create a SessionSnapshot when closing.
Additional cleanup:
- Split out Java7SessionWrapper into two classes: Java7ExtendedSSLSession and Java8ExtendedSSLSession. The Java 8 version no longer requires reflection and is more consistent with platform-specific code elsewhere. Both classes implement SessionDecorator.
- Renamed SslWrapper->NativeSsl and SslSessionWrapper->NativeSslSession for clarity, since the term ""wrapper"" was being overloaded.
Fixes #379/"
conscrypt,"Refactoring externalization of SSLSessions (#383)
This is an implementation to #381. This change attempts to provide more
consistency to the session that is returned to the caller by `ConscryptEngine`/`ConscryptFileDescriptorSocket`.
Main changes:
- New interface ConscryptSession adds a few methods currently only defined by ActiveSession
- New interface SessionDecorator that defines getDelegate()
- New class ProvidedSessionDecorator delegates to an external provider of the ""current"" session. The provider implementations are in ConscryptEngine and ConscryptFileDescriptorSocket.
- New class SessionSnapshot that takes a snapshot of any ConscryptSession.
- Changed ActiveSession and SSLNullSession to implement ConscryptSession.
- Updated ConscryptEngine/ConscryptFileDescriptorSocket to create a SessionSnapshot when closing.
Additional cleanup:
- Split out Java7SessionWrapper into two classes: Java7ExtendedSSLSession and Java8ExtendedSSLSession. The Java 8 version no longer requires reflection and is more consistent with platform-specific code elsewhere. Both classes implement SessionDecorator.
- Renamed SslWrapper->NativeSsl and SslSessionWrapper->NativeSslSession for clarity, since the term ""wrapper"" was being overloaded.
Fixes #379/"
conscrypt,"Mark env as intentionally unused. (#420)
When CHECK_ERROR_QUEUE_ON_RETURN is disabled, we need to inform the
compiler that we intended not to use env./Add compile option for checking error queue. (#416)
We need to ensure that the BoringSSL error stack is clear when
returning from native functions, otherwise a later function might
inspect the error stack and interpret it incorrectly.
Adds the compile option CONSCRYPT_CHECK_ERROR_QUEUE which enables the
macro CHECK_ERROR_QUEUE_ON_RETURN.  That macro, when enabled, creates
a class that checks the error queue is empty in its destructor.  The
macro has been added to almost every native method called from Java,
enforcing that the error queue is empty when we return from native
code back to Java code.
Adds the gradle property checkErrorQueue to enable the code and adds
it to the Travis config.
Also fixes a couple places found by this checking that we were failing
to clear the error queue after handling errors./Clean up exception throwing in native code. (#417)
Change throwExceptionIfNecessary to throwExceptionFromBoringSSLError.
The definition changes from throwing an exception if there's an error
on the stack to having a precondition of having an error on the stack.
This makes its behavior and the expected usage more clear (it always
results in an exception pending).  This also should let us know if
we're encountering return-failure-but-don't-stack-an-error situations
that we didn't know about.
Normalize function names to throwFooException.
Ensure that we always return immediately after throwing an exception.
Some call sites allowed the exception-throwing branch to fall through
to the return statement from a non-throwing branch, which is unclear,
since that return statement is useless, and runs the risk of
additional code being inserted after the exception.
Fixes #97./"
conscrypt,"Revert ""Throw SocketException on ERR_SSL_SYSCALL. (#430)"" (#432)
We've had reports from people that depended on ""normal"" connection
termination (such as in HTTP where the peer sends data and then closes
the TCP connection) returning -1 from read(), and in some cases this
change causes read() to throw a SocketException in that circumstance.
Rather than causing such a fundamental change in behavior, probably
better to just adjust the test to allow for a -1 return.
This reverts commit d84f6f57b216ab53dc3a71d30fd2252ce2208c13./Throw SocketException on ERR_SSL_SYSCALL. (#430)
SSLSocketTest#test_SSLSocket_interrupt_readWrapperAndCloseUnderlying
is failing periodically on our internal continuous builds, and it
appears to be happening due to a race condition.
The test is testing what happens when an SSLSocket that's wrapping an
underlying Socket is blocked on a read and then underlying socket is
closed by another thread.  There appears to be a race condition
between the OS waking up the reading thread and the write of -1 to
java.io.FileDescriptor's private field.  If the reading thread wakes
up and proceeds past the check of the file descriptor's validity
before the field write is visible, then it will attempt to call
SSL_read() and get ERR_SSL_SYSCALL, and it responds by returning -1,
whereas the test expects SocketException to be thrown (which it does
if the file descriptor is invalid).
This changes the code to always throw SocketException when
ERR_SSL_SYSCALL is reported with a return value of 0, which the
BoringSSL docs say happens ""if the transport returned EOF"", which
should mean the file descriptor is closed./Add compile option for checking error queue. (#416)
We need to ensure that the BoringSSL error stack is clear when
returning from native functions, otherwise a later function might
inspect the error stack and interpret it incorrectly.
Adds the compile option CONSCRYPT_CHECK_ERROR_QUEUE which enables the
macro CHECK_ERROR_QUEUE_ON_RETURN.  That macro, when enabled, creates
a class that checks the error queue is empty in its destructor.  The
macro has been added to almost every native method called from Java,
enforcing that the error queue is empty when we return from native
code back to Java code.
Adds the gradle property checkErrorQueue to enable the code and adds
it to the Travis config.
Also fixes a couple places found by this checking that we were failing
to clear the error queue after handling errors./Clean up exception throwing in native code. (#417)
Change throwExceptionIfNecessary to throwExceptionFromBoringSSLError.
The definition changes from throwing an exception if there's an error
on the stack to having a precondition of having an error on the stack.
This makes its behavior and the expected usage more clear (it always
results in an exception pending).  This also should let us know if
we're encountering return-failure-but-don't-stack-an-error situations
that we didn't know about.
Normalize function names to throwFooException.
Ensure that we always return immediately after throwing an exception.
Some call sites allowed the exception-throwing branch to fall through
to the return statement from a non-throwing branch, which is unclear,
since that return statement is useless, and runs the risk of
additional code being inserted after the exception.
Fixes #97./Fix typo in string (#413)/Mark unused parameters in native_crypto.cc (#412)
Our Android build rules generate errors for unused parameters.  We
can't enable the warnings in the external build rules because
BoringSSL has many unused parameters and we build the two together in
the external build./Pass NativeSsl references to NativeCrypto (#408)
* Pass NativeSsl references to NativeCrypto
The existing implementation of passing raw addresses to NativeCrypto
can cause issues where the native code may still be executing when the
finalizer runs and frees the underlying native resources.  A call to
NativeSsl.read(), for instance, is not enough to keep the NativeSsl or
its owning socket alive, so if it's waiting for input the finalizer
can run.  Switching to passing the Java object to native code keeps
the Java object alive for GC purposes, preventing its finalizer from
running.
As part of this, also move the freeing of NativeSsl instances into a
finalizer on NativeSsl instead of on the sockets.  The sockets can
still become garbage even if the NativeSsl is kept alive, so we only
want to free it when the NativeSsl itself is garbage.
We will also want to do this for other native objects, but SSL*
instances are by far the most-used native objects and the most likely
to be used in a long-running I/O operation, so starting here gives us
a lot of benefit.
* Reliably close objects in tests.
* Pass both pointer and Java reference.
This allows us to access the SSL* pointer without having to indirect
through the Java object's fields, but still prevents the NativeSsl
from being GCed while the method is being run.
* Explain unsafe finalization fix in NativeCrypto Javadoc./Fix error detection in RSA_generate_key_ex. (#398)
RSA_generate_key_ex returns 1 on success and 0 on failure, so we could
never detect failures that happened.  Also update an allocation
failure to throw OutOfMemoryError instead of RuntimeException./Relax RSA key parsing to allow parsing a partial buffer. (#392)
Other implementations allow parsing keys out of buffers that are
larger than the encoded key structure, including Conscrypt before we
changed to EVP_parse_{public,private}_key(), and there've been public
reports of this breaking apps on Android.  Switch back to the old
behavior./Don't check member of X509_REVOKED instances. (#382)
X509_REVOKED doesn't have a double-dereference in get_ext* like X509
and X509_CRL do, so an empty list will have a null pointer there by
design, and it won't cause a problem.  Indeed, checking it causes a
NullPointerException in a valid use case, where otherwise it would
return a valid result./Check an X509-like structure submember for nullness. (#380)
We've seen very sporadic crashes due to null pointer dereferencing
somewhere inside X509_get_ext_by_critical, and this is the only way I
can see that that can happen.  X509_get_ext_by_critical passes
x->cert_info->extensions to X509v3_get_ext_by_critical, and that's the
only pointer that isn't explicitly checked for nullness.  These
crashes are incredibly rare, so it's not out of the realm of
possibility for them to be memory corruption or something, but better
safe than sorry./"
conscrypt,"Clean up exception throwing in native code. (#417)
Change throwExceptionIfNecessary to throwExceptionFromBoringSSLError.
The definition changes from throwing an exception if there's an error
on the stack to having a precondition of having an error on the stack.
This makes its behavior and the expected usage more clear (it always
results in an exception pending).  This also should let us know if
we're encountering return-failure-but-don't-stack-an-error situations
that we didn't know about.
Normalize function names to throwFooException.
Ensure that we always return immediately after throwing an exception.
Some call sites allowed the exception-throwing branch to fall through
to the return statement from a non-throwing branch, which is unclear,
since that return statement is useless, and runs the risk of
additional code being inserted after the exception.
Fixes #97./Check if an exception is pending before throwing another one. (#386)
This can occur if a BoringSSL call results in a socket read from a
Java socket which throws an exception.  Since throwing an exception
when another exception is pending causes the process to crash, just
let the other exception propagate out of the function./"
conscrypt,"Refactoring externalization of SSLSessions (#383)
This is an implementation to #381. This change attempts to provide more
consistency to the session that is returned to the caller by `ConscryptEngine`/`ConscryptFileDescriptorSocket`.
Main changes:
- New interface ConscryptSession adds a few methods currently only defined by ActiveSession
- New interface SessionDecorator that defines getDelegate()
- New class ProvidedSessionDecorator delegates to an external provider of the ""current"" session. The provider implementations are in ConscryptEngine and ConscryptFileDescriptorSocket.
- New class SessionSnapshot that takes a snapshot of any ConscryptSession.
- Changed ActiveSession and SSLNullSession to implement ConscryptSession.
- Updated ConscryptEngine/ConscryptFileDescriptorSocket to create a SessionSnapshot when closing.
Additional cleanup:
- Split out Java7SessionWrapper into two classes: Java7ExtendedSSLSession and Java8ExtendedSSLSession. The Java 8 version no longer requires reflection and is more consistent with platform-specific code elsewhere. Both classes implement SessionDecorator.
- Renamed SslWrapper->NativeSsl and SslSessionWrapper->NativeSslSession for clarity, since the term ""wrapper"" was being overloaded.
Fixes #379/"
conscrypt,"Refactoring externalization of SSLSessions (#383)
This is an implementation to #381. This change attempts to provide more
consistency to the session that is returned to the caller by `ConscryptEngine`/`ConscryptFileDescriptorSocket`.
Main changes:
- New interface ConscryptSession adds a few methods currently only defined by ActiveSession
- New interface SessionDecorator that defines getDelegate()
- New class ProvidedSessionDecorator delegates to an external provider of the ""current"" session. The provider implementations are in ConscryptEngine and ConscryptFileDescriptorSocket.
- New class SessionSnapshot that takes a snapshot of any ConscryptSession.
- Changed ActiveSession and SSLNullSession to implement ConscryptSession.
- Updated ConscryptEngine/ConscryptFileDescriptorSocket to create a SessionSnapshot when closing.
Additional cleanup:
- Split out Java7SessionWrapper into two classes: Java7ExtendedSSLSession and Java8ExtendedSSLSession. The Java 8 version no longer requires reflection and is more consistent with platform-specific code elsewhere. Both classes implement SessionDecorator.
- Renamed SslWrapper->NativeSsl and SslSessionWrapper->NativeSslSession for clarity, since the term ""wrapper"" was being overloaded.
Fixes #379/"
conscrypt,"A few small fixes in prep for adding tests. (#402)
Add ARC4 KeyGenerator.  Upcoming tests assume that every cipher also
has a KeyGenerator available, so provide one.
Add support for PKCS7PADDING constant and remove ISO10126PADDING.  We
never use the latter, and the former is used in an alias.  When a user
requests an alias, OpenJDK provides the alias name in the
engineSetPadding call, whereas Android provides the concrete name, so
make sure we can handle either.
Fix a problem where engineSetPadding would never recognize OAEPPadding
when passed to OpenSSLCipherRSA./"
conscrypt,"Pass NativeSsl references to NativeCrypto (#408)
* Pass NativeSsl references to NativeCrypto
The existing implementation of passing raw addresses to NativeCrypto
can cause issues where the native code may still be executing when the
finalizer runs and frees the underlying native resources.  A call to
NativeSsl.read(), for instance, is not enough to keep the NativeSsl or
its owning socket alive, so if it's waiting for input the finalizer
can run.  Switching to passing the Java object to native code keeps
the Java object alive for GC purposes, preventing its finalizer from
running.
As part of this, also move the freeing of NativeSsl instances into a
finalizer on NativeSsl instead of on the sockets.  The sockets can
still become garbage even if the NativeSsl is kept alive, so we only
want to free it when the NativeSsl itself is garbage.
We will also want to do this for other native objects, but SSL*
instances are by far the most-used native objects and the most likely
to be used in a long-running I/O operation, so starting here gives us
a lot of benefit.
* Reliably close objects in tests.
* Pass both pointer and Java reference.
This allows us to access the SSL* pointer without having to indirect
through the Java object's fields, but still prevents the NativeSsl
from being GCed while the method is being run.
* Explain unsafe finalization fix in NativeCrypto Javadoc./Fix NullPointerException when IOException is thrown during socket creation (#405)/Throw SSLException from newSsl(). (#401)
The constructors already declare that they throw IOException, so I
don't see why this should be a problem.
Fixes #399./Move session value API into ProvidedSessionDecorator. (#389)
* Move session value API into ProvidedSessionDecorator.
The application-level value API on SSLSession objects makes them
mutable, which means that using singleton objects (like we do with
SSLNullSession) or swapping out implementations (like we do with
ActiveSession/SessionSnapshot) doesn't work properly if you actually
want to use this API.  By moving it into ProvidedSessionDecorator, it
can be used without any of these problems.
* Rename ProvidedSessionDecorator to ExternalSession./Refactoring externalization of SSLSessions (#383)
This is an implementation to #381. This change attempts to provide more
consistency to the session that is returned to the caller by `ConscryptEngine`/`ConscryptFileDescriptorSocket`.
Main changes:
- New interface ConscryptSession adds a few methods currently only defined by ActiveSession
- New interface SessionDecorator that defines getDelegate()
- New class ProvidedSessionDecorator delegates to an external provider of the ""current"" session. The provider implementations are in ConscryptEngine and ConscryptFileDescriptorSocket.
- New class SessionSnapshot that takes a snapshot of any ConscryptSession.
- Changed ActiveSession and SSLNullSession to implement ConscryptSession.
- Updated ConscryptEngine/ConscryptFileDescriptorSocket to create a SessionSnapshot when closing.
Additional cleanup:
- Split out Java7SessionWrapper into two classes: Java7ExtendedSSLSession and Java8ExtendedSSLSession. The Java 8 version no longer requires reflection and is more consistent with platform-specific code elsewhere. Both classes implement SessionDecorator.
- Renamed SslWrapper->NativeSsl and SslSessionWrapper->NativeSslSession for clarity, since the term ""wrapper"" was being overloaded.
Fixes #379/"
conscrypt,"A few small fixes in prep for adding tests. (#402)
Add ARC4 KeyGenerator.  Upcoming tests assume that every cipher also
has a KeyGenerator available, so provide one.
Add support for PKCS7PADDING constant and remove ISO10126PADDING.  We
never use the latter, and the former is used in an alias.  When a user
requests an alias, OpenJDK provides the alias name in the
engineSetPadding call, whereas Android provides the concrete name, so
make sure we can handle either.
Fix a problem where engineSetPadding would never recognize OAEPPadding
when passed to OpenSSLCipherRSA./"
conscrypt,"Pass NativeSsl references to NativeCrypto (#408)
* Pass NativeSsl references to NativeCrypto
The existing implementation of passing raw addresses to NativeCrypto
can cause issues where the native code may still be executing when the
finalizer runs and frees the underlying native resources.  A call to
NativeSsl.read(), for instance, is not enough to keep the NativeSsl or
its owning socket alive, so if it's waiting for input the finalizer
can run.  Switching to passing the Java object to native code keeps
the Java object alive for GC purposes, preventing its finalizer from
running.
As part of this, also move the freeing of NativeSsl instances into a
finalizer on NativeSsl instead of on the sockets.  The sockets can
still become garbage even if the NativeSsl is kept alive, so we only
want to free it when the NativeSsl itself is garbage.
We will also want to do this for other native objects, but SSL*
instances are by far the most-used native objects and the most likely
to be used in a long-running I/O operation, so starting here gives us
a lot of benefit.
* Reliably close objects in tests.
* Pass both pointer and Java reference.
This allows us to access the SSL* pointer without having to indirect
through the Java object's fields, but still prevents the NativeSsl
from being GCed while the method is being run.
* Explain unsafe finalization fix in NativeCrypto Javadoc./Move session value API into ProvidedSessionDecorator. (#389)
* Move session value API into ProvidedSessionDecorator.
The application-level value API on SSLSession objects makes them
mutable, which means that using singleton objects (like we do with
SSLNullSession) or swapping out implementations (like we do with
ActiveSession/SessionSnapshot) doesn't work properly if you actually
want to use this API.  By moving it into ProvidedSessionDecorator, it
can be used without any of these problems.
* Rename ProvidedSessionDecorator to ExternalSession./Refactoring externalization of SSLSessions (#383)
This is an implementation to #381. This change attempts to provide more
consistency to the session that is returned to the caller by `ConscryptEngine`/`ConscryptFileDescriptorSocket`.
Main changes:
- New interface ConscryptSession adds a few methods currently only defined by ActiveSession
- New interface SessionDecorator that defines getDelegate()
- New class ProvidedSessionDecorator delegates to an external provider of the ""current"" session. The provider implementations are in ConscryptEngine and ConscryptFileDescriptorSocket.
- New class SessionSnapshot that takes a snapshot of any ConscryptSession.
- Changed ActiveSession and SSLNullSession to implement ConscryptSession.
- Updated ConscryptEngine/ConscryptFileDescriptorSocket to create a SessionSnapshot when closing.
Additional cleanup:
- Split out Java7SessionWrapper into two classes: Java7ExtendedSSLSession and Java8ExtendedSSLSession. The Java 8 version no longer requires reflection and is more consistent with platform-specific code elsewhere. Both classes implement SessionDecorator.
- Renamed SslWrapper->NativeSsl and SslSessionWrapper->NativeSslSession for clarity, since the term ""wrapper"" was being overloaded.
Fixes #379/"
conscrypt,"Pass NativeSsl references to NativeCrypto (#408)
* Pass NativeSsl references to NativeCrypto
The existing implementation of passing raw addresses to NativeCrypto
can cause issues where the native code may still be executing when the
finalizer runs and frees the underlying native resources.  A call to
NativeSsl.read(), for instance, is not enough to keep the NativeSsl or
its owning socket alive, so if it's waiting for input the finalizer
can run.  Switching to passing the Java object to native code keeps
the Java object alive for GC purposes, preventing its finalizer from
running.
As part of this, also move the freeing of NativeSsl instances into a
finalizer on NativeSsl instead of on the sockets.  The sockets can
still become garbage even if the NativeSsl is kept alive, so we only
want to free it when the NativeSsl itself is garbage.
We will also want to do this for other native objects, but SSL*
instances are by far the most-used native objects and the most likely
to be used in a long-running I/O operation, so starting here gives us
a lot of benefit.
* Reliably close objects in tests.
* Pass both pointer and Java reference.
This allows us to access the SSL* pointer without having to indirect
through the Java object's fields, but still prevents the NativeSsl
from being GCed while the method is being run.
* Explain unsafe finalization fix in NativeCrypto Javadoc./"
conscrypt,"A few small fixes in prep for adding tests. (#402)
Add ARC4 KeyGenerator.  Upcoming tests assume that every cipher also
has a KeyGenerator available, so provide one.
Add support for PKCS7PADDING constant and remove ISO10126PADDING.  We
never use the latter, and the former is used in an alias.  When a user
requests an alias, OpenJDK provides the alias name in the
engineSetPadding call, whereas Android provides the concrete name, so
make sure we can handle either.
Fix a problem where engineSetPadding would never recognize OAEPPadding
when passed to OpenSSLCipherRSA./"
conscrypt,"Refactoring externalization of SSLSessions (#383)
This is an implementation to #381. This change attempts to provide more
consistency to the session that is returned to the caller by `ConscryptEngine`/`ConscryptFileDescriptorSocket`.
Main changes:
- New interface ConscryptSession adds a few methods currently only defined by ActiveSession
- New interface SessionDecorator that defines getDelegate()
- New class ProvidedSessionDecorator delegates to an external provider of the ""current"" session. The provider implementations are in ConscryptEngine and ConscryptFileDescriptorSocket.
- New class SessionSnapshot that takes a snapshot of any ConscryptSession.
- Changed ActiveSession and SSLNullSession to implement ConscryptSession.
- Updated ConscryptEngine/ConscryptFileDescriptorSocket to create a SessionSnapshot when closing.
Additional cleanup:
- Split out Java7SessionWrapper into two classes: Java7ExtendedSSLSession and Java8ExtendedSSLSession. The Java 8 version no longer requires reflection and is more consistent with platform-specific code elsewhere. Both classes implement SessionDecorator.
- Renamed SslWrapper->NativeSsl and SslSessionWrapper->NativeSslSession for clarity, since the term ""wrapper"" was being overloaded.
Fixes #379/"
conscrypt,"Clean up some ErrorProne warnings. (#493)
* Add explicit charset to byte-to-String conversions.
* Add -1 to String.split() calls to make its behavior more intuitive.
* Add a missing @Override.
* Clarify an implicit int-to-byte conversion.
* Switch StringBuffer to StringBuilder.
* Inline an unnecessary function.
* Stop depending on FileDescriptor's toString./"
conscrypt,"Clean up some ErrorProne warnings. (#493)
* Add explicit charset to byte-to-String conversions.
* Add -1 to String.split() calls to make its behavior more intuitive.
* Add a missing @Override.
* Clarify an implicit int-to-byte conversion.
* Switch StringBuffer to StringBuilder.
* Inline an unnecessary function.
* Stop depending on FileDescriptor's toString./"
conscrypt,"Add logging macros that work on all platforms. (#462)
This adds CONSCRYPT_LOG_X macros that redirect to either ALOG on
Android or fprintf(stderr) on non-Android.  In the future, we could
use these to allow users to register a logging callback and send the
logs to a destination of their choice (via java.util.Logger or log4j
or what have you), but for now we'll keep it simple.
Fixes #460./"
conscrypt,"Add logging macros that work on all platforms. (#462)
This adds CONSCRYPT_LOG_X macros that redirect to either ALOG on
Android or fprintf(stderr) on non-Android.  In the future, we could
use these to allow users to register a logging callback and send the
logs to a destination of their choice (via java.util.Logger or log4j
or what have you), but for now we'll keep it simple.
Fixes #460./"
conscrypt,"Add a function to force an engine read. (#453)
The SSLEngine implementation sometimes need to prompt BoringSSL
to process any incoming TLS data in order to determine whether
there is enough data to produce plaintext.  We previously were
reading into a zero-byte buffer to do this, but that causes
ambiguity in return values because a return of 0 from SSL_read()
could mean a failure (generally EOF) or could mean a successful
read of 0 bytes (which would be expected when reading into a
zero-byte array).  Instead, use SSL_peek.
Fixes #452./Tag some variable as const. (#469)
I'm not sure why we made SSL_get0_peer_certificates return non-const
pointer. In preparation for fixing that, tag the field as const in
Conscrypt./Avoid reaching into BoringSSL internals. (#464)
Ideally Conscrypt wouldn't be trying to access bits of SSL_SESSION
anyway (bug #350), but use the accessor in the meantime. The accessor is
new, so it's protected by BORINGSSL_API_VERSION for the time being./Add logging macros that work on all platforms. (#462)
This adds CONSCRYPT_LOG_X macros that redirect to either ALOG on
Android or fprintf(stderr) on non-Android.  In the future, we could
use these to allow users to register a logging callback and send the
logs to a destination of their choice (via java.util.Logger or log4j
or what have you), but for now we'll keep it simple.
Fixes #460./Use size_t to avoid sign-compare warnings (#451)/Parse ASN1_TIME structures in constructors. (#446)
The legacy OpenSSL APIs in BoringSSL don't parse ASN1_TIME values
until they're used, which means that the existing code could explode
in the middle of X509Certificate.getNotAfter() and similar
Date-returning calls, and those calls aren't declared to throw
anything.  Instead, read and cache the values in the constructor,
where we can throw a relevant exception if necessary.
We have to clone the Date values when returning them because Date is
mutable./"
conscrypt,"Update short buffer handling. (#440)
This fixes a number of problems in Conscrypt's ciphers when they are
given an output buffer that is too small for the output.
We didn't specifically handle CIPHER_R_BUFFER_TOO_SMALL errors from
BoringSSL, so we threw RuntimeException on encountering them.  We
should be throwing ShortBufferException.
Raw ChaCha20 didn't check for a short buffer at all, so it just passed
the arrays down to native code, which could cause crashes or other
weird behavior.
EVP_AEAD ciphers used update() to only record data that needed to be
encrypted and then did the actual encrypting in doFinal().  This
combined with our implementation that implements doFinal() as a
combination of updateInternal() + doFinalInternal() led to a situation
where if the buffer passed to doFinal() was too small, the data would
get added to the buffer to be encrypted in updateInternal() and then
doFinalInternal() call would fail, which would mean a future call to
doFinal() with the same data would end up encrypting that data twice.
This call pattern is used by some internal CipherSpi methods from
OpenJDK, so you could see it in practice even if the caller did
nothing wrong.
Also add tests around short buffer handling./"
conscrypt,"Remove exception throwing on bad hostnames. (#478)
Testing on Android has indicated that there are too many things that
rely on passing whatever string has been passed to them to
setHostname() and aren't prepared to get an exception (including IP
addresses, single-element hostnames, and whatnot) for it to be
reasonable to throw an exception here.  Settle for documenting what
the behavior of passing an invalid hostname is./"
conscrypt,"Add a function to force an engine read. (#453)
The SSLEngine implementation sometimes need to prompt BoringSSL
to process any incoming TLS data in order to determine whether
there is enough data to produce plaintext.  We previously were
reading into a zero-byte buffer to do this, but that causes
ambiguity in return values because a return of 0 from SSL_read()
could mean a failure (generally EOF) or could mean a successful
read of 0 bytes (which would be expected when reading into a
zero-byte array).  Instead, use SSL_peek.
Fixes #452./Fix SSLEngine bug with multiple heap buffer inputs. (#485)
When the SSLEngine overload that accepts an array of ByteBuffers is
called with heap buffers for both the source and destination, those
heap buffers are converted to direct buffers for passing to JNI by way
of copying them to a single temporary direct buffer.  A bug in the
reading of the encrypted data out of BoringSSL resulted in the data
being placed at the wrong offset of the temporary buffer, meaning that
the output data was prefixed in the worst case by the plaintext.
Fixes CVE-2017-13309./Remove exception throwing on bad hostnames. (#478)
Testing on Android has indicated that there are too many things that
rely on passing whatever string has been passed to them to
setHostname() and aren't prepared to get an exception (including IP
addresses, single-element hostnames, and whatnot) for it to be
reasonable to throw an exception here.  Settle for documenting what
the behavior of passing an invalid hostname is./"
conscrypt,"Add a function to force an engine read. (#453)
The SSLEngine implementation sometimes need to prompt BoringSSL
to process any incoming TLS data in order to determine whether
there is enough data to produce plaintext.  We previously were
reading into a zero-byte buffer to do this, but that causes
ambiguity in return values because a return of 0 from SSL_read()
could mean a failure (generally EOF) or could mean a successful
read of 0 bytes (which would be expected when reading into a
zero-byte array).  Instead, use SSL_peek.
Fixes #452./Parse ASN1_TIME structures in constructors. (#446)
The legacy OpenSSL APIs in BoringSSL don't parse ASN1_TIME values
until they're used, which means that the existing code could explode
in the middle of X509Certificate.getNotAfter() and similar
Date-returning calls, and those calls aren't declared to throw
anything.  Instead, read and cache the values in the constructor,
where we can throw a relevant exception if necessary.
We have to clone the Date values when returning them because Date is
mutable./Update short buffer handling. (#440)
This fixes a number of problems in Conscrypt's ciphers when they are
given an output buffer that is too small for the output.
We didn't specifically handle CIPHER_R_BUFFER_TOO_SMALL errors from
BoringSSL, so we threw RuntimeException on encountering them.  We
should be throwing ShortBufferException.
Raw ChaCha20 didn't check for a short buffer at all, so it just passed
the arrays down to native code, which could cause crashes or other
weird behavior.
EVP_AEAD ciphers used update() to only record data that needed to be
encrypted and then did the actual encrypting in doFinal().  This
combined with our implementation that implements doFinal() as a
combination of updateInternal() + doFinalInternal() led to a situation
where if the buffer passed to doFinal() was too small, the data would
get added to the buffer to be encrypted in updateInternal() and then
doFinalInternal() call would fail, which would mean a future call to
doFinal() with the same data would end up encrypting that data twice.
This call pattern is used by some internal CipherSpi methods from
OpenJDK, so you could see it in practice even if the caller did
nothing wrong.
Also add tests around short buffer handling./"
conscrypt,"Update short buffer handling. (#440)
This fixes a number of problems in Conscrypt's ciphers when they are
given an output buffer that is too small for the output.
We didn't specifically handle CIPHER_R_BUFFER_TOO_SMALL errors from
BoringSSL, so we threw RuntimeException on encountering them.  We
should be throwing ShortBufferException.
Raw ChaCha20 didn't check for a short buffer at all, so it just passed
the arrays down to native code, which could cause crashes or other
weird behavior.
EVP_AEAD ciphers used update() to only record data that needed to be
encrypted and then did the actual encrypting in doFinal().  This
combined with our implementation that implements doFinal() as a
combination of updateInternal() + doFinalInternal() led to a situation
where if the buffer passed to doFinal() was too small, the data would
get added to the buffer to be encrypted in updateInternal() and then
doFinalInternal() call would fail, which would mean a future call to
doFinal() with the same data would end up encrypting that data twice.
This call pattern is used by some internal CipherSpi methods from
OpenJDK, so you could see it in practice even if the caller did
nothing wrong.
Also add tests around short buffer handling./"
conscrypt,"Remove exception throwing on bad hostnames. (#478)
Testing on Android has indicated that there are too many things that
rely on passing whatever string has been passed to them to
setHostname() and aren't prepared to get an exception (including IP
addresses, single-element hostnames, and whatnot) for it to be
reasonable to throw an exception here.  Settle for documenting what
the behavior of passing an invalid hostname is./"
conscrypt,"Clean up some ErrorProne warnings. (#493)
* Add explicit charset to byte-to-String conversions.
* Add -1 to String.split() calls to make its behavior more intuitive.
* Add a missing @Override.
* Clarify an implicit int-to-byte conversion.
* Switch StringBuffer to StringBuilder.
* Inline an unnecessary function.
* Stop depending on FileDescriptor's toString./"
conscrypt,"Move TrustManagerImpl to common. (#503)
This is the first step in making the TrustManager implementation
available on OpenJDK, which is necessary for TLS 1.3 because the
TrustManager implementations in OpenJDK throw an exception when they
encounter an SSLSocket or SSLEngine that reports a protocol not in
their enumerated lists.  It moves the code and tests over so they
compile on OpenJDK, but doesn't yet change anything about the
provider, so the code isn't used.
There are a few changes necessary:
Extract an interface for TrustedCertificateStore, which is still
platform-only due to its reliance on specific directories to find
certs and other details of the Android platform.
Extract an interface for CertBlacklist, for the same reason.
Adjust TrustManagerImpl to get implementations of the add-on
functionality (CertBlacklist, CTLogStore, and CTPolicy) from the
Platform class instead of constructing them itself and tolerate nulls
for those classes.  The Platform classes for non-platform builds
return null for those classes, but we might want to change that in the
future.
Make a few minor changes while moving things over (JDK 6 source
compatibility, adjust tests for JUnit4, etc.)./"
conscrypt,"Stop using set_options to set protocol support. (#500)
The *_set_min_protocol_version and *_set_max_protocol_version
functions were introduced to be explicit about setting supported
versions.  Use those functions instead of SSL_set_options with
disabling constants.
There aren't any higher-level tests because this is already covered by
tests like SSLSocket.test_SSLSocket_setEnabledProtocols,
SSLSocket.test_SSLSocket_noncontiguousProtocols_useLower, etc./"
conscrypt,"Reduce warning spam (#522)
A significant number of log statements from this Platform method were
due to bad file descriptors, so check for those and throw
SocketException, which mirrors what sockets do when they have a bad
file descriptor in other situations./Move TrustManagerImpl to common. (#503)
This is the first step in making the TrustManager implementation
available on OpenJDK, which is necessary for TLS 1.3 because the
TrustManager implementations in OpenJDK throw an exception when they
encounter an SSLSocket or SSLEngine that reports a protocol not in
their enumerated lists.  It moves the code and tests over so they
compile on OpenJDK, but doesn't yet change anything about the
provider, so the code isn't used.
There are a few changes necessary:
Extract an interface for TrustedCertificateStore, which is still
platform-only due to its reliance on specific directories to find
certs and other details of the Android platform.
Extract an interface for CertBlacklist, for the same reason.
Adjust TrustManagerImpl to get implementations of the add-on
functionality (CertBlacklist, CTLogStore, and CTPolicy) from the
Platform class instead of constructing them itself and tolerate nulls
for those classes.  The Platform classes for non-platform builds
return null for those classes, but we might want to change that in the
future.
Make a few minor changes while moving things over (JDK 6 source
compatibility, adjust tests for JUnit4, etc.)./"
conscrypt,"Support opaque keys with RSA-PSS signatures. (#513)
TLS 1.3 only uses RSA-PSS signatures (rather than RSA-PKCS#1), so we
need to support these.  Implement it by switching to
Cipher.RSA/ECB/NoPadding instead of using Signature.RSA.  Fix the
opaque key tests so they actually work properly./Stop using set_options to set protocol support. (#500)
The *_set_min_protocol_version and *_set_max_protocol_version
functions were introduced to be explicit about setting supported
versions.  Use those functions instead of SSL_set_options with
disabling constants.
There aren't any higher-level tests because this is already covered by
tests like SSLSocket.test_SSLSocket_setEnabledProtocols,
SSLSocket.test_SSLSocket_noncontiguousProtocols_useLower, etc./"
conscrypt,"fix #491 ConscryptEngine.closeInbound should free resources (#511)
If closeOutbound is invoked prior to closeInbound, resources should
be freed./"
conscrypt,"Don't init cipher suites if native code didn't load (#517)
The try/catch and setting of loadError prevents the first static
initializer in NativeCrypto from rendering the class unloadable, but
the second static initializer still does, which means that users tend
to get NoClassDefFoundErrors when they try to use Conscrypt instead of
a more useful UnsatisfiedLinkError that points to the root cause./Move TrustManagerImpl to common. (#503)
This is the first step in making the TrustManager implementation
available on OpenJDK, which is necessary for TLS 1.3 because the
TrustManager implementations in OpenJDK throw an exception when they
encounter an SSLSocket or SSLEngine that reports a protocol not in
their enumerated lists.  It moves the code and tests over so they
compile on OpenJDK, but doesn't yet change anything about the
provider, so the code isn't used.
There are a few changes necessary:
Extract an interface for TrustedCertificateStore, which is still
platform-only due to its reliance on specific directories to find
certs and other details of the Android platform.
Extract an interface for CertBlacklist, for the same reason.
Adjust TrustManagerImpl to get implementations of the add-on
functionality (CertBlacklist, CTLogStore, and CTPolicy) from the
Platform class instead of constructing them itself and tolerate nulls
for those classes.  The Platform classes for non-platform builds
return null for those classes, but we might want to change that in the
future.
Make a few minor changes while moving things over (JDK 6 source
compatibility, adjust tests for JUnit4, etc.)./Stop using set_options to set protocol support. (#500)
The *_set_min_protocol_version and *_set_max_protocol_version
functions were introduced to be explicit about setting supported
versions.  Use those functions instead of SSL_set_options with
disabling constants.
There aren't any higher-level tests because this is already covered by
tests like SSLSocket.test_SSLSocket_setEnabledProtocols,
SSLSocket.test_SSLSocket_noncontiguousProtocols_useLower, etc./"
conscrypt,"Provide TrustManagerFactory (#516)
This is necessary for users who want to enable TLS 1.3, since the
TrustManagerFactory implementation shipped with OpenJDK throws an
exception if it encounters an SSLSocket or SSLEngine that's negotiated
TLS 1.3.  Use our TrustManager in tests.
Also adds a HostnameVerifier in the tests that does the simplest
thing, because our TrustManager verifies hostnames by default, whereas
the OpenJDK one doesn't, and the bundled HostnameVerifier on OpenJDK
just fails to verify anything./Support opaque keys with RSA-PSS signatures. (#513)
TLS 1.3 only uses RSA-PSS signatures (rather than RSA-PKCS#1), so we
need to support these.  Implement it by switching to
Cipher.RSA/ECB/NoPadding instead of using Signature.RSA.  Fix the
opaque key tests so they actually work properly./"
conscrypt,"Reduce warning spam (#522)
A significant number of log statements from this Platform method were
due to bad file descriptors, so check for those and throw
SocketException, which mirrors what sockets do when they have a bad
file descriptor in other situations./Move TrustManagerImpl to common. (#503)
This is the first step in making the TrustManager implementation
available on OpenJDK, which is necessary for TLS 1.3 because the
TrustManager implementations in OpenJDK throw an exception when they
encounter an SSLSocket or SSLEngine that reports a protocol not in
their enumerated lists.  It moves the code and tests over so they
compile on OpenJDK, but doesn't yet change anything about the
provider, so the code isn't used.
There are a few changes necessary:
Extract an interface for TrustedCertificateStore, which is still
platform-only due to its reliance on specific directories to find
certs and other details of the Android platform.
Extract an interface for CertBlacklist, for the same reason.
Adjust TrustManagerImpl to get implementations of the add-on
functionality (CertBlacklist, CTLogStore, and CTPolicy) from the
Platform class instead of constructing them itself and tolerate nulls
for those classes.  The Platform classes for non-platform builds
return null for those classes, but we might want to change that in the
future.
Make a few minor changes while moving things over (JDK 6 source
compatibility, adjust tests for JUnit4, etc.)./"
conscrypt,"Add TLS 1.3 benchmarks (#543)
Adds a BenchmarkProtocol parameter to ClientSocketBenchmark and
EngineHandshakeBenchmark to determine which protocol to use.
Switched EngineHandshakeBenchmark off TestUtils.doEngineHandshake and
onto its own implementation.  This lets us simulate network transit
time as well as eliminating all the test assertions and generally
operating closer to the typical usage of an SSLEngine.
Also adds the ability to specify JMH params on the command line./"
conscrypt,"Update handling of empty error queue (#555)
Some BoringSSL functions don't make any guarantees about the state of
the error queue if they return an error, and in most cases we don't
actually care what error occurred.  Instead of throwing AssertionError
when we encounter an error with no entry in the error queue, throw the
default exception type (which is usually RuntimeException).
Also removes NativeCrypto.ERR_peek_last_error(), which was only used
in tests.  We now have the CHECK_ERROR_QUEUE_ON_RETURN macro that
serves the same purpose but does it more comprehensively.
Fixes #553./Support TLS 1.3 (#524)
Enables support for negotiating TLS 1.3.  TLS 1.3 is not enabled
unless SSLContext.TLSv1.3 is requested or setEnabledProtocols() is
called with a set of values that includes TLSv1.3.
Detailed changes:
Adds protocol constants for TLS 1.3, and provides SSLContext.TLSv1.3,
which has TLS 1.3 enabled by default.
Adjusts cipher suite code for TLS 1.3 suites.  When enabled, all TLS
1.3 cipher suites are always returned from supportedCipherSuites() and
enabledCipherSuites().  Attempts to customize TLS 1.3 cipher suites in
setEnabledCipherSuites() are ignored.
Splits {SSLEngine,SSLSocket}Test into version-dependent and
version-independent tests.  The latter remain in
{SSLEngine,SSLSocket}Test and the former move into new files
{SSLEngine,SSLSocket}VersionCompatibilityTest, which are parameterized
to test all combinations of client and server on TLS 1.2 and TLS 1.3.
Remove a pile of RI-specific TLS-related expectation declarations from
StandardNames.  We don't actually verify the behavior of the RI at any
point, so it was just making the code more confusing.
Fixes #479./"
conscrypt,"Support TLS 1.3 (#524)
Enables support for negotiating TLS 1.3.  TLS 1.3 is not enabled
unless SSLContext.TLSv1.3 is requested or setEnabledProtocols() is
called with a set of values that includes TLSv1.3.
Detailed changes:
Adds protocol constants for TLS 1.3, and provides SSLContext.TLSv1.3,
which has TLS 1.3 enabled by default.
Adjusts cipher suite code for TLS 1.3 suites.  When enabled, all TLS
1.3 cipher suites are always returned from supportedCipherSuites() and
enabledCipherSuites().  Attempts to customize TLS 1.3 cipher suites in
setEnabledCipherSuites() are ignored.
Splits {SSLEngine,SSLSocket}Test into version-dependent and
version-independent tests.  The latter remain in
{SSLEngine,SSLSocket}Test and the former move into new files
{SSLEngine,SSLSocket}VersionCompatibilityTest, which are parameterized
to test all combinations of client and server on TLS 1.2 and TLS 1.3.
Remove a pile of RI-specific TLS-related expectation declarations from
StandardNames.  We don't actually verify the behavior of the RI at any
point, so it was just making the code more confusing.
Fixes #479./"
conscrypt,"General cleanup (#579)
Deal with some new ErrorProne warnings: unnecessary parentheses and
importing classes named Builder.
Add new cert failure logging to the test logging file so it doesn't
pollute the test output./"
conscrypt,"Fix X509_verify exceptions (#537)
Unexpectedly, X509_verify does not set an entry in the error queue
when the signature algorithm in a certificate's info doesn't match the
algorithm in the signature block, it just returns 0.  This trips an
AssertionError in throwExceptionFromBoringSSLError, so check for that
condition explicitly.
Also default to throwing CertificateException instead of
RuntimeException when X509_verify encounters an error that we haven't
explicitly handled.  I don't know if there are any such errors in
practice, but it'll be more correct if there are./"
conscrypt,"Update handling of empty error queue (#555)
Some BoringSSL functions don't make any guarantees about the state of
the error queue if they return an error, and in most cases we don't
actually care what error occurred.  Instead of throwing AssertionError
when we encounter an error with no entry in the error queue, throw the
default exception type (which is usually RuntimeException).
Also removes NativeCrypto.ERR_peek_last_error(), which was only used
in tests.  We now have the CHECK_ERROR_QUEUE_ON_RETURN macro that
serves the same purpose but does it more comprehensively.
Fixes #553./Allow d2i_X509_bio and friends to not set an error (#552)
BoringSSL recently changed so that d2i_X509_bio doesn't set an error
in the error queue when it receives certain garbage inputs.  We don't
actually care what error is set in the queue (we just end up catching
whatever is thrown and throwing CertificateException), so change to
tolerate having no error in the queue./Fix X509_verify exceptions (#537)
Unexpectedly, X509_verify does not set an entry in the error queue
when the signature algorithm in a certificate's info doesn't match the
algorithm in the signature block, it just returns 0.  This trips an
AssertionError in throwExceptionFromBoringSSLError, so check for that
condition explicitly.
Also default to throwing CertificateException instead of
RuntimeException when X509_verify encounters an error that we haven't
explicitly handled.  I don't know if there are any such errors in
practice, but it'll be more correct if there are./Support TLS 1.3 (#524)
Enables support for negotiating TLS 1.3.  TLS 1.3 is not enabled
unless SSLContext.TLSv1.3 is requested or setEnabledProtocols() is
called with a set of values that includes TLSv1.3.
Detailed changes:
Adds protocol constants for TLS 1.3, and provides SSLContext.TLSv1.3,
which has TLS 1.3 enabled by default.
Adjusts cipher suite code for TLS 1.3 suites.  When enabled, all TLS
1.3 cipher suites are always returned from supportedCipherSuites() and
enabledCipherSuites().  Attempts to customize TLS 1.3 cipher suites in
setEnabledCipherSuites() are ignored.
Splits {SSLEngine,SSLSocket}Test into version-dependent and
version-independent tests.  The latter remain in
{SSLEngine,SSLSocket}Test and the former move into new files
{SSLEngine,SSLSocket}VersionCompatibilityTest, which are parameterized
to test all combinations of client and server on TLS 1.2 and TLS 1.3.
Remove a pile of RI-specific TLS-related expectation declarations from
StandardNames.  We don't actually verify the behavior of the RI at any
point, so it was just making the code more confusing.
Fixes #479./"
conscrypt,"General cleanup (#579)
Deal with some new ErrorProne warnings: unnecessary parentheses and
importing classes named Builder.
Add new cert failure logging to the test logging file so it doesn't
pollute the test output./"
conscrypt,"Support TLS 1.3 (#524)
Enables support for negotiating TLS 1.3.  TLS 1.3 is not enabled
unless SSLContext.TLSv1.3 is requested or setEnabledProtocols() is
called with a set of values that includes TLSv1.3.
Detailed changes:
Adds protocol constants for TLS 1.3, and provides SSLContext.TLSv1.3,
which has TLS 1.3 enabled by default.
Adjusts cipher suite code for TLS 1.3 suites.  When enabled, all TLS
1.3 cipher suites are always returned from supportedCipherSuites() and
enabledCipherSuites().  Attempts to customize TLS 1.3 cipher suites in
setEnabledCipherSuites() are ignored.
Splits {SSLEngine,SSLSocket}Test into version-dependent and
version-independent tests.  The latter remain in
{SSLEngine,SSLSocket}Test and the former move into new files
{SSLEngine,SSLSocket}VersionCompatibilityTest, which are parameterized
to test all combinations of client and server on TLS 1.2 and TLS 1.3.
Remove a pile of RI-specific TLS-related expectation declarations from
StandardNames.  We don't actually verify the behavior of the RI at any
point, so it was just making the code more confusing.
Fixes #479./"
conscrypt,"Create ActiveSession during transitionTo() (#586)
The SessionContext we should use in ActiveSession depends on whether
the engine is in client or server mode, which we don't know until the
handshake is started, so wait until handshake start to create it.  As
a bonus, this makes the comment for activeSession correct again.
Also make closeInbound() the same as closeOutbound() where if you
close it before the handshake starts it just closes the engine
entirely.  STATE_CLOSED_INBOUND is assumed to be a post-handshake
state by a bunch of stuff, so we need to skip it.
Fixes #585./Add buffer allocators to ConscryptEngineSocket (#550)
This allows users to set a buffer allocator for both the buffers used
by ConscryptEngineSocket directly and the ones use by the enclosed
ConscryptEngine.
Fixes #549./"
conscrypt,"Add debug logging to TrustManagerImpl (#566)
This allows users to more easily debug failing chain construction.
Fixes #559./"
conscrypt,"Update handling of empty error queue (#555)
Some BoringSSL functions don't make any guarantees about the state of
the error queue if they return an error, and in most cases we don't
actually care what error occurred.  Instead of throwing AssertionError
when we encounter an error with no entry in the error queue, throw the
default exception type (which is usually RuntimeException).
Also removes NativeCrypto.ERR_peek_last_error(), which was only used
in tests.  We now have the CHECK_ERROR_QUEUE_ON_RETURN macro that
serves the same purpose but does it more comprehensively.
Fixes #553./Initialize HAS_AES_HARDWARE inside a loadError check (#567)
If loadError != null, then the native methods won't link, so we need
to ensure we don't call any.  The static initializer blocks check this
but this inline initialization expression was missed.
Fixes #560./Support TLS 1.3 (#524)
Enables support for negotiating TLS 1.3.  TLS 1.3 is not enabled
unless SSLContext.TLSv1.3 is requested or setEnabledProtocols() is
called with a set of values that includes TLSv1.3.
Detailed changes:
Adds protocol constants for TLS 1.3, and provides SSLContext.TLSv1.3,
which has TLS 1.3 enabled by default.
Adjusts cipher suite code for TLS 1.3 suites.  When enabled, all TLS
1.3 cipher suites are always returned from supportedCipherSuites() and
enabledCipherSuites().  Attempts to customize TLS 1.3 cipher suites in
setEnabledCipherSuites() are ignored.
Splits {SSLEngine,SSLSocket}Test into version-dependent and
version-independent tests.  The latter remain in
{SSLEngine,SSLSocket}Test and the former move into new files
{SSLEngine,SSLSocket}VersionCompatibilityTest, which are parameterized
to test all combinations of client and server on TLS 1.2 and TLS 1.3.
Remove a pile of RI-specific TLS-related expectation declarations from
StandardNames.  We don't actually verify the behavior of the RI at any
point, so it was just making the code more confusing.
Fixes #479./"
conscrypt,"General cleanup (#579)
Deal with some new ErrorProne warnings: unnecessary parentheses and
importing classes named Builder.
Add new cert failure logging to the test logging file so it doesn't
pollute the test output./"
conscrypt,"General cleanup (#579)
Deal with some new ErrorProne warnings: unnecessary parentheses and
importing classes named Builder.
Add new cert failure logging to the test logging file so it doesn't
pollute the test output./Fix typo in assumption (#578)
The tests that relied on this were being skipped in all cases, rather
than just when 1.3 would be negotiated./Move libcore.tlswire to org.conscrypt.tlswire (#568)
The TLS wire protocol stuff isn't actually used anywhere except in
Conscrypt, so move it to our package with the plan to delete it from
libcore once this goes into AOSP.
Also refactor two identical sets of methods into a single new
TlsTester class./Support TLS 1.3 (#524)
Enables support for negotiating TLS 1.3.  TLS 1.3 is not enabled
unless SSLContext.TLSv1.3 is requested or setEnabledProtocols() is
called with a set of values that includes TLSv1.3.
Detailed changes:
Adds protocol constants for TLS 1.3, and provides SSLContext.TLSv1.3,
which has TLS 1.3 enabled by default.
Adjusts cipher suite code for TLS 1.3 suites.  When enabled, all TLS
1.3 cipher suites are always returned from supportedCipherSuites() and
enabledCipherSuites().  Attempts to customize TLS 1.3 cipher suites in
setEnabledCipherSuites() are ignored.
Splits {SSLEngine,SSLSocket}Test into version-dependent and
version-independent tests.  The latter remain in
{SSLEngine,SSLSocket}Test and the former move into new files
{SSLEngine,SSLSocket}VersionCompatibilityTest, which are parameterized
to test all combinations of client and server on TLS 1.2 and TLS 1.3.
Remove a pile of RI-specific TLS-related expectation declarations from
StandardNames.  We don't actually verify the behavior of the RI at any
point, so it was just making the code more confusing.
Fixes #479./"
conscrypt,"General cleanup (#579)
Deal with some new ErrorProne warnings: unnecessary parentheses and
importing classes named Builder.
Add new cert failure logging to the test logging file so it doesn't
pollute the test output./"
conscrypt,"Add TLS 1.3 benchmarks (#543)
Adds a BenchmarkProtocol parameter to ClientSocketBenchmark and
EngineHandshakeBenchmark to determine which protocol to use.
Switched EngineHandshakeBenchmark off TestUtils.doEngineHandshake and
onto its own implementation.  This lets us simulate network transit
time as well as eliminating all the test assertions and generally
operating closer to the typical usage of an SSLEngine.
Also adds the ability to specify JMH params on the command line./"
conscrypt,"Enable TLS 1.3 by default (#595)
TLS 1.3 has seen successful rollouts in Chrome and Firefox, so we're
enabling it by default as well.  We expect this to result in better
security and performance.
Detailed changes:
Change the default TLS version to 1.3.  Callers can still get
connections that don't use TLS 1.3 by calling
SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols()
or SSLEngine.setEnabledProtocols().
Change to provide the TrustManager by default on OpenJDK.  The
TrustManager included in OpenJDK versions prior to 11 throws an
exception if it encounters a TLS version higher than 1.2, so we need
to provide a trust manager that will work with TLS 1.3.  The Android
trust manager (which is Conscrypt) will work fine, so don't provide
ours there.
Parameterize SSLSessionContextTest, since session behavior is
significantly different on TLS 1.2 and 1.3.  Also parameterized a few
other test cases whose behavior significantly differs between the
versions.
Use session tickets in test connections.  BoringSSL only supports
session resumption using tickets in 1.3, and we want to have
resumption functioning in our tests for the most part./Clean up session handling (#594)
The session passed to the SSLSessionBindingListener was always an
ExternalSession, even when that session was wrapped to support
ExtendedSSLSession, which meant that observers saw two different
sessions.  Refactor putValue() and removeValue() on ExternalSession to
take the session so that the wrappers can provide themselves.  Add a
test for SSLSessionBindingListener calling.
Slightly clean up ConscryptEngineSocket.getSession().  It doesn't need
to do cache the session from before it tries to handshake, and doing
so means that if you call getSession() twice in succession it might
return different results for no good reason.
Get rid of SSLNullSession.isNullSession, SSLUtils.unwrapSession, and
SessionDecorator, since that entire chain was only used in
ConscryptEngineSocket.getSession().
Fixes #593/Stop using InetAddress.isNumeric() (#588)
This method is likely to be blacklisted from reflective access on
Android, and we have an implementation that works acceptably./"
conscrypt,"Move libcore testing classes into testing (#607)
When conscrypt was first separated from AOSP some of the AOSP libcore
classes were copied into libcore-stub which is compiled against for
both the openjdk and platform builds but only used at runtime by the
openjdk builds. Unfortunately, those classes clash with internal classes
provided by the Android runtime which will cause problems in future
releases.
This change moves those libcore-stub classes that are only used for
testing from their libcore.... package into a org.conscrypt.... package
to prevent clashes. It also moves them out of the libcore-stub module
and into the testing module so they will be used on both platform and
openjdk builds./"
conscrypt,"Enable TLS 1.3 by default (#595)
TLS 1.3 has seen successful rollouts in Chrome and Firefox, so we're
enabling it by default as well.  We expect this to result in better
security and performance.
Detailed changes:
Change the default TLS version to 1.3.  Callers can still get
connections that don't use TLS 1.3 by calling
SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols()
or SSLEngine.setEnabledProtocols().
Change to provide the TrustManager by default on OpenJDK.  The
TrustManager included in OpenJDK versions prior to 11 throws an
exception if it encounters a TLS version higher than 1.2, so we need
to provide a trust manager that will work with TLS 1.3.  The Android
trust manager (which is Conscrypt) will work fine, so don't provide
ours there.
Parameterize SSLSessionContextTest, since session behavior is
significantly different on TLS 1.2 and 1.3.  Also parameterized a few
other test cases whose behavior significantly differs between the
versions.
Use session tickets in test connections.  BoringSSL only supports
session resumption using tickets in 1.3, and we want to have
resumption functioning in our tests for the most part./Clean up session handling (#594)
The session passed to the SSLSessionBindingListener was always an
ExternalSession, even when that session was wrapped to support
ExtendedSSLSession, which meant that observers saw two different
sessions.  Refactor putValue() and removeValue() on ExternalSession to
take the session so that the wrappers can provide themselves.  Add a
test for SSLSessionBindingListener calling.
Slightly clean up ConscryptEngineSocket.getSession().  It doesn't need
to do cache the session from before it tries to handshake, and doing
so means that if you call getSession() twice in succession it might
return different results for no good reason.
Get rid of SSLNullSession.isNullSession, SSLUtils.unwrapSession, and
SessionDecorator, since that entire chain was only used in
ConscryptEngineSocket.getSession().
Fixes #593/Stop using InetAddress.isNumeric() (#588)
This method is likely to be blacklisted from reflective access on
Android, and we have an implementation that works acceptably./"
conscrypt,"Update Provider installation in tests (#629)
Change CertPinManagerTest and CTVerifierTest to only install the
provider if it's not installed already and check if the provider was
installed before uninstalling.  Otherwise, when running on the Android
platform they will uninstall the platform copy of Conscrypt and break
every following test./"
conscrypt,"Remove CompatibilityCloseMonitor (#613)
This is only used on Android and we don't believe it's necessary.  The
ART team has asked that we remove it since the unbundled Android build
reaches into libjavacore.so and explicitly references compiled symbol
names, which is unreliable and could break in a future release./"
conscrypt,"Clean up session handling (#594)
The session passed to the SSLSessionBindingListener was always an
ExternalSession, even when that session was wrapped to support
ExtendedSSLSession, which meant that observers saw two different
sessions.  Refactor putValue() and removeValue() on ExternalSession to
take the session so that the wrappers can provide themselves.  Add a
test for SSLSessionBindingListener calling.
Slightly clean up ConscryptEngineSocket.getSession().  It doesn't need
to do cache the session from before it tries to handshake, and doing
so means that if you call getSession() twice in succession it might
return different results for no good reason.
Get rid of SSLNullSession.isNullSession, SSLUtils.unwrapSession, and
SessionDecorator, since that entire chain was only used in
ConscryptEngineSocket.getSession().
Fixes #593/"
conscrypt,"Enable TLS 1.3 by default (#595)
TLS 1.3 has seen successful rollouts in Chrome and Firefox, so we're
enabling it by default as well.  We expect this to result in better
security and performance.
Detailed changes:
Change the default TLS version to 1.3.  Callers can still get
connections that don't use TLS 1.3 by calling
SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols()
or SSLEngine.setEnabledProtocols().
Change to provide the TrustManager by default on OpenJDK.  The
TrustManager included in OpenJDK versions prior to 11 throws an
exception if it encounters a TLS version higher than 1.2, so we need
to provide a trust manager that will work with TLS 1.3.  The Android
trust manager (which is Conscrypt) will work fine, so don't provide
ours there.
Parameterize SSLSessionContextTest, since session behavior is
significantly different on TLS 1.2 and 1.3.  Also parameterized a few
other test cases whose behavior significantly differs between the
versions.
Use session tickets in test connections.  BoringSSL only supports
session resumption using tickets in 1.3, and we want to have
resumption functioning in our tests for the most part./"
conscrypt,"Clean up session handling (#594)
The session passed to the SSLSessionBindingListener was always an
ExternalSession, even when that session was wrapped to support
ExtendedSSLSession, which meant that observers saw two different
sessions.  Refactor putValue() and removeValue() on ExternalSession to
take the session so that the wrappers can provide themselves.  Add a
test for SSLSessionBindingListener calling.
Slightly clean up ConscryptEngineSocket.getSession().  It doesn't need
to do cache the session from before it tries to handshake, and doing
so means that if you call getSession() twice in succession it might
return different results for no good reason.
Get rid of SSLNullSession.isNullSession, SSLUtils.unwrapSession, and
SessionDecorator, since that entire chain was only used in
ConscryptEngineSocket.getSession().
Fixes #593/"
conscrypt,"Move libcore testing classes into testing (#607)
When conscrypt was first separated from AOSP some of the AOSP libcore
classes were copied into libcore-stub which is compiled against for
both the openjdk and platform builds but only used at runtime by the
openjdk builds. Unfortunately, those classes clash with internal classes
provided by the Android runtime which will cause problems in future
releases.
This change moves those libcore-stub classes that are only used for
testing from their libcore.... package into a org.conscrypt.... package
to prevent clashes. It also moves them out of the libcore-stub module
and into the testing module so they will be used on both platform and
openjdk builds./"
conscrypt,"Enable TLS 1.3 by default (#595)
TLS 1.3 has seen successful rollouts in Chrome and Firefox, so we're
enabling it by default as well.  We expect this to result in better
security and performance.
Detailed changes:
Change the default TLS version to 1.3.  Callers can still get
connections that don't use TLS 1.3 by calling
SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols()
or SSLEngine.setEnabledProtocols().
Change to provide the TrustManager by default on OpenJDK.  The
TrustManager included in OpenJDK versions prior to 11 throws an
exception if it encounters a TLS version higher than 1.2, so we need
to provide a trust manager that will work with TLS 1.3.  The Android
trust manager (which is Conscrypt) will work fine, so don't provide
ours there.
Parameterize SSLSessionContextTest, since session behavior is
significantly different on TLS 1.2 and 1.3.  Also parameterized a few
other test cases whose behavior significantly differs between the
versions.
Use session tickets in test connections.  BoringSSL only supports
session resumption using tickets in 1.3, and we want to have
resumption functioning in our tests for the most part./Move libcore testing classes into testing (#607)
When conscrypt was first separated from AOSP some of the AOSP libcore
classes were copied into libcore-stub which is compiled against for
both the openjdk and platform builds but only used at runtime by the
openjdk builds. Unfortunately, those classes clash with internal classes
provided by the Android runtime which will cause problems in future
releases.
This change moves those libcore-stub classes that are only used for
testing from their libcore.... package into a org.conscrypt.... package
to prevent clashes. It also moves them out of the libcore-stub module
and into the testing module so they will be used on both platform and
openjdk builds./"
conscrypt,"Enable TLS 1.3 by default (#595)
TLS 1.3 has seen successful rollouts in Chrome and Firefox, so we're
enabling it by default as well.  We expect this to result in better
security and performance.
Detailed changes:
Change the default TLS version to 1.3.  Callers can still get
connections that don't use TLS 1.3 by calling
SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols()
or SSLEngine.setEnabledProtocols().
Change to provide the TrustManager by default on OpenJDK.  The
TrustManager included in OpenJDK versions prior to 11 throws an
exception if it encounters a TLS version higher than 1.2, so we need
to provide a trust manager that will work with TLS 1.3.  The Android
trust manager (which is Conscrypt) will work fine, so don't provide
ours there.
Parameterize SSLSessionContextTest, since session behavior is
significantly different on TLS 1.2 and 1.3.  Also parameterized a few
other test cases whose behavior significantly differs between the
versions.
Use session tickets in test connections.  BoringSSL only supports
session resumption using tickets in 1.3, and we want to have
resumption functioning in our tests for the most part./Move libcore testing classes into testing (#607)
When conscrypt was first separated from AOSP some of the AOSP libcore
classes were copied into libcore-stub which is compiled against for
both the openjdk and platform builds but only used at runtime by the
openjdk builds. Unfortunately, those classes clash with internal classes
provided by the Android runtime which will cause problems in future
releases.
This change moves those libcore-stub classes that are only used for
testing from their libcore.... package into a org.conscrypt.... package
to prevent clashes. It also moves them out of the libcore-stub module
and into the testing module so they will be used on both platform and
openjdk builds./"
conscrypt,"Enable TLS 1.3 by default (#595)
TLS 1.3 has seen successful rollouts in Chrome and Firefox, so we're
enabling it by default as well.  We expect this to result in better
security and performance.
Detailed changes:
Change the default TLS version to 1.3.  Callers can still get
connections that don't use TLS 1.3 by calling
SSLContext.get(""TLSv1.2"") or calling SSLSocket.setEnabledProtocols()
or SSLEngine.setEnabledProtocols().
Change to provide the TrustManager by default on OpenJDK.  The
TrustManager included in OpenJDK versions prior to 11 throws an
exception if it encounters a TLS version higher than 1.2, so we need
to provide a trust manager that will work with TLS 1.3.  The Android
trust manager (which is Conscrypt) will work fine, so don't provide
ours there.
Parameterize SSLSessionContextTest, since session behavior is
significantly different on TLS 1.2 and 1.3.  Also parameterized a few
other test cases whose behavior significantly differs between the
versions.
Use session tickets in test connections.  BoringSSL only supports
session resumption using tickets in 1.3, and we want to have
resumption functioning in our tests for the most part./Clean up session handling (#594)
The session passed to the SSLSessionBindingListener was always an
ExternalSession, even when that session was wrapped to support
ExtendedSSLSession, which meant that observers saw two different
sessions.  Refactor putValue() and removeValue() on ExternalSession to
take the session so that the wrappers can provide themselves.  Add a
test for SSLSessionBindingListener calling.
Slightly clean up ConscryptEngineSocket.getSession().  It doesn't need
to do cache the session from before it tries to handshake, and doing
so means that if you call getSession() twice in succession it might
return different results for no good reason.
Get rid of SSLNullSession.isNullSession, SSLUtils.unwrapSession, and
SessionDecorator, since that entire chain was only used in
ConscryptEngineSocket.getSession().
Fixes #593/Stop using InetAddress.isNumeric() (#588)
This method is likely to be blacklisted from reflective access on
Android, and we have an implementation that works acceptably./"
conscrypt,"Don't send TLS_FALLBACK_SCSV if max version is >= 1.2 (#651)
TLS_FALLBACK_SCSV protects against downgrade attacks when clients
implement a version fallback independent of TLS version
negotiation, but if it's set on a non-fallback connection
attempt, it will prevent an otherwise-safe connection if the
server supports a version higher than the client does.  Because
the default OpenJDK TLS implementation doesn't support
TLS_FALLBACK_SCSV, some developers mistakenly enable it on every
connection due to thinking it's a normal cipher suite, which is
starting to cause issues when servers upgrade to TLS 1.3.
We can obviously omit it on connections with a max version of 1.3,
since that's Conscrypt's max version, so it can't be a version
fallback.
As far as connections with a max version of 1.2 are concerned, this
type of fallback is generally not needed any longer, since TLS
1.3-supporting servers should all perform version negotiation
properly.  (Chrome and Firefox have both disabled version fallback
entirely.)  Thus TLS_FALLBACK_SCSV's presence in connections with a
max version of 1.2 is significantly more likely to be a
misconfiguration than a true fallback indication.
We continue to include the cipher suite for connections with a max
version of 1.1 or lower.  First, flaws in pre-1.2 versions are more
likely to exist than flaws in 1.2, so the benefit of flagging
downgrades to those versions are higher.  As well, fallback is most
likely to be useful when dealing with buggy TLS 1.2 servers.
Fixes #574/"
conscrypt,"Update OID->name mapping code (#670)
Add our own class for the standard OIDs.  This should eliminate our
reliance on the platform data for the vast majority of cases.
Catch IllegalAccessError if thrown in OpenJDK, since java.base doesn't
export AlgorithmId so under JPMS we might not have access to it.
Fixes #667./"
conscrypt,"Add Conscrypt-specific hostname verifier (#636)
This allows users to set hostname verifiers either Conscrypt-wide or
on an individual trust manager without polluting the default
HostnameVerifier of HttpsURLConnection.
Fixes #598/"
conscrypt,"Fetch local certs when available (#663)
Local certificates don't change once they're set, so we don't have to
wait for any particular point to fetch and cache them.  If someone
requests them, we can just get them from the SSL if available.
Also adds tests for getHandshakeSession() on the server side, which is
a time when these certs would previously not have been available.
Fixes #634/"
conscrypt,"Add Conscrypt-specific hostname verifier (#636)
This allows users to set hostname verifiers either Conscrypt-wide or
on an individual trust manager without polluting the default
HostnameVerifier of HttpsURLConnection.
Fixes #598/"
conscrypt,"Don't send TLS_FALLBACK_SCSV if max version is >= 1.2 (#651)
TLS_FALLBACK_SCSV protects against downgrade attacks when clients
implement a version fallback independent of TLS version
negotiation, but if it's set on a non-fallback connection
attempt, it will prevent an otherwise-safe connection if the
server supports a version higher than the client does.  Because
the default OpenJDK TLS implementation doesn't support
TLS_FALLBACK_SCSV, some developers mistakenly enable it on every
connection due to thinking it's a normal cipher suite, which is
starting to cause issues when servers upgrade to TLS 1.3.
We can obviously omit it on connections with a max version of 1.3,
since that's Conscrypt's max version, so it can't be a version
fallback.
As far as connections with a max version of 1.2 are concerned, this
type of fallback is generally not needed any longer, since TLS
1.3-supporting servers should all perform version negotiation
properly.  (Chrome and Firefox have both disabled version fallback
entirely.)  Thus TLS_FALLBACK_SCSV's presence in connections with a
max version of 1.2 is significantly more likely to be a
misconfiguration than a true fallback indication.
We continue to include the cipher suite for connections with a max
version of 1.1 or lower.  First, flaws in pre-1.2 versions are more
likely to exist than flaws in 1.2, so the benefit of flagging
downgrades to those versions are higher.  As well, fallback is most
likely to be useful when dealing with buggy TLS 1.2 servers.
Fixes #574/"
conscrypt,"Refactor OpenSSLCipher (#654)
The heavily-nested class structure makes it hard to follow what every
class is doing.  Instead, break them out into their own classes by
algorithm./"
conscrypt,"Add ServiceTester helper class (#661)
We have a lot of tests that follow the same basic pattern of ""for all
providers, for some/all algorithms of a given type, check {X, Y, Z}"".
This introduces a helper object that handles the common parts (finding
supported providers, matching errors to providers, etc) so the tests
can focus on the test logic.
This change also cleans up a bunch of minor test problems:
* Test arrays with assertArraysEqual(), not assertTrue(Arrays.equal())
* Unusual formatting (extraneous blocks, etc.)
* Unnecessary installing of BouncyCastleProvider in TestKeyStore/"
conscrypt,"Move openjdk-integ-tests to common (#720)
The tests in openjdk-integ-tests haven't matched their name in a
while: they test Conscrypt-specific features in places, we run them on
platforms other than OpenJDK, and they're a combination of
integration, unit, and regression tests.  To ease confusion, move them
into common alongside other common tests.  Their package names (eg,
org.conscrypt.java.security) will still indicate that they're testing
the overall interface rather than Conscrypt-specific classes, but it
should be more clear that they're just part of the overall testing
scheme of Conscrypt on all platforms.
As part of this, remove the architecture-specific test rules in
openjdk and only test on the preferred architecture.  The additional
test classes increase the running time of the test rule to multiple
minutes, and neither the new nor the old tests are obviously
architecture-sensitive. In the rare case where it's desired to test on
multiple architectures, we can run the test rule twice in different
configurations.
We also change the existing OpenJDK tests to run in a suite that
installs Conscrypt before running.  This works better with the new
tests and makes the tests not need to manage provider installation
themselves.  As part of this, also remove calls to TestUtils methods
that need the Conscrypt provider to be installed during static
initialization; during static initialization, the provider isn't
installed and having those calls makes TLS tests fail on OpenJDK < 11./"
conscrypt,"Fix ConscryptEngine state machine (#687)
The SSLEngine state machine is slightly more complicated than our
previous code presumed.  After closeInbound() or closeOutbound() are
called, isInboundDone() and isOutboundDone() shouldn't immediately
return true.  Rather, closeInbound() and closeOutbound() indicate the
caller's intention to never supply any more input data in the given
direction, but isInboundDone() and isOutboundDone() indicate that no
more output data in the given direction will be produced.  This means
those methods need to be adjusted to take into account the state of
internal plaintext/ciphertext buffers.
This simplifies and corrects some of the other code as well.  In
particular, we no longer have to stash exceptions that are thrown
during the handshake, because the caller is expected to see those
exceptions and drain the outgoing buffer (which previously they had no
way of doing).
Fixes #577/"
conscrypt,"Move openjdk-integ-tests to common (#720)
The tests in openjdk-integ-tests haven't matched their name in a
while: they test Conscrypt-specific features in places, we run them on
platforms other than OpenJDK, and they're a combination of
integration, unit, and regression tests.  To ease confusion, move them
into common alongside other common tests.  Their package names (eg,
org.conscrypt.java.security) will still indicate that they're testing
the overall interface rather than Conscrypt-specific classes, but it
should be more clear that they're just part of the overall testing
scheme of Conscrypt on all platforms.
As part of this, remove the architecture-specific test rules in
openjdk and only test on the preferred architecture.  The additional
test classes increase the running time of the test rule to multiple
minutes, and neither the new nor the old tests are obviously
architecture-sensitive. In the rare case where it's desired to test on
multiple architectures, we can run the test rule twice in different
configurations.
We also change the existing OpenJDK tests to run in a suite that
installs Conscrypt before running.  This works better with the new
tests and makes the tests not need to manage provider installation
themselves.  As part of this, also remove calls to TestUtils methods
that need the Conscrypt provider to be installed during static
initialization; during static initialization, the provider isn't
installed and having those calls makes TLS tests fail on OpenJDK < 11./"
conscrypt,"Fixes for issues found by lgtm.com (#706)
* KeyManagerFactoryImpl: close opened file stream
lgtm.com found an issue where FileInputStream was not closed when
setting up a KeyManagerFactoryImpl.
* FileClientSessionCache: use IoUtils.closeQuietly
lgtm.com found a useless null check because FileInputStream never
returns null. However, we can just use our utility function
IoUtils.closeQuietly to achieve the same thing that was intended here./"
conscrypt,"Fix implementation of available() in sockets (#694)
The file descriptor socket used the default implementation of
available(), which just always returns 0.  We can at least return the
pending bytes in the plaintext buffer, since those are definitely
available.
The engine socket had two issues.  First, it used
fromSocket.remaining(), but fromSocket was in a writing posture, so it
always had a high return from remaining() regardless of whether there
was pending readable data in the buffer.  This was the cause of #433:
a BufferedReader would read some data, then check available() to see
if it could freely fill some more data without blocking.  The engine
socket would report that it could, so it would try to read that data
and then unexpectedly block.
The second issue is that incoming socket data doesn't necessarily
imply readable plaintext data: it might be a partial TLS record, a
handshake or other management record, etc.  So we should only report
plaintext data that's actually been successfully decrypted from
available().
Fixes #433/"
conscrypt,"Fix engine socket tests (#707)
The engine test system property was being overwritten, which resulted
in the engine socket test not actually being executed with the engine
socket.  This fixes that problem, so :testEngineSocket now actually
runs with the engine socket.
This revealed several test failures that were all due to the engine
and engine socket closing behavior.  In particular, the engine
wouldn't mark itself as closed when an SSLException was thrown, which
it is supposed to per the documentation.  This meant that when the
engine socket attempted to flush the outgoing buffer, it would just
trigger whatever exception had originally caused the problem again,
the outgoing buffer wouldn't get flushed, and alerts wouldn't reach
the peer.  Closing the engine whenever an exception propagates out
fixes this problem, along with tolerating a CLOSED status return in
the engine socket./Fix ConscryptEngine state machine (#687)
The SSLEngine state machine is slightly more complicated than our
previous code presumed.  After closeInbound() or closeOutbound() are
called, isInboundDone() and isOutboundDone() shouldn't immediately
return true.  Rather, closeInbound() and closeOutbound() indicate the
caller's intention to never supply any more input data in the given
direction, but isInboundDone() and isOutboundDone() indicate that no
more output data in the given direction will be produced.  This means
those methods need to be adjusted to take into account the state of
internal plaintext/ciphertext buffers.
This simplifies and corrects some of the other code as well.  In
particular, we no longer have to stash exceptions that are thrown
during the handshake, because the caller is expected to see those
exceptions and drain the outgoing buffer (which previously they had no
way of doing).
Fixes #577/"
conscrypt,"Accommodate KeyStores that don't support getEntry() (#686)
The Android Keystore implementation of KeyStore doesn't implement
getEntry() and throws UnsupportedOperationException if you try to call
it.  We can adapt to that by attempting to retrieve the private key
and certificate chain manually if the call to getEntry() fails.
Fixes #685/"
conscrypt,"Minor cleanup (#688)
Clean up some unused variable and method ErrorProne warnings.
Eliminate debug logging from NativeLibraryLoader in tests./Ignore RuntimeExceptions thrown in CryptoUpcalls (#684)
Signature's provider selection code ignores RuntimeExceptions thrown
during init and continues to test providers to see if a lower priority
provider will be successful, whereas we previously allowed
RuntimeExceptions to propagate out of our provider selection code.
Follow Signature's lead and catch RuntimeExceptions.
The motivation for this change is a problem on Android versions up to
L where Android Keystore opaque keys are used in signing operations.
They appear to be valid EC keys, but throw
UnsupportedOperationException when their key material is accessed,
which causes Conscrypt's delegate selection code to explode.  Instead
now we will catch the RuntimeException and continue to test providers
until one is found that can use the key.
As part of this, move OpaqueProvider to testing infrastructure and add
a BrokenProvider that just explodes on everything.
Fixes #679/"
conscrypt,"Ignore RuntimeExceptions thrown in CryptoUpcalls (#684)
Signature's provider selection code ignores RuntimeExceptions thrown
during init and continues to test providers to see if a lower priority
provider will be successful, whereas we previously allowed
RuntimeExceptions to propagate out of our provider selection code.
Follow Signature's lead and catch RuntimeExceptions.
The motivation for this change is a problem on Android versions up to
L where Android Keystore opaque keys are used in signing operations.
They appear to be valid EC keys, but throw
UnsupportedOperationException when their key material is accessed,
which causes Conscrypt's delegate selection code to explode.  Instead
now we will catch the RuntimeException and continue to test providers
until one is found that can use the key.
As part of this, move OpaqueProvider to testing infrastructure and add
a BrokenProvider that just explodes on everything.
Fixes #679/"
Frostwire,[desktop] Fixes bug setting author on m4a from YT. Cleanup./
Frostwire,"[desktop] Fixes bug setting author on m4a from YT. Cleanup./[dekstop] Using fmp4, fixed compilation/"
Frostwire,[desktop] Fixes bug opening certain YT preview URLs/
Frostwire,Compilation fixes/
Frostwire,"[common] NPE check, cleanup on BTDownload.java/"
Frostwire,[common] Fixes EZTV search (Issue #78)/
Frostwire,[common] username fix for YT/[common] Fix in YT extractor/[common] Fixed YT dash extraction/
Frostwire,[common] Minor regex fix/[common] Avoid channels in YT search performer/
Frostwire,[android] Updated to jlibtorrent 1.1.0.21 and fixed issues with common changes/
Frostwire,[common] Should fix Monova search. Issue #79. (tested only on desktop)/
Frostwire,[android] next batch of fragment refactors and fixes./
Frostwire,[android] Fixes issue #118 - Repeated 'More by artist' menu entry. changelog./[android] next batch of fragment refactors and fixes./
Frostwire,[android] next batch of fragment refactors and fixes./
Frostwire,"[android] fixed scrolling issue on profile adapters./[android] don't call refresh() inside restartLoader. minor optimizations. hunting for bug on favoritefragment./[android] fixes issue where last added favorite wasn't displaying. other refresh issues remain./[android] fixes on favorite fragment, adding to favorites./[android] next batch of fragment refactors and fixes./"
Frostwire,[android] next batch of fragment refactors and fixes./
Frostwire,"[android/apollo] Bug fix. Now a playlist can be created out of 'More by artist' songs./[android] build 242 - Fixes refresh issues adding/removing playlists. Refactors, cleanup./[android] fixed scrolling issue on profile adapters./[android] don't call refresh() inside restartLoader. minor optimizations. hunting for bug on favoritefragment./[android] multiple fixes and cleanup.
- Back arrow on top bar and back button behave the same -> goBack().
If user is inside an album view, it goes back to the artist profile, otherwise
it finishes the task.
- When an album is removed list of albums is refreshed and songs are removed from recent./[android] fixes issue where last added favorite wasn't displaying. other refresh issues remain./[android] fixes on playlist handling./[android] fix display of recents, refactor on albumLoader./[android] fixes crash on long pressing special playlists./[android] fixes on favorite fragment, adding to favorites./[android] almost ready to merge, cleaning up, fixes./[android] mistery solved, several fixes, lots of logging to find it./[android] next batch of fragment refactors and fixes./"
Frostwire,[android] next batch of fragment refactors and fixes./
Frostwire,[android] next batch of fragment refactors and fixes./
Frostwire,[android] fixes on playlist handling./[android] next batch of fragment refactors and fixes./
Frostwire,[android] next batch of fragment refactors and fixes./
Frostwire,"[android] mistery solved, several fixes, lots of logging to find it./"
Frostwire,"[android] fixes on playlist handling./[android] mistery solved, several fixes, lots of logging to find it./"
Frostwire,"[android] build 242 - Fixes refresh issues adding/removing playlists. Refactors, cleanup./[android] fixes on playlist handling./[android] almost ready to merge, cleaning up, fixes./"
Frostwire,"[android] almost ready to merge, cleaning up, fixes./"
Frostwire,"[android] solves back button issue on Album fragment./[android] almost ready to merge, cleaning up, fixes./[android] next batch of fragment refactors and fixes./"
Frostwire,"[android] fix backgrounds of MyMusic search. cleanup, refactors./"
Frostwire,"[android] multiple fixes and cleanup.
- Back arrow on top bar and back button behave the same -> goBack().
If user is inside an album view, it goes back to the artist profile, otherwise
it finishes the task.
- When an album is removed list of albums is refreshed and songs are removed from recent./[android] fixes on playlist handling./[android] almost ready to merge, cleaning up, fixes./"
Frostwire,[android] don't call refresh() inside restartLoader. minor optimizations. hunting for bug on favoritefragment./[android] fixes on playlist handling./
Frostwire,"[android] fix backgrounds of MyMusic search. cleanup, refactors./[android] fixes on playlist handling./"
Frostwire,"[android] fix display of recents, refactor on albumLoader./"
Frostwire,[android] Avoid load of non existent resources for colors (no more warning log from android)/
Frostwire,"[android] fixes on favorite fragment, adding to favorites./[android] mistery solved, several fixes, lots of logging to find it./[android] next batch of fragment refactors and fixes./"
Frostwire,"[android] fixes issue with adapters adding null extra element at the end/[android] Fixes issue creating playlist off of artist./[android] fixed scrolling issue on profile adapters./[android] almost ready to merge, cleaning up, fixes./[android] mistery solved, several fixes, lots of logging to find it./"
Frostwire,"[android] Fixes issue #107 - update My files headers on file deletion.
Updates ""My Files"" header file count when:
- File is removed from ""My Files""
- File is/are removed from ""My Music"", context menu actions.
- File is removed from Music Player screen during playback.
- File is/are removed from a finished transfer./"
Frostwire,"[android] last fixes on create/rename playlist dialog./[android] build 242 - Fixes refresh issues adding/removing playlists. Refactors, cleanup./"
Frostwire,"[android] Fixed show cover on lockscreen
is stopped - not show
is paused from notification - show
is close notification - not show
is paused from foreground - not show
is kill notification and paused- not show/[android] don't stop shutting down the music service if anything happens during broadcast to effect processors./[android] Avoiding NPE related to apollo/[android] Protecting from a failure in getAlbumtArt, specially a NPE while updating the remote control client/[android] Don't crash if we cant access ""content://media/external/fs_id""/[android] Don't crash if we can't get the MODIFY_PHONE_STATE permission. This is only used for remote control from the lock screen./[android] Fixed potential concurrency issue while releasing the mNextMediaPlayer/[android] NPEs are possible even after checking for non null. Fix./"
Frostwire,"[android] fix display of recents, refactor on albumLoader./"
Frostwire,"[android] almost ready to merge, cleaning up, fixes./"
Frostwire,"[android] multiple fixes and cleanup.
- Back arrow on top bar and back button behave the same -> goBack().
If user is inside an album view, it goes back to the artist profile, otherwise
it finishes the task.
- When an album is removed list of albums is refreshed and songs are removed from recent./[android] mistery solved, several fixes, lots of logging to find it./[android] next batch of fragment refactors and fixes./"
Frostwire,[android] fixed scrolling issue on profile adapters./
Frostwire,[android] fixed scrolling issue on profile adapters./
Frostwire,[android] Avoid internal NPE in android BitmapFactory#decodeFile/
Frostwire,[android] Fixed build/
Frostwire,[android] Fixed build/
Frostwire,[android] copyright fixes. DRY refactor with dlg.setStyle()/[android] cast crash fixed./[android] fix issue with thumbnail. refactored dialog and adapter out of DownloadSoundcloudFromUrlTask into separate files./[android] checkboxs work. finished breaking dependency on SearchResult for ConfirmListDialog./Making more fail safe getting the last selected item from results lists/[android] cast crash fixed./[android] fix issue with thumbnail. refactored dialog and adapter out of DownloadSoundcloudFromUrlTask into separate files./[android] checkboxs work. finished breaking dependency on SearchResult for ConfirmListDialog./Making more fail safe getting the last selected item from results lists/[android] Updated to jlibtorrent 1.1.0.21 and fixed issues with common changes/
Frostwire,"[android] search and other torrent downloads now support partial download dialog. edge cases to fix./[android] pluggin HandpickedTorrentDialog on more use cases, got it to crash./"
Frostwire,"[android] copyright fixes. DRY refactor with dlg.setStyle()/[android] search and other torrent downloads now support partial download dialog. edge cases to fix./[android] pluggin HandpickedTorrentDialog on more use cases, got it to crash./"
Frostwire,"[android] Fixes issue #107 - update My files headers on file deletion.
Updates ""My Files"" header file count when:
- File is removed from ""My Files""
- File is/are removed from ""My Music"", context menu actions.
- File is removed from Music Player screen during playback.
- File is/are removed from a finished transfer./[android] Updates file count after files are deleted. Fixes #104/[android] fix onItemChecked on browse peers./[android] checkboxs work. finished breaking dependency on SearchResult for ConfirmListDialog./[android] checkboxs work. finished breaking dependency on SearchResult for ConfirmListDialog./"
Frostwire,"[common] typo, missing fix (versioning)./"
Frostwire,"[android] Fixes issue #107 - update My files headers on file deletion.
Updates ""My Files"" header file count when:
- File is removed from ""My Files""
- File is/are removed from ""My Music"", context menu actions.
- File is removed from Music Player screen during playback.
- File is/are removed from a finished transfer./[android] Avoid scan of private temp files/"
Frostwire,[android] search and other torrent downloads now support partial download dialog. edge cases to fix./
Frostwire,"[android] Shows descriptive error on Internet dropped (Issue #107). Clears errored cloud transfers./[android] Not using File.renameTo, it fails in Android if mount points are different/"
Frostwire,"[android] Fixes issue #107 - update My files headers on file deletion.
Updates ""My Files"" header file count when:
- File is removed from ""My Files""
- File is/are removed from ""My Music"", context menu actions.
- File is removed from Music Player screen during playback.
- File is/are removed from a finished transfer./"
Frostwire,"[android] Shows descriptive error on Internet dropped (Issue #107). Clears errored cloud transfers./[android] Not using File.renameTo, it fails in Android if mount points are different/[android] Fixed potential issue with saving pure http downloads in SD/[android] SoundCloud transfers were not reporting progress correctly due to unknown file size. Fixes Issue #95/"
Frostwire,Compilation fixes/
Frostwire,"[android] import cleanup, fixes broken build./[android] multiple fixes and cleanup.
- Back arrow on top bar and back button behave the same -> goBack().
If user is inside an album view, it goes back to the artist profile, otherwise
it finishes the task.
- When an album is removed list of albums is refreshed and songs are removed from recent./"
Frostwire,[android] Shows descriptive error on Internet dropped (Issue #107). Clears errored cloud transfers./
Frostwire,[android] Updated to jlibtorrent 1.1.0.21 and fixed issues with common changes/
Frostwire,[android] copyright fixes. DRY refactor with dlg.setStyle()/
Frostwire,[android] copyright fixes. DRY refactor with dlg.setStyle()/
Frostwire,[android] copyright fixes. DRY refactor with dlg.setStyle()/
Frostwire,[android] fixed Illegal state exception with FragmentManager when showing AbstractConfirmListDialog./[android] copyright fixes. DRY refactor with dlg.setStyle()/[android] search and other torrent downloads now support partial download dialog. edge cases to fix./
Frostwire,[android] copyright fixes. DRY refactor with dlg.setStyle()/
Frostwire,[android] checkboxs work. finished breaking dependency on SearchResult for ConfirmListDialog./[android] checkboxs work. finished breaking dependency on SearchResult for ConfirmListDialog./
Frostwire,[desktop] avoid touching the UI from a background thread (that could freeze the application)/
Frostwire,[android] fixes bug where torrent download dialog would keep coming back./[desktop] better error output when encountering invalid torrent/
Frostwire,[desktop] Show update download progress on Tools menu. Fixes #103/
Frostwire,[desktop] fix width of search tools panel/
Frostwire,[desktop] fix width of search tools panel/
Frostwire,[desktop] possible NPE witnessed in Linux/
Frostwire,[desktop] Show update download progress on Tools menu. Fixes #103/
Frostwire,"[common] Fixed NPE if downloading magnet/[android] fixing conflicts./[common] Another NPE fix due to bad timing, in need of refactor/[common] Fixed NPE but the main reason is bad timing in loading (needs refactor)/"
Frostwire,[common] Allow natural flow of exceptions in http client save/
Frostwire,[common] fix some yt regex/
Frostwire,[common] Fixes YT search issues/[common] fix some yt regex/[common] YT preliminary html offset finder was broken after updates./
Frostwire,"Merge pull request #142 from alejandroarturom/torlock-fixes
[common] Fixes Torlock Search/[common] Fixes Torlock Search/"
Frostwire,"Merge pull request #142 from alejandroarturom/torlock-fixes
[common] Fixes Torlock Search/[common] Fixes Torlock Search/"
Frostwire,"[android] removed strange/unused DnD debug tracker/Merge pull request #139 from grzesiekrzaca/moving_playlist_double_list_modification_iside_a_critical_section
[android] issue #116 repositioning songs in playlist - new branch/Everyting was ""ok"" in the View. The problem lay with no listener that would change the adapter (and data in system). Problem with the adapter is that it uses a copy of the data other than the one in ArryAdaper (why? 0.o) so that copy also has to be updated./"
Frostwire,[android] removed strange/unused DnD debug tracker/
Frostwire,[android] removed strange/unused DnD debug tracker/[android] crash fix on ApolloFragment::restartLoader/[android] Fixes #145. Formatting./
Frostwire,[android] Fixes #145. Formatting./
Frostwire,[android] removed strange/unused DnD debug tracker/
Frostwire,"[android] fixed missing remote control update logic path/[android] avoid NPE/[android] avoid NPE if user tries to play before audio service can be obtained./[android] reverted ""true"" argument in stop playback, notification was not working properly/[android] NPE fix reported in console/[android] try to stop and dismiss music faster. avoid issue of music that stopped coming back on next session./[android] fixing conflicts./[android] Using last service id for stopSelf in MusicPlaybackService/"
Frostwire,[android] removed strange/unused DnD debug tracker/
Frostwire,[android] PREF_KEY_GUI_SUPPORT_FROSTWIRE wasn't fixed all the way/
Frostwire,[android] prevents a failed display of a currently showing applovin ad/
Frostwire,[android] NPE fix when no external drives can't be found/[android] fixing conflicts./
Frostwire,"[android] NPE fix reported in console/[android] Multiple fixes.
- Respects ""Show Transfers"" preference for cloud downloads.
- https:// based torrents search results work again.
- Shows a toast to appeace user in case torrent fetching takes a while when a torrent search result is clicked./"
Frostwire,"[android] Avoid IndexOutOfBoundsException on BrowsePeerFragment.onLoadFinished()
If the BrowsePeerFragment manager *for some reason* returns a null list or an
empty list for a given file type, the FileListAdapter's visualList will have
0 elements.
When AbstractListAdapter.getItem() is triggered it crashes with an IndexOutOfBoundsException.
This might be happening between refreshes, as getItem() is often seen asking high indices
when the underlying visualList has 0 elements./[android] Fixes #149/"
Frostwire,[android] fixing conflicts./
Frostwire,[android] avoid accidental swipe gesture when scrolling down with thumb./
Frostwire,"[android] turned off ui-debug flag./[android] Multiple fixes.
- Respects ""Show Transfers"" preference for cloud downloads.
- https:// based torrents search results work again.
- Shows a toast to appeace user in case torrent fetching takes a while when a torrent search result is clicked./"
Frostwire,[android] fixes bug where torrent download dialog would keep coming back./
Frostwire,"[android] bug fix on dialog that wouldn't dismiss/[android] Fixes issue where seeding dialog wasn't dismissed on OK/[android] avoid crash when trying to seed a non existent file descriptor, fixes #162/[android] crash reported in console/[android] Since BTEngine#download is asynchronous, this findTorrent and successive torrent handle calls were causing memory issues inside libtorrent/[android] broken build/"
Frostwire,[android] Fixes #145. Formatting./
Frostwire,"[android] Closes #107, more descriptive error on Connection timed out for cloud transfers./[android] fixing conflicts./"
Frostwire,[android] IllegalStageException reported in console/
Frostwire,[android] Fixed YesNoDialog/
Frostwire,"[android] Fixes issue #134, torrent picker sorting./"
Frostwire,"[android] Fixes bug where app wouldn't shutdown.
The isShutdown() method was always failing because it used `getIntent()`.
Added a parameter to it and invoked it on the `MainActivity.onNewIntent()`
method.
My belief is that this bug surfaced when the MainActivity was converted
to `launchMode=singleTask` https://github.com/frostwire/frostwire/commit/b2e211954450f128af553ca5a88ef158081c83d8#diff-9832a7bd42037dd9b6595bb2c5eea58bR63
When new Intents were fired on it, it wouldn't call `onCreate()`, it would go straight to
`onResume()`, and even though I also tried putting the logic to check the intent there,
it wouldn't work because it would be working with the original intent, not the one that
was just sent./[android] fixed issue of onNewIntent with second open/[android] better handling of action view intent (minor issue left with second open)/[android] fixes bug where torrent download dialog would keep coming back./[android] fixed refresh of player notifier, build 263/[android] Fixed logic for SD permission check from MainActivity/[android] fixing conflicts./[android] Flush ux stats as early as possible during the shutdown situation (not a problem is user cancel)/"
Frostwire,"[android] Don't crash on illegal state
Looks like this is being called twice, or there's a timing bug. Don't choke on this
as it probably happened already.
java.lang.IllegalStateException: Can not perform this action after onSaveInstanceState
at android.app.FragmentManagerImpl.checkStateLoss(FragmentManager.java:1280)
at android.app.FragmentManagerImpl.popBackStackImmediate(FragmentManager.java:451)
at android.app.Activity.onBackPressed(Activity.java:2153)
at com.frostwire.android.gui.activities.VPNStatusDetailActivity.onBackPressed(VPNStatusDetailActivity.java:159)/"
Frostwire,"[android] fixed refresh of player notifier, build 263/"
Frostwire,[android] Fixes NumberPickerPreference./
Frostwire,[android] fixing conflicts./
Frostwire,[android] Fixes #145. Formatting./[android] fixing conflicts./
Frostwire,[android] NPE on IabHelper./
Frostwire,[desktop] verbose error output in case a binary can't be loaded (does not include jlibtorrent)/
Frostwire,[desktop] verbose error output in case a binary can't be loaded (does not include jlibtorrent)/
Frostwire,[common/desktop] should fix issues with FW not opening '.TORRENT' files/
Frostwire,[common/desktop] should fix issues with FW not opening '.TORRENT' files/
Frostwire,[desktop] verbose error output in case a binary can't be loaded (does not include jlibtorrent)/
Frostwire,[desktop] make sure the media player share button is hidden when playback stops/
Frostwire,[desktop] verbose error output in case a binary can't be loaded (does not include jlibtorrent)/
Frostwire,[desktop] extension check fix on MacEventHandler/
Frostwire,[desktop] get TransfersTab reference from MainFrame to avoid casting issues/[desktop] fixes bug where transfers wouldn't be shown upon a download starting./
Frostwire,[common/desktop] should fix issues with FW not opening '.TORRENT' files/
Frostwire,[common/desktop] should fix issues with FW not opening '.TORRENT' files/
Frostwire,[desktop] verbose error output in case a binary can't be loaded (does not include jlibtorrent)/
Frostwire,"[common] using new jlibtorrent API for load settings (fix log setting)/[common] improved error log in BTEngine/[common/desktop] should fix issues with FW not opening '.TORRENT' files/[android] avoid ArrayIndexOutOfBoundsException/[common] NPE on BTEngine.download, priorities can be null/"
Frostwire,[common] fixed getProgress calculation/[common] avoid possible NPE/
Frostwire,[common] Bitsnoop/torcache/magnet fix/
Frostwire,"[common] removed excess logging, it can hangs the app (specially in Windows)/"
Frostwire,"[common] removed excess logging, it can hangs the app (specially in Windows)/[common] Bitsnoop/torcache/magnet fix/"
Frostwire,"Merge pull request #186 from alejandroarturom/monova-fixed-20160609
[Common] Fixed Monova Search Results/[Common] Fixed Monova Search Results/"
Frostwire,"[android] More edge cases and better shutdown.
- MusicUtils.mService renamed to MusicUtils.musicPlaybackServices
- Fixed log entry on Offers.dismissAndOrShutdownIfNecessary
- Cleanup/"
Frostwire,"[android] More edge cases and better shutdown.
- MusicUtils.mService renamed to MusicUtils.musicPlaybackServices
- Fixed log entry on Offers.dismissAndOrShutdownIfNecessary
- Cleanup/"
Frostwire,"[android] More edge cases and better shutdown.
- MusicUtils.mService renamed to MusicUtils.musicPlaybackServices
- Fixed log entry on Offers.dismissAndOrShutdownIfNecessary
- Cleanup/"
Frostwire,"[android] More edge cases and better shutdown.
- MusicUtils.mService renamed to MusicUtils.musicPlaybackServices
- Fixed log entry on Offers.dismissAndOrShutdownIfNecessary
- Cleanup/"
Frostwire,[android] NPE fix on DragSortListView.measureItemAndGetHeights()/
Frostwire,"[android] fix crash on MusicPlaybackService.getQueue() when the playlist is null, import cleanup/[android] don't crash if you can't register the apollo remote control client/[android] fixes premature music service stop during music playback, refactor, much better shutdown./[android] More edge cases and better shutdown.
- MusicUtils.mService renamed to MusicUtils.musicPlaybackServices
- Fixed log entry on Offers.dismissAndOrShutdownIfNecessary
- Cleanup/[android] Fixes auto-restarting on exit issue.
the issue was MusicPlaybackService's shutdown logic.
The way this service shuts itself down is by receiving a delayed PendingIntent (this is a way to start a service at a later time even if the app isn't running) via Android's AlarmManager. This shutdown was being scheduled in 60 seconds.
If the service is started normally with Context.startService() it's onStartCommand() method returns START_STICKY, but if it's started with the special SHUTDOWN command, it checks if there's anything playing, and if it's not playing, it releases everything and returns START_NOT_STICKY./[android] test, don't go to idle when stopping.
seems to stop faster and finish the audio player activity faster this way. Trying to understand why the player keeps coming back even after we've stopped it completely, might be something else entirely that brings the last song back. Trying to see if this is what's making the app restart by itself, perhaps it's not the player, perhaps it's the new MobFox network that keeps something in the background./"
Frostwire,"[android] finish or shutdown on dismiss DRY refactor
- All ad networks reuse logic to handle dismiss or shutdown, fixing possible
case where app wouldn't be shutdown on one of the networks.
- Future proofing improvement on Offers.getActiveNetworks() for
new network codes or configuration typos./"
Frostwire,"[android] finish or shutdown on dismiss DRY refactor
- All ad networks reuse logic to handle dismiss or shutdown, fixing possible
case where app wouldn't be shutdown on one of the networks.
- Future proofing improvement on Offers.getActiveNetworks() for
new network codes or configuration typos./"
Frostwire,"[android] finish or shutdown on dismiss DRY refactor
- All ad networks reuse logic to handle dismiss or shutdown, fixing possible
case where app wouldn't be shutdown on one of the networks.
- Future proofing improvement on Offers.getActiveNetworks() for
new network codes or configuration typos./"
Frostwire,[android] don't crash when priority selection doesn't match number of files (seen on build 299)/
Frostwire,"[android] mobfox hack not needed, issue fixed by mobfox/[android] avoid double finish/[android] finish or shutdown on dismiss DRY refactor
- All ad networks reuse logic to handle dismiss or shutdown, fixing possible
case where app wouldn't be shutdown on one of the networks.
- Future proofing improvement on Offers.getActiveNetworks() for
new network codes or configuration typos./"
Frostwire,"[android] remove finishAffinity() call, causing crashes./[android] fixes premature music service stop during music playback, refactor, much better shutdown./[android] More edge cases and better shutdown.
- MusicUtils.mService renamed to MusicUtils.musicPlaybackServices
- Fixed log entry on Offers.dismissAndOrShutdownIfNecessary
- Cleanup/[android] Fixes auto-restarting on exit issue.
the issue was MusicPlaybackService's shutdown logic.
The way this service shuts itself down is by receiving a delayed PendingIntent (this is a way to start a service at a later time even if the app isn't running) via Android's AlarmManager. This shutdown was being scheduled in 60 seconds.
If the service is started normally with Context.startService() it's onStartCommand() method returns START_STICKY, but if it's started with the special SHUTDOWN command, it checks if there's anything playing, and if it's not playing, it releases everything and returns START_NOT_STICKY./[android] NPE fix MainActivity.onOptionsItemSelected, round 2./[android] NPE opening drawer too quickly
java.lang.IllegalArgumentException: No drawer view found with gravity LEFT
at android.support.v4.widget.DrawerLayout.openDrawer(DrawerLayout.java:1618)
at android.support.v4.app.ActionBarDrawerToggle.onOptionsItemSelected(ActionBarDrawerToggle.java:409)
at com.frostwire.android.gui.activities.MainActivity.onOptionsItemSelected(MainActivity.java:804)/[android] few more conditions. naming refactor to avoid confusions/"
Frostwire,"[android] fixes premature music service stop during music playback, refactor, much better shutdown./[android] More edge cases and better shutdown.
- MusicUtils.mService renamed to MusicUtils.musicPlaybackServices
- Fixed log entry on Offers.dismissAndOrShutdownIfNecessary
- Cleanup/[android] Fixes auto-restarting on exit issue.
the issue was MusicPlaybackService's shutdown logic.
The way this service shuts itself down is by receiving a delayed PendingIntent (this is a way to start a service at a later time even if the app isn't running) via Android's AlarmManager. This shutdown was being scheduled in 60 seconds.
If the service is started normally with Context.startService() it's onStartCommand() method returns START_STICKY, but if it's started with the special SHUTDOWN command, it checks if there's anything playing, and if it's not playing, it releases everything and returns START_NOT_STICKY./"
Frostwire,"[desktop] playlist handling bug fixes
- bugfix: dragging starred track from some playlist onto another playlist would unmark track as starred
- bugfix: dragging starred track from starred woudl remove from starred
- accepts drops on starred/"
Frostwire,"[desktop] playlist handling bug fixes
- bugfix: dragging starred track from some playlist onto another playlist would unmark track as starred
- bugfix: dragging starred track from starred woudl remove from starred
- accepts drops on starred/"
Frostwire,"[desktop] playlist handling bug fixes
- bugfix: dragging starred track from some playlist onto another playlist would unmark track as starred
- bugfix: dragging starred track from starred woudl remove from starred
- accepts drops on starred/"
Frostwire,[DESKTOP-182] Avoiding Starred playlist to be deleted or renamed/
Frostwire,"[desktop] playlist handling bug fixes
- bugfix: dragging starred track from some playlist onto another playlist would unmark track as starred
- bugfix: dragging starred track from starred woudl remove from starred
- accepts drops on starred/"
Frostwire,[desktop/issue #329] New: 'All Free Downloads' button/
Frostwire,[common] fixed YT regex/
Frostwire,[common] fixed limetorrents details regex/
Frostwire,[common] fixed SC search/
Frostwire,[common] fixed monova engine using the http torrent url/[common] added unit test for monova and partial fix to search (still not working)/
Frostwire,[common] fix warnings in mp4 Box class/
Frostwire,[android] mute clicks on fake spacer header item in lists in ArtistAlbumFragment to avoid NPE (#269)/
Frostwire,"[android] fixed purchase cancelled bug, more testing needed/[android] MoPub progress
- Added close ad button and handling logic.
- Does not load the ad if user disabled ads.
- NPE onDestroy fixed.
- Refactor on AudioPlayerActivity::PlaybackStatus
- Avoid temporary crashes while the landscape mode isn't finished./[android] gotta fix logic to show or not. listener working/"
Frostwire,"Merge pull request #235 from gubatron/issue225_ringtone_playback_enchancement
[android] Issues with ringtone playback (#225, #226, #233)/[android]
Allow simple playback of ringtones without adversly affecting the user's
current playback
and
incidental stop/play status fix for file lists (affects both ringtone and music playback):
-If something is playing and a ringtone is to be played the current played
music will be paused
-If a ringtone is playing and music playback is resumed/started then the
ringtone will be stopped
-Only one ringtone can be played at the same time. Starting new playback
will stop the old one.
-Clicking a ringtone that is being played will stop the playback
-Navigating out of the fragment or changing the tab carusel will stop playback of a ringtone. (User can no longer see the stop button, so it's stopped for him)/"
Frostwire,"[android] Fixing tab carousel height calculations. Removing unused
carousel shadow references #236/"
Frostwire,"[android] InMobi/Offers maintenance after 0 impressions from InMobi
- Moved InMobi constant to InMobiAdNetwork
- UIUtils.inUIThread() new convenience method
- InMobi checks/flags to avoid double interstitial loading
- Offer checks to avoid too rapid network re-initialization
- Raised InMobi reload period from 20secs to 60secs
- InMobiInterstitialListener now implements InMobiInterstitial.InterstitialAdListener2, as InMobiInterstitial.InterstitialAdListener is now deprecated and will be phased out soon
- InMobi InterstitialReloader avoids double interstitial loading
- It seems InMobi changed account parameters, everything should be working but error says to contact partner. I believe there was a conflict between MoPub and InMobi and that's why we were getting the double loading of InMobi interstitials, most likely will remove InMobi manual integration next (while leaving the libraries for MoPub to use)/[android] no more broadcast receiver leaks, improved abstractions, brainfart refactors/"
Frostwire,"[android] InMobi/Offers maintenance after 0 impressions from InMobi
- Moved InMobi constant to InMobiAdNetwork
- UIUtils.inUIThread() new convenience method
- InMobi checks/flags to avoid double interstitial loading
- Offer checks to avoid too rapid network re-initialization
- Raised InMobi reload period from 20secs to 60secs
- InMobiInterstitialListener now implements InMobiInterstitial.InterstitialAdListener2, as InMobiInterstitial.InterstitialAdListener is now deprecated and will be phased out soon
- InMobi InterstitialReloader avoids double interstitial loading
- It seems InMobi changed account parameters, everything should be working but error says to contact partner. I believe there was a conflict between MoPub and InMobi and that's why we were getting the double loading of InMobi interstitials, most likely will remove InMobi manual integration next (while leaving the libraries for MoPub to use)/"
Frostwire,"[android] no more broadcast receiver leaks, improved abstractions, brainfart refactors/[android] WIP, AdNetworks abstraction refactor, starting, stopping and all common logic moved up to new AbstractAdNetwork/"
Frostwire,"[android] no more broadcast receiver leaks, improved abstractions, brainfart refactors/"
Frostwire,"[android] InMobi/Offers maintenance after 0 impressions from InMobi
- Moved InMobi constant to InMobiAdNetwork
- UIUtils.inUIThread() new convenience method
- InMobi checks/flags to avoid double interstitial loading
- Offer checks to avoid too rapid network re-initialization
- Raised InMobi reload period from 20secs to 60secs
- InMobiInterstitialListener now implements InMobiInterstitial.InterstitialAdListener2, as InMobiInterstitial.InterstitialAdListener is now deprecated and will be phased out soon
- InMobi InterstitialReloader avoids double interstitial loading
- It seems InMobi changed account parameters, everything should be working but error says to contact partner. I believe there was a conflict between MoPub and InMobi and that's why we were getting the double loading of InMobi interstitials, most likely will remove InMobi manual integration next (while leaving the libraries for MoPub to use)/[android] multiple fixes with promo views/adapter
- makes sure 'remove ads' offer isn't shown if user removed ads
- ads touch to 'frostwire features' black background title view
- refactors
- WIP: crashing for some reason on plus build/[android] no more broadcast receiver leaks, improved abstractions, brainfart refactors/[android] WIP, AdNetworks abstraction refactor, starting, stopping and all common logic moved up to new AbstractAdNetwork/[android] gotta fix logic to show or not. listener working/"
Frostwire,"[android] bug fix, clean any handwritten filters before submitting search/[android] bugfix/[android] fixes glitch on scroll detection/[android] better scroll change direction detection, avoids false positives./[android] multiple fixes with promo views/adapter
- makes sure 'remove ads' offer isn't shown if user removed ads
- ads touch to 'frostwire features' black background title view
- refactors
- WIP: crashing for some reason on plus build/[android] no special offers in horizontal mode. fix number of slides when in landscape mode to always have an even number/"
Frostwire,"Merge pull request #292 from gubatron/small_file_list_bugs
[android/#285] Small file list bugs - RELOADED/[android] fix list refresh/Merge pull request #235 from gubatron/issue225_ringtone_playback_enchancement
[android] Issues with ringtone playback (#225, #226, #233)/[android]
Allow simple playback of ringtones without adversly affecting the user's
current playback
and
incidental stop/play status fix for file lists (affects both ringtone and music playback):
-If something is playing and a ringtone is to be played the current played
music will be paused
-If a ringtone is playing and music playback is resumed/started then the
ringtone will be stopped
-Only one ringtone can be played at the same time. Starting new playback
will stop the old one.
-Clicking a ringtone that is being played will stop the playback
-Navigating out of the fragment or changing the tab carusel will stop playback of a ringtone. (User can no longer see the stop button, so it's stopped for him)/[android] Fix for ringtone item selection and context menu
-disabled the ability to check multiple ringtones by hiding the checkboxes
-when there are no items for the context menu don't show it
-ringtone menu ignores other checked files (always can play and set as
ringtone)/"
Frostwire,"[android] feature/mobile data protection fix (#338)
* [android] check if torrents should be resumed when on mobile data and mobile data saving is on
* [android] seeding while on mobile data saving and no wifi/"
Frostwire,"[android] feature/mobile data protection fix (#338)
* [android] check if torrents should be resumed when on mobile data and mobile data saving is on
* [android] seeding while on mobile data saving and no wifi/"
Frostwire,[android/crash] fixes index out of bounds crash/
Frostwire,"[android] multiple fixes with promo views/adapter
- makes sure 'remove ads' offer isn't shown if user removed ads
- ads touch to 'frostwire features' black background title view
- refactors
- WIP: crashing for some reason on plus build/[android] fixed purchase cancelled bug, more testing needed/[android] avoids invalid argument issue on startActivityForResult()/"
Frostwire,"[android] no more broadcast receiver leaks, improved abstractions, brainfart refactors/"
Frostwire,Wizard activity material update fix (#305)/
Frostwire,Wizard activity material update fix (#305)/
Frostwire,"Merge pull request #235 from gubatron/issue225_ringtone_playback_enchancement
[android] Issues with ringtone playback (#225, #226, #233)/[android]
Allow simple playback of ringtones without adversly affecting the user's
current playback
and
incidental stop/play status fix for file lists (affects both ringtone and music playback):
-If something is playing and a ringtone is to be played the current played
music will be paused
-If a ringtone is playing and music playback is resumed/started then the
ringtone will be stopped
-Only one ringtone can be played at the same time. Starting new playback
will stop the old one.
-Clicking a ringtone that is being played will stop the playback
-Navigating out of the fragment or changing the tab carusel will stop playback of a ringtone. (User can no longer see the stop button, so it's stopped for him)/[android] Fix for ringtone item selection and context menu
-disabled the ability to check multiple ringtones by hiding the checkboxes
-when there are no items for the context menu don't show it
-ringtone menu ignores other checked files (always can play and set as
ringtone)/"
Frostwire,"[android] New FWSeekbarPreference replaces NumberPicker2.
Much better, natural experience.
- new styleables for FWSeekbarPreference.
- renamed styleable numberpicker to fwPickerPreference
- got rid of styeleables used by NumberPicker2, unused.
- removed NumberPickerPreferenceDialog.java, NumberPickerPreference2.java
- Now that the preference can be configured in XML, the setupNumericalPreference (renamed to setupFWSeekbarPreference)
API is simplified enourmously, easier to maintain.
- NumberPickerPreference (old) fetching of its custom styleables refactoed after styleable rename
Pending:
- Need help figuring out why app crashes when rotated the second time around when the preference dialog is shown.
It seems it has something to do with setting target fragments correctly. Issue might be rooted in parent class
AbstractPreferenceFragment.PreferenceDialogFragment/"
Frostwire,[android] avoid NPE on SwipeLayout::dispatchTouchEvent. build 327/
Frostwire,"Merge pull request #235 from gubatron/issue225_ringtone_playback_enchancement
[android] Issues with ringtone playback (#225, #226, #233)/[android]
Allow simple playback of ringtones without adversly affecting the user's
current playback
and
incidental stop/play status fix for file lists (affects both ringtone and music playback):
-If something is playing and a ringtone is to be played the current played
music will be paused
-If a ringtone is playing and music playback is resumed/started then the
ringtone will be stopped
-Only one ringtone can be played at the same time. Starting new playback
will stop the old one.
-Clicking a ringtone that is being played will stop the playback
-Navigating out of the fragment or changing the tab carusel will stop playback of a ringtone. (User can no longer see the stop button, so it's stopped for him)/[android] Fix for ringtone item selection and context menu
-disabled the ability to check multiple ringtones by hiding the checkboxes
-when there are no items for the context menu don't show it
-ringtone menu ignores other checked files (always can play and set as
ringtone)/"
Frostwire,[desktop] fixes issue with transfer text filter/
Frostwire,[desktop] cleanup unthrown exceptions/
Frostwire,"[all] fixes logic bug in update manager that made wrong (old) update message show instead of the one with the bullets/[android] do not stop btEngine, the app never assumes btEngine is stopped./"
Frostwire,[desktop] cleanup unthrown exceptions/
Frostwire,[desktop] cleanup unthrown exceptions/
Frostwire,[desktop] cleanup unthrown exceptions/
Frostwire,"[desktop] cleanup unthrown exceptions/[android] do not stop btEngine, the app never assumes btEngine is stopped./"
Frostwire,"Fixes broken link on Language change (#398)
This is a minor issue when trying to change the Language from the 'flag' icon at the bottom bar, the Language-Window has a link 'Help to translate FrostWire' that was pointing the old frostwire-desktop repo. I didn't open an issue because is a tiny thing./"
Frostwire,[common] set stop_tracker_timeout to 0 to supress trackers communications during shutdown/[common] reset libtorrent state when in presence of ABI issues/[common] fixed issue that some settings wasn't applied in BTEngine/
Frostwire,[common] fixed old issue of ThreadPool not using LinkedBlockingQueue/
Frostwire,[common] fixed YT player regex/[common] fixed YT/
Frostwire,[common] YT first pass regex fix/
Frostwire,[common] fix SC/
Frostwire,[common] TorLock search fixed/
Frostwire,"[common] Monova fixed.
- Monova no longer provides seeds. Since seeds tend to be always out of date, I've provided a random number between 50 and 100.
- Monova no longer provides .torrent urls, we'll have to settle for magnet uris only/"
Frostwire,"[android] refactor to avoid one more type/[android] avoid mixing v4 and native fragments, fix player orientation issue/[android] Enable icon display in toolbar's overflow menu
This is a refactor of a reflection hack @marcelinkaaa found as a solution.
See https://github.com/marcelinkaaa/frostwire/commit/adfa17c01b2d329c52f0d834f301d62b2e09637d (never merged)/"
Frostwire,"[android] avoid mixing v4 and native fragments, fix player orientation issue/"
Frostwire,"[android] refactor to avoid one more type/[android] Enable icon display in toolbar's overflow menu
This is a refactor of a reflection hack @marcelinkaaa found as a solution.
See https://github.com/marcelinkaaa/frostwire/commit/adfa17c01b2d329c52f0d834f301d62b2e09637d (never merged)/"
Frostwire,"[android] refactor to avoid one more type/[android] Enable icon display in toolbar's overflow menu
This is a refactor of a reflection hack @marcelinkaaa found as a solution.
See https://github.com/marcelinkaaa/frostwire/commit/adfa17c01b2d329c52f0d834f301d62b2e09637d (never merged)/[android] fixed title header bug and NPE/"
Frostwire,"[android] avoid mixing v4 and native fragments, fix player orientation issue/"
Frostwire,[android] fixed title header bug and NPE/
Frostwire,"[android] avoid broadcast receiver leak, ogury fixes./"
Frostwire,"[android] don't crash if mopub couldn't load interstitial.
It may happen that MoPub's network request queue can't be started because context.getCacheDir() might return
null at the time of the call.
See
https://github.com/mopub/mopub-android-sdk/blame/master/mopub-sdk/mopub-sdk-base/src/main/java/com/mopub/network/Networking.java#L65/"
Frostwire,[android] GridView for My Files Images and Audio (Issue #228)/
Frostwire,"[android] fixed myfiles title issue, removed warnings inflating headers/"
Frostwire,"[android] fixed myfiles title issue, removed warnings inflating headers/[android] commented code fix. renamed settings_search.xml -> settings_search_engines.xml/[android] NPE on SearchFragment scroll events fixed, refactor/"
Frostwire,"[android] GridView for My Files Images and Audio (Issue #228)/[android] fixed logic of selection check box with bias towards select all/[android] MyFiles new action toolbar on selection mode (#413)
- Brings out action mode on long press
- styled ActionMode toolbar
- Handles visibility of menu action depending on different factors like, number of files checked, file type, SAF
- Bug fix: When seeding was only enabled for WiFi, the file would still be added to transfers in Finished state.
Now it doesn't add the file and it stays in the same screen as it was originally./[android] fixes UI when deleting files in selection mode (#406)/[android] fixed myfiles title issue, removed warnings inflating headers/"
Frostwire,"[android] UIUtils.openFile(..., boolean useFileProvider)
To solve issue of FrostWire not knowing how to handle its own .apk update.
Works on Android 7.0, need to test on Android 4.0, 5.0 and 6.0/"
Frostwire,"[android] change of 3g/4g option to wifi only option  (#344)
minor fix in AbstractActivity/"
Frostwire,"[android] MyFiles new action toolbar on selection mode (#413)
- Brings out action mode on long press
- styled ActionMode toolbar
- Handles visibility of menu action depending on different factors like, number of files checked, file type, SAF
- Bug fix: When seeding was only enabled for WiFi, the file would still be added to transfers in Finished state.
Now it doesn't add the file and it stays in the same screen as it was originally./"
Frostwire,"[android] change of 3g/4g option to wifi only option  (#344)
minor fix in AbstractActivity/"
Frostwire,[android] commented code fix. renamed settings_search.xml -> settings_search_engines.xml/
Frostwire,[android] GridView for My Files Images and Audio (Issue #228)/
Frostwire,[android] avoids possibility of getting stuck on Buy screen/
Frostwire,"Player minimized (#392)
* [android] adjusted the player notifier layout
* [android] PlayerNotificationView and layout cleanup
* [android] rename refactor -> PlayerNotifier -> MiniPlayer
* [android] miniplayer controls plugged
* [android] fixed miniPlayer layout
* [android] miniplayer cover art logic
* [android] miniplayer single line titles, ellipsis/[android] better control of toolbar custom view gravity and fixed visibility issue/"
Frostwire,[android] Fixes Broadcast receiver leaked error on PreviewActivity/[android] move destroy view to onPause() is more effective at avoiding Intent receiver leak/
Frostwire,"Player minimized (#392)
* [android] adjusted the player notifier layout
* [android] PlayerNotificationView and layout cleanup
* [android] rename refactor -> PlayerNotifier -> MiniPlayer
* [android] miniplayer controls plugged
* [android] fixed miniPlayer layout
* [android] miniplayer cover art logic
* [android] miniplayer single line titles, ellipsis/"
Frostwire,[android] refactor in GeneralWizardPage and minor string translation fix/
Frostwire,[android] GridView for My Files Images and Audio (Issue #228)/
Frostwire,"Player minimized (#392)
* [android] adjusted the player notifier layout
* [android] PlayerNotificationView and layout cleanup
* [android] rename refactor -> PlayerNotifier -> MiniPlayer
* [android] miniplayer controls plugged
* [android] fixed miniPlayer layout
* [android] miniplayer cover art logic
* [android] miniplayer single line titles, ellipsis/"
Frostwire,[android] debug output shutting down/
Frostwire,[desktop] solve issue with Cmd+A not working unless clicking twice on playlist row/[desktop] avoid UI thread violation/
Frostwire,"[desktop] no need of temporary lastClickedActionsHolder, it wasn't working anyway, there is an issue in isActiveTorrentDownload/[desktop] since add torrent is async, it's to early to find it right after makeTorrentAndDownload, avoid NPE/"
Frostwire,[common] avoid re-download of torrent is already complete/
Frostwire,[common] fixed issue of thread pool for fixed maximum pool size/
Frostwire,[common] fix getting player id/
Frostwire,[common] fixed TorLock/
Frostwire,[common] fixed Monova/
Frostwire,[android] avoid crash getting LoaderManager when Fragment still not attached to Activity/
Frostwire,[android] avoid crash getting LoaderManager when Fragment still not attached to Activity/
Frostwire,"[android] fixes bug what crashed the app on deleting Last added playlist (#485)
There was an issue with positioning of the playlists, and in consequence the delete option was now available on Last Added playlist. And it should not be available. In consequence deleting it crashed the app./Apollo playlist ui update (#481)
* [android] set up for updated UI in playlist tab
* [android] added new empty playlist functionality to the playlist tab on apollo
* [android] added padding to TabLayout and increased size of Toolbar text
* [android] deleted unused imports
* [android] fixed double rendering bug on playlist adapter, refactor/"
Frostwire,[android] NPE on apollo ShortcutActivity.onServiceConnected()/
Frostwire,[android/apollo] don't crash if you can't show photo selection dialog due to illegal state exception/[android] NPE on ProfileActivity.onActivityResult/
Frostwire,[android] rare NPE on BaseActivity/
Frostwire,[android] don't fail in the AsyncTask during ImageCache#initDiskCache/
Frostwire,[android] TODO comment about crash in NotificationHelper#buildNotification/
Frostwire,"[android] avoid ANR adding to recently played/[android] avoid possible ANR by android.app.AlarmManager.cancel()/[android] NPE on MusicPlaybackService/[android] anti-ANR MusicPlaybackService refactors
Addresses tickets #532 and #533.
Operations like .openXXX() and .duration() may take a long time and cause
ANRs if invoked in the main thread. The code has been refactored to use callbacks
to the main thread and avoid the numerous ANR reports we've been getting in the google play console
Also fixes a possible NPE on ensurePlayListCapacity/[android] possible NPE on a fast start and shutdown averted/[android] attempt to recover from IllegalStateException in MusicPlaybackService#getAlbumId/[android] mitigating another NPE in MusicPlaybackService#onDestroy (documented the possible reason of mShutdownIntent being null)/[android] mitigating another NPE in MusicPlaybackService#scheduleDelayedShutdown due to excessive (and bad) use of mutable state in player/[android] log StaleDataException error and return false in MusicPlaybackService#openFile/[android] log UnsupportedOperationException error and return false in MusicPlaybackService#openFile/[android] revert ingored exception catch/[android] MusicPlaybackService possible Runtime Exception submitting task/[android] fixed NPE in releaseServiceUiAndStop/[android] avoid ArrayIndexOutOfBoundsException at runtime in reloadQueue/[android] fixed issue if visible mini player when existing the app/[android] avoid ANR, dont lock whole service object to get audioSessionId/[android] possible NPE on RemoteControlClient::MetadataEditor.apply()/"
Frostwire,"[android] one more context leak check in ImageLoader/[android] one more potential context leak fixed/[android] avoid taking closure via anonymous class to the thread pool/[android] avoid context leak in ImageViewerFragment, improved Debug#hasContext/[android] avoid leaking Picasso types in our API/[android] added Debug utility class with context leak detection/[android] necessary to use picasso 3.0.0-SNAPSHOT because of the head marker issue, using uri from MediaStore instead of internal one/[android] avoid use of picasso fit() since it delays the actual bitmap request until the image view bounds are calculated/[android] removed ImageLoader priority argument. It leaks picasso API, it does nothing if not using the internal picasso thread pool and it's only useful in situations like an image stream feed, for which picasso is not good as a whole/[android] ImageViewer simplifications. ImageLoader DEBUG_ERRORS flag/[android] fixes bug loading high res images/[android] ImageViewer fragment (#437)
* [android] ImageViewer activity, Video/Pic grid improvements
* [android] Fixes selection mode issues on grids, Media Overlay View, Pinch and Zoom
* [android] ads metadata to image viewer fragment
* [android] set wallpaper action non-blocking
* [android] ImageLoader asyncload wraps fetch() to use Picasso's background threads
* [android] New FileInformation action shows file information dialog
* [android] add preview screen listener
* [android] Cleanup and bug fixes.
Fixes bug on ImageViewerFragment where after renaming an image and rotating
the screen, the window title would revert to the original file name.
Cleanup, license headers./"
Frostwire,"[android] Fixes issue where My Files SearchView was being hidden right after being shown.
The culprit was a runnable sent from the ToolbarActionBar which would invoke populateOptionsMenu. This runnable was sent whenever the activity's invalidateOptionsMenu() method was called. After a search, the TransfersFragment.onTime() method was found to have a periodic call to invalidateOptionsMenu() from a recent fix on the transfer's menu. The fix was making sure such invalidation only happened when the TransfersFragment was visible. 14 characters.  The rest of the code changes had to do with a hard coded string and tighter checks on when to perform the filtering/[android] fix of menu logic in TransfersFragment/"
Frostwire,"[android] Fixes rotation applied filters bug, thanks @marcelinkaaa. Build 423/[android] bug fix, filter drawer could be dragged from any other view or when no search was available/[android] 2 bugfixes in keyword suggestions
- One endless loop that was only twarted by throttling, thanks @aldenml
- Keyword Detector wasn't being reset when filters were applied/[android] avoid NPE on rotations if fragments still not attached/[android] bug fix on filtered results. more on keywordtagview event handling
there is still a bug when trying to change inclusion mode for a second tag, works fine with the first one only/[android] fixes issue with filter button dissapearing/[android] fixed null pointer error due to incorrect call of requestHistogramUpdateAsync on MANUAL_ENTRY feature/[android] improved documentation of last NPE fix/[android] best effort to avoid NPE due to ill timed call of showSearchView in onResume (temporary fix until refactor is done)/[android] KeywordDetector simplifications, cpu savings, animation stops when filter button clicked/[common/android] using List for histogram, better API and avoid extra memory creation/[android] Avoid any possible Context leaks when submitting results to KeywordDetector/[android] Fixes search media type tab selection bug
Upon a first search, the adapter would filter results by the last searche's media type however the UI's tab wouldn't be selected, also on rotation it would not remember the last tab selected and if you had previously selected a file type that didn't match your search you'd think there was something wrong as you'd see wrong file types in your search results or nothing at all and you'd see the audio tab selected with the search result counter > 0/"
Frostwire,"[android] refactored hideCheckBoxMenuItem
Fixed possible null pointer.
Make sure the last selected file type is considered, ringtones are not checkable since they cannot be deleted/[android] Avoid IllegalStateException, don't getResources() unless fragment attached/[android] avoid NPE on rotations if fragments still not attached/[android] avoid illegal state exception updating header on browse peer fragment/[android] avoid crash getting LoaderManager when Fragment still not attached to Activity/[android] filtering bug fix/[android] Fixes issue where My Files SearchView was being hidden right after being shown.
The culprit was a runnable sent from the ToolbarActionBar which would invoke populateOptionsMenu. This runnable was sent whenever the activity's invalidateOptionsMenu() method was called. After a search, the TransfersFragment.onTime() method was found to have a periodic call to invalidateOptionsMenu() from a recent fix on the transfer's menu. The fix was making sure such invalidation only happened when the TransfersFragment was visible. 14 characters.  The rest of the code changes had to do with a hard coded string and tighter checks on when to perform the filtering/[android] avert crash on RejectedExecutionException/[android] ringtone/audio playback from menu issue fixed/[android] select/deselect all autocheck/uncheck bug fix/[android] fixes last tab selected issue on rotate/[android] ImageViewer fragment (#437)
* [android] ImageViewer activity, Video/Pic grid improvements
* [android] Fixes selection mode issues on grids, Media Overlay View, Pinch and Zoom
* [android] ads metadata to image viewer fragment
* [android] set wallpaper action non-blocking
* [android] ImageLoader asyncload wraps fetch() to use Picasso's background threads
* [android] New FileInformation action shows file information dialog
* [android] add preview screen listener
* [android] Cleanup and bug fixes.
Fixes bug on ImageViewerFragment where after renaming an image and rotating
the screen, the window title would revert to the original file name.
Cleanup, license headers./"
Frostwire,"[android] ImageViewer fragment (#437)
* [android] ImageViewer activity, Video/Pic grid improvements
* [android] Fixes selection mode issues on grids, Media Overlay View, Pinch and Zoom
* [android] ads metadata to image viewer fragment
* [android] set wallpaper action non-blocking
* [android] ImageLoader asyncload wraps fetch() to use Picasso's background threads
* [android] New FileInformation action shows file information dialog
* [android] add preview screen listener
* [android] Cleanup and bug fixes.
Fixes bug on ImageViewerFragment where after renaming an image and rotating
the screen, the window title would revert to the original file name.
Cleanup, license headers./"
Frostwire,[android] fix update path security issue for Nougat/
Frostwire,[android] ANR fix. Don't scan files on main thread/
Frostwire,[android] fixed potential context leak in SeedAction/[android] fixed issue of all transfers go to seeding/
Frostwire,"[android] ImageViewer fragment (#437)
* [android] ImageViewer activity, Video/Pic grid improvements
* [android] Fixes selection mode issues on grids, Media Overlay View, Pinch and Zoom
* [android] ads metadata to image viewer fragment
* [android] set wallpaper action non-blocking
* [android] ImageLoader asyncload wraps fetch() to use Picasso's background threads
* [android] New FileInformation action shows file information dialog
* [android] add preview screen listener
* [android] Cleanup and bug fixes.
Fixes bug on ImageViewerFragment where after renaming an image and rotating
the screen, the window title would revert to the original file name.
Cleanup, license headers./"
Frostwire,"[android] avoid context leak on DeleteFileMenuAction/[android] ImageViewer fragment (#437)
* [android] ImageViewer activity, Video/Pic grid improvements
* [android] Fixes selection mode issues on grids, Media Overlay View, Pinch and Zoom
* [android] ads metadata to image viewer fragment
* [android] set wallpaper action non-blocking
* [android] ImageLoader asyncload wraps fetch() to use Picasso's background threads
* [android] New FileInformation action shows file information dialog
* [android] add preview screen listener
* [android] Cleanup and bug fixes.
Fixes bug on ImageViewerFragment where after renaming an image and rotating
the screen, the window title would revert to the original file name.
Cleanup, license headers./"
Frostwire,[android] fixed CancelMenuAction context leak background task (the first one detected with the engine thread pool)/
Frostwire,[android] crash dismissing NewTransferDialog/
Frostwire,[android] avoid capturing context references in startTorrentPartialDownload/[android] HandpickedTorrentDownloadDialog dialog dismiss crash fix/
Frostwire,"[android] bug fix first display onResume interstitial/[android] don't crash at runtime if call to commit in MainActivity#hideFragments fails with IllegalStateException/[android] ImageViewer fragment (#437)
* [android] ImageViewer activity, Video/Pic grid improvements
* [android] Fixes selection mode issues on grids, Media Overlay View, Pinch and Zoom
* [android] ads metadata to image viewer fragment
* [android] set wallpaper action non-blocking
* [android] ImageLoader asyncload wraps fetch() to use Picasso's background threads
* [android] New FileInformation action shows file information dialog
* [android] add preview screen listener
* [android] Cleanup and bug fixes.
Fixes bug on ImageViewerFragment where after renaming an image and rotating
the screen, the window title would revert to the original file name.
Cleanup, license headers./"
Frostwire,"[android] avoid IllegalState crash unregistering receivers
MoPub's initialization may trigger a call to a broadcast receiver unregistration on some devices that can lead to an illegal state crash since the receiver may be already unregistered or not registered at all/[android] avoid NPE ImageViewerActivity and refactor for better API/"
Frostwire,"[android] ImageViewer fragment (#437)
* [android] ImageViewer activity, Video/Pic grid improvements
* [android] Fixes selection mode issues on grids, Media Overlay View, Pinch and Zoom
* [android] ads metadata to image viewer fragment
* [android] set wallpaper action non-blocking
* [android] ImageLoader asyncload wraps fetch() to use Picasso's background threads
* [android] New FileInformation action shows file information dialog
* [android] add preview screen listener
* [android] Cleanup and bug fixes.
Fixes bug on ImageViewerFragment where after renaming an image and rotating
the screen, the window title would revert to the original file name.
Cleanup, license headers./"
Frostwire,"[android] SwipeLayout, don't crash if super.dispatchTouchEvent can't dispatch, just return as unhandled event/"
Frostwire,"[android] avoid possible NPE/[android] Fixes search media type tab selection bug
Upon a first search, the adapter would filter results by the last searche's media type however the UI's tab wouldn't be selected, also on rotation it would not remember the last tab selected and if you had previously selected a file type that didn't match your search you'd think there was something wrong as you'd see wrong file types in your search results or nothing at all and you'd see the audio tab selected with the search result counter > 0/"
Frostwire,[android] avoid possible ANRs shutting down/[android] ignoring SecurityException while canceling all notifications in EngineService#onStartCommand/
Frostwire,[android] ogury logic fix/
Frostwire,"[desktop] UpdateMessage reader, make sure conection is closed even if exception is thrown/"
Frostwire,[desktop] BugManager revision/
Frostwire,[desktop] BugManager revision/
Frostwire,[desktop] fix issue of listening to IPv6 and random port from settings/
Frostwire,[desktop] fix issue of listening to IPv6 and random port from settings/
Frostwire,"[all] EZTV search fixed
for the longest time it wasn't adding the search keywords to the search url.
test code updated/"
Frostwire,[common] fixed SC/
Frostwire,[common] fixed torlock/[all] TorLock search fixed/
Frostwire,[common] using magnet url for yi-fi if torrent url fails/
Frostwire,"[android] bug fix on song fragments
clicking on a song that was already being played would not open the music player screen. other cleanups/"
Frostwire,"[android] avoid possible IndexOutOfBoundsExceptions on playlist drops/[android] bug fix on song fragments
clicking on a song that was already being played would not open the music player screen. other cleanups/"
Frostwire,"[android] bug fix on song fragments
clicking on a song that was already being played would not open the music player screen. other cleanups/"
Frostwire,"[android] bug fix on song fragments
clicking on a song that was already being played would not open the music player screen. other cleanups/"
Frostwire,"[android] bug fix on song fragments
clicking on a song that was already being played would not open the music player screen. other cleanups/"
Frostwire,"[android] bug fix on song fragments
clicking on a song that was already being played would not open the music player screen. other cleanups/"
Frostwire,"[android] bug fix on song fragments
clicking on a song that was already being played would not open the music player screen. other cleanups/"
Frostwire,"[android] bug fix on song fragments
clicking on a song that was already being played would not open the music player screen. other cleanups/"
Frostwire,"[android] bug fix on song fragments
clicking on a song that was already being played would not open the music player screen. other cleanups/"
Frostwire,[android] avoid possible IndexOutOfBoundsExceptions on playlist drops/
Frostwire,"[android] issue #598 fix
Minimize the number of calls to the MusicService on the main thread.
It was aggresively calling all the way down to the music service every 500ms to update the
user interface. In many ocassions these calls would take a long time to come back thus causing
thousands of ANR reports.
Along the way the Debug context leak detection tool was fixed helping sort out 2 false positives.
This implementation minimizes the number of static Runnables submited to just 3. I'm not certain if we should be
using the same thread pool for all these things. Perhaps the Engine's getThreadPool() could use a parameter and
internally work with multiple pools for distinct purposes. This requires a design conversation if we move forward
in that direction, so that we can group threads accordingly in the minimum number of thread pools as possible./"
Frostwire,"[WIP] Horizontal layout my music (#559)
* [android] ititnal set up for the missing horizontal screens in my music
* [android] updated headers
* [android] fix for the unresponsive song list in horizontal views
* [android] dont repeat layouts, use values-land/dimens.xml
* [android] cleanup/"
Frostwire,"[android] bug fix on song fragments
clicking on a song that was already being played would not open the music player screen. other cleanups/"
Frostwire,"[android] apollo's FavoriteStore and RecentStore optimizations
Should avoid possible NPE in addSongId/"
Frostwire,"[android] NPE fix on FavoritesStore.addSongId (issue #606)/[android] apollo's FavoriteStore and RecentStore optimizations
Should avoid possible NPE in addSongId/"
Frostwire,[android] avoid NPE on NotificationHelper/[android] better ignore only SecurityException when dealing with NotificationManager (something new in Android 7)/[android] avoid crashes with NotificationManager (SecurityExceptions - Issue #555)/
Frostwire,[android] avoid possible IndexOutOfBoundsExceptions on playlist drops/
Frostwire,"[android] somehow an NPE can happen right after the NPE check/[android] MusicPlaybackService.onDestroy ANR fix/[android] issue #604, avoid ANR updating remote control client playback state/[android] avoid context leak int MuscPlaybackService#updateNotificationAsync background task/[android] avoid context leak int MuscPlaybackService#setDataSourceImpl background task/[android] possible Index out of bound exception
(now that it's not synchronized)/[android] MusicPlaybackService onDestroy() crash/[android] capturing only IllegalStateException and StaleDataException (partial revert of https://github.com/frostwire/frostwire/commit/ccdff5496bbe1172c47813574f02dfcb42e3e21b)/[android] ANR/MusicPlaybackService.start fix
Make sure mCurrentMediaPlayer.start() never occurs in main thread, where it can some times take too long performing isDrm() checks./[android] bug fix on song fragments
clicking on a song that was already being played would not open the music player screen. other cleanups/[android] MusicPlaybackService.notifyChange() refactor/optimizations
- Make sure notifyChange logic always runs in background thread
- Avoid unnecessary database re-querying
- Invert string.equals() comparison to avoid possible NPEs/[android] MusicPlaybackService.openCurrentAndMaybeNext - remove synchronized, avoid ANRs/[android] MusicPlaybackService.changeQueueAsync refactor. isFavorite() deadlock avoidance
The change on isFavorite() to not synchronize on the whole object is to help avoid the ANR reported on issue #430 when notifyChange() is called, which is called quite a lot. A refactor on notifyChange() is coming/[android] crash fix on MusicPlaybackService (Issue #554)/"
Frostwire,[android] bugfix: resume audio playback in case interstitial takes audio focus/
Frostwire,"[android] using execute instead of submit to avoid unused creation of Future objects/[android] reverting mopub interstitial init back to ui thread
a silent crash on the thread didn't let me see it couldn't be initialized on a thread that didn't have Looper.prepare()
Will have to live with possible ANRs loading these interstitials/[android] avoid context leak on MoPubAdNetwork.loadMoPubInterstitial/"
Frostwire,"[android] Fix onResume interstitial display bug when app was minimized/[android] Offers, debug output update/[android] avoid back to back onResume interstitials
While testing I've left an interstitial unattended for more than the interval period to display the next one and this results in 2 or up to 4 ads being displayed in a row (including the remove-ads interstitials), therefore we refresh the lastDisplay time keeper when an ad is dismissed as well as when we display it/[android] Less interstitial ads
MainActivity and Search interstitials now share the same timestamp, this way we avoid all possibility of back to back interstitials/"
Frostwire,"[android] avoid picasso internal logic duplication/[android] removed not useful calculateDiskCacheSize
The nature of this app is heavy use of disk, increasing or decreasing, the target should't change in each app start,
also, the phone will more likely to fail before we reach the ~120MB max specified./"
Frostwire,"[android] Issue #460 ImageViewerActivity: Swipe to the next/previous picture (#612)/Issue 590 scrollbar fix (#592)
* [android] disable fast scroll on idle state
prevents the user from scrolling by mistake while touching the right side of the screen while on the listview
* [android] added ComposedOnScrollListener/"
Frostwire,"[android] transfers selected tab on rotation bug fix/[android] issue 594, shows transfer while fetching torrent (#596)
Also, when transfers are removed the transfer list is now refreshed immediatly./Issue 590 scrollbar fix (#592)
* [android] disable fast scroll on idle state
prevents the user from scrolling by mistake while touching the right side of the screen while on the listview
* [android] added ComposedOnScrollListener/[android] Transfers > Seeding - Views to encourage seeding
Makes the new Seeding tab user experience a lot better when we can detect things like: is seeding disabled? or are there any transfers we should be seeding?
Cleanup and fixes on TransfersFragment/[android] SeedAction can now be used to seed all finished transfers.
- Fixes bug where top menu seed all wouldn't show the dialogs pertinent to bittorrent off or seeding off. TransferFragment menu action now reuses SeedAction
- SeedAction cleanup, formatting and Context-leak avoidance maintenance/[WIP] additional no results text on search for when connection  (#567)
* [android] additional no results text on search for when connection is not available.
only when no Wifi and Data are available at the moment.
* [android] NetworkManager broadcast listener refactor, integration with SearchProgressView (1st leg)
* [android] wording on more results
* [android] get rid of extra broadcast receiver, thanks @aldenml
* [android] show snackbar on search fragment when connection dropped
Transfers already have a few way of showing, so not adding it there yet
* [android] update link to more results url
* [android] flip string checks, add default switch case
* [android] NetworkManager parameter refactor, url fix/"
Frostwire,"[android] Issue #460 ImageViewerActivity: Swipe to the next/previous picture (#612)/[android] Crash fix on ImageViewerFragment opening file externally. Build 448.
Don't try to open files with other apps by hand, in this case there were two bugs for reinventing the wheel.
1. The wrong file URI was being passed, after Android 7.0 file:// uris are not allowed.
2. The intent was missing a flag
all this logic has been encapsulated nicely in a one liner -> UIUtils.openFile(...)/[android] Open Menu Action to open image with external Image Viewer (#586)
* [android] Open Menu Action to open image with external Image Viewer
Issue #585
* [android] removed unncessary inFullScreenMode from the ImageViewerFragment
* [android] removed unnecessary characters
put in by mistake/"
Frostwire,"[android] SearchHeader banner reload bug fix
Did not have to be so aggresive about destroying the mopub view. When destroyed, it gets rid of its internal controller.
A mopub view that has a null internal controller aborts its ad loading logic.
That controller can only be created when the mopub view is instantiated, this only happened onCreate(), therefore only one ad was displayed./[android] Issue #608, revert last commit, refactor, copy list before submitting to thread/[android] DirectionDetectorScrollListener context leak fix and refactor/Issue 590 scrollbar fix (#592)
* [android] disable fast scroll on idle state
prevents the user from scrolling by mistake while touching the right side of the screen while on the listview
* [android] added ComposedOnScrollListener/[android] SearchFragment avoid context leaks/[android] using execute instead of submit to avoid unused creation of Future objects/"
Frostwire,"[android] properly fail if containerView is null
design comment: isn't that the message? and also, it's hard to think of CheckableImageView as a view, it is not even added to any container/"
Frostwire,"[android] minor warning fixes in SoftwareUpdater/[android] avoid ANR caused by ConfigurationManager.putLong()/[android] vpn offer name fix, remote vpn offer config/"
Frostwire,[android] fix context leak in UniversalScanner/[android] fix of context leak in prepareOnMediaScannerConnectedRunnable/[android] using execute instead of submit to avoid unused creation of Future objects/
Frostwire,"[android] issue 594, shows transfer while fetching torrent (#596)
Also, when transfers are removed the transfer list is now refreshed immediatly./"
Frostwire,"[WIP] additional no results text on search for when connection  (#567)
* [android] additional no results text on search for when connection is not available.
only when no Wifi and Data are available at the moment.
* [android] NetworkManager broadcast listener refactor, integration with SearchProgressView (1st leg)
* [android] wording on more results
* [android] get rid of extra broadcast receiver, thanks @aldenml
* [android] show snackbar on search fragment when connection dropped
Transfers already have a few way of showing, so not adding it there yet
* [android] update link to more results url
* [android] flip string checks, add default switch case
* [android] NetworkManager parameter refactor, url fix/"
Frostwire,"[android] removed problematic and inconsistent seed check, now that we are using DHT in mobile networks
This should match better the results in desktop./"
Frostwire,"[android] possible Index out of bound exception
(now that it's not synchronized)/"
Frostwire,"[android] SeedAction can now be used to seed all finished transfers.
- Fixes bug where top menu seed all wouldn't show the dialogs pertinent to bittorrent off or seeding off. TransferFragment menu action now reuses SeedAction
- SeedAction cleanup, formatting and Context-leak avoidance maintenance/[android] Fixed context leak detected in SeedAction.onClick()/[WIP] additional no results text on search for when connection  (#567)
* [android] additional no results text on search for when connection is not available.
only when no Wifi and Data are available at the moment.
* [android] NetworkManager broadcast listener refactor, integration with SearchProgressView (1st leg)
* [android] wording on more results
* [android] get rid of extra broadcast receiver, thanks @aldenml
* [android] show snackbar on search fragment when connection dropped
Transfers already have a few way of showing, so not adding it there yet
* [android] update link to more results url
* [android] flip string checks, add default switch case
* [android] NetworkManager parameter refactor, url fix/"
Frostwire,"[android] issue 594, shows transfer while fetching torrent (#596)
Also, when transfers are removed the transfer list is now refreshed immediatly./"
Frostwire,[android] making inner DialogButtonClickListener inner to the DialogFragment and no static (no context leak problem here)/
Frostwire,"[android] issue 594, shows transfer while fetching torrent (#596)
Also, when transfers are removed the transfer list is now refreshed immediatly./[WIP] additional no results text on search for when connection  (#567)
* [android] additional no results text on search for when connection is not available.
only when no Wifi and Data are available at the moment.
* [android] NetworkManager broadcast listener refactor, integration with SearchProgressView (1st leg)
* [android] wording on more results
* [android] get rid of extra broadcast receiver, thanks @aldenml
* [android] show snackbar on search fragment when connection dropped
Transfers already have a few way of showing, so not adding it there yet
* [android] update link to more results url
* [android] flip string checks, add default switch case
* [android] NetworkManager parameter refactor, url fix/"
Frostwire,"[android] issue 594, shows transfer while fetching torrent (#596)
Also, when transfers are removed the transfer list is now refreshed immediatly./"
Frostwire,"[android] move updateNavigationMenu() call out of setupDrawer()
avoid possible infinite loop/[android] MainActivity update system fixes
- Made BroadcastReceivers static classes with weak references to activity to avoid any possible memory leaks
- Persist an 'updateAvailable' boolean state to update nav menu with
upgrade icon notification.
- updateNavigationMenu(bool) check is also done when instantiating a new nav menu
- cleaned constructor of unnecessary ""this."" notation
- rearranged member declarations, simpler (smaller sized) types to the top/[android/bugfix] issue that showed first ad ever way too soon/[android] issue 594, shows transfer while fetching torrent (#596)
Also, when transfers are removed the transfer list is now refreshed immediatly./[android] using execute instead of submit to avoid unused creation of Future objects/[android] Fix onResume interstitial display bug when app was minimized/[android] avoid back to back interstitials/[android] MainActivity.hideFragments() - Issue #556
don't crash if weaker transaction commit fails. Looking at Android's souce code it seems the IllegalStateException will occur if the BackStackRecord.mCommitted property has already been set to true. This makes me wonder if this happens because this hideFragments() call is being called concurrently as the real source of the bug/[android] Less interstitial ads
MainActivity and Search interstitials now share the same timestamp, this way we avoid all possibility of back to back interstitials/"
Frostwire,[android] Issue #460 ImageViewerActivity: Swipe to the next/previous picture (#612)/
Frostwire,"[android] vpn offer name fix, remote vpn offer config/"
Frostwire,[android] Issue #460 ImageViewerActivity: Swipe to the next/previous picture (#612)/
Frostwire,[android] Issue #460 ImageViewerActivity: Swipe to the next/previous picture (#612)/
Frostwire,"[WIP] additional no results text on search for when connection  (#567)
* [android] additional no results text on search for when connection is not available.
only when no Wifi and Data are available at the moment.
* [android] NetworkManager broadcast listener refactor, integration with SearchProgressView (1st leg)
* [android] wording on more results
* [android] get rid of extra broadcast receiver, thanks @aldenml
* [android] show snackbar on search fragment when connection dropped
Transfers already have a few way of showing, so not adding it there yet
* [android] update link to more results url
* [android] flip string checks, add default switch case
* [android] NetworkManager parameter refactor, url fix/[android] avoid crashes with NotificationManager (SecurityExceptions - Issue #555)/"
Frostwire,[android] bugfix: resume audio playback in case interstitial takes audio focus/
Frostwire,[desktop] NPE Fix on NameHolderRenderer/
Frostwire,"[android] NPE on EngineBroadcastReceiver::reopenNetworkSockets.
Error wording clarification/"
Frostwire,[common] more robust handling of network errors in BaseHttpDownload/
Frostwire,[common] fixed SC/
Frostwire,"[WIP] Setting up correclty strings to empty fragments (#641)
* [WIP] Setting up correclty strings to empty fragments
* Adding default fragment empty message with a field
* Removed getString method call by @aldenml suggestion. Fixing the string empty value for RecentFragment./"
Frostwire,"[WIP] Setting up correclty strings to empty fragments (#641)
* [WIP] Setting up correclty strings to empty fragments
* Adding default fragment empty message with a field
* Removed getString method call by @aldenml suggestion. Fixing the string empty value for RecentFragment./"
Frostwire,"[android] avoid context leak in RecentFragment/[WIP] Setting up correclty strings to empty fragments (#641)
* [WIP] Setting up correclty strings to empty fragments
* Adding default fragment empty message with a field
* Removed getString method call by @aldenml suggestion. Fixing the string empty value for RecentFragment./[android/issue-637] Showing songs instead of albums in recent player tab (#638)
* [android][WIP] issue 637 Showing song instead of albums in recent player tab
* [WIP] Code compiles. Having problems with closing a cursor.
* [WIP] Project compiles. Add songs to the Recent Fragment and plays as expected. Need more work to put song related information on screen
* [WIP] Changes to save track duration correctly
* [WIP] Fixes in RecentSongLoader
* [WIP] Reusing existent interface to get song field names
* [WIP] Adding licenses and cleaning up
* [WIP] Removing unnecessary classes to save some symbols. RecentSongLoader removed, all the functionality was added to RecentLoader. RecentSongStore class removed, all funcionality was added to RecentStore
* [WIP] Removed BaseSongFragment. RecentFragment inherits from ApolloFragment directly. Removed menu for 'View as' in Recent tab
* Removed getLastSongForArtist because isn't used
* [WIP] Cleaning up
* More cleaning. Updating docstring
* [WIP] choosing a better name for last time played column.
* Minor Fixes requested by @gubatron
* [WIP] Calling restartLoader using force equals  in order to update the Recent list without reload the Fragment
* [WIP] Almost there, fixing odd behavior in Recent List
* [android] lambda refactor, NPE checks on SongAdapter
* exec improvements. reloading data in a different thread./"
Frostwire,"[WIP] Setting up correclty strings to empty fragments (#641)
* [WIP] Setting up correclty strings to empty fragments
* Adding default fragment empty message with a field
* Removed getString method call by @aldenml suggestion. Fixing the string empty value for RecentFragment./"
Frostwire,"[android/issue-637] Showing songs instead of albums in recent player tab (#638)
* [android][WIP] issue 637 Showing song instead of albums in recent player tab
* [WIP] Code compiles. Having problems with closing a cursor.
* [WIP] Project compiles. Add songs to the Recent Fragment and plays as expected. Need more work to put song related information on screen
* [WIP] Changes to save track duration correctly
* [WIP] Fixes in RecentSongLoader
* [WIP] Reusing existent interface to get song field names
* [WIP] Adding licenses and cleaning up
* [WIP] Removing unnecessary classes to save some symbols. RecentSongLoader removed, all the functionality was added to RecentLoader. RecentSongStore class removed, all funcionality was added to RecentStore
* [WIP] Removed BaseSongFragment. RecentFragment inherits from ApolloFragment directly. Removed menu for 'View as' in Recent tab
* Removed getLastSongForArtist because isn't used
* [WIP] Cleaning up
* More cleaning. Updating docstring
* [WIP] choosing a better name for last time played column.
* Minor Fixes requested by @gubatron
* [WIP] Calling restartLoader using force equals  in order to update the Recent list without reload the Fragment
* [WIP] Almost there, fixing odd behavior in Recent List
* [android] lambda refactor, NPE checks on SongAdapter
* exec improvements. reloading data in a different thread./"
Frostwire,[android] FileUriExposedException for SDK >= 24 fixed when sharing a screenshot of music player/
Frostwire,"[android] don't crash if FavoritesStore, RecentStore constructors fail on SQLiteException/[android/issue-637] Showing songs instead of albums in recent player tab (#638)
* [android][WIP] issue 637 Showing song instead of albums in recent player tab
* [WIP] Code compiles. Having problems with closing a cursor.
* [WIP] Project compiles. Add songs to the Recent Fragment and plays as expected. Need more work to put song related information on screen
* [WIP] Changes to save track duration correctly
* [WIP] Fixes in RecentSongLoader
* [WIP] Reusing existent interface to get song field names
* [WIP] Adding licenses and cleaning up
* [WIP] Removing unnecessary classes to save some symbols. RecentSongLoader removed, all the functionality was added to RecentLoader. RecentSongStore class removed, all funcionality was added to RecentStore
* [WIP] Removed BaseSongFragment. RecentFragment inherits from ApolloFragment directly. Removed menu for 'View as' in Recent tab
* Removed getLastSongForArtist because isn't used
* [WIP] Cleaning up
* More cleaning. Updating docstring
* [WIP] choosing a better name for last time played column.
* Minor Fixes requested by @gubatron
* [WIP] Calling restartLoader using force equals  in order to update the Recent list without reload the Fragment
* [WIP] Almost there, fixing odd behavior in Recent List
* [android] lambda refactor, NPE checks on SongAdapter
* exec improvements. reloading data in a different thread./"
Frostwire,"[android] don't crash if FavoritesStore, RecentStore constructors fail on SQLiteException/"
Frostwire,"[android] don't crash if FavoritesStore, RecentStore constructors fail on SQLiteException/[android] MusicPlaybackService maintenance
- Avoid possible crash if Power Manager can't be obtained
- Avoid possible crash obtaining a lock on mFavoritesCache == null, do not synchronize non-final objects/[android/issue-637] Showing songs instead of albums in recent player tab (#638)
* [android][WIP] issue 637 Showing song instead of albums in recent player tab
* [WIP] Code compiles. Having problems with closing a cursor.
* [WIP] Project compiles. Add songs to the Recent Fragment and plays as expected. Need more work to put song related information on screen
* [WIP] Changes to save track duration correctly
* [WIP] Fixes in RecentSongLoader
* [WIP] Reusing existent interface to get song field names
* [WIP] Adding licenses and cleaning up
* [WIP] Removing unnecessary classes to save some symbols. RecentSongLoader removed, all the functionality was added to RecentLoader. RecentSongStore class removed, all funcionality was added to RecentStore
* [WIP] Removed BaseSongFragment. RecentFragment inherits from ApolloFragment directly. Removed menu for 'View as' in Recent tab
* Removed getLastSongForArtist because isn't used
* [WIP] Cleaning up
* More cleaning. Updating docstring
* [WIP] choosing a better name for last time played column.
* Minor Fixes requested by @gubatron
* [WIP] Calling restartLoader using force equals  in order to update the Recent list without reload the Fragment
* [WIP] Almost there, fixing odd behavior in Recent List
* [android] lambda refactor, NPE checks on SongAdapter
* exec improvements. reloading data in a different thread./"
Frostwire,"[android/issue-637] Showing songs instead of albums in recent player tab (#638)
* [android][WIP] issue 637 Showing song instead of albums in recent player tab
* [WIP] Code compiles. Having problems with closing a cursor.
* [WIP] Project compiles. Add songs to the Recent Fragment and plays as expected. Need more work to put song related information on screen
* [WIP] Changes to save track duration correctly
* [WIP] Fixes in RecentSongLoader
* [WIP] Reusing existent interface to get song field names
* [WIP] Adding licenses and cleaning up
* [WIP] Removing unnecessary classes to save some symbols. RecentSongLoader removed, all the functionality was added to RecentLoader. RecentSongStore class removed, all funcionality was added to RecentStore
* [WIP] Removed BaseSongFragment. RecentFragment inherits from ApolloFragment directly. Removed menu for 'View as' in Recent tab
* Removed getLastSongForArtist because isn't used
* [WIP] Cleaning up
* More cleaning. Updating docstring
* [WIP] choosing a better name for last time played column.
* Minor Fixes requested by @gubatron
* [WIP] Calling restartLoader using force equals  in order to update the Recent list without reload the Fragment
* [WIP] Almost there, fixing odd behavior in Recent List
* [android] lambda refactor, NPE checks on SongAdapter
* exec improvements. reloading data in a different thread./"
Frostwire,"[WIP] Setting up correclty strings to empty fragments (#641)
* [WIP] Setting up correclty strings to empty fragments
* Adding default fragment empty message with a field
* Removed getString method call by @aldenml suggestion. Fixing the string empty value for RecentFragment./"
Frostwire,"[WIP] Frostwire 2.0 (#624)
* [android] new layouts for the transfer detail pages
* [android] initial set up for the transfer detail activity
* [android] added toolbar menu to TransferDetails
* [android] Extended AbstractFragment from the remaining transfer detail screens
* [android] cleanup in TransferDetailActivity
* [android] added status tab to transfer details, code cleanup
* [android] added status layout to torrent details, layout code cleanup and headers
* [android] added resource values for transfer detail activity
* [android] removed unnecessary styles
* [android] adjusted style of the view_transfer_list_item
* [android] replaced missing style in view_transfer_item_list_item.xml
* [android] minor adjustement in dividers of view_transfer_list_item.xml
* [android] Transfer detail fragments reused. cleanup on fragment classes
* [android] TransferDetailActivity refactor. New AbstractTransferDetailFragment.
* [android] remove setContext hack, do it the android way
* [android] cleanup
* [android] TransferManager::getBittorrentDownload(String infoHash)
* [android] plugged BittorrentDownload object all the way to fragments
Common section with title and progress plugged. Next transfer status and upload/download speed in that common section
* [android] plugged transfer status string into common progress component
- New TransferStateStrings singleton class to map transfer states to strings
- TransferListAdapter refactored to use new TransferStateStrings
* [android] plugged download and upload speeds on common progress panel
* [android] transfer detail > status > Completed plugged
renamed some of the textviews to have a '_label' suffix
* [desktop] CommonUtils cleanup
* [android] Transfer Detail > Status > Time remaining plugged
* [android] Transfer Details, Status tab done
* [android] abort updateDetailProgress when transfer is null
* [android] transfer details layout cleanup
* [android] adding a recyclerview to Details, moved mock layout for its views to fragment_transfer_detail_files_recyclerview_item.xml
* [android] plugged number of files and total download size on FILES tab
* [android] started pluggin ReciclerView, still not working
* [android] got files showing on details > files. main transfer list broken, might transition to recycler view here too, testing with ListViewCompat (v7)
* [android] cleanup
* [android] cleanup
* [android] TransferFragment RecyclerView refactor (broken)
* [android] RecyclerView on TransfersFragment working
* [android] cleanup, component lookup optimization in Transfers Fragment
* [android] Progress on Transfer Detail > Details fragment
* [common] BTDownload.getTorrentHandle()
* [android] Details > Details > Comment section handled
* [android] Transfer Detail > Details tab.
Just have an issue with the 'Sequential Download' checkbox
* [android] updated torrent_details_files
* [android] progress on Transfers Details > Trackers tab
* [android] updated transfer detail trackers fragment layout
* [android] new UIUtils.showEditTextDialog
* [android] Transfer Detail > Trackers can add trackers to torrent
* [android] fixed width issues with individual tracker layout
* [android] minor refactor on TransferManager
* [android] TransferDetailStatusFragment doesn't crash on rotation
* [android] broken progress towards adding/editing trackers
* [android] fix another on rotation crash
* [android] uiBittorrentDownload is serialized and deserialized on screen rotation
* [android] set adapter after you've set the layout manager
* [android] adds and deletes trackers
* [android] trackers can be removed. edit text dialog can be configured for single/multi line
* [android] fixes issue where recycler views would not show items when tabs switched
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android] Transfer Details > Peers tab working
* [andriod] fixed build.gradle to use new plugin 3.0.0 DSL
* [android] Details tab cleanup.
- Removed 'Seeding On' checkbox. That can be handled with action bar controls for seeding/pausing
- Dialog button handlers now use lambdas
* [android] don't refresh tab if not visible cleanup
* [android] Transfer Details > Pieces tab (not working correctly)
Also lint cleanup on the activity and related fragments
* [android] few minor changes to transfer detail layouts
* [android] added and updated icons for the view_transfer_list_item
* [android] set up for the right side transfer item actions
* [android] pieces colors work, had to do r.getColor(). refactor
* [android] First pass at setting the media type icon on transfer list items
* [common] BittorrentDownload::getPredominantFileExtension()
* [android] uses BittorrentDownload's getPredominantFileExtension() to determine transfer media icon
* [android] show missing /s on transfer detail speed indicators
* [android] warning cleanup on ClickAdapter<T>
* [android] Details button on TransferListAdapter works.
TransferListAdapter refactored so that we only have a single instance for every click listener, not individual listeners for every view created
* [android] found inconsistency between download and upload rate unlimited values in libtorrent, cleanup
* [android] fixed overlapping of the text on view_transfer_detail_peer_item
* [android] updated TransferDetailDetails dialog title
* [android] added appropriate padding to the pieces view in transfer detail
* [android] fixes rotation crashes. refactors to deal with rotation
if for some reason getting pieces takes a while, an indeterminate progress bar is shown in place of the pieces
other rotation bugs fixed, more robust behavior
* [android] files becomes the first, and default selected tab
* [android] remove timer subscription responsibility from fragments
Use only one TimeObserver subscriber defined in the TransferDetailActivity.
Fragments still implement TimerObserver, have the single subscriber instance invoke the fragment's onTime method
only on the currently active fragment
* [android] SectionsPagerAdapter doesn't need to keep a reference to activity
- Just pass a SparseArray with the string resources it actually needs
- Implements a new OnPageChangeListener that keeps track of what the current fragment is
- When current fragment changes invoke onTime() on it
- Implements TimerObserver on the activity which delegates an onTime() call to the current fragment
* [android] isVisible() check no longer necessary
also found out that in some cases, isVisible() would give a false negative
* [android] more work towards avoiding issues on rotation and fast tab changes
* [android] import cleanup, if unwraps
* [android] stick to empty default constructors on YouTubeDownloadDialog
* [android] lint warnings, import cleanups
* [android] semi-aldenization of fragment code, still rotation issues
* [android] move all init calls to initComponents
* [android] cleanup. still issues on rotation, fragments not being added after rotation
* [android] finally resolved rotation issue
It seems the pager adapter and the programatic approach to adding transfers ended up in fragments not being able to be tracked correctly by their tags when the activity was reloaded.
Some of the fragments we ended up with inside detailFragments[] wouldn't be added, however, we luckily have methods in the parent AbstractFragment class to keep track of fragments that have been added (since Android only provides these after API 21 or so), by looking at the added fragments I'm able to find the correct instance and replace it inside our internal detailFragments array.
Writing this commit message makes me want to use that list, and get rid of the internal detailFragments array, to keep track of the fragments used, they could easily be filtered if they're instances of AbstractTransferDetailFragment
* [android] edit text dialog is now an extension of AbstractDialog
* [android] EditTextDialog moved to its own file, handles screen rotation
* [android] removed unused vars
* [android] rotation bug finally fixed
* [android] inline call
* [android] Transfer > Status > Time left only shown when downloading
* [android] transfer detail tab layout cleanup
* [android] transfer details details speed limit dialog issues
- When transfers are first created their upload/download rate limits come as -1
- When you want to set them to -1 for unlimited, this does not go well. You have to use 0 for unlimited, after that, they return 0
- Added a dialog closed listener that refreshes the fragment on close so new rate limit is reflected on the ui right away
* [android] remove tracker dialog look is uniform. UIUtil.showYesNoDialog now uses YesNoDialog.
* [android] don't hide time left textview, show 0 instead
* [android] progress with transfer details action bar menu
* [android] logic fix with pause/resume action bar action
* [android] updated action bar icons, added new resume aciton bar icon
* [android] removed double resume action
That action is not on the main branch, it was added later - it said resume but it was starting to seed even with seeding settings off.
* [android] updated icons for resume and cancel context menu action
* [android] added action bar seed icon
* [android] removed repeating action menu option
* [android] fixed and updated action_bar_seed icons
Sorry saved them with a wrong setting, looked pixelated
* [android] better logic on pause, resume, seed
* [android] added clear option on details.
cancel menu action uses the proper icon depending on the parameters
* [android] removed Open action from details, files are already there for individual access
* [android] added action_bar_stop_transfer icon
* [android] seeding|pausing made left most action. delete transfer sent to the context menu and cancel transfer the 2nd action shown only if room is available
* [android] use SeedAction when seedable
* [android] Update Translation: Spanish
* [android] Update Translation: Portuguese
* [android] start of HexHiveView for piece display, bye RecyclerView in this fragment
* [android] detail pieces layout cleanup
* [android] updated files and trackers layouts
RecyclerViewer no longer moves independently from the rest of hte scroll view - better user experience on small screens and horizontal views.
Fixed the files tab to open lower then top of the page.
The issue was connected to recycleviewer receiving the focus.
* [android] calculate height of other components to correctly measure height for hexhiveview
* [android] HexHiveView sizing issues fixed
- No need to manually calculate bounds when the containing layout is simpler
- fragment_transfer_detail_pieces no longer inside ScrollView, no need to scroll as our HexHiveView will only use remaining vertical space
- To make this work, view_transfer_detail_progress now has a fixed height, otherwise the folder icon would go towards the center of the screen
* [android] fix to the height of the detail_progress layout
* [android] very wip hex drawing experiments
* [android] Update Translations: French and Italian
* [android] HexView advances
- New DrawingProperties object is used to create buffer objects and useful constants for drawing the hexagonal hive
- drawing functions refactored to reduce the number of parameter copies on each onDraw iteration
- more cleanup to be done, gotta take into consideration real pixel width of hexagon borders when moving along the hive
* [android] hex fill logic implemented, wip, more fixes needed to calculate right max hex side length
* [android] fixed color assigment bug, only repaint when number of pieces downloaded has changed
* [android] made debug drawing an XML attribute. Better aproximation on desired hexagon length, still need to account for maximum rows.
* [android] simplifications
* [android] unneded file
* [android] 2.0.0 (beta) build 473
* [android] stricter checks initializing UIBittorrentDownload
* [android] no need to import Objects
* [android] Update Translation: German
* [android] NPE bullet proofing
My guess is that the NPE reported on detailProgressStatusTextView.setText(transferStateStrings.get(uiBittorrentDownload.getState())); wasn't due
to the view being null, but to the transferStateStrings object being null due to possible synchronization issues with TransferStateStrings.getInstance()
To make sure this doesn't happen, I perform another check later on, and if we've been wrongly assigned a null value, we request the singleton again.
* [android] rebasing left-overs
* [android] math brainfart calculating Y position of rows fixed
* [android] hex hive drawing fixes
* [android] cube-piece drawing support
* [android] upgrades
- don't animate tabs when touching tab title
- new CubePaint object extends Paint and calculates and keeps colors for dark left cube face and light top face out of the given fill color which is used on the right side face
* [android] adds URL validation when adding or editing trackers
* [android] fix bug with active time and seeding time calculation
when context menu actions are invoked they invoke onTime() on the underlying activity (Context that implements TimerObserver)
cleanup
* [android] s/delete/remove torrent and data/ menu entry
* [android] cleanup
* [android] avoid Runtime error trying to open transfer with no infoHash/[android] removal of static Context reference in Librarian to avoid memory leaks/"
Frostwire,"[WIP] Frostwire 2.0 (#624)
* [android] new layouts for the transfer detail pages
* [android] initial set up for the transfer detail activity
* [android] added toolbar menu to TransferDetails
* [android] Extended AbstractFragment from the remaining transfer detail screens
* [android] cleanup in TransferDetailActivity
* [android] added status tab to transfer details, code cleanup
* [android] added status layout to torrent details, layout code cleanup and headers
* [android] added resource values for transfer detail activity
* [android] removed unnecessary styles
* [android] adjusted style of the view_transfer_list_item
* [android] replaced missing style in view_transfer_item_list_item.xml
* [android] minor adjustement in dividers of view_transfer_list_item.xml
* [android] Transfer detail fragments reused. cleanup on fragment classes
* [android] TransferDetailActivity refactor. New AbstractTransferDetailFragment.
* [android] remove setContext hack, do it the android way
* [android] cleanup
* [android] TransferManager::getBittorrentDownload(String infoHash)
* [android] plugged BittorrentDownload object all the way to fragments
Common section with title and progress plugged. Next transfer status and upload/download speed in that common section
* [android] plugged transfer status string into common progress component
- New TransferStateStrings singleton class to map transfer states to strings
- TransferListAdapter refactored to use new TransferStateStrings
* [android] plugged download and upload speeds on common progress panel
* [android] transfer detail > status > Completed plugged
renamed some of the textviews to have a '_label' suffix
* [desktop] CommonUtils cleanup
* [android] Transfer Detail > Status > Time remaining plugged
* [android] Transfer Details, Status tab done
* [android] abort updateDetailProgress when transfer is null
* [android] transfer details layout cleanup
* [android] adding a recyclerview to Details, moved mock layout for its views to fragment_transfer_detail_files_recyclerview_item.xml
* [android] plugged number of files and total download size on FILES tab
* [android] started pluggin ReciclerView, still not working
* [android] got files showing on details > files. main transfer list broken, might transition to recycler view here too, testing with ListViewCompat (v7)
* [android] cleanup
* [android] cleanup
* [android] TransferFragment RecyclerView refactor (broken)
* [android] RecyclerView on TransfersFragment working
* [android] cleanup, component lookup optimization in Transfers Fragment
* [android] Progress on Transfer Detail > Details fragment
* [common] BTDownload.getTorrentHandle()
* [android] Details > Details > Comment section handled
* [android] Transfer Detail > Details tab.
Just have an issue with the 'Sequential Download' checkbox
* [android] updated torrent_details_files
* [android] progress on Transfers Details > Trackers tab
* [android] updated transfer detail trackers fragment layout
* [android] new UIUtils.showEditTextDialog
* [android] Transfer Detail > Trackers can add trackers to torrent
* [android] fixed width issues with individual tracker layout
* [android] minor refactor on TransferManager
* [android] TransferDetailStatusFragment doesn't crash on rotation
* [android] broken progress towards adding/editing trackers
* [android] fix another on rotation crash
* [android] uiBittorrentDownload is serialized and deserialized on screen rotation
* [android] set adapter after you've set the layout manager
* [android] adds and deletes trackers
* [android] trackers can be removed. edit text dialog can be configured for single/multi line
* [android] fixes issue where recycler views would not show items when tabs switched
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android] Transfer Details > Peers tab working
* [andriod] fixed build.gradle to use new plugin 3.0.0 DSL
* [android] Details tab cleanup.
- Removed 'Seeding On' checkbox. That can be handled with action bar controls for seeding/pausing
- Dialog button handlers now use lambdas
* [android] don't refresh tab if not visible cleanup
* [android] Transfer Details > Pieces tab (not working correctly)
Also lint cleanup on the activity and related fragments
* [android] few minor changes to transfer detail layouts
* [android] added and updated icons for the view_transfer_list_item
* [android] set up for the right side transfer item actions
* [android] pieces colors work, had to do r.getColor(). refactor
* [android] First pass at setting the media type icon on transfer list items
* [common] BittorrentDownload::getPredominantFileExtension()
* [android] uses BittorrentDownload's getPredominantFileExtension() to determine transfer media icon
* [android] show missing /s on transfer detail speed indicators
* [android] warning cleanup on ClickAdapter<T>
* [android] Details button on TransferListAdapter works.
TransferListAdapter refactored so that we only have a single instance for every click listener, not individual listeners for every view created
* [android] found inconsistency between download and upload rate unlimited values in libtorrent, cleanup
* [android] fixed overlapping of the text on view_transfer_detail_peer_item
* [android] updated TransferDetailDetails dialog title
* [android] added appropriate padding to the pieces view in transfer detail
* [android] fixes rotation crashes. refactors to deal with rotation
if for some reason getting pieces takes a while, an indeterminate progress bar is shown in place of the pieces
other rotation bugs fixed, more robust behavior
* [android] files becomes the first, and default selected tab
* [android] remove timer subscription responsibility from fragments
Use only one TimeObserver subscriber defined in the TransferDetailActivity.
Fragments still implement TimerObserver, have the single subscriber instance invoke the fragment's onTime method
only on the currently active fragment
* [android] SectionsPagerAdapter doesn't need to keep a reference to activity
- Just pass a SparseArray with the string resources it actually needs
- Implements a new OnPageChangeListener that keeps track of what the current fragment is
- When current fragment changes invoke onTime() on it
- Implements TimerObserver on the activity which delegates an onTime() call to the current fragment
* [android] isVisible() check no longer necessary
also found out that in some cases, isVisible() would give a false negative
* [android] more work towards avoiding issues on rotation and fast tab changes
* [android] import cleanup, if unwraps
* [android] stick to empty default constructors on YouTubeDownloadDialog
* [android] lint warnings, import cleanups
* [android] semi-aldenization of fragment code, still rotation issues
* [android] move all init calls to initComponents
* [android] cleanup. still issues on rotation, fragments not being added after rotation
* [android] finally resolved rotation issue
It seems the pager adapter and the programatic approach to adding transfers ended up in fragments not being able to be tracked correctly by their tags when the activity was reloaded.
Some of the fragments we ended up with inside detailFragments[] wouldn't be added, however, we luckily have methods in the parent AbstractFragment class to keep track of fragments that have been added (since Android only provides these after API 21 or so), by looking at the added fragments I'm able to find the correct instance and replace it inside our internal detailFragments array.
Writing this commit message makes me want to use that list, and get rid of the internal detailFragments array, to keep track of the fragments used, they could easily be filtered if they're instances of AbstractTransferDetailFragment
* [android] edit text dialog is now an extension of AbstractDialog
* [android] EditTextDialog moved to its own file, handles screen rotation
* [android] removed unused vars
* [android] rotation bug finally fixed
* [android] inline call
* [android] Transfer > Status > Time left only shown when downloading
* [android] transfer detail tab layout cleanup
* [android] transfer details details speed limit dialog issues
- When transfers are first created their upload/download rate limits come as -1
- When you want to set them to -1 for unlimited, this does not go well. You have to use 0 for unlimited, after that, they return 0
- Added a dialog closed listener that refreshes the fragment on close so new rate limit is reflected on the ui right away
* [android] remove tracker dialog look is uniform. UIUtil.showYesNoDialog now uses YesNoDialog.
* [android] don't hide time left textview, show 0 instead
* [android] progress with transfer details action bar menu
* [android] logic fix with pause/resume action bar action
* [android] updated action bar icons, added new resume aciton bar icon
* [android] removed double resume action
That action is not on the main branch, it was added later - it said resume but it was starting to seed even with seeding settings off.
* [android] updated icons for resume and cancel context menu action
* [android] added action bar seed icon
* [android] removed repeating action menu option
* [android] fixed and updated action_bar_seed icons
Sorry saved them with a wrong setting, looked pixelated
* [android] better logic on pause, resume, seed
* [android] added clear option on details.
cancel menu action uses the proper icon depending on the parameters
* [android] removed Open action from details, files are already there for individual access
* [android] added action_bar_stop_transfer icon
* [android] seeding|pausing made left most action. delete transfer sent to the context menu and cancel transfer the 2nd action shown only if room is available
* [android] use SeedAction when seedable
* [android] Update Translation: Spanish
* [android] Update Translation: Portuguese
* [android] start of HexHiveView for piece display, bye RecyclerView in this fragment
* [android] detail pieces layout cleanup
* [android] updated files and trackers layouts
RecyclerViewer no longer moves independently from the rest of hte scroll view - better user experience on small screens and horizontal views.
Fixed the files tab to open lower then top of the page.
The issue was connected to recycleviewer receiving the focus.
* [android] calculate height of other components to correctly measure height for hexhiveview
* [android] HexHiveView sizing issues fixed
- No need to manually calculate bounds when the containing layout is simpler
- fragment_transfer_detail_pieces no longer inside ScrollView, no need to scroll as our HexHiveView will only use remaining vertical space
- To make this work, view_transfer_detail_progress now has a fixed height, otherwise the folder icon would go towards the center of the screen
* [android] fix to the height of the detail_progress layout
* [android] very wip hex drawing experiments
* [android] Update Translations: French and Italian
* [android] HexView advances
- New DrawingProperties object is used to create buffer objects and useful constants for drawing the hexagonal hive
- drawing functions refactored to reduce the number of parameter copies on each onDraw iteration
- more cleanup to be done, gotta take into consideration real pixel width of hexagon borders when moving along the hive
* [android] hex fill logic implemented, wip, more fixes needed to calculate right max hex side length
* [android] fixed color assigment bug, only repaint when number of pieces downloaded has changed
* [android] made debug drawing an XML attribute. Better aproximation on desired hexagon length, still need to account for maximum rows.
* [android] simplifications
* [android] unneded file
* [android] 2.0.0 (beta) build 473
* [android] stricter checks initializing UIBittorrentDownload
* [android] no need to import Objects
* [android] Update Translation: German
* [android] NPE bullet proofing
My guess is that the NPE reported on detailProgressStatusTextView.setText(transferStateStrings.get(uiBittorrentDownload.getState())); wasn't due
to the view being null, but to the transferStateStrings object being null due to possible synchronization issues with TransferStateStrings.getInstance()
To make sure this doesn't happen, I perform another check later on, and if we've been wrongly assigned a null value, we request the singleton again.
* [android] rebasing left-overs
* [android] math brainfart calculating Y position of rows fixed
* [android] hex hive drawing fixes
* [android] cube-piece drawing support
* [android] upgrades
- don't animate tabs when touching tab title
- new CubePaint object extends Paint and calculates and keeps colors for dark left cube face and light top face out of the given fill color which is used on the right side face
* [android] adds URL validation when adding or editing trackers
* [android] fix bug with active time and seeding time calculation
when context menu actions are invoked they invoke onTime() on the underlying activity (Context that implements TimerObserver)
cleanup
* [android] s/delete/remove torrent and data/ menu entry
* [android] cleanup
* [android] avoid Runtime error trying to open transfer with no infoHash/"
Frostwire,[android] removal of static Context reference in Librarian to avoid memory leaks/
Frostwire,"[android] Dataflow issues, inverted methods that were always used in negation/"
Frostwire,"[WIP] Frostwire 2.0 (#624)
* [android] new layouts for the transfer detail pages
* [android] initial set up for the transfer detail activity
* [android] added toolbar menu to TransferDetails
* [android] Extended AbstractFragment from the remaining transfer detail screens
* [android] cleanup in TransferDetailActivity
* [android] added status tab to transfer details, code cleanup
* [android] added status layout to torrent details, layout code cleanup and headers
* [android] added resource values for transfer detail activity
* [android] removed unnecessary styles
* [android] adjusted style of the view_transfer_list_item
* [android] replaced missing style in view_transfer_item_list_item.xml
* [android] minor adjustement in dividers of view_transfer_list_item.xml
* [android] Transfer detail fragments reused. cleanup on fragment classes
* [android] TransferDetailActivity refactor. New AbstractTransferDetailFragment.
* [android] remove setContext hack, do it the android way
* [android] cleanup
* [android] TransferManager::getBittorrentDownload(String infoHash)
* [android] plugged BittorrentDownload object all the way to fragments
Common section with title and progress plugged. Next transfer status and upload/download speed in that common section
* [android] plugged transfer status string into common progress component
- New TransferStateStrings singleton class to map transfer states to strings
- TransferListAdapter refactored to use new TransferStateStrings
* [android] plugged download and upload speeds on common progress panel
* [android] transfer detail > status > Completed plugged
renamed some of the textviews to have a '_label' suffix
* [desktop] CommonUtils cleanup
* [android] Transfer Detail > Status > Time remaining plugged
* [android] Transfer Details, Status tab done
* [android] abort updateDetailProgress when transfer is null
* [android] transfer details layout cleanup
* [android] adding a recyclerview to Details, moved mock layout for its views to fragment_transfer_detail_files_recyclerview_item.xml
* [android] plugged number of files and total download size on FILES tab
* [android] started pluggin ReciclerView, still not working
* [android] got files showing on details > files. main transfer list broken, might transition to recycler view here too, testing with ListViewCompat (v7)
* [android] cleanup
* [android] cleanup
* [android] TransferFragment RecyclerView refactor (broken)
* [android] RecyclerView on TransfersFragment working
* [android] cleanup, component lookup optimization in Transfers Fragment
* [android] Progress on Transfer Detail > Details fragment
* [common] BTDownload.getTorrentHandle()
* [android] Details > Details > Comment section handled
* [android] Transfer Detail > Details tab.
Just have an issue with the 'Sequential Download' checkbox
* [android] updated torrent_details_files
* [android] progress on Transfers Details > Trackers tab
* [android] updated transfer detail trackers fragment layout
* [android] new UIUtils.showEditTextDialog
* [android] Transfer Detail > Trackers can add trackers to torrent
* [android] fixed width issues with individual tracker layout
* [android] minor refactor on TransferManager
* [android] TransferDetailStatusFragment doesn't crash on rotation
* [android] broken progress towards adding/editing trackers
* [android] fix another on rotation crash
* [android] uiBittorrentDownload is serialized and deserialized on screen rotation
* [android] set adapter after you've set the layout manager
* [android] adds and deletes trackers
* [android] trackers can be removed. edit text dialog can be configured for single/multi line
* [android] fixes issue where recycler views would not show items when tabs switched
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android] Transfer Details > Peers tab working
* [andriod] fixed build.gradle to use new plugin 3.0.0 DSL
* [android] Details tab cleanup.
- Removed 'Seeding On' checkbox. That can be handled with action bar controls for seeding/pausing
- Dialog button handlers now use lambdas
* [android] don't refresh tab if not visible cleanup
* [android] Transfer Details > Pieces tab (not working correctly)
Also lint cleanup on the activity and related fragments
* [android] few minor changes to transfer detail layouts
* [android] added and updated icons for the view_transfer_list_item
* [android] set up for the right side transfer item actions
* [android] pieces colors work, had to do r.getColor(). refactor
* [android] First pass at setting the media type icon on transfer list items
* [common] BittorrentDownload::getPredominantFileExtension()
* [android] uses BittorrentDownload's getPredominantFileExtension() to determine transfer media icon
* [android] show missing /s on transfer detail speed indicators
* [android] warning cleanup on ClickAdapter<T>
* [android] Details button on TransferListAdapter works.
TransferListAdapter refactored so that we only have a single instance for every click listener, not individual listeners for every view created
* [android] found inconsistency between download and upload rate unlimited values in libtorrent, cleanup
* [android] fixed overlapping of the text on view_transfer_detail_peer_item
* [android] updated TransferDetailDetails dialog title
* [android] added appropriate padding to the pieces view in transfer detail
* [android] fixes rotation crashes. refactors to deal with rotation
if for some reason getting pieces takes a while, an indeterminate progress bar is shown in place of the pieces
other rotation bugs fixed, more robust behavior
* [android] files becomes the first, and default selected tab
* [android] remove timer subscription responsibility from fragments
Use only one TimeObserver subscriber defined in the TransferDetailActivity.
Fragments still implement TimerObserver, have the single subscriber instance invoke the fragment's onTime method
only on the currently active fragment
* [android] SectionsPagerAdapter doesn't need to keep a reference to activity
- Just pass a SparseArray with the string resources it actually needs
- Implements a new OnPageChangeListener that keeps track of what the current fragment is
- When current fragment changes invoke onTime() on it
- Implements TimerObserver on the activity which delegates an onTime() call to the current fragment
* [android] isVisible() check no longer necessary
also found out that in some cases, isVisible() would give a false negative
* [android] more work towards avoiding issues on rotation and fast tab changes
* [android] import cleanup, if unwraps
* [android] stick to empty default constructors on YouTubeDownloadDialog
* [android] lint warnings, import cleanups
* [android] semi-aldenization of fragment code, still rotation issues
* [android] move all init calls to initComponents
* [android] cleanup. still issues on rotation, fragments not being added after rotation
* [android] finally resolved rotation issue
It seems the pager adapter and the programatic approach to adding transfers ended up in fragments not being able to be tracked correctly by their tags when the activity was reloaded.
Some of the fragments we ended up with inside detailFragments[] wouldn't be added, however, we luckily have methods in the parent AbstractFragment class to keep track of fragments that have been added (since Android only provides these after API 21 or so), by looking at the added fragments I'm able to find the correct instance and replace it inside our internal detailFragments array.
Writing this commit message makes me want to use that list, and get rid of the internal detailFragments array, to keep track of the fragments used, they could easily be filtered if they're instances of AbstractTransferDetailFragment
* [android] edit text dialog is now an extension of AbstractDialog
* [android] EditTextDialog moved to its own file, handles screen rotation
* [android] removed unused vars
* [android] rotation bug finally fixed
* [android] inline call
* [android] Transfer > Status > Time left only shown when downloading
* [android] transfer detail tab layout cleanup
* [android] transfer details details speed limit dialog issues
- When transfers are first created their upload/download rate limits come as -1
- When you want to set them to -1 for unlimited, this does not go well. You have to use 0 for unlimited, after that, they return 0
- Added a dialog closed listener that refreshes the fragment on close so new rate limit is reflected on the ui right away
* [android] remove tracker dialog look is uniform. UIUtil.showYesNoDialog now uses YesNoDialog.
* [android] don't hide time left textview, show 0 instead
* [android] progress with transfer details action bar menu
* [android] logic fix with pause/resume action bar action
* [android] updated action bar icons, added new resume aciton bar icon
* [android] removed double resume action
That action is not on the main branch, it was added later - it said resume but it was starting to seed even with seeding settings off.
* [android] updated icons for resume and cancel context menu action
* [android] added action bar seed icon
* [android] removed repeating action menu option
* [android] fixed and updated action_bar_seed icons
Sorry saved them with a wrong setting, looked pixelated
* [android] better logic on pause, resume, seed
* [android] added clear option on details.
cancel menu action uses the proper icon depending on the parameters
* [android] removed Open action from details, files are already there for individual access
* [android] added action_bar_stop_transfer icon
* [android] seeding|pausing made left most action. delete transfer sent to the context menu and cancel transfer the 2nd action shown only if room is available
* [android] use SeedAction when seedable
* [android] Update Translation: Spanish
* [android] Update Translation: Portuguese
* [android] start of HexHiveView for piece display, bye RecyclerView in this fragment
* [android] detail pieces layout cleanup
* [android] updated files and trackers layouts
RecyclerViewer no longer moves independently from the rest of hte scroll view - better user experience on small screens and horizontal views.
Fixed the files tab to open lower then top of the page.
The issue was connected to recycleviewer receiving the focus.
* [android] calculate height of other components to correctly measure height for hexhiveview
* [android] HexHiveView sizing issues fixed
- No need to manually calculate bounds when the containing layout is simpler
- fragment_transfer_detail_pieces no longer inside ScrollView, no need to scroll as our HexHiveView will only use remaining vertical space
- To make this work, view_transfer_detail_progress now has a fixed height, otherwise the folder icon would go towards the center of the screen
* [android] fix to the height of the detail_progress layout
* [android] very wip hex drawing experiments
* [android] Update Translations: French and Italian
* [android] HexView advances
- New DrawingProperties object is used to create buffer objects and useful constants for drawing the hexagonal hive
- drawing functions refactored to reduce the number of parameter copies on each onDraw iteration
- more cleanup to be done, gotta take into consideration real pixel width of hexagon borders when moving along the hive
* [android] hex fill logic implemented, wip, more fixes needed to calculate right max hex side length
* [android] fixed color assigment bug, only repaint when number of pieces downloaded has changed
* [android] made debug drawing an XML attribute. Better aproximation on desired hexagon length, still need to account for maximum rows.
* [android] simplifications
* [android] unneded file
* [android] 2.0.0 (beta) build 473
* [android] stricter checks initializing UIBittorrentDownload
* [android] no need to import Objects
* [android] Update Translation: German
* [android] NPE bullet proofing
My guess is that the NPE reported on detailProgressStatusTextView.setText(transferStateStrings.get(uiBittorrentDownload.getState())); wasn't due
to the view being null, but to the transferStateStrings object being null due to possible synchronization issues with TransferStateStrings.getInstance()
To make sure this doesn't happen, I perform another check later on, and if we've been wrongly assigned a null value, we request the singleton again.
* [android] rebasing left-overs
* [android] math brainfart calculating Y position of rows fixed
* [android] hex hive drawing fixes
* [android] cube-piece drawing support
* [android] upgrades
- don't animate tabs when touching tab title
- new CubePaint object extends Paint and calculates and keeps colors for dark left cube face and light top face out of the given fill color which is used on the right side face
* [android] adds URL validation when adding or editing trackers
* [android] fix bug with active time and seeding time calculation
when context menu actions are invoked they invoke onTime() on the underlying activity (Context that implements TimerObserver)
cleanup
* [android] s/delete/remove torrent and data/ menu entry
* [android] cleanup
* [android] avoid Runtime error trying to open transfer with no infoHash/"
Frostwire,"[WIP] Frostwire 2.0 (#624)
* [android] new layouts for the transfer detail pages
* [android] initial set up for the transfer detail activity
* [android] added toolbar menu to TransferDetails
* [android] Extended AbstractFragment from the remaining transfer detail screens
* [android] cleanup in TransferDetailActivity
* [android] added status tab to transfer details, code cleanup
* [android] added status layout to torrent details, layout code cleanup and headers
* [android] added resource values for transfer detail activity
* [android] removed unnecessary styles
* [android] adjusted style of the view_transfer_list_item
* [android] replaced missing style in view_transfer_item_list_item.xml
* [android] minor adjustement in dividers of view_transfer_list_item.xml
* [android] Transfer detail fragments reused. cleanup on fragment classes
* [android] TransferDetailActivity refactor. New AbstractTransferDetailFragment.
* [android] remove setContext hack, do it the android way
* [android] cleanup
* [android] TransferManager::getBittorrentDownload(String infoHash)
* [android] plugged BittorrentDownload object all the way to fragments
Common section with title and progress plugged. Next transfer status and upload/download speed in that common section
* [android] plugged transfer status string into common progress component
- New TransferStateStrings singleton class to map transfer states to strings
- TransferListAdapter refactored to use new TransferStateStrings
* [android] plugged download and upload speeds on common progress panel
* [android] transfer detail > status > Completed plugged
renamed some of the textviews to have a '_label' suffix
* [desktop] CommonUtils cleanup
* [android] Transfer Detail > Status > Time remaining plugged
* [android] Transfer Details, Status tab done
* [android] abort updateDetailProgress when transfer is null
* [android] transfer details layout cleanup
* [android] adding a recyclerview to Details, moved mock layout for its views to fragment_transfer_detail_files_recyclerview_item.xml
* [android] plugged number of files and total download size on FILES tab
* [android] started pluggin ReciclerView, still not working
* [android] got files showing on details > files. main transfer list broken, might transition to recycler view here too, testing with ListViewCompat (v7)
* [android] cleanup
* [android] cleanup
* [android] TransferFragment RecyclerView refactor (broken)
* [android] RecyclerView on TransfersFragment working
* [android] cleanup, component lookup optimization in Transfers Fragment
* [android] Progress on Transfer Detail > Details fragment
* [common] BTDownload.getTorrentHandle()
* [android] Details > Details > Comment section handled
* [android] Transfer Detail > Details tab.
Just have an issue with the 'Sequential Download' checkbox
* [android] updated torrent_details_files
* [android] progress on Transfers Details > Trackers tab
* [android] updated transfer detail trackers fragment layout
* [android] new UIUtils.showEditTextDialog
* [android] Transfer Detail > Trackers can add trackers to torrent
* [android] fixed width issues with individual tracker layout
* [android] minor refactor on TransferManager
* [android] TransferDetailStatusFragment doesn't crash on rotation
* [android] broken progress towards adding/editing trackers
* [android] fix another on rotation crash
* [android] uiBittorrentDownload is serialized and deserialized on screen rotation
* [android] set adapter after you've set the layout manager
* [android] adds and deletes trackers
* [android] trackers can be removed. edit text dialog can be configured for single/multi line
* [android] fixes issue where recycler views would not show items when tabs switched
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android] Transfer Details > Peers tab working
* [andriod] fixed build.gradle to use new plugin 3.0.0 DSL
* [android] Details tab cleanup.
- Removed 'Seeding On' checkbox. That can be handled with action bar controls for seeding/pausing
- Dialog button handlers now use lambdas
* [android] don't refresh tab if not visible cleanup
* [android] Transfer Details > Pieces tab (not working correctly)
Also lint cleanup on the activity and related fragments
* [android] few minor changes to transfer detail layouts
* [android] added and updated icons for the view_transfer_list_item
* [android] set up for the right side transfer item actions
* [android] pieces colors work, had to do r.getColor(). refactor
* [android] First pass at setting the media type icon on transfer list items
* [common] BittorrentDownload::getPredominantFileExtension()
* [android] uses BittorrentDownload's getPredominantFileExtension() to determine transfer media icon
* [android] show missing /s on transfer detail speed indicators
* [android] warning cleanup on ClickAdapter<T>
* [android] Details button on TransferListAdapter works.
TransferListAdapter refactored so that we only have a single instance for every click listener, not individual listeners for every view created
* [android] found inconsistency between download and upload rate unlimited values in libtorrent, cleanup
* [android] fixed overlapping of the text on view_transfer_detail_peer_item
* [android] updated TransferDetailDetails dialog title
* [android] added appropriate padding to the pieces view in transfer detail
* [android] fixes rotation crashes. refactors to deal with rotation
if for some reason getting pieces takes a while, an indeterminate progress bar is shown in place of the pieces
other rotation bugs fixed, more robust behavior
* [android] files becomes the first, and default selected tab
* [android] remove timer subscription responsibility from fragments
Use only one TimeObserver subscriber defined in the TransferDetailActivity.
Fragments still implement TimerObserver, have the single subscriber instance invoke the fragment's onTime method
only on the currently active fragment
* [android] SectionsPagerAdapter doesn't need to keep a reference to activity
- Just pass a SparseArray with the string resources it actually needs
- Implements a new OnPageChangeListener that keeps track of what the current fragment is
- When current fragment changes invoke onTime() on it
- Implements TimerObserver on the activity which delegates an onTime() call to the current fragment
* [android] isVisible() check no longer necessary
also found out that in some cases, isVisible() would give a false negative
* [android] more work towards avoiding issues on rotation and fast tab changes
* [android] import cleanup, if unwraps
* [android] stick to empty default constructors on YouTubeDownloadDialog
* [android] lint warnings, import cleanups
* [android] semi-aldenization of fragment code, still rotation issues
* [android] move all init calls to initComponents
* [android] cleanup. still issues on rotation, fragments not being added after rotation
* [android] finally resolved rotation issue
It seems the pager adapter and the programatic approach to adding transfers ended up in fragments not being able to be tracked correctly by their tags when the activity was reloaded.
Some of the fragments we ended up with inside detailFragments[] wouldn't be added, however, we luckily have methods in the parent AbstractFragment class to keep track of fragments that have been added (since Android only provides these after API 21 or so), by looking at the added fragments I'm able to find the correct instance and replace it inside our internal detailFragments array.
Writing this commit message makes me want to use that list, and get rid of the internal detailFragments array, to keep track of the fragments used, they could easily be filtered if they're instances of AbstractTransferDetailFragment
* [android] edit text dialog is now an extension of AbstractDialog
* [android] EditTextDialog moved to its own file, handles screen rotation
* [android] removed unused vars
* [android] rotation bug finally fixed
* [android] inline call
* [android] Transfer > Status > Time left only shown when downloading
* [android] transfer detail tab layout cleanup
* [android] transfer details details speed limit dialog issues
- When transfers are first created their upload/download rate limits come as -1
- When you want to set them to -1 for unlimited, this does not go well. You have to use 0 for unlimited, after that, they return 0
- Added a dialog closed listener that refreshes the fragment on close so new rate limit is reflected on the ui right away
* [android] remove tracker dialog look is uniform. UIUtil.showYesNoDialog now uses YesNoDialog.
* [android] don't hide time left textview, show 0 instead
* [android] progress with transfer details action bar menu
* [android] logic fix with pause/resume action bar action
* [android] updated action bar icons, added new resume aciton bar icon
* [android] removed double resume action
That action is not on the main branch, it was added later - it said resume but it was starting to seed even with seeding settings off.
* [android] updated icons for resume and cancel context menu action
* [android] added action bar seed icon
* [android] removed repeating action menu option
* [android] fixed and updated action_bar_seed icons
Sorry saved them with a wrong setting, looked pixelated
* [android] better logic on pause, resume, seed
* [android] added clear option on details.
cancel menu action uses the proper icon depending on the parameters
* [android] removed Open action from details, files are already there for individual access
* [android] added action_bar_stop_transfer icon
* [android] seeding|pausing made left most action. delete transfer sent to the context menu and cancel transfer the 2nd action shown only if room is available
* [android] use SeedAction when seedable
* [android] Update Translation: Spanish
* [android] Update Translation: Portuguese
* [android] start of HexHiveView for piece display, bye RecyclerView in this fragment
* [android] detail pieces layout cleanup
* [android] updated files and trackers layouts
RecyclerViewer no longer moves independently from the rest of hte scroll view - better user experience on small screens and horizontal views.
Fixed the files tab to open lower then top of the page.
The issue was connected to recycleviewer receiving the focus.
* [android] calculate height of other components to correctly measure height for hexhiveview
* [android] HexHiveView sizing issues fixed
- No need to manually calculate bounds when the containing layout is simpler
- fragment_transfer_detail_pieces no longer inside ScrollView, no need to scroll as our HexHiveView will only use remaining vertical space
- To make this work, view_transfer_detail_progress now has a fixed height, otherwise the folder icon would go towards the center of the screen
* [android] fix to the height of the detail_progress layout
* [android] very wip hex drawing experiments
* [android] Update Translations: French and Italian
* [android] HexView advances
- New DrawingProperties object is used to create buffer objects and useful constants for drawing the hexagonal hive
- drawing functions refactored to reduce the number of parameter copies on each onDraw iteration
- more cleanup to be done, gotta take into consideration real pixel width of hexagon borders when moving along the hive
* [android] hex fill logic implemented, wip, more fixes needed to calculate right max hex side length
* [android] fixed color assigment bug, only repaint when number of pieces downloaded has changed
* [android] made debug drawing an XML attribute. Better aproximation on desired hexagon length, still need to account for maximum rows.
* [android] simplifications
* [android] unneded file
* [android] 2.0.0 (beta) build 473
* [android] stricter checks initializing UIBittorrentDownload
* [android] no need to import Objects
* [android] Update Translation: German
* [android] NPE bullet proofing
My guess is that the NPE reported on detailProgressStatusTextView.setText(transferStateStrings.get(uiBittorrentDownload.getState())); wasn't due
to the view being null, but to the transferStateStrings object being null due to possible synchronization issues with TransferStateStrings.getInstance()
To make sure this doesn't happen, I perform another check later on, and if we've been wrongly assigned a null value, we request the singleton again.
* [android] rebasing left-overs
* [android] math brainfart calculating Y position of rows fixed
* [android] hex hive drawing fixes
* [android] cube-piece drawing support
* [android] upgrades
- don't animate tabs when touching tab title
- new CubePaint object extends Paint and calculates and keeps colors for dark left cube face and light top face out of the given fill color which is used on the right side face
* [android] adds URL validation when adding or editing trackers
* [android] fix bug with active time and seeding time calculation
when context menu actions are invoked they invoke onTime() on the underlying activity (Context that implements TimerObserver)
cleanup
* [android] s/delete/remove torrent and data/ menu entry
* [android] cleanup
* [android] avoid Runtime error trying to open transfer with no infoHash/[android] removal of static Context reference in Librarian to avoid memory leaks/"
Frostwire,"[WIP] Frostwire 2.0 (#624)
* [android] new layouts for the transfer detail pages
* [android] initial set up for the transfer detail activity
* [android] added toolbar menu to TransferDetails
* [android] Extended AbstractFragment from the remaining transfer detail screens
* [android] cleanup in TransferDetailActivity
* [android] added status tab to transfer details, code cleanup
* [android] added status layout to torrent details, layout code cleanup and headers
* [android] added resource values for transfer detail activity
* [android] removed unnecessary styles
* [android] adjusted style of the view_transfer_list_item
* [android] replaced missing style in view_transfer_item_list_item.xml
* [android] minor adjustement in dividers of view_transfer_list_item.xml
* [android] Transfer detail fragments reused. cleanup on fragment classes
* [android] TransferDetailActivity refactor. New AbstractTransferDetailFragment.
* [android] remove setContext hack, do it the android way
* [android] cleanup
* [android] TransferManager::getBittorrentDownload(String infoHash)
* [android] plugged BittorrentDownload object all the way to fragments
Common section with title and progress plugged. Next transfer status and upload/download speed in that common section
* [android] plugged transfer status string into common progress component
- New TransferStateStrings singleton class to map transfer states to strings
- TransferListAdapter refactored to use new TransferStateStrings
* [android] plugged download and upload speeds on common progress panel
* [android] transfer detail > status > Completed plugged
renamed some of the textviews to have a '_label' suffix
* [desktop] CommonUtils cleanup
* [android] Transfer Detail > Status > Time remaining plugged
* [android] Transfer Details, Status tab done
* [android] abort updateDetailProgress when transfer is null
* [android] transfer details layout cleanup
* [android] adding a recyclerview to Details, moved mock layout for its views to fragment_transfer_detail_files_recyclerview_item.xml
* [android] plugged number of files and total download size on FILES tab
* [android] started pluggin ReciclerView, still not working
* [android] got files showing on details > files. main transfer list broken, might transition to recycler view here too, testing with ListViewCompat (v7)
* [android] cleanup
* [android] cleanup
* [android] TransferFragment RecyclerView refactor (broken)
* [android] RecyclerView on TransfersFragment working
* [android] cleanup, component lookup optimization in Transfers Fragment
* [android] Progress on Transfer Detail > Details fragment
* [common] BTDownload.getTorrentHandle()
* [android] Details > Details > Comment section handled
* [android] Transfer Detail > Details tab.
Just have an issue with the 'Sequential Download' checkbox
* [android] updated torrent_details_files
* [android] progress on Transfers Details > Trackers tab
* [android] updated transfer detail trackers fragment layout
* [android] new UIUtils.showEditTextDialog
* [android] Transfer Detail > Trackers can add trackers to torrent
* [android] fixed width issues with individual tracker layout
* [android] minor refactor on TransferManager
* [android] TransferDetailStatusFragment doesn't crash on rotation
* [android] broken progress towards adding/editing trackers
* [android] fix another on rotation crash
* [android] uiBittorrentDownload is serialized and deserialized on screen rotation
* [android] set adapter after you've set the layout manager
* [android] adds and deletes trackers
* [android] trackers can be removed. edit text dialog can be configured for single/multi line
* [android] fixes issue where recycler views would not show items when tabs switched
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android] Transfer Details > Peers tab working
* [andriod] fixed build.gradle to use new plugin 3.0.0 DSL
* [android] Details tab cleanup.
- Removed 'Seeding On' checkbox. That can be handled with action bar controls for seeding/pausing
- Dialog button handlers now use lambdas
* [android] don't refresh tab if not visible cleanup
* [android] Transfer Details > Pieces tab (not working correctly)
Also lint cleanup on the activity and related fragments
* [android] few minor changes to transfer detail layouts
* [android] added and updated icons for the view_transfer_list_item
* [android] set up for the right side transfer item actions
* [android] pieces colors work, had to do r.getColor(). refactor
* [android] First pass at setting the media type icon on transfer list items
* [common] BittorrentDownload::getPredominantFileExtension()
* [android] uses BittorrentDownload's getPredominantFileExtension() to determine transfer media icon
* [android] show missing /s on transfer detail speed indicators
* [android] warning cleanup on ClickAdapter<T>
* [android] Details button on TransferListAdapter works.
TransferListAdapter refactored so that we only have a single instance for every click listener, not individual listeners for every view created
* [android] found inconsistency between download and upload rate unlimited values in libtorrent, cleanup
* [android] fixed overlapping of the text on view_transfer_detail_peer_item
* [android] updated TransferDetailDetails dialog title
* [android] added appropriate padding to the pieces view in transfer detail
* [android] fixes rotation crashes. refactors to deal with rotation
if for some reason getting pieces takes a while, an indeterminate progress bar is shown in place of the pieces
other rotation bugs fixed, more robust behavior
* [android] files becomes the first, and default selected tab
* [android] remove timer subscription responsibility from fragments
Use only one TimeObserver subscriber defined in the TransferDetailActivity.
Fragments still implement TimerObserver, have the single subscriber instance invoke the fragment's onTime method
only on the currently active fragment
* [android] SectionsPagerAdapter doesn't need to keep a reference to activity
- Just pass a SparseArray with the string resources it actually needs
- Implements a new OnPageChangeListener that keeps track of what the current fragment is
- When current fragment changes invoke onTime() on it
- Implements TimerObserver on the activity which delegates an onTime() call to the current fragment
* [android] isVisible() check no longer necessary
also found out that in some cases, isVisible() would give a false negative
* [android] more work towards avoiding issues on rotation and fast tab changes
* [android] import cleanup, if unwraps
* [android] stick to empty default constructors on YouTubeDownloadDialog
* [android] lint warnings, import cleanups
* [android] semi-aldenization of fragment code, still rotation issues
* [android] move all init calls to initComponents
* [android] cleanup. still issues on rotation, fragments not being added after rotation
* [android] finally resolved rotation issue
It seems the pager adapter and the programatic approach to adding transfers ended up in fragments not being able to be tracked correctly by their tags when the activity was reloaded.
Some of the fragments we ended up with inside detailFragments[] wouldn't be added, however, we luckily have methods in the parent AbstractFragment class to keep track of fragments that have been added (since Android only provides these after API 21 or so), by looking at the added fragments I'm able to find the correct instance and replace it inside our internal detailFragments array.
Writing this commit message makes me want to use that list, and get rid of the internal detailFragments array, to keep track of the fragments used, they could easily be filtered if they're instances of AbstractTransferDetailFragment
* [android] edit text dialog is now an extension of AbstractDialog
* [android] EditTextDialog moved to its own file, handles screen rotation
* [android] removed unused vars
* [android] rotation bug finally fixed
* [android] inline call
* [android] Transfer > Status > Time left only shown when downloading
* [android] transfer detail tab layout cleanup
* [android] transfer details details speed limit dialog issues
- When transfers are first created their upload/download rate limits come as -1
- When you want to set them to -1 for unlimited, this does not go well. You have to use 0 for unlimited, after that, they return 0
- Added a dialog closed listener that refreshes the fragment on close so new rate limit is reflected on the ui right away
* [android] remove tracker dialog look is uniform. UIUtil.showYesNoDialog now uses YesNoDialog.
* [android] don't hide time left textview, show 0 instead
* [android] progress with transfer details action bar menu
* [android] logic fix with pause/resume action bar action
* [android] updated action bar icons, added new resume aciton bar icon
* [android] removed double resume action
That action is not on the main branch, it was added later - it said resume but it was starting to seed even with seeding settings off.
* [android] updated icons for resume and cancel context menu action
* [android] added action bar seed icon
* [android] removed repeating action menu option
* [android] fixed and updated action_bar_seed icons
Sorry saved them with a wrong setting, looked pixelated
* [android] better logic on pause, resume, seed
* [android] added clear option on details.
cancel menu action uses the proper icon depending on the parameters
* [android] removed Open action from details, files are already there for individual access
* [android] added action_bar_stop_transfer icon
* [android] seeding|pausing made left most action. delete transfer sent to the context menu and cancel transfer the 2nd action shown only if room is available
* [android] use SeedAction when seedable
* [android] Update Translation: Spanish
* [android] Update Translation: Portuguese
* [android] start of HexHiveView for piece display, bye RecyclerView in this fragment
* [android] detail pieces layout cleanup
* [android] updated files and trackers layouts
RecyclerViewer no longer moves independently from the rest of hte scroll view - better user experience on small screens and horizontal views.
Fixed the files tab to open lower then top of the page.
The issue was connected to recycleviewer receiving the focus.
* [android] calculate height of other components to correctly measure height for hexhiveview
* [android] HexHiveView sizing issues fixed
- No need to manually calculate bounds when the containing layout is simpler
- fragment_transfer_detail_pieces no longer inside ScrollView, no need to scroll as our HexHiveView will only use remaining vertical space
- To make this work, view_transfer_detail_progress now has a fixed height, otherwise the folder icon would go towards the center of the screen
* [android] fix to the height of the detail_progress layout
* [android] very wip hex drawing experiments
* [android] Update Translations: French and Italian
* [android] HexView advances
- New DrawingProperties object is used to create buffer objects and useful constants for drawing the hexagonal hive
- drawing functions refactored to reduce the number of parameter copies on each onDraw iteration
- more cleanup to be done, gotta take into consideration real pixel width of hexagon borders when moving along the hive
* [android] hex fill logic implemented, wip, more fixes needed to calculate right max hex side length
* [android] fixed color assigment bug, only repaint when number of pieces downloaded has changed
* [android] made debug drawing an XML attribute. Better aproximation on desired hexagon length, still need to account for maximum rows.
* [android] simplifications
* [android] unneded file
* [android] 2.0.0 (beta) build 473
* [android] stricter checks initializing UIBittorrentDownload
* [android] no need to import Objects
* [android] Update Translation: German
* [android] NPE bullet proofing
My guess is that the NPE reported on detailProgressStatusTextView.setText(transferStateStrings.get(uiBittorrentDownload.getState())); wasn't due
to the view being null, but to the transferStateStrings object being null due to possible synchronization issues with TransferStateStrings.getInstance()
To make sure this doesn't happen, I perform another check later on, and if we've been wrongly assigned a null value, we request the singleton again.
* [android] rebasing left-overs
* [android] math brainfart calculating Y position of rows fixed
* [android] hex hive drawing fixes
* [android] cube-piece drawing support
* [android] upgrades
- don't animate tabs when touching tab title
- new CubePaint object extends Paint and calculates and keeps colors for dark left cube face and light top face out of the given fill color which is used on the right side face
* [android] adds URL validation when adding or editing trackers
* [android] fix bug with active time and seeding time calculation
when context menu actions are invoked they invoke onTime() on the underlying activity (Context that implements TimerObserver)
cleanup
* [android] s/delete/remove torrent and data/ menu entry
* [android] cleanup
* [android] avoid Runtime error trying to open transfer with no infoHash/"
Frostwire,"[WIP] Frostwire 2.0 (#624)
* [android] new layouts for the transfer detail pages
* [android] initial set up for the transfer detail activity
* [android] added toolbar menu to TransferDetails
* [android] Extended AbstractFragment from the remaining transfer detail screens
* [android] cleanup in TransferDetailActivity
* [android] added status tab to transfer details, code cleanup
* [android] added status layout to torrent details, layout code cleanup and headers
* [android] added resource values for transfer detail activity
* [android] removed unnecessary styles
* [android] adjusted style of the view_transfer_list_item
* [android] replaced missing style in view_transfer_item_list_item.xml
* [android] minor adjustement in dividers of view_transfer_list_item.xml
* [android] Transfer detail fragments reused. cleanup on fragment classes
* [android] TransferDetailActivity refactor. New AbstractTransferDetailFragment.
* [android] remove setContext hack, do it the android way
* [android] cleanup
* [android] TransferManager::getBittorrentDownload(String infoHash)
* [android] plugged BittorrentDownload object all the way to fragments
Common section with title and progress plugged. Next transfer status and upload/download speed in that common section
* [android] plugged transfer status string into common progress component
- New TransferStateStrings singleton class to map transfer states to strings
- TransferListAdapter refactored to use new TransferStateStrings
* [android] plugged download and upload speeds on common progress panel
* [android] transfer detail > status > Completed plugged
renamed some of the textviews to have a '_label' suffix
* [desktop] CommonUtils cleanup
* [android] Transfer Detail > Status > Time remaining plugged
* [android] Transfer Details, Status tab done
* [android] abort updateDetailProgress when transfer is null
* [android] transfer details layout cleanup
* [android] adding a recyclerview to Details, moved mock layout for its views to fragment_transfer_detail_files_recyclerview_item.xml
* [android] plugged number of files and total download size on FILES tab
* [android] started pluggin ReciclerView, still not working
* [android] got files showing on details > files. main transfer list broken, might transition to recycler view here too, testing with ListViewCompat (v7)
* [android] cleanup
* [android] cleanup
* [android] TransferFragment RecyclerView refactor (broken)
* [android] RecyclerView on TransfersFragment working
* [android] cleanup, component lookup optimization in Transfers Fragment
* [android] Progress on Transfer Detail > Details fragment
* [common] BTDownload.getTorrentHandle()
* [android] Details > Details > Comment section handled
* [android] Transfer Detail > Details tab.
Just have an issue with the 'Sequential Download' checkbox
* [android] updated torrent_details_files
* [android] progress on Transfers Details > Trackers tab
* [android] updated transfer detail trackers fragment layout
* [android] new UIUtils.showEditTextDialog
* [android] Transfer Detail > Trackers can add trackers to torrent
* [android] fixed width issues with individual tracker layout
* [android] minor refactor on TransferManager
* [android] TransferDetailStatusFragment doesn't crash on rotation
* [android] broken progress towards adding/editing trackers
* [android] fix another on rotation crash
* [android] uiBittorrentDownload is serialized and deserialized on screen rotation
* [android] set adapter after you've set the layout manager
* [android] adds and deletes trackers
* [android] trackers can be removed. edit text dialog can be configured for single/multi line
* [android] fixes issue where recycler views would not show items when tabs switched
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android] Transfer Details > Peers tab working
* [andriod] fixed build.gradle to use new plugin 3.0.0 DSL
* [android] Details tab cleanup.
- Removed 'Seeding On' checkbox. That can be handled with action bar controls for seeding/pausing
- Dialog button handlers now use lambdas
* [android] don't refresh tab if not visible cleanup
* [android] Transfer Details > Pieces tab (not working correctly)
Also lint cleanup on the activity and related fragments
* [android] few minor changes to transfer detail layouts
* [android] added and updated icons for the view_transfer_list_item
* [android] set up for the right side transfer item actions
* [android] pieces colors work, had to do r.getColor(). refactor
* [android] First pass at setting the media type icon on transfer list items
* [common] BittorrentDownload::getPredominantFileExtension()
* [android] uses BittorrentDownload's getPredominantFileExtension() to determine transfer media icon
* [android] show missing /s on transfer detail speed indicators
* [android] warning cleanup on ClickAdapter<T>
* [android] Details button on TransferListAdapter works.
TransferListAdapter refactored so that we only have a single instance for every click listener, not individual listeners for every view created
* [android] found inconsistency between download and upload rate unlimited values in libtorrent, cleanup
* [android] fixed overlapping of the text on view_transfer_detail_peer_item
* [android] updated TransferDetailDetails dialog title
* [android] added appropriate padding to the pieces view in transfer detail
* [android] fixes rotation crashes. refactors to deal with rotation
if for some reason getting pieces takes a while, an indeterminate progress bar is shown in place of the pieces
other rotation bugs fixed, more robust behavior
* [android] files becomes the first, and default selected tab
* [android] remove timer subscription responsibility from fragments
Use only one TimeObserver subscriber defined in the TransferDetailActivity.
Fragments still implement TimerObserver, have the single subscriber instance invoke the fragment's onTime method
only on the currently active fragment
* [android] SectionsPagerAdapter doesn't need to keep a reference to activity
- Just pass a SparseArray with the string resources it actually needs
- Implements a new OnPageChangeListener that keeps track of what the current fragment is
- When current fragment changes invoke onTime() on it
- Implements TimerObserver on the activity which delegates an onTime() call to the current fragment
* [android] isVisible() check no longer necessary
also found out that in some cases, isVisible() would give a false negative
* [android] more work towards avoiding issues on rotation and fast tab changes
* [android] import cleanup, if unwraps
* [android] stick to empty default constructors on YouTubeDownloadDialog
* [android] lint warnings, import cleanups
* [android] semi-aldenization of fragment code, still rotation issues
* [android] move all init calls to initComponents
* [android] cleanup. still issues on rotation, fragments not being added after rotation
* [android] finally resolved rotation issue
It seems the pager adapter and the programatic approach to adding transfers ended up in fragments not being able to be tracked correctly by their tags when the activity was reloaded.
Some of the fragments we ended up with inside detailFragments[] wouldn't be added, however, we luckily have methods in the parent AbstractFragment class to keep track of fragments that have been added (since Android only provides these after API 21 or so), by looking at the added fragments I'm able to find the correct instance and replace it inside our internal detailFragments array.
Writing this commit message makes me want to use that list, and get rid of the internal detailFragments array, to keep track of the fragments used, they could easily be filtered if they're instances of AbstractTransferDetailFragment
* [android] edit text dialog is now an extension of AbstractDialog
* [android] EditTextDialog moved to its own file, handles screen rotation
* [android] removed unused vars
* [android] rotation bug finally fixed
* [android] inline call
* [android] Transfer > Status > Time left only shown when downloading
* [android] transfer detail tab layout cleanup
* [android] transfer details details speed limit dialog issues
- When transfers are first created their upload/download rate limits come as -1
- When you want to set them to -1 for unlimited, this does not go well. You have to use 0 for unlimited, after that, they return 0
- Added a dialog closed listener that refreshes the fragment on close so new rate limit is reflected on the ui right away
* [android] remove tracker dialog look is uniform. UIUtil.showYesNoDialog now uses YesNoDialog.
* [android] don't hide time left textview, show 0 instead
* [android] progress with transfer details action bar menu
* [android] logic fix with pause/resume action bar action
* [android] updated action bar icons, added new resume aciton bar icon
* [android] removed double resume action
That action is not on the main branch, it was added later - it said resume but it was starting to seed even with seeding settings off.
* [android] updated icons for resume and cancel context menu action
* [android] added action bar seed icon
* [android] removed repeating action menu option
* [android] fixed and updated action_bar_seed icons
Sorry saved them with a wrong setting, looked pixelated
* [android] better logic on pause, resume, seed
* [android] added clear option on details.
cancel menu action uses the proper icon depending on the parameters
* [android] removed Open action from details, files are already there for individual access
* [android] added action_bar_stop_transfer icon
* [android] seeding|pausing made left most action. delete transfer sent to the context menu and cancel transfer the 2nd action shown only if room is available
* [android] use SeedAction when seedable
* [android] Update Translation: Spanish
* [android] Update Translation: Portuguese
* [android] start of HexHiveView for piece display, bye RecyclerView in this fragment
* [android] detail pieces layout cleanup
* [android] updated files and trackers layouts
RecyclerViewer no longer moves independently from the rest of hte scroll view - better user experience on small screens and horizontal views.
Fixed the files tab to open lower then top of the page.
The issue was connected to recycleviewer receiving the focus.
* [android] calculate height of other components to correctly measure height for hexhiveview
* [android] HexHiveView sizing issues fixed
- No need to manually calculate bounds when the containing layout is simpler
- fragment_transfer_detail_pieces no longer inside ScrollView, no need to scroll as our HexHiveView will only use remaining vertical space
- To make this work, view_transfer_detail_progress now has a fixed height, otherwise the folder icon would go towards the center of the screen
* [android] fix to the height of the detail_progress layout
* [android] very wip hex drawing experiments
* [android] Update Translations: French and Italian
* [android] HexView advances
- New DrawingProperties object is used to create buffer objects and useful constants for drawing the hexagonal hive
- drawing functions refactored to reduce the number of parameter copies on each onDraw iteration
- more cleanup to be done, gotta take into consideration real pixel width of hexagon borders when moving along the hive
* [android] hex fill logic implemented, wip, more fixes needed to calculate right max hex side length
* [android] fixed color assigment bug, only repaint when number of pieces downloaded has changed
* [android] made debug drawing an XML attribute. Better aproximation on desired hexagon length, still need to account for maximum rows.
* [android] simplifications
* [android] unneded file
* [android] 2.0.0 (beta) build 473
* [android] stricter checks initializing UIBittorrentDownload
* [android] no need to import Objects
* [android] Update Translation: German
* [android] NPE bullet proofing
My guess is that the NPE reported on detailProgressStatusTextView.setText(transferStateStrings.get(uiBittorrentDownload.getState())); wasn't due
to the view being null, but to the transferStateStrings object being null due to possible synchronization issues with TransferStateStrings.getInstance()
To make sure this doesn't happen, I perform another check later on, and if we've been wrongly assigned a null value, we request the singleton again.
* [android] rebasing left-overs
* [android] math brainfart calculating Y position of rows fixed
* [android] hex hive drawing fixes
* [android] cube-piece drawing support
* [android] upgrades
- don't animate tabs when touching tab title
- new CubePaint object extends Paint and calculates and keeps colors for dark left cube face and light top face out of the given fill color which is used on the right side face
* [android] adds URL validation when adding or editing trackers
* [android] fix bug with active time and seeding time calculation
when context menu actions are invoked they invoke onTime() on the underlying activity (Context that implements TimerObserver)
cleanup
* [android] s/delete/remove torrent and data/ menu entry
* [android] cleanup
* [android] avoid Runtime error trying to open transfer with no infoHash/"
Frostwire,[android] removal of static Context reference in Librarian to avoid memory leaks/
Frostwire,[android] don't fail silently. avoid context leak on thread/
Frostwire,"[WIP] Frostwire 2.0 (#624)
* [android] new layouts for the transfer detail pages
* [android] initial set up for the transfer detail activity
* [android] added toolbar menu to TransferDetails
* [android] Extended AbstractFragment from the remaining transfer detail screens
* [android] cleanup in TransferDetailActivity
* [android] added status tab to transfer details, code cleanup
* [android] added status layout to torrent details, layout code cleanup and headers
* [android] added resource values for transfer detail activity
* [android] removed unnecessary styles
* [android] adjusted style of the view_transfer_list_item
* [android] replaced missing style in view_transfer_item_list_item.xml
* [android] minor adjustement in dividers of view_transfer_list_item.xml
* [android] Transfer detail fragments reused. cleanup on fragment classes
* [android] TransferDetailActivity refactor. New AbstractTransferDetailFragment.
* [android] remove setContext hack, do it the android way
* [android] cleanup
* [android] TransferManager::getBittorrentDownload(String infoHash)
* [android] plugged BittorrentDownload object all the way to fragments
Common section with title and progress plugged. Next transfer status and upload/download speed in that common section
* [android] plugged transfer status string into common progress component
- New TransferStateStrings singleton class to map transfer states to strings
- TransferListAdapter refactored to use new TransferStateStrings
* [android] plugged download and upload speeds on common progress panel
* [android] transfer detail > status > Completed plugged
renamed some of the textviews to have a '_label' suffix
* [desktop] CommonUtils cleanup
* [android] Transfer Detail > Status > Time remaining plugged
* [android] Transfer Details, Status tab done
* [android] abort updateDetailProgress when transfer is null
* [android] transfer details layout cleanup
* [android] adding a recyclerview to Details, moved mock layout for its views to fragment_transfer_detail_files_recyclerview_item.xml
* [android] plugged number of files and total download size on FILES tab
* [android] started pluggin ReciclerView, still not working
* [android] got files showing on details > files. main transfer list broken, might transition to recycler view here too, testing with ListViewCompat (v7)
* [android] cleanup
* [android] cleanup
* [android] TransferFragment RecyclerView refactor (broken)
* [android] RecyclerView on TransfersFragment working
* [android] cleanup, component lookup optimization in Transfers Fragment
* [android] Progress on Transfer Detail > Details fragment
* [common] BTDownload.getTorrentHandle()
* [android] Details > Details > Comment section handled
* [android] Transfer Detail > Details tab.
Just have an issue with the 'Sequential Download' checkbox
* [android] updated torrent_details_files
* [android] progress on Transfers Details > Trackers tab
* [android] updated transfer detail trackers fragment layout
* [android] new UIUtils.showEditTextDialog
* [android] Transfer Detail > Trackers can add trackers to torrent
* [android] fixed width issues with individual tracker layout
* [android] minor refactor on TransferManager
* [android] TransferDetailStatusFragment doesn't crash on rotation
* [android] broken progress towards adding/editing trackers
* [android] fix another on rotation crash
* [android] uiBittorrentDownload is serialized and deserialized on screen rotation
* [android] set adapter after you've set the layout manager
* [android] adds and deletes trackers
* [android] trackers can be removed. edit text dialog can be configured for single/multi line
* [android] fixes issue where recycler views would not show items when tabs switched
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android] Transfer Details > Peers tab working
* [andriod] fixed build.gradle to use new plugin 3.0.0 DSL
* [android] Details tab cleanup.
- Removed 'Seeding On' checkbox. That can be handled with action bar controls for seeding/pausing
- Dialog button handlers now use lambdas
* [android] don't refresh tab if not visible cleanup
* [android] Transfer Details > Pieces tab (not working correctly)
Also lint cleanup on the activity and related fragments
* [android] few minor changes to transfer detail layouts
* [android] added and updated icons for the view_transfer_list_item
* [android] set up for the right side transfer item actions
* [android] pieces colors work, had to do r.getColor(). refactor
* [android] First pass at setting the media type icon on transfer list items
* [common] BittorrentDownload::getPredominantFileExtension()
* [android] uses BittorrentDownload's getPredominantFileExtension() to determine transfer media icon
* [android] show missing /s on transfer detail speed indicators
* [android] warning cleanup on ClickAdapter<T>
* [android] Details button on TransferListAdapter works.
TransferListAdapter refactored so that we only have a single instance for every click listener, not individual listeners for every view created
* [android] found inconsistency between download and upload rate unlimited values in libtorrent, cleanup
* [android] fixed overlapping of the text on view_transfer_detail_peer_item
* [android] updated TransferDetailDetails dialog title
* [android] added appropriate padding to the pieces view in transfer detail
* [android] fixes rotation crashes. refactors to deal with rotation
if for some reason getting pieces takes a while, an indeterminate progress bar is shown in place of the pieces
other rotation bugs fixed, more robust behavior
* [android] files becomes the first, and default selected tab
* [android] remove timer subscription responsibility from fragments
Use only one TimeObserver subscriber defined in the TransferDetailActivity.
Fragments still implement TimerObserver, have the single subscriber instance invoke the fragment's onTime method
only on the currently active fragment
* [android] SectionsPagerAdapter doesn't need to keep a reference to activity
- Just pass a SparseArray with the string resources it actually needs
- Implements a new OnPageChangeListener that keeps track of what the current fragment is
- When current fragment changes invoke onTime() on it
- Implements TimerObserver on the activity which delegates an onTime() call to the current fragment
* [android] isVisible() check no longer necessary
also found out that in some cases, isVisible() would give a false negative
* [android] more work towards avoiding issues on rotation and fast tab changes
* [android] import cleanup, if unwraps
* [android] stick to empty default constructors on YouTubeDownloadDialog
* [android] lint warnings, import cleanups
* [android] semi-aldenization of fragment code, still rotation issues
* [android] move all init calls to initComponents
* [android] cleanup. still issues on rotation, fragments not being added after rotation
* [android] finally resolved rotation issue
It seems the pager adapter and the programatic approach to adding transfers ended up in fragments not being able to be tracked correctly by their tags when the activity was reloaded.
Some of the fragments we ended up with inside detailFragments[] wouldn't be added, however, we luckily have methods in the parent AbstractFragment class to keep track of fragments that have been added (since Android only provides these after API 21 or so), by looking at the added fragments I'm able to find the correct instance and replace it inside our internal detailFragments array.
Writing this commit message makes me want to use that list, and get rid of the internal detailFragments array, to keep track of the fragments used, they could easily be filtered if they're instances of AbstractTransferDetailFragment
* [android] edit text dialog is now an extension of AbstractDialog
* [android] EditTextDialog moved to its own file, handles screen rotation
* [android] removed unused vars
* [android] rotation bug finally fixed
* [android] inline call
* [android] Transfer > Status > Time left only shown when downloading
* [android] transfer detail tab layout cleanup
* [android] transfer details details speed limit dialog issues
- When transfers are first created their upload/download rate limits come as -1
- When you want to set them to -1 for unlimited, this does not go well. You have to use 0 for unlimited, after that, they return 0
- Added a dialog closed listener that refreshes the fragment on close so new rate limit is reflected on the ui right away
* [android] remove tracker dialog look is uniform. UIUtil.showYesNoDialog now uses YesNoDialog.
* [android] don't hide time left textview, show 0 instead
* [android] progress with transfer details action bar menu
* [android] logic fix with pause/resume action bar action
* [android] updated action bar icons, added new resume aciton bar icon
* [android] removed double resume action
That action is not on the main branch, it was added later - it said resume but it was starting to seed even with seeding settings off.
* [android] updated icons for resume and cancel context menu action
* [android] added action bar seed icon
* [android] removed repeating action menu option
* [android] fixed and updated action_bar_seed icons
Sorry saved them with a wrong setting, looked pixelated
* [android] better logic on pause, resume, seed
* [android] added clear option on details.
cancel menu action uses the proper icon depending on the parameters
* [android] removed Open action from details, files are already there for individual access
* [android] added action_bar_stop_transfer icon
* [android] seeding|pausing made left most action. delete transfer sent to the context menu and cancel transfer the 2nd action shown only if room is available
* [android] use SeedAction when seedable
* [android] Update Translation: Spanish
* [android] Update Translation: Portuguese
* [android] start of HexHiveView for piece display, bye RecyclerView in this fragment
* [android] detail pieces layout cleanup
* [android] updated files and trackers layouts
RecyclerViewer no longer moves independently from the rest of hte scroll view - better user experience on small screens and horizontal views.
Fixed the files tab to open lower then top of the page.
The issue was connected to recycleviewer receiving the focus.
* [android] calculate height of other components to correctly measure height for hexhiveview
* [android] HexHiveView sizing issues fixed
- No need to manually calculate bounds when the containing layout is simpler
- fragment_transfer_detail_pieces no longer inside ScrollView, no need to scroll as our HexHiveView will only use remaining vertical space
- To make this work, view_transfer_detail_progress now has a fixed height, otherwise the folder icon would go towards the center of the screen
* [android] fix to the height of the detail_progress layout
* [android] very wip hex drawing experiments
* [android] Update Translations: French and Italian
* [android] HexView advances
- New DrawingProperties object is used to create buffer objects and useful constants for drawing the hexagonal hive
- drawing functions refactored to reduce the number of parameter copies on each onDraw iteration
- more cleanup to be done, gotta take into consideration real pixel width of hexagon borders when moving along the hive
* [android] hex fill logic implemented, wip, more fixes needed to calculate right max hex side length
* [android] fixed color assigment bug, only repaint when number of pieces downloaded has changed
* [android] made debug drawing an XML attribute. Better aproximation on desired hexagon length, still need to account for maximum rows.
* [android] simplifications
* [android] unneded file
* [android] 2.0.0 (beta) build 473
* [android] stricter checks initializing UIBittorrentDownload
* [android] no need to import Objects
* [android] Update Translation: German
* [android] NPE bullet proofing
My guess is that the NPE reported on detailProgressStatusTextView.setText(transferStateStrings.get(uiBittorrentDownload.getState())); wasn't due
to the view being null, but to the transferStateStrings object being null due to possible synchronization issues with TransferStateStrings.getInstance()
To make sure this doesn't happen, I perform another check later on, and if we've been wrongly assigned a null value, we request the singleton again.
* [android] rebasing left-overs
* [android] math brainfart calculating Y position of rows fixed
* [android] hex hive drawing fixes
* [android] cube-piece drawing support
* [android] upgrades
- don't animate tabs when touching tab title
- new CubePaint object extends Paint and calculates and keeps colors for dark left cube face and light top face out of the given fill color which is used on the right side face
* [android] adds URL validation when adding or editing trackers
* [android] fix bug with active time and seeding time calculation
when context menu actions are invoked they invoke onTime() on the underlying activity (Context that implements TimerObserver)
cleanup
* [android] s/delete/remove torrent and data/ menu entry
* [android] cleanup
* [android] avoid Runtime error trying to open transfer with no infoHash/"
Frostwire,"[WIP] Frostwire 2.0 (#624)
* [android] new layouts for the transfer detail pages
* [android] initial set up for the transfer detail activity
* [android] added toolbar menu to TransferDetails
* [android] Extended AbstractFragment from the remaining transfer detail screens
* [android] cleanup in TransferDetailActivity
* [android] added status tab to transfer details, code cleanup
* [android] added status layout to torrent details, layout code cleanup and headers
* [android] added resource values for transfer detail activity
* [android] removed unnecessary styles
* [android] adjusted style of the view_transfer_list_item
* [android] replaced missing style in view_transfer_item_list_item.xml
* [android] minor adjustement in dividers of view_transfer_list_item.xml
* [android] Transfer detail fragments reused. cleanup on fragment classes
* [android] TransferDetailActivity refactor. New AbstractTransferDetailFragment.
* [android] remove setContext hack, do it the android way
* [android] cleanup
* [android] TransferManager::getBittorrentDownload(String infoHash)
* [android] plugged BittorrentDownload object all the way to fragments
Common section with title and progress plugged. Next transfer status and upload/download speed in that common section
* [android] plugged transfer status string into common progress component
- New TransferStateStrings singleton class to map transfer states to strings
- TransferListAdapter refactored to use new TransferStateStrings
* [android] plugged download and upload speeds on common progress panel
* [android] transfer detail > status > Completed plugged
renamed some of the textviews to have a '_label' suffix
* [desktop] CommonUtils cleanup
* [android] Transfer Detail > Status > Time remaining plugged
* [android] Transfer Details, Status tab done
* [android] abort updateDetailProgress when transfer is null
* [android] transfer details layout cleanup
* [android] adding a recyclerview to Details, moved mock layout for its views to fragment_transfer_detail_files_recyclerview_item.xml
* [android] plugged number of files and total download size on FILES tab
* [android] started pluggin ReciclerView, still not working
* [android] got files showing on details > files. main transfer list broken, might transition to recycler view here too, testing with ListViewCompat (v7)
* [android] cleanup
* [android] cleanup
* [android] TransferFragment RecyclerView refactor (broken)
* [android] RecyclerView on TransfersFragment working
* [android] cleanup, component lookup optimization in Transfers Fragment
* [android] Progress on Transfer Detail > Details fragment
* [common] BTDownload.getTorrentHandle()
* [android] Details > Details > Comment section handled
* [android] Transfer Detail > Details tab.
Just have an issue with the 'Sequential Download' checkbox
* [android] updated torrent_details_files
* [android] progress on Transfers Details > Trackers tab
* [android] updated transfer detail trackers fragment layout
* [android] new UIUtils.showEditTextDialog
* [android] Transfer Detail > Trackers can add trackers to torrent
* [android] fixed width issues with individual tracker layout
* [android] minor refactor on TransferManager
* [android] TransferDetailStatusFragment doesn't crash on rotation
* [android] broken progress towards adding/editing trackers
* [android] fix another on rotation crash
* [android] uiBittorrentDownload is serialized and deserialized on screen rotation
* [android] set adapter after you've set the layout manager
* [android] adds and deletes trackers
* [android] trackers can be removed. edit text dialog can be configured for single/multi line
* [android] fixes issue where recycler views would not show items when tabs switched
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android] Transfer Details > Peers tab working
* [andriod] fixed build.gradle to use new plugin 3.0.0 DSL
* [android] Details tab cleanup.
- Removed 'Seeding On' checkbox. That can be handled with action bar controls for seeding/pausing
- Dialog button handlers now use lambdas
* [android] don't refresh tab if not visible cleanup
* [android] Transfer Details > Pieces tab (not working correctly)
Also lint cleanup on the activity and related fragments
* [android] few minor changes to transfer detail layouts
* [android] added and updated icons for the view_transfer_list_item
* [android] set up for the right side transfer item actions
* [android] pieces colors work, had to do r.getColor(). refactor
* [android] First pass at setting the media type icon on transfer list items
* [common] BittorrentDownload::getPredominantFileExtension()
* [android] uses BittorrentDownload's getPredominantFileExtension() to determine transfer media icon
* [android] show missing /s on transfer detail speed indicators
* [android] warning cleanup on ClickAdapter<T>
* [android] Details button on TransferListAdapter works.
TransferListAdapter refactored so that we only have a single instance for every click listener, not individual listeners for every view created
* [android] found inconsistency between download and upload rate unlimited values in libtorrent, cleanup
* [android] fixed overlapping of the text on view_transfer_detail_peer_item
* [android] updated TransferDetailDetails dialog title
* [android] added appropriate padding to the pieces view in transfer detail
* [android] fixes rotation crashes. refactors to deal with rotation
if for some reason getting pieces takes a while, an indeterminate progress bar is shown in place of the pieces
other rotation bugs fixed, more robust behavior
* [android] files becomes the first, and default selected tab
* [android] remove timer subscription responsibility from fragments
Use only one TimeObserver subscriber defined in the TransferDetailActivity.
Fragments still implement TimerObserver, have the single subscriber instance invoke the fragment's onTime method
only on the currently active fragment
* [android] SectionsPagerAdapter doesn't need to keep a reference to activity
- Just pass a SparseArray with the string resources it actually needs
- Implements a new OnPageChangeListener that keeps track of what the current fragment is
- When current fragment changes invoke onTime() on it
- Implements TimerObserver on the activity which delegates an onTime() call to the current fragment
* [android] isVisible() check no longer necessary
also found out that in some cases, isVisible() would give a false negative
* [android] more work towards avoiding issues on rotation and fast tab changes
* [android] import cleanup, if unwraps
* [android] stick to empty default constructors on YouTubeDownloadDialog
* [android] lint warnings, import cleanups
* [android] semi-aldenization of fragment code, still rotation issues
* [android] move all init calls to initComponents
* [android] cleanup. still issues on rotation, fragments not being added after rotation
* [android] finally resolved rotation issue
It seems the pager adapter and the programatic approach to adding transfers ended up in fragments not being able to be tracked correctly by their tags when the activity was reloaded.
Some of the fragments we ended up with inside detailFragments[] wouldn't be added, however, we luckily have methods in the parent AbstractFragment class to keep track of fragments that have been added (since Android only provides these after API 21 or so), by looking at the added fragments I'm able to find the correct instance and replace it inside our internal detailFragments array.
Writing this commit message makes me want to use that list, and get rid of the internal detailFragments array, to keep track of the fragments used, they could easily be filtered if they're instances of AbstractTransferDetailFragment
* [android] edit text dialog is now an extension of AbstractDialog
* [android] EditTextDialog moved to its own file, handles screen rotation
* [android] removed unused vars
* [android] rotation bug finally fixed
* [android] inline call
* [android] Transfer > Status > Time left only shown when downloading
* [android] transfer detail tab layout cleanup
* [android] transfer details details speed limit dialog issues
- When transfers are first created their upload/download rate limits come as -1
- When you want to set them to -1 for unlimited, this does not go well. You have to use 0 for unlimited, after that, they return 0
- Added a dialog closed listener that refreshes the fragment on close so new rate limit is reflected on the ui right away
* [android] remove tracker dialog look is uniform. UIUtil.showYesNoDialog now uses YesNoDialog.
* [android] don't hide time left textview, show 0 instead
* [android] progress with transfer details action bar menu
* [android] logic fix with pause/resume action bar action
* [android] updated action bar icons, added new resume aciton bar icon
* [android] removed double resume action
That action is not on the main branch, it was added later - it said resume but it was starting to seed even with seeding settings off.
* [android] updated icons for resume and cancel context menu action
* [android] added action bar seed icon
* [android] removed repeating action menu option
* [android] fixed and updated action_bar_seed icons
Sorry saved them with a wrong setting, looked pixelated
* [android] better logic on pause, resume, seed
* [android] added clear option on details.
cancel menu action uses the proper icon depending on the parameters
* [android] removed Open action from details, files are already there for individual access
* [android] added action_bar_stop_transfer icon
* [android] seeding|pausing made left most action. delete transfer sent to the context menu and cancel transfer the 2nd action shown only if room is available
* [android] use SeedAction when seedable
* [android] Update Translation: Spanish
* [android] Update Translation: Portuguese
* [android] start of HexHiveView for piece display, bye RecyclerView in this fragment
* [android] detail pieces layout cleanup
* [android] updated files and trackers layouts
RecyclerViewer no longer moves independently from the rest of hte scroll view - better user experience on small screens and horizontal views.
Fixed the files tab to open lower then top of the page.
The issue was connected to recycleviewer receiving the focus.
* [android] calculate height of other components to correctly measure height for hexhiveview
* [android] HexHiveView sizing issues fixed
- No need to manually calculate bounds when the containing layout is simpler
- fragment_transfer_detail_pieces no longer inside ScrollView, no need to scroll as our HexHiveView will only use remaining vertical space
- To make this work, view_transfer_detail_progress now has a fixed height, otherwise the folder icon would go towards the center of the screen
* [android] fix to the height of the detail_progress layout
* [android] very wip hex drawing experiments
* [android] Update Translations: French and Italian
* [android] HexView advances
- New DrawingProperties object is used to create buffer objects and useful constants for drawing the hexagonal hive
- drawing functions refactored to reduce the number of parameter copies on each onDraw iteration
- more cleanup to be done, gotta take into consideration real pixel width of hexagon borders when moving along the hive
* [android] hex fill logic implemented, wip, more fixes needed to calculate right max hex side length
* [android] fixed color assigment bug, only repaint when number of pieces downloaded has changed
* [android] made debug drawing an XML attribute. Better aproximation on desired hexagon length, still need to account for maximum rows.
* [android] simplifications
* [android] unneded file
* [android] 2.0.0 (beta) build 473
* [android] stricter checks initializing UIBittorrentDownload
* [android] no need to import Objects
* [android] Update Translation: German
* [android] NPE bullet proofing
My guess is that the NPE reported on detailProgressStatusTextView.setText(transferStateStrings.get(uiBittorrentDownload.getState())); wasn't due
to the view being null, but to the transferStateStrings object being null due to possible synchronization issues with TransferStateStrings.getInstance()
To make sure this doesn't happen, I perform another check later on, and if we've been wrongly assigned a null value, we request the singleton again.
* [android] rebasing left-overs
* [android] math brainfart calculating Y position of rows fixed
* [android] hex hive drawing fixes
* [android] cube-piece drawing support
* [android] upgrades
- don't animate tabs when touching tab title
- new CubePaint object extends Paint and calculates and keeps colors for dark left cube face and light top face out of the given fill color which is used on the right side face
* [android] adds URL validation when adding or editing trackers
* [android] fix bug with active time and seeding time calculation
when context menu actions are invoked they invoke onTime() on the underlying activity (Context that implements TimerObserver)
cleanup
* [android] s/delete/remove torrent and data/ menu entry
* [android] cleanup
* [android] avoid Runtime error trying to open transfer with no infoHash/"
Frostwire,"[WIP] Frostwire 2.0 (#624)
* [android] new layouts for the transfer detail pages
* [android] initial set up for the transfer detail activity
* [android] added toolbar menu to TransferDetails
* [android] Extended AbstractFragment from the remaining transfer detail screens
* [android] cleanup in TransferDetailActivity
* [android] added status tab to transfer details, code cleanup
* [android] added status layout to torrent details, layout code cleanup and headers
* [android] added resource values for transfer detail activity
* [android] removed unnecessary styles
* [android] adjusted style of the view_transfer_list_item
* [android] replaced missing style in view_transfer_item_list_item.xml
* [android] minor adjustement in dividers of view_transfer_list_item.xml
* [android] Transfer detail fragments reused. cleanup on fragment classes
* [android] TransferDetailActivity refactor. New AbstractTransferDetailFragment.
* [android] remove setContext hack, do it the android way
* [android] cleanup
* [android] TransferManager::getBittorrentDownload(String infoHash)
* [android] plugged BittorrentDownload object all the way to fragments
Common section with title and progress plugged. Next transfer status and upload/download speed in that common section
* [android] plugged transfer status string into common progress component
- New TransferStateStrings singleton class to map transfer states to strings
- TransferListAdapter refactored to use new TransferStateStrings
* [android] plugged download and upload speeds on common progress panel
* [android] transfer detail > status > Completed plugged
renamed some of the textviews to have a '_label' suffix
* [desktop] CommonUtils cleanup
* [android] Transfer Detail > Status > Time remaining plugged
* [android] Transfer Details, Status tab done
* [android] abort updateDetailProgress when transfer is null
* [android] transfer details layout cleanup
* [android] adding a recyclerview to Details, moved mock layout for its views to fragment_transfer_detail_files_recyclerview_item.xml
* [android] plugged number of files and total download size on FILES tab
* [android] started pluggin ReciclerView, still not working
* [android] got files showing on details > files. main transfer list broken, might transition to recycler view here too, testing with ListViewCompat (v7)
* [android] cleanup
* [android] cleanup
* [android] TransferFragment RecyclerView refactor (broken)
* [android] RecyclerView on TransfersFragment working
* [android] cleanup, component lookup optimization in Transfers Fragment
* [android] Progress on Transfer Detail > Details fragment
* [common] BTDownload.getTorrentHandle()
* [android] Details > Details > Comment section handled
* [android] Transfer Detail > Details tab.
Just have an issue with the 'Sequential Download' checkbox
* [android] updated torrent_details_files
* [android] progress on Transfers Details > Trackers tab
* [android] updated transfer detail trackers fragment layout
* [android] new UIUtils.showEditTextDialog
* [android] Transfer Detail > Trackers can add trackers to torrent
* [android] fixed width issues with individual tracker layout
* [android] minor refactor on TransferManager
* [android] TransferDetailStatusFragment doesn't crash on rotation
* [android] broken progress towards adding/editing trackers
* [android] fix another on rotation crash
* [android] uiBittorrentDownload is serialized and deserialized on screen rotation
* [android] set adapter after you've set the layout manager
* [android] adds and deletes trackers
* [android] trackers can be removed. edit text dialog can be configured for single/multi line
* [android] fixes issue where recycler views would not show items when tabs switched
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android] Transfer Details > Peers tab working
* [andriod] fixed build.gradle to use new plugin 3.0.0 DSL
* [android] Details tab cleanup.
- Removed 'Seeding On' checkbox. That can be handled with action bar controls for seeding/pausing
- Dialog button handlers now use lambdas
* [android] don't refresh tab if not visible cleanup
* [android] Transfer Details > Pieces tab (not working correctly)
Also lint cleanup on the activity and related fragments
* [android] few minor changes to transfer detail layouts
* [android] added and updated icons for the view_transfer_list_item
* [android] set up for the right side transfer item actions
* [android] pieces colors work, had to do r.getColor(). refactor
* [android] First pass at setting the media type icon on transfer list items
* [common] BittorrentDownload::getPredominantFileExtension()
* [android] uses BittorrentDownload's getPredominantFileExtension() to determine transfer media icon
* [android] show missing /s on transfer detail speed indicators
* [android] warning cleanup on ClickAdapter<T>
* [android] Details button on TransferListAdapter works.
TransferListAdapter refactored so that we only have a single instance for every click listener, not individual listeners for every view created
* [android] found inconsistency between download and upload rate unlimited values in libtorrent, cleanup
* [android] fixed overlapping of the text on view_transfer_detail_peer_item
* [android] updated TransferDetailDetails dialog title
* [android] added appropriate padding to the pieces view in transfer detail
* [android] fixes rotation crashes. refactors to deal with rotation
if for some reason getting pieces takes a while, an indeterminate progress bar is shown in place of the pieces
other rotation bugs fixed, more robust behavior
* [android] files becomes the first, and default selected tab
* [android] remove timer subscription responsibility from fragments
Use only one TimeObserver subscriber defined in the TransferDetailActivity.
Fragments still implement TimerObserver, have the single subscriber instance invoke the fragment's onTime method
only on the currently active fragment
* [android] SectionsPagerAdapter doesn't need to keep a reference to activity
- Just pass a SparseArray with the string resources it actually needs
- Implements a new OnPageChangeListener that keeps track of what the current fragment is
- When current fragment changes invoke onTime() on it
- Implements TimerObserver on the activity which delegates an onTime() call to the current fragment
* [android] isVisible() check no longer necessary
also found out that in some cases, isVisible() would give a false negative
* [android] more work towards avoiding issues on rotation and fast tab changes
* [android] import cleanup, if unwraps
* [android] stick to empty default constructors on YouTubeDownloadDialog
* [android] lint warnings, import cleanups
* [android] semi-aldenization of fragment code, still rotation issues
* [android] move all init calls to initComponents
* [android] cleanup. still issues on rotation, fragments not being added after rotation
* [android] finally resolved rotation issue
It seems the pager adapter and the programatic approach to adding transfers ended up in fragments not being able to be tracked correctly by their tags when the activity was reloaded.
Some of the fragments we ended up with inside detailFragments[] wouldn't be added, however, we luckily have methods in the parent AbstractFragment class to keep track of fragments that have been added (since Android only provides these after API 21 or so), by looking at the added fragments I'm able to find the correct instance and replace it inside our internal detailFragments array.
Writing this commit message makes me want to use that list, and get rid of the internal detailFragments array, to keep track of the fragments used, they could easily be filtered if they're instances of AbstractTransferDetailFragment
* [android] edit text dialog is now an extension of AbstractDialog
* [android] EditTextDialog moved to its own file, handles screen rotation
* [android] removed unused vars
* [android] rotation bug finally fixed
* [android] inline call
* [android] Transfer > Status > Time left only shown when downloading
* [android] transfer detail tab layout cleanup
* [android] transfer details details speed limit dialog issues
- When transfers are first created their upload/download rate limits come as -1
- When you want to set them to -1 for unlimited, this does not go well. You have to use 0 for unlimited, after that, they return 0
- Added a dialog closed listener that refreshes the fragment on close so new rate limit is reflected on the ui right away
* [android] remove tracker dialog look is uniform. UIUtil.showYesNoDialog now uses YesNoDialog.
* [android] don't hide time left textview, show 0 instead
* [android] progress with transfer details action bar menu
* [android] logic fix with pause/resume action bar action
* [android] updated action bar icons, added new resume aciton bar icon
* [android] removed double resume action
That action is not on the main branch, it was added later - it said resume but it was starting to seed even with seeding settings off.
* [android] updated icons for resume and cancel context menu action
* [android] added action bar seed icon
* [android] removed repeating action menu option
* [android] fixed and updated action_bar_seed icons
Sorry saved them with a wrong setting, looked pixelated
* [android] better logic on pause, resume, seed
* [android] added clear option on details.
cancel menu action uses the proper icon depending on the parameters
* [android] removed Open action from details, files are already there for individual access
* [android] added action_bar_stop_transfer icon
* [android] seeding|pausing made left most action. delete transfer sent to the context menu and cancel transfer the 2nd action shown only if room is available
* [android] use SeedAction when seedable
* [android] Update Translation: Spanish
* [android] Update Translation: Portuguese
* [android] start of HexHiveView for piece display, bye RecyclerView in this fragment
* [android] detail pieces layout cleanup
* [android] updated files and trackers layouts
RecyclerViewer no longer moves independently from the rest of hte scroll view - better user experience on small screens and horizontal views.
Fixed the files tab to open lower then top of the page.
The issue was connected to recycleviewer receiving the focus.
* [android] calculate height of other components to correctly measure height for hexhiveview
* [android] HexHiveView sizing issues fixed
- No need to manually calculate bounds when the containing layout is simpler
- fragment_transfer_detail_pieces no longer inside ScrollView, no need to scroll as our HexHiveView will only use remaining vertical space
- To make this work, view_transfer_detail_progress now has a fixed height, otherwise the folder icon would go towards the center of the screen
* [android] fix to the height of the detail_progress layout
* [android] very wip hex drawing experiments
* [android] Update Translations: French and Italian
* [android] HexView advances
- New DrawingProperties object is used to create buffer objects and useful constants for drawing the hexagonal hive
- drawing functions refactored to reduce the number of parameter copies on each onDraw iteration
- more cleanup to be done, gotta take into consideration real pixel width of hexagon borders when moving along the hive
* [android] hex fill logic implemented, wip, more fixes needed to calculate right max hex side length
* [android] fixed color assigment bug, only repaint when number of pieces downloaded has changed
* [android] made debug drawing an XML attribute. Better aproximation on desired hexagon length, still need to account for maximum rows.
* [android] simplifications
* [android] unneded file
* [android] 2.0.0 (beta) build 473
* [android] stricter checks initializing UIBittorrentDownload
* [android] no need to import Objects
* [android] Update Translation: German
* [android] NPE bullet proofing
My guess is that the NPE reported on detailProgressStatusTextView.setText(transferStateStrings.get(uiBittorrentDownload.getState())); wasn't due
to the view being null, but to the transferStateStrings object being null due to possible synchronization issues with TransferStateStrings.getInstance()
To make sure this doesn't happen, I perform another check later on, and if we've been wrongly assigned a null value, we request the singleton again.
* [android] rebasing left-overs
* [android] math brainfart calculating Y position of rows fixed
* [android] hex hive drawing fixes
* [android] cube-piece drawing support
* [android] upgrades
- don't animate tabs when touching tab title
- new CubePaint object extends Paint and calculates and keeps colors for dark left cube face and light top face out of the given fill color which is used on the right side face
* [android] adds URL validation when adding or editing trackers
* [android] fix bug with active time and seeding time calculation
when context menu actions are invoked they invoke onTime() on the underlying activity (Context that implements TimerObserver)
cleanup
* [android] s/delete/remove torrent and data/ menu entry
* [android] cleanup
* [android] avoid Runtime error trying to open transfer with no infoHash/[android] syntax error. redundant logic fixes/[android] removal of static Context reference in Librarian to avoid memory leaks/"
Frostwire,"[WIP] Frostwire 2.0 (#624)
* [android] new layouts for the transfer detail pages
* [android] initial set up for the transfer detail activity
* [android] added toolbar menu to TransferDetails
* [android] Extended AbstractFragment from the remaining transfer detail screens
* [android] cleanup in TransferDetailActivity
* [android] added status tab to transfer details, code cleanup
* [android] added status layout to torrent details, layout code cleanup and headers
* [android] added resource values for transfer detail activity
* [android] removed unnecessary styles
* [android] adjusted style of the view_transfer_list_item
* [android] replaced missing style in view_transfer_item_list_item.xml
* [android] minor adjustement in dividers of view_transfer_list_item.xml
* [android] Transfer detail fragments reused. cleanup on fragment classes
* [android] TransferDetailActivity refactor. New AbstractTransferDetailFragment.
* [android] remove setContext hack, do it the android way
* [android] cleanup
* [android] TransferManager::getBittorrentDownload(String infoHash)
* [android] plugged BittorrentDownload object all the way to fragments
Common section with title and progress plugged. Next transfer status and upload/download speed in that common section
* [android] plugged transfer status string into common progress component
- New TransferStateStrings singleton class to map transfer states to strings
- TransferListAdapter refactored to use new TransferStateStrings
* [android] plugged download and upload speeds on common progress panel
* [android] transfer detail > status > Completed plugged
renamed some of the textviews to have a '_label' suffix
* [desktop] CommonUtils cleanup
* [android] Transfer Detail > Status > Time remaining plugged
* [android] Transfer Details, Status tab done
* [android] abort updateDetailProgress when transfer is null
* [android] transfer details layout cleanup
* [android] adding a recyclerview to Details, moved mock layout for its views to fragment_transfer_detail_files_recyclerview_item.xml
* [android] plugged number of files and total download size on FILES tab
* [android] started pluggin ReciclerView, still not working
* [android] got files showing on details > files. main transfer list broken, might transition to recycler view here too, testing with ListViewCompat (v7)
* [android] cleanup
* [android] cleanup
* [android] TransferFragment RecyclerView refactor (broken)
* [android] RecyclerView on TransfersFragment working
* [android] cleanup, component lookup optimization in Transfers Fragment
* [android] Progress on Transfer Detail > Details fragment
* [common] BTDownload.getTorrentHandle()
* [android] Details > Details > Comment section handled
* [android] Transfer Detail > Details tab.
Just have an issue with the 'Sequential Download' checkbox
* [android] updated torrent_details_files
* [android] progress on Transfers Details > Trackers tab
* [android] updated transfer detail trackers fragment layout
* [android] new UIUtils.showEditTextDialog
* [android] Transfer Detail > Trackers can add trackers to torrent
* [android] fixed width issues with individual tracker layout
* [android] minor refactor on TransferManager
* [android] TransferDetailStatusFragment doesn't crash on rotation
* [android] broken progress towards adding/editing trackers
* [android] fix another on rotation crash
* [android] uiBittorrentDownload is serialized and deserialized on screen rotation
* [android] set adapter after you've set the layout manager
* [android] adds and deletes trackers
* [android] trackers can be removed. edit text dialog can be configured for single/multi line
* [android] fixes issue where recycler views would not show items when tabs switched
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android] Transfer Details > Peers tab working
* [andriod] fixed build.gradle to use new plugin 3.0.0 DSL
* [android] Details tab cleanup.
- Removed 'Seeding On' checkbox. That can be handled with action bar controls for seeding/pausing
- Dialog button handlers now use lambdas
* [android] don't refresh tab if not visible cleanup
* [android] Transfer Details > Pieces tab (not working correctly)
Also lint cleanup on the activity and related fragments
* [android] few minor changes to transfer detail layouts
* [android] added and updated icons for the view_transfer_list_item
* [android] set up for the right side transfer item actions
* [android] pieces colors work, had to do r.getColor(). refactor
* [android] First pass at setting the media type icon on transfer list items
* [common] BittorrentDownload::getPredominantFileExtension()
* [android] uses BittorrentDownload's getPredominantFileExtension() to determine transfer media icon
* [android] show missing /s on transfer detail speed indicators
* [android] warning cleanup on ClickAdapter<T>
* [android] Details button on TransferListAdapter works.
TransferListAdapter refactored so that we only have a single instance for every click listener, not individual listeners for every view created
* [android] found inconsistency between download and upload rate unlimited values in libtorrent, cleanup
* [android] fixed overlapping of the text on view_transfer_detail_peer_item
* [android] updated TransferDetailDetails dialog title
* [android] added appropriate padding to the pieces view in transfer detail
* [android] fixes rotation crashes. refactors to deal with rotation
if for some reason getting pieces takes a while, an indeterminate progress bar is shown in place of the pieces
other rotation bugs fixed, more robust behavior
* [android] files becomes the first, and default selected tab
* [android] remove timer subscription responsibility from fragments
Use only one TimeObserver subscriber defined in the TransferDetailActivity.
Fragments still implement TimerObserver, have the single subscriber instance invoke the fragment's onTime method
only on the currently active fragment
* [android] SectionsPagerAdapter doesn't need to keep a reference to activity
- Just pass a SparseArray with the string resources it actually needs
- Implements a new OnPageChangeListener that keeps track of what the current fragment is
- When current fragment changes invoke onTime() on it
- Implements TimerObserver on the activity which delegates an onTime() call to the current fragment
* [android] isVisible() check no longer necessary
also found out that in some cases, isVisible() would give a false negative
* [android] more work towards avoiding issues on rotation and fast tab changes
* [android] import cleanup, if unwraps
* [android] stick to empty default constructors on YouTubeDownloadDialog
* [android] lint warnings, import cleanups
* [android] semi-aldenization of fragment code, still rotation issues
* [android] move all init calls to initComponents
* [android] cleanup. still issues on rotation, fragments not being added after rotation
* [android] finally resolved rotation issue
It seems the pager adapter and the programatic approach to adding transfers ended up in fragments not being able to be tracked correctly by their tags when the activity was reloaded.
Some of the fragments we ended up with inside detailFragments[] wouldn't be added, however, we luckily have methods in the parent AbstractFragment class to keep track of fragments that have been added (since Android only provides these after API 21 or so), by looking at the added fragments I'm able to find the correct instance and replace it inside our internal detailFragments array.
Writing this commit message makes me want to use that list, and get rid of the internal detailFragments array, to keep track of the fragments used, they could easily be filtered if they're instances of AbstractTransferDetailFragment
* [android] edit text dialog is now an extension of AbstractDialog
* [android] EditTextDialog moved to its own file, handles screen rotation
* [android] removed unused vars
* [android] rotation bug finally fixed
* [android] inline call
* [android] Transfer > Status > Time left only shown when downloading
* [android] transfer detail tab layout cleanup
* [android] transfer details details speed limit dialog issues
- When transfers are first created their upload/download rate limits come as -1
- When you want to set them to -1 for unlimited, this does not go well. You have to use 0 for unlimited, after that, they return 0
- Added a dialog closed listener that refreshes the fragment on close so new rate limit is reflected on the ui right away
* [android] remove tracker dialog look is uniform. UIUtil.showYesNoDialog now uses YesNoDialog.
* [android] don't hide time left textview, show 0 instead
* [android] progress with transfer details action bar menu
* [android] logic fix with pause/resume action bar action
* [android] updated action bar icons, added new resume aciton bar icon
* [android] removed double resume action
That action is not on the main branch, it was added later - it said resume but it was starting to seed even with seeding settings off.
* [android] updated icons for resume and cancel context menu action
* [android] added action bar seed icon
* [android] removed repeating action menu option
* [android] fixed and updated action_bar_seed icons
Sorry saved them with a wrong setting, looked pixelated
* [android] better logic on pause, resume, seed
* [android] added clear option on details.
cancel menu action uses the proper icon depending on the parameters
* [android] removed Open action from details, files are already there for individual access
* [android] added action_bar_stop_transfer icon
* [android] seeding|pausing made left most action. delete transfer sent to the context menu and cancel transfer the 2nd action shown only if room is available
* [android] use SeedAction when seedable
* [android] Update Translation: Spanish
* [android] Update Translation: Portuguese
* [android] start of HexHiveView for piece display, bye RecyclerView in this fragment
* [android] detail pieces layout cleanup
* [android] updated files and trackers layouts
RecyclerViewer no longer moves independently from the rest of hte scroll view - better user experience on small screens and horizontal views.
Fixed the files tab to open lower then top of the page.
The issue was connected to recycleviewer receiving the focus.
* [android] calculate height of other components to correctly measure height for hexhiveview
* [android] HexHiveView sizing issues fixed
- No need to manually calculate bounds when the containing layout is simpler
- fragment_transfer_detail_pieces no longer inside ScrollView, no need to scroll as our HexHiveView will only use remaining vertical space
- To make this work, view_transfer_detail_progress now has a fixed height, otherwise the folder icon would go towards the center of the screen
* [android] fix to the height of the detail_progress layout
* [android] very wip hex drawing experiments
* [android] Update Translations: French and Italian
* [android] HexView advances
- New DrawingProperties object is used to create buffer objects and useful constants for drawing the hexagonal hive
- drawing functions refactored to reduce the number of parameter copies on each onDraw iteration
- more cleanup to be done, gotta take into consideration real pixel width of hexagon borders when moving along the hive
* [android] hex fill logic implemented, wip, more fixes needed to calculate right max hex side length
* [android] fixed color assigment bug, only repaint when number of pieces downloaded has changed
* [android] made debug drawing an XML attribute. Better aproximation on desired hexagon length, still need to account for maximum rows.
* [android] simplifications
* [android] unneded file
* [android] 2.0.0 (beta) build 473
* [android] stricter checks initializing UIBittorrentDownload
* [android] no need to import Objects
* [android] Update Translation: German
* [android] NPE bullet proofing
My guess is that the NPE reported on detailProgressStatusTextView.setText(transferStateStrings.get(uiBittorrentDownload.getState())); wasn't due
to the view being null, but to the transferStateStrings object being null due to possible synchronization issues with TransferStateStrings.getInstance()
To make sure this doesn't happen, I perform another check later on, and if we've been wrongly assigned a null value, we request the singleton again.
* [android] rebasing left-overs
* [android] math brainfart calculating Y position of rows fixed
* [android] hex hive drawing fixes
* [android] cube-piece drawing support
* [android] upgrades
- don't animate tabs when touching tab title
- new CubePaint object extends Paint and calculates and keeps colors for dark left cube face and light top face out of the given fill color which is used on the right side face
* [android] adds URL validation when adding or editing trackers
* [android] fix bug with active time and seeding time calculation
when context menu actions are invoked they invoke onTime() on the underlying activity (Context that implements TimerObserver)
cleanup
* [android] s/delete/remove torrent and data/ menu entry
* [android] cleanup
* [android] avoid Runtime error trying to open transfer with no infoHash/[android] minor cleanups, npe prevention, lambda refactors/"
Frostwire,"[WIP] Frostwire 2.0 (#624)
* [android] new layouts for the transfer detail pages
* [android] initial set up for the transfer detail activity
* [android] added toolbar menu to TransferDetails
* [android] Extended AbstractFragment from the remaining transfer detail screens
* [android] cleanup in TransferDetailActivity
* [android] added status tab to transfer details, code cleanup
* [android] added status layout to torrent details, layout code cleanup and headers
* [android] added resource values for transfer detail activity
* [android] removed unnecessary styles
* [android] adjusted style of the view_transfer_list_item
* [android] replaced missing style in view_transfer_item_list_item.xml
* [android] minor adjustement in dividers of view_transfer_list_item.xml
* [android] Transfer detail fragments reused. cleanup on fragment classes
* [android] TransferDetailActivity refactor. New AbstractTransferDetailFragment.
* [android] remove setContext hack, do it the android way
* [android] cleanup
* [android] TransferManager::getBittorrentDownload(String infoHash)
* [android] plugged BittorrentDownload object all the way to fragments
Common section with title and progress plugged. Next transfer status and upload/download speed in that common section
* [android] plugged transfer status string into common progress component
- New TransferStateStrings singleton class to map transfer states to strings
- TransferListAdapter refactored to use new TransferStateStrings
* [android] plugged download and upload speeds on common progress panel
* [android] transfer detail > status > Completed plugged
renamed some of the textviews to have a '_label' suffix
* [desktop] CommonUtils cleanup
* [android] Transfer Detail > Status > Time remaining plugged
* [android] Transfer Details, Status tab done
* [android] abort updateDetailProgress when transfer is null
* [android] transfer details layout cleanup
* [android] adding a recyclerview to Details, moved mock layout for its views to fragment_transfer_detail_files_recyclerview_item.xml
* [android] plugged number of files and total download size on FILES tab
* [android] started pluggin ReciclerView, still not working
* [android] got files showing on details > files. main transfer list broken, might transition to recycler view here too, testing with ListViewCompat (v7)
* [android] cleanup
* [android] cleanup
* [android] TransferFragment RecyclerView refactor (broken)
* [android] RecyclerView on TransfersFragment working
* [android] cleanup, component lookup optimization in Transfers Fragment
* [android] Progress on Transfer Detail > Details fragment
* [common] BTDownload.getTorrentHandle()
* [android] Details > Details > Comment section handled
* [android] Transfer Detail > Details tab.
Just have an issue with the 'Sequential Download' checkbox
* [android] updated torrent_details_files
* [android] progress on Transfers Details > Trackers tab
* [android] updated transfer detail trackers fragment layout
* [android] new UIUtils.showEditTextDialog
* [android] Transfer Detail > Trackers can add trackers to torrent
* [android] fixed width issues with individual tracker layout
* [android] minor refactor on TransferManager
* [android] TransferDetailStatusFragment doesn't crash on rotation
* [android] broken progress towards adding/editing trackers
* [android] fix another on rotation crash
* [android] uiBittorrentDownload is serialized and deserialized on screen rotation
* [android] set adapter after you've set the layout manager
* [android] adds and deletes trackers
* [android] trackers can be removed. edit text dialog can be configured for single/multi line
* [android] fixes issue where recycler views would not show items when tabs switched
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android] Transfer Details > Peers tab working
* [andriod] fixed build.gradle to use new plugin 3.0.0 DSL
* [android] Details tab cleanup.
- Removed 'Seeding On' checkbox. That can be handled with action bar controls for seeding/pausing
- Dialog button handlers now use lambdas
* [android] don't refresh tab if not visible cleanup
* [android] Transfer Details > Pieces tab (not working correctly)
Also lint cleanup on the activity and related fragments
* [android] few minor changes to transfer detail layouts
* [android] added and updated icons for the view_transfer_list_item
* [android] set up for the right side transfer item actions
* [android] pieces colors work, had to do r.getColor(). refactor
* [android] First pass at setting the media type icon on transfer list items
* [common] BittorrentDownload::getPredominantFileExtension()
* [android] uses BittorrentDownload's getPredominantFileExtension() to determine transfer media icon
* [android] show missing /s on transfer detail speed indicators
* [android] warning cleanup on ClickAdapter<T>
* [android] Details button on TransferListAdapter works.
TransferListAdapter refactored so that we only have a single instance for every click listener, not individual listeners for every view created
* [android] found inconsistency between download and upload rate unlimited values in libtorrent, cleanup
* [android] fixed overlapping of the text on view_transfer_detail_peer_item
* [android] updated TransferDetailDetails dialog title
* [android] added appropriate padding to the pieces view in transfer detail
* [android] fixes rotation crashes. refactors to deal with rotation
if for some reason getting pieces takes a while, an indeterminate progress bar is shown in place of the pieces
other rotation bugs fixed, more robust behavior
* [android] files becomes the first, and default selected tab
* [android] remove timer subscription responsibility from fragments
Use only one TimeObserver subscriber defined in the TransferDetailActivity.
Fragments still implement TimerObserver, have the single subscriber instance invoke the fragment's onTime method
only on the currently active fragment
* [android] SectionsPagerAdapter doesn't need to keep a reference to activity
- Just pass a SparseArray with the string resources it actually needs
- Implements a new OnPageChangeListener that keeps track of what the current fragment is
- When current fragment changes invoke onTime() on it
- Implements TimerObserver on the activity which delegates an onTime() call to the current fragment
* [android] isVisible() check no longer necessary
also found out that in some cases, isVisible() would give a false negative
* [android] more work towards avoiding issues on rotation and fast tab changes
* [android] import cleanup, if unwraps
* [android] stick to empty default constructors on YouTubeDownloadDialog
* [android] lint warnings, import cleanups
* [android] semi-aldenization of fragment code, still rotation issues
* [android] move all init calls to initComponents
* [android] cleanup. still issues on rotation, fragments not being added after rotation
* [android] finally resolved rotation issue
It seems the pager adapter and the programatic approach to adding transfers ended up in fragments not being able to be tracked correctly by their tags when the activity was reloaded.
Some of the fragments we ended up with inside detailFragments[] wouldn't be added, however, we luckily have methods in the parent AbstractFragment class to keep track of fragments that have been added (since Android only provides these after API 21 or so), by looking at the added fragments I'm able to find the correct instance and replace it inside our internal detailFragments array.
Writing this commit message makes me want to use that list, and get rid of the internal detailFragments array, to keep track of the fragments used, they could easily be filtered if they're instances of AbstractTransferDetailFragment
* [android] edit text dialog is now an extension of AbstractDialog
* [android] EditTextDialog moved to its own file, handles screen rotation
* [android] removed unused vars
* [android] rotation bug finally fixed
* [android] inline call
* [android] Transfer > Status > Time left only shown when downloading
* [android] transfer detail tab layout cleanup
* [android] transfer details details speed limit dialog issues
- When transfers are first created their upload/download rate limits come as -1
- When you want to set them to -1 for unlimited, this does not go well. You have to use 0 for unlimited, after that, they return 0
- Added a dialog closed listener that refreshes the fragment on close so new rate limit is reflected on the ui right away
* [android] remove tracker dialog look is uniform. UIUtil.showYesNoDialog now uses YesNoDialog.
* [android] don't hide time left textview, show 0 instead
* [android] progress with transfer details action bar menu
* [android] logic fix with pause/resume action bar action
* [android] updated action bar icons, added new resume aciton bar icon
* [android] removed double resume action
That action is not on the main branch, it was added later - it said resume but it was starting to seed even with seeding settings off.
* [android] updated icons for resume and cancel context menu action
* [android] added action bar seed icon
* [android] removed repeating action menu option
* [android] fixed and updated action_bar_seed icons
Sorry saved them with a wrong setting, looked pixelated
* [android] better logic on pause, resume, seed
* [android] added clear option on details.
cancel menu action uses the proper icon depending on the parameters
* [android] removed Open action from details, files are already there for individual access
* [android] added action_bar_stop_transfer icon
* [android] seeding|pausing made left most action. delete transfer sent to the context menu and cancel transfer the 2nd action shown only if room is available
* [android] use SeedAction when seedable
* [android] Update Translation: Spanish
* [android] Update Translation: Portuguese
* [android] start of HexHiveView for piece display, bye RecyclerView in this fragment
* [android] detail pieces layout cleanup
* [android] updated files and trackers layouts
RecyclerViewer no longer moves independently from the rest of hte scroll view - better user experience on small screens and horizontal views.
Fixed the files tab to open lower then top of the page.
The issue was connected to recycleviewer receiving the focus.
* [android] calculate height of other components to correctly measure height for hexhiveview
* [android] HexHiveView sizing issues fixed
- No need to manually calculate bounds when the containing layout is simpler
- fragment_transfer_detail_pieces no longer inside ScrollView, no need to scroll as our HexHiveView will only use remaining vertical space
- To make this work, view_transfer_detail_progress now has a fixed height, otherwise the folder icon would go towards the center of the screen
* [android] fix to the height of the detail_progress layout
* [android] very wip hex drawing experiments
* [android] Update Translations: French and Italian
* [android] HexView advances
- New DrawingProperties object is used to create buffer objects and useful constants for drawing the hexagonal hive
- drawing functions refactored to reduce the number of parameter copies on each onDraw iteration
- more cleanup to be done, gotta take into consideration real pixel width of hexagon borders when moving along the hive
* [android] hex fill logic implemented, wip, more fixes needed to calculate right max hex side length
* [android] fixed color assigment bug, only repaint when number of pieces downloaded has changed
* [android] made debug drawing an XML attribute. Better aproximation on desired hexagon length, still need to account for maximum rows.
* [android] simplifications
* [android] unneded file
* [android] 2.0.0 (beta) build 473
* [android] stricter checks initializing UIBittorrentDownload
* [android] no need to import Objects
* [android] Update Translation: German
* [android] NPE bullet proofing
My guess is that the NPE reported on detailProgressStatusTextView.setText(transferStateStrings.get(uiBittorrentDownload.getState())); wasn't due
to the view being null, but to the transferStateStrings object being null due to possible synchronization issues with TransferStateStrings.getInstance()
To make sure this doesn't happen, I perform another check later on, and if we've been wrongly assigned a null value, we request the singleton again.
* [android] rebasing left-overs
* [android] math brainfart calculating Y position of rows fixed
* [android] hex hive drawing fixes
* [android] cube-piece drawing support
* [android] upgrades
- don't animate tabs when touching tab title
- new CubePaint object extends Paint and calculates and keeps colors for dark left cube face and light top face out of the given fill color which is used on the right side face
* [android] adds URL validation when adding or editing trackers
* [android] fix bug with active time and seeding time calculation
when context menu actions are invoked they invoke onTime() on the underlying activity (Context that implements TimerObserver)
cleanup
* [android] s/delete/remove torrent and data/ menu entry
* [android] cleanup
* [android] avoid Runtime error trying to open transfer with no infoHash/"
Frostwire,"[android] refactor of register/unregister code, avoid creation of IntentFilter on each resume/"
Frostwire,"[android] minor cleanups, npe prevention, lambda refactors/"
Frostwire,[android] removal of static Context reference in Librarian to avoid memory leaks/
Frostwire,"[android] minor cleanups, npe prevention, lambda refactors/"
Frostwire,"[WIP] Frostwire 2.0 (#624)
* [android] new layouts for the transfer detail pages
* [android] initial set up for the transfer detail activity
* [android] added toolbar menu to TransferDetails
* [android] Extended AbstractFragment from the remaining transfer detail screens
* [android] cleanup in TransferDetailActivity
* [android] added status tab to transfer details, code cleanup
* [android] added status layout to torrent details, layout code cleanup and headers
* [android] added resource values for transfer detail activity
* [android] removed unnecessary styles
* [android] adjusted style of the view_transfer_list_item
* [android] replaced missing style in view_transfer_item_list_item.xml
* [android] minor adjustement in dividers of view_transfer_list_item.xml
* [android] Transfer detail fragments reused. cleanup on fragment classes
* [android] TransferDetailActivity refactor. New AbstractTransferDetailFragment.
* [android] remove setContext hack, do it the android way
* [android] cleanup
* [android] TransferManager::getBittorrentDownload(String infoHash)
* [android] plugged BittorrentDownload object all the way to fragments
Common section with title and progress plugged. Next transfer status and upload/download speed in that common section
* [android] plugged transfer status string into common progress component
- New TransferStateStrings singleton class to map transfer states to strings
- TransferListAdapter refactored to use new TransferStateStrings
* [android] plugged download and upload speeds on common progress panel
* [android] transfer detail > status > Completed plugged
renamed some of the textviews to have a '_label' suffix
* [desktop] CommonUtils cleanup
* [android] Transfer Detail > Status > Time remaining plugged
* [android] Transfer Details, Status tab done
* [android] abort updateDetailProgress when transfer is null
* [android] transfer details layout cleanup
* [android] adding a recyclerview to Details, moved mock layout for its views to fragment_transfer_detail_files_recyclerview_item.xml
* [android] plugged number of files and total download size on FILES tab
* [android] started pluggin ReciclerView, still not working
* [android] got files showing on details > files. main transfer list broken, might transition to recycler view here too, testing with ListViewCompat (v7)
* [android] cleanup
* [android] cleanup
* [android] TransferFragment RecyclerView refactor (broken)
* [android] RecyclerView on TransfersFragment working
* [android] cleanup, component lookup optimization in Transfers Fragment
* [android] Progress on Transfer Detail > Details fragment
* [common] BTDownload.getTorrentHandle()
* [android] Details > Details > Comment section handled
* [android] Transfer Detail > Details tab.
Just have an issue with the 'Sequential Download' checkbox
* [android] updated torrent_details_files
* [android] progress on Transfers Details > Trackers tab
* [android] updated transfer detail trackers fragment layout
* [android] new UIUtils.showEditTextDialog
* [android] Transfer Detail > Trackers can add trackers to torrent
* [android] fixed width issues with individual tracker layout
* [android] minor refactor on TransferManager
* [android] TransferDetailStatusFragment doesn't crash on rotation
* [android] broken progress towards adding/editing trackers
* [android] fix another on rotation crash
* [android] uiBittorrentDownload is serialized and deserialized on screen rotation
* [android] set adapter after you've set the layout manager
* [android] adds and deletes trackers
* [android] trackers can be removed. edit text dialog can be configured for single/multi line
* [android] fixes issue where recycler views would not show items when tabs switched
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android] Transfer Details > Peers tab working
* [andriod] fixed build.gradle to use new plugin 3.0.0 DSL
* [android] Details tab cleanup.
- Removed 'Seeding On' checkbox. That can be handled with action bar controls for seeding/pausing
- Dialog button handlers now use lambdas
* [android] don't refresh tab if not visible cleanup
* [android] Transfer Details > Pieces tab (not working correctly)
Also lint cleanup on the activity and related fragments
* [android] few minor changes to transfer detail layouts
* [android] added and updated icons for the view_transfer_list_item
* [android] set up for the right side transfer item actions
* [android] pieces colors work, had to do r.getColor(). refactor
* [android] First pass at setting the media type icon on transfer list items
* [common] BittorrentDownload::getPredominantFileExtension()
* [android] uses BittorrentDownload's getPredominantFileExtension() to determine transfer media icon
* [android] show missing /s on transfer detail speed indicators
* [android] warning cleanup on ClickAdapter<T>
* [android] Details button on TransferListAdapter works.
TransferListAdapter refactored so that we only have a single instance for every click listener, not individual listeners for every view created
* [android] found inconsistency between download and upload rate unlimited values in libtorrent, cleanup
* [android] fixed overlapping of the text on view_transfer_detail_peer_item
* [android] updated TransferDetailDetails dialog title
* [android] added appropriate padding to the pieces view in transfer detail
* [android] fixes rotation crashes. refactors to deal with rotation
if for some reason getting pieces takes a while, an indeterminate progress bar is shown in place of the pieces
other rotation bugs fixed, more robust behavior
* [android] files becomes the first, and default selected tab
* [android] remove timer subscription responsibility from fragments
Use only one TimeObserver subscriber defined in the TransferDetailActivity.
Fragments still implement TimerObserver, have the single subscriber instance invoke the fragment's onTime method
only on the currently active fragment
* [android] SectionsPagerAdapter doesn't need to keep a reference to activity
- Just pass a SparseArray with the string resources it actually needs
- Implements a new OnPageChangeListener that keeps track of what the current fragment is
- When current fragment changes invoke onTime() on it
- Implements TimerObserver on the activity which delegates an onTime() call to the current fragment
* [android] isVisible() check no longer necessary
also found out that in some cases, isVisible() would give a false negative
* [android] more work towards avoiding issues on rotation and fast tab changes
* [android] import cleanup, if unwraps
* [android] stick to empty default constructors on YouTubeDownloadDialog
* [android] lint warnings, import cleanups
* [android] semi-aldenization of fragment code, still rotation issues
* [android] move all init calls to initComponents
* [android] cleanup. still issues on rotation, fragments not being added after rotation
* [android] finally resolved rotation issue
It seems the pager adapter and the programatic approach to adding transfers ended up in fragments not being able to be tracked correctly by their tags when the activity was reloaded.
Some of the fragments we ended up with inside detailFragments[] wouldn't be added, however, we luckily have methods in the parent AbstractFragment class to keep track of fragments that have been added (since Android only provides these after API 21 or so), by looking at the added fragments I'm able to find the correct instance and replace it inside our internal detailFragments array.
Writing this commit message makes me want to use that list, and get rid of the internal detailFragments array, to keep track of the fragments used, they could easily be filtered if they're instances of AbstractTransferDetailFragment
* [android] edit text dialog is now an extension of AbstractDialog
* [android] EditTextDialog moved to its own file, handles screen rotation
* [android] removed unused vars
* [android] rotation bug finally fixed
* [android] inline call
* [android] Transfer > Status > Time left only shown when downloading
* [android] transfer detail tab layout cleanup
* [android] transfer details details speed limit dialog issues
- When transfers are first created their upload/download rate limits come as -1
- When you want to set them to -1 for unlimited, this does not go well. You have to use 0 for unlimited, after that, they return 0
- Added a dialog closed listener that refreshes the fragment on close so new rate limit is reflected on the ui right away
* [android] remove tracker dialog look is uniform. UIUtil.showYesNoDialog now uses YesNoDialog.
* [android] don't hide time left textview, show 0 instead
* [android] progress with transfer details action bar menu
* [android] logic fix with pause/resume action bar action
* [android] updated action bar icons, added new resume aciton bar icon
* [android] removed double resume action
That action is not on the main branch, it was added later - it said resume but it was starting to seed even with seeding settings off.
* [android] updated icons for resume and cancel context menu action
* [android] added action bar seed icon
* [android] removed repeating action menu option
* [android] fixed and updated action_bar_seed icons
Sorry saved them with a wrong setting, looked pixelated
* [android] better logic on pause, resume, seed
* [android] added clear option on details.
cancel menu action uses the proper icon depending on the parameters
* [android] removed Open action from details, files are already there for individual access
* [android] added action_bar_stop_transfer icon
* [android] seeding|pausing made left most action. delete transfer sent to the context menu and cancel transfer the 2nd action shown only if room is available
* [android] use SeedAction when seedable
* [android] Update Translation: Spanish
* [android] Update Translation: Portuguese
* [android] start of HexHiveView for piece display, bye RecyclerView in this fragment
* [android] detail pieces layout cleanup
* [android] updated files and trackers layouts
RecyclerViewer no longer moves independently from the rest of hte scroll view - better user experience on small screens and horizontal views.
Fixed the files tab to open lower then top of the page.
The issue was connected to recycleviewer receiving the focus.
* [android] calculate height of other components to correctly measure height for hexhiveview
* [android] HexHiveView sizing issues fixed
- No need to manually calculate bounds when the containing layout is simpler
- fragment_transfer_detail_pieces no longer inside ScrollView, no need to scroll as our HexHiveView will only use remaining vertical space
- To make this work, view_transfer_detail_progress now has a fixed height, otherwise the folder icon would go towards the center of the screen
* [android] fix to the height of the detail_progress layout
* [android] very wip hex drawing experiments
* [android] Update Translations: French and Italian
* [android] HexView advances
- New DrawingProperties object is used to create buffer objects and useful constants for drawing the hexagonal hive
- drawing functions refactored to reduce the number of parameter copies on each onDraw iteration
- more cleanup to be done, gotta take into consideration real pixel width of hexagon borders when moving along the hive
* [android] hex fill logic implemented, wip, more fixes needed to calculate right max hex side length
* [android] fixed color assigment bug, only repaint when number of pieces downloaded has changed
* [android] made debug drawing an XML attribute. Better aproximation on desired hexagon length, still need to account for maximum rows.
* [android] simplifications
* [android] unneded file
* [android] 2.0.0 (beta) build 473
* [android] stricter checks initializing UIBittorrentDownload
* [android] no need to import Objects
* [android] Update Translation: German
* [android] NPE bullet proofing
My guess is that the NPE reported on detailProgressStatusTextView.setText(transferStateStrings.get(uiBittorrentDownload.getState())); wasn't due
to the view being null, but to the transferStateStrings object being null due to possible synchronization issues with TransferStateStrings.getInstance()
To make sure this doesn't happen, I perform another check later on, and if we've been wrongly assigned a null value, we request the singleton again.
* [android] rebasing left-overs
* [android] math brainfart calculating Y position of rows fixed
* [android] hex hive drawing fixes
* [android] cube-piece drawing support
* [android] upgrades
- don't animate tabs when touching tab title
- new CubePaint object extends Paint and calculates and keeps colors for dark left cube face and light top face out of the given fill color which is used on the right side face
* [android] adds URL validation when adding or editing trackers
* [android] fix bug with active time and seeding time calculation
when context menu actions are invoked they invoke onTime() on the underlying activity (Context that implements TimerObserver)
cleanup
* [android] s/delete/remove torrent and data/ menu entry
* [android] cleanup
* [android] avoid Runtime error trying to open transfer with no infoHash/"
Frostwire,"[WIP] Frostwire 2.0 (#624)
* [android] new layouts for the transfer detail pages
* [android] initial set up for the transfer detail activity
* [android] added toolbar menu to TransferDetails
* [android] Extended AbstractFragment from the remaining transfer detail screens
* [android] cleanup in TransferDetailActivity
* [android] added status tab to transfer details, code cleanup
* [android] added status layout to torrent details, layout code cleanup and headers
* [android] added resource values for transfer detail activity
* [android] removed unnecessary styles
* [android] adjusted style of the view_transfer_list_item
* [android] replaced missing style in view_transfer_item_list_item.xml
* [android] minor adjustement in dividers of view_transfer_list_item.xml
* [android] Transfer detail fragments reused. cleanup on fragment classes
* [android] TransferDetailActivity refactor. New AbstractTransferDetailFragment.
* [android] remove setContext hack, do it the android way
* [android] cleanup
* [android] TransferManager::getBittorrentDownload(String infoHash)
* [android] plugged BittorrentDownload object all the way to fragments
Common section with title and progress plugged. Next transfer status and upload/download speed in that common section
* [android] plugged transfer status string into common progress component
- New TransferStateStrings singleton class to map transfer states to strings
- TransferListAdapter refactored to use new TransferStateStrings
* [android] plugged download and upload speeds on common progress panel
* [android] transfer detail > status > Completed plugged
renamed some of the textviews to have a '_label' suffix
* [desktop] CommonUtils cleanup
* [android] Transfer Detail > Status > Time remaining plugged
* [android] Transfer Details, Status tab done
* [android] abort updateDetailProgress when transfer is null
* [android] transfer details layout cleanup
* [android] adding a recyclerview to Details, moved mock layout for its views to fragment_transfer_detail_files_recyclerview_item.xml
* [android] plugged number of files and total download size on FILES tab
* [android] started pluggin ReciclerView, still not working
* [android] got files showing on details > files. main transfer list broken, might transition to recycler view here too, testing with ListViewCompat (v7)
* [android] cleanup
* [android] cleanup
* [android] TransferFragment RecyclerView refactor (broken)
* [android] RecyclerView on TransfersFragment working
* [android] cleanup, component lookup optimization in Transfers Fragment
* [android] Progress on Transfer Detail > Details fragment
* [common] BTDownload.getTorrentHandle()
* [android] Details > Details > Comment section handled
* [android] Transfer Detail > Details tab.
Just have an issue with the 'Sequential Download' checkbox
* [android] updated torrent_details_files
* [android] progress on Transfers Details > Trackers tab
* [android] updated transfer detail trackers fragment layout
* [android] new UIUtils.showEditTextDialog
* [android] Transfer Detail > Trackers can add trackers to torrent
* [android] fixed width issues with individual tracker layout
* [android] minor refactor on TransferManager
* [android] TransferDetailStatusFragment doesn't crash on rotation
* [android] broken progress towards adding/editing trackers
* [android] fix another on rotation crash
* [android] uiBittorrentDownload is serialized and deserialized on screen rotation
* [android] set adapter after you've set the layout manager
* [android] adds and deletes trackers
* [android] trackers can be removed. edit text dialog can be configured for single/multi line
* [android] fixes issue where recycler views would not show items when tabs switched
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android] Transfer Details > Peers tab working
* [andriod] fixed build.gradle to use new plugin 3.0.0 DSL
* [android] Details tab cleanup.
- Removed 'Seeding On' checkbox. That can be handled with action bar controls for seeding/pausing
- Dialog button handlers now use lambdas
* [android] don't refresh tab if not visible cleanup
* [android] Transfer Details > Pieces tab (not working correctly)
Also lint cleanup on the activity and related fragments
* [android] few minor changes to transfer detail layouts
* [android] added and updated icons for the view_transfer_list_item
* [android] set up for the right side transfer item actions
* [android] pieces colors work, had to do r.getColor(). refactor
* [android] First pass at setting the media type icon on transfer list items
* [common] BittorrentDownload::getPredominantFileExtension()
* [android] uses BittorrentDownload's getPredominantFileExtension() to determine transfer media icon
* [android] show missing /s on transfer detail speed indicators
* [android] warning cleanup on ClickAdapter<T>
* [android] Details button on TransferListAdapter works.
TransferListAdapter refactored so that we only have a single instance for every click listener, not individual listeners for every view created
* [android] found inconsistency between download and upload rate unlimited values in libtorrent, cleanup
* [android] fixed overlapping of the text on view_transfer_detail_peer_item
* [android] updated TransferDetailDetails dialog title
* [android] added appropriate padding to the pieces view in transfer detail
* [android] fixes rotation crashes. refactors to deal with rotation
if for some reason getting pieces takes a while, an indeterminate progress bar is shown in place of the pieces
other rotation bugs fixed, more robust behavior
* [android] files becomes the first, and default selected tab
* [android] remove timer subscription responsibility from fragments
Use only one TimeObserver subscriber defined in the TransferDetailActivity.
Fragments still implement TimerObserver, have the single subscriber instance invoke the fragment's onTime method
only on the currently active fragment
* [android] SectionsPagerAdapter doesn't need to keep a reference to activity
- Just pass a SparseArray with the string resources it actually needs
- Implements a new OnPageChangeListener that keeps track of what the current fragment is
- When current fragment changes invoke onTime() on it
- Implements TimerObserver on the activity which delegates an onTime() call to the current fragment
* [android] isVisible() check no longer necessary
also found out that in some cases, isVisible() would give a false negative
* [android] more work towards avoiding issues on rotation and fast tab changes
* [android] import cleanup, if unwraps
* [android] stick to empty default constructors on YouTubeDownloadDialog
* [android] lint warnings, import cleanups
* [android] semi-aldenization of fragment code, still rotation issues
* [android] move all init calls to initComponents
* [android] cleanup. still issues on rotation, fragments not being added after rotation
* [android] finally resolved rotation issue
It seems the pager adapter and the programatic approach to adding transfers ended up in fragments not being able to be tracked correctly by their tags when the activity was reloaded.
Some of the fragments we ended up with inside detailFragments[] wouldn't be added, however, we luckily have methods in the parent AbstractFragment class to keep track of fragments that have been added (since Android only provides these after API 21 or so), by looking at the added fragments I'm able to find the correct instance and replace it inside our internal detailFragments array.
Writing this commit message makes me want to use that list, and get rid of the internal detailFragments array, to keep track of the fragments used, they could easily be filtered if they're instances of AbstractTransferDetailFragment
* [android] edit text dialog is now an extension of AbstractDialog
* [android] EditTextDialog moved to its own file, handles screen rotation
* [android] removed unused vars
* [android] rotation bug finally fixed
* [android] inline call
* [android] Transfer > Status > Time left only shown when downloading
* [android] transfer detail tab layout cleanup
* [android] transfer details details speed limit dialog issues
- When transfers are first created their upload/download rate limits come as -1
- When you want to set them to -1 for unlimited, this does not go well. You have to use 0 for unlimited, after that, they return 0
- Added a dialog closed listener that refreshes the fragment on close so new rate limit is reflected on the ui right away
* [android] remove tracker dialog look is uniform. UIUtil.showYesNoDialog now uses YesNoDialog.
* [android] don't hide time left textview, show 0 instead
* [android] progress with transfer details action bar menu
* [android] logic fix with pause/resume action bar action
* [android] updated action bar icons, added new resume aciton bar icon
* [android] removed double resume action
That action is not on the main branch, it was added later - it said resume but it was starting to seed even with seeding settings off.
* [android] updated icons for resume and cancel context menu action
* [android] added action bar seed icon
* [android] removed repeating action menu option
* [android] fixed and updated action_bar_seed icons
Sorry saved them with a wrong setting, looked pixelated
* [android] better logic on pause, resume, seed
* [android] added clear option on details.
cancel menu action uses the proper icon depending on the parameters
* [android] removed Open action from details, files are already there for individual access
* [android] added action_bar_stop_transfer icon
* [android] seeding|pausing made left most action. delete transfer sent to the context menu and cancel transfer the 2nd action shown only if room is available
* [android] use SeedAction when seedable
* [android] Update Translation: Spanish
* [android] Update Translation: Portuguese
* [android] start of HexHiveView for piece display, bye RecyclerView in this fragment
* [android] detail pieces layout cleanup
* [android] updated files and trackers layouts
RecyclerViewer no longer moves independently from the rest of hte scroll view - better user experience on small screens and horizontal views.
Fixed the files tab to open lower then top of the page.
The issue was connected to recycleviewer receiving the focus.
* [android] calculate height of other components to correctly measure height for hexhiveview
* [android] HexHiveView sizing issues fixed
- No need to manually calculate bounds when the containing layout is simpler
- fragment_transfer_detail_pieces no longer inside ScrollView, no need to scroll as our HexHiveView will only use remaining vertical space
- To make this work, view_transfer_detail_progress now has a fixed height, otherwise the folder icon would go towards the center of the screen
* [android] fix to the height of the detail_progress layout
* [android] very wip hex drawing experiments
* [android] Update Translations: French and Italian
* [android] HexView advances
- New DrawingProperties object is used to create buffer objects and useful constants for drawing the hexagonal hive
- drawing functions refactored to reduce the number of parameter copies on each onDraw iteration
- more cleanup to be done, gotta take into consideration real pixel width of hexagon borders when moving along the hive
* [android] hex fill logic implemented, wip, more fixes needed to calculate right max hex side length
* [android] fixed color assigment bug, only repaint when number of pieces downloaded has changed
* [android] made debug drawing an XML attribute. Better aproximation on desired hexagon length, still need to account for maximum rows.
* [android] simplifications
* [android] unneded file
* [android] 2.0.0 (beta) build 473
* [android] stricter checks initializing UIBittorrentDownload
* [android] no need to import Objects
* [android] Update Translation: German
* [android] NPE bullet proofing
My guess is that the NPE reported on detailProgressStatusTextView.setText(transferStateStrings.get(uiBittorrentDownload.getState())); wasn't due
to the view being null, but to the transferStateStrings object being null due to possible synchronization issues with TransferStateStrings.getInstance()
To make sure this doesn't happen, I perform another check later on, and if we've been wrongly assigned a null value, we request the singleton again.
* [android] rebasing left-overs
* [android] math brainfart calculating Y position of rows fixed
* [android] hex hive drawing fixes
* [android] cube-piece drawing support
* [android] upgrades
- don't animate tabs when touching tab title
- new CubePaint object extends Paint and calculates and keeps colors for dark left cube face and light top face out of the given fill color which is used on the right side face
* [android] adds URL validation when adding or editing trackers
* [android] fix bug with active time and seeding time calculation
when context menu actions are invoked they invoke onTime() on the underlying activity (Context that implements TimerObserver)
cleanup
* [android] s/delete/remove torrent and data/ menu entry
* [android] cleanup
* [android] avoid Runtime error trying to open transfer with no infoHash/"
Frostwire,"[WIP] Frostwire 2.0 (#624)
* [android] new layouts for the transfer detail pages
* [android] initial set up for the transfer detail activity
* [android] added toolbar menu to TransferDetails
* [android] Extended AbstractFragment from the remaining transfer detail screens
* [android] cleanup in TransferDetailActivity
* [android] added status tab to transfer details, code cleanup
* [android] added status layout to torrent details, layout code cleanup and headers
* [android] added resource values for transfer detail activity
* [android] removed unnecessary styles
* [android] adjusted style of the view_transfer_list_item
* [android] replaced missing style in view_transfer_item_list_item.xml
* [android] minor adjustement in dividers of view_transfer_list_item.xml
* [android] Transfer detail fragments reused. cleanup on fragment classes
* [android] TransferDetailActivity refactor. New AbstractTransferDetailFragment.
* [android] remove setContext hack, do it the android way
* [android] cleanup
* [android] TransferManager::getBittorrentDownload(String infoHash)
* [android] plugged BittorrentDownload object all the way to fragments
Common section with title and progress plugged. Next transfer status and upload/download speed in that common section
* [android] plugged transfer status string into common progress component
- New TransferStateStrings singleton class to map transfer states to strings
- TransferListAdapter refactored to use new TransferStateStrings
* [android] plugged download and upload speeds on common progress panel
* [android] transfer detail > status > Completed plugged
renamed some of the textviews to have a '_label' suffix
* [desktop] CommonUtils cleanup
* [android] Transfer Detail > Status > Time remaining plugged
* [android] Transfer Details, Status tab done
* [android] abort updateDetailProgress when transfer is null
* [android] transfer details layout cleanup
* [android] adding a recyclerview to Details, moved mock layout for its views to fragment_transfer_detail_files_recyclerview_item.xml
* [android] plugged number of files and total download size on FILES tab
* [android] started pluggin ReciclerView, still not working
* [android] got files showing on details > files. main transfer list broken, might transition to recycler view here too, testing with ListViewCompat (v7)
* [android] cleanup
* [android] cleanup
* [android] TransferFragment RecyclerView refactor (broken)
* [android] RecyclerView on TransfersFragment working
* [android] cleanup, component lookup optimization in Transfers Fragment
* [android] Progress on Transfer Detail > Details fragment
* [common] BTDownload.getTorrentHandle()
* [android] Details > Details > Comment section handled
* [android] Transfer Detail > Details tab.
Just have an issue with the 'Sequential Download' checkbox
* [android] updated torrent_details_files
* [android] progress on Transfers Details > Trackers tab
* [android] updated transfer detail trackers fragment layout
* [android] new UIUtils.showEditTextDialog
* [android] Transfer Detail > Trackers can add trackers to torrent
* [android] fixed width issues with individual tracker layout
* [android] minor refactor on TransferManager
* [android] TransferDetailStatusFragment doesn't crash on rotation
* [android] broken progress towards adding/editing trackers
* [android] fix another on rotation crash
* [android] uiBittorrentDownload is serialized and deserialized on screen rotation
* [android] set adapter after you've set the layout manager
* [android] adds and deletes trackers
* [android] trackers can be removed. edit text dialog can be configured for single/multi line
* [android] fixes issue where recycler views would not show items when tabs switched
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android/build] build.gradle flavorDimensions update for Android 3.0
* [android] Transfer Details > Peers tab working
* [andriod] fixed build.gradle to use new plugin 3.0.0 DSL
* [android] Details tab cleanup.
- Removed 'Seeding On' checkbox. That can be handled with action bar controls for seeding/pausing
- Dialog button handlers now use lambdas
* [android] don't refresh tab if not visible cleanup
* [android] Transfer Details > Pieces tab (not working correctly)
Also lint cleanup on the activity and related fragments
* [android] few minor changes to transfer detail layouts
* [android] added and updated icons for the view_transfer_list_item
* [android] set up for the right side transfer item actions
* [android] pieces colors work, had to do r.getColor(). refactor
* [android] First pass at setting the media type icon on transfer list items
* [common] BittorrentDownload::getPredominantFileExtension()
* [android] uses BittorrentDownload's getPredominantFileExtension() to determine transfer media icon
* [android] show missing /s on transfer detail speed indicators
* [android] warning cleanup on ClickAdapter<T>
* [android] Details button on TransferListAdapter works.
TransferListAdapter refactored so that we only have a single instance for every click listener, not individual listeners for every view created
* [android] found inconsistency between download and upload rate unlimited values in libtorrent, cleanup
* [android] fixed overlapping of the text on view_transfer_detail_peer_item
* [android] updated TransferDetailDetails dialog title
* [android] added appropriate padding to the pieces view in transfer detail
* [android] fixes rotation crashes. refactors to deal with rotation
if for some reason getting pieces takes a while, an indeterminate progress bar is shown in place of the pieces
other rotation bugs fixed, more robust behavior
* [android] files becomes the first, and default selected tab
* [android] remove timer subscription responsibility from fragments
Use only one TimeObserver subscriber defined in the TransferDetailActivity.
Fragments still implement TimerObserver, have the single subscriber instance invoke the fragment's onTime method
only on the currently active fragment
* [android] SectionsPagerAdapter doesn't need to keep a reference to activity
- Just pass a SparseArray with the string resources it actually needs
- Implements a new OnPageChangeListener that keeps track of what the current fragment is
- When current fragment changes invoke onTime() on it
- Implements TimerObserver on the activity which delegates an onTime() call to the current fragment
* [android] isVisible() check no longer necessary
also found out that in some cases, isVisible() would give a false negative
* [android] more work towards avoiding issues on rotation and fast tab changes
* [android] import cleanup, if unwraps
* [android] stick to empty default constructors on YouTubeDownloadDialog
* [android] lint warnings, import cleanups
* [android] semi-aldenization of fragment code, still rotation issues
* [android] move all init calls to initComponents
* [android] cleanup. still issues on rotation, fragments not being added after rotation
* [android] finally resolved rotation issue
It seems the pager adapter and the programatic approach to adding transfers ended up in fragments not being able to be tracked correctly by their tags when the activity was reloaded.
Some of the fragments we ended up with inside detailFragments[] wouldn't be added, however, we luckily have methods in the parent AbstractFragment class to keep track of fragments that have been added (since Android only provides these after API 21 or so), by looking at the added fragments I'm able to find the correct instance and replace it inside our internal detailFragments array.
Writing this commit message makes me want to use that list, and get rid of the internal detailFragments array, to keep track of the fragments used, they could easily be filtered if they're instances of AbstractTransferDetailFragment
* [android] edit text dialog is now an extension of AbstractDialog
* [android] EditTextDialog moved to its own file, handles screen rotation
* [android] removed unused vars
* [android] rotation bug finally fixed
* [android] inline call
* [android] Transfer > Status > Time left only shown when downloading
* [android] transfer detail tab layout cleanup
* [android] transfer details details speed limit dialog issues
- When transfers are first created their upload/download rate limits come as -1
- When you want to set them to -1 for unlimited, this does not go well. You have to use 0 for unlimited, after that, they return 0
- Added a dialog closed listener that refreshes the fragment on close so new rate limit is reflected on the ui right away
* [android] remove tracker dialog look is uniform. UIUtil.showYesNoDialog now uses YesNoDialog.
* [android] don't hide time left textview, show 0 instead
* [android] progress with transfer details action bar menu
* [android] logic fix with pause/resume action bar action
* [android] updated action bar icons, added new resume aciton bar icon
* [android] removed double resume action
That action is not on the main branch, it was added later - it said resume but it was starting to seed even with seeding settings off.
* [android] updated icons for resume and cancel context menu action
* [android] added action bar seed icon
* [android] removed repeating action menu option
* [android] fixed and updated action_bar_seed icons
Sorry saved them with a wrong setting, looked pixelated
* [android] better logic on pause, resume, seed
* [android] added clear option on details.
cancel menu action uses the proper icon depending on the parameters
* [android] removed Open action from details, files are already there for individual access
* [android] added action_bar_stop_transfer icon
* [android] seeding|pausing made left most action. delete transfer sent to the context menu and cancel transfer the 2nd action shown only if room is available
* [android] use SeedAction when seedable
* [android] Update Translation: Spanish
* [android] Update Translation: Portuguese
* [android] start of HexHiveView for piece display, bye RecyclerView in this fragment
* [android] detail pieces layout cleanup
* [android] updated files and trackers layouts
RecyclerViewer no longer moves independently from the rest of hte scroll view - better user experience on small screens and horizontal views.
Fixed the files tab to open lower then top of the page.
The issue was connected to recycleviewer receiving the focus.
* [android] calculate height of other components to correctly measure height for hexhiveview
* [android] HexHiveView sizing issues fixed
- No need to manually calculate bounds when the containing layout is simpler
- fragment_transfer_detail_pieces no longer inside ScrollView, no need to scroll as our HexHiveView will only use remaining vertical space
- To make this work, view_transfer_detail_progress now has a fixed height, otherwise the folder icon would go towards the center of the screen
* [android] fix to the height of the detail_progress layout
* [android] very wip hex drawing experiments
* [android] Update Translations: French and Italian
* [android] HexView advances
- New DrawingProperties object is used to create buffer objects and useful constants for drawing the hexagonal hive
- drawing functions refactored to reduce the number of parameter copies on each onDraw iteration
- more cleanup to be done, gotta take into consideration real pixel width of hexagon borders when moving along the hive
* [android] hex fill logic implemented, wip, more fixes needed to calculate right max hex side length
* [android] fixed color assigment bug, only repaint when number of pieces downloaded has changed
* [android] made debug drawing an XML attribute. Better aproximation on desired hexagon length, still need to account for maximum rows.
* [android] simplifications
* [android] unneded file
* [android] 2.0.0 (beta) build 473
* [android] stricter checks initializing UIBittorrentDownload
* [android] no need to import Objects
* [android] Update Translation: German
* [android] NPE bullet proofing
My guess is that the NPE reported on detailProgressStatusTextView.setText(transferStateStrings.get(uiBittorrentDownload.getState())); wasn't due
to the view being null, but to the transferStateStrings object being null due to possible synchronization issues with TransferStateStrings.getInstance()
To make sure this doesn't happen, I perform another check later on, and if we've been wrongly assigned a null value, we request the singleton again.
* [android] rebasing left-overs
* [android] math brainfart calculating Y position of rows fixed
* [android] hex hive drawing fixes
* [android] cube-piece drawing support
* [android] upgrades
- don't animate tabs when touching tab title
- new CubePaint object extends Paint and calculates and keeps colors for dark left cube face and light top face out of the given fill color which is used on the right side face
* [android] adds URL validation when adding or editing trackers
* [android] fix bug with active time and seeding time calculation
when context menu actions are invoked they invoke onTime() on the underlying activity (Context that implements TimerObserver)
cleanup
* [android] s/delete/remove torrent and data/ menu entry
* [android] cleanup
* [android] avoid Runtime error trying to open transfer with no infoHash/"
Frostwire,[android] attempt to fix the ANR caused by io.presage.receiver.NetworkChangeReceiver/
Frostwire,[desktop] fixed SystemUtilities internal GetJavaWindowHandle for Windows x64/
Frostwire,[desktop] Search Database factory reset on clear failure/
Frostwire,[desktop] NPE on transfer click/
Frostwire,[desktop] removed non-functional (and completely broken code) related notifications display/
Frostwire,[desktop] fixed issue of both thumb to the left in range slider/
Frostwire,"[desktop] avoid one more deprecation suppresion, FilePane/"
Frostwire,[desktop] avoid use of private AWT api in MPlayerOverlayControls/
Frostwire,[desktop] avoid direct use of eawt FullScreenUtilities class/
Frostwire,"[android] Adjustments in BTEngine.instance() and stop()
- Cannot set a timeout when waiting for the context. Tests with 1 minute show how this can cause breakage elsewhere. Behaves well otherwise, nothing locks the UI thread and those that need the BTEngine instance will happily wait.
- Only throw illegal state if you can't find a context and you're supposed to be running. Otherwise it means you never really started and you shouldn't complain about not having the context.
- Override stop() to make sure that all pending threads waiting for a latch can be released and shutdown happens properly WHEN we're stopped prematurely. e.g. quick open and exit case./"
Frostwire,"[common] truncate long file names to 127 chars for BaseHttpDownload
This error might be ocurring with other transfer types/"
Frostwire,[common] Zooqle search fixed/
Frostwire,[common] Zooqle search fixed/
Frostwire,[common] commented debug log in extractor/
Frostwire,[common] Zooqle search fixed/
Frostwire,[common] Zooqle search fixed/
Frostwire,[common] LimeTorrentsSearchPerformer fix/[common] Zooqle search fixed/
Frostwire,[common] Zooqle search fixed/
Frostwire,[common] TorrentDownloads search title matching fix. More results/[common] Zooqle search fixed/
Frostwire,[common] fixed yi-fi/[common] Zooqle search fixed/
Frostwire,[android] should solve issue with non-responding keyword filter first time its flipped to negation/
Frostwire,[common] Zooqle search fixed/
Frostwire,"[android] avoid wrong thread exception, adapter.notifyDataSetChanged must occur in the UI thread/[android] Issue #652 - ANR on ApolloFragment.onSongItemClick fixed/"
Frostwire,[android] more mopub fixes/[android] NPE on AudioPlayerActivity.onPrepareOptionsMenu/[android] Avoid possible NPE taking screenshot/[android] Apollo ImageFetcher NPE protections/
Frostwire,[android] NPE on ProfileActivity onPrepareOptionsMenu/
Frostwire,[android] Apollo ImageFetcher NPE protections/
Frostwire,"[android] crash fix closing notification player, refactor, FIXME note/[android] Android Oreo(8) notification issues fixed/[android] Notifications work on Android 8.0 - Issue #691/[android] apollo NotificationHelper fixes
- remove unused parameter
- remove unnecessary final keyword
- catch possible IllegalArgumentException exception on service.startForefound/"
Frostwire,[android] at least print exceptions in DragSortListView/[android] DragSortListView. abort disptachDraw if parent fails/
Frostwire,[android] DeleteDialog imageFetcher NPE protection. typo fixed/
Frostwire,"[android] NPE on MusicPlaybackService
albumArt can be null/[android] capture IllegalStateException in MusicPlaybackService#openFile/[android] bug fix, notification music player goes away when music fully stopped on miniplayer
thanks @muckahina/[android] Android Oreo(8) notification issues fixed/[android] NPE on MusicPlaybackService.initNextMediaPlayer/[android] NPE on MusicPlayer::playSimple/[android] apollo NotificationHelper fixes
- remove unused parameter
- remove unnecessary final keyword
- catch possible IllegalArgumentException exception on service.startForefound/[android] catch NPE from android/[android] build 509. VPN Page fixes
- One more MusicPlaybackService recentsStoreAddSongIdTask async cleanup
- build 509
- Adjusted view_vpn_status_detail to look good all the way down to 3.7' screens
- removed unused old vpn strings
- All 'Wi-Fi' strings are now spelled uniformly
- Fixed VPN copy, more concise, no 'etc's, brought back 'Privacy is a fundamental human right'
- Renamed VPN constants to denote that they represent urls with _URL suffixes
- SoftwareUpdater cleanup
- Click listeners turned to lambdas on VPNStatusDetailActivity
- Updated date in license header to 2018/[android] IndexOutOfBounds exception on MusicPlaybackService.getNextPosition/[android] array out of bounds exception getting next song in shuffle mode
aparently there's a possibility for mHistory to change its size during those iterations, to avoid the issue I've made a copy of it and iterate over the copy/[android] Prevent ArrayIndexOutofBounds error on MusicPlaybackService::addToPlayList/"
Frostwire,"[android] Simplifications
- PrebidInitializer renamed to PrebidManager
- PrebidManager no longer has background initialization, unnecessary as it performs
expensive network IO on its internal executor
- PrebidManager.Placement enums created
- AdUnits also added to Map<Placement, AdUnit> to quickly obtain ad unit based on placement at bidding attachment time
- Added mock sizes to test ad units
- Caught Mopub error on which receiver leak warning would not allow for banner to be inflated. We attempt destroying the listener and re-inflating (still not convinced this will help, might revert soon, looking for the cause of the error)/[android] refactor prebid onBanner<Load|Failed> integration to a single liner/[android] SearchHeaderBanner listener onBannerFailed prebid logic/[android] PreBid integration on Search Header Banner
Also NPE protection before inflating search header banner view/"
Frostwire,"[android] Simplifications
- PrebidInitializer renamed to PrebidManager
- PrebidManager no longer has background initialization, unnecessary as it performs
expensive network IO on its internal executor
- PrebidManager.Placement enums created
- AdUnits also added to Map<Placement, AdUnit> to quickly obtain ad unit based on placement at bidding attachment time
- Added mock sizes to test ad units
- Caught Mopub error on which receiver leak warning would not allow for banner to be inflated. We attempt destroying the listener and re-inflating (still not convinced this will help, might revert soon, looking for the cause of the error)/[android] Offers.forceDisabledAds optimization
Only stop ad networks if you started them in the first place./"
Frostwire,"[android] crash fix closing notification player, refactor, FIXME note/"
Frostwire,[android] avoid header update with wrong data in MyFilesFragment#onLoadFinished/
Frostwire,[android] build fix/[android] CalledFromWrongThreadException on TransfersFragment.updateTransferList/[android] CalledFromWrongThreadException on TransfersFragment.updateTransferList/
Frostwire,"[android] build fix/[android] s/StartDownloadTask/AsyncStartDownload refactor
Favors use of Asyncs api over buggy ContextTask/[android] workaround fix in notifyHistogramsUpdate to avoid excessive number of tasks in background/[android] should solve issue with non-responding keyword filter first time its flipped to negation/"
Frostwire,"[android] build 509. VPN Page fixes
- One more MusicPlaybackService recentsStoreAddSongIdTask async cleanup
- build 509
- Adjusted view_vpn_status_detail to look good all the way down to 3.7' screens
- removed unused old vpn strings
- All 'Wi-Fi' strings are now spelled uniformly
- Fixed VPN copy, more concise, no 'etc's, brought back 'Privacy is a fundamental human right'
- Renamed VPN constants to denote that they represent urls with _URL suffixes
- SoftwareUpdater cleanup
- Click listeners turned to lambdas on VPNStatusDetailActivity
- Updated date in license header to 2018/[android] SoftwareUpdater scope reduction fix
No need for casts when you pass the right parameter. Reduced from Context to MainActivity, this class is only used by MainActivity.
Refactored use of UIUtil yes no dialog to pass the MainActivity's FragmentManager/"
Frostwire,"[android] can't replicate Zombie Torrent issue anymore
It seems the ContentResolver didn't perform the physical file deletion when it came to .torrent files
Also fixed NPE on UIBittorrentDownload/"
Frostwire,"[android] IllegalArgument exception fix/[android] Issue #547
- When audio files are deleted from 'My Files' they're cleared from 'Recents' in 'My Music'
- We make sure all deletion logic occurs in a background thread, including the adapter's internal collections are modified in the background
- AbstractListAdapter's addItem(item) and deleteItem(item) methods only call notifyDataSetChanged() if on the main thread. This way we can call addItem or deleteItem
from a background thread multiple times without trying to communicate with main thread and then we can invoke adapter.notifyDataSetChanged() once on the main thread when we're finished
- License header updates
- Librarian.deleteFiles() uses MusicUtils.deleteTracks() if the files passed are audio files
- MusicUtils.deleteTracks() had a bug where it tried to delete the Recent's cache using the wrong data field, I believe this is because in the past Recents would display Recent albums, not recent tracks./"
Frostwire,[android] Issue #653. Don't hog the main thread checking SD permissions on resume/
Frostwire,[android] remove stack-overflow causing brainfart on YesNoDialog/[android] better fix for YesNoDialog clicklisteners/[android] Bug fix handling YesNoDialogs without positive or negative custom listeners/
Frostwire,"[android] s/StartDownloadTask/AsyncStartDownload refactor
Favors use of Asyncs api over buggy ContextTask/"
Frostwire,"[android] possible NPE on Android 4.4 (MainActivity.onKeyDown)/[android] MainActivity cleanup
- Dice roll refactor to use UIUtils.diceRollPassesThreshold
- NPE warnings fixed
- Removed TODO/[android] IllegalStateException on MainActivity.switchContent/[android] Context leak at com.frostwire.android.gui.MainApplication.onCreateSafe(MainApplication.java:102)/[android] possible NPE on MainActivity.refreshTransfers
The startActivity() call begins, but somewhere deep inside ViewGroup.java it can throw an NPE.
My guess is that this can happen at a moment in time while the activity is being destroyed.
Rare crash./[android] catch possible IllegalStateException showing SD permission dlg/[android] Issue #547
- When audio files are deleted from 'My Files' they're cleared from 'Recents' in 'My Music'
- We make sure all deletion logic occurs in a background thread, including the adapter's internal collections are modified in the background
- AbstractListAdapter's addItem(item) and deleteItem(item) methods only call notifyDataSetChanged() if on the main thread. This way we can call addItem or deleteItem
from a background thread multiple times without trying to communicate with main thread and then we can invoke adapter.notifyDataSetChanged() once on the main thread when we're finished
- License header updates
- Librarian.deleteFiles() uses MusicUtils.deleteTracks() if the files passed are audio files
- MusicUtils.deleteTracks() had a bug where it tried to delete the Recent's cache using the wrong data field, I believe this is because in the past Recents would display Recent albums, not recent tracks./[android] Issue #653. Don't hog the main thread checking SD permissions on resume/"
Frostwire,[android] avoid calling async when just a post (it's delayed) is used in refreshMenuRemoveAdsItem/[android] CalledFromWrongThreadException crash on NavigationMenu.refreshMenuRemoveAdsItem/
Frostwire,[android] patch fix for NPE in loadFallbackBanner/
Frostwire,"[android] build 509. VPN Page fixes
- One more MusicPlaybackService recentsStoreAddSongIdTask async cleanup
- build 509
- Adjusted view_vpn_status_detail to look good all the way down to 3.7' screens
- removed unused old vpn strings
- All 'Wi-Fi' strings are now spelled uniformly
- Fixed VPN copy, more concise, no 'etc's, brought back 'Privacy is a fundamental human right'
- Renamed VPN constants to denote that they represent urls with _URL suffixes
- SoftwareUpdater cleanup
- Click listeners turned to lambdas on VPNStatusDetailActivity
- Updated date in license header to 2018/"
Frostwire,"[android] EngineThreadPool disables task queue size verification
when the debugger is connected. Renamed .isEnable to .isEnabled (English grammar fix)/"
Frostwire,"[android] Issue #547
- When audio files are deleted from 'My Files' they're cleared from 'Recents' in 'My Music'
- We make sure all deletion logic occurs in a background thread, including the adapter's internal collections are modified in the background
- AbstractListAdapter's addItem(item) and deleteItem(item) methods only call notifyDataSetChanged() if on the main thread. This way we can call addItem or deleteItem
from a background thread multiple times without trying to communicate with main thread and then we can invoke adapter.notifyDataSetChanged() once on the main thread when we're finished
- License header updates
- Librarian.deleteFiles() uses MusicUtils.deleteTracks() if the files passed are audio files
- MusicUtils.deleteTracks() had a bug where it tried to delete the Recent's cache using the wrong data field, I believe this is because in the past Recents would display Recent albums, not recent tracks./"
Frostwire,[android] cleanup of commented log debug output in AbstractFragment/
Frostwire,"[android] Android Oreo(8) notification issues fixed/[android] Notifications work on Android 8.0 - Issue #691/[android] EngineService async refactors, no warnings.
- ResumeBTEngine async refactor
- Component enabling async refactor
- Notification cancellation async refactor
- Permanent Notification Updates start async refactor
- null checks
- syncrhonization on local variable warning fixed/[android] compilation fix/[android] One last ANR on EngineService.onStartCommand and fixes
- Moved the start of the NotificationUpdateDemon to a background thread, it was the only ANR coming out of here with the last build.
- Since shutdownSupport is already a background thread no need to spawn more subthreads for component disable and NotificationCanceller
- Added some try/catch protections on all those methods to avoid unexpected crashes during startup/shutdown/[android] Cancel All Notifications refactor on EngineService
When starting the app the main thread could be held gettings the notification system service, which in android 7 has the possibility of a security exception (catched already), then all notifications are asked to be cancelled.
This code was repeated also when shutting down, also on the main thread
This has now been moved to a background runnable to make startup and shutdown faster to the user./[android] ConfigurationManager fixes.
1. There should be only a single call to ConfigurationManager.create(Application)
My theory is that ConfigurationManager.preferences was null because PreferenceManager.getDefaultSharedPreferences(Context context) was failing in the case where somehow EngineService was the one calling ConfigurationManager.create(getApplication() -> invalid object here)
The correct place for that call is on MainApplication.onCreate(), now there's only one call
2. ConfigurationManager getter methods now throw IllegalStateException if the preferences property is null, the application simply can't work without this, don't hide errors
3. Moved BTEngineInitializer thread a bit later in case too early of an initialization was causing the NPE issue on the ConfigurationManager (doubt it but it doesn't hurt to move it after Engine.instance().onApplicationCreate/[android] typo on EngineService debug output/[android] don't stop what hasn't started
Thanks @aldeml/[android] ANR on EngineService components startup - Issue #655/"
Frostwire,"[desktop] transfer tab fixes
- Transfer Tab components were not taking all vertical space available on big screens
- Added new 'Hide' button on Transfer Details, will turn it into an icon based button next/[desktop] last 2 usability bugs with transfers fixed
- It will correctly scroll to the last selected transfer after the details component is shown
- It will not wait for the next refresh to update the details component the first time it's shown/"
Frostwire,[desktop] LibraryExplorer min dimensions fix. cleanup/
Frostwire,[desktop] NPE fixed on LibraryPlaylists.refresh()/
Frostwire,"[desktop] transfer tab fixes
- Transfer Tab components were not taking all vertical space available on big screens
- Added new 'Hide' button on Transfer Details, will turn it into an icon based button next/"
Frostwire,"[desktop] added code to stop the refresh timer during the shutdown/[desktop] New: Send Feedback Dialog
* [issue-632] Adding Send Feedback Dialog
* [issue-632]Adding  Send Feedback Dialog
* [desktop] temp
* [desktop][issue-632] Adding Send Feedback action
* [desktop][issue-632] Updated endpoint
* [desktop][issue-632] warning fixes
* [desktop][issue-632] Adding Your Name field to SendFeedback Dialog
* [desktop][issue-632] Adding validations to Dialog
* [desktop][issue-632] improvements to Send Feedback Dialog
* [desktop][issue-632] misc fixes & refactors
* [desktop][issue-632] system info output in HTML or not
* [desktop][issue-632] Feedback interval to 5 mins, make sure user can copy & paste long messages and layout doesn't break
* [desktop] cleanup/"
Frostwire,[desktop] added code to stop the refresh timer during the shutdown/
Frostwire,"[desktop] New: Send Feedback Dialog
* [issue-632] Adding Send Feedback Dialog
* [issue-632]Adding  Send Feedback Dialog
* [desktop] temp
* [desktop][issue-632] Adding Send Feedback action
* [desktop][issue-632] Updated endpoint
* [desktop][issue-632] warning fixes
* [desktop][issue-632] Adding Your Name field to SendFeedback Dialog
* [desktop][issue-632] Adding validations to Dialog
* [desktop][issue-632] improvements to Send Feedback Dialog
* [desktop][issue-632] misc fixes & refactors
* [desktop][issue-632] system info output in HTML or not
* [desktop][issue-632] Feedback interval to 5 mins, make sure user can copy & paste long messages and layout doesn't break
* [desktop] cleanup/"
Frostwire,[common] eztv fixed seeds number and phantom search results/[common/desktop] Yify search fixes/
Frostwire,[common/desktop] Yify search fixes/
Frostwire,[common/desktop] Yify search fixes/
Frostwire,"[common] fixed limetorrents regex for title issue/[common] limetorrents fix, now it needs to use magnet/"
Frostwire,[common/desktop] Yify search fixes/
Frostwire,[common] fixed TorrentDownloads by switching to magnet/[common/desktop] Yify search fixes/
Frostwire,"[common] yifi fix, back to /movie/ page/[common/desktop] Yify search fixes/"
Frostwire,"[android] Fix empty message for playlist detailed view (#721)
* [android] Fix empty message for playlist detailed view
* [android] Changing empty text for PlaylistSongFragment
* [android] Cleaning up imports. Using the default constructor/"
Frostwire,"[android] Music player saves shuffle preferences
Fixes also an array out of bound when trying to play the first song of a playlist when the last shuffle mode was true.
Other refactors./[android] Fix empty message for playlist detailed view (#721)
* [android] Fix empty message for playlist detailed view
* [android] Changing empty text for PlaylistSongFragment
* [android] Cleaning up imports. Using the default constructor/"
Frostwire,[android] Changing itemsOffset parameter in SongFragment to avoid blank row creating at the end of the list/
Frostwire,"[android] Music player saves shuffle preferences
Fixes also an array out of bound when trying to play the first song of a playlist when the last shuffle mode was true.
Other refactors./"
Frostwire,"[android] Music player saves shuffle preferences
Fixes also an array out of bound when trying to play the first song of a playlist when the last shuffle mode was true.
Other refactors./"
Frostwire,"[android] NPE on AudioPlayer.onPrepareOptionsMenu (equalizer)/[android] NPE sharing curring track fixed/[android] logic fix for plus/[android] Don't show interstitial when leaving AudioPlayerActivity
Despite attempts to fix the issue with some media interstitials hijacking the audio, they still occur as I witnessed today during a run while I dismissed the audio player screen. To avoid annoying users with this no interstitials should be played if the user dismisses the screen and music is being played/[android] don't stop music playback on applovin video ads
indentation also/[android] Music player saves shuffle preferences
Fixes also an array out of bound when trying to play the first song of a playlist when the last shuffle mode was true.
Other refactors./[android] Less intrusive interstitial ads (#726)
* [android] No more interstitial on resume
No interstitial should be done before a transitional action, otherwise it's too annoying and gets in the way of the user experience
[android
* [android] okhttp3 pro-guard rules
* [android] interstitial logic on back pressed
* [android] interstitial logic on nav menu
other fixes and code added for API's completion and consistency on MainController and MainActivity/"
Frostwire,"[android] Music player saves shuffle preferences
Fixes also an array out of bound when trying to play the first song of a playlist when the last shuffle mode was true.
Other refactors./[android] Less intrusive interstitial ads (#726)
* [android] No more interstitial on resume
No interstitial should be done before a transitional action, otherwise it's too annoying and gets in the way of the user experience
[android
* [android] okhttp3 pro-guard rules
* [android] interstitial logic on back pressed
* [android] interstitial logic on nav menu
other fixes and code added for API's completion and consistency on MainController and MainActivity/"
Frostwire,"[android] Music player saves shuffle preferences
Fixes also an array out of bound when trying to play the first song of a playlist when the last shuffle mode was true.
Other refactors./"
Frostwire,"[android] NPE protections/[android] Fixes Illegal arg exception on random.nextInt()/[android] Music player saves shuffle preferences
Fixes also an array out of bound when trying to play the first song of a playlist when the last shuffle mode was true.
Other refactors./"
Frostwire,"[android] Music player saves shuffle preferences
Fixes also an array out of bound when trying to play the first song of a playlist when the last shuffle mode was true.
Other refactors./"
Frostwire,"[android] Music player saves shuffle preferences
Fixes also an array out of bound when trying to play the first song of a playlist when the last shuffle mode was true.
Other refactors./"
Frostwire,"[android] don't stop music playback on applovin video ads
indentation also/"
Frostwire,"[android] don't stop music playback on applovin video ads
indentation also/"
Frostwire,"[android] MoPub initialization
Add a starting state to avoid redundant calls to MopPub.initializeSdk
Don't try to initialize if you received a null activity.
There are still issues with MoPub 5.2.0 initialization, a lot of times that initialization just never finishes./[android] don't stop music playback on applovin video ads
indentation also/[android] Less intrusive interstitial ads (#726)
* [android] No more interstitial on resume
No interstitial should be done before a transitional action, otherwise it's too annoying and gets in the way of the user experience
[android
* [android] okhttp3 pro-guard rules
* [android] interstitial logic on back pressed
* [android] interstitial logic on nav menu
other fixes and code added for API's completion and consistency on MainController and MainActivity/"
Frostwire,"[android] using internal PrebidManager application context in calls to attachBids.
It happens that although not documented, the context in attachBids is used in multiple places internally, and a context leak is possible if it's not an application context./"
Frostwire,"[android] fixed compilation issue/[android] Less intrusive interstitial ads (#726)
* [android] No more interstitial on resume
No interstitial should be done before a transitional action, otherwise it's too annoying and gets in the way of the user experience
[android
* [android] okhttp3 pro-guard rules
* [android] interstitial logic on back pressed
* [android] interstitial logic on nav menu
other fixes and code added for API's completion and consistency on MainController and MainActivity/"
Frostwire,"[android] Less intrusive interstitial ads (#726)
* [android] No more interstitial on resume
No interstitial should be done before a transitional action, otherwise it's too annoying and gets in the way of the user experience
[android
* [android] okhttp3 pro-guard rules
* [android] interstitial logic on back pressed
* [android] interstitial logic on nav menu
other fixes and code added for API's completion and consistency on MainController and MainActivity/"
Frostwire,"[android] fixed connection type string in peers details/[desktop/android] crash fix getting peer client name, thanks @aldenml/[android] compilation fix/[desktop/android] crash fix getting peer client name, thanks @aldenml/[android] compilation fix/"
Frostwire,"[android] Less intrusive interstitial ads (#726)
* [android] No more interstitial on resume
No interstitial should be done before a transitional action, otherwise it's too annoying and gets in the way of the user experience
[android
* [android] okhttp3 pro-guard rules
* [android] interstitial logic on back pressed
* [android] interstitial logic on nav menu
other fixes and code added for API's completion and consistency on MainController and MainActivity/[android] fixed context leak related to mopub view destroy in MainActivity/"
Frostwire,"[android] Less intrusive interstitial ads (#726)
* [android] No more interstitial on resume
No interstitial should be done before a transitional action, otherwise it's too annoying and gets in the way of the user experience
[android
* [android] okhttp3 pro-guard rules
* [android] interstitial logic on back pressed
* [android] interstitial logic on nav menu
other fixes and code added for API's completion and consistency on MainController and MainActivity/"
Frostwire,"[android] Fixes Illegal arg exception on random.nextInt()/[android] LocalSearchEngine.instance() refactor
A refactor to avoid a rare NPE getting the instance, also should slightly improve app startup time.
- Removes LocalSearchEngine.onCreate()
- LocalSearchEngine.instance() should never return null, uses synchronization only once in most cases and in the rare event it will somehow be called at the same time during startup.
The bug probably existed because instance() was somehow being called before MainApplication.onCreate()/"
Frostwire,"[android] avoid crash on KitKat showing mopub banner/[android] Less intrusive interstitial ads (#726)
* [android] No more interstitial on resume
No interstitial should be done before a transitional action, otherwise it's too annoying and gets in the way of the user experience
[android
* [android] okhttp3 pro-guard rules
* [android] interstitial logic on back pressed
* [android] interstitial logic on nav menu
other fixes and code added for API's completion and consistency on MainController and MainActivity/"
Frostwire,"[android] Less intrusive interstitial ads (#726)
* [android] No more interstitial on resume
No interstitial should be done before a transitional action, otherwise it's too annoying and gets in the way of the user experience
[android
* [android] okhttp3 pro-guard rules
* [android] interstitial logic on back pressed
* [android] interstitial logic on nav menu
other fixes and code added for API's completion and consistency on MainController and MainActivity/"
Frostwire,"[android] Less intrusive interstitial ads (#726)
* [android] No more interstitial on resume
No interstitial should be done before a transitional action, otherwise it's too annoying and gets in the way of the user experience
[android
* [android] okhttp3 pro-guard rules
* [android] interstitial logic on back pressed
* [android] interstitial logic on nav menu
other fixes and code added for API's completion and consistency on MainController and MainActivity/"
Frostwire,[android] avoid display of BuyActivity with no data from local Play Store cache/
Frostwire,"[android] Fixes freeze loading GDPR consent dialog
cleanup, formatting/[android] Less intrusive interstitial ads (#726)
* [android] No more interstitial on resume
No interstitial should be done before a transitional action, otherwise it's too annoying and gets in the way of the user experience
[android
* [android] okhttp3 pro-guard rules
* [android] interstitial logic on back pressed
* [android] interstitial logic on nav menu
other fixes and code added for API's completion and consistency on MainController and MainActivity/[android] fixed context leak related to mopub view destroy in MainActivity/"
Frostwire,"[android] Less intrusive interstitial ads (#726)
* [android] No more interstitial on resume
No interstitial should be done before a transitional action, otherwise it's too annoying and gets in the way of the user experience
[android
* [android] okhttp3 pro-guard rules
* [android] interstitial logic on back pressed
* [android] interstitial logic on nav menu
other fixes and code added for API's completion and consistency on MainController and MainActivity/"
Frostwire,[android] NPE protections/
Frostwire,"[android] don't stop music playback on applovin video ads
indentation also/"
Frostwire,[desktop] fix macOS handling of open files/
Frostwire,[desktop] NPE fix on search result click/
Frostwire,"[android] BaseHttpDownload update
- On error, map out SocketTimeoutException to TransferState.ERROR_CONNETION_TIMED_OUT
- Show more info about failed BaseHttpDownload (BaseHttpDownload.Info::toString() implemented)/"
Frostwire,[common] more fixes in YT signature detection/
Frostwire,[common] fix YT prefix offset index/
Frostwire,"[common] Archive.org, fixed stream only results and save path/"
Frostwire,"[android] bug fix dismissing fallback banner on music player/[android] safely register Playbackstatus broadcast receiver
avoids possible IllegalStatus crash/[android] NPE issue #184 with FWVibrator/"
Frostwire,"[android] ANR fix on loadMopubInterstitial/[android] AdMob loading fixed/[android] simplification, cleanup, no need to stop ad-network
No need to stop ad-network when interstitial has been marked for shutdown upon dismissed.
for one, we no longer show interstitials on the way out, and second, we should do the network shutdown logic on MainActivity.shutdown() and that's not to be the case anymore/[android] hack to workaround the use of AsyncTask.SERIAL_EXECUTOR inside MoPub initialization/"
Frostwire,"[android] Prebid instantiation can fail, protect MoPub banner dispatchers
found:
08-07 15:56:37.631 29218 29218 I PrebidManager: Creating PrebidManager singleton
08-07 15:56:37.632 29218 29218 I Prebid  : Initializing with a list of AdUnits
08-07 15:56:37.634 29218 29218 W System.err: org.prebid.mobile.core.PrebidException: Unable to instantiating the adapter.
08-07 15:56:37.636 29218 29218 W System.err: at org.prebid.mobile.core.Prebid.init(Prebid.java:141)
08-07 15:56:37.636 29218 29218 W System.err: at com.frostwire.android.offers.PrebidManager.initializePrebid(PrebidManager.java:186)
08-07 15:56:37.636 29218 29218 W System.err: at com.frostwire.android.offers.PrebidManager.<init>(PrebidManager.java:107)
08-07 15:56:37.636 29218 29218 W System.err: at com.frostwire.android.offers.PrebidManager.getInstance(PrebidManager.java:84)
08-07 15:56:37.636 29218 29218 W System.err: at com.frostwire.android.offers.Offers.initAdNetworks(Offers.java:79)
08-07 15:56:37.636 29218 29218 W System.err: at com.frostwire.android.gui.activities.MainActivity.onResume(MainActivity.java:355)
08-07 15:56:37.636 29218 29218 W System.err: at android.app.Instrumentation.callActivityOnResume(Instrumentation.java:1361)
08-07 15:56:37.636 29218 29218 W System.err: at android.app.Activity.performResume(Activity.java:7344)
08-07 15:56:37.636 29218 29218 W System.err: at android.app.ActivityThread.performResumeActivity(ActivityThread.java:3763)
08-07 15:56:37.636 29218 29218 W System.err: at android.app.ActivityThread.handleResumeActivity(ActivityThread.java:3828)
08-07 15:56:37.636 29218 29218 W System.err: at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3036)
08-07 15:56:37.636 29218 29218 W System.err: at android.app.ActivityThread.-wrap11(Unknown Source:0)
08-07 15:56:37.636 29218 29218 W System.err: at android.app.ActivityThread.handleMessage(ActivityThread.java:1696)
08-07 15:56:37.636 29218 29218 W System.err: at android.os.Handler.dispatchMessage(Handler.java:105)
08-07 15:56:37.636 29218 29218 W System.err: at android.os.Looper.loop(Looper.java:164)
08-07 15:56:37.636 29218 29218 W System.err: at android.app.ActivityThread.main(ActivityThread.java:6938)
08-07 15:56:37.636 29218 29218 W System.err: at java.lang.reflect.Method.invoke(Native Method)
08-07 15:56:37.636 29218 29218 W System.err: at com.android.internal.os.Zygote.run(Zygote.java:327)
08-07 15:56:37.636 29218 29218 W System.err: at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1374)/"
Frostwire,"[android] note after onBannerFailed manual reload experiment/[android] MopubBannerView repairs
- Avoid ANRs, don't perform banner load on main thread
- Support for fallback banner loaded/dismissed listeners
- Don't use the banner onLoadListener after you load the fallback banner
- Do not destroy the banner onLoadFailed otherwise further banners cannot be loaded
- No need to keep reloading the fallback banner over and over
- onDismissBannerOnClickListener refactor and use of possibly given banner and fallback banner dismissed listeners used/[android] Prebid instantiation can fail, protect MoPub banner dispatchers
found:
08-07 15:56:37.631 29218 29218 I PrebidManager: Creating PrebidManager singleton
08-07 15:56:37.632 29218 29218 I Prebid  : Initializing with a list of AdUnits
08-07 15:56:37.634 29218 29218 W System.err: org.prebid.mobile.core.PrebidException: Unable to instantiating the adapter.
08-07 15:56:37.636 29218 29218 W System.err: at org.prebid.mobile.core.Prebid.init(Prebid.java:141)
08-07 15:56:37.636 29218 29218 W System.err: at com.frostwire.android.offers.PrebidManager.initializePrebid(PrebidManager.java:186)
08-07 15:56:37.636 29218 29218 W System.err: at com.frostwire.android.offers.PrebidManager.<init>(PrebidManager.java:107)
08-07 15:56:37.636 29218 29218 W System.err: at com.frostwire.android.offers.PrebidManager.getInstance(PrebidManager.java:84)
08-07 15:56:37.636 29218 29218 W System.err: at com.frostwire.android.offers.Offers.initAdNetworks(Offers.java:79)
08-07 15:56:37.636 29218 29218 W System.err: at com.frostwire.android.gui.activities.MainActivity.onResume(MainActivity.java:355)
08-07 15:56:37.636 29218 29218 W System.err: at android.app.Instrumentation.callActivityOnResume(Instrumentation.java:1361)
08-07 15:56:37.636 29218 29218 W System.err: at android.app.Activity.performResume(Activity.java:7344)
08-07 15:56:37.636 29218 29218 W System.err: at android.app.ActivityThread.performResumeActivity(ActivityThread.java:3763)
08-07 15:56:37.636 29218 29218 W System.err: at android.app.ActivityThread.handleResumeActivity(ActivityThread.java:3828)
08-07 15:56:37.636 29218 29218 W System.err: at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3036)
08-07 15:56:37.636 29218 29218 W System.err: at android.app.ActivityThread.-wrap11(Unknown Source:0)
08-07 15:56:37.636 29218 29218 W System.err: at android.app.ActivityThread.handleMessage(ActivityThread.java:1696)
08-07 15:56:37.636 29218 29218 W System.err: at android.os.Handler.dispatchMessage(Handler.java:105)
08-07 15:56:37.636 29218 29218 W System.err: at android.os.Looper.loop(Looper.java:164)
08-07 15:56:37.636 29218 29218 W System.err: at android.app.ActivityThread.main(ActivityThread.java:6938)
08-07 15:56:37.636 29218 29218 W System.err: at java.lang.reflect.Method.invoke(Native Method)
08-07 15:56:37.636 29218 29218 W System.err: at com.android.internal.os.Zygote.run(Zygote.java:327)
08-07 15:56:37.636 29218 29218 W System.err: at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1374)/"
Frostwire,"[android] don't crash if adnetwork fails initialization/[android] NPE issue #184 with FWVibrator/[android] simplification, cleanup, no need to stop ad-network
No need to stop ad-network when interstitial has been marked for shutdown upon dismissed.
for one, we no longer show interstitials on the way out, and second, we should do the network shutdown logic on MainActivity.shutdown() and that's not to be the case anymore/[android] possible bug: don't stop network on finish activity/"
Frostwire,"[android] fixes issue where transfers wouldn't appear right away
The old adapter instance kept coming back with 0 transfers for about 30 seconds. On destroy let's make sure the adapter reference is removed, next time the fragment is created a new adapter is created and it works right away when restoring a session from exit.
perhaps the adapter should have a way to clear its inner lists  adapter.onDestroy() ?/"
Frostwire,[android] NPE issue #184 with FWVibrator/[android] try to fix context leak related to mopub promotions view destroy/
Frostwire,[android] NPE issue #184 with FWVibrator/
Frostwire,[android] NPE issue #184 with FWVibrator/
Frostwire,"[android] simplification, cleanup, no need to stop ad-network
No need to stop ad-network when interstitial has been marked for shutdown upon dismissed.
for one, we no longer show interstitials on the way out, and second, we should do the network shutdown logic on MainActivity.shutdown() and that's not to be the case anymore/[android] try to fix context leak related to mopub promotions view destroy/"
Frostwire,[android] NPE issue #184 with FWVibrator/
Frostwire,[android] NPE issue #184 with FWVibrator/
Frostwire,"[android] simplification, cleanup, no need to stop ad-network
No need to stop ad-network when interstitial has been marked for shutdown upon dismissed.
for one, we no longer show interstitials on the way out, and second, we should do the network shutdown logic on MainActivity.shutdown() and that's not to be the case anymore/"
Frostwire,"[common/android] crash fix due to libtorrent.generate_fingerprint param intake
the last int tag parameter has to be a number between 0-19, otherwise the string returned contains a character that makes androids crash due to incompatible UTF being generated by libtorrent/"
Frostwire,"[android] Transfers > Clear all finished update
It will also clear errored transfers/"
Frostwire,[common] EZTV Search fix/
Frostwire,"[android] SwitchPreference rendering issues fixed after sdk 28
min sdk bumped from 16 to 19 (android 4.4, app didn't really work on 4.1 and very little installs)/"
Frostwire,[android] bugfix where music playback and audio ad could play simultaneously/
Frostwire,[android] mopub interstitial loading bugfix/
Frostwire,"[android] don't crash, just warn, this can happen now that it's async/[android] NoSuchMethodError caught in ImageLoader.calculateDiskSize
can occur in very old Android 4.2 now that we've upped the target/"
Frostwire,"[android] Transfers > Clear all finished update
It will also clear errored transfers/"
Frostwire,"[android] revert async mopubBannerView.loadMoPubBanner call
when view was destroyed not being on the main thread would cause the app to crash/[android] fix ANR on PromotionsAdapter loading mopub view/"
Frostwire,"[android] revert async mopubBannerView.loadMoPubBanner call
when view was destroyed not being on the main thread would cause the app to crash/[android] fix ANR on PromotionsAdapter loading mopub view/"
Frostwire,"[desktop] more deprecation fixes, NPE catches, cleanup/"
Frostwire,[desktop] bug loading SystemUtilities.dll on windows 64 (no longer called SystemUtilitiesX64.dll)/
Frostwire,"[desktop] deprecation fixes, unboxing, labmda refactors/"
Frostwire,"[desktop] deprecation fixes, unboxing, labmda refactors/"
Frostwire,"[desktop] deprecation fixes, unboxing, labmda refactors/"
Frostwire,"[desktop] more deprecation fixes, NPE catches, cleanup/"
Frostwire,"[desktop] more deprecation fixes, NPE catches, cleanup/"
Frostwire,"[desktop] deprecation fixes, unboxing, labmda refactors/"
Frostwire,"[desktop] more deprecation fixes, NPE catches, cleanup/"
Frostwire,"[desktop] cleanup, refactors, deprecation fixes/"
Frostwire,"[desktop] deprecation fixes, unboxing, labmda refactors/"
Frostwire,"[desktop] cleanup, refactors, deprecation fixes/"
Frostwire,"[desktop] cleanup, refactors, deprecation fixes/"
Frostwire,"[desktop] cleanup, refactors, deprecation fixes/"
Frostwire,"[desktop] cleanup, refactors, deprecation fixes/"
Frostwire,[common] SC fixed/
Frostwire,[common] archive.org http -> https request fixes search on android/
Frostwire,"[android] b585. Fixes promos url parameter passing, other promo display on androdi issue/"
Frostwire,"[android] applovin 9.4.2, okhttp client npe fixes/"
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] fix non-atomic ops on volatile fields/[desktop] declaration access fixes/
Frostwire,[desktop] javadoc issues cleanup/
Frostwire,"[desktop] azureus debug code cleanup/[desktop] cleanup empty methods, encapsulation fixes/"
Frostwire,"[desktop] azureus debug code cleanup/[desktop] java7 <T> -> <> explicit types fix/[desktop] cleanup empty methods, encapsulation fixes/"
Frostwire,[desktop] azureus debug code cleanup/
Frostwire,[desktop] declaration access fixes/[desktop] synchronized on non final fields warnings fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,"[common/desktop] avoid numeric overflow when dealing with large file sizes
jlibtorrent needs a few fixes/"
Frostwire,"[desktop] declaration access fixes/[common/desktop] avoid numeric overflow when dealing with large file sizes
jlibtorrent needs a few fixes/"
Frostwire,"[common/desktop] avoid numeric overflow when dealing with large file sizes
jlibtorrent needs a few fixes/"
Frostwire,[desktop] declaration access fixes/[desktop] azureus debug code cleanup/
Frostwire,"[desktop] declaration access fixes/[common/desktop] avoid numeric overflow when dealing with large file sizes
jlibtorrent needs a few fixes/"
Frostwire,"[common/desktop] avoid numeric overflow when dealing with large file sizes
jlibtorrent needs a few fixes/"
Frostwire,"[desktop] Fixes 'Time remaining' rendering bug/[common/desktop] avoid numeric overflow when dealing with large file sizes
jlibtorrent needs a few fixes/"
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,"[common/desktop] avoid numeric overflow when dealing with large file sizes
jlibtorrent needs a few fixes/"
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/[desktop] javadoc issues cleanup/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/[desktop] javadoc issues cleanup/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,"[desktop] MacOSXUtils update
- removed old multi architecture build of libMacOSXUtilsLeopard.jnilib
- Added debug messages to libMacOSXUtils.jnilib to show when app is added/removed from apps in macOS startup list
- libMacOSXUtilsLeopard -> libMacOSXUtils
- Don't attempt to invoke native function to add app to startup list when running from source/"
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] javadoc issues cleanup/
Frostwire,[desktop] declaration access fixes/[desktop] javadoc issues cleanup/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] javadoc issues cleanup/
Frostwire,[desktop] declaration access fixes/[desktop] javadoc issues cleanup/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/[desktop] javadoc issues cleanup/
Frostwire,[desktop] declaration access fixes/[desktop] javadoc issues cleanup/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/[desktop] javadoc issues cleanup/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/[desktop] javadoc issues cleanup/
Frostwire,[desktop] declaration access fixes/[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/[desktop] more cleanups and fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,"[desktop] declaration access fixes/[common/desktop] avoid numeric overflow when dealing with large file sizes
jlibtorrent needs a few fixes/"
Frostwire,"[common/desktop] avoid numeric overflow when dealing with large file sizes
jlibtorrent needs a few fixes/"
Frostwire,[desktop] more cleanups and fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] more cleanups and fixes/
Frostwire,[desktop] javadoc issues cleanup/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] more cleanups and fixes/
Frostwire,"[desktop] declaration access fixes/[common/desktop] avoid numeric overflow when dealing with large file sizes
jlibtorrent needs a few fixes/"
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/[desktop] javadoc issues cleanup/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,[desktop] declaration access fixes/
Frostwire,"[common/desktop] avoid numeric overflow when dealing with large file sizes
jlibtorrent needs a few fixes/"
Frostwire,"[common/desktop] avoid numeric overflow when dealing with large file sizes
jlibtorrent needs a few fixes/"
Frostwire,[common] Nyaa search fixed and optimized/
Frostwire,[android] compilation issues fixed/
Frostwire,[android] compilation issues fixed/
Frostwire,"[common] Torrentz2 and TorLock are magnet based exclusively
This will lead to less download torrent errors caused by broken links or Cloudfare errors and keep the DHT performing lots of queries and keeping the keys/buckets with the .torrents alive, the more the merrier/"
Frostwire,[android] avoid static leak on ImageCache.flush()/
Frostwire,[android] Fixes issue #848/[android] fixes on EngineService startup/shutdown/
Frostwire,[android] avert crash on MoPub interstitial destruction/
Frostwire,"[common] Torrentz2 and TorLock are magnet based exclusively
This will lead to less download torrent errors caused by broken links or Cloudfare errors and keep the DHT performing lots of queries and keeping the keys/buckets with the .torrents alive, the more the merrier/"
Frostwire,"[desktop/mac] .dylibs signed
- libosx_jdk8.dylib contains native dispatch functions for macOS, this needs to be rebuilt to pass new mac notarization process
the new .dylib will only contain Dispatch.m symbols as the rest are not used, memory savings yay.
Source here: https://github.com/bpupadhyaya/openjdk-8/blob/master/jdk/src/macosx/native/com/apple/concurrent/Dispatch.m
- libJMPlayer.dylib needs to be rebuilt as well with newer MacOS SDK to pass notarization, this will be a bitch but it might help fix
a few bugs of the MPlayer on macOS/"
Frostwire,[android] purchase flow bug on new billing sdk fixed/
Frostwire,[android] fixes on EngineService startup/shutdown/
Frostwire,"[desktop] make sure SC.getDownloadURL() never happens on main thread
other fixes for copy paste url downloads/"
Frostwire,"[desktop] Fixes issues w/NetworkInterfacePanelItem, startBittorrentCore fixes
- Code to select network interfaces and port in Initializer.startBittorrentCore() and NetworkInterfacePanelItem.applyOptions() refactored to avoid code repetition.
- A crash and a  on NetworkInterfacePanelItem.applyOptions() prevented FrostWire from saving the preferred network interface
- NetworkInterfacePanelItem now shows the network interfaces that make sense. Excludes localLink addresses, loopback or other ineligible network interfaces.
- RouterConfigurationPaneItem port range picking refactored
- org.limewire.util.NetworkUtils gets new functions
public static int getPortInRange(boolean useManualRange,
int defaultPort0,
int defaultPort1,
int manualPort0,
int manualPort1)
public static String getLibtorrentFormattedNetworkInterface(boolean useCustomNetworkInterface,
String defaultInetAddress,
String customInetAddress,
final int port)
public static boolean isLinkLocal(Address address)/"
Frostwire,"[desktop] make sure SC.getDownloadURL() never happens on main thread
other fixes for copy paste url downloads/"
Frostwire,"[desktop] make sure SC.getDownloadURL() never happens on main thread
other fixes for copy paste url downloads/"
Frostwire,"[android] Fixes issue where an existing partial torrent transfer could not add more items from a .torrent in My files
it's not working 100% of the way, trying to figure out why the uiBittorrentDownload in the Transfer Detail fragment isn't updated all the times, it works most of the times.
Gets wonky if the transfer is paused sometimes, but if you try again it will add all of the specified files. Gotta come back to this/"
Frostwire,[common] make sure HEAD http connections are not leaked/
Frostwire,"[android] fixes issue where it appeared as if there were no search results
The LocalSearchEngineListener would lose its SearchFragment reference and wasn't able to report results on ocassions/"
Frostwire,"[common] SC client_id update, fixes issue #858/[common] SC fixes
- avoid deserialization NPE when media == null
- resolve url updated
- multitrack download fixes/"
Frostwire,"[android] Major MusicPlaybackService overhaul
- The most important playback issues are gone, playback continues through playlist, repeat modes work
- There's still a glitch on the very first song played, gotta hit play again, will fix
Now MusicPlaybackService is supposed to receive all of its background calls, or perhaps, all calls routed through its MusicPlayerHandler Thread/Loop. If all calls are routed through this queue, there should be no need to synchronize any resource and there should be no unexpected behaviors.
No more expensive synchronized blocks, no more deadlocks. synchronized is evil.
Also, no more anonymous callbacks, or nested callbacks. Since everything is done on the background and it doesn't block the UI thread, all methods that used to receive callbacks now return boolean, true for sucess, false for failure, usually on success callbacks are acted upon. Some callbacks used to get boolean results, it's now very 'functional' or a la go-lang, keep it simple stupid.
anonymous callbacks, dynamic runnables and lambdas are also hard to debug/trace, it's perhaps a bit more verbose but it's clean and easy to read in stack traces and to step through in the debugger.
Still a lot more to fix: album art not loading properly in song adapter or music activity/"
Frostwire,"[android] Save to playlist fixed, build 624/"
Frostwire,"[android/apollo] Simplification of MusicPlaybackService lifecycle.
Instead of constantly trying to cancel a shutdown alarm, the service is not started until it's needed and stopped as soon as playback is fully stopped.
Removed a bunch of unncessary stuff around that old logic/"
Frostwire,"[android] array out of bounds issue adding uiTransfer to TransferManager, mopub banner on basic home/[android] Major MusicPlaybackService overhaul
- The most important playback issues are gone, playback continues through playlist, repeat modes work
- There's still a glitch on the very first song played, gotta hit play again, will fix
Now MusicPlaybackService is supposed to receive all of its background calls, or perhaps, all calls routed through its MusicPlayerHandler Thread/Loop. If all calls are routed through this queue, there should be no need to synchronize any resource and there should be no unexpected behaviors.
No more expensive synchronized blocks, no more deadlocks. synchronized is evil.
Also, no more anonymous callbacks, or nested callbacks. Since everything is done on the background and it doesn't block the UI thread, all methods that used to receive callbacks now return boolean, true for sucess, false for failure, usually on success callbacks are acted upon. Some callbacks used to get boolean results, it's now very 'functional' or a la go-lang, keep it simple stupid.
anonymous callbacks, dynamic runnables and lambdas are also hard to debug/trace, it's perhaps a bit more verbose but it's clean and easy to read in stack traces and to step through in the debugger.
Still a lot more to fix: album art not loading properly in song adapter or music activity/[android] Fixes issue where player would stop at the end of a song
## MusicPlaybackService is now decoupled from Asyncs.async/EngineThreadPool
Do not compromise the performance of search and download when using the
music player. Sending all background requests to a single HandlerThread
in MusicPlaybackService makes things a lot simpler, less chances for
race conditions if all requests are executed in the order they're requested
given all the synchronized blocks we inherited from Apollo's codebase
More fine grained intervals when notifying music player changes, depending
on the change being notified
There are still glitches with Repeat song mode, this code is full of overcomplexities that are hard to track down.
## My Music / Art Albums not loading
Started debugging and doing a few fixes, album art isn't loading correctly
for some reason/[android/apollo] Simplification of MusicPlaybackService lifecycle.
Instead of constantly trying to cancel a shutdown alarm, the service is not started until it's needed and stopped as soon as playback is fully stopped.
Removed a bunch of unncessary stuff around that old logic/[android] NPE that could happen if mMopubBannerView wasn't created due to ad removal/[android] NPE on AudioPlayer, logic fix
don't abort banner initialization if player is paused and hasn't reached the minimum seconds to load the ad, player is paused.../[android] crash only if on debug build/[android] async AudioPlayerActivity::updateLastKnown can optionally callback AudioPlayerActivity::onLastKnownUpdatePostTask when done
Fixes bug on which the song's title wasn't updated accordingly/[android] fix double notification issue/"
Frostwire,"[android] Fixes crash when searching within My Music/[android] avoid issues registering intent receivers
Avoid issues that could prevent intent receivers from not being unregistered, in case we still have them, don't crash when you are already registered/[android] Save to playlist fixed, build 624/[android] cleanup and crashes starting music player from my music gone
Tested all the way from Android 5.0 to Android 10/[android/apollo] Simplification of MusicPlaybackService lifecycle.
Instead of constantly trying to cancel a shutdown alarm, the service is not started until it's needed and stopped as soon as playback is fully stopped.
Removed a bunch of unncessary stuff around that old logic/"
Frostwire,"[android] Fixes crash when searching within My Music/[android] cleanup and crashes starting music player from my music gone
Tested all the way from Android 5.0 to Android 10/[android/apollo] Simplification of MusicPlaybackService lifecycle.
Instead of constantly trying to cancel a shutdown alarm, the service is not started until it's needed and stopped as soon as playback is fully stopped.
Removed a bunch of unncessary stuff around that old logic/"
Frostwire,[android/apollo] ImageCache optimizations and fixes/
Frostwire,"[android] Major MusicPlaybackService overhaul
- The most important playback issues are gone, playback continues through playlist, repeat modes work
- There's still a glitch on the very first song played, gotta hit play again, will fix
Now MusicPlaybackService is supposed to receive all of its background calls, or perhaps, all calls routed through its MusicPlayerHandler Thread/Loop. If all calls are routed through this queue, there should be no need to synchronize any resource and there should be no unexpected behaviors.
No more expensive synchronized blocks, no more deadlocks. synchronized is evil.
Also, no more anonymous callbacks, or nested callbacks. Since everything is done on the background and it doesn't block the UI thread, all methods that used to receive callbacks now return boolean, true for sucess, false for failure, usually on success callbacks are acted upon. Some callbacks used to get boolean results, it's now very 'functional' or a la go-lang, keep it simple stupid.
anonymous callbacks, dynamic runnables and lambdas are also hard to debug/trace, it's perhaps a bit more verbose but it's clean and easy to read in stack traces and to step through in the debugger.
Still a lot more to fix: album art not loading properly in song adapter or music activity/"
Frostwire,"[android] add to playlist should happen in handler thread
also fixes infinite loop bug/[android] avoid issues registering intent receivers
Avoid issues that could prevent intent receivers from not being unregistered, in case we still have them, don't crash when you are already registered/[android] don't crash attempting to register intent receiver on MusicPlaybackService.initService
java.lang.IllegalStateException:
at android.os.Parcel.createException (Parcel.java:1974)
at android.os.Parcel.readException (Parcel.java:1934)
at android.os.Parcel.readException (Parcel.java:1884)
at android.app.IActivityManager.registerReceiver (IActivityManager.java:3690)
at android.app.ContextImpl.registerReceiverInternal (ContextImpl.java:1567)
at android.app.ContextImpl.registerReceiver (ContextImpl.java:1528)
at android.app.ContextImpl.registerReceiver (ContextImpl.java:1516)
at android.content.ContextWrapper.registerReceiver (ContextWrapper.java:636)
at com.andrew.apollo.MusicPlaybackService.initService (MusicPlaybackService.java:892)
at com.andrew.apollo.MusicPlaybackService.lambda (Unknown Source)
at com.andrew.apollo.-57443Lambda.run (Unknown Source:2)
at android.os.Handler.handleCallback (Handler.java:873)
at android.os.Handler.dispatchMessage (Handler.java:99)
at android.os.Looper.loop (Looper.java:214)/[android] Save to playlist fixed, build 624/[android] Major MusicPlaybackService overhaul
- The most important playback issues are gone, playback continues through playlist, repeat modes work
- There's still a glitch on the very first song played, gotta hit play again, will fix
Now MusicPlaybackService is supposed to receive all of its background calls, or perhaps, all calls routed through its MusicPlayerHandler Thread/Loop. If all calls are routed through this queue, there should be no need to synchronize any resource and there should be no unexpected behaviors.
No more expensive synchronized blocks, no more deadlocks. synchronized is evil.
Also, no more anonymous callbacks, or nested callbacks. Since everything is done on the background and it doesn't block the UI thread, all methods that used to receive callbacks now return boolean, true for sucess, false for failure, usually on success callbacks are acted upon. Some callbacks used to get boolean results, it's now very 'functional' or a la go-lang, keep it simple stupid.
anonymous callbacks, dynamic runnables and lambdas are also hard to debug/trace, it's perhaps a bit more verbose but it's clean and easy to read in stack traces and to step through in the debugger.
Still a lot more to fix: album art not loading properly in song adapter or music activity/[android] Fixes issue where player would stop at the end of a song
## MusicPlaybackService is now decoupled from Asyncs.async/EngineThreadPool
Do not compromise the performance of search and download when using the
music player. Sending all background requests to a single HandlerThread
in MusicPlaybackService makes things a lot simpler, less chances for
race conditions if all requests are executed in the order they're requested
given all the synchronized blocks we inherited from Apollo's codebase
More fine grained intervals when notifying music player changes, depending
on the change being notified
There are still glitches with Repeat song mode, this code is full of overcomplexities that are hard to track down.
## My Music / Art Albums not loading
Started debugging and doing a few fixes, album art isn't loading correctly
for some reason/[android] MusicPlaybackService encapsulation fixes/[android] Fixes issue creating ephemeral playlist/[android] intent registration crash detected in some android 9's (IllegalState)/[android] fixes after crash reports from 618
relaxed syncrhonization on entire MusicPlaybackService
simplifications and cleanups
multiplayer got lost (null)/[android] cleanup and crashes starting music player from my music gone
Tested all the way from Android 5.0 to Android 10/[android] don't crash if you can't unbind serviceconnection listener on service shutdown/[android/apollo] Simplification of MusicPlaybackService lifecycle.
Instead of constantly trying to cancel a shutdown alarm, the service is not started until it's needed and stopped as soon as playback is fully stopped.
Removed a bunch of unncessary stuff around that old logic/[android] bullet proof access to MusicPlaybackService::mPlayer (rare NPE crash fix attempt/[android] Fixes player notification bug where play/pause button wasn't refreshed on pause/[android] don't sweat Illegal State error onNotificationCreated()/[android] fix double notification issue/[android] MusicPlaybackService updates
- AudioManager AudioFocusRequest based integration for Android O+
- Don't call Engine.foregroundServicesStartForAndroidO(this), this seems to have been broken, it wasn't sending an icon and it included no information
whatever the case we can't be using that mechanism.
- Initialization of repeat mode and shuffle is now done in an async task. This code would make use of the ConfigurationManager.instance() which can freeze the main thread if there are IO issues
- mAudioManager.abandonAudioFocusRequest(AUDIO_FOCUS_REQUEST_ for Android O+
- cancelShutdown async tasks throttled to be spaced at least with 1 second in between
- notifyChange async task submissions are now throttled. META_CHANGE to 100ms, other changes to 200ms/"
Frostwire,"[android] Major MusicPlaybackService overhaul
- The most important playback issues are gone, playback continues through playlist, repeat modes work
- There's still a glitch on the very first song played, gotta hit play again, will fix
Now MusicPlaybackService is supposed to receive all of its background calls, or perhaps, all calls routed through its MusicPlayerHandler Thread/Loop. If all calls are routed through this queue, there should be no need to synchronize any resource and there should be no unexpected behaviors.
No more expensive synchronized blocks, no more deadlocks. synchronized is evil.
Also, no more anonymous callbacks, or nested callbacks. Since everything is done on the background and it doesn't block the UI thread, all methods that used to receive callbacks now return boolean, true for sucess, false for failure, usually on success callbacks are acted upon. Some callbacks used to get boolean results, it's now very 'functional' or a la go-lang, keep it simple stupid.
anonymous callbacks, dynamic runnables and lambdas are also hard to debug/trace, it's perhaps a bit more verbose but it's clean and easy to read in stack traces and to step through in the debugger.
Still a lot more to fix: album art not loading properly in song adapter or music activity/"
Frostwire,[android] MoPubAdNetwork test ad units. Interstitial loading bug fix/
Frostwire,"[android] array out of bounds issue adding uiTransfer to TransferManager, mopub banner on basic home/[android] catch more exceptions on messages sent to main looper, warnings, cleanup/[android] avoid possible crash leaving My Music/"
Frostwire,"[android] catch more exceptions on messages sent to main looper, warnings, cleanup/"
Frostwire,"[android] Fixes issue where player would stop at the end of a song
## MusicPlaybackService is now decoupled from Asyncs.async/EngineThreadPool
Do not compromise the performance of search and download when using the
music player. Sending all background requests to a single HandlerThread
in MusicPlaybackService makes things a lot simpler, less chances for
race conditions if all requests are executed in the order they're requested
given all the synchronized blocks we inherited from Apollo's codebase
More fine grained intervals when notifying music player changes, depending
on the change being notified
There are still glitches with Repeat song mode, this code is full of overcomplexities that are hard to track down.
## My Music / Art Albums not loading
Started debugging and doing a few fixes, album art isn't loading correctly
for some reason/[android] protect UI thread from unexpected crashes when posting to main looper
if ran on development environment the crash still happens, should lower to some extent a lot of vague crashes posting messages from unknown locations to the main thread/"
Frostwire,"[android] Fixes issue where player would stop at the end of a song
## MusicPlaybackService is now decoupled from Asyncs.async/EngineThreadPool
Do not compromise the performance of search and download when using the
music player. Sending all background requests to a single HandlerThread
in MusicPlaybackService makes things a lot simpler, less chances for
race conditions if all requests are executed in the order they're requested
given all the synchronized blocks we inherited from Apollo's codebase
More fine grained intervals when notifying music player changes, depending
on the change being notified
There are still glitches with Repeat song mode, this code is full of overcomplexities that are hard to track down.
## My Music / Art Albums not loading
Started debugging and doing a few fixes, album art isn't loading correctly
for some reason/[android] catch more exceptions on messages sent to main looper, warnings, cleanup/"
Frostwire,[android] possible crash on MyFilesFragment registering broadcast receiver/
Frostwire,"[android] catch more exceptions on messages sent to main looper, warnings, cleanup/[android] fixes timer unsubscription issues in TransfersFragment/"
Frostwire,"[android] continuation of 3b6e8383180696202c7589e960c7aeb5a9534b6d
Recovers if it loses reference to fragment manager. Simple, effective but possibly risky approach of keeping a static reference to the living SearchFragment in a static variable in case the weak reference is lost. The reference is always removed and rewritten when the search fragment is destroyed, created or resumed. Gotta keep an eye for OOM errors after this hack/[android] fixes issue where it appeared as if there were no search results
The LocalSearchEngineListener would lose its SearchFragment reference and wasn't able to report results on ocassions/[android/common] Fixed synchronization issues with Keyword detector
Tried:
- Minimize synchronized block spans
- Don't synchronize the collection object, use an Object as the monitor instead
- The issue was that on one end the submission time was measured with SystemClock.elapsedRealtime, and on the other end with System.currentTimeMillis
I might just remove all mentions of SystemClock.ellapsedRealtime from the code base to avoid these issues in the future
- Some cleanups/[android] catch more exceptions on messages sent to main looper, warnings, cleanup/"
Frostwire,"[android] UIBittorrentDownload not always had a listener set
Refactor: Moved UIBittorrentDownload.StatusListener to its own class UIBTDownloadListener.
Made sure that the BTDownload inside the UIBittorrentDownload always has a UIBTDownloadListener to notify of important events, like finishing.
Made sure we perform a finalCleanup if we're not seeding after a download finishes.
There's still an issue with 1 out of N files not being scanned upon download finishing./[android/common] Fixed synchronization issues with Keyword detector
Tried:
- Minimize synchronized block spans
- Don't synchronize the collection object, use an Object as the monitor instead
- The issue was that on one end the submission time was measured with SystemClock.elapsedRealtime, and on the other end with System.currentTimeMillis
I might just remove all mentions of SystemClock.ellapsedRealtime from the code base to avoid these issues in the future
- Some cleanups/[android] Fixes issue where an existing partial torrent transfer could not add more items from a .torrent in My files
it's not working 100% of the way, trying to figure out why the uiBittorrentDownload in the Transfer Detail fragment isn't updated all the times, it works most of the times.
Gets wonky if the transfer is paused sometimes, but if you try again it will add all of the specified files. Gotta come back to this/[android] cleanup and crashes starting music player from my music gone
Tested all the way from Android 5.0 to Android 10/"
Frostwire,[android] update dialog starts apk download on browser if apk install fails/
Frostwire,"[android] UIBittorrentDownload not always had a listener set
Refactor: Moved UIBittorrentDownload.StatusListener to its own class UIBTDownloadListener.
Made sure that the BTDownload inside the UIBittorrentDownload always has a UIBTDownloadListener to notify of important events, like finishing.
Made sure we perform a finalCleanup if we're not seeding after a download finishes.
There's still an issue with 1 out of N files not being scanned upon download finishing./[android] possible NPE on transfer removal/"
Frostwire,"[android] fixes issue where it appeared as if there were no search results
The LocalSearchEngineListener would lose its SearchFragment reference and wasn't able to report results on ocassions/[android] possible crash when searching way too fast after the app opens/"
Frostwire,"[android] array out of bounds issue adding uiTransfer to TransferManager, mopub banner on basic home/[android] fix buggy behavior of PromotionsAdapter, simply offer ad removal everytime/"
Frostwire,[android] update dialog starts apk download on browser if apk install fails/
Frostwire,"[android] array out of bounds issue adding uiTransfer to TransferManager, mopub banner on basic home/[android] Fixes issue where an existing partial torrent transfer could not add more items from a .torrent in My files
it's not working 100% of the way, trying to figure out why the uiBittorrentDownload in the Transfer Detail fragment isn't updated all the times, it works most of the times.
Gets wonky if the transfer is paused sometimes, but if you try again it will add all of the specified files. Gotta come back to this/"
Frostwire,"[android] protect UI thread from unexpected crashes when posting to main looper
if ran on development environment the crash still happens, should lower to some extent a lot of vague crashes posting messages from unknown locations to the main thread/[android] fix crash dismissing Remove Ads interstitial, cleanup/"
Frostwire,"[android] continuation of 3b6e8383180696202c7589e960c7aeb5a9534b6d
Recovers if it loses reference to fragment manager. Simple, effective but possibly risky approach of keeping a static reference to the living SearchFragment in a static variable in case the weak reference is lost. The reference is always removed and rewritten when the search fragment is destroyed, created or resumed. Gotta keep an eye for OOM errors after this hack/[android] fixes after crash reports from 618
relaxed syncrhonization on entire MusicPlaybackService
simplifications and cleanups
multiplayer got lost (null)/[android/apollo] Simplification of MusicPlaybackService lifecycle.
Instead of constantly trying to cancel a shutdown alarm, the service is not started until it's needed and stopped as soon as playback is fully stopped.
Removed a bunch of unncessary stuff around that old logic/[android] crash: MainActivity.registerMainBroadcastReceiver/"
Frostwire,"[android] protect UI thread from unexpected crashes when posting to main looper
if ran on development environment the crash still happens, should lower to some extent a lot of vague crashes posting messages from unknown locations to the main thread/"
Frostwire,"[android] Major MusicPlaybackService overhaul
- The most important playback issues are gone, playback continues through playlist, repeat modes work
- There's still a glitch on the very first song played, gotta hit play again, will fix
Now MusicPlaybackService is supposed to receive all of its background calls, or perhaps, all calls routed through its MusicPlayerHandler Thread/Loop. If all calls are routed through this queue, there should be no need to synchronize any resource and there should be no unexpected behaviors.
No more expensive synchronized blocks, no more deadlocks. synchronized is evil.
Also, no more anonymous callbacks, or nested callbacks. Since everything is done on the background and it doesn't block the UI thread, all methods that used to receive callbacks now return boolean, true for sucess, false for failure, usually on success callbacks are acted upon. Some callbacks used to get boolean results, it's now very 'functional' or a la go-lang, keep it simple stupid.
anonymous callbacks, dynamic runnables and lambdas are also hard to debug/trace, it's perhaps a bit more verbose but it's clean and easy to read in stack traces and to step through in the debugger.
Still a lot more to fix: album art not loading properly in song adapter or music activity/"
Frostwire,"[android/apollo] Simplification of MusicPlaybackService lifecycle.
Instead of constantly trying to cancel a shutdown alarm, the service is not started until it's needed and stopped as soon as playback is fully stopped.
Removed a bunch of unncessary stuff around that old logic/"
Frostwire,[android] crash caught on AbstractActivity.onResume()/
Frostwire,"[android] EngineService recovers BTEngine perfectly on exit/restart
In the process:
- Made boolean state volatile
- Added thread safety mechanisms to change state. A lock and an updateState method which was used to debug what was happening
- Nothing was making sense because every time we talked to the service for stopping or shutting down, it seems as if we were working with a new instance of the service, so you don't really want to keep states in the service and expect it will remain, therefore the solution was to make state a static private variable for EngineService/"
javacpp,"* Before loading the JNI library, the `Loader` now also tries to extract and load libraries listed in the `@Platform(link={...}, preload={...})` annotation values, and to support library names with version numbers, each value has to follow the format ""libname@version"" (or ""libname@@version"" to have `Builder` use it for the compiler as well), where ""version"" is the version number found in the filename as required by the native dynamic linker, usually a short sequence of digits and dots, but it can be anything (e.g.: ""mylib@.4.2"" would map to ""libmylib.so.4.2"", ""libmylib.4.2.dylib"", and ""mylib.4.2.dll"" under Linux, Mac OS X, and Windows respectively)
* Stopped using `java.net.URL` as hash key in `Loader` (very bad idea)/Fixed Maven build and Mac OS X `-framework` option (issue #10) and other minor things/"
javacpp,"* Fixed `Pointer.equals(null)` throwing `NullPointerException` (issue #22)
* `@NoOffset` would erroneously prevent `sizeof()` operations from getting generated/"
javacpp,"* Exported `Loader.isLoadLibraries()`, which always returns true, except when the `Builder` loads the classes
* Made it possible to specify a nested class (with a '$' character in the name) on the command line
* When `Pointer.limit == 0`, the methods `put()`, `zero()`, and `asBuffer()` now assume a size of 1/Fixed a few small things/ * Fixed memory corruption when returning by value an `std::vector<>` using an adapter
* Added `Pointer.zero()` method that calls `memset(0)` on the range
* For easier memory management, more than one `Pointer` now allowed to share the `deallocator` when ""casting"" them/"
javacpp,"* Exported `Loader.isLoadLibraries()`, which always returns true, except when the `Builder` loads the classes
* Made it possible to specify a nested class (with a '$' character in the name) on the command line
* When `Pointer.limit == 0`, the methods `put()`, `zero()`, and `asBuffer()` now assume a size of 1/"
javacpp,"* Arguments of `Pointer` type now get handled as `char*` in cases when the `position` can be used for arithmetic
* Worked around bug of `InputStream.available()` always returning 0 with the `http` protocol in `Loader.extractResource(URL)`/ * Fixed callbacks not working on Android anymore (issue #30)
* Added some Javadoc to most of the code/"
javacpp,"* Arguments of `Pointer` type now get handled as `char*` in cases when the `position` can be used for arithmetic
* Worked around bug of `InputStream.available()` always returning 0 with the `http` protocol in `Loader.extractResource(URL)`/ * Fixed callbacks not working on Android anymore (issue #30)
* Added some Javadoc to most of the code/"
javacpp,"* Arguments of `Pointer` type now get handled as `char*` in cases when the `position` can be used for arithmetic
* Worked around bug of `InputStream.available()` always returning 0 with the `http` protocol in `Loader.extractResource(URL)`/ * Fixed callbacks not working on Android anymore (issue #30)
* Added some Javadoc to most of the code/"
javacpp,"* Arguments of `Pointer` type now get handled as `char*` in cases when the `position` can be used for arithmetic
* Worked around bug of `InputStream.available()` always returning 0 with the `http` protocol in `Loader.extractResource(URL)`/ * Fixed callbacks not working on Android anymore (issue #30)
* Added some Javadoc to most of the code/ * To help diagnose `UnsatisfiedLinkError` thrown by `Loader.load()`, they have been augmented with a potential cause originating from the ""preloading"" of libraries, whose premature deletion has also been fixed/ * Provided new `@Platform(library=""..."")` annotation value to let users specify the name of the native library used by both `Builder` and `Loader`, where different classes with the same name get built together, which also works on nested classes (issue #29)/"
javacpp,"* Arguments of `Pointer` type now get handled as `char*` in cases when the `position` can be used for arithmetic
* Worked around bug of `InputStream.available()` always returning 0 with the `http` protocol in `Loader.extractResource(URL)`/ * Fixed callbacks not working on Android anymore (issue #30)
* Added some Javadoc to most of the code/"
javacpp,"* Arguments of `Pointer` type now get handled as `char*` in cases when the `position` can be used for arithmetic
* Worked around bug of `InputStream.available()` always returning 0 with the `http` protocol in `Loader.extractResource(URL)`/ * Fixed callbacks not working on Android anymore (issue #30)
* Added some Javadoc to most of the code/"
javacpp,"* Arguments of `Pointer` type now get handled as `char*` in cases when the `position` can be used for arithmetic
* Worked around bug of `InputStream.available()` always returning 0 with the `http` protocol in `Loader.extractResource(URL)`/ * Fixed callbacks not working on Android anymore (issue #30)
* Added some Javadoc to most of the code/"
javacpp,"* Arguments of `Pointer` type now get handled as `char*` in cases when the `position` can be used for arithmetic
* Worked around bug of `InputStream.available()` always returning 0 with the `http` protocol in `Loader.extractResource(URL)`/ * Fixed callbacks not working on Android anymore (issue #30)
* Added some Javadoc to most of the code/"
javacpp,"* Arguments of `Pointer` type now get handled as `char*` in cases when the `position` can be used for arithmetic
* Worked around bug of `InputStream.available()` always returning 0 with the `http` protocol in `Loader.extractResource(URL)`/ * Fixed callbacks not working on Android anymore (issue #30)
* Added some Javadoc to most of the code/"
javacpp,"* Arguments of `Pointer` type now get handled as `char*` in cases when the `position` can be used for arithmetic
* Worked around bug of `InputStream.available()` always returning 0 with the `http` protocol in `Loader.extractResource(URL)`/ * Fixed callbacks not working on Android anymore (issue #30)
* Added some Javadoc to most of the code/"
javacpp,"* Arguments of `Pointer` type now get handled as `char*` in cases when the `position` can be used for arithmetic
* Worked around bug of `InputStream.available()` always returning 0 with the `http` protocol in `Loader.extractResource(URL)`/ * Fixed callbacks not working on Android anymore (issue #30)
* Added some Javadoc to most of the code/"
javacpp,"* Arguments of `Pointer` type now get handled as `char*` in cases when the `position` can be used for arithmetic
* Worked around bug of `InputStream.available()` always returning 0 with the `http` protocol in `Loader.extractResource(URL)`/ * Fixed callbacks not working on Android anymore (issue #30)
* Added some Javadoc to most of the code/"
javacpp,"* Arguments of `Pointer` type now get handled as `char*` in cases when the `position` can be used for arithmetic
* Worked around bug of `InputStream.available()` always returning 0 with the `http` protocol in `Loader.extractResource(URL)`/ * Fixed callbacks not working on Android anymore (issue #30)
* Added some Javadoc to most of the code/"
javacpp,"* Fixed duplicate code getting generated when both specifying the output filename with ""-o <name>"" and using wildcards on packages containing nested classes/"
javacpp,"* Removed call to `Arrays.copyOf()` in `Loader.findLibrary()`, which would prevent it from working on Android 2.2 (issue #39)/ * Fixed `NullPointerException` in `Loader.load()` when no `@Platform` annotation is provided (issue #38)
* Parsing for anonymous `struct` or `union` and for `typedef void` (mapped to `@Opaque Pointer`) now outputs something
* The `Parser` now expands preprocessor macros and outputs all unprocessed directives as comments/ * Fixed `typedef` of function pointers and a few code formatting issues with `Parser`
* Supplied checks to prevent `Loader.load()` from throwing `java.lang.IllegalStateException: Can't overwrite cause`/"
javacpp,"* Added new `Pointer.deallocate(false)` call to disable garbage collection on a per object basis, allowing users to deal with memory leaks in other ways
* Changed the default compiler option `-mfpu=vfpv` for ARM to `-mfpu=vfpv3-d16`, because the former is not supported by Tegra 2/"
javacpp,"* Made `Loader.load()` work, within reason, even when all annotations and resources have been removed, for example, by ProGuard
* Fixed compile error when using a `FunctionPointer` as parameter from outside its top-level enclosing class
* The `Parser` now filters tokens appropriately with preprocessor directives
* Improved the C++ support of the `Parser` for macros, templates, etc/"
javacpp,"* Fixed a few potential issues with the hacks in `Loader`
* Generalized somewhat more the compiler options used inside `linux-arm.properties` (issue javacv:418)/Fixed a Windows bug that caused immediate crash (issue #41)
In Windows, File.separator returns ""\"" which is also an escape character in Regex. This caused an exception that crashed the program immediately.
Remove Regex and use '/' the character for clarity./ * Made `Loader.load()` work, within reason, even when all annotations and resources have been removed, for example, by ProGuard
* Fixed compile error when using a `FunctionPointer` as parameter from outside its top-level enclosing class
* The `Parser` now filters tokens appropriately with preprocessor directives
* Improved the C++ support of the `Parser` for macros, templates, etc/"
javacpp,"* Added `public long Pointer.address()` getter method, useful when one needs to subtract two pointers
* Removed old NetBeans project files that cause a conflict when trying to open as a Maven project (issue javacv:210)/"
javacpp,"* Added a `platform.library.path` property, such as ""lib/armeabi/"" in the case of the ""android-arm"" platform, to be used instead of ""package/platform"" (issue javacv:427)
* Generalized references to the path of the Android NDK
* Improved a few small things in the set of `Pointer` classes`/"
javacpp,"* Added a `platform.library.path` property, such as ""lib/armeabi/"" in the case of the ""android-arm"" platform, to be used instead of ""package/platform"" (issue javacv:427)
* Generalized references to the path of the Android NDK
* Improved a few small things in the set of `Pointer` classes`/"
javacpp,"* Added a `platform.library.path` property, such as ""lib/armeabi/"" in the case of the ""android-arm"" platform, to be used instead of ""package/platform"" (issue javacv:427)
* Generalized references to the path of the Android NDK
* Improved a few small things in the set of `Pointer` classes`/"
javacpp,"* Added a `platform.library.path` property, such as ""lib/armeabi/"" in the case of the ""android-arm"" platform, to be used instead of ""package/platform"" (issue javacv:427)
* Generalized references to the path of the Android NDK
* Improved a few small things in the set of `Pointer` classes`/"
javacpp,"* Added a `platform.library.path` property, such as ""lib/armeabi/"" in the case of the ""android-arm"" platform, to be used instead of ""package/platform"" (issue javacv:427)
* Generalized references to the path of the Android NDK
* Improved a few small things in the set of `Pointer` classes`/"
javacpp,"* Added a `platform.library.path` property, such as ""lib/armeabi/"" in the case of the ""android-arm"" platform, to be used instead of ""package/platform"" (issue javacv:427)
* Generalized references to the path of the Android NDK
* Improved a few small things in the set of `Pointer` classes`/"
javacpp,"* Added a `platform.library.path` property, such as ""lib/armeabi/"" in the case of the ""android-arm"" platform, to be used instead of ""package/platform"" (issue javacv:427)
* Generalized references to the path of the Android NDK
* Improved a few small things in the set of `Pointer` classes`/"
javacpp,"* Added a `platform.library.path` property, such as ""lib/armeabi/"" in the case of the ""android-arm"" platform, to be used instead of ""package/platform"" (issue javacv:427)
* Generalized references to the path of the Android NDK
* Improved a few small things in the set of `Pointer` classes`/"
javacpp,"* Added a `platform.library.path` property, such as ""lib/armeabi/"" in the case of the ""android-arm"" platform, to be used instead of ""package/platform"" (issue javacv:427)
* Generalized references to the path of the Android NDK
* Improved a few small things in the set of `Pointer` classes`/"
javacpp,"* Added a `platform.library.path` property, such as ""lib/armeabi/"" in the case of the ""android-arm"" platform, to be used instead of ""package/platform"" (issue javacv:427)
* Generalized references to the path of the Android NDK
* Improved a few small things in the set of `Pointer` classes`/ * Annotations such as `@Adapter` or `@ByVal` are no longer ignored on parameters of getters or setters annotated with `@Index`
* Fixed some other corner cases in `Generator`
* Added for convenience to `PointerPointer` a generic parameter `<P extends Pointer>` and the associated `get(Class<P> ...)` getters, as well as `String` getters and setters
* Passing a `Class` object as first argument to a native method that returns a `Pointer` now determines the runtime type of that returned object/"
javacpp,"* Added a `platform.library.path` property, such as ""lib/armeabi/"" in the case of the ""android-arm"" platform, to be used instead of ""package/platform"" (issue javacv:427)
* Generalized references to the path of the Android NDK
* Improved a few small things in the set of `Pointer` classes`/"
javacpp,"* Added a `platform.library.path` property, such as ""lib/armeabi/"" in the case of the ""android-arm"" platform, to be used instead of ""package/platform"" (issue javacv:427)
* Generalized references to the path of the Android NDK
* Improved a few small things in the set of `Pointer` classes`/"
javacpp,"* Disable DocLint, which prevents the build from succeeding on Java 8 (issue #5)/"
javacpp,"Update version in the `pom.xml` file to 0.11-SNAPSHOT
* Provide `UByteIndexer` and `UShortIndexer`, treating array and buffer data as unsigned integers, for ease of use
* Clean up Windows `java.io.tmpdir` even when program messes with `java.class.path` (issue #12)/"
javacpp,"Merge pull request #13 from mabruce/tempfile-deleter
* Clean up Windows `java.io.tmpdir` even when program messes with `java.class.path` (issue #12)/Feed javacpp.jar path to temp file deleter
Get OS-localized file path to jar file enclosing Loader class, and feed this path to the temp file deleter on Windows instead of java.class.path. If the java program is launched through a dedicated classpath loader, java.class.path may not contain the javacpp jar. By locating the correct jar, this circumstance should be avoided./"
javacpp,"* Offer the Apache License, Version 2.0, as a new choice of license, in addition to the GPLv2 with Classpath exception/"
javacpp,"* Offer the Apache License, Version 2.0, as a new choice of license, in addition to the GPLv2 with Classpath exception/"
javacpp,"* Offer the Apache License, Version 2.0, as a new choice of license, in addition to the GPLv2 with Classpath exception/"
javacpp,"* Offer the Apache License, Version 2.0, as a new choice of license, in addition to the GPLv2 with Classpath exception/"
javacpp,"* Add `-undefined dynamic_lookup` option to Mac OS X compiler, making its native linker behave a bit better, plus search for libraries suffixed with "".so"" too/ * Offer the Apache License, Version 2.0, as a new choice of license, in addition to the GPLv2 with Classpath exception/"
javacpp,"* Offer the Apache License, Version 2.0, as a new choice of license, in addition to the GPLv2 with Classpath exception/"
javacpp,"* Offer the Apache License, Version 2.0, as a new choice of license, in addition to the GPLv2 with Classpath exception/"
javacpp,"* Offer the Apache License, Version 2.0, as a new choice of license, in addition to the GPLv2 with Classpath exception/"
javacpp,"* Offer the Apache License, Version 2.0, as a new choice of license, in addition to the GPLv2 with Classpath exception/"
javacpp,"* Offer the Apache License, Version 2.0, as a new choice of license, in addition to the GPLv2 with Classpath exception/"
javacpp,"* Offer the Apache License, Version 2.0, as a new choice of license, in addition to the GPLv2 with Classpath exception/"
javacpp,"* Offer the Apache License, Version 2.0, as a new choice of license, in addition to the GPLv2 with Classpath exception/"
javacpp,"* Offer the Apache License, Version 2.0, as a new choice of license, in addition to the GPLv2 with Classpath exception/"
javacpp,"* Offer the Apache License, Version 2.0, as a new choice of license, in addition to the GPLv2 with Classpath exception/"
javacpp,"* Log when `Pointer.deallocator` gets registered, garbage collected, or deallocated manually, if `Logger.isDebugEnabled()` (redirectable to SLF4J)
* Make `Pointer implements AutoCloseable` to let us try-with-resources, thus bumping requirements to Java SE 7 and Android 4.0/"
javacpp,"* Log when `Pointer.deallocator` gets registered, garbage collected, or deallocated manually, if `Logger.isDebugEnabled()` (redirectable to SLF4J)
* Make `Pointer implements AutoCloseable` to let us try-with-resources, thus bumping requirements to Java SE 7 and Android 4.0/"
javacpp,* Take into account `Buffer.arrayOffset()` when creating a `Pointer` from a buffer backed by an array (issue bytedeco/javacv#190)/
javacpp,"* Take into account `Buffer.arrayOffset()` when creating a `Pointer` from a buffer backed by an array (issue bytedeco/javacv#190)/ * Adjust `BytePointer`, `CharPointer`, `IntPointer`, and `StringAdapter` to work with data strings that are not null-terminated (issue #24)/"
javacpp,* Take into account `Buffer.arrayOffset()` when creating a `Pointer` from a buffer backed by an array (issue bytedeco/javacv#190)/
javacpp,"* Take into account `Buffer.arrayOffset()` when creating a `Pointer` from a buffer backed by an array (issue bytedeco/javacv#190)/ * Adjust `BytePointer`, `CharPointer`, `IntPointer`, and `StringAdapter` to work with data strings that are not null-terminated (issue #24)/"
javacpp,"* Take into account `Buffer.arrayOffset()` when creating a `Pointer` from a buffer backed by an array (issue bytedeco/javacv#190)/ * Adjust `BytePointer`, `CharPointer`, `IntPointer`, and `StringAdapter` to work with data strings that are not null-terminated (issue #24)/"
javacpp,* Take into account `Buffer.arrayOffset()` when creating a `Pointer` from a buffer backed by an array (issue bytedeco/javacv#190)/
javacpp,* Take into account `Buffer.arrayOffset()` when creating a `Pointer` from a buffer backed by an array (issue bytedeco/javacv#190)/
javacpp,* Fix potential race condition when deallocating `Pointer` objects from multiple threads/
javacpp,"* Prevent `Generator` from initializing classes when preloading them, which can cause problems (issue bytedeco/javacpp-presets#126)/ * Prevent `Loader` from extracting libraries more than once, which can cause problems (issue bytedeco/javacpp-presets#126)
* Make `Indexer implements AutoCloseable` to let us try-with-resources/ * Add missing calls to `close()` for `InputStream` and `OutputStream` in `Loader` (issue #53)
* Remove `Piper` class no longer needed with Java SE 7/ * Add logging to `Loader.loadLibrary()` to help diagnose loading problems (issue #41)/"
javacpp,"Merge pull request #86 from osialr/staging/pointer-close-throws-runtime
* Remove `throws Exception` from `Pointer.close()`/Remove 'throws Exception' from Pointer::close
Pointer throws a RuntimeException on close.  Removing the throws
allows the user's try-with-resource blocks not require a catch(Exception)/Merge pull request #67 from georgekankava/staging/nested-blocks-of-code-should-not-be-left-empty-fix-1
Do at least something for exceptions we swallow but do not expect/Fix up functionality for `Info.flatten`/"
javacpp,"Merge pull request #67 from georgekankava/staging/nested-blocks-of-code-should-not-be-left-empty-fix-1
Do at least something for exceptions we swallow but do not expect/ * Fix swallowed `InterruptedException` (issue bytedeco/javacv#315)/"
javacpp,* Fix `Loader.load()` error when called right after `Builder.build()` within the same process/
javacpp,* Deallocate native memory in a dedicated thread to reduce lock contention (issue #103)/
javacpp,* Throw `OutOfMemoryError` on `allocateArray()` for `Pointer` of primitive types with `size > 0 && address == 0`/
javacpp,* Throw `OutOfMemoryError` on `allocateArray()` for `Pointer` of primitive types with `size > 0 && address == 0`/
javacpp,"* Fix `IndexerTest` potentially failing with `OutOfMemoryError` (issue bytedeco/javacpp-presets#234)
* Preload libraries to work around some cases when they refuse to load once renamed (issue deeplearning4j/libnd4j#235)
* Fix compilation error on some `linux-ppc64le` platforms (issue deeplearning4j/libnd4j#232)/* Fix `Loader` crashing on Android (issue bytedeco/javacv#412)/ * Fix `NullPointerException` on ""generic"" platforms/ * Fix `Loader.load()` error when called right after `Builder.build()` within the same process/"
javacpp,* Throw `OutOfMemoryError` on `allocateArray()` for `Pointer` of primitive types with `size > 0 && address == 0`/
javacpp,* Throw `OutOfMemoryError` on `allocateArray()` for `Pointer` of primitive types with `size > 0 && address == 0`/
javacpp,* Throw `OutOfMemoryError` on `allocateArray()` for `Pointer` of primitive types with `size > 0 && address == 0`/
javacpp,* Throw `OutOfMemoryError` on `allocateArray()` for `Pointer` of primitive types with `size > 0 && address == 0`/
javacpp,* Throw `OutOfMemoryError` on `allocateArray()` for `Pointer` of primitive types with `size > 0 && address == 0`/
javacpp,* Throw `OutOfMemoryError` on `allocateArray()` for `Pointer` of primitive types with `size > 0 && address == 0`/
javacpp,* Throw `OutOfMemoryError` on `allocateArray()` for `Pointer` of primitive types with `size > 0 && address == 0`/
javacpp,* Throw `OutOfMemoryError` on `allocateArray()` for `Pointer` of primitive types with `size > 0 && address == 0`/
javacpp,* Throw `OutOfMemoryError` on `allocateArray()` for `Pointer` of primitive types with `size > 0 && address == 0`/
javacpp,* Add `UniquePtrAdapter` and corresponding `@UniquePtr` annotation to support `unique_ptr` containers (issue bytedeco/javacpp-presets#266)/
javacpp,"* Accelerate call to `Pointer.physicalBytes()` on Linux (issue #133)/ * Add ""org.bytedeco.javacpp.maxphysicalbytes"" system property to force calls to `System.gc()` based on `Pointer.physicalBytes()`
* Allow strings ending with ""t"", ""g"", ""m"", etc to specify the number of bytes in system properties (issue #125)/Simplify synchronization of memory allocation to avoid `OutOfMemoryError` when low on memory/ * Synchronize memory allocation in `Pointer` when low on memory to avoid `OutOfMemoryError`/"
javacpp,Throw more information when `OutOfMemoryError` occurs on `allocateArray()` for `Pointer` of primitive types/
javacpp,Throw more information when `OutOfMemoryError` occurs on `allocateArray()` for `Pointer` of primitive types/
javacpp,"Merge pull request #123 from vb216/master
* Work around `linux-armhf` not being properly detected with OpenJDK (issue #105)/ * Fix `Loader.load()` not renaming a library when previously loaded under a different name/"
javacpp,Throw more information when `OutOfMemoryError` occurs on `allocateArray()` for `Pointer` of primitive types/
javacpp,Throw more information when `OutOfMemoryError` occurs on `allocateArray()` for `Pointer` of primitive types/
javacpp,Throw more information when `OutOfMemoryError` occurs on `allocateArray()` for `Pointer` of primitive types/
javacpp,Throw more information when `OutOfMemoryError` occurs on `allocateArray()` for `Pointer` of primitive types/
javacpp,Throw more information when `OutOfMemoryError` occurs on `allocateArray()` for `Pointer` of primitive types/
javacpp,Throw more information when `OutOfMemoryError` occurs on `allocateArray()` for `Pointer` of primitive types/
javacpp,Throw more information when `OutOfMemoryError` occurs on `allocateArray()` for `Pointer` of primitive types/
javacpp,Throw more information when `OutOfMemoryError` occurs on `allocateArray()` for `Pointer` of primitive types/
javacpp,Throw more information when `OutOfMemoryError` occurs on `allocateArray()` for `Pointer` of primitive types/
javacpp,"Update version in the `pom.xml` file to 1.3.2-SNAPSHOT
* Make `Pointer.asBuffer()` thread-safe (issue #155)/Update version in the `pom.xml` file to 1.3-SNAPSHOT
* Print memory sizes in a human-readable format with `Pointer.formatBytes()`
* Map standard `malloc()`, `calloc()`, `realloc()`, and `free()` functions (issue #136)/"
javacpp,"Update version in the `pom.xml` file to 1.3-SNAPSHOT
* Print memory sizes in a human-readable format with `Pointer.formatBytes()`
* Map standard `malloc()`, `calloc()`, `realloc()`, and `free()` functions (issue #136)/"
javacpp,"Update version in the `pom.xml` file to 1.3-SNAPSHOT
* Print memory sizes in a human-readable format with `Pointer.formatBytes()`
* Map standard `malloc()`, `calloc()`, `realloc()`, and `free()` functions (issue #136)/"
javacpp,"* Fix broken `outputDirectory` property and corresponding `-d` command line option (issue #153)
* Add `Loader.extractResources()` and `cacheResources()` methods to extract or cache all resources with given name/Update version in the `pom.xml` file to 1.3.1-SNAPSHOT
* Fix potential issues with `Parser` repeating the `@ByPtrPtr` or `@ByPtrRef` annotations on parameters
* To support Scala singleton objects better, consider as `static` methods from objects that are not `Pointer`
* Allow `Loader.extractResource()` and `cacheResource()` to extract or cache all files from a directory in a JAR file
* Create version-less symbolic links to libraries in cache on those platforms where it is useful to link easily
* Use `java.io.tmpdir` as fallback in `Loader.getCacheDir()`, and throw a clear exception on failure/Release version 1.2.7
* Fix `Loader` errors that could occur due to recent changes/ * Prevent `Loader` from overwriting previously extracted and renamed libraries (issue deeplearning4j/nd4j#1460)/"
javacpp,"Update version in the `pom.xml` file to 1.3-SNAPSHOT
* Print memory sizes in a human-readable format with `Pointer.formatBytes()`
* Map standard `malloc()`, `calloc()`, `realloc()`, and `free()` functions (issue #136)/"
javacpp,"Update version in the `pom.xml` file to 1.3-SNAPSHOT
* Print memory sizes in a human-readable format with `Pointer.formatBytes()`
* Map standard `malloc()`, `calloc()`, `realloc()`, and `free()` functions (issue #136)/"
javacpp,"Update version in the `pom.xml` file to 1.3-SNAPSHOT
* Print memory sizes in a human-readable format with `Pointer.formatBytes()`
* Map standard `malloc()`, `calloc()`, `realloc()`, and `free()` functions (issue #136)/"
javacpp,"Update version in the `pom.xml` file to 1.3-SNAPSHOT
* Print memory sizes in a human-readable format with `Pointer.formatBytes()`
* Map standard `malloc()`, `calloc()`, `realloc()`, and `free()` functions (issue #136)/"
javacpp,"Update version in the `pom.xml` file to 1.3-SNAPSHOT
* Print memory sizes in a human-readable format with `Pointer.formatBytes()`
* Map standard `malloc()`, `calloc()`, `realloc()`, and `free()` functions (issue #136)/"
javacpp,"Update version in the `pom.xml` file to 1.3-SNAPSHOT
* Print memory sizes in a human-readable format with `Pointer.formatBytes()`
* Map standard `malloc()`, `calloc()`, `realloc()`, and `free()` functions (issue #136)/"
javacpp,"Update version in the `pom.xml` file to 1.3-SNAPSHOT
* Print memory sizes in a human-readable format with `Pointer.formatBytes()`
* Map standard `malloc()`, `calloc()`, `realloc()`, and `free()` functions (issue #136)/"
javacpp,"Update version in the `pom.xml` file to 1.3-SNAPSHOT
* Print memory sizes in a human-readable format with `Pointer.formatBytes()`
* Map standard `malloc()`, `calloc()`, `realloc()`, and `free()` functions (issue #136)/"
javacpp,"Update version in the `pom.xml` file to 1.3-SNAPSHOT
* Print memory sizes in a human-readable format with `Pointer.formatBytes()`
* Map standard `malloc()`, `calloc()`, `realloc()`, and `free()` functions (issue #136)/"
javacpp,* Let `Pointer` log debug messages when forced to call `System.gc()`/
javacpp,* Prevent `Pointer` from copying array data from NIO buffers that are also direct (issue bytedeco/javacpp-presets#380)/
javacpp,* Prevent `Pointer` from copying array data from NIO buffers that are also direct (issue bytedeco/javacpp-presets#380)/
javacpp,"* Add new ""org.bytedeco.javacpp.cachedir.nosubdir"" system property to restore old behavior (issue #167)/ * Prevent `Pointer` from copying array data from NIO buffers that are also direct (issue bytedeco/javacpp-presets#380)/ * Prevent `Loader` from loading system libraries, which causes problems on Android 7.x (issue bytedeco/javacv#617)/ * Avoid `Loader` issues with spaces, etc in paths to library files (issue deeplearning4j/nd4j#1564)/"
javacpp,* Prevent `Pointer` from copying array data from NIO buffers that are also direct (issue bytedeco/javacpp-presets#380)/
javacpp,* Prevent `Pointer` from copying array data from NIO buffers that are also direct (issue bytedeco/javacpp-presets#380)/
javacpp,* Prevent `Pointer` from copying array data from NIO buffers that are also direct (issue bytedeco/javacpp-presets#380)/
javacpp,* Prevent `Pointer` from copying array data from NIO buffers that are also direct (issue bytedeco/javacpp-presets#380)/
javacpp,* Prevent `Pointer` from copying array data from NIO buffers that are also direct (issue bytedeco/javacpp-presets#380)/
javacpp,* Call `malloc_trim(0)` after `System.gc()` on Linux to make sure memory gets released (issue bytedeco/javacpp-presets#423)/ * Fix potential formatting issues with `OutOfMemoryError` thrown from `Pointer`/
javacpp,* Fix issue with `Loader.getCallerClass()` when a `SecurityManager` cannot be created (issue #176)/ * Fix `Loader.getCallerClass()` (pull #175)/
javacpp,"* Fix `Parser` incorrectly resolving type definitions with classes of the same name in parent namespaces
* Fix `Generator` compile errors for `const` template types of `@Adapter` classes using the `@Cast` annotation/"
javacpp,"* Catch `SecurityException` in `Loader.getCacheDir()` (pull #198)
Logic in the area will already try the next directory./"
javacpp,"* Fix ""Negative Buffer Capacity"" errors happening in subclasses on `Pointer.asBuffer()` (issue deeplearning4j/deeplearning4j#4061)/"
javacpp,"* Fix ""Negative Buffer Capacity"" errors happening in subclasses on `Pointer.asBuffer()` (issue deeplearning4j/deeplearning4j#4061)/ * Prevent `JNI_OnLoad()` from failing when `Loader.putMemberOffset()` cannot find a class
* Throw clear error message when `Loader.load()` gets called on a class not supporting current platform/ * Add `@Platform(exclude=...)` annotation value to remove header files from inherited `@Platform(include=...`
Also fix a few more issues with `Parser`/ * Fix potential race conditions and various issues with `Loader` that could prevent libraries like MKL from working properly/"
javacpp,* Fix `SharedPtrAdapter` and `UniquePtrAdapter` failing to take ownership of temporary objects/
javacpp,* Avoid `synchronized` on first call to `physicalBytes()` in `Pointer.deallocator()` to reduce contention (pull #232)/ * Add `Info.enumerate` to let `Parser` map C++ enum classes to Java enum types (issue #108)/
javacpp,* Avoid `synchronized` on first call to `physicalBytes()` in `Pointer.deallocator()` to reduce contention (pull #232)/ * Make call to `Pointer.physicalBytes()` thread safe and remove lock (issue #231)/
javacpp,* Prevent `Loader` from loading twice copies of the same DLL (issue deeplearning4j/deeplearning4j#4776)/ * Catch more exceptions that can occur in `Loader` when caching resources (pull #226)/
javacpp,* Tweak `Pointer.formatBytes()` to increase the number of digits returned (issue #240)/
javacpp,"* Tweak `Pointer.formatBytes()` to increase the number of digits returned (issue #240)/ * Fix memory leak that occurs with ""org.bytedeco.javacpp.nopointergc"" (issue #239)/"
javacpp,"* Clarify that `Loader.load()` can throw `UnsatisfiedLinkError` when interrupted/ * Synchronize `Loader.loadLibrary()` to fix potential race condition (pull #246)/ * Fix issues with anonymous classes by calling `getEnclosingClass()` instead of `getDeclaringClass()`/ * Search in `linkpath` before `preloadpath` to avoid copying or loading unwanted libraries/ * Do not fall back on `System.loadLibrary()` when we are renaming libraries (issue deeplearning4j/deeplearning4j#5503)/Fix potential `NullPointerException` in `Loader`/ * Fall back on Android-friendly `System.loadLibrary()` in `Loader.load()` instead of ""java.library.path"" (issue bytedeco/javacv#970)/"
javacpp,Add `PointerTest.testPointerPointer()` to make sure it works correctly (issue #251)/
javacpp,"* Add `Loader.getLoadedLibraries()` method for debugging purposes and fix flaky `BuilderTest` (issue #245)
* Call `PointerScope.attach()` as part of `Pointer.deallocator()`, instead of `init()`, to support custom deallocators as well
* Prevent `Parser` from appending annotations to setter methods of variables to satisfy the `Generator`/"
javacpp,"* Add `Loader.getLoadedLibraries()` method for debugging purposes and fix flaky `BuilderTest` (issue #245)
* Call `PointerScope.attach()` as part of `Pointer.deallocator()`, instead of `init()`, to support custom deallocators as well
* Prevent `Parser` from appending annotations to setter methods of variables to satisfy the `Generator`/"
javacpp,"* Add `Loader.getLoadedLibraries()` method for debugging purposes and fix flaky `BuilderTest` (issue #245)
* Call `PointerScope.attach()` as part of `Pointer.deallocator()`, instead of `init()`, to support custom deallocators as well
* Prevent `Parser` from appending annotations to setter methods of variables to satisfy the `Generator`/ * Let `Loader` rename JNI libraries when ""already loaded in another classloader"" (issue deeplearning4j/deeplearning4j#6166)/ * Allow `Builder` to create links for resource libraries even when no Java classes are built
* Fix `Loader.cacheResource()` creating a subdirectory named ""null"" when caching a top-level file/"
javacpp,"* Replace calls to `Class.getResource()` with `Loader.findResource()` to work around issues with JPMS ([pull #276](https://github.com/bytedeco/javacpp/pull/276))
* Enhance `Loader.findResources()` with `Class.getResource()` and search among parent packages
* Take shortest common package name among all user classes for the default output path of `Builder`/"
javacpp,"* Fix potential `NullPointerException` in `Loader.findResources()` under the bootstrap class loader/Fix bug introduced in changes to `Loader.findResources()` for dealing with JPMS/ * Replace calls to `Class.getResource()` with `Loader.findResource()` to work around issues with JPMS ([pull #276](https://github.com/bytedeco/javacpp/pull/276))
* Enhance `Loader.findResources()` with `Class.getResource()` and search among parent packages
* Take shortest common package name among all user classes for the default output path of `Builder`/ * Synchronize `Loader.cacheResources()` on `Runtime` to avoid `OverlappingFileLockException` with multiple class loaders (issue bytedeco/javacpp-presets#650)/"
javacpp,"* Support multiple instances of `FunctionPointer` subclasses, up to the value in `@Allocator(max=...)` (issue bytedeco/javacpp-presets#683)/"
javacpp,* Add `Loader.loadGlobal()` to load symbols globally as often required by Python libraries (issue ContinuumIO/anaconda-issues#6401)/
javacpp,* Start `Pointer.DeallocatorThread` with `setContextClassLoader(null)` as required by containers (issue deeplearning4j/deeplearning4j#7737)/
javacpp,"* Allow suffixing library names with `:` to specify exact relative paths to libraries, ignoring any additional prefix or suffix/ * Let `Loader.load()` extract libraries suffixed with `##`, but still ignored for copying by `Builder`/ * Fix `Loader.createLibraryLink()` incorrectly truncating library versions when there is one before and another after the suffix/ * Allow prefixing library names with `:` to have `Loader` consider them as filenames with prefix and suffix already included/ * Add `Loader.loadGlobal()` to load symbols globally as often required by Python libraries (issue ContinuumIO/anaconda-issues#6401)/ * Prevent `ClassCastException` in `Loader` on illegal system properties (issue #289)
* Fix `Parser` not replacing all type names of the base class with `Info.flatten` (issue #288)/"
javacpp,"* Accelerate `Loader.extractResource()` for directories already cached, also preventing failures (issue #197)/ * Fix `Loader.cacheResource()` with the ""jrt"" protocol as used by jlink (pull #305)/"
javacpp,* Consider `Pointer` values `maxBytes` or `maxPhysicalBytes` suffixed with `%` as relative to `Runtime.maxMemory()` (pull #365)/Fix IndexerTest and PointerTest on 32-bit platforms (issue #347)/
javacpp,Fix call to `parseBytes()` to be relative to `Runtime.maxMemory()` also for `maxPhysicalBytes`/ * Consider `Pointer` values `maxBytes` or `maxPhysicalBytes` suffixed with `%` as relative to `Runtime.maxMemory()` (pull #365)/
javacpp,* Fix `Pointer` losing its owner when mistakenly ignoring deallocators for `const` values returned from adapters/
javacpp,* Add `Generator` support for `enum` classes with `boolean` values (issue #388)/
javacpp,* Speed up `Loader.load()` by caching results returned from `Loader.findLibrary()` (issue #287)/
javacpp,* Add presets for `jnijavacpp` and `javacpp-platform` artifact to fix issues at load time (issue bytedeco/javacv#1305)/
javacpp,* Add presets for `jnijavacpp` and `javacpp-platform` artifact to fix issues at load time (issue bytedeco/javacv#1305)/
javacpp,* Add presets for `jnijavacpp` and `javacpp-platform` artifact to fix issues at load time (issue bytedeco/javacv#1305)/ * Allow using `Charset` to avoid `UnsupportedEncodingException` from `BytePointer` (pull #384)/
javacpp,* Add presets for `jnijavacpp` and `javacpp-platform` artifact to fix issues at load time (issue bytedeco/javacv#1305)/ * Prevent potential `NullPointerException` in `Loader.checkVersion()` (pull #385)/ * Fix exception in `Loader` when running jlink image with JDK 13+ (pull #375)/ * Speed up `Loader.load()` by caching results returned from `Loader.findLibrary()` (issue #287)/
javacpp,* Add presets for `jnijavacpp` and `javacpp-platform` artifact to fix issues at load time (issue bytedeco/javacv#1305)/
javacpp,* Add presets for `jnijavacpp` and `javacpp-platform` artifact to fix issues at load time (issue bytedeco/javacv#1305)/
javacpp,* Add presets for `jnijavacpp` and `javacpp-platform` artifact to fix issues at load time (issue bytedeco/javacv#1305)/
javacpp,* Add presets for `jnijavacpp` and `javacpp-platform` artifact to fix issues at load time (issue bytedeco/javacv#1305)/
javacpp,* Add presets for `jnijavacpp` and `javacpp-platform` artifact to fix issues at load time (issue bytedeco/javacv#1305)/
javacpp,* Add presets for `jnijavacpp` and `javacpp-platform` artifact to fix issues at load time (issue bytedeco/javacv#1305)/
javacpp,* Add presets for `jnijavacpp` and `javacpp-platform` artifact to fix issues at load time (issue bytedeco/javacv#1305)/
javacpp,* Add presets for `jnijavacpp` and `javacpp-platform` artifact to fix issues at load time (issue bytedeco/javacv#1305)/ * Allow using `Charset` to avoid `UnsupportedEncodingException` from `BytePointer` (pull #384)/
javacpp,* Add presets for `jnijavacpp` and `javacpp-platform` artifact to fix issues at load time (issue bytedeco/javacv#1305)/
javacpp,* Add presets for `jnijavacpp` and `javacpp-platform` artifact to fix issues at load time (issue bytedeco/javacv#1305)/
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,Testsuite fixes./
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Pulled in libffi from gcc trunk.
Fixed build and install for standalone use./"
jna,"Fix wchar_t* return when null
Allow Pointer[] as function argument
Fix window utils test on osx to avoid os-cast shadows
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@326 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix failing argument marshal test
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@302 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix GetLastError bug
Make ByReference derive from Memory
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@299 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Enable VM crash protection on w32, linux
Move native library init from Pointer to Native
Fix Pointer.setNativeLong bug
Make library initialization explicit in Pointer/NativeLibrary
Javadoc cleanup
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@279 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Start on issue #38.  Main thing I wanted to do was get the second parameter to ToNativeConverter.toNative() in there so we don't have future API breakage by adding it later.
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@273 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Implement (most of) the fixes from issue #35.
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@266 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add auto-conversion for custom types
Fix X11 lib for 64-bit use
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@257 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add callback tests for smaller int types
Copy generic java.nio.Buffer support from v3 branch + tests
Copy missed sparc-isms from v3 branch for building sunos variants
Add stubs for platform-specific jars
Include libffi testsuite
Remove /lib64 references as per v3 branch
Auto-generate os prefix from os.name (as per v3 branch) to automatically handle new targets
Update overview to include Buffer, function pointer info
Include src.zip and doc.zip in dist generation
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@243 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Clean up varargs
Add per-field Structure read/write
Avoid automatic writes to 'volatile' structure fields
Read/wrap function pointers in Structure fields
Disallow Memory/Function as declared Structure fields
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@241 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Improve error messages when illegal argument/return types are used
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@440 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix bug in stdcall function mapping when using struct by value
Defer size_t/off_t definition, for now
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@436 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Consolidate Structure.ByReference reads
Cache native library options as well as alignments/type mappers
Ensure library options are passed to callbacks
Add protection around remaining Pointer read/write calls
Consolidate wide character reads/writes
Avoid stack overflow reading self-referential structures or loops
More prettification of Structure.toString
Add size_t/off_t standard types
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@435 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Move w32 JAWT load into native code
Fix Structure.ByValue for callback arg/return
Perform better type checking on callback arg/return types
Propagate library/symbol lookup error messages
Enable loading of libraries with non-ascii names
Tighten type checking in native code
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@425 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"fix bug where struct is incorrectly passed by value instead of by reference
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@529 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix NPE
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@520 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"avoid reallocating Integer objects
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@638 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix UnsatisfiedLinkError calling toString on a Library interface
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@244 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Clean up varargs
Add per-field Structure read/write
Avoid automatic writes to 'volatile' structure fields
Read/wrap function pointers in Structure fields
Disallow Memory/Function as declared Structure fields
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@241 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Consolidate Structure.ByReference reads
Cache native library options as well as alignments/type mappers
Ensure library options are passed to callbacks
Add protection around remaining Pointer read/write calls
Consolidate wide character reads/writes
Avoid stack overflow reading self-referential structures or loops
More prettification of Structure.toString
Add size_t/off_t standard types
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@435 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Enable VM crash protection on w32, linux
Move native library init from Pointer to Native
Fix Pointer.setNativeLong bug
Make library initialization explicit in Pointer/NativeLibrary
Javadoc cleanup
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@279 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Consolidate Structure.ByReference reads
Cache native library options as well as alignments/type mappers
Ensure library options are passed to callbacks
Add protection around remaining Pointer read/write calls
Consolidate wide character reads/writes
Avoid stack overflow reading self-referential structures or loops
More prettification of Structure.toString
Add size_t/off_t standard types
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@435 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix Memory ctor signature
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@403 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Don't keep a strong reference to the library proxy
Keep a mapping for the proxy on calls to loadLibrary
Don't fail if no alpha on shaped window demo
Clean up a few comments
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@351 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Clean up temp files on w32
Avoid empty paths in search list
Add canonical 'out-of-date' jar
Clean up ant build script targets
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@347 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/library suffix required on w32
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@331 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/extract integer type with platform-specific size
remove temporary file suffix altogether
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@328 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix GetLastError bug
Make ByReference derive from Memory
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@299 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix string decoding bug, add tests
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@282 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Enable VM crash protection on w32, linux
Move native library init from Pointer to Native
Fix Pointer.setNativeLong bug
Make library initialization explicit in Pointer/NativeLibrary
Javadoc cleanup
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@279 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Native.loadLibrary() no longer requires interface classes to extend Library.
If this breaks anything, blame Charles Nutter :-)
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@276 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add callback tests for smaller int types
Copy generic java.nio.Buffer support from v3 branch + tests
Copy missed sparc-isms from v3 branch for building sunos variants
Add stubs for platform-specific jars
Include libffi testsuite
Remove /lib64 references as per v3 branch
Auto-generate os prefix from os.name (as per v3 branch) to automatically handle new targets
Update overview to include Buffer, function pointer info
Include src.zip and doc.zip in dist generation
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@243 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Clean up varargs
Add per-field Structure read/write
Avoid automatic writes to 'volatile' structure fields
Read/wrap function pointers in Structure fields
Disallow Memory/Function as declared Structure fields
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@241 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Copy issue #25 fix from v3 branch
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@237 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix javadoc warnings
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@465 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Improve error messages when illegal argument/return types are used
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@440 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix bug in callback proxy.equals (wolfgang.roekelein)
Clean up some javadoc
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@439 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix JNLP class loader method lookup
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@438 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix bug in stdcall function mapping when using struct by value
Defer size_t/off_t definition, for now
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@436 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Consolidate Structure.ByReference reads
Cache native library options as well as alignments/type mappers
Ensure library options are passed to callbacks
Add protection around remaining Pointer read/write calls
Consolidate wide character reads/writes
Avoid stack overflow reading self-referential structures or loops
More prettification of Structure.toString
Add size_t/off_t standard types
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@435 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Move w32 JAWT load into native code
Fix Structure.ByValue for callback arg/return
Perform better type checking on callback arg/return types
Propagate library/symbol lookup error messages
Enable loading of libraries with non-ascii names
Tighten type checking in native code
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@425 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/reinstate w32 JAWT workaround; tests work without it, but demo code doesn't
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@423 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Consolidate structure ffi type info initialization and avoid premature GC
Enable union by-value by using largest field's type info
Explicitly throw IllegalArgument on bad type info
Throw IllegalState on missing type info
Explicitly write version/md5 info into Makefile from ant (to avoid platform-specific variances in sed)
Make Structure.ByValue/ByReference public to allow client code comparisons
Consolidate Structure field get/set operations
Avoid extra Pointer peer lookup from native code (wmeissner)
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@421 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/defer AWT toolkit initialization until actual JAWT use
Make w32 dynamically load JAWT to avoid forcing toolkit init on JNA load
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@418 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Use simpler workaround for loading AWT/JAWT on X11-based platforms
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@392 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix class cast exception 
read all TYPE_MAPPERs regardless of access
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@725 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Allow arbitrary callback method names
Allow specification of callback type mapper with TYPE_MAPPER
Allow write with uninitialized boxed primitives in Structure
Fix memory leak with callbacks called from native threads w/no java context
Fix Structure derived classes to allow setting TypeMapper
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@690 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"fix indexOf return value
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@382 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Allow Pointer[] as field in Structure
Clean up error messages when Structure size calculation fails
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@297 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Enable VM crash protection on w32, linux
Move native library init from Pointer to Native
Fix Pointer.setNativeLong bug
Make library initialization explicit in Pointer/NativeLibrary
Javadoc cleanup
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@279 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add callback tests for smaller int types
Copy generic java.nio.Buffer support from v3 branch + tests
Copy missed sparc-isms from v3 branch for building sunos variants
Add stubs for platform-specific jars
Include libffi testsuite
Remove /lib64 references as per v3 branch
Auto-generate os prefix from os.name (as per v3 branch) to automatically handle new targets
Update overview to include Buffer, function pointer info
Include src.zip and doc.zip in dist generation
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@243 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Consolidate structure ffi type info initialization and avoid premature GC
Enable union by-value by using largest field's type info
Explicitly throw IllegalArgument on bad type info
Throw IllegalState on missing type info
Explicitly write version/md5 info into Makefile from ant (to avoid platform-specific variances in sed)
Make Structure.ByValue/ByReference public to allow client code comparisons
Consolidate Structure field get/set operations
Avoid extra Pointer peer lookup from native code (wmeissner)
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@421 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Allow ByReference types in callbacks
Clean up some Structure field error messages
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@340 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Allow Pointer[] as field in Structure
Clean up error messages when Structure size calculation fails
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@297 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add callback tests for smaller int types
Copy generic java.nio.Buffer support from v3 branch + tests
Copy missed sparc-isms from v3 branch for building sunos variants
Add stubs for platform-specific jars
Include libffi testsuite
Remove /lib64 references as per v3 branch
Auto-generate os prefix from os.name (as per v3 branch) to automatically handle new targets
Update overview to include Buffer, function pointer info
Include src.zip and doc.zip in dist generation
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@243 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Clean up varargs
Add per-field Structure read/write
Avoid automatic writes to 'volatile' structure fields
Read/wrap function pointers in Structure fields
Disallow Memory/Function as declared Structure fields
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@241 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix bug in STructure.toArray w/nested struct arrays
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@455 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix bug in nested struct array read/write
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@445 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Improve error messages when illegal argument/return types are used
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@440 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix bug in stdcall function mapping when using struct by value
Defer size_t/off_t definition, for now
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@436 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Consolidate Structure.ByReference reads
Cache native library options as well as alignments/type mappers
Ensure library options are passed to callbacks
Add protection around remaining Pointer read/write calls
Consolidate wide character reads/writes
Avoid stack overflow reading self-referential structures or loops
More prettification of Structure.toString
Add size_t/off_t standard types
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@435 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix NPE when sizing struct with a struct array field
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@434 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix VM crash running test under linux-amd64
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@430 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix arg/result handling for callback values in callbacks
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@428 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Move w32 JAWT load into native code
Fix Structure.ByValue for callback arg/return
Perform better type checking on callback arg/return types
Propagate library/symbol lookup error messages
Enable loading of libraries with non-ascii names
Tighten type checking in native code
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@425 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Consolidate structure ffi type info initialization and avoid premature GC
Enable union by-value by using largest field's type info
Explicitly throw IllegalArgument on bad type info
Throw IllegalState on missing type info
Explicitly write version/md5 info into Makefile from ant (to avoid platform-specific variances in sed)
Make Structure.ByValue/ByReference public to allow client code comparisons
Consolidate Structure field get/set operations
Avoid extra Pointer peer lookup from native code (wmeissner)
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@421 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix bug in ByValue structs using NativeMapped
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@547 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix NPE when using NativeMapped within Structure (https://jna.dev.java.net/issues/show_bug.cgi?id=54)
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@499 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix division by zero on OSX/ppc calculating struct size
Fix overwriting of already-initialized NativeMapped field in struct when calculating struct size
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@620 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix class cast exception 
read all TYPE_MAPPERs regardless of access
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@725 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix pointer field read bug
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@708 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Allow arbitrary callback method names
Allow specification of callback type mapper with TYPE_MAPPER
Allow write with uninitialized boxed primitives in Structure
Fix memory leak with callbacks called from native threads w/no java context
Fix Structure derived classes to allow setting TypeMapper
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@690 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix stdcall callbacks
catch all exceptions when invoking callback
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@370 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Allocate executable memory for callbacks on w32
Synchronize on java callback allocation methods to avoid more complex native synchronization
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@332 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/64bit fixes, and add local queue.h for solaris builds
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@255 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"fix indexOf return value
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@382 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix GetLastError bug
Make ByReference derive from Memory
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@299 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix solaris build
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@281 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Enable VM crash protection on w32, linux
Move native library init from Pointer to Native
Fix Pointer.setNativeLong bug
Make library initialization explicit in Pointer/NativeLibrary
Javadoc cleanup
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@279 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Unbreak 64bit sparc support
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@260 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add auto-conversion for custom types
Fix X11 lib for 64-bit use
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@257 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/64bit fixes, and add local queue.h for solaris builds
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@255 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add callback tests for smaller int types
Copy generic java.nio.Buffer support from v3 branch + tests
Copy missed sparc-isms from v3 branch for building sunos variants
Add stubs for platform-specific jars
Include libffi testsuite
Remove /lib64 references as per v3 branch
Auto-generate os prefix from os.name (as per v3 branch) to automatically handle new targets
Update overview to include Buffer, function pointer info
Include src.zip and doc.zip in dist generation
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@243 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Remove superfluous exception checks, enable peer access on OSX
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@239 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"update project files (netbeans/eclipse)
use setjmp/longjmp to recover from w32 faults instead of simply setting SP
embed version resource information in w32 dll
don't update last error if ffi_call faults
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@462 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix bug in Pointer.setChar
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@460 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix bug in stdcall function mapping when using struct by value
Defer size_t/off_t definition, for now
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@436 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Consolidate Structure.ByReference reads
Cache native library options as well as alignments/type mappers
Ensure library options are passed to callbacks
Add protection around remaining Pointer read/write calls
Consolidate wide character reads/writes
Avoid stack overflow reading self-referential structures or loops
More prettification of Structure.toString
Add size_t/off_t standard types
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@435 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Move w32 JAWT load into native code
Fix Structure.ByValue for callback arg/return
Perform better type checking on callback arg/return types
Propagate library/symbol lookup error messages
Enable loading of libraries with non-ascii names
Tighten type checking in native code
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@425 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Consolidate structure ffi type info initialization and avoid premature GC
Enable union by-value by using largest field's type info
Explicitly throw IllegalArgument on bad type info
Throw IllegalState on missing type info
Explicitly write version/md5 info into Makefile from ant (to avoid platform-specific variances in sed)
Make Structure.ByValue/ByReference public to allow client code comparisons
Consolidate Structure field get/set operations
Avoid extra Pointer peer lookup from native code (wmeissner)
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@421 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/defer AWT toolkit initialization until actual JAWT use
Make w32 dynamically load JAWT to avoid forcing toolkit init on JNA load
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@418 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Avoid error loading JAWT when running headless
Use primary colors in window shape test (Dan)
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@412 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Use simpler workaround for loading AWT/JAWT on X11-based platforms
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@392 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Allow ByReference types in callbacks
Clean up some Structure field error messages
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@340 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix wchar_t* return when null
Allow Pointer[] as function argument
Fix window utils test on osx to avoid os-cast shadows
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@326 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add auto-conversion for custom types
Fix X11 lib for 64-bit use
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@257 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/64bit fixes, and add local queue.h for solaris builds
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@255 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix int32 definition for 64bit arches
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@254 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add callback tests for smaller int types
Copy generic java.nio.Buffer support from v3 branch + tests
Copy missed sparc-isms from v3 branch for building sunos variants
Add stubs for platform-specific jars
Include libffi testsuite
Remove /lib64 references as per v3 branch
Auto-generate os prefix from os.name (as per v3 branch) to automatically handle new targets
Update overview to include Buffer, function pointer info
Include src.zip and doc.zip in dist generation
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@243 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Clean up varargs
Add per-field Structure read/write
Avoid automatic writes to 'volatile' structure fields
Read/wrap function pointers in Structure fields
Disallow Memory/Function as declared Structure fields
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@241 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Improve error messages when illegal argument/return types are used
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@440 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix bug in stdcall function mapping when using struct by value
Defer size_t/off_t definition, for now
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@436 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix arg/result handling for callback values in callbacks
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@428 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Move w32 JAWT load into native code
Fix Structure.ByValue for callback arg/return
Perform better type checking on callback arg/return types
Propagate library/symbol lookup error messages
Enable loading of libraries with non-ascii names
Tighten type checking in native code
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@425 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/defer AWT toolkit initialization until actual JAWT use
Make w32 dynamically load JAWT to avoid forcing toolkit init on JNA load
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@418 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix callbacks when DEP is enabled
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@540 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"add small struct return by value test
Fix issue #94
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@742 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Add auto-conversion for custom types
Fix X11 lib for 64-bit use
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@257 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix X11 mappings for 64-bit
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@492 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix window alpha compositing on X11
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@500 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix cursor tracking on alpha-masked windows
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@629 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Show drop shadow on OSX BalloonManager
Fix NPE on OSX BalloonManager
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@337 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Implement (most of) the fixes from issue #35.
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@266 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"fix failure messages in demo
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@333 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"fix obsolete import
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@368 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix compilation error in file monitor example
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@306 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix issue# 68 - File monitor thread terminates on any removeWatch call. Change W32FileMonitor.dispose() to unwatch any remaining files in map, allows watcher thread to exit.
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@553 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix issue# 68 - File monitor thread terminates on any removeWatch call.
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@551 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix for Jira issue: 67 - FileMonitor incorrectly handles FILE_DELETED notification mask. Added a unit test and committed fix.
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@548 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix X11 keyboard test (XQueryKeymap result is not documented)
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@320 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Enable VM crash protection on w32, linux
Move native library init from Pointer to Native
Fix Pointer.setNativeLong bug
Make library initialization explicit in Pointer/NativeLibrary
Javadoc cleanup
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@279 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add auto-conversion for custom types
Fix X11 lib for 64-bit use
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@257 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Don't keep a strong reference to the library proxy
Keep a mapping for the proxy on calls to loadLibrary
Don't fail if no alpha on shaped window demo
Clean up a few comments
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@351 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/fix failure messages in demo
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@333 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Consolidate structure ffi type info initialization and avoid premature GC
Enable union by-value by using largest field's type info
Explicitly throw IllegalArgument on bad type info
Throw IllegalState on missing type info
Explicitly write version/md5 info into Makefile from ant (to avoid platform-specific variances in sed)
Make Structure.ByValue/ByReference public to allow client code comparisons
Consolidate Structure field get/set operations
Avoid extra Pointer peer lookup from native code (wmeissner)
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@421 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix window alpha compositing on X11
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@500 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"avoid more content dragging on OSX, or warn
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@647 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix javadoc error
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@343 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Allow ByReference types in callbacks
Clean up some Structure field error messages
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@340 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Show drop shadow on OSX BalloonManager
Fix NPE on OSX BalloonManager
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@337 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Throw UnsupportedOperationException when alpha not available and explain why, if possible
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@313 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix GetLastError bug
Make ByReference derive from Memory
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@299 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add auto-conversion for custom types
Fix X11 lib for 64-bit use
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@257 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix X11 mappings for 64-bit
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@492 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix OSX window transparency for 1.5+/Leopard
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@487 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Avoid creating too many windows when setting window mask
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@458 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"fix bug where struct is incorrectly passed by value instead of by reference
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@529 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix window alpha compositing on X11
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@500 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"avoid more content dragging on OSX, or warn
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@647 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix cursor tracking on alpha-masked windows
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@629 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Work around OSX transparent window dragging bug
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@619 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix transparent window error on win2k
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@669 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix X11 mappings for 64-bit
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@492 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix wchar_t* return when null
Allow Pointer[] as function argument
Fix window utils test on osx to avoid os-cast shadows
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@326 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Implement (most of) the fixes from issue #35.
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@266 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add auto-conversion for custom types
Fix X11 lib for 64-bit use
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@257 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add callback tests for smaller int types
Copy generic java.nio.Buffer support from v3 branch + tests
Copy missed sparc-isms from v3 branch for building sunos variants
Add stubs for platform-specific jars
Include libffi testsuite
Remove /lib64 references as per v3 branch
Auto-generate os prefix from os.name (as per v3 branch) to automatically handle new targets
Update overview to include Buffer, function pointer info
Include src.zip and doc.zip in dist generation
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@243 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Improve error messages when illegal argument/return types are used
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@440 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"fix callback allocation on freebsd
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@545 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/fix bug where struct is incorrectly passed by value instead of by reference
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@529 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix NPE
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@520 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Allow ByReference types in callbacks
Clean up some Structure field error messages
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@340 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add auto-conversion for custom types
Fix X11 lib for 64-bit use
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@257 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add callback tests for smaller int types
Copy generic java.nio.Buffer support from v3 branch + tests
Copy missed sparc-isms from v3 branch for building sunos variants
Add stubs for platform-specific jars
Include libffi testsuite
Remove /lib64 references as per v3 branch
Auto-generate os prefix from os.name (as per v3 branch) to automatically handle new targets
Update overview to include Buffer, function pointer info
Include src.zip and doc.zip in dist generation
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@243 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix arg/result handling for callback values in callbacks
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@428 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Allow arbitrary callback method names
Allow specification of callback type mapper with TYPE_MAPPER
Allow write with uninitialized boxed primitives in Structure
Fix memory leak with callbacks called from native threads w/no java context
Fix Structure derived classes to allow setting TypeMapper
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@690 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Implement (most of) the fixes from issue #35.
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@266 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add auto-conversion for custom types
Fix X11 lib for 64-bit use
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@257 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Improve error messages when illegal argument/return types are used
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@440 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Consolidate structure ffi type info initialization and avoid premature GC
Enable union by-value by using largest field's type info
Explicitly throw IllegalArgument on bad type info
Throw IllegalState on missing type info
Explicitly write version/md5 info into Makefile from ant (to avoid platform-specific variances in sed)
Make Structure.ByValue/ByReference public to allow client code comparisons
Consolidate Structure field get/set operations
Avoid extra Pointer peer lookup from native code (wmeissner)
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@421 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"add small struct return by value test
Fix issue #94
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@742 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix wchar_t* return when null
Allow Pointer[] as function argument
Fix window utils test on osx to avoid os-cast shadows
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@326 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix swing threading violation in test
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@312 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Enable VM crash protection on w32, linux
Move native library init from Pointer to Native
Fix Pointer.setNativeLong bug
Make library initialization explicit in Pointer/NativeLibrary
Javadoc cleanup
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@279 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Avoid creating too many windows when setting window mask
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@458 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/defer AWT toolkit initialization until actual JAWT use
Make w32 dynamically load JAWT to avoid forcing toolkit init on JNA load
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@418 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Avoid error loading JAWT when running headless
Use primary colors in window shape test (Dan)
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@412 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix window alpha compositing on X11
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@500 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Clean up temp files on w32
Avoid empty paths in search list
Add canonical 'out-of-date' jar
Clean up ant build script targets
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@347 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix GetLastError bug
Make ByReference derive from Memory
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@299 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Enable VM crash protection on w32, linux
Move native library init from Pointer to Native
Fix Pointer.setNativeLong bug
Make library initialization explicit in Pointer/NativeLibrary
Javadoc cleanup
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@279 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add callback tests for smaller int types
Copy generic java.nio.Buffer support from v3 branch + tests
Copy missed sparc-isms from v3 branch for building sunos variants
Add stubs for platform-specific jars
Include libffi testsuite
Remove /lib64 references as per v3 branch
Auto-generate os prefix from os.name (as per v3 branch) to automatically handle new targets
Update overview to include Buffer, function pointer info
Include src.zip and doc.zip in dist generation
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@243 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Copy fix for issue  #32 from v3 branch
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@236 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix linux library name mapping (sans regexp)
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@466 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Move w32 JAWT load into native code
Fix Structure.ByValue for callback arg/return
Perform better type checking on callback arg/return types
Propagate library/symbol lookup error messages
Enable loading of libraries with non-ascii names
Tighten type checking in native code
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@425 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix linux library load bug
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@572 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix 32/64-bit library lookup where both arch versions exist
Try 'lib' prefix on w32
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@625 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Apply xylo's library load patch, fix versioned name checking tests
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@573 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix for issue #93 and JRUBY-3084.
This alters the library search algorithm slightly:
1) Searches jna.library.path and any custom (per-library) paths for a
matching library.
2) If that fails, tries to load the mapped library name, using
dlopen/LoadLibrary.
3) If that fails, add all paths back into the search path and try to locate
the library in jna.platform.library.path with all the normal fallbacks.
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@737 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix stdcall callbacks
catch all exceptions when invoking callback
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@370 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Allocate executable memory for callbacks on w32
Synchronize on java callback allocation methods to avoid more complex native synchronization
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@332 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix GetLastError bug
Make ByReference derive from Memory
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@299 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Start on issue #38.  Main thing I wanted to do was get the second parameter to ToNativeConverter.toNative() in there so we don't have future API breakage by adding it later.
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@273 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Implement (most of) the fixes from issue #35.
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@266 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Add auto-conversion for custom types
Fix X11 lib for 64-bit use
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@257 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Clean up varargs
Add per-field Structure read/write
Avoid automatic writes to 'volatile' structure fields
Read/wrap function pointers in Structure fields
Disallow Memory/Function as declared Structure fields
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@241 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix bug in callback proxy.equals (wolfgang.roekelein)
Clean up some javadoc
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@439 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Consolidate Structure.ByReference reads
Cache native library options as well as alignments/type mappers
Ensure library options are passed to callbacks
Add protection around remaining Pointer read/write calls
Consolidate wide character reads/writes
Avoid stack overflow reading self-referential structures or loops
More prettification of Structure.toString
Add size_t/off_t standard types
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@435 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix arg/result handling for callback values in callbacks
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@428 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Move w32 JAWT load into native code
Fix Structure.ByValue for callback arg/return
Perform better type checking on callback arg/return types
Propagate library/symbol lookup error messages
Enable loading of libraries with non-ascii names
Tighten type checking in native code
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@425 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"avoid reallocating Integer objects
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@638 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"add small struct return by value test
Fix issue #94
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@742 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Allow arbitrary callback method names
Allow specification of callback type mapper with TYPE_MAPPER
Allow write with uninitialized boxed primitives in Structure
Fix memory leak with callbacks called from native threads w/no java context
Fix Structure derived classes to allow setting TypeMapper
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@690 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Implement (most of) the fixes from issue #35.
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@266 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"fix w32 api type mapper bug exposed by last round of changes
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@508 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix bug in stdcall function mapping when using struct by value
Defer size_t/off_t definition, for now
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@436 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix callbacks when DEP is enabled
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@540 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Consolidate structure ffi type info initialization and avoid premature GC
Enable union by-value by using largest field's type info
Explicitly throw IllegalArgument on bad type info
Throw IllegalState on missing type info
Explicitly write version/md5 info into Makefile from ant (to avoid platform-specific variances in sed)
Make Structure.ByValue/ByReference public to allow client code comparisons
Consolidate Structure field get/set operations
Avoid extra Pointer peer lookup from native code (wmeissner)
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@421 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Allow arbitrary callback method names
Allow specification of callback type mapper with TYPE_MAPPER
Allow write with uninitialized boxed primitives in Structure
Fix memory leak with callbacks called from native threads w/no java context
Fix Structure derived classes to allow setting TypeMapper
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@690 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix NPE in NativeMappedConverter
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@560 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix NPE when using NativeMapped within Structure (https://jna.dev.java.net/issues/show_bug.cgi?id=54)
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@499 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix non-w32 compilation
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@463 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/update project files (netbeans/eclipse)
use setjmp/longjmp to recover from w32 faults instead of simply setting SP
embed version resource information in w32 dll
don't update last error if ffi_call faults
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@462 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/Fix bug in stdcall function mapping when using struct by value
Defer size_t/off_t definition, for now
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@436 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix bug checking IntegerType limits
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@391 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix NPE when using NativeMapped within Structure (https://jna.dev.java.net/issues/show_bug.cgi?id=54)
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@499 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
jna,"Fix callbacks when DEP is enabled
git-svn-id: https://svn.java.net/svn/jna~svn/trunk@540 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80/"
OpenDDS,Properly open ErrorDialog in UI thread./
OpenDDS,"Tue Nov  2 18:29:27 UTC 2010  Don Hudson  <hudsond@ociweb.com>
- Made minor tweaks to formatting of error and debug messages for consistency and readability.
- Corrected a few incorrect method names in error and debug messages.
- Corrected a few spelling errors./"
OpenDDS,"Fixing a problem caused by not cleansing user input. Any
leading and/or trailing spaces must not be considered as part 
of the file name, otherwice a missing file to pop up shows up.
Improved user feedback on input errors due to non-existing model file,
or incorrect destination directory. Added a visual warning when the
chosen destination does not exist yet. A combination of visual clues
is used: a) errorneous input changes the text color to red; 
b) generation buttons are disabled when model file is not accessible, 
or if the target directory is invalid; c) if the target directory path
does not exist, the target dir label is decorated with info-level icon./"
OpenDDS,work-in-progress on transport refactoring: adapted the rest of the DDS_no_tests workspace; fixed bugs in wait_for_acks and shutdown/
OpenDDS,improved error indication from specific transport to framework/
OpenDDS,"Added links_lock_ to stop contention during connect_datalink causing multiple datalink instances to be created/Multicast Transport work -removed possible deadlocking in MulticastTransport.cpp, added logging to trace assoc failures throughout multicast, removed an unused TransportClient* arg in UdpTransport/"
OpenDDS,"Multicast Transport work -removed possible deadlocking in MulticastTransport.cpp, added logging to trace assoc failures throughout multicast, removed an unused TransportClient* arg in UdpTransport/UdpTransport updated to remove deadlock scenario between connections_lock_ and DataReaderImpl::publication_handle_lock_ as well as TransportClient::use_datalink_i to use a local copy of the RepoId for remote instead of the reference passed in to alleviate memory access violation caused when stop_accepting_or_connecting deletes callback but use_datalink_i still requires the RepoId to call transport_assoc_done/"
OpenDDS,Fixed another warning in FaceTSS./
OpenDDS,"More fixes for localhost./Merge remote branch 'upstream/master' into face-conf-test-suite
Conflicts:
dds/CORBA/tao/BasicSequences.cpp
dds/CORBA/tao/ORB_Misc.cpp
dds/CORBA/tao/OctetSeqC.cpp
dds/CORBA/tao/SystemException.cpp/"
OpenDDS,"Merge pull request #159 from mitza-oci/master
Warnings fixes for Visual C++./Warnings fixes for Visual C++./"
OpenDDS,"Merge pull request #159 from mitza-oci/master
Warnings fixes for Visual C++./Warnings fixes for Visual C++./"
OpenDDS,"Merge pull request #176 from objectcomputing/ipv6_changes
Fix test to call set_address with the proper arguments for IPV6 addre/Fix test to call set_address with the proper arguments for IPV6 addresses./Refactor open_dual_stack_socket into one function to open the appropriate type of socket for the configuration.  Fix issues with IPV6 builds in the transport tests to use correct sockets and address types./"
OpenDDS,"Merge pull request #140 from mitza-oci/master
Removed workarounds for GCC 3.3.x bugs./Removed workarounds for GCC 3.3.x bugs./"
OpenDDS,"Merge pull request #128 from objectcomputing/ts_api_updates_redmine_2334
Fix SampleInfo initializer in java test/Fix SampleInfo initializer in java test/"
OpenDDS,"Merge pull request #158 from objectcomputing/ipv6_updates
Bug and compilation error fixes./Bug and compilation error fixes./"
OpenDDS,"Merge pull request #146 from objectcomputing/ipv6_updates
Fix issues with IPV6 enabled builds on Windows./"
OpenDDS,"Merge pull request #275 from mitza-oci/master
Fixed reference counting and other memory management bugs/"
OpenDDS,"Merge pull request #360 from jwillemsen/master
Minor typo and doxygen fixes/"
OpenDDS,Fixed dissector bugs./
OpenDDS,"Merge pull request #349 from mitza-oci/master
Added ACE includes to fix static linking problem, needed template instantiations/Added ACE includes to fix static linking problem, needed template instantiations/"
OpenDDS,"Merge pull request #399 from huangminghuang/RcHandle_fix
Some fixes for RcHandle/Fix JNI compile errors/"
OpenDDS,"Initial support for Wireshark 2.x, see TODO comments
proto_tree_add* still needs to be handled as this has a large breaking change in wireshark/"
OpenDDS,Coverity Scan Defects: Addressing Uncaught Exceptions/
OpenDDS,"Merge pull request #556 from jwillemsen/jwi-aceerror-541
Use ACE_ERROR together with LM_ERROR, see issue #541/Use ACE_ERROR together with LM_ERROR, see issue #541
* dds/DCPS/DataReaderImpl.cpp:
* dds/DCPS/DataWriterImpl.cpp:
* dds/DCPS/DiscoveryBase.h:
* dds/DCPS/MultiTopicDataReaderBase.cpp:
* dds/DCPS/RTPS/ParameterListConverter.cpp:
* dds/DCPS/RTPS/Sedp.cpp:
* dds/DCPS/RTPS/Spdp.cpp:
* dds/DCPS/ReactorInterceptor.cpp:
* dds/DCPS/RecorderImpl.cpp:
* dds/DCPS/ReplayerImpl.cpp:
* dds/DCPS/StaticDiscovery.cpp:
* dds/DCPS/transport/framework/ReceiveListenerSet.cpp:
* dds/DCPS/transport/multicast/MulticastTransport.cpp:
* dds/DCPS/transport/rtps_udp/RtpsUdpDataLink.cpp:
* dds/DCPS/transport/rtps_udp/RtpsUdpSendStrategy.cpp:
* dds/DCPS/transport/rtps_udp/RtpsUdpTransport.cpp:
* dds/DCPS/transport/shmem/ShmemTransport.cpp:
* dds/DCPS/transport/tcp/TcpTransport.cpp:
* dds/DCPS/transport/udp/UdpTransport.cpp:
* dds/FACE/config/QosSettings.cpp:
* dds/idl/ts_generator.cpp:
* performance-tests/DCPS/MulticastListenerTest/Writer.cpp:
* performance-tests/DCPS/SimpleE2ETest/Reader.cpp:
* performance-tests/DCPS/SimpleE2ETest/Writer.cpp:
* performance-tests/DCPS/TCPListenerTest/Writer.cpp:
* performance-tests/DCPS/UDPListenerTest/Writer.cpp:
* performance-tests/DCPS/UDPNoKeyTest/Reader.cpp:
* performance-tests/DCPS/UDPNoKeyTest/Writer.cpp:
* tests/DCPS/Compiler/idl_test1_main/main.cpp:
* tests/DCPS/Compiler/idl_test3_main/main.cpp:
* tests/DCPS/FooTest5/DataReaderListener.cpp:
* tests/DCPS/ManyToMany/publisher.cpp:
* tests/DCPS/ManyToMany/subscriber.cpp:
* tests/DCPS/NotifyTest/subscriber.cpp:
* tests/DCPS/Ownership/DataReaderListener.cpp:
* tests/DCPS/Ownership/subscriber.cpp:
* tests/DCPS/Presentation/main.cpp:
* tests/DCPS/RtpsDiscovery/RtpsDiscoveryTest.cpp:
* tests/DCPS/StaticDiscovery/DataReaderListenerImpl.cpp:
* tests/FACE/Compiler/idl_test1_main/main.cpp:
* tests/FACE/Compiler/idl_test3_main/main.cpp:
* tests/FACE/Unit/test_check.h:
* tests/transport/rtps/subscriber.cpp:
* tests/transport/rtps_reliability/rtps_reliability.cpp:/"
OpenDDS,"Merge pull request #556 from jwillemsen/jwi-aceerror-541
Use ACE_ERROR together with LM_ERROR, see issue #541/Use ACE_ERROR together with LM_ERROR, see issue #541
* dds/DCPS/DataReaderImpl.cpp:
* dds/DCPS/DataWriterImpl.cpp:
* dds/DCPS/DiscoveryBase.h:
* dds/DCPS/MultiTopicDataReaderBase.cpp:
* dds/DCPS/RTPS/ParameterListConverter.cpp:
* dds/DCPS/RTPS/Sedp.cpp:
* dds/DCPS/RTPS/Spdp.cpp:
* dds/DCPS/ReactorInterceptor.cpp:
* dds/DCPS/RecorderImpl.cpp:
* dds/DCPS/ReplayerImpl.cpp:
* dds/DCPS/StaticDiscovery.cpp:
* dds/DCPS/transport/framework/ReceiveListenerSet.cpp:
* dds/DCPS/transport/multicast/MulticastTransport.cpp:
* dds/DCPS/transport/rtps_udp/RtpsUdpDataLink.cpp:
* dds/DCPS/transport/rtps_udp/RtpsUdpSendStrategy.cpp:
* dds/DCPS/transport/rtps_udp/RtpsUdpTransport.cpp:
* dds/DCPS/transport/shmem/ShmemTransport.cpp:
* dds/DCPS/transport/tcp/TcpTransport.cpp:
* dds/DCPS/transport/udp/UdpTransport.cpp:
* dds/FACE/config/QosSettings.cpp:
* dds/idl/ts_generator.cpp:
* performance-tests/DCPS/MulticastListenerTest/Writer.cpp:
* performance-tests/DCPS/SimpleE2ETest/Reader.cpp:
* performance-tests/DCPS/SimpleE2ETest/Writer.cpp:
* performance-tests/DCPS/TCPListenerTest/Writer.cpp:
* performance-tests/DCPS/UDPListenerTest/Writer.cpp:
* performance-tests/DCPS/UDPNoKeyTest/Reader.cpp:
* performance-tests/DCPS/UDPNoKeyTest/Writer.cpp:
* tests/DCPS/Compiler/idl_test1_main/main.cpp:
* tests/DCPS/Compiler/idl_test3_main/main.cpp:
* tests/DCPS/FooTest5/DataReaderListener.cpp:
* tests/DCPS/ManyToMany/publisher.cpp:
* tests/DCPS/ManyToMany/subscriber.cpp:
* tests/DCPS/NotifyTest/subscriber.cpp:
* tests/DCPS/Ownership/DataReaderListener.cpp:
* tests/DCPS/Ownership/subscriber.cpp:
* tests/DCPS/Presentation/main.cpp:
* tests/DCPS/RtpsDiscovery/RtpsDiscoveryTest.cpp:
* tests/DCPS/StaticDiscovery/DataReaderListenerImpl.cpp:
* tests/FACE/Compiler/idl_test1_main/main.cpp:
* tests/FACE/Compiler/idl_test3_main/main.cpp:
* tests/FACE/Unit/test_check.h:
* tests/transport/rtps/subscriber.cpp:
* tests/transport/rtps_reliability/rtps_reliability.cpp:/Merge pull request #547 from oschwaldp-oci/coverity_scan_defects_fixes
Coverity Scan defect: checking result of dynamic; ACE logging fixes; etc./"
OpenDDS,"Dissector: Handle invalid ITLs, mark missing ITLs
Handle Segfaults in sample dissectors from invalid ITLs.
This wouldn't detect if an ITL is valid, just check if a pointer
is definitely invalid during the payload dissection, inform the user
via the GUI that the error is most likely caused by an invalid ITL file
and exit as gracefully as possible (exit()).
Ideally it would just mark the packets as malformed and recover, but
that code is less than ideal (using set long jump from the SIGSEGV handler).
Also in this commit is using Wireshark's expert info to inform the user in
the GUI that it couldn't dissect a sample payload for other reasons:
No Topic to Track or No Dissector could be found for the Type./Dissector: Basic Payload Dissection in WS2
This is the basic framework for payload dissection in wireshark2.
Involves adding a hf vector to the Sample_Manager Singleton, adding
fields as they encountered in Sample_Dissector, and merging them with
the constant DCPS fields and passing the result to wireshark when DCPS
is registered. Sample Fields are left with a int that is the wireshark
field id (hf_).
During packet dissect, Sample_Fields are passed the wireshark field id
and using that they can add data corresponding to their field. Payload
type is now set on opendds.sample.payload and payload contents are added
in a tree under that.
Work left as of writing this is: to fix/complete registration of non
string fields, involve composite types (seq, union, etc), clean up
Sample_Manager usage, check/stop possible leak of dynamically generated
field names and get working with tests other than Messenger./Dissector: Fixed switched labels on opendds.length/Dissector: Fixed ""double"" DCPS packet info
In the packet tree, OpenDDS packet infomation would be added twice to
the packet information tree, at least in Wireshark 2.4.1 for the
Messager tests.
This appears to resolve that by removing a dissection call for TCP
packets./DCPS Dissector now running on Wireshark 2.4.1
- Added ""ws"" prefix to remaining calls to proto_tree_add and tvb_length./"
OpenDDS,"Merge pull request #719 from huangminghuang/master
Third batch of memory leak fixes/Merge pull request #710 from huangminghuang/master
Several memory leak fixes/Fix memory leaks in tests/transport//"
OpenDDS,Fix problem with delete interface/
OpenDDS,"Merge pull request #719 from huangminghuang/master
Third batch of memory leak fixes/"
OpenDDS,"Merge pull request #787 from iguessthislldo/wireshark2
Wireshark 2 Dissector: Fixes for Windows and Scoreboard/Dissector: Changes for Scoreboard, and others
Also:
Print ITL files and types found
Fixed Bug where every field was a struct/Dissector: Adjustments for WS compatibility
Made some changes to README
Sample Dissection enabled for Wireshark 1.x.
Attempted to make compatible with the next release, 2.5/2.6,
but it has an assertion error on start up. 1.10 and before segfaults.
Tested successfully with 1.12, 2.0, 2.2, and 2.4 on Linux./Dissector: Various Smaller Tasks
Completely Removed ws_proto_tree_add_text().
Mark Packet if a determinable error occurs during sample dissection./"
OpenDDS,"Merge pull request #794 from iguessthislldo/wireshark_improvements
dissector: Fixed Type Support and expert changes/dissector: Fixed Type Support and expert changes
Added support for dissection for OpenDDS fixed-point numbers which are
converted to doubles for numerical functions. If ACE_CDR::Fixed is
missing, a message will be displayed that this is so.
Also started marking some packets with a warning instead of marking it
as malformed. For example, when an individual field fails for some
reason or non essential information is unavailable, like the dissector
ITL file./Merge pull request #787 from iguessthislldo/wireshark2
Wireshark 2 Dissector: Fixes for Windows and Scoreboard/Dissector: Changes for Scoreboard, and others
Also:
Print ITL files and types found
Fixed Bug where every field was a struct/Dissector: %s -> %C ACE_DEBUG/Dissector: Fixed Content Filter Display/Dissector: READ and error handling fix/Dissector: Adjustments for WS compatibility
Made some changes to README
Sample Dissection enabled for Wireshark 1.x.
Attempted to make compatible with the next release, 2.5/2.6,
but it has an assertion error on start up. 1.10 and before segfaults.
Tested successfully with 1.12, 2.0, 2.2, and 2.4 on Linux./Dissector: Fixs for PR
Addressing Adams inital comments, Codacy, the Merge Conflict and a few
things I found along the way./Dissector: Various Smaller Tasks
Completely Removed ws_proto_tree_add_text().
Mark Packet if a determinable error occurs during sample dissection./Dissector: Serializer Refactor: Compiles, but broken/Dissector: Namespace Resolution and Union Bug
Added Sample_Base as a Parent Class to Sample_Field and
Sample_Dissector. Sample_Base holds wireshark namespace and field for
every context that it's child class is used in.
Tweaked Array and Sequence Labels and Namespace. For now using
""_e"" (for element) to access an element of the sequence or array.
Removed namespace debug messages.
Fixed bug in Union length calculation that caused String Key Test to
hang on dissection./"
OpenDDS,"Dissector: Refctr SD with RCH (Compiles but broken)/Various Improvements to the Dissector
- Made small changes to make it more complaint with what Wireshark is
expecting.
- Some Formatting fixes and more comments
- Fixed a malformed packet error where multiple samples causes
a boundary error of some kind./"
OpenDDS,"Dissector: Removed RCH, Fixed Warnings
Using Reference Count Handles was not working out as well as I liked, so
I have removed them, but left the double tree pass initialization so
that something similar (along the lines of the Proxy pattern) might be
able to be done in the future maybe.
Also got rid of proto_tree_add_*_format() warnings by inserting ""%s"" in
the parameters./"
OpenDDS,Merge branch 'security' of github.com:objectcomputing/OpenDDS into security (resolving a few conflicts / compile errors)/fixed a unit test for RTPS flags change/
OpenDDS,"i2jrt_TAOObject.cpp: Workaround for Android
This call was causing a ClassNotFoundException because the class loader
didn't have TAOObject in it's dexpath (classpath) the during the
finalize call. The workaround appears to be not to use the our
findClass() function and just use jni->FindClass()./"
OpenDDS,"Merge pull request #1089 from simpsont-oci/unit_tests_and_valgrind_issues_cleanup
Unit tests and valgrind issues cleanup/fixing several issues caught during valgrind run of scalability testing/"
OpenDDS,"delete_contained_entities hangs when Service Participant thread is interrupted (#1206)
An interrupt delievered to the Service Participant thread causes the
run_reactor_event_loop function to return with an ""interrupted system
call"" error.  An attempt to shutdown will notify the now stopped
reactor.  Since the reactor isn't running,
DomainParticipantImpl::handle_exception is never called.  Since
handle_exception is never called, the condition variable is not
released and shutdown hangs.
The solution is to block signals in the Service Participant thread (and
other threads that are running the reactor event loop).  This was already
being done in the transport reactor task so it was promoted and similar
classes were consolidated./Merge pull request #1212 from objectcomputing/post-1202-transport-test
rtps_reliability.cpp: fixed compile error/rtps_reliability.cpp: fixed compile error/remove debug output from rtps_reliability test/fix security test issues (double association / volatile gap without info_dst / secure discovery), fix rtps transport test to associate correctly/"
OpenDDS,"Fixes for Saftey Profile and C++03/Refactor with Stricter Time Types
Types representing monotonic clock time, system clock time and time
duration. Refactored the core libraries to use them over ACE_Time_Value
wherever possible. Tests were left alone for the most part unless they
interacted with the converted values in the core libraries. Also fixes
for the previous monotonic commits./"
OpenDDS,Various Fixes/
OpenDDS,"Merge pull request #1524 from simpsont-oci/fix_multi_transport_messenger_test
Fix multi-transport Messenger test/"
OpenDDS,Fix Java test/
OpenDDS,"Merge pull request #1552 from simpsont-oci/fixing_ooo_data_and_fragment_issues
Fixing Out-of-Order / Missing Data and Fragment Handling Issues/fixing duplicate fragment range insertion issue in TransportReassembly::insert/"
pljava,Added plug for bug votes on the jar file specification bug./
pljava,Fixes to some problems reported by Filip Hrbek/
pljava,Fix for bug #907 and #908/
pljava,Fix for bug #907 and #908/
pljava,Fixed some gcjh compiler problems/Fixed bug occuring sporadically on re-entry./Fix of bug 915 and 916/
pljava,GCJ bug #20193/
pljava,Fixed bug causing primitive arrays to fail./
pljava,Fixed ArrayIndexOutOfBounds exception reported by Petr Michalek/Fixed bug# 1218/
pljava,"From now getWarning throws an exception on a closed statement, according to JDBC specification/"
pljava,Fixed bug# 1218/Fixed glitch that made GCJ compilation fail./
pljava,Fixed bug #1231/Fixed bug# 1218/
pljava,"Dropped support for versions prior to 8.0.
Fixed bug causing stack check failur when backend was called from thread other than main
Fixed stability issue related to GC and MemoryContexts/"
pljava,Fixed bug causing crash after fence rewrite when returning tuples./
pljava,"Reinstated Exception traces when log level >= DEBUG1
Merged Invocation and CallContext
Cleanup and refactoring/"
pljava,"Dropped support for versions prior to 8.0.
Fixed bug causing stack check failur when backend was called from thread other than main
Fixed stability issue related to GC and MemoryContexts/"
pljava,"Dropped support for versions prior to 8.0.
Fixed bug causing stack check failur when backend was called from thread other than main
Fixed stability issue related to GC and MemoryContexts/"
pljava,Fixed needed code to accomodate API change for LargeObjects/
pljava,"Dropped support for versions prior to 8.0.
Fixed bug causing stack check failur when backend was called from thread other than main
Fixed stability issue related to GC and MemoryContexts/"
pljava,Fixed portal clean-up./
pljava,"Dropped support for versions prior to 8.0.
Fixed bug causing stack check failur when backend was called from thread other than main
Fixed stability issue related to GC and MemoryContexts/"
pljava,"Reinstated Exception traces when log level >= DEBUG1
Merged Invocation and CallContext
Cleanup and refactoring/Dropped support for versions prior to 8.0.
Fixed bug causing stack check failur when backend was called from thread other than main
Fixed stability issue related to GC and MemoryContexts/"
pljava,"Dropped support for versions prior to 8.0.
Fixed bug causing stack check failur when backend was called from thread other than main
Fixed stability issue related to GC and MemoryContexts/"
pljava,"Dropped support for versions prior to 8.0.
Fixed bug causing stack check failur when backend was called from thread other than main
Fixed stability issue related to GC and MemoryContexts/"
pljava,"Reinstated Exception traces when log level >= DEBUG1
Merged Invocation and CallContext
Cleanup and refactoring/"
pljava,"Dropped support for versions prior to 8.0.
Fixed bug causing stack check failur when backend was called from thread other than main
Fixed stability issue related to GC and MemoryContexts/"
pljava,Fixed bug that caused crash when initializing using incorrect pljava.classpath/
pljava,"Dropped support for versions prior to 8.0.
Fixed bug causing stack check failur when backend was called from thread other than main
Fixed stability issue related to GC and MemoryContexts/"
pljava,"Reinstated Exception traces when log level >= DEBUG1
Merged Invocation and CallContext
Cleanup and refactoring/Fixed bug causing crash after fence rewrite when returning tuples./Dropped support for versions prior to 8.0.
Fixed bug causing stack check failur when backend was called from thread other than main
Fixed stability issue related to GC and MemoryContexts/"
pljava,"Reinstated Exception traces when log level >= DEBUG1
Merged Invocation and CallContext
Cleanup and refactoring/Fixed bug causing crash after fence rewrite when returning tuples./Dropped support for versions prior to 8.0.
Fixed bug causing stack check failur when backend was called from thread other than main
Fixed stability issue related to GC and MemoryContexts/"
pljava,"Dropped support for versions prior to 8.0.
Fixed bug causing stack check failur when backend was called from thread other than main
Fixed stability issue related to GC and MemoryContexts/"
pljava,"Reinstated Exception traces when log level >= DEBUG1
Merged Invocation and CallContext
Cleanup and refactoring/Fixed bug causing crash after fence rewrite when returning tuples./Fixed typo/Dropped support for versions prior to 8.0.
Fixed bug causing stack check failur when backend was called from thread other than main
Fixed stability issue related to GC and MemoryContexts/Fixed bug that caused crash when initializing using incorrect pljava.classpath/"
pljava,Fixed bug #1506. Jar owner in the sqlj.jar_repository table changed type from oid to name./
pljava,Testcase covering bug #1317/
pljava,Fixed memory leak that occured during recursive calls to function returning sets/Fixed bug #1506. Jar owner in the sqlj.jar_repository table changed type from oid to name./
pljava,Fixed memory leak that occured during recursive calls to function returning sets/Fixed support for parameters of type RECORD./
pljava,Testcase covering bug #1317/
pljava,"Fixed some backward compatibility issues
Added explicit coercion capability/"
pljava,Fix of bug #1556/
pljava,"Fixed some backward compatibility issues
Added explicit coercion capability/"
pljava,Fix of bug #1556/
pljava,Fix of bug #1556/
pljava,Fixed stack backtrace on failure to load class/Improved exception handling/Fixed typo/
pljava,Fixed some issues with Meta-data/
pljava,Fixed some issues with Meta-data/
pljava,"When doing batch execution with batches that have different types,
the server crashes because it did not replan the query for the new
types.  Save the type information for each batch and compare it with
the previous values to see if we need to replan.
Bug #1010188/Batch execution of PreparedStatements failed because addBatch was
only saving off the parameter values while it ignored the parameter
types.  Save both the types and values.
Reported by Lucas Madar
Bug #1010183/"
pljava,"For a multi-threaded pljava function we need to adjust stack_base_ptr
before calling into the backend to avoid stack depth limit exceeded
errors.  Previously this was done only on query execution, but we
need to do it on iteration of the ResultSet as well.
In general it seems that anything operating inside of
synchronized(Backend.THREADLOCK) might need to adjust the stack
unless it's certain the work it's doing is trivial and won't invoke
check_stack_depth.  Unfortunately I don't know enough about when pg
calls check_stack_depth to know offhand what is/is not safe.  A more
thorough audit is required here.
Per report from Alexander Whrer./"
pljava,"When executing a statement, we want to make sure any previous state
was cleaned up, so the code was calling close().  This additionally
set a closed flag which would throw exceptions later saying that you
can't call various methods because the Statement is closed.  It's
not actually closed, so split the internal cleanup routine to clear()
and make close() something that only a user should call./"
pljava,"Code in a TransactionListener which tried to make a backend call
would crash because the Invocation context was not setup.  Some
simple backend calls might be safe, but we really don't want any
user code calling into the backend when we're at transaction end,
so prevent all access./"
pljava,"Bugfix: 1010971 SPIConnection.getMetaData() is incorrectly documented
It is now correctly documented./"
pljava,Fix ambiguity when compiling with Java 6./
pljava,"Bug 1011119: Let Postgres' bool --> java.sql.Types.BOOLEAN match
Java's java.sql.Types.BOOLEAN --> Postgres' bool./"
pljava,WIP 1011095: Proposed change to fix loading of security related classes./
pljava,Bugfix 1011181: PL/Java fails to compile with -Werror=format-security./
pljava,"Changes are required because of move of GETSTRUCT() and timeout
handling framework changes done in PG 9.3. Along with that I fixes
minor issue in DDRProcessor.java that is causing ""illegal start of
expression"" error. Maven did not worked for me to build it and hang
endlessly while building c source code (pljava-so). As a workaround I
temporarily fixed makefiles to test PG9.3 related fix that seems
worked and generated pljava.jar and pljava.so files and their basic
sanity seems working fine./"
pljava,"Merge pull request #42 from jcflack/workaround/master/javac7
Workaround #39 breakage seen with Java 7/Workaround the problem reported in #39.
The annotation processor in javac runs in multiple 'rounds', as long as
generated source files keep appearing, and one final round after they
don't. This code used to save some mapping of Class objects to the
javax.lang.model objects (TypeElement/TypeMirror) until the final round,
which worked in Java 6, but as of 7 one gets back different model objects
in different rounds, for the same types, and they don't match, so type
mapping breaks.
This workaround moves all those lookups to before or during round 1, when
a consistent set of model objects can be looked up. So, it will work as
long as all the source files that might contain pljava annotations will be
found in round 1. That should always be the case unless someone is using a
very fancy build with _other_ annotation processors generating new source
files with pljava annotations that have to be processed in additional
rounds. For now, that won't work, because their types won't seem to match
what was computed in round 1. So don't do that.
http://bugs.java.com/bugdatabase/view_bug.do?bug_id=8038455 might refer
to this problem, and promises a fix in Java 9, for what it's worth./"
pljava,"Merge pull request #41 from jcflack/bug/master/ddrorder
Run deployment descriptors in correct order./Run deployment descriptors in correct order.
Previously determined the order of multiple deployment descriptors in
a single jar according to the order of those entries as stored in the jar
(used in that order for install, and that order reversed for remove).
But that wasn't correct. I got my hands on 2003 and 2006 drafts of the
SQL/JRT spec and they both clearly say it is the order _as the entries
are listed in the manifest_ that matters (again, in that order for install,
and the reverse for remove).
This should be a welcome improvement, because I had noted back in
commit 0edc9e5f that maven doesn't always put things in a jar in
the same order, and that was causing the pljava-examples jar to be
broken about half the time (for autodeployment anyway). But the manifest
is a static file listing the ddrs in the right order, so as long as
maven doesn't reorder it while putting it in the jar, that behavior
should now be stable./"
pljava,"Merge pull request #42 from jcflack/workaround/master/javac7
Workaround #39 breakage seen with Java 7/"
pljava,"Merge pull request #57 from jcflack/bug/master/issue21
Pass all Unicode codepoints transparently (issue #21)./Eliminate threadlock ops in string conversion.
The Java methods related to charset encoding/decoding may be called
repeatedly, and they don't require the threadlock to be released and
reacquired. I don't measure much difference in timing (I don't really
have a good ""average text"" corpus to test on; the test case for this
bug is worst case because it uses all of the biggest characters.)
Even without a compelling timing difference, the Java charset encoders/
decoders aren't thread safe, so I feel just that much better holding
on to the lock./Make String.c use Java's charset en/decoders.
In this commit, all the conversions in String.c except
String_createJavaString(text*) which can have a bug fixed first./Merge pull request #55 from jcflack/bug/master/issue54
Only ignore the expected exception in method lookup./Only ignore the expected exception in method lookup.
That way other exceptions (like a problem in a class initializer, or
out of memory) will not be hidden from view. Closes #54./Merge pull request #29 from kenolson/bug/master/msvc_build
Fix to allow building pljava with Microsoft Visual C/Fix to allow building pljava with Microsoft Visual C
Code changes to allow compilation and linking with Microsoft
Visual C. Maven build process conditionalized to to detect Visual C
and adjust options appropriately. See msvc-build-notes.txt for
full details. Property names updated for clarity/"
pljava,"Zap a few more conversion (not sign-) warnings.
count|how
-----|------
2  |  fixed with obvious cast lacking in PG macro (e.g. PGUNSIXBIT)
5  |  fixed using `size_t/Size` not `int`, locally verifiable
1  |  cast to member defined by others, static `AssertVariableIsOfType`
1  |  fixed with width suffix on literal/"
pljava,"Improve message in strange javac error case.
Earlier in the week I saw truly perplexing errors that stemmed
from a simple missing or misspelled import, but javac, instead
of reporting the error, would supply DDRProcessor with an instance
of an internal Error class where the unresolvable value should have
been. So now, at least recognize that Error class and produce a more
helpful message. Now, of course, I am unable to test the change,
because javac (same version! same machine!) is now doing the right
thing every time. At least with this change, if the right conditions
are ever hit again for javac to misbehave as it was earlier, the
message should be more helpful./Conform to BaseUDT rename, add MappedUDT.
Supporting MappedUDT is much simpler. It emits a
CREATE TYPE foo AS ( ... structure ... )
if a structure is provided, or not, if it isn't, followed by a
SELECT sqlj.add_type_mapping( ... ), and that's it.
Much javadoc also added.
This commit ends with pure renames of the Point and ComplexTuple
examples in preparation to make them annotation examples ... breaking
compilation until they are fixed up in the next commit, but git can
see where they went./Add a class annotation to make a base/scalar UDT.
- Add the annotation, have DDRProcessor recognize it.
- Check the annotated class for the required properties and members.
- The snippets map formerly allowed only one type of annotation on
a given element. That happened to work, but not now when a class
could have both a UDT and a SQLAction annotation, for example.
Adapt the map to key by element and snippet class, so snippets
of different classes can be hung on an element and selectively
retrieved.
- An old comment in populateAnnotationImpl suggested it would reduce
boilerplate setter code if, failing to find a setter method, the
field itself could be reflectively looked up and stored. That's done
now, so setter methods are needed only when something more special
has to be done.
- Function declarations will be synthesized automagically for the four
mandatory (in, out, recv, send) methods, but to allow their properties
to be individually adjusted, they can still accept Function
annotations. That's done by hanging a new subclass of FunctionImpl on
those elements, that generates the right special form of declaration,
and has setters that refuse changes to certain properties where that
wouldn't make sense.
- Treat the default implementor-tag (PostgreSQL if not changed with new
ddr.implementor command line property) specially. Now that everything
is getting wrapped with an implementor tag by default, the implied
requires=""implementor-tag"" was holding everything back until released
by the cycle-breaker, sometimes in puzzling order. The implementor tag
that happens to be the default one should /not/ be treated as a
pending requirement.
- Move ComplexScalar to annotation subpackage, in preparation for
revamping it as an annotation example. So git won't lose track of it,
this is a breaking change, to be fixed in the next commit with edits
corresponding to the move./"
pljava,"Workaround Windows creating_extension visibility.
Should now detect (in most cases?) when an extension is
being created, even in versions where creating_extension
isn't visible in Windows. Test depends on seeing the command
in ActivePortal; I am not sure what contexts could be contrived
where that wouldn't work right, but ordinary foreseeable cases
seem to work.
Got rid of pljavaInExtension: the idea that two cases have to be
distinguished (loading PL/Java itself as an extension, or using it
in the creation of some other extension) was sound, but the second
case isn't something that can be checked once at load time; it needs
a backend function that sqlj.install_jar can invoke whenever needed./"
pljava,"Merge pull request #75 from tada/chore/master/javadoc8
Could as well have been called a bug, because javadoc 8 lint _stops_ `mvn site`./"
pljava,"Merge pull request #75 from tada/chore/master/javadoc8
Could as well have been called a bug, because javadoc 8 lint _stops_ `mvn site`./"
pljava,"Don't leave SET ROLE broken after DDR execution.
Comments in miscinit.c suggest the PostgreSQL team considers
{Get,Set}UserIdAndContext to be obsolete API kept around only
for PL/Java, with {Get,Set}UserIdAndSecContext being the preferred
newer API. Something for another day..../"
pljava,"Merge pull request #75 from tada/chore/master/javadoc8
Could as well have been called a bug, because javadoc 8 lint _stops_ `mvn site`./"
pljava,"Merge pull request #75 from tada/chore/master/javadoc8
Could as well have been called a bug, because javadoc 8 lint _stops_ `mvn site`./"
pljava,"Work around symbols MSVC can't link to.
The long pgsql-hackers thread in 2014 discovering that MSVC could
silently link global variables to the wrong stuff if not properly
decorated in PG's .h files documents how the problem of silently
succeeding was solved by making such cases fail instead. That's
great, only now they fail.
These patches make the pessimistic assumption that no working way
to access the global variables will be found. That might not be the
case, because there's a recent new pgsql-hackers thread
http://www.postgresql.org/message-id/CAFj8pRAEj9vCj6kn0Vh7o1xRKty=zTmSSTrc1e2uSRMOq8cCVw@mail.gmail.com
that has rekindled some interest in finding a better solution to the
problem. Anyway, until that day, these workarounds should achieve the
correct behavior under MSVC./Add a GUC option for libjvm location.
The linker used to embed a dependency for libjvm into the pljava shared
object, which required using one of several system-specific ways to get
the system's library loader (not PostgreSQL's) to be able to find libjvm,
or loading pljava would simply fail.
By omitting the linked-in dependency on libjvm, pljava can now successfully
load and then use PostgreSQL's own dlopen wrapper to find libjvm using the
pljava.libjvm_location option, or give a helpful error report.
The history of PGDLLEXPORT through the years has been
somewhat bewildering, and it begins to seem tidier to cleanly define
a PLJAVADLLEXPORT that is used only here and doesn't change its meaning
across PG releases./"
pljava,"Use PG 8.3 find_coercion_pathway API.
Ok, this compiles and doesn't break any -examples tests (and will give
errors for unhandled return cases, or a warning when disregarding
domain constraints). The reason it went unnoticed so long is that
Type_getCoerce{In,Out} are really very seldom called. They are almost
dead code--fairly contrived function declarations are needed even to
force them to be called for test purposes.
That seems to be mostly because Type_getCoerce{In,Out} won't be
called if Type_canReplaceType returns true, which it very often does,
because (a) Type_fromOid silently replaces domains with their base
types, and (b) Function builds the method signature by mapping the
SQL return type to a Java type and looking for a matching method, failing
if none is found, rather than looking for a method by its name and
parameter signature only, then validating its return type. So, essentially
by construction, coercion of the return type can't ever turn out to be
necessary.
It could, however, if the AS string gives the Java return type explicitly,
and it requires coercion to the (base type of the) SQL type. SQL/JRT has
no syntax to specify the Java return type, but as an extension it seems
PL/Java does: ""Function mapping"" in the wiki gives an example where it
precedes class.method, separated by a space. Only the example doesn't
work. That's because the getAS code accepts the syntax only when the
return type is purely alphanumeric (no dots, so non-package-qualified).
Not a recent change, has been that way since 2006. An = is also accepted,
though, even after a package-qualified return type. The example works if
retried with an =.
SQL/JRT, it seems to me, specifies the other approach to method
resolution, that is, find the method by name and parameter signature,
then work out what to do with its return type, but that would be a change
to current PL/Java behavior.
The unimplemented warning for RELABELTYPE to a domain type essentially
can't be triggered, because of the way any domain is replaced by its base
type before consulting canReplaceType. That's harmless for IN parameters.
For the return type, it's a type-safety hole: a PL/Java function can
return a value that isn't valid for its declared result domain. Fixing
that should be possible, but beyond the scope of this issue.
The not-implemented errors for COERCEVIAIO and ARRAYCOERCE can be
triggered, just by constructing exactly the sort of function declarations
where you would expect those things to happen. They would still be
arguably contrived cases, where the AS string specifies a method with
different types than would naturally correspond to the SQL ones.
Nevertheless, the ""Function mappping"" wiki page says ""PL/Java will use
a standard PostgreSQL explicit cast when the SQL type of the parameter
or return value does not correspond..."" and that's not completely true
at the moment, as long as some features available in standard PostgreSQL
explicit casts, like array or I/O coercion, aren't yet implemented.
Again, beyond the scope of issue 65. At least those cases now give clear
errors, instead of crashes or Krueger numbers as I just confirmed in a
build without this change, so this does in fact fix a latent bug.
Note that the single-row result set writers used for functions that
return composite or set-of-composite results have their own coercion
logic completely unrelated to this, and implemented in SPIConnection.java.
There are more moving parts here than I had hoped..../Merge pull request #66 from tada/bug/master/coerceout
Type_getCoerceOut correct statement order.
Calling this one obvious enough to be uncontroversial./Type_getCoerceOut correct statement order.
Ken Olson pointed this out as a case of 'dead code', but in fact it was
live use of an unassigned variable just before the function call that
was going to assign it. Had to be an editing mixup, has been that way
a very long time, and has probably not caused more problems only because
it's statistically rare for a random stack location to be exactly equal
to InvalidOid.
Scratches the surface of #65. A full solution for that issue will have to
come later, but this much was an obvious Heisenbug with an obvious fix./"
pljava,"Merge branch 'chore/master/java7ify'
Bump the minimum Java to 7 and begin adopting Java 7 features
in places where the fruit hangs low./Merge branch 'feature/REL1_5_STABLE/typmodprep' into REL1_5_STABLE
Not a full implementation of type modifiers (which were requested
in feature request 1011140), which would be too much to hold 1.5.0 for,
but just enough to avoid releasing a version that gets in the way later:
the SQL generator had better at least emit the three-argument forms for
input and receive function declarations, or they would later have to be
dropped and replaced, a cascading disruption. Non-default values in the
extra arguments are not yet supported; they'll just cause unsupported
feature ereports.
As it turns out, only rare corners of PostgreSQL need that support;
most application of typmods is done with the three-argument cast, which
is already expressible in PL/Java. So, unexpectedly, mostly-usable
typmod support is already here, and a new example illustrates it./Lay groundwork for typmod support.
To fully support type modifiers, including the three-argument forms
of input/receive functions, will take more thought than 1.5.0 can wait
for. But to release 1.5.0 with the SQL generator emitting the
one-argument forms would invite headaches later, because CREATE OR
REPLACE FUNCTION can't change the parameter list, and DROP/reCREATE
would cause cascading disruption. So, make sure the generator already
emits the three-argument form, and just be sure to fail if a non-default
typmod is in fact passed, with more complete support to be added later.
By happy chance, it seems that PostgreSQL only very rarely passes non-
default typmods to the input/receive functions--possibly only during
COPY operations. (Those were the only way I was able to test this
change.)
In most other cases where a typmod is used, PostgreSQL relies on a
typmod application cast in a separate step, not on passing the typmod
to input/receive. PL/Java is already usable to implement typmodin,
typmodout, and cast functions, so in limited testing it seems possible
already to do types with typmods, maybe as long as COPY operations on
them are not needed. Therefore, add an example that illustrates it./Merge issue #95 fix.
Certain later-detected annotation errors were being output with no
source location info, probably because of that javac (new with 7?
see also #39) habit of throwing away symbol tables between rounds.
Merge branch 'workaround/REL1_5_STABLE-BASE/sourcelocs'/Merge issue #95 fix.
Certain later-detected annotation errors were being output with no
source location info, probably because of that javac (new with 7?
see also #39) habit of throwing away symbol tables between rounds.
Merge branch 'workaround/REL1_5_STABLE-BASE/sourcelocs' into REL1_5_STABLE./Catch compiler-caused classcast confusion.
When the compiler hasn't made sense of an annotated element because
of some error in the source, it may pass the annotation processor an
element of an unexpected type. The right response seems
to be to silently return (before anything that risks a class cast
exception), as the compiler will produce its own messages about what
the true problem was./Call getSQLType earlier for errors' sake.
Unmappable types can be discovered when building the deployStrings
for a function, which normally happens too late for good error
messages if javac throws stuff away between rounds. So, just make
the messages, if any, happen early, by having FunctionImpl call its
deployStrings from characterize./Invoke characterize methods earlier.
When this step was done as part of generateDescriptor (which only runs
once in the final round), any errors reported by characterize() were
being shown with no source location info ... apparently because javac
(since 7?) throws symbol tables away between rounds./Merge branch 'bug/REL1_5_STABLE-BASE/issue92' into REL1_5_STABLE/Merge branch 'bug/REL1_5_STABLE-BASE/issue92'/Now passes issue 92 test./Merge pull request #86 from tada/workaround/master/modelerrors
Improve message in strange javac error case./Cover other possible javac-error case.
Another case was possible that wouldn't have created a message.
I still can't test this now, because javac won't mess up when
it knows I'm looking./"
pljava,"Merge branch 'bug/REL1_5_STABLE/udtarch' into REL1_5_STABLE
Addresses the user-defined type issues reported as #98 and #99./Clunky but serviceable way to set byte order.
Addresses issue #98. There really hasn't been a document that just lays
out in detail how PL/Java's data coercions are chosen and especially how
the raw-chunk-based versions of SQLInput/SQLOutput work. Discovered,
while documenting that, the reason Point was showing bogus values (noted
in pull request #59 comments) ... byte order ... leading to a
last-minute rework of SQLInputFromChunk and SQLOutputToChunk allowing
byte order to be selected.
(It has to be selectable, not just fixed, in case PL/Java gets updated
at a site that has a bunch of data stored under the old byte order.
A switch allows dumping with the old order, then reloading with the
new. In fact, by choosing a different byte order for each conversion
direction, it is possible ... carefully ... to update in place.)
A flag is passed to SQLInputFromChunk_create and
SQLOutputFromChunk_create to indicate whether the type is
a 'java-based scalar' (otherwise, it is a non-composite mirror),
and this allows byte order to be specified separately for scalars
and mirrors: historically, it was always bigendian regardless of
architecture. Presumably that has never mattered much for java-based
scalars (because PostgreSQL itself doesn't have any independent way
of seeing into them, so no inconsistency was visible), but for a
mirror type it is definitely broken if the hardware is not bigendian,
with PostgreSQL and Java not seeing the values the same way.
Therefore, this change leaves the scalar default (for 1.5.0 at least)
at bigendian, in case some sites may have used Java-based scalars in
the past and have tables that contain them. Also, the current UDT
implementation gives every scalar type a binary send/receive/COPY
format that can't (yet) be decoupled from its internal stored form, and
the PostgreSQL docs specify big-endian for those binary transfer formats,
so it would be premature to change the scalar byte-order default before
it is also possible to have a separate transfer format.
For mirror types, on the other hand, the default is here immediately
changed to native ... it is less likely that sites were heavily
using mirror UDTs if they were seeing bogus values, and this will
make them work right by default.
Java properties are used (set with -D in the pljava.vmoptions GUC):
org.postgresql.pljava.udt.byteorder  to set everything the same,
org.postgresql.pljava.udt.byteorder.scalar
org.postgresql.pljava.udt.byteorder.mirror  to set them separately.
The allowable values for each property are big_endian, little_endian,
and native.
Even finer-grained control is available with:
org.postgresql.pljava.udt.byteorder.scalar.p2j
org.postgresql.pljava.udt.byteorder.scalar.j2p
org.postgresql.pljava.udt.byteorder.mirror.p2j
org.postgresql.pljava.udt.byteorder.mirror.j2p
for a very special purpose, should someone wish to attempt an
UPDATE where within a session, a column with values written
in one order gets rewritten in another, a fiddly and somewhat
unnerving process that turns out to actually work, and has a
full new page documenting it now./"
pljava,"Add large object truncate and 64-bit offsets.
PG 8.3 introduced inv_truncate, and 9.3 made offsets/lengths 64 bit.
What's nice is that the Java and JNI method signatures have
always been 64-bit ready; now just stop downcasting to 32 on
9.3+ PostgreSQLs where 64 bit offsets are really accepted./"
pljava,"Merge branch 'chore/master/java7ify'
Bump the minimum Java to 7 and begin adopting Java 7 features
in places where the fruit hangs low./No more standard charset lookups by name.
Rethink use of java.util.Scanner to slurp data ... it's very
convenient, but part of the reason is it swallows IOExceptions.
If you add the extra lines of code to hang onto the reference
and call its ioException() method to see if something went wrong,
the brevity advantage slips away./Merge branch 'doc/REL1_5_STABLE/clarify' into REL1_5_STABLE
Clarifies permissions needed for self-extractor, and the
CREATE-EXTENSION-failed-because-new-session-needed message,
as Daniel Blanch Bataller suggested./Make create-extension-didn't message clearer.
The only error message resulting from a CREATE EXTENSION attempt
that failed (because the library had been loaded before in the
session, therefore LOAD was a no-op) is one about a table that
already exists.
But the name of the table appears in the error message, so the
table may as well be named
""see doc: do CREATE EXTENSION PLJAVA in new session""
which may serve to get the point across./Merge branch 'bug/REL1_5_STABLE/udtarch' into REL1_5_STABLE
Addresses the user-defined type issues reported as #98 and #99./Clunky but serviceable way to set byte order.
Addresses issue #98. There really hasn't been a document that just lays
out in detail how PL/Java's data coercions are chosen and especially how
the raw-chunk-based versions of SQLInput/SQLOutput work. Discovered,
while documenting that, the reason Point was showing bogus values (noted
in pull request #59 comments) ... byte order ... leading to a
last-minute rework of SQLInputFromChunk and SQLOutputToChunk allowing
byte order to be selected.
(It has to be selectable, not just fixed, in case PL/Java gets updated
at a site that has a bunch of data stored under the old byte order.
A switch allows dumping with the old order, then reloading with the
new. In fact, by choosing a different byte order for each conversion
direction, it is possible ... carefully ... to update in place.)
A flag is passed to SQLInputFromChunk_create and
SQLOutputFromChunk_create to indicate whether the type is
a 'java-based scalar' (otherwise, it is a non-composite mirror),
and this allows byte order to be specified separately for scalars
and mirrors: historically, it was always bigendian regardless of
architecture. Presumably that has never mattered much for java-based
scalars (because PostgreSQL itself doesn't have any independent way
of seeing into them, so no inconsistency was visible), but for a
mirror type it is definitely broken if the hardware is not bigendian,
with PostgreSQL and Java not seeing the values the same way.
Therefore, this change leaves the scalar default (for 1.5.0 at least)
at bigendian, in case some sites may have used Java-based scalars in
the past and have tables that contain them. Also, the current UDT
implementation gives every scalar type a binary send/receive/COPY
format that can't (yet) be decoupled from its internal stored form, and
the PostgreSQL docs specify big-endian for those binary transfer formats,
so it would be premature to change the scalar byte-order default before
it is also possible to have a separate transfer format.
For mirror types, on the other hand, the default is here immediately
changed to native ... it is less likely that sites were heavily
using mirror UDTs if they were seeing bogus values, and this will
make them work right by default.
Java properties are used (set with -D in the pljava.vmoptions GUC):
org.postgresql.pljava.udt.byteorder  to set everything the same,
org.postgresql.pljava.udt.byteorder.scalar
org.postgresql.pljava.udt.byteorder.mirror  to set them separately.
The allowable values for each property are big_endian, little_endian,
and native.
Even finer-grained control is available with:
org.postgresql.pljava.udt.byteorder.scalar.p2j
org.postgresql.pljava.udt.byteorder.scalar.j2p
org.postgresql.pljava.udt.byteorder.mirror.p2j
org.postgresql.pljava.udt.byteorder.mirror.j2p
for a very special purpose, should someone wish to attempt an
UPDATE where within a session, a column with values written
in one order gets rewritten in another, a fiddly and somewhat
unnerving process that turns out to actually work, and has a
full new page documenting it now./Rework extension wrappers slightly.
Instead of different ad-hoc ways of detecting the already-LOADed
no-op issue for different CREATE EXTENSION cases, have the LOAD-
invoked code always drop the loadpath table, so all extension scripts
can use the same approach to force an error if it didn't happen./Change default USAGE grant for 'java'.
Ok, it seems that another change to the PostgreSQL large object APIs
happened in PG 9.0: large objects got ACLs. Before that, anybody could
access them. In PL/Java, anybody still can. :(
The ideal accommodation on PL/Java's side will be to retarget PL/Java's
LargeObject code from the PG inv_api.c layer to the be-fsstubs.c layer
(if something doesn't make that prohibitively difficult), because that's
where the 9.0+ access checks happen. Otherwise, the checking code needs
to be duplicated in PL/Java.
The fsstubs layer has only-good-within-one-transaction semantics.
Happily, that's all that's expected for the JDBC *LOB interfaces,
which presumably are the public API this stuff should ultimately have.
Too involved for 1.5.0. However, this is a good argument for a least-
privilege, no-public-by-default installation of the 'java' language,
documenting how GRANT USAGE can then be used to allow specific
users/roles to make PL/Java functions.
Moral: this wasn't a problem before 9.0, when everybody knew LOBs had
no access controls. It became a problem when PG added access controls
for them, and PL/Java didn't follow suit. What's a trusted language
today could need adjustments tomorrow, so no-public-usage-by-default
really seems like the best posture; the user/installer should always be
encouraged to follow the least privilege principle./"
pljava,"Merge branch 'chore/master/java7ify'
Bump the minimum Java to 7 and begin adopting Java 7 features
in places where the fruit hangs low./"
pljava,"Merge branch 'chore/master/java7ify'
Bump the minimum Java to 7 and begin adopting Java 7 features
in places where the fruit hangs low./"
pljava,"Merge branch 'chore/master/java7ify'
Bump the minimum Java to 7 and begin adopting Java 7 features
in places where the fruit hangs low./No more standard charset lookups by name.
Rethink use of java.util.Scanner to slurp data ... it's very
convenient, but part of the reason is it swallows IOExceptions.
If you add the extra lines of code to hang onto the reference
and call its ioException() method to see if something went wrong,
the brevity advantage slips away./Merge branch 'bug/REL1_5_STABLE/udtarch' into REL1_5_STABLE
Addresses the user-defined type issues reported as #98 and #99./Clunky but serviceable way to set byte order.
Addresses issue #98. There really hasn't been a document that just lays
out in detail how PL/Java's data coercions are chosen and especially how
the raw-chunk-based versions of SQLInput/SQLOutput work. Discovered,
while documenting that, the reason Point was showing bogus values (noted
in pull request #59 comments) ... byte order ... leading to a
last-minute rework of SQLInputFromChunk and SQLOutputToChunk allowing
byte order to be selected.
(It has to be selectable, not just fixed, in case PL/Java gets updated
at a site that has a bunch of data stored under the old byte order.
A switch allows dumping with the old order, then reloading with the
new. In fact, by choosing a different byte order for each conversion
direction, it is possible ... carefully ... to update in place.)
A flag is passed to SQLInputFromChunk_create and
SQLOutputFromChunk_create to indicate whether the type is
a 'java-based scalar' (otherwise, it is a non-composite mirror),
and this allows byte order to be specified separately for scalars
and mirrors: historically, it was always bigendian regardless of
architecture. Presumably that has never mattered much for java-based
scalars (because PostgreSQL itself doesn't have any independent way
of seeing into them, so no inconsistency was visible), but for a
mirror type it is definitely broken if the hardware is not bigendian,
with PostgreSQL and Java not seeing the values the same way.
Therefore, this change leaves the scalar default (for 1.5.0 at least)
at bigendian, in case some sites may have used Java-based scalars in
the past and have tables that contain them. Also, the current UDT
implementation gives every scalar type a binary send/receive/COPY
format that can't (yet) be decoupled from its internal stored form, and
the PostgreSQL docs specify big-endian for those binary transfer formats,
so it would be premature to change the scalar byte-order default before
it is also possible to have a separate transfer format.
For mirror types, on the other hand, the default is here immediately
changed to native ... it is less likely that sites were heavily
using mirror UDTs if they were seeing bogus values, and this will
make them work right by default.
Java properties are used (set with -D in the pljava.vmoptions GUC):
org.postgresql.pljava.udt.byteorder  to set everything the same,
org.postgresql.pljava.udt.byteorder.scalar
org.postgresql.pljava.udt.byteorder.mirror  to set them separately.
The allowable values for each property are big_endian, little_endian,
and native.
Even finer-grained control is available with:
org.postgresql.pljava.udt.byteorder.scalar.p2j
org.postgresql.pljava.udt.byteorder.scalar.j2p
org.postgresql.pljava.udt.byteorder.mirror.p2j
org.postgresql.pljava.udt.byteorder.mirror.j2p
for a very special purpose, should someone wish to attempt an
UPDATE where within a session, a column with values written
in one order gets rewritten in another, a fiddly and somewhat
unnerving process that turns out to actually work, and has a
full new page documenting it now./"
pljava,"Merge branch 'chore/master/java7ify'
Bump the minimum Java to 7 and begin adopting Java 7 features
in places where the fruit hangs low./No more standard charset lookups by name.
Rethink use of java.util.Scanner to slurp data ... it's very
convenient, but part of the reason is it swallows IOExceptions.
If you add the extra lines of code to hang onto the reference
and call its ioException() method to see if something went wrong,
the brevity advantage slips away./Merge branch 'bug/REL1_5_STABLE/udtarch' into REL1_5_STABLE
Addresses the user-defined type issues reported as #98 and #99./Clunky but serviceable way to set byte order.
Addresses issue #98. There really hasn't been a document that just lays
out in detail how PL/Java's data coercions are chosen and especially how
the raw-chunk-based versions of SQLInput/SQLOutput work. Discovered,
while documenting that, the reason Point was showing bogus values (noted
in pull request #59 comments) ... byte order ... leading to a
last-minute rework of SQLInputFromChunk and SQLOutputToChunk allowing
byte order to be selected.
(It has to be selectable, not just fixed, in case PL/Java gets updated
at a site that has a bunch of data stored under the old byte order.
A switch allows dumping with the old order, then reloading with the
new. In fact, by choosing a different byte order for each conversion
direction, it is possible ... carefully ... to update in place.)
A flag is passed to SQLInputFromChunk_create and
SQLOutputFromChunk_create to indicate whether the type is
a 'java-based scalar' (otherwise, it is a non-composite mirror),
and this allows byte order to be specified separately for scalars
and mirrors: historically, it was always bigendian regardless of
architecture. Presumably that has never mattered much for java-based
scalars (because PostgreSQL itself doesn't have any independent way
of seeing into them, so no inconsistency was visible), but for a
mirror type it is definitely broken if the hardware is not bigendian,
with PostgreSQL and Java not seeing the values the same way.
Therefore, this change leaves the scalar default (for 1.5.0 at least)
at bigendian, in case some sites may have used Java-based scalars in
the past and have tables that contain them. Also, the current UDT
implementation gives every scalar type a binary send/receive/COPY
format that can't (yet) be decoupled from its internal stored form, and
the PostgreSQL docs specify big-endian for those binary transfer formats,
so it would be premature to change the scalar byte-order default before
it is also possible to have a separate transfer format.
For mirror types, on the other hand, the default is here immediately
changed to native ... it is less likely that sites were heavily
using mirror UDTs if they were seeing bogus values, and this will
make them work right by default.
Java properties are used (set with -D in the pljava.vmoptions GUC):
org.postgresql.pljava.udt.byteorder  to set everything the same,
org.postgresql.pljava.udt.byteorder.scalar
org.postgresql.pljava.udt.byteorder.mirror  to set them separately.
The allowable values for each property are big_endian, little_endian,
and native.
Even finer-grained control is available with:
org.postgresql.pljava.udt.byteorder.scalar.p2j
org.postgresql.pljava.udt.byteorder.scalar.j2p
org.postgresql.pljava.udt.byteorder.mirror.p2j
org.postgresql.pljava.udt.byteorder.mirror.j2p
for a very special purpose, should someone wish to attempt an
UPDATE where within a session, a column with values written
in one order gets rewritten in another, a fiddly and somewhat
unnerving process that turns out to actually work, and has a
full new page documenting it now./"
pljava,Merge branch 'bug/REL1_5_STABLE-BASE/issue92' into REL1_5_STABLE/Merge branch 'bug/REL1_5_STABLE-BASE/issue92'/Add test detecting issue 92./
pljava,"Merge branch 'bug/REL1_5_STABLE/tupdescleak' into REL1_5_STABLE
Eliminate TupleDesc reference leak warnings at uses of
composite UDTs; also commit a test class from an old pgFoundry
bug report 1010962 - different issue, but also TupleDesc reference
leak warnings, and it runs without any now, so in it goes as a
regression test./Plug composite UDT TupleDesc leak.
In the composite case, UDT was keeping a reference to the type's
TupleDesc, causing PostgreSQL's reference counter to report a leak.
Not a growing, memory leak: only one TupleDesc for each type would
be kept. Of more concern would be how to invalidate it if the
underlying type is altered. More convincing to just grab it from the
type cache whenever needed. More at:
http://www.postgresql.org/message-id/flat/56DF8122.20607@anastigmatix.net/Merge branch 'bug/REL1_5_STABLE/udtarch' into REL1_5_STABLE
Addresses the user-defined type issues reported as #98 and #99./Check for base UDT if no other type mapping found.
Addresses issue #99. The strategy of registering base UDTs on the
first call to their input/output/send/recv functions breaks down if
the first reference in a session to such a type is one that doesn't
involve calling those functions (for example, an existing table has
a column of that type, and a query wants to pass it to a Java
function accepting that type; PostgreSQL has no reason to think it
should call an I/O function in that case).
This change adds one more step to the rules in Type_fromOid. If no
previous step succeeded, and just before punting to String, take a
close look at the type to see if it could be a Base UDT.
That's a tedious check that involves following the type's input/
output/receive/send Oids via prolang back to their language Oids, and
(one could stop here by assuming the language will always be named
'java' or 'javaU', but if not) from there to the language's call
handler C function and its dynamic library path, which should match
PL/Java's. A future optimization could cache language Oids that are
found to refer to PL/Java, but it might not be needed often enough
to matter./"
pljava,"Merge pull request #97 from TwentyOneSolutions/REL1_5_STABLE
Clarifies init-sequence error hint about JVM library file name, which can be somewhat different between platforms./Merge branch 'bug/REL1_5_STABLE/udtarch' into REL1_5_STABLE
Addresses the user-defined type issues reported as #98 and #99./Check for base UDT if no other type mapping found.
Addresses issue #99. The strategy of registering base UDTs on the
first call to their input/output/send/recv functions breaks down if
the first reference in a session to such a type is one that doesn't
involve calling those functions (for example, an existing table has
a column of that type, and a query wants to pass it to a Java
function accepting that type; PostgreSQL has no reason to think it
should call an I/O function in that case).
This change adds one more step to the rules in Type_fromOid. If no
previous step succeeded, and just before punting to String, take a
close look at the type to see if it could be a Base UDT.
That's a tedious check that involves following the type's input/
output/receive/send Oids via prolang back to their language Oids, and
(one could stop here by assuming the language will always be named
'java' or 'javaU', but if not) from there to the language's call
handler C function and its dynamic library path, which should match
PL/Java's. A future optimization could cache language Oids that are
found to refer to PL/Java, but it might not be needed often enough
to matter./Accommodate Windowsish printf format differences.
Windows sets int = long = int32, int64 = ""long long"". jni_md.h
on Windows defines jint as long, jlong as long long. The gcc
printf format checker in mingw notices these things. To keep it
quiet, cast to known types and use corresponding formats.
The debug messages are elogs, not ereports, hence not candidates for
localization, so the format macro can be used directly. If localization
were needed, the formats would need %s with the number-to-string
conversion done in a separate step./Merge pull request #89 from tada/chore/master/debuglevels
Make DEBUG1 quieter.
Move a bunch of DEBUG1s to DEBUG2, leaving DEBUG1 for the
initial load message that identifies PL/Java and JVM versions.
(This is NOTICE if PL/Java is explicitly LOADed, so it's seen
by default, but in other cases you can now see it by enabling
DEBUG1, and not mixed in with a lot of other stuff.)/Make DEBUG1 quieter.
Move a bunch of DEBUG1s to DEBUG2, leaving DEBUG1 for the
initial load message that identifies PL/Java and JVM versions.
(This is NOTICE if PL/Java is explicitly LOADed, so it's seen
by default, but in other cases you can now see it by enabling
DEBUG1, and not mixed in with a lot of other stuff.)/"
pljava,"Handle widening of portalPos and demise of posOverflow.
No need for version conditionals around isPosOverflow: it isn't in
an API class, and nothing in this code base uses it, so out it goes.
This eliminates the other compile-time error that was blocking
compilation for PG 9.6, but it's not the last thing to have had
its width changed./"
pljava,"Handle the widening of FuncCallContext's call_cntr.
This one is a bit stickier, because the value is passed to Java code
that implements ResultSetProvider, an interface in pljava-api. The
signature for assignRowValues can't just be changed.
Instead, for now, a ResultSetProvider is limited to returning INT_MAX
rows, but the limit is checked to ensure a predictable failure.
For the future, in the Java 8 world, the ResultSetProvider interface
could grow a default method largeAssignRowValues that takes a long
row number; the Java 8 default implementation would just signal the
same error, and classes implementing the old interface won't break.
Alas, PL/Java isn't committed to supporting only Java 8 yet.
In fact, the same thing could be done on the quiet: PL/Java could check
whether the class implementing ResultSetProvider happens to have a
largeAssignRowValues method with the right signature, and use it if
present. It would simply have to be covered in documentation, and not
formally declared in the interface until the Java support bar moves to
Java 8.
All of that is future work - this change merely checks and enforces
an INT_MAX limit./"
pljava,"Initialize more lazily in background workers.
In a background worker (in particular, one running ParallelWorkerMain),
PL/Java's _PG_init can get called even if the parallel query being
executed makes no reference to PL/Java functions. That's because
ParallelWorkerMain makes sure the same libraries are loaded that were
present in the lead process, so if it had loaded PL/Java at any time,
it gets loaded in the background worker ... quite early, and _PG_init
gets called before much of the state it wants to look at has been
set up.
Detect that case and bail from the initsequencer as soon as possible
(right after defining the custom GUCs), leaving all the rest to be
completed when (if!) any actual call arrives at the call handler.
This prevents a baffling failure in parallel queries that make no use
of PL/Java; even better, it also avoids starting JVMs unnecessarily in
parallel queries that aren't going to use them./"
pljava,"Merge pull request #121 from tada/chore/REL1_5_STABLE/debuglevels
Keep making DEBUG1 quieter./Keep making DEBUG1 quieter.
These sites were missed in commit 1eb3bd8, trying to get the
PL/Java-loaded-versions announcement to be the only thing at DEBUG1./"
pljava,"Merge pull request #123 from tada/bug/REL1_5_STABLE/loapi
Do away with never-documented, long-broken LargeObject code./Do away with never-documented LargeObject code.
In the run-up to releasing 1.5.0, the code to do with large objects
was looked over in a very conservative and cautious way, as fits
code that was never documented or presented as API and didn't have
any test coverage, with little way of knowing whether some client
code somewhere in the wild might have been developed around it.
So, it got carefully updated to 64-bit offsets, and even had a
vulnerability reported because it hadn't been updated to honor
the object access controls added in 9.0.
What all that very conservative analysis failed to notice was,
thanks to a change made back in 77bfc34, coupled with the absence
of test coverage, it has been about eleven years since the last
chance anyone ever had of doing anything useful with a LargeObject
instance. That makes the decision to do away with it much easier.
In all the PostgreSQL versions PL/Java currently supports, all the
functions needed to manipulate large objects are already exposed in
SQL and usable through the JDBC/SPI, without any specific effort
needed in PL/Java. For programming convenience, some later version
(after Java 7 becomes the minimum requirement) could add a simple
utility method to turn an integer LO fd from lo_open into a
SeekableByteChannel that could then be used without further trips
through SPI, but even that would be about optimization and convenience,
not functionality./"
pljava,"Merge pull request #121 from tada/chore/REL1_5_STABLE/debuglevels
Keep making DEBUG1 quieter./Keep making DEBUG1 quieter.
These sites were missed in commit 1eb3bd8, trying to get the
PL/Java-loaded-versions announcement to be the only thing at DEBUG1./"
pljava,"Merge pull request #123 from tada/bug/REL1_5_STABLE/loapi
Do away with never-documented, long-broken LargeObject code./Do away with never-documented LargeObject code.
In the run-up to releasing 1.5.0, the code to do with large objects
was looked over in a very conservative and cautious way, as fits
code that was never documented or presented as API and didn't have
any test coverage, with little way of knowing whether some client
code somewhere in the wild might have been developed around it.
So, it got carefully updated to 64-bit offsets, and even had a
vulnerability reported because it hadn't been updated to honor
the object access controls added in 9.0.
What all that very conservative analysis failed to notice was,
thanks to a change made back in 77bfc34, coupled with the absence
of test coverage, it has been about eleven years since the last
chance anyone ever had of doing anything useful with a LargeObject
instance. That makes the decision to do away with it much easier.
In all the PostgreSQL versions PL/Java currently supports, all the
functions needed to manipulate large objects are already exposed in
SQL and usable through the JDBC/SPI, without any specific effort
needed in PL/Java. For programming convenience, some later version
(after Java 7 becomes the minimum requirement) could add a simple
utility method to turn an integer LO fd from lo_open into a
SeekableByteChannel that could then be used without further trips
through SPI, but even that would be about optimization and convenience,
not functionality./"
pljava,"Merge pull request #123 from tada/bug/REL1_5_STABLE/loapi
Do away with never-documented, long-broken LargeObject code./Do away with never-documented LargeObject code.
In the run-up to releasing 1.5.0, the code to do with large objects
was looked over in a very conservative and cautious way, as fits
code that was never documented or presented as API and didn't have
any test coverage, with little way of knowing whether some client
code somewhere in the wild might have been developed around it.
So, it got carefully updated to 64-bit offsets, and even had a
vulnerability reported because it hadn't been updated to honor
the object access controls added in 9.0.
What all that very conservative analysis failed to notice was,
thanks to a change made back in 77bfc34, coupled with the absence
of test coverage, it has been about eleven years since the last
chance anyone ever had of doing anything useful with a LargeObject
instance. That makes the decision to do away with it much easier.
In all the PostgreSQL versions PL/Java currently supports, all the
functions needed to manipulate large objects are already exposed in
SQL and usable through the JDBC/SPI, without any specific effort
needed in PL/Java. For programming convenience, some later version
(after Java 7 becomes the minimum requirement) could add a simple
utility method to turn an integer LO fd from lo_open into a
SeekableByteChannel that could then be used without further trips
through SPI, but even that would be about optimization and convenience,
not functionality./"
pljava,"Merge pull request #119 from tada/bug/REL1_5_STABLE/pg_upgrade
Address #117 and document upgrade procedures./"
pljava,"Merge pull request #145 from feature/REL1_5_STABLE/constrainttrigger
Constraint triggers can be declared and are usable (the runtime will
deliver them; a trigger method should throw an exception to report that
a constraint would be violated); however, the TriggerData interface has
not been extended to expose any of the new contraint-trigger-specific
information to the called method./Adjust per earlier discussion.
Now has enum Constraint with only the constraint-related values; its
actual omission is what indicates a non-constraint trigger. The name
fromSchema is kept (it has no analog in the PG syntax), but fromTable
is now simply from, to match the PG syntax. Semantic errors are checked.
Also some whitespace tweaks.
An example/test is still needed./"
pljava,"Merge pull request #142 from tada/bug/REL1_5_STABLE/issue142
Enable row triggers to suppress operations./Enable row triggers to suppress operations.
Adds to TriggerData the suppress() method suggested in issue #142./Merge pull request #135 from tada/bug/REL1_5_STABLE/issue134
Accomodate upstream SPI_push/pop API changes (issue #134)/"
pljava,"Merge pull request #135 from tada/bug/REL1_5_STABLE/issue134
Accomodate upstream SPI_push/pop API changes (issue #134)/"
pljava,"Annotate Connection methods and add more comments.
Add @Override to the methods in SPIConnection that are specified
by the Connection API (to make it easier to spot the ones that
aren't). For those added in JDBC 4.1, the annotation is commented out,
as PL/Java 1.5 still strives to be buildable with Java 6. Once the
back-compatibility horizon is Java 7 or later, those @Overrides can
be uncommented.
It would also be fair to say this has added annotations (or
commented-out annotations) through JDBC 4.2, as it didn't add
any new Connection methods.
The PL/Java-specific and internal methods are now easier to pick out
(they're the ones without @Override annotations), and have some more
extensive comments about what they're doing there. Also moved one
method to be nearer the stuff it pertains to. No code changes (except
to add the specified generic signature on getTypeMap/setTypeMap).
Indentation adjusted in a couple contiguous areas./Merge pull request #141 from pmichalek/bug/REL1_5_STABLE/issue136
PL/Java's internal JDBC driver was forked from pgjdbc a long time ago,
and there's a lot wrong with the nativeSQL method. It gives a meaning to
backslash that isn't from the SQL or JDBC standards, it has no knowledge
of standard JDBC escapes, or the difference between standard-conforming
and e-quoted strings, or Unicode strings, or dollar-quoted strings, or
continuation of string literals. Bringing it all to spec would be far
too much change for a minor PL/Java release.
All that being said, this particular quoting issue is a simple, obvious
bug among bugs, and has been reported, so it is clearly in somebody's
way, so no objection to fixing it here, though it leaves nativeSQL() for
now only slightly less wrong./Fix #136 SPIConnection prepareStatement doesn't recognize all parameters
when SQL combines single and double quotes/"
pljava,"Merge pull request #145 from feature/REL1_5_STABLE/constrainttrigger
Constraint triggers can be declared and are usable (the runtime will
deliver them; a trigger method should throw an exception to report that
a constraint would be violated); however, the TriggerData interface has
not been extended to expose any of the new contraint-trigger-specific
information to the called method./Merge pull request #142 from tada/bug/REL1_5_STABLE/issue142
Enable row triggers to suppress operations./Add a constraint-trigger example.
A more interesting test would be to actually try to insert 44, and
verify that the exception happens. (Oh, for the chance to use pgTAP...)./Enable row triggers to suppress operations.
Adds to TriggerData the suppress() method suggested in issue #142./Merge pull request #135 from tada/bug/REL1_5_STABLE/issue134
Accomodate upstream SPI_push/pop API changes (issue #134)/Document (lack of) issue #134 regression test.
An obvious place to put it, in examples/Triggers.java, won't really
help, because those all run with SPI already connected and would not
catch the bug.
This is more of a note to the future, to make such a test when there
is more of a regression test infrastructure to run tests from outside
PL/Java itself./"
pljava,"Fix dangling pointer left as GUC boot value.
The clearly-intended-but-forgotten 'static' here never caused
functional trouble in practice, because the value was valid at the only
time it was used. It could, however, cause unexpected bytes to appear
in the boot_val column of the pg_settings view, which in turn appeared
as character-encoding errors in tests of XML processing with
schema_to_xml('pg_catalog', ...) as the source document for testing,
which ended up being how this missing 'static' came to light./"
pljava,"Don't repeat yourself with UDT mappings.
It was never satisfying to define a UDT in Java through annotations
and still have the DDR generator give ""no mapping to an SQL type"" errors
for functions accepting or returning that type. It was easy enough (if
tedious) to work around by adding explicit type= or @SQLType annotations,
but the DDR generator had all the necessary information to figure that out
without such manual help. Now it does, eliminating the tedium
illustrated in jcflack/pljava-udt-type-extension@bcb5734.
To accommodate mappings added from the source being compiled, the
protoMappings collection is now of TypeMirror instances rather than
of Class instances.
Still future work: also add implied ordering dependencies for uses of
the new type (such as functions that have it as parameter or return
types and have to follow the type declaration, as illustrated in
jcflack/pljava-udt-type-extension@225ef5c, or that are named in it as,
for example, typmod in/out functions, and have to precede it)./Merge pull request bug/REL1_5_STABLE/issue157
Fix failure of the compile-time SQL generator to recognize bytea as the
SQL type corresponding to Java's byte[]. Also eliminates a longstanding
warning message./This fixes a problem but not the problem.
The name passed to getTypeElement is expected to be a canonical name,
but that isn't what Class.getName() returns (or there wouldn't be a
Class.getCanonicalName()).
However, the problem seems to be deeper; arrays are not listed among the
things TypeElements exist to represent. It may be necessary to drill down
to the component type and then construct the TypeMirror using
getArrayType()./Let annotations give row-type parameters defaults.
The @SQLType annotation can now supply an array of strings as
defaultValue for a parameter that has a row type (either the RECORD
type, whose structure is unknown, or a named row type).
In the case of RECORD, the only default that will be accepted is
{} (the array of no strings). While a bit limiting, that is still
just the ticket when a RECORD-typed parameter is being used to
supply a function with an optional, arbitrary sequence of named, typed
parameters.
In the case of a named row type, the default should be an array of
as many strings as the components of the type, and the strings should
be castable to the corresponding component types. The DDR generator
has no way to check that at compile time, but PostgreSQL will report
the error at jar install time if there is a mismatch./"
pljava,"Merge pull request #150 from trackjdbc/REL1_5_STABLE/udttypename
Supplies one of the short-term improvements suggested in issue #149./Use getSQLTypeName, and add a test.
Provide one of the short-term solutions suggested in issue #149.
As the current PreparedStatement implementation does not get the
inferred parameter types from PostgreSQL (which became possible
with SPI only as recently as PostgreSQL 9.0), its setObject method
must make a best effort to map in the other direction, finding the
PostgreSQL type that corresponds to the Java parameter value. In
one case, this is easily made much more reliable: when the Java
parameter value is an SQLData instance (a UDT), and therefore has
a getSQLTypeName method, unused until now.
Add a test method (in the ComplexTuple UDT example) to confirm that
the type is properly mapped when passed as a parameter to a
PreparedStatement./"
pljava,"Sort implemented from unimplemented JDBC4 methods.
Move those that have some JDBC-allowed behavior (other than
throwing a not-supported exception) into the 'implemented'
category, even when the JDBC-allowed behavior is to do
nothing special. Leave in the 'unimplemented' category just
the methods that ought to do something else, but currently
throw the not-supported exception.
In passing, just provide the natural implementation for
isWrapperFor and unwrap; it's no more trouble than throwing
the exception!
For ResultSetMetaData, pull up their implementations into
AbstractResultSetMetaData, so they don't have to be duplicated
in SPIResultSetMetaData and SyntheticResultSetMetaData.
Some indentation normalized, only in areas touched./"
pljava,"Sort implemented from unimplemented JDBC4 methods.
Move those that have some JDBC-allowed behavior (other than
throwing a not-supported exception) into the 'implemented'
category, even when the JDBC-allowed behavior is to do
nothing special. Leave in the 'unimplemented' category just
the methods that ought to do something else, but currently
throw the not-supported exception.
In passing, just provide the natural implementation for
isWrapperFor and unwrap; it's no more trouble than throwing
the exception!
For ResultSetMetaData, pull up their implementations into
AbstractResultSetMetaData, so they don't have to be duplicated
in SPIResultSetMetaData and SyntheticResultSetMetaData.
Some indentation normalized, only in areas touched./"
pljava,"Sort implemented from unimplemented JDBC4 methods.
Move those that have some JDBC-allowed behavior (other than
throwing a not-supported exception) into the 'implemented'
category, even when the JDBC-allowed behavior is to do
nothing special. Leave in the 'unimplemented' category just
the methods that ought to do something else, but currently
throw the not-supported exception.
In passing, just provide the natural implementation for
isWrapperFor and unwrap; it's no more trouble than throwing
the exception!
For ResultSetMetaData, pull up their implementations into
AbstractResultSetMetaData, so they don't have to be duplicated
in SPIResultSetMetaData and SyntheticResultSetMetaData.
Some indentation normalized, only in areas touched./"
pljava,"Sort implemented from unimplemented JDBC4 methods.
Move those that have some JDBC-allowed behavior (other than
throwing a not-supported exception) into the 'implemented'
category, even when the JDBC-allowed behavior is to do
nothing special. Leave in the 'unimplemented' category just
the methods that ought to do something else, but currently
throw the not-supported exception.
In passing, just provide the natural implementation for
isWrapperFor and unwrap; it's no more trouble than throwing
the exception!
For ResultSetMetaData, pull up their implementations into
AbstractResultSetMetaData, so they don't have to be duplicated
in SPIResultSetMetaData and SyntheticResultSetMetaData.
Some indentation normalized, only in areas touched./"
pljava,"Restore javadoc buildability with Java 8+
Fix a few recently-touched javadoc comments that do not prevent
doc building in Java 7, but do under the stricter rules introduced
in javadoc in Java 8./Sort implemented from unimplemented JDBC4 methods.
Move those that have some JDBC-allowed behavior (other than
throwing a not-supported exception) into the 'implemented'
category, even when the JDBC-allowed behavior is to do
nothing special. Leave in the 'unimplemented' category just
the methods that ought to do something else, but currently
throw the not-supported exception.
In passing, just provide the natural implementation for
isWrapperFor and unwrap; it's no more trouble than throwing
the exception!
For ResultSetMetaData, pull up their implementations into
AbstractResultSetMetaData, so they don't have to be duplicated
in SPIResultSetMetaData and SyntheticResultSetMetaData.
Some indentation normalized, only in areas touched./"
pljava,"SQLXML in/out of PreparedStatements / ResultSets.
For PreparedStatement.setObject(col, x, Types.SQLXML) to work,
it's sufficient to mention the type in Oid.c. Getting the type
back from the ResultSet already works, thanks to the
Type_registerType() already done in SQLXMLImpl.c. However, the
test in the getObject(col, SQLXML.class) needed fixing, as it was
testing exact class equality, not whether it got an implementation
of the desired interface. (In passing, reorder those methods to make
clearer what JDBC revision brought them in.)
The setObject overload without the explicit Types.SQLXML will not
work yet, and simply adding addType(SQLXML.class,Types.SQLXML)
in SPIConnection is not sufficient ... because that uses a hash
table and therefore also depends on exact class equality; the full
grody names of the implementing classes would have to be added.
Or the mechanism would have to be fixed.
Wondering why the out.updateObject(col, x) works, without giving
an explicit type? That result set is already typed (by the column
definition list you have to include in the query calling this
RECORD-typed function). That method succeeding is /almost/ enough
to make a subsequent ps.setObject(col, x) work right (because in
succeeding, it primed the s_class2typeId cache in Oid); how would
that be for spooky action at a distance? But that doesn't quite
happen, because that cache is also a strict-class-equality hash map.
At this point, implementing the various (get,set,update}SQLXML methods
will be an easy formality, as they can be implemented in terms of the
methods taking explicit types, which now work.
Alas, this current behavior won't do for a 1.5.x release, because it
would actually start producing SQLXML objects by default where old
code may be expecting String. Before merging, this will need a way
to suppress that automatic mapping but still allow the explicit kind.
A subsequent major release can then go the rest of the way./Sort implemented from unimplemented JDBC4 methods.
Move those that have some JDBC-allowed behavior (other than
throwing a not-supported exception) into the 'implemented'
category, even when the JDBC-allowed behavior is to do
nothing special. Leave in the 'unimplemented' category just
the methods that ought to do something else, but currently
throw the not-supported exception.
In passing, just provide the natural implementation for
isWrapperFor and unwrap; it's no more trouble than throwing
the exception!
For ResultSetMetaData, pull up their implementations into
AbstractResultSetMetaData, so they don't have to be duplicated
in SPIResultSetMetaData and SyntheticResultSetMetaData.
Some indentation normalized, only in areas touched./"
pljava,"Merge pull request #150 from trackjdbc/REL1_5_STABLE/udttypename
Supplies one of the short-term improvements suggested in issue #149./Use getSQLTypeName, and add a test.
Provide one of the short-term solutions suggested in issue #149.
As the current PreparedStatement implementation does not get the
inferred parameter types from PostgreSQL (which became possible
with SPI only as recently as PostgreSQL 9.0), its setObject method
must make a best effort to map in the other direction, finding the
PostgreSQL type that corresponds to the Java parameter value. In
one case, this is easily made much more reliable: when the Java
parameter value is an SQLData instance (a UDT), and therefore has
a getSQLTypeName method, unused until now.
Add a test method (in the ComplexTuple UDT example) to confirm that
the type is properly mapped when passed as a parameter to a
PreparedStatement./"
pljava,"Don't repeat yourself with UDT mappings.
It was never satisfying to define a UDT in Java through annotations
and still have the DDR generator give ""no mapping to an SQL type"" errors
for functions accepting or returning that type. It was easy enough (if
tedious) to work around by adding explicit type= or @SQLType annotations,
but the DDR generator had all the necessary information to figure that out
without such manual help. Now it does, eliminating the tedium
illustrated in jcflack/pljava-udt-type-extension@bcb5734.
To accommodate mappings added from the source being compiled, the
protoMappings collection is now of TypeMirror instances rather than
of Class instances.
Still future work: also add implied ordering dependencies for uses of
the new type (such as functions that have it as parameter or return
types and have to follow the type declaration, as illustrated in
jcflack/pljava-udt-type-extension@225ef5c, or that are named in it as,
for example, typmod in/out functions, and have to precede it)./"
realm-java,"Moved the Table annotation into ""com.tightdb"" package (issue #47)./Removed "".generated"" suffix in generated sources packages (issue #46)./Updated and adjusted examples due to the model changes (issue #50)./"
realm-java,Fixes for: Support for transactions and replication added/
realm-java,"Fixed bug in ""isEmpty"" method of a View./Prepared and added new methods to table/view interface (issue #53)./"
realm-java,"Used the ""short"" low-level methods by appropriate methods (issue #53)./"
realm-java,Switched from errors to warnings for non-critical problems(issue #49)./
realm-java,small update in error-text for Windows/Updated error-msg when we can't find the jni lib/Better Error message when lib can't be loaded./Fixed library path configuration (issue #61)./
realm-java,Wrapped new JNI-level methods with high-level methods (issue #53)./
realm-java,Prepared and added new methods to table/view interface (issue #53)./
realm-java,Tracking latest error handling improvements in core library/
realm-java,Fixed create of Group(byte[]). Enabled all GroupTest tests and added new test./
realm-java,"Tracking latest error handling improvements in core library/Changes due to improved error handling in core library. Group no longer has an is_valid() method. From now on, Group instances are always valid./Fixes due to changed Group and SharedGroup constructors in core library/Fixed create of Group(byte[]). Enabled all GroupTest tests and added new test./"
realm-java,Change C++ header suffix from '.h' to '.hpp' since this selects the correct syntax highlighting mode in editors as well as in code browsers such as GitHub/
realm-java,"Merge remote-tracking branch 'Tightdb/move_last_over'
Conflicts:
tightdb-java-core/src/main/java/com/tightdb/typed/AbstractTable.java
Contains BUG FIX: GetBinaryData() could throw when empty BinaryData.
AFTER Merge:
- Contains new move_last_over method (currently disabled)
- Removed the graph example./Fixing memory leak in: Correct transcoding from UTF-16 to UTF-8/bugfix: wrong error in GetBinaryData() could occur when len=0/Change C++ header suffix from '.h' to '.hpp' since this selects the correct syntax highlighting mode in editors as well as in code browsers such as GitHub/"
realm-java,Change C++ header suffix from '.h' to '.hpp' since this selects the correct syntax highlighting mode in editors as well as in code browsers such as GitHub/String conversion in both directions is complete - except for an important FIXME in to_jstring() in 'util.h'/
realm-java,Change C++ header suffix from '.h' to '.hpp' since this selects the correct syntax highlighting mode in editors as well as in code browsers such as GitHub/String conversion in both directions is complete - except for an important FIXME in to_jstring() in 'util.h'/Fix due to core lib change: Group::get_table_count() -> Group::size()/
realm-java,Change C++ header suffix from '.h' to '.hpp' since this selects the correct syntax highlighting mode in editors as well as in code browsers such as GitHub/
realm-java,"Merge remote-tracking branch 'Tightdb/move_last_over'
Conflicts:
tightdb-java-core/src/main/java/com/tightdb/typed/AbstractTable.java
Contains BUG FIX: GetBinaryData() could throw when empty BinaryData.
AFTER Merge:
- Contains new move_last_over method (currently disabled)
- Removed the graph example./Fixes for: Merge branch 'master' into explicit_string_size/Change C++ header suffix from '.h' to '.hpp' since this selects the correct syntax highlighting mode in editors as well as in code browsers such as GitHub/String conversion in both directions is complete - except for an important FIXME in to_jstring() in 'util.h'/WIP: Updated with float, double support. Still a crash./"
realm-java,Change C++ header suffix from '.h' to '.hpp' since this selects the correct syntax highlighting mode in editors as well as in code browsers such as GitHub/
realm-java,"Change C++ header suffix from '.h' to '.hpp' since this selects the correct syntax highlighting mode in editors as well as in code browsers such as GitHub/WIP: Updated with float, double support. Still a crash./"
realm-java,Adjusted docs and examples to the refactoring (issue #69 and issue #72)./
realm-java,"Merge remote-tracking branch 'Tightdb/move_last_over'
Conflicts:
tightdb-java-core/src/main/java/com/tightdb/typed/AbstractTable.java
Contains BUG FIX: GetBinaryData() could throw when empty BinaryData.
AFTER Merge:
- Contains new move_last_over method (currently disabled)
- Removed the graph example./"
realm-java,Added testcases for Mixed float and double/
realm-java,"WIP: Updated with float, double support. Still a crash./"
realm-java,"Merge remote-tracking branch 'Tightdb/move_last_over'
Conflicts:
tightdb-java-core/src/main/java/com/tightdb/typed/AbstractTable.java
Contains BUG FIX: GetBinaryData() could throw when empty BinaryData.
AFTER Merge:
- Contains new move_last_over method (currently disabled)
- Removed the graph example./WIP: Updated with float, double support. Still a crash./"
realm-java,"Merge remote-tracking branch 'Tightdb/move_last_over'
Conflicts:
tightdb-java-core/src/main/java/com/tightdb/typed/AbstractTable.java
Contains BUG FIX: GetBinaryData() could throw when empty BinaryData.
AFTER Merge:
- Contains new move_last_over method (currently disabled)
- Removed the graph example./WIP: Updated with float, double support. Still a crash./"
realm-java,"Merge remote-tracking branch 'Tightdb/move_last_over'
Conflicts:
tightdb-java-core/src/main/java/com/tightdb/typed/AbstractTable.java
Contains BUG FIX: GetBinaryData() could throw when empty BinaryData.
AFTER Merge:
- Contains new move_last_over method (currently disabled)
- Removed the graph example./"
realm-java,Exception File::OpenError renamed to File::AccessError/
realm-java,"Merge pull request #91 from kneth/master
Use java.io.IOException/Use java.io.IOException./"
realm-java,Exception File::OpenError renamed to File::AccessError/
realm-java,DOS line endings eliminated. Pelase avoid reintroducing them./
realm-java,DOS line endings eliminated. Pelase avoid reintroducing them./
realm-java,"Now throws exception when calling a method on a closed Group()
Updated tutorial and showcase a bit./A 'config' step has been introduced into the build procedure.
The main reason is that it allows reliable uninstallation, but there are several other benefits too.
Also, support for running in debug mode has been improved./DOS line endings eliminated. Pelase avoid reintroducing them./Bugfix: mem-leak removed/"
realm-java,DOS line endings eliminated. Pelase avoid reintroducing them./
realm-java,DOS line endings eliminated. Pelase avoid reintroducing them./
realm-java,DOS line endings eliminated. Pelase avoid reintroducing them./
realm-java,"Fixes for: A 'config' step has been introduced into the build procedure./A 'config' step has been introduced into the build procedure.
The main reason is that it allows reliable uninstallation, but there are several other benefits too.
Also, support for running in debug mode has been improved./DOS line endings eliminated. Pelase avoid reintroducing them./"
realm-java,DOS line endings eliminated. Pelase avoid reintroducing them./
realm-java,DOS line endings eliminated. Pelase avoid reintroducing them./
realm-java,DOS line endings eliminated. Pelase avoid reintroducing them./
realm-java,"merge conflicts fixed/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java2 into Breaking-updates/Merge branch 'develop' of github.com:Tightdb/tightdb_java2 into Breaking-updates
Conflicts:
tightdb-java-test/src/test/java/com/tightdb/JNICloseTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIQueryTest.java
tightdb-java-test/src/test/java/com/tightdb/JNISubtableTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITableInsertTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITransactions.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSearchTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSortTest.java
tightdb-java-test/src/test/java/com/tightdb/experiment/SetIndexTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/GroupTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/TableTest.java
tightdb_jni/src/com_tightdb_Group.cpp
tightdb_jni/src/com_tightdb_table.cpp/Merge pull request #124 from Tightdb/develop-exceptions
Exceptions handling added/Exception handling added for SharedGroup (untested)/"
realm-java,"merge conflicts fixed/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java2 into Breaking-updates/Merge branch 'develop' of github.com:Tightdb/tightdb_java2 into Breaking-updates
Conflicts:
tightdb-java-test/src/test/java/com/tightdb/JNICloseTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIQueryTest.java
tightdb-java-test/src/test/java/com/tightdb/JNISubtableTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITableInsertTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITransactions.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSearchTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSortTest.java
tightdb-java-test/src/test/java/com/tightdb/experiment/SetIndexTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/GroupTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/TableTest.java
tightdb_jni/src/com_tightdb_Group.cpp
tightdb_jni/src/com_tightdb_table.cpp/Merge branch 'develop' of github.com:Tightdb/tightdb_java2 into Breaking-updates
Conflicts:
tightdb-java-test/src/test/java/com/tightdb/JNICloseTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIQueryTest.java
tightdb-java-test/src/test/java/com/tightdb/JNISubtableTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITableInsertTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITransactions.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSearchTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSortTest.java
tightdb-java-test/src/test/java/com/tightdb/experiment/SetIndexTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/GroupTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/TableTest.java
tightdb_jni/src/com_tightdb_Group.cpp
tightdb_jni/src/com_tightdb_table.cpp/Merge pull request #135 from Tightdb/dev-equals
Added com.tightdb.Table.equals() and fixed com.tightdb.Group.equals(/Merge pull request #131 from hovoere/file_exceptions
File exceptions/Updated group exceptions to be RuntimeExceptions/Merge pull request #124 from Tightdb/develop-exceptions
Exceptions handling added/Fixed SubTableDefinition to check for wrong columnIndex and exceptions. And some refactoring.
Changed OutOfMemory Exception til com.tightdb.OutOfMemory/Added test cases for all Exceptions that native interface can throw./Added exception handling for Group (untested)/Merge branch 'develop' into Breaking-updates/Added parameter checks to all Table methods. (lacking testcases!)
Changed Exception for invalid Table form IllegalArgumentException to InvalidStateException./"
realm-java,"merge conflicts fixed/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java2 into Breaking-updates/Merge branch 'develop' of github.com:Tightdb/tightdb_java2 into Breaking-updates
Conflicts:
tightdb-java-test/src/test/java/com/tightdb/JNICloseTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIQueryTest.java
tightdb-java-test/src/test/java/com/tightdb/JNISubtableTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITableInsertTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITransactions.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSearchTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSortTest.java
tightdb-java-test/src/test/java/com/tightdb/experiment/SetIndexTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/GroupTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/TableTest.java
tightdb_jni/src/com_tightdb_Group.cpp
tightdb_jni/src/com_tightdb_table.cpp/Merge pull request #124 from Tightdb/develop-exceptions
Exceptions handling added/Exception handling for Table (not tested)/"
realm-java,"merge conflicts fixed/Merge remote-tracking branch 'Tightdb/Breaking-updates' into Breaking-updates
Conflicts:
.JNI-h-file-generation.launch/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java into breaking-updates
Conflicts:
doc/ref/data/group_ref.yaml/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java2 into Breaking-updates/Merge branch 'develop' of github.com:Tightdb/tightdb_java2 into Breaking-updates
Conflicts:
tightdb-java-test/src/test/java/com/tightdb/JNICloseTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIQueryTest.java
tightdb-java-test/src/test/java/com/tightdb/JNISubtableTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITableInsertTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITransactions.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSearchTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSortTest.java
tightdb-java-test/src/test/java/com/tightdb/experiment/SetIndexTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/GroupTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/TableTest.java
tightdb_jni/src/com_tightdb_Group.cpp
tightdb_jni/src/com_tightdb_table.cpp/Merge pull request #135 from Tightdb/dev-equals
Added com.tightdb.Table.equals() and fixed com.tightdb.Group.equals(/Fixed bug in Group.equals(). Added Table.equals and tests./Merge pull request #124 from Tightdb/develop-exceptions
Exceptions handling added/Fixed merge bug./Added exception handling for Group (untested)/Merge branch 'develop' into Breaking-updates/Fixed leak in group.writeToFile. The string for the filename was leaked./! BREAKING CHANGE: Group() now takes a new OpenMode parameter and not a boolean.
It now supports multiple ways to open a group. (ReadOnly, ReadWrite, WriteNoCreate)
+ Added Group.Commit()/"
realm-java,"merge conflicts fixed/Merge remote-tracking branch 'Tightdb/Breaking-updates' into Breaking-updates
Conflicts:
pom.xml/Fixed merge conflicts/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java into breaking-updates/Merge pull request #154 from Tightdb/breaking2
Breaking2 in Breaking-updates/Merge branch 'breaking2' of github.com:Tightdb/tightdb_java into breaking2/"
realm-java,"merge conflicts fixed/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java into breaking-updates
Conflicts:
doc/ref/data/group_ref.yaml/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java2 into Breaking-updates/Merge pull request #106 from mekjaer/master
Merging changes from develop into Breaking-updates + ref doc setup. Many changes, please review/Example Util changed to ExampleHelper to avoid conflict with internal.Util/"
realm-java,"Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java into breaking-updates
Conflicts:
doc/ref/data/group_ref.yaml/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java2 into Breaking-updates/Merge pull request #106 from mekjaer/master
Merging changes from develop into Breaking-updates + ref doc setup. Many changes, please review/Example Util changed to ExampleHelper to avoid conflict with internal.Util/"
realm-java,"Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java into breaking-updates
Conflicts:
doc/ref/data/group_ref.yaml/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java2 into Breaking-updates/Merge pull request #106 from mekjaer/master
Merging changes from develop into Breaking-updates + ref doc setup. Many changes, please review/Example Util changed to ExampleHelper to avoid conflict with internal.Util/"
realm-java,"Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java into breaking-updates
Conflicts:
doc/ref/data/group_ref.yaml/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java2 into Breaking-updates/Merge remote-tracking branch 'Tightdb/Breaking-updates' into Breaking-updates
Conflicts:
doc/changes.txt/Merge pull request #106 from mekjaer/master
Merging changes from develop into Breaking-updates + ref doc setup. Many changes, please review/minor fixes./"
realm-java,"renamed exception/add exception. Throw it when wrong type is acessed from Mixed type/merge conflicts fixed/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java into breaking-updates
Conflicts:
doc/ref/data/group_ref.yaml/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java2 into Breaking-updates/Merge branch 'develop' of github.com:Tightdb/tightdb_java2 into Breaking-updates
Conflicts:
tightdb-java-test/src/test/java/com/tightdb/JNICloseTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIQueryTest.java
tightdb-java-test/src/test/java/com/tightdb/JNISubtableTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITableInsertTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITransactions.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSearchTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSortTest.java
tightdb-java-test/src/test/java/com/tightdb/experiment/SetIndexTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/GroupTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/TableTest.java
tightdb_jni/src/com_tightdb_Group.cpp
tightdb_jni/src/com_tightdb_table.cpp/Merge pull request #130 from Tightdb/dev-fixleak
Fixed leak in Query/Query could leak./Table.close() now private (added private_debug_close() instead.
Added better support for detecting valid View and Query after close of table.  Still not completely tested, also missing core-support./"
realm-java,"merge conflicts fixed/Merge remote-tracking branch 'Tightdb/Breaking-updates' into Breaking-updates
Conflicts:
pom.xml/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java into breaking-updates
Conflicts:
doc/ref/data/group_ref.yaml/Merge pull request #148 from mekjaer/ref-doc-breaking
Ref doc breaking + group.isEmpty() added/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java2 into Breaking-updates/Merge branch 'develop' of github.com:Tightdb/tightdb_java2 into Breaking-updates
Conflicts:
tightdb-java-test/src/test/java/com/tightdb/JNICloseTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIQueryTest.java
tightdb-java-test/src/test/java/com/tightdb/JNISubtableTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITableInsertTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITransactions.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSearchTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSortTest.java
tightdb-java-test/src/test/java/com/tightdb/experiment/SetIndexTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/GroupTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/TableTest.java
tightdb_jni/src/com_tightdb_Group.cpp
tightdb_jni/src/com_tightdb_table.cpp/Merge branch 'develop' of github.com:Tightdb/tightdb_java2 into Breaking-updates
Conflicts:
tightdb-java-test/src/test/java/com/tightdb/JNICloseTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIQueryTest.java
tightdb-java-test/src/test/java/com/tightdb/JNISubtableTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITableInsertTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITransactions.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSearchTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSortTest.java
tightdb-java-test/src/test/java/com/tightdb/experiment/SetIndexTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/GroupTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/TableTest.java
tightdb_jni/src/com_tightdb_Group.cpp
tightdb_jni/src/com_tightdb_table.cpp/Merge pull request #135 from Tightdb/dev-equals
Added com.tightdb.Table.equals() and fixed com.tightdb.Group.equals(/fix Group.equals()/Fixed bug in Group.equals(). Added Table.equals and tests./! BREAKING CHANGE: Group() now takes a new OpenMode parameter and not a boolean.
It now supports multiple ways to open a group. (ReadOnly, ReadWrite, WriteNoCreate)
+ Added Group.Commit()/Added exception for getTable(null) and getTable("""").
Updated an example to use new addColumn() methods./"
realm-java,"merge conflicts fixed/Merge remote-tracking branch 'Tightdb/Breaking-updates' into Breaking-updates
Conflicts:
.JNI-h-file-generation.launch/Merge remote-tracking branch 'Tightdb/Breaking-updates' into Breaking-updates
Conflicts:
pom.xml/merged breaking-updates and resolved conflicts/merge conflict fixed/Merge pull request #159 from hovoere/query_fixes
Updated query examples and added exception to subtable.. Also updated some aggregates in the examples/Fixed merge conflicts/Updated query examples and added exception to subtable/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java into breaking-updates/Merge pull request #154 from Tightdb/breaking2
Breaking2 in Breaking-updates/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java into breaking-updates
Conflicts:
doc/ref/data/group_ref.yaml/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java2 into Breaking-updates/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java2 into Breaking-updates
Conflicts:
.gitignore
tightdb-java-test/src/test/java/com/tightdb/JNITableTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/TableTest.java/Merge branch 'develop' of github.com:Tightdb/tightdb_java2 into Breaking-updates
Conflicts:
tightdb-java-test/src/test/java/com/tightdb/JNICloseTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIQueryTest.java
tightdb-java-test/src/test/java/com/tightdb/JNISubtableTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITableInsertTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITransactions.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSearchTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSortTest.java
tightdb-java-test/src/test/java/com/tightdb/experiment/SetIndexTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/GroupTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/TableTest.java
tightdb_jni/src/com_tightdb_Group.cpp
tightdb_jni/src/com_tightdb_table.cpp/Merge pull request #130 from Tightdb/dev-fixleak
Fixed leak in Query/Query could leak./Merge pull request #113 from mekjaer/mekjaer-dev
Merging changes from develop into Breaking-updates + Showcase example now uses built-in toString()/Merge pull request #106 from mekjaer/master
Merging changes from develop into Breaking-updates + ref doc setup. Many changes, please review/"
realm-java,"merge conflicts fixed/Merge pull request #186 from mekjaer/master_new
lookup reimplemented and fixed test cases for column type/lookup reimplemented and fixed test cases for column type/Added where() to TableOrView interface and updated testcase/Merge remote-tracking branch 'Tightdb/Breaking-updates' into Breaking-updates
Conflicts:
.JNI-h-file-generation.launch/Merge remote-tracking branch 'Tightdb/Breaking-updates' into Breaking-updates
Conflicts:
pom.xml/Merge pull request #171 from mekjaer/Breaking-updates
Master merged into Breaking-updates + SharedGroup examples/Merge branch 'master' of github.com:Tightdb/tightdb_java into Breaking-updates
Conflicts:
tightdb-java-test/src/test/java/com/tightdb/JNISubtableTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewTest.java/Merge pull request #162 from hovoere/dev_into_breaking
Merged develop into Breaking/Merged develop into Breaking/Fixed merge conflicts/Fixed merge conflicts/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java into breaking-updates/Merge pull request #154 from Tightdb/breaking2
Breaking2 in Breaking-updates/Merge branch 'breaking2' of github.com:Tightdb/tightdb_java into breaking2/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java into breaking-updates
Conflicts:
doc/ref/data/group_ref.yaml/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java2 into Breaking-updates/Merge pull request #138 from mekjaer/Breaking-updates
Breaking updates - lookup outcommented in table and tableview + fixes in quick benchmark tests/Merge branch 'develop' of github.com:Tightdb/tightdb_java2 into Breaking-updates
Conflicts:
tightdb-java-test/src/test/java/com/tightdb/JNICloseTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIQueryTest.java
tightdb-java-test/src/test/java/com/tightdb/JNISubtableTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITableInsertTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITransactions.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSearchTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSortTest.java
tightdb-java-test/src/test/java/com/tightdb/experiment/SetIndexTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/GroupTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/TableTest.java
tightdb_jni/src/com_tightdb_Group.cpp
tightdb_jni/src/com_tightdb_table.cpp/Merge pull request #130 from Tightdb/dev-fixleak
Fixed leak in Query/Merge remote-tracking branch 'Tightdb/develop' into dev-fixleak/Query could leak./Merge pull request #117 from mekjaer/master
prevent crash when providing null as byte[] in typed and avoid NullPointerException in exception in dyn and sort in read trans/fixed the immutable on sorting/Merge pull request #113 from mekjaer/mekjaer-dev
Merging changes from develop into Breaking-updates + Showcase example now uses built-in toString()/Merge remote-tracking branch 'Tightdb/Breaking-updates' into Breaking-updates
Conflicts:
doc/changes.txt/Merge branch 'develop' into Breaking-updates
Conflicts:
tightdb-java-core/src/main/java/com/tightdb/Table.java
tightdb-java-test/src/test/java/com/tightdb/experiment/GroupToStringTest.java/Merge pull request #106 from mekjaer/master
Merging changes from develop into Breaking-updates + ref doc setup. Many changes, please review/Renaming to adjustColumnValues. Added exception thrown in JNI/Merge branch 'develop' into Breaking-updates/"
realm-java,"Lookup reenabled on typed table. Test case added, Check for null otherwise core crash/merge conflicts fixed/Merge pull request #186 from mekjaer/master_new
lookup reimplemented and fixed test cases for column type/lookup reimplemented and fixed test cases for column type/Added where() to TableOrView interface and updated testcase/Fixed testcase bug in date-test/debugging datebug - fixed one/Merge remote-tracking branch 'Tightdb/Breaking-updates' into Breaking-updates
Conflicts:
.JNI-h-file-generation.launch/Merge remote-tracking branch 'Tightdb/Breaking-updates' into Breaking-updates
Conflicts:
pom.xml/Merge pull request #162 from hovoere/dev_into_breaking
Merged develop into Breaking/Merged develop into Breaking/Fixed merge conflicts/Fixed merge conflicts/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java into breaking-updates/Merge pull request #154 from Tightdb/breaking2
Breaking2 in Breaking-updates/Merge branch 'breaking2' of github.com:Tightdb/tightdb_java into breaking2/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java into breaking-updates
Conflicts:
doc/ref/data/group_ref.yaml/merged develop into breaking/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java2 into Breaking-updates/Merge pull request #138 from mekjaer/Breaking-updates
Breaking updates - lookup outcommented in table and tableview + fixes in quick benchmark tests/Merge branch 'develop' of github.com:Tightdb/tightdb_java2 into Breaking-updates
Conflicts:
tightdb-java-test/src/test/java/com/tightdb/JNICloseTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIQueryTest.java
tightdb-java-test/src/test/java/com/tightdb/JNISubtableTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITableInsertTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITransactions.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSearchTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSortTest.java
tightdb-java-test/src/test/java/com/tightdb/experiment/SetIndexTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/GroupTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/TableTest.java
tightdb_jni/src/com_tightdb_Group.cpp
tightdb_jni/src/com_tightdb_table.cpp/Merge branch 'develop' of github.com:Tightdb/tightdb_java2 into Breaking-updates
Conflicts:
tightdb-java-test/src/test/java/com/tightdb/JNICloseTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIQueryTest.java
tightdb-java-test/src/test/java/com/tightdb/JNISubtableTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITableInsertTest.java
tightdb-java-test/src/test/java/com/tightdb/JNITransactions.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSearchTest.java
tightdb-java-test/src/test/java/com/tightdb/JNIViewSortTest.java
tightdb-java-test/src/test/java/com/tightdb/experiment/SetIndexTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/GroupTest.java
tightdb-java-test/src/test/java/com/tightdb/typed/TableTest.java
tightdb_jni/src/com_tightdb_Group.cpp
tightdb_jni/src/com_tightdb_table.cpp/Merge pull request #135 from Tightdb/dev-equals
Added com.tightdb.Table.equals() and fixed com.tightdb.Group.equals(/Fixed bug in Group.equals(). Added Table.equals and tests./Merge pull request #130 from Tightdb/dev-fixleak
Fixed leak in Query/Merge remote-tracking branch 'Tightdb/develop' into dev-fixleak/Query could leak./Merge branch 'develop' of github.com:Tightdb/tightdb_java2 into Breaking-updates
Conflicts:
.gitignore
doc/changes.txt
tightdb-java-test/src/test/java/com/tightdb/typed/TableTest.java/Merge remote-tracking branch 'Tightdb/develop' into develop-exceptions
Conflicts:
tightdb_jni/src/com_tightdb_table.cpp/Fixed type errors/Merge pull request #117 from mekjaer/master
prevent crash when providing null as byte[] in typed and avoid NullPointerException in exception in dyn and sort in read trans/fixed the immutable on sorting/line breaks/exception handling when insert null as byte[]. Dyn and typed/merge fixes/Merge pull request #113 from mekjaer/mekjaer-dev
Merging changes from develop into Breaking-updates + Showcase example now uses built-in toString()/line break/Table.close() now private (added private_debug_close() instead.
Added better support for detecting valid View and Query after close of table.  Still not completely tested, also missing core-support./Merge remote-tracking branch 'Tightdb/Breaking-updates' into Breaking-updates
Conflicts:
doc/changes.txt/Merge branch 'develop' into Breaking-updates
Conflicts:
tightdb-java-core/src/main/java/com/tightdb/Table.java
tightdb-java-test/src/test/java/com/tightdb/experiment/GroupToStringTest.java/Enabled and fixed testcases for column type tests./Renaming to adjustColumnValues. Added exception thrown in JNI/Merge branch 'develop' into Breaking-updates/"
realm-java,"Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java2 into Breaking-updates/Merge pull request #106 from mekjaer/master
Merging changes from develop into Breaking-updates + ref doc setup. Many changes, please review/Merge branch 'develop' into Breaking-updates/Merge branch 'develop' of github.com:Tightdb/tightdb_java2 into Breaking-updates/Fixed initialisation to be threadsafe.
Updated load of library file for Windows (must look into this again later - created Asana task)./"
realm-java,merge conflicts fixed/
realm-java,"merge conflicts fixed/Merge branch 'Breaking-updates' of github.com:Tightdb/tightdb_java2 into Breaking-updates/Merge pull request #106 from mekjaer/master
Merging changes from develop into Breaking-updates + ref doc setup. Many changes, please review/Merged develop into breaking updates and updated test case correspondingly/"
realm-java,"Merge pull request #250 from mekjaer/gc-issue
Gc issue. Implementation of Context in all tightdb objects/Merge pull request #215 from mekjaer/lock-sharedgroup
Checking for missing db, if lock file exist, and throws corresponding exception. Test case for that/BUG fixed: crash could occur when a Group was garbage collected and Tables was still in use./"
realm-java,Fixes due to some core header files having been moved into subdir /util//
realm-java,Fixes due to https://github.com/Tightdb/tightdb/pull/311/
realm-java,"Eliminate warnings relating to `MAX_JLONG`.
First warning was eliminated by add suffix `LL` to the constant. This is necessary becuase `long long` is the smallest and only type that ANSI guarantees is 64 bits.
Likewise, `MAX_JINT` must have an `L` suffix, because `long` is the smallest type that ANSI guarantees is 32 bits.
The second and last warning was removed by using `util::int_less_than_or_equal()` (a utility function created precisely for this purpose)./Merge pull request #250 from mekjaer/gc-issue
Gc issue. Implementation of Context in all tightdb objects/"
realm-java,"Merge pull request #250 from mekjaer/gc-issue
Gc issue. Implementation of Context in all tightdb objects/more lines breaks/subtable sort test case added + try fail added more places/Merge pull request #214 from mekjaer/doc-fixes
Doc fixes/Merge pull request #207 from mekjaer/mixed-runtime-exc
add exception. Throw it when wrong type is acessed from Mixed type/"
realm-java,"Merge pull request #250 from mekjaer/gc-issue
Gc issue. Implementation of Context in all tightdb objects/Merge pull request #257 from mekjaer/group-readonly-bug
check for read-only group mode added in constrcutor + test case/"
realm-java,"Error message in constant/moved check to java and changed to illegalArgument exception/Merge pull request #259 from mekjaer/gc-issue
indent issue/indent issue/Merge pull request #250 from mekjaer/gc-issue
Gc issue. Implementation of Context in all tightdb objects/Merge branch 'master' of github.com:Tightdb/tightdb_java into group-readonly-bug/"
realm-java,"Changed NullPointerException to IllegalArgumentException when it's an argument that's wrong./Merge pull request #250 from mekjaer/gc-issue
Gc issue. Implementation of Context in all tightdb objects/Merge branch 'master' of github.com:Tightdb/tightdb_java into group-readonly-bug/debug added. Removed class reference in jni TR output, just the pointer now/"
realm-java,"Changed NullPointerException to IllegalArgumentException when it's an argument that's wrong./Merge pull request #250 from mekjaer/gc-issue
Gc issue. Implementation of Context in all tightdb objects/Merge branch 'master' of github.com:Tightdb/tightdb_java into group-readonly-bug/debug added. Removed class reference in jni TR output, just the pointer now/cleanup + tighter testcase/fixed constructor issue in test case/fixed merge conflicts/Merge pull request #245 from mekjaer/set-string-null
throw exception when setting null on string + test cases/throw exception when setting null on string + test cases/enabled test for table.lookup. Throws more specific exceptions. Non-breaking as they are subclasses of RuntimeException/BUG fixed: crash could occur when a Group was garbage collected and Tables was still in use./fixed merge-conflicts/"
realm-java,"Merge pull request #250 from mekjaer/gc-issue
Gc issue. Implementation of Context in all tightdb objects/debug added. Removed class reference in jni TR output, just the pointer now/cleanup + tighter testcase/Merge pull request #243 from mekjaer/read-trans-testcase
check for if group is closed when closing transactions + test case/removed line break/check for if group is closed when closing transactions + test case
Will crash core if not detected/"
realm-java,Doc fixes and spelling/
realm-java,"Supports new Version API (so far undocumented).
Changed tableview->is_valid() to is_attached()
Updated *.h files - they must be autogenerated and not fixed by hand./"
realm-java,"Merge branch 'master' into WIP-update-checker
* master: (25 commits)
Add migration example template to distribution folder
Removed old files.
Fix distribution script
Removed Guava dependency
Add migration example to the distribution folder
Added some comments
Add License headers
animal capitalization
finish migration code/add versioned realm file
migration bug fix
Cache column indices
disable realm file with missing version
migration bug fix
bug fixes
Some fixes
Introduce the RealmMigrationNeededException
Disable the table check until we have a better solution
migration example
Check link and link list tables
Verify the name of the table of link and link list targets
...
Conflicts:
realm-annotations-processor/src/main/java/io/realm/processor/RealmProcessor.java/Modified code generation to use static column indices. Since the Java VM keeps the fields in a different order than the java compiler, I had to introduce proxy based table generation. removed setter/getter method for row no RealmObject. row is now accessed directly. Proxy class suffix has been changed to '_PROXY* has been changed to RealmProxy./performance test runs without fail./"
realm-java,"Style fixes./Merge branch 'master' into cm-file-permission-error
Conflicts:
changelog.txt
realm/src/androidTest/java/io/realm/RealmTest.java/Merge pull request #793 from realm/cm-doc-gettersetters
Missing accessors no longer crash annotation compiler/Missing accessors no longer results in NullPointerException./Fix merge mistake + style fixes./Merge branch 'master' of github.com:realm/realm-java into kg-utf-more-debug/Merge branch 'master' into cm-bug-close
Conflicts:
changelog.txt/Updated JavaDoc and error messages./Cleanup + fixed merge mistake./Added unit tests and fixes bug found on the way/"
realm-java,fixed conflicts from merging with master/Merge remote-tracking branch 'origin/master' into ez-fail-write/
realm-java,fixed conflicts from merging with master/Merge remote-tracking branch 'origin/master' into ez-fail-write/
realm-java,fixed conflicts from merging with master/Merge remote-tracking branch 'origin/master' into ez-fail-write/
realm-java,fixed conflicts from merging with master/Merge remote-tracking branch 'origin/master' into ez-fail-write/
realm-java,fixed some conflicts/Fixed wrong usage of ViewHolder pattern. Fixed bad practise when inflating views./
realm-java,"Merge pull request #746 from realm/kg-utf-more-debug
More debug info when converting a string from to Java fails./Printing location of error/Merge branch 'master' of github.com:realm/realm-java into kg-utf-more-debug/Merge branch 'master' into cm-bug-close
Conflicts:
changelog.txt/Merge pull request #748 from realm/tg-exception-bloat
Cut down on the size of the library a bit/Move C++ -> Java exception mapping to a function/More debug info when converting a string from to Java fails./Doc fixes for: Lenient UTF-8 -> UTF-16 transcoding (insert replacement characters)/Fix for: Lenient UTF-8 -> UTF-16 transcoding (insert replacement characters)/Fix for: Lenient UTF-8 -> UTF-16 transcoding (insert replacement characters)/Fix for: Lenient UTF-8 -> UTF-16 transcoding (insert replacement characters)/Fix for: Lenient UTF-8 -> UTF-16 transcoding (insert replacement characters)/Fix for: Lenient UTF-8 -> UTF-16 transcoding (insert replacement characters)/Merge branch 'master' of github.com:realm/realm-java into kg-bugfix-sort
Conflicts:
changelog.txt/Merge branch 'master' into bp-case
* master: (62 commits)
Close realms in tests
Disable UTF8 test which is slow...
Remove rowIndex from RealmObject.toString()
Stylistic updates
Improve javadocs for Realm constructors
Delete design document.
Cleanup unit tests.
Update RealmTest.java
Add unit test exposing more solid reference counter
Make the reference counter depend on the realm path
Cleanup examples.
Cleaned up unit tests and iterators.
Fixed unit test so it now properly closes it's resources.
Update Realm.java
Removed unnecessary object.
Added copyright
Added Realm.close(). Cleanup unit tests.
Catching standard exceptions.
Fixed unit test.
Fix minor issues
...
Conflicts:
realm/src/androidTest/java/io/realm/RealmTest.java/Catching standard exceptions./Adding better error messages when converting to Java string/Merge pull request #568 from realm/kg-bugfix-nonlatin-chars
Use to_jstring() everywhere at the JNI layer/"
realm-java,"Merge pull request #783 from realm/cm-file-permission-error
Better error reporting opening Realms/Error handling now uses exception thrown from core where it makes sense./fixed conflicts from merging with master/fixed some conflicts/Merge pull request #568 from realm/kg-bugfix-nonlatin-chars
Use to_jstring() everywhere at the JNI layer/"
realm-java,"fixed conflicts from merging with master/fixed some conflicts/Merge pull request #568 from realm/kg-bugfix-nonlatin-chars
Use to_jstring() everywhere at the JNI layer/"
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg-utf-more-debug/Merge branch 'master' into cm-bug-close
Conflicts:
changelog.txt/Merge pull request #748 from realm/tg-exception-bloat
Cut down on the size of the library a bit/Merge branch 'master' into kg-bugfix-sort
Conflicts:
changelog.txt
realm/src/androidTest/java/io/realm/RealmResultsTest.java/Fixed bug in equalTo() for date.
Updated testcases/"
realm-java,"Merge branch 'master' into cm-file-permission-error
Conflicts:
changelog.txt/Grammar and small fixes./Grammar fixes./Grammar fixes./Merge branch 'master' into cm-bug-sort-breaks-query-chaining
Conflicts:
changelog.txt/Adding an error message./Throw NoSuchMethodError when RealmResults.indexOf() is called as the
method is not implemented./Merge pull request #712 from realm/cm-bug-sort-childobject
Improve error message for sorting by child object/Refactored sort so using a null fieldname always throw an exception./Improved error message for child object sorting./Merge pull request #634 from realm/kg-bugfix-sort
Changing sort()/In sort() throw exception if field name does not exist./Merge branch 'master' into bp-case
* master: (62 commits)
Close realms in tests
Disable UTF8 test which is slow...
Remove rowIndex from RealmObject.toString()
Stylistic updates
Improve javadocs for Realm constructors
Delete design document.
Cleanup unit tests.
Update RealmTest.java
Add unit test exposing more solid reference counter
Make the reference counter depend on the realm path
Cleanup examples.
Cleaned up unit tests and iterators.
Fixed unit test so it now properly closes it's resources.
Update Realm.java
Removed unnecessary object.
Added copyright
Added Realm.close(). Cleanup unit tests.
Catching standard exceptions.
Fixed unit test.
Fix minor issues
...
Conflicts:
realm/src/androidTest/java/io/realm/RealmTest.java/Merge branch 'master' into cm-utf8-test
* master: (34 commits)
Update RealmTest.java
Add unit test exposing more solid reference counter
Make the reference counter depend on the realm path
Cleaned up unit tests and iterators.
Fixed unit test so it now properly closes it's resources.
Added copyright
Added Realm.close(). Cleanup unit tests.
Fixed unit test.
Fix minor issues
Added Realm.close() to all examples. Streamlined activity and app names.
Revert ""Update SimpleRealmProxy.java""
Update SimpleRealmProxy.java
Update changelog.txt
Fix annotation processor test
Updated changelog.
Modify the unit tests to comply to Realm.close()
Fixed merge mistake.
Align ListIterator with standard Java behaviour.
Fix RealmTest for Realm.close()
Added support for remove in RealmResults iterators. Additional unit tests for their usage.
...
Conflicts:
realm/src/androidTest/java/io/realm/RealmTest.java/Merge pull request #617 from realm/ez-file-size
Mitigate the file size growing problem/Mitigate the file size growing problem
This change does the following:
* disables the caching of Realm instances in threads without an event loop
* makes the Realm class implement Closable
* does reference counting for closing Realm instances
* checks if the Realm instance has not been closed before any operation/Fixed spelling mistake + missing constructor exception./Fixed exceptions being thrown on next/previous iterator methods./Merge pull request #555 from realm/kg-bugfix-maxdate
maxDate was not correct./"
realm-java,"Merge branch 'master' into cm-bug-asyncloaders
Conflicts:
changelog.txt/Fixed issue with Realm cache not being cleared during a RealmMigrationNeededException + Added unit test./Merge remote-tracking branch 'origin/master' into ez-fail-write/Merge pull request #653 from realm/cm-rotation-crash
Handlers for closed Realms are now properly removed/spelling fixed/Merge branch 'master' of github.com:realm/realm-java into kg-bugfix-sort
Conflicts:
changelog.txt/"
realm-java,"Merge branch 'master' into bp-case
* master: (62 commits)
Close realms in tests
Disable UTF8 test which is slow...
Remove rowIndex from RealmObject.toString()
Stylistic updates
Improve javadocs for Realm constructors
Delete design document.
Cleanup unit tests.
Update RealmTest.java
Add unit test exposing more solid reference counter
Make the reference counter depend on the realm path
Cleanup examples.
Cleaned up unit tests and iterators.
Fixed unit test so it now properly closes it's resources.
Update Realm.java
Removed unnecessary object.
Added copyright
Added Realm.close(). Cleanup unit tests.
Catching standard exceptions.
Fixed unit test.
Fix minor issues
...
Conflicts:
realm/src/androidTest/java/io/realm/RealmTest.java/Merge branch 'master' into cm-utf8-test
* master: (34 commits)
Update RealmTest.java
Add unit test exposing more solid reference counter
Make the reference counter depend on the realm path
Cleaned up unit tests and iterators.
Fixed unit test so it now properly closes it's resources.
Added copyright
Added Realm.close(). Cleanup unit tests.
Fixed unit test.
Fix minor issues
Added Realm.close() to all examples. Streamlined activity and app names.
Revert ""Update SimpleRealmProxy.java""
Update SimpleRealmProxy.java
Update changelog.txt
Fix annotation processor test
Updated changelog.
Modify the unit tests to comply to Realm.close()
Fixed merge mistake.
Align ListIterator with standard Java behaviour.
Fix RealmTest for Realm.close()
Added support for remove in RealmResults iterators. Additional unit tests for their usage.
...
Conflicts:
realm/src/androidTest/java/io/realm/RealmTest.java/Merge branch 'master' of github.com:realm/realm-java into kg-bugfix-removefromrealm
Conflicts:
changelog.txt/Merge pull request #599 from realm/kg-bugfix-incorrect-cast
Subquerying RealmResults/Querying RealmResults with where() returns a query object but resolving
field name to column index throwed an exception since it didn't cast correctly./"
realm-java,"Style fixes./Fix merge mistake + style fixes./Merge branch 'master' of github.com:realm/realm-java into kg-utf-more-debug/Merge branch 'master' into cm-bug-close
Conflicts:
changelog.txt/fixed conflicts from merging with master/Merge pull request #642 from realm/ez-fail-write
Add a unit test about editing a RealmObject outside of a transaction/It is no longer possible to manually set 0 or """" in primary key fields. Refactored error checking so it is more maintainable./"
realm-java,"Fix broken unit tests./Style fixes./Fix merge mistake + style fixes./fixed conflicts from merging with master/Merge pull request #642 from realm/ez-fail-write
Add a unit test about editing a RealmObject outside of a transaction/Merge branch 'master' of github.com:realm/realm-java into kg-bugfix-sort
Conflicts:
changelog.txt/Merge branch 'master' into bp-case
* master: (62 commits)
Close realms in tests
Disable UTF8 test which is slow...
Remove rowIndex from RealmObject.toString()
Stylistic updates
Improve javadocs for Realm constructors
Delete design document.
Cleanup unit tests.
Update RealmTest.java
Add unit test exposing more solid reference counter
Make the reference counter depend on the realm path
Cleanup examples.
Cleaned up unit tests and iterators.
Fixed unit test so it now properly closes it's resources.
Update Realm.java
Removed unnecessary object.
Added copyright
Added Realm.close(). Cleanup unit tests.
Catching standard exceptions.
Fixed unit test.
Fix minor issues
...
Conflicts:
realm/src/androidTest/java/io/realm/RealmTest.java/Merge branch 'master' into cm-utf8-test
* master: (34 commits)
Update RealmTest.java
Add unit test exposing more solid reference counter
Make the reference counter depend on the realm path
Cleaned up unit tests and iterators.
Fixed unit test so it now properly closes it's resources.
Added copyright
Added Realm.close(). Cleanup unit tests.
Fixed unit test.
Fix minor issues
Added Realm.close() to all examples. Streamlined activity and app names.
Revert ""Update SimpleRealmProxy.java""
Update SimpleRealmProxy.java
Update changelog.txt
Fix annotation processor test
Updated changelog.
Modify the unit tests to comply to Realm.close()
Fixed merge mistake.
Align ListIterator with standard Java behaviour.
Fix RealmTest for Realm.close()
Added support for remove in RealmResults iterators. Additional unit tests for their usage.
...
Conflicts:
realm/src/androidTest/java/io/realm/RealmTest.java/Merge pull request #598 from realm/kg-bugfix-removefromrealm
Extending removeFromRealm() to be able to remove last object/Merge branch 'master' of github.com:realm/realm-java into kg-bugfix-removefromrealm
Conflicts:
changelog.txt/Merge pull request #599 from realm/kg-bugfix-incorrect-cast
Subquerying RealmResults/fixed some conflicts/Fixed unit test./It is no longer possible to manually set 0 or """" in primary key fields. Refactored error checking so it is more maintainable./"
realm-java,"Merge pull request #783 from realm/cm-file-permission-error
Better error reporting opening Realms/Unit test style fixes. IOError now being thrown instead of OutOfMemory when opening Realms fail./Better error reporting for error cases when creating a Realm using the File constructors./fixed conflicts from merging with master/Merge remote-tracking branch 'origin/master' into ez-fail-write/Merge pull request #653 from realm/cm-rotation-crash
Handlers for closed Realms are now properly removed/Merge branch 'master' of github.com:realm/realm-java into kg-bugfix-sort
Conflicts:
changelog.txt/Merge branch 'master' into bp-case
* master: (62 commits)
Close realms in tests
Disable UTF8 test which is slow...
Remove rowIndex from RealmObject.toString()
Stylistic updates
Improve javadocs for Realm constructors
Delete design document.
Cleanup unit tests.
Update RealmTest.java
Add unit test exposing more solid reference counter
Make the reference counter depend on the realm path
Cleanup examples.
Cleaned up unit tests and iterators.
Fixed unit test so it now properly closes it's resources.
Update Realm.java
Removed unnecessary object.
Added copyright
Added Realm.close(). Cleanup unit tests.
Catching standard exceptions.
Fixed unit test.
Fix minor issues
...
Conflicts:
realm/src/androidTest/java/io/realm/RealmTest.java/Merge pull request #617 from realm/ez-file-size
Mitigate the file size growing problem/Mitigate the file size growing problem
This change does the following:
* disables the caching of Realm instances in threads without an event loop
* makes the Realm class implement Closable
* does reference counting for closing Realm instances
* checks if the Realm instance has not been closed before any operation/"
realm-java,"Fixed Date and byte[] being updated by mistake when updating from Json/Merge pull request #1022 from realm/cm-bug-createorupdatefromjson
Realm.copyOrUpdateFromJson shouldn't update unset properties/Merge pull request #890 from realm/cm-bug-json-long-null
Fix support for Json NULL values/Merge branch 'master' into cm-bug-json-long-null
Conflicts:
changelog.txt
realm-annotations-processor/src/test/resources/io/realm/AllTypesRealmProxy.java/Merge branch 'master' into cm-bug-realmlist-remove
Conflicts:
changelog.txt/Fixed issues with Null when using JSONObject./Fixed issue in annotation processor with field names called ""name""./"
realm-java,JavaDoc fixes./Document fixes and styling./More use of boolean flag as error more consistent. Cleanup/Added description to annotation processor + additional error check/Updated error message./
realm-java,"Merge branch 'master' into cm-bug-createorupdatefromjson
Conflicts:
changelog.txt/Merge branch 'master' into cm-bug-compactfile
Conflicts:
changelog.txt/Merge pull request #979 from realm/cm-better-table-error
Annotation processor now fails if a RealmObject contains no fields./Fixed unit test./"
realm-java,"Merge branch 'master' into cm-bug-createorupdatefromjson
Conflicts:
changelog.txt/Merge branch 'master' into cm-bug-compactfile
Conflicts:
changelog.txt/"
realm-java,"Merge branch 'master' into cm-bug-createorupdatefromjson
Conflicts:
changelog.txt/Merge branch 'master' of github.com:realm/realm-java into cm-bug-compactfile/Merge branch 'master' into cm-bug-compactfile
Conflicts:
changelog.txt/"
realm-java,"Merge branch 'master' into cm-bug-createorupdatefromjson
Conflicts:
changelog.txt/Merge branch 'master' into cm-bug-compactfile
Conflicts:
changelog.txt/"
realm-java,"Merge pull request #928 from ClaudiuBele/patch-1
Fixed RealmResults javadoc issues/Fixed javadoc issues
@link tags have been corrected in RealmResults.java/"
realm-java,"Merge branch 'master' into cm-bug-createorupdatefromjson
Conflicts:
changelog.txt/Merge branch 'master' into cm-bug-compactfile
Conflicts:
changelog.txt/"
realm-java,"Merge branch 'master' into cm-bug-createorupdatefromjson
Conflicts:
changelog.txt/Merge branch 'master' into cm-bug-compactfile
Conflicts:
changelog.txt/Merge pull request #948 from realm/cm-bug-wrong-errormsg
Improved error message for unknown tables/Improved error message when trying to access unknown tables outside a transaction./"
realm-java,"Merge branch 'master' into cm-bug-createorupdatefromjson
Conflicts:
changelog.txt/Merge branch 'master' of github.com:realm/realm-java into cm-bug-compactfile/fixed minor spacing style/"
realm-java,"Merge branch 'master' into cm-bug-createorupdatefromjson
Conflicts:
changelog.txt/Merge branch 'master' into cm-bug-compactfile
Conflicts:
changelog.txt/"
realm-java,"Merge branch 'master' into cm-bug-createorupdatefromjson
Conflicts:
changelog.txt/Merge branch 'master' into cm-bug-compactfile
Conflicts:
changelog.txt/Merge branch 'master' into cm-bug-migration
Conflicts:
changelog.txt/Merge pull request #995 from realm/cm-bug-copytorealm-primarykey
Fixed bug in Realm.copyToRealm() with primary key values/Minor style fix for better readability./fixed comment/Fixed bug where copyToRealm() crashed when copying objects with primary key data./"
realm-java,"Merge branch 'master' into cm-bug-null-primarykey
Conflicts:
changelog.txt/Merge pull request #1065 from realm/cm-realmpath
RealmMigrationNeededException can now return the path to the Realm/Adds RealmPath to RealmMigrationNeedException/Merge branch 'master' into cm-bug-createorupdatefromjson
Conflicts:
changelog.txt/Merge pull request #955 from realm/cm-bug-compactfile
Made Realm.compactRealmFile() more failure resilient./Compacting encrypted Realms fail on some devices, and it is disabled temporarily./Merge branch 'master' into cm-bug-compactfile
Conflicts:
changelog.txt/"
realm-java,"Handle null value for String in Json when updating
Fix #1344
Update the object's String field to empty string when the corresponding
field in Json is null./Merge pull request #1116 from realm/kg-bug-migrate-linkview
Tighter check when validating tables with links/Better error messages/Merge branch 'master' into cm-bug-clear/Merge branch 'master' of github.com:realm/realm-java into kg-bug-migrate-linkview/"
realm-java,"Merge pull request #1116 from realm/kg-bug-migrate-linkview
Tighter check when validating tables with links/Better error messages/Merge branch 'master' into cm-bug-clear/Merge branch 'master' of github.com:realm/realm-java into kg-bug-migrate-linkview/"
realm-java,"Handle null value for String in Json when updating
Fix #1344
Update the object's String field to empty string when the corresponding
field in Json is null./Merge pull request #1096 from realm/cm-bug-updatejson-date
Fix Date and byte[] being reset when using createOrUpdateFromJson/"
realm-java,"Avoid wildcard imports and execute in the background/Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/Support search indexing for column int, bool, date
1. Enable the search index annotation on byte, short, int, long,
boolean, and Date.
2. Enable add/remove search index in java.
3. Annotation processor test to support better detailed test cases.
4. Modify JNI test cases.
5. Update doc.
6. Add AnnotationIndexTypes to avoid polluting other test cases.
This is the first PR for #1039. Implicit index to int primary keys will
be handled in another PR./Merge branch 'master' into cm-bug-attached-check
Conflicts:
changelog.txt/Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/Merge pull request #1192 from realm/kg-bug-missing-generic-type
Checking for missing generic type during annotation processing/Merge branch 'master' into cm-bug-clear/Merge branch 'master' of github.com:realm/realm-java into kg-bug-migrate-linkview/"
realm-java,"Merge pull request #1341 from realm/ez-allow-disable-analytics
Ignore errors in analytics BG thread and allow disabling it/Ignore errors in analytics BG thread and allow disabling it/Avoid wildcard imports and execute in the background/Merge branch 'master' into cm-bug-clear/Merge branch 'master' of github.com:realm/realm-java into kg-bug-migrate-linkview/"
realm-java,Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/Merge branch 'master' of github.com:realm/realm-java into kg-bug-findfirst-null-values/minor tweaks to the concurrency example (fix possible Liveness issue)/
realm-java,Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/Merge branch 'master' of github.com:realm/realm-java into kg-bug-findfirst-null-values/minor tweaks to the concurrency example (fix possible Liveness issue)/
realm-java,Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/Merge branch 'master' of github.com:realm/realm-java into kg-bug-findfirst-null-values/minor tweaks to the concurrency example (fix possible Liveness issue)/
realm-java,Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/
realm-java,Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/
realm-java,Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/
realm-java,"Merge pull request #1180 from realm/kg-bug-throw-error
Introducing RealmError/using  std::unique_ptr for handover + remove unnecessary begin_read in a spearate JNI call + latest fixes from 'fsa_handover_demo' (untyped query etc.)/Unspecified exception (std::exception) should be a RealmError/Support 'UnreachableVersionException' from Core/Realm will now throw a RealmError when Realm Core enters an unrecoverable error condition./"
realm-java,"using std::unique_ptr for handover + remove unnecessary begin_read in a spearate JNI call + latest fixes from 'fsa_handover_demo' (untyped query etc.)/Changing logic to handover the query from caller to background thread, handle different failure points (begin_read, import_handover), update UnitTests/Support 'UnreachableVersionException' from Core/"
realm-java,"Documenting that RealmResults.{first,last} throw exception if result is empty./Merge pull request #1154 from realm/ez-findbugs-hunt
Add support for Findbugs and fix the issues found/Add support for Findbugs and fix the issues found/"
realm-java,"Merge pull request #1180 from realm/kg-bug-throw-error
Introducing RealmError/Unspecified exception (std::exception) should be a RealmError/Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/Merge branch 'master' of github.com:realm/realm-java into kg-bug-findfirst-null-values/Merge pull request #1182 from realm/nh-1169-unchecked_cast
Fixes #1169 unchecked cast/Merge pull request #1154 from realm/ez-findbugs-hunt
Add support for Findbugs and fix the issues found/Add support for Findbugs and fix the issues found/Improved error message for objects not part of the schema./"
realm-java,"Merge pull request #1154 from realm/ez-findbugs-hunt
Add support for Findbugs and fix the issues found/Add support for Findbugs and fix the issues found/"
realm-java,"Merge pull request #1164 from realm/kg-bug-multiple-queries
Querying RealmResults can crash/Prevent GC release TableView and Query
Parsed native backtrace can be found at
https://github.com/realm/realm-java-private/wiki/CrashLog1164 .
1. Add references to TableView and TableQuery in order to
prevent premature garbage collection.
2. Add test helper function to trigger GC.
3. Add relevant test case./Changing logic to handover the query from caller to background thread, handle different failure points (begin_read, import_handover), update UnitTests/"
realm-java,"Merge pull request #1164 from realm/kg-bug-multiple-queries
Querying RealmResults can crash/Prevent GC release TableView and Query
Parsed native backtrace can be found at
https://github.com/realm/realm-java-private/wiki/CrashLog1164 .
1. Add references to TableView and TableQuery in order to
prevent premature garbage collection.
2. Add test helper function to trigger GC.
3. Add relevant test case./"
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/Merge branch 'master' into cm-bug-attached-check
Conflicts:
changelog.txt/Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/Merge branch 'master' of github.com:realm/realm-java into kg-bug-findfirst-null-values/"
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/Merge branch 'master' into cm-bug-attached-check
Conflicts:
changelog.txt/Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/Merge pull request #1194 from realm/kg-bug-findfirst-null-values
Added a check for null values in io.realm.internal.Table.findFirst{String,Date}()./Merge branch 'master' of github.com:realm/realm-java into kg-bug-findfirst-null-values/Merge pull request #1154 from realm/ez-findbugs-hunt
Add support for Findbugs and fix the issues found/Add support for Findbugs and fix the issues found/Merge pull request #1153 from realm/ez-table-lint-warnings
Fix a few lint warning reported by the Android Linter/Fix a few lint warning reported by the Android Linter/Merge branch 'master' of github.com:realm/realm-java into kg-bug-migrate-linkview/Merge branch 'master' of github.com:realm/realm-java into kg-bug-migrate-linkview/Merge pull request #1117 from realm/cm-bug-clear
RealmList methods now fail if not within a write transaction/"
realm-java,"Merge pull request #1329 from realm/mc-bug-1328
Fix dead lock might happen in shutdown hook./Remove broken shutdown hook.
To fix #1328
When System.exit(0) called, shutdown hook will be run. There is no
guarantee in this case GC will collect everything. So a dead lock will
happen here.
Remove this part of code since the core side can ensure the integrity of
db file when other resource is not released./Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/Merge pull request #1154 from realm/ez-findbugs-hunt
Add support for Findbugs and fix the issues found/Add support for Findbugs and fix the issues found/"
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/Merge pull request #1187 from PavelSynek/logger-bug
Fixes loggers/"
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/PR comment fixes./Merge branch 'master' of github.com:realm/realm-java into kg-bug-findfirst-null-values/Merge branch 'master' of github.com:realm/realm-java into kg-bug-migrate-linkview/Merge pull request #1117 from realm/cm-bug-clear
RealmList methods now fail if not within a write transaction/"
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg-bug-throw-error/Merge branch 'master' into cm-bug-attached-check
Conflicts:
changelog.txt/Changing logic to handover the query from caller to background thread, handle different failure points (begin_read, import_handover), update UnitTests/Merge branch 'master' into cm-bug-clear/Merge branch 'master' of github.com:realm/realm-java into kg-bug-migrate-linkview/"
realm-java,"Merge pull request #1654 from realm/my/fix-1644
fix RealmProxy code generator to avoid warnings/Removed update() method from generated proxy class corresponding to un-updatable model. fixes #1660/Suppress useless cast and raw type warnings in generated proxy classes.
This warnings are reported when `-Xlint:all` is added to the compilar args.
Example configuration of `build.gradle` is:
```
allprojects {
gradle.projectsEvaluated {
tasks.withType(JavaCompile) {
options.compilerArgs << '-Xlint:all'
options.compilerArgs << '-Werror'
}
}
}
```/Merge pull request #1632 from realm/my/field-indices-cache-for-each-Realm
fix for #1611/fix for #1611
Problem:
The Proxy class of each model holds column indices in static fields.
These indices are good only when all Realm databases have the same column index in every column of the model class.
If Realm databases have different column indices, the getter/setter of Proxy class reads/writes wrong column.
Solution:
This commit introduces `ColumnInfo` object that holds column indices information per Realm instance which shares the same database file./"
realm-java,"Merge pull request #1654 from realm/my/fix-1644
fix RealmProxy code generator to avoid warnings/Removed update() method from generated proxy class corresponding to un-updatable model. fixes #1660/Suppress useless cast and raw type warnings in generated proxy classes.
This warnings are reported when `-Xlint:all` is added to the compilar args.
Example configuration of `build.gradle` is:
```
allprojects {
gradle.projectsEvaluated {
tasks.withType(JavaCompile) {
options.compilerArgs << '-Xlint:all'
options.compilerArgs << '-Werror'
}
}
}
```/Merge pull request #1632 from realm/my/field-indices-cache-for-each-Realm
fix for #1611/fix for #1611
Problem:
The Proxy class of each model holds column indices in static fields.
These indices are good only when all Realm databases have the same column index in every column of the model class.
If Realm databases have different column indices, the getter/setter of Proxy class reads/writes wrong column.
Solution:
This commit introduces `ColumnInfo` object that holds column indices information per Realm instance which shares the same database file./"
realm-java,"Merge pull request #1438 from realm/cm-bug-gridview-example
Removed excessive calls to getInstance in GridViewExample/"
realm-java,fix tests/
realm-java,"REAL_NOEXCEPT was removed from core/enabling encryption exception again/REAL_NOEXCEPT was removed from core/fix tests/Merge pull request #1447 from realm/mc-enc-not-supported
Add RealmEncryptionNotSupportedException/Update core to v0.89.8
Add RealmEncryptionNotSupportedException/"
realm-java,"Merge pull request #1729 from realm/my/isNull-nested-query-for-link-field
throws IllegalArgumentException if isNull/isNotNull is called for unsupported field./throws IllegalArgumentException instead of RealmError if isNull/isNotNull is called for linked field and the last element is a link./Merge branch 'master' into cm/bug/migrate-open-realm/Merge pull request #1623 from realm/nh/post-async-codestyle
fix code style/fix code style/small code style fix/Merge pull request #1602 from realm/kg/bugfix-binary-isnotnull
Bugfix binary isnotnull/Fixing a bug in RealmQuery.isNotNull() for binary data/now throwing Exception if we try to add/remove listener for unmanaged RealmObject/RealmResults/deleting a handover TableView to avoid memory leaks/fix tests/"
realm-java,"Merge pull request #1471 from zaki50/fix_typo
fix typos/fix typos/"
realm-java,"Fix generic,  update Javadoc & error messages/now throwing Exception if we try to add/remove listener for unmanaged RealmObject/RealmResults/now RealmQuery throw exception if reused for another async query/Add RealmQuery.isValid(), RealmResults#isValid() and RealmList#isValid().
fixes #1431/fix javadoc, revert getByIndex to Realm.get, remove ArgumentsHolder fron public package/"
realm-java,"fix tests/Merge pull request #1447 from realm/mc-enc-not-supported
Add RealmEncryptionNotSupportedException/Update core to v0.89.8
Add RealmEncryptionNotSupportedException/"
realm-java,"Merge pull request #1407 from realm/cm-bug-handler
Cleanup SharedGroup.java and Group.java/"
realm-java,Fixed a bug in RealmQuery.isNull() and RealmQuery.isNotNull() which validated the query prematurely./Merge branch 'master' of github.com:realm/realm-java into kg/bugfix-binary-isnotnull/
realm-java,"Adapt core changes in 0.92.0
* Remove insert_xxx methods from Table.
* Table.where() changed to user a Ref instead of a raw ptr.
* makeWriteLogCollector to make_client_history
* advance_read/promote_to_write/rollback_and_continue_as_read need a
replication ptr as param now.
* Remove add_int method.
* A bug fix in linkview jni.
* adjust is removed from TableOrView.
* Other test cases fix.
** testMoveUp & testRemove don't pass right now./Merge pull request #1471 from zaki50/fix_typo
fix typos/fix typos/Adapt core changes in 0.92.0
* Remove insert_xxx methods from Table.
* Table.where() changed to user a Ref instead of a raw ptr.
* makeWriteLogCollector to make_client_history
* advance_read/promote_to_write/rollback_and_continue_as_read need a
replication ptr as param now.
* Remove add_int method.
* A bug fix in linkview jni.
* adjust is removed from TableOrView.
* Other test cases fix.
** testMoveUp & testRemove don't pass right now./fix tests/"
realm-java,"Merge pull request #1572 from realm/lk-primary-key-constraint-exception
Add RealmPrimaryKeyConstraintException./Add RealmPrimaryKeyConstraintException.
Closes #1416/Adapt core changes in 0.92.0
* Remove insert_xxx methods from Table.
* Table.where() changed to user a Ref instead of a raw ptr.
* makeWriteLogCollector to make_client_history
* advance_read/promote_to_write/rollback_and_continue_as_read need a
replication ptr as param now.
* Remove add_int method.
* A bug fix in linkview jni.
* adjust is removed from TableOrView.
* Other test cases fix.
** testMoveUp & testRemove don't pass right now./Merge pull request #1471 from zaki50/fix_typo
fix typos/fix typos/Adapt core changes in 0.92.0
* Remove insert_xxx methods from Table.
* Table.where() changed to user a Ref instead of a raw ptr.
* makeWriteLogCollector to make_client_history
* advance_read/promote_to_write/rollback_and_continue_as_read need a
replication ptr as param now.
* Remove add_int method.
* A bug fix in linkview jni.
* adjust is removed from TableOrView.
* Other test cases fix.
** testMoveUp & testRemove don't pass right now./"
realm-java,"Merge pull request #1471 from zaki50/fix_typo
fix typos/fix typos/"
realm-java,"Merge pull request #1379 from realm/kg-bug-timeout
Unit test to expose timeout in finalizer/Merge branch 'kg-bug-timeout' of github.com:realm/realm-java into kg-bug-timeout/Fixes #1342/"
realm-java,"Merge pull request #1379 from realm/kg-bug-timeout
Unit test to expose timeout in finalizer/Merge branch 'kg-bug-timeout' of github.com:realm/realm-java into kg-bug-timeout/Fixes #1342/"
realm-java,"Merge pull request #1395 from realm/kg-bug-isvalid
isValid should not throw/Fixes #1393
Updates due to PR feedback/"
realm-java,"Merge pull request #1564 from realm/my-fix-crash-of-RealmList
Fix native crash and wrong exception in RealmList./Fix native crash or wrong exception in RealmList.
This commit fixes #1561
Methods listed below in RealmList now throws IllegalStateException if parent object has been removed or the Realm instance has been closed.
* add(int,RealmOject)
* add(RealmObject)
* set(int,RealmObject)
* move(int,int)
* clear()
* remove(int)
* remove(int)
* remove(RealmObject)
* removeAll(Collection)
* get(int)
* first()
* last()
* size()
* where()
RealmList#toString() now returns ""<ClassName>@[invalid]"" if container object has been removed or Realm instance has been closed./"
realm-java,"Adapt core changes in 0.92.0
* Remove insert_xxx methods from Table.
* Table.where() changed to user a Ref instead of a raw ptr.
* makeWriteLogCollector to make_client_history
* advance_read/promote_to_write/rollback_and_continue_as_read need a
replication ptr as param now.
* Remove add_int method.
* A bug fix in linkview jni.
* adjust is removed from TableOrView.
* Other test cases fix.
** testMoveUp & testRemove don't pass right now./Adapt core changes in 0.92.0
* Remove insert_xxx methods from Table.
* Table.where() changed to user a Ref instead of a raw ptr.
* makeWriteLogCollector to make_client_history
* advance_read/promote_to_write/rollback_and_continue_as_read need a
replication ptr as param now.
* Remove add_int method.
* A bug fix in linkview jni.
* adjust is removed from TableOrView.
* Other test cases fix.
** testMoveUp & testRemove don't pass right now./fix tests/Merge pull request #1407 from realm/cm-bug-handler
Cleanup SharedGroup.java and Group.java/"
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #2032 from maciejwitowski/mw-fix-comment-in-example
Fix comment in gridViewExample/Fix comment in gridViewExample/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/"
realm-java,"Merge pull request #2152 from realm/nh/fixes_2130_exception_in_transac
Using separate interfaces for async transaction also fixes #2130/Using separate interfaces for async transaction also fixes #2130/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/"
realm-java,Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/
realm-java,"More fixes for the AP/Fix the AP unit tests/Fix the unit tests of the annotations processor.
Also remove one unit test which makes no sense now that users can
write model classes in any way they like./Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/"
realm-java,"More fixes for the AP/Fix the AP unit tests/Fix the unit tests of the annotations processor.
Also remove one unit test which makes no sense now that users can
write model classes in any way they like./Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/"
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1780 from realm/cm/bug/copyorupdate-primarykey
copyObjectFromJson now works correctly with PrimaryKey/Merge pull request #1664 from realm/lk-fix-javadoc
Fix javadocs/"
realm-java,Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/
realm-java,Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/
realm-java,"Fixed bug when multiple RealmResults.distinct() to return wrong results/Merge pull request #2133 from realm/mc/bug/1945
Access to RealmResults based on deleted RealmList/Access to RealmResults based on deleted RealmList
* When the original RealmList is deleted, for most methods of
RealmResults should just work without crash by just treat it like an
empty RealmResults.
* RealmResults.where() throws IllegalStateExecption in this case.
* RealmResults.isValid() returns false in this case.
This is a temp fix, check https://github.com/realm/realm-core/pull/1434
for more details.
Close #1945/Merge pull request #2103 from realm/mc/bug/2057
Better exception message when sort on sub object/Better exception message when sort on sub object
Close #2034/Merge pull request #2096 from realm/lk/fix-pmd-nested-if
Fix PMD error/Fix PMD error. Nested if/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge branch 'master' into kg/bug/improving-so-loading-using-relinker
Conflicts:
changelog.txt/Merge branch 'master' into kg/bug/improving-so-loading-using-relinker/Adding jni layer interop code to utilize find method.
Testing
Adding header file
Checking to ensure we're on the right Realm before performing the contains check.
Adding changlog
Adding table view code and changing return types to jlong so we can use them in the indexOf
Adding multi-realm test
Removing code that should not have been in the commit
Changing LinkView.cpp method to use commonly used Macro and udpated null checks.
Changing LinkView.cpp method to use commonly used Macro and udpated null checks and moved contains method to override instead of overload.
Using instance of instead of assignable from and using long value instead of returning a boolean.
Checking for row and index validity in the cpp layer. Also removing the not found constant in order to the use the constant in TableOrView
Checking for managed mode. Falling back to default impl. Updating changelog.
Reverting back to to_jlong_or_not_found
Fixing a few compilation issues as well as applying code review updates.
Fixing managed mode bug that I accidentally introduced.
Updates as per @beeender recommended, issues listed below.
After changing cpp code to return -1 tests started failing - items were not found. I'm on the fence if this is expected or not. I'm not to familiar wit the underlying core to know if -1 should be needed.
Also added tests to check to see if a query or list contains an item that is in the same Realm, but from another query/result. This test creates a native crash. I tried to identify the root cause by pulling the tombstone and performing `ndk-stack` and `addr2line` on it but I could not properly identify the symbols and where they might be.
Inspiration and HOWTO to debug NDK from here: http://bytesthink.com/blog/?p=133
Adding nativePtr to JNI call. Also added isLoaded() call. Not contained test failing on out of bounds exception on row indexes.
Changing TableOrView#find() name to TableOrView#sourceRowIndex() as per recommendation of @beeender
Adding check for parent table and re-enabled the other jni targets and fixed incorrect test.
Received help with this from @beeender and @cmelchior./Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1927 from realm/nh/fix_1894_changelistener_not_called
Nh/fix 1894 changelistener not called/fix 1894 changelistener not called/Merge pull request #1892 from realm/nh/fix-1884-listener-trigger
Nh/fix 1884 listener trigger/fix 1884 listener trigger/Fixed unit tests/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1664 from realm/lk-fix-javadoc
Fix javadocs/"
realm-java,"Merge pull request #2133 from realm/mc/bug/1945
Access to RealmResults based on deleted RealmList/Access to RealmResults based on deleted RealmList
* When the original RealmList is deleted, for most methods of
RealmResults should just work without crash by just treat it like an
empty RealmResults.
* RealmResults.where() throws IllegalStateExecption in this case.
* RealmResults.isValid() returns false in this case.
This is a temp fix, check https://github.com/realm/realm-core/pull/1434
for more details.
Close #1945/Merge pull request #1771 from realm/kg/bug/improving-so-loading-using-relinker
Improving .so loading by using the ReLinker library/Merge branch 'kg/bug/improving-so-loading-using-relinker' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1664 from realm/lk-fix-javadoc
Fix javadocs/"
realm-java,"Merge pull request #1771 from realm/kg/bug/improving-so-loading-using-relinker
Improving .so loading by using the ReLinker library/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1664 from realm/lk-fix-javadoc
Fix javadocs/"
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #2028 from realm/lk/fix-realmquery-isnotempty
Fix RealmQuery.isNotEmpty() correctly./Fix RealmQuery.isNotEmpty().
It is fix for #2025. Fix the native method + Renaming./Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1895 from realm/nh/fix-1851-async-badversion-crash
fix1851 async badversion crash/add batch update for async queries to fix #1851/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1664 from realm/lk-fix-javadoc
Fix javadocs/"
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge branch 'master' into kg/bug/improving-so-loading-using-relinker
Conflicts:
changelog.txt/Adding jni layer interop code to utilize find method.
Testing
Adding header file
Checking to ensure we're on the right Realm before performing the contains check.
Adding changlog
Adding table view code and changing return types to jlong so we can use them in the indexOf
Adding multi-realm test
Removing code that should not have been in the commit
Changing LinkView.cpp method to use commonly used Macro and udpated null checks.
Changing LinkView.cpp method to use commonly used Macro and udpated null checks and moved contains method to override instead of overload.
Using instance of instead of assignable from and using long value instead of returning a boolean.
Checking for row and index validity in the cpp layer. Also removing the not found constant in order to the use the constant in TableOrView
Checking for managed mode. Falling back to default impl. Updating changelog.
Reverting back to to_jlong_or_not_found
Fixing a few compilation issues as well as applying code review updates.
Fixing managed mode bug that I accidentally introduced.
Updates as per @beeender recommended, issues listed below.
After changing cpp code to return -1 tests started failing - items were not found. I'm on the fence if this is expected or not. I'm not to familiar wit the underlying core to know if -1 should be needed.
Also added tests to check to see if a query or list contains an item that is in the same Realm, but from another query/result. This test creates a native crash. I tried to identify the root cause by pulling the tombstone and performing `ndk-stack` and `addr2line` on it but I could not properly identify the symbols and where they might be.
Inspiration and HOWTO to debug NDK from here: http://bytesthink.com/blog/?p=133
Adding nativePtr to JNI call. Also added isLoaded() call. Not contained test failing on out of bounds exception on row indexes.
Changing TableOrView#find() name to TableOrView#sourceRowIndex() as per recommendation of @beeender
Adding check for parent table and re-enabled the other jni targets and fixed incorrect test.
Received help with this from @beeender and @cmelchior./Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1664 from realm/lk-fix-javadoc
Fix javadocs/"
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1664 from realm/lk-fix-javadoc
Fix javadocs/"
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge branch 'master' into kg/bug/improving-so-loading-using-relinker
Conflicts:
changelog.txt/Adding jni layer interop code to utilize find method.
Testing
Adding header file
Checking to ensure we're on the right Realm before performing the contains check.
Adding changlog
Adding table view code and changing return types to jlong so we can use them in the indexOf
Adding multi-realm test
Removing code that should not have been in the commit
Changing LinkView.cpp method to use commonly used Macro and udpated null checks.
Changing LinkView.cpp method to use commonly used Macro and udpated null checks and moved contains method to override instead of overload.
Using instance of instead of assignable from and using long value instead of returning a boolean.
Checking for row and index validity in the cpp layer. Also removing the not found constant in order to the use the constant in TableOrView
Checking for managed mode. Falling back to default impl. Updating changelog.
Reverting back to to_jlong_or_not_found
Fixing a few compilation issues as well as applying code review updates.
Fixing managed mode bug that I accidentally introduced.
Updates as per @beeender recommended, issues listed below.
After changing cpp code to return -1 tests started failing - items were not found. I'm on the fence if this is expected or not. I'm not to familiar wit the underlying core to know if -1 should be needed.
Also added tests to check to see if a query or list contains an item that is in the same Realm, but from another query/result. This test creates a native crash. I tried to identify the root cause by pulling the tombstone and performing `ndk-stack` and `addr2line` on it but I could not properly identify the symbols and where they might be.
Inspiration and HOWTO to debug NDK from here: http://bytesthink.com/blog/?p=133
Adding nativePtr to JNI call. Also added isLoaded() call. Not contained test failing on out of bounds exception on row indexes.
Changing TableOrView#find() name to TableOrView#sourceRowIndex() as per recommendation of @beeender
Adding check for parent table and re-enabled the other jni targets and fixed incorrect test.
Received help with this from @beeender and @cmelchior./Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #2020 from realm/kk-typo
Fix typo in documentation comment: (ndex => index)/Fix typo in documentation comment: (ndex => index)/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1664 from realm/lk-fix-javadoc
Fix javadocs/"
realm-java,"Merge pull request #1771 from realm/kg/bug/improving-so-loading-using-relinker
Improving .so loading by using the ReLinker library/Merge branch 'kg/bug/improving-so-loading-using-relinker' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/"
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1292 from realm/mc-linkview-leak
Release LinkView native pointers/Release LinkView native pointers
Fix #1285
* Add abstract method to NativeObjectReference for native resource
releasing.
* Implement NativeObjectReference.cleanup for UncheckRow and LinkView/Merge pull request #1664 from realm/lk-fix-javadoc
Fix javadocs/"
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1664 from realm/lk-fix-javadoc
Fix javadocs/"
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1292 from realm/mc-linkview-leak
Release LinkView native pointers/Release LinkView native pointers
Fix #1285
* Add abstract method to NativeObjectReference for native resource
releasing.
* Implement NativeObjectReference.cleanup for UncheckRow and LinkView/Merge pull request #1664 from realm/lk-fix-javadoc
Fix javadocs/"
realm-java,Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1664 from realm/lk-fix-javadoc
Fix javadocs/"
realm-java,"Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge branch 'master' into kg/bug/improving-so-loading-using-relinker
Conflicts:
changelog.txt/Adding jni layer interop code to utilize find method.
Testing
Adding header file
Checking to ensure we're on the right Realm before performing the contains check.
Adding changlog
Adding table view code and changing return types to jlong so we can use them in the indexOf
Adding multi-realm test
Removing code that should not have been in the commit
Changing LinkView.cpp method to use commonly used Macro and udpated null checks.
Changing LinkView.cpp method to use commonly used Macro and udpated null checks and moved contains method to override instead of overload.
Using instance of instead of assignable from and using long value instead of returning a boolean.
Checking for row and index validity in the cpp layer. Also removing the not found constant in order to the use the constant in TableOrView
Checking for managed mode. Falling back to default impl. Updating changelog.
Reverting back to to_jlong_or_not_found
Fixing a few compilation issues as well as applying code review updates.
Fixing managed mode bug that I accidentally introduced.
Updates as per @beeender recommended, issues listed below.
After changing cpp code to return -1 tests started failing - items were not found. I'm on the fence if this is expected or not. I'm not to familiar wit the underlying core to know if -1 should be needed.
Also added tests to check to see if a query or list contains an item that is in the same Realm, but from another query/result. This test creates a native crash. I tried to identify the root cause by pulling the tombstone and performing `ndk-stack` and `addr2line` on it but I could not properly identify the symbols and where they might be.
Inspiration and HOWTO to debug NDK from here: http://bytesthink.com/blog/?p=133
Adding nativePtr to JNI call. Also added isLoaded() call. Not contained test failing on out of bounds exception on row indexes.
Changing TableOrView#find() name to TableOrView#sourceRowIndex() as per recommendation of @beeender
Adding check for parent table and re-enabled the other jni targets and fixed incorrect test.
Received help with this from @beeender and @cmelchior./Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1292 from realm/mc-linkview-leak
Release LinkView native pointers/Release LinkView native pointers
Fix #1285
* Add abstract method to NativeObjectReference for native resource
releasing.
* Implement NativeObjectReference.cleanup for UncheckRow and LinkView/Merge pull request #1664 from realm/lk-fix-javadoc
Fix javadocs/"
realm-java,"Merge pull request #2060 from realm/ez/fix-findbugs
Fix a couple of Findbugs issues/Fix a couple of Findbugs issues/Merge pull request #1771 from realm/kg/bug/improving-so-loading-using-relinker
Improving .so loading by using the ReLinker library/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge branch 'master' into kg/bug/improving-so-loading-using-relinker
Conflicts:
changelog.txt/Merge pull request #1994 from realm/mc/bug/close-in-object-query
Always close shared group first before async msg/Merge pull request #1664 from realm/lk-fix-javadoc
Fix javadocs/"
realm-java,"Merge pull request #2152 from realm/nh/fixes_2130_exception_in_transac
Using separate interfaces for async transaction also fixes #2130/Using separate interfaces for async transaction also fixes #2130/Merge pull request #2090 from realm/mc/bug/flaky-test-fix
Fix flaky tests related with async transaction/Fix flaky tests related with async transaction
* Background realm needs to be closed before notifying other threads
in async transaction.
* Latch needs to be called after Realm closed./Merge pull request #2065 from realm/cm/bug/copyfromrealm-dynamicrealmobject
IllegalArgumentException when calling copyFromRealm(dynamicRealmObject)/IllegalArgumentException now being thrown when calling copyFromRealm(dynamicRealmObject)/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Adding @throws declarations to javadocs for BaseRealm, Realm and DynamicRealm
Applying changes from review.
Adding updated javadoc
Removing RuntimeException declaration and adding grammar fix./Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1892 from realm/nh/fix-1884-listener-trigger
Nh/fix 1884 listener trigger/fix 1884 listener trigger/Merge pull request #1900 from realm/mc/bug/close-in-listener
Fix crash when close Realm in listener/Fix crash when closing a Realm in listener #1900/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1780 from realm/cm/bug/copyorupdate-primarykey
copyObjectFromJson now works correctly with PrimaryKey/Merge pull request #1725 from realm/nh/listener-strong-ref
fix #1675 RealmChangeListener are strong reference now./Checking to see if a transaction is currently in progress for sync and async transaction pathways.
Also adding logging.
Added a test helper to assist with log assertion.
Fixes #1682
Fixing typo.
Removing logger after testing
Removing extra line
Fixing tests and adding change log message.
Adding breaking change message
Small cosmetic changes
Adding punctuation
formatting
Fixing unit test./Merge pull request #1664 from realm/lk-fix-javadoc
Fix javadocs/"
realm-java,"Merge pull request #2181 from realm/kg/enhancement/surrogates
String setters will throw IllegalArgumentException/String setters will throw IllegalArgumentException/Merge pull request #2148 from realm/my/fix_data_usage_of_StringData
Fix wrong usages of StringData.data()./Fix wrong usages of StringData.data().
`StringData.data()` does not guarantee the null termination of returned char array.
We must use `size()` information to properly handle the char array in the StringData such as `std::string(str.data(), str.size())`./Merge pull request #2133 from realm/mc/bug/1945
Access to RealmResults based on deleted RealmList/Access to RealmResults based on deleted RealmList
* When the original RealmList is deleted, for most methods of
RealmResults should just work without crash by just treat it like an
empty RealmResults.
* RealmResults.where() throws IllegalStateExecption in this case.
* RealmResults.isValid() returns false in this case.
This is a temp fix, check https://github.com/realm/realm-core/pull/1434
for more details.
Close #1945/Merge pull request #2146 from realm/my/fix_concat_StringData_and_C_string
Fix field name in the message of IllegalArgumentException throw by the accessors of DynamicRealmObject/Fix field name in the message of IllegalArgumentException throw by the accessors of DynamicRealmObject/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/Merge pull request #1895 from realm/nh/fix-1851-async-badversion-crash
fix1851 async badversion crash/add batch update for async queries to fix #1851/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/"
realm-java,"Merge pull request #2133 from realm/mc/bug/1945
Access to RealmResults based on deleted RealmList/Access to RealmResults based on deleted RealmList
* When the original RealmList is deleted, for most methods of
RealmResults should just work without crash by just treat it like an
empty RealmResults.
* RealmResults.where() throws IllegalStateExecption in this case.
* RealmResults.isValid() returns false in this case.
This is a temp fix, check https://github.com/realm/realm-core/pull/1434
for more details.
Close #1945/Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/"
realm-java,Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/
realm-java,Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/
realm-java,Merge branch 'master' of github.com:realm/realm-java into kg/bug/improving-so-loading-using-relinker/
realm-java,"Interface as supplement to extending RealmObject (#2599)
* Backup
* Add RealmModel
* Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests
* fixing examples
* WIP
* fix Annotation processor
* clean up
* fix javadoc
* add transformer tests & fix DynamicRealm tests
* fixing tests
* adding tests
* adding tests
* fixing tests for the realm-annotations-processor
* add tests to cover more UC for RealmList
* renamed POJO to RealmModel
* reduce method count by using proxyState only in RealmObjectProxy
* fix examples, no need to exclude RealmObject using Gson https://realm.io/docs/java/latest/#gson
* making RealmList final, remove unused method & fixing APT test/"
realm-java,"Merge pull request #2377 from rmekdma/patch-1
Fix migration example description/"
realm-java,"Merge pull request #2304 from realm/mc/bug/deprecate-getInstance
Deprecate Realm.getInstance(Context)/"
realm-java,"@PrimaryKey in String, Byte, Short, Integer, and Long types can be null. (#2634)
@PrimaryKey is allowed to be null for String and Boxed primitive types.
Features part of this commit are
1. A @PrimaryKey annotated field in java.lang.String/Byte/Short/"
realm-java,"@PrimaryKey in String, Byte, Short, Integer, and Long types can be null. (#2634)
@PrimaryKey is allowed to be null for String and Boxed primitive types.
Features part of this commit are
1. A @PrimaryKey annotated field in java.lang.String/Byte/Short/"
realm-java,"Merge pull request #2593 from realm/lk/fix-doc
Fix javadoc/Fix javadoc/"
realm-java,"Interface as supplement to extending RealmObject (#2599)
* Backup
* Add RealmModel
* Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests
* fixing examples
* WIP
* fix Annotation processor
* clean up
* fix javadoc
* add transformer tests & fix DynamicRealm tests
* fixing tests
* adding tests
* adding tests
* fixing tests for the realm-annotations-processor
* add tests to cover more UC for RealmList
* renamed POJO to RealmModel
* reduce method count by using proxyState only in RealmObjectProxy
* fix examples, no need to exclude RealmObject using Gson https://realm.io/docs/java/latest/#gson
* making RealmList final, remove unused method & fixing APT test/"
realm-java,"RealmCollection iterators are now stable (#2124)
This commit changes the semantics of how live RealmResults really are. Before this commit
RealmResults where live _all the time_, which meant that code like the below didn't work as expected (only half the elements would be deleted):
```
for (int i = 0; i < results.size(); i++) {
results.get(i).deleteFromRealm();
}
```
The rather unintuitive work-around was counting backwards:
```
for (int i = results.size() -1; i >=0; i--) {
results.get(i).deleteFromRealm();
}
```
This commit changes the behaviour of RealmResults, so they no longer are automatically up to date. They are instead refreshed using Looper events just like changes from other threads.
RealmList iterators are not live in the same way that RealmResults are but act more like standard ArrayLists, so they don't suffer from the same liveness issues.
The high-level arguments for doing this change was:
Pros:
* All iterators now work as you would normally expect (ease of use).
* The liveness of Realm objects are now all controlled through the Looper (simpler internal code / easier to document Realm behaviour).
Cons:
* There is a small chance that people can accidentally reference a deleted RealmObject in a RealmResult. (Can be checked through use of `RealmObject.isValid()`)/Interface as supplement to extending RealmObject (#2599)
* Backup
* Add RealmModel
* Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests
* fixing examples
* WIP
* fix Annotation processor
* clean up
* fix javadoc
* add transformer tests & fix DynamicRealm tests
* fixing tests
* adding tests
* adding tests
* fixing tests for the realm-annotations-processor
* add tests to cover more UC for RealmList
* renamed POJO to RealmModel
* reduce method count by using proxyState only in RealmObjectProxy
* fix examples, no need to exclude RealmObject using Gson https://realm.io/docs/java/latest/#gson
* making RealmList final, remove unused method & fixing APT test/Merge pull request #2450 from realm/cm/bug/badversionexception
Fix BadVersionException/Fixed race condition causing BadVersionException/Merge pull request #2361 from realm/mc/bug/1990
Only load RealmObservableFactory when RxJava exist/Only load RealmObservableFactory when RxJava exist
Close #1990.
* Check RxJava existence only once.
* Don't load RealmObservableFactory if RxJava doesn't exist.
NOTE: When reflection called on the RealmObject/RealmResults, crash will
still happen because of Observable doesn't exist in the class path. In
such a case, a dummy rx.Observable is still needed as a workaround./Merge pull request #2280 from realm/mc/bug/deleted-linkview-release-branch
Adapt core fix for the delete RealmList/Adapt core fix for the delete RealmList
Update core to 0.96.1.
No more exception will be thrown when access RealmResults if the base
RealmList has be deleted. Instead, it will be treated as an empty
RealmResults forever./"
realm-java,"Interface as supplement to extending RealmObject (#2599)
* Backup
* Add RealmModel
* Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests
* fixing examples
* WIP
* fix Annotation processor
* clean up
* fix javadoc
* add transformer tests & fix DynamicRealm tests
* fixing tests
* adding tests
* adding tests
* fixing tests for the realm-annotations-processor
* add tests to cover more UC for RealmList
* renamed POJO to RealmModel
* reduce method count by using proxyState only in RealmObjectProxy
* fix examples, no need to exclude RealmObject using Gson https://realm.io/docs/java/latest/#gson
* making RealmList final, remove unused method & fixing APT test/Merge pull request #2280 from realm/mc/bug/deleted-linkview-release-branch
Adapt core fix for the delete RealmList/Adapt core fix for the delete RealmList
Update core to 0.96.1.
No more exception will be thrown when access RealmResults if the base
RealmList has be deleted. Instead, it will be treated as an empty
RealmResults forever./"
realm-java,"Merge pull request #2593 from realm/lk/fix-doc
Fix javadoc/Fix javadoc/"
realm-java,"Merge pull request #2450 from realm/cm/bug/badversionexception
Fix BadVersionException/Fixed race condition causing BadVersionException/"
realm-java,"RealmCollection iterators are now stable (#2124)
This commit changes the semantics of how live RealmResults really are. Before this commit
RealmResults where live _all the time_, which meant that code like the below didn't work as expected (only half the elements would be deleted):
```
for (int i = 0; i < results.size(); i++) {
results.get(i).deleteFromRealm();
}
```
The rather unintuitive work-around was counting backwards:
```
for (int i = results.size() -1; i >=0; i--) {
results.get(i).deleteFromRealm();
}
```
This commit changes the behaviour of RealmResults, so they no longer are automatically up to date. They are instead refreshed using Looper events just like changes from other threads.
RealmList iterators are not live in the same way that RealmResults are but act more like standard ArrayLists, so they don't suffer from the same liveness issues.
The high-level arguments for doing this change was:
Pros:
* All iterators now work as you would normally expect (ease of use).
* The liveness of Realm objects are now all controlled through the Looper (simpler internal code / easier to document Realm behaviour).
Cons:
* There is a small chance that people can accidentally reference a deleted RealmObject in a RealmResult. (Can be checked through use of `RealmObject.isValid()`)/Merge pull request #2593 from realm/lk/fix-doc
Fix javadoc/Fix javadoc/"
realm-java,"RealmCollection iterators are now stable (#2124)
This commit changes the semantics of how live RealmResults really are. Before this commit
RealmResults where live _all the time_, which meant that code like the below didn't work as expected (only half the elements would be deleted):
```
for (int i = 0; i < results.size(); i++) {
results.get(i).deleteFromRealm();
}
```
The rather unintuitive work-around was counting backwards:
```
for (int i = results.size() -1; i >=0; i--) {
results.get(i).deleteFromRealm();
}
```
This commit changes the behaviour of RealmResults, so they no longer are automatically up to date. They are instead refreshed using Looper events just like changes from other threads.
RealmList iterators are not live in the same way that RealmResults are but act more like standard ArrayLists, so they don't suffer from the same liveness issues.
The high-level arguments for doing this change was:
Pros:
* All iterators now work as you would normally expect (ease of use).
* The liveness of Realm objects are now all controlled through the Looper (simpler internal code / easier to document Realm behaviour).
Cons:
* There is a small chance that people can accidentally reference a deleted RealmObject in a RealmResult. (Can be checked through use of `RealmObject.isValid()`)/@PrimaryKey in String, Byte, Short, Integer, and Long types can be null. (#2634)
@PrimaryKey is allowed to be null for String and Boxed primitive types.
Features part of this commit are
1. A @PrimaryKey annotated field in java.lang.String/Byte/Short/Integer/Long type can be null.
2. The object with nil primary key can be updated.
3. Migration checks if existing nullable type @PrimaryKey is set to be nullable in existing file. If not, throws RealmMigrationNeeded.
4. Duplicated null as PrimaryKey throws RealmPrimaryKeyConstraintException.
5. When a new empty row is added, the default value checked for duplicated is still the same empty string ("""") at Table.addEmptyRow()
6. Since there isn't equivalent term for Optional in Java 7 yet, nullable PK types are configured as following in this PR.
| String PK | Number PK | Primitive PK |
------------------------------------------------------------------------
Table Column | Nullable   | Nullable          | Not Nullable |/Merge pull request #2593 from realm/lk/fix-doc
Fix javadoc/Fix javadoc/Merge pull request #2441 from realm/my/fix_2439
Fix the String from DynamicRealmObject.toString()./fix the String from DynamicRealmObject.toString().
Now DynamicRealmObject.toString() shows null value as ""null"".
""class_"" prefix is removed from type name in that String.
Align the format to the String from typed RealmObject./"
realm-java,"Use ReLinker of JCenter instead of including the dependency ourselves.
There was the problem that se Realm were forced to tell users to add the
jitpack repo manually, so we have decided to include the dependency
ourselves (#2415).
ReLinker is on JCenter now. We can use Relinker of JCenter instead. It
will resolve #2596./Use a local copy of ReLinker
The problem is that libraries that use Realm were forced to tell users
to add the jitpack repo manually, which is inconvenient./"
realm-java,"@PrimaryKey in String, Byte, Short, Integer, and Long types can be null. (#2634)
@PrimaryKey is allowed to be null for String and Boxed primitive types.
Features part of this commit are
1. A @PrimaryKey annotated field in java.lang.String/Byte/Short/"
realm-java,"@PrimaryKey in String, Byte, Short, Integer, and Long types can be null. (#2634)
@PrimaryKey is allowed to be null for String and Boxed primitive types.
Features part of this commit are
1. A @PrimaryKey annotated field in java.lang.String/Byte/Short/"
realm-java,"Finalizer optimization: Replace hashmap
Problems we had by using hashmap:
1. Hashmap is not thread save and we access the same hashmap in
finalizer thread and caller thread of Row's constructor.
2. Removing reference from the hashmap is a little bit slower when
there are many references waited to be GCed.
Refactor the NativeObjectReference, make it as a final class and calling
native resource's deallocation directly inside the class. This is needed
for further optimization, like batch delete native pointers to avoid
multiple JNI calls.
Some benchmark comparison using the array solution vs hashmap solution:
(Benchmark running on Genymotion Nexus 6 5.1.0)
(hashmap) Creating 200000 rows - in avg 10000 rows takes 65ms
(array) Creating 200000 rows - in avg 10000 rows takes 67ms
(hashmap) Deleting 200000 rows - in avg 10000 rows takes 8ms
(array) Deleting 200000 rows - in avg 10000 rows takes 4ms
(hashmap) Creating 2000000 rows - in avg 10000 rows takes 30ms
(array) Creating 2000000 rows - in avg 10000 rows takes 28ms
(hashmap) Deleting 200000 rows - in avg 10000 rows takes 95ms
(array) Deleting 200000 rows - in avg 10000 rows takes 46ms
(hashmap) Creating 10000000 rows - in avg 10000 rows takes 33ms
(array) Creating 10000000 rows - in avg 10000 rows takes 28ms
(hashmap) Deleting 1000000 rows - in avg 10000 rows takes 62ms
(array) Deleting 1000000 rows - in avg 10000 rows takes 23ms/Merge pull request #2390 from realm/mc/bug/2381
More checkings when modify RealmList/More checkings when modify RealmList
Fix #2381
* New method LinkView.getTargetTable().
* Proper checking to add DynamicRealmObject to RealmList.
* Disallow modifying with RealmObject belongs to another Realm instance./"
realm-java,"Implementation of SharedGroup::wait_for_change() method. (#2386)
Goal
1. Add BaseRealm.waitForChange() which blocks until a change is available, then advance the Realm and continue without triggering RealmChangeListeners.
2. Add BaseRealm.stopWaitForChange() that makes any current waitForChange() return false immediately.
3. Deprecated BaseRealm.refresh().
Behaviors
1. waitForChange() will throw IllegalStateException within a transaction.
2. BaseRealm cannot wait in a thread with Looper. IllegalStateException will be thrown.
3. Once stopWaitForChange is called, all future calls to waitForChange will immediately return false.
For detailed discussions, please refer https://github.com/realm/realm-wiki/wiki/Java-Multi-threaded-wait_for_change/Merge pull request #2450 from realm/cm/bug/badversionexception
Fix BadVersionException/Fixed race condition causing BadVersionException/"
realm-java,"Handle PK when calling RealmSchema's remove/rename (#2663)
* Handle PK when calling RealmSchema's remove/rename
* RealmSchema.remove() should remove the field from PK table.
* RealmSchema.rename() should change the corresponding row in the PK
table.
Fix #2555/@PrimaryKey in String, Byte, Short, Integer, and Long types can be null. (#2634)
@PrimaryKey is allowed to be null for String and Boxed primitive types.
Features part of this commit are
1. A @PrimaryKey annotated field in java.lang.String/Byte/Short/Integer/Long type can be null.
2. The object with nil primary key can be updated.
3. Migration checks if existing nullable type @PrimaryKey is set to be nullable in existing file. If not, throws RealmMigrationNeeded.
4. Duplicated null as PrimaryKey throws RealmPrimaryKeyConstraintException.
5. When a new empty row is added, the default value checked for duplicated is still the same empty string ("""") at Table.addEmptyRow()
6. Since there isn't equivalent term for Optional in Java 7 yet, nullable PK types are configured as following in this PR.
| String PK | Number PK | Primitive PK |
------------------------------------------------------------------------
Table Column | Nullable   | Nullable             | Not Nullable |/Merge pull request #2593 from realm/lk/fix-doc
Fix javadoc/Fix javadoc/Merge pull request #2565 from micronax/patch-1
Fixed wrong method name in exception/Fixed wrong method name in exception
Fixed wrong method name in exception/Merge pull request #2380 from realm/mc/bug/2368
Correct checking in DynamicRealmObject.setList/Correct checking in DynamicRealmObject.setList
* Fix #2368
* Check equality of Realm in DynamicRealmObject setters to avoid risks
mentioned 2) in #2382/"
realm-java,"Nh/fix listener generics (#2726)
* Fix generics when attaching RealmChangeListener for Realm & DynamicRealm/Add to realmObjects when addChangeListener called (#2723)
* Only add the RealmObject to HandlerController.realmObjects when
addChangeListener called. This will avoid we have too many objects in
the map.
* addToRealmObjects missed reference queue which would lead to the map
grows always without cleaning.
Close #2569, potentially a fix to #2686 ./Make Realm.createObject(Class,PrimaryKey) public (#2622)
This method is a way to solve the problem that people might have data with a primary key that is is the default value for that type, e.g a long primary key with the value 0.
Once this object is saved in Realm any calls to the normal Realm.createObject() would throw an exception as it would try to assign the default value (zero) to the object before the user could set it to something else. With this method that is no longer a problem.
Internally we already use this method and it is already public in the Dynamic API. The reason for not making this public earlier was due to fear of mis-use since there is no type-safe guarantee at compile time. However since it is already public in the Dynamic API and we haven't seen any indication of that being misused we feel it should be safe to make this public. Also our Query API is also semi-threadsafe so there is precedence there as well./Only throw RealmException if absolutely necessary (#2618)
We should avoid wrapping lower level exceptions in RealmExceptions unless there is a good reason for it. We had multiple support issues where people were confused about the RealmException and didn't understand they had to dig through the stack trace for the original exception.
This change alters the behaviour of all our JSON methods so they now only convert JSONException to RealmException in order to prevent checked exceptions to reach the user. All other exceptions should be thrown directly./RealmCollection iterators are now stable (#2124)
This commit changes the semantics of how live RealmResults really are. Before this commit
RealmResults where live _all the time_, which meant that code like the below didn't work as expected (only half the elements would be deleted):
```
for (int i = 0; i < results.size(); i++) {
results.get(i).deleteFromRealm();
}
```
The rather unintuitive work-around was counting backwards:
```
for (int i = results.size() -1; i >=0; i--) {
results.get(i).deleteFromRealm();
}
```
This commit changes the behaviour of RealmResults, so they no longer are automatically up to date. They are instead refreshed using Looper events just like changes from other threads.
RealmList iterators are not live in the same way that RealmResults are but act more like standard ArrayLists, so they don't suffer from the same liveness issues.
The high-level arguments for doing this change was:
Pros:
* All iterators now work as you would normally expect (ease of use).
* The liveness of Realm objects are now all controlled through the Looper (simpler internal code / easier to document Realm behaviour).
Cons:
* There is a small chance that people can accidentally reference a deleted RealmObject in a RealmResult. (Can be checked through use of `RealmObject.isValid()`)/Interface as supplement to extending RealmObject (#2599)
* Backup
* Add RealmModel
* Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests
* fixing examples
* WIP
* fix Annotation processor
* clean up
* fix javadoc
* add transformer tests & fix DynamicRealm tests
* fixing tests
* adding tests
* adding tests
* fixing tests for the realm-annotations-processor
* add tests to cover more UC for RealmList
* renamed POJO to RealmModel
* reduce method count by using proxyState only in RealmObjectProxy
* fix examples, no need to exclude RealmObject using Gson https://realm.io/docs/java/latest/#gson
* making RealmList final, remove unused method & fixing APT test/aAInitial dataset for a Realm (#2602)
* Support creating an initial dataset for a Realm
* PR fixes for initial data set/Merge pull request #2593 from realm/lk/fix-doc
Fix javadoc/Fix javadoc/Merge pull request #2480 from realm/mc/bug/threading-check-copy-to-realm
Thread check for copyToRealm/copyToRealmOrUpdate/Merge pull request #2327 from realm/mc/bug/2316
migrateRealm throws when db doesn't exsit/Merge pull request #2304 from realm/mc/bug/deprecate-getInstance
Deprecate Realm.getInstance(Context)/"
realm-java,"Interface as supplement to extending RealmObject (#2599)
* Backup
* Add RealmModel
* Modifying the annotation processor & byte code modification to use RealmModel, add UnitTests
* fixing examples
* WIP
* fix Annotation processor
* clean up
* fix javadoc
* add transformer tests & fix DynamicRealm tests
* fixing tests
* adding tests
* adding tests
* fixing tests for the realm-annotations-processor
* add tests to cover more UC for RealmList
* renamed POJO to RealmModel
* reduce method count by using proxyState only in RealmObjectProxy
* fix examples, no need to exclude RealmObject using Gson https://realm.io/docs/java/latest/#gson
* making RealmList final, remove unused method & fixing APT test/Merge pull request #2493 from realm/cm/bug/oberservable-gc
RealmResults/Objects are no longer accidentially GC'ed/Merge pull request #2364 from realm/cm/rxjava-close-bug
Realm Observables now holds a Realm instance reference/Merge pull request #2361 from realm/mc/bug/1990
Only load RealmObservableFactory when RxJava exist/Only load RealmObservableFactory when RxJava exist
Close #1990.
* Check RxJava existence only once.
* Don't load RealmObservableFactory if RxJava doesn't exist.
NOTE: When reflection called on the RealmObject/RealmResults, crash will
still happen because of Observable doesn't exist in the class path. In
such a case, a dummy rx.Observable is still needed as a workaround./Merge pull request #2335 from marukami/rx-typo
fixed typo/fixed typo/"
realm-java,"Merge pull request #2280 from realm/mc/bug/deleted-linkview-release-branch
Adapt core fix for the delete RealmList/Adapt core fix for the delete RealmList
Update core to 0.96.1.
No more exception will be thrown when access RealmResults if the base
RealmList has be deleted. Instead, it will be treated as an empty
RealmResults forever./"
realm-java,"Merge pull request #2280 from realm/mc/bug/deleted-linkview-release-branch
Adapt core fix for the delete RealmList/Adapt core fix for the delete RealmList
Update core to 0.96.1.
No more exception will be thrown when access RealmResults if the base
RealmList has be deleted. Instead, it will be treated as an empty
RealmResults forever./"
realm-java,"Examples should use transaction blocks (#2800)
* Moving examples over to execute transaction
* Updating comments to use executeTransaction
* Use partial mocks for Realm#executeTransaction(...) and create additional tests to illustrate mock verification of Realm#executeTransaction(...).
Had to do this because of a problem with Powermock: https://github.com/jayway/powermock/issues/649/"
realm-java,"Removed all deprecated methods and fixed examples./Examples should use transaction blocks (#2800)
* Moving examples over to execute transaction
* Updating comments to use executeTransaction
* Use partial mocks for Realm#executeTransaction(...) and create additional tests to illustrate mock verification of Realm#executeTransaction(...).
Had to do this because of a problem with Powermock: https://github.com/jayway/powermock/issues/649/"
realm-java,"Merge pull request #3250 from realm/merge-f3b025-to-master
* Check transaction state for buld insertion (#3228)
* Throws if they are not called in a transaction.
* Test cases for buld insertion thread checking.
* Lint warnings fix.
Close #3173
* Clarify how insertOrUpdate behave for objects with primary keys. (#3241)
* Missing transaction in threading example (#3245)
Close #3244
* insert(): Correctly detect multiple objects with the same primary key  (#3239)
* Fix isLoaded JavaDoc (#3240)/Removed all deprecated methods and fixed examples./Examples should use transaction blocks (#2800)
* Moving examples over to execute transaction
* Updating comments to use executeTransaction
* Use partial mocks for Realm#executeTransaction(...) and create additional tests to illustrate mock verification of Realm#executeTransaction(...).
Had to do this because of a problem with Powermock: https://github.com/jayway/powermock/issues/649/"
realm-java,"Removed all deprecated methods and fixed examples./Examples should use transaction blocks (#2800)
* Moving examples over to execute transaction
* Updating comments to use executeTransaction
* Use partial mocks for Realm#executeTransaction(...) and create additional tests to illustrate mock verification of Realm#executeTransaction(...).
Had to do this because of a problem with Powermock: https://github.com/jayway/powermock/issues/649/"
realm-java,"Add quotes around terms in exceptions message (#3221)
Close #3217/Merge pull request #3090 from realm/merge-ecbacf-to-master
Fix merge from ecbacf to master/Use qualified name for model classes in generated code in order to avoid name conflict. (#3083)
* use qualified name for model classes in generated code in order to avoid name conflict.
* add model classes that test issue 3077.
* update changelog for #3077/"
realm-java,"Add quotes around terms in exceptions message (#3221)
Close #3217/Merge pull request #3090 from realm/merge-ecbacf-to-master
Fix merge from ecbacf to master/Use qualified name for model classes in generated code in order to avoid name conflict. (#3083)
* use qualified name for model classes in generated code in order to avoid name conflict.
* add model classes that test issue 3077.
* update changelog for #3077/"
realm-java,"Add quotes around terms in exceptions message (#3221)
Close #3217/Merge pull request #3090 from realm/merge-ecbacf-to-master
Fix merge from ecbacf to master/Use qualified name for model classes in generated code in order to avoid name conflict. (#3083)
* use qualified name for model classes in generated code in order to avoid name conflict.
* add model classes that test issue 3077.
* update changelog for #3077/"
realm-java,"Merge pull request #3090 from realm/merge-ecbacf-to-master
Fix merge from ecbacf to master/Use qualified name for model classes in generated code in order to avoid name conflict. (#3083)
* use qualified name for model classes in generated code in order to avoid name conflict.
* add model classes that test issue 3077.
* update changelog for #3077/Merge pull request #2948 from realm/lk/fix-typo
Fix typo and rename a test./Fix typo and rename a test./"
realm-java,Fixed unit tests./
realm-java,Fixed unit tests./
realm-java,"Fix listeners can exposing unsynchronized RealmResults (Async queries) (#2951)
When async queries are updated, they call listeners in a specific order. Before this commit this had a very subtle bug, so accessing synchronous RealmResults from inside a async RealmResult listener might hit a detached row accessor.
Reason being is that the Realm is advanced, then all listeners called in order, but RealmResults are not synchronised until just before listener is called.
This commit fixes this so all RealmResults are now synced before the listener is called./Remove optional APIs if dependencies don't meet (#2727)
* Add @OptionalAPI to mark a method as optional with dependencies.
* New bytecode transformer to remove an optional API if it doesn't
have enough dependencies.
* Modify gradle plugin.
* Mark the rx.Observable related APIs as optional.
* Add integration-tests module.
This is not the perfect solution since the RxObservableFactory is still
in the final result. But it is good enough for us to work around the
issue with Jackson and other lib which needs to do reflection on the
RealmObject./RealmResults.isLoaded description fix (#2896)
The Javadoc of RealmResults.isLoaded() is revised for the correct status according to a return value./Fixed grammar in exception message (#2827)/add a null check to addChangeListener and removeChangeListener (#2805)
* add a null check to addChangeListener and removeChangeListener in Realm and DynamicRealm (fixes #2772)
* reflect review comments/Removed all deprecated methods and fixed examples./Examples should use transaction blocks (#2800)
* Moving examples over to execute transaction
* Updating comments to use executeTransaction
* Use partial mocks for Realm#executeTransaction(...) and create additional tests to illustrate mock verification of Realm#executeTransaction(...).
Had to do this because of a problem with Powermock: https://github.com/jayway/powermock/issues/649/Javadoc for using Realm with ObservedOn() & SubscribedOn()  (#2787)
It is recommended to use Realm.where().find*Async() instead of the combination of ObservedOn()/SubscribedOn() to avoid Realm being accessed from different threads./"
realm-java,"Optimistic opening of a Realm file (#3013)
We have anecdotal evidence that multiple processes might be open for the same app. We have not been able to verify this, but the result matches the ""IncompatibleLockFile"" errors reported in #2459. This happens if the two processes have two versions of Realm (e.g. during app upgrades).
This PR is based on our assumption that such an overlap is not intentional and only happens because one process is started before the previous was completely shut down.
So this PR introduces an optimistic opening scheme where we retry for 3 second before crashing as before./"
realm-java,"JNI clean up (#3010)
* Enable -Wmissing-declarations and -Werror to ensure all global
functions are defined with a proper declaration. JNI function not
found problem can only be seen at run time, thus we need to do so.
* Add static keyword for local functions.
* Fix wrong JNI function declaration.
* Remove useless functions.
* TableView distinct should return void.
* Rename JNI cpp files./"
realm-java,"JNI clean up (#3010)
* Enable -Wmissing-declarations and -Werror to ensure all global
functions are defined with a proper declaration. JNI function not
found problem can only be seen at run time, thus we need to do so.
* Add static keyword for local functions.
* Fix wrong JNI function declaration.
* Remove useless functions.
* TableView distinct should return void.
* Rename JNI cpp files./Remove optional APIs if dependencies don't meet (#2727)
* Add @OptionalAPI to mark a method as optional with dependencies.
* New bytecode transformer to remove an optional API if it doesn't
have enough dependencies.
* Modify gradle plugin.
* Mark the rx.Observable related APIs as optional.
* Add integration-tests module.
This is not the perfect solution since the RxObservableFactory is still
in the final result. But it is good enough for us to work around the
issue with Jackson and other lib which needs to do reflection on the
RealmObject./Minor fix of using StringBuilder/Avoid Table.nativeToString/nativeRowToString (#2884)
Table::row_to_string Table::to_string are for debugging purpose only, it
calls string::substr which might truncate an UTF-8 string at any char.
Thus a crash could happend in JNI when converting to UTF-16.
This will only happen when user attach a debugger and the debugger is
trying to call Table.toString.
Close #2429/"
realm-java,"Merge pull request #3250 from realm/merge-f3b025-to-master
* Check transaction state for buld insertion (#3228)
* Throws if they are not called in a transaction.
* Test cases for buld insertion thread checking.
* Lint warnings fix.
Close #3173
* Clarify how insertOrUpdate behave for objects with primary keys. (#3241)
* Missing transaction in threading example (#3245)
Close #3244
* insert(): Correctly detect multiple objects with the same primary key  (#3239)
* Fix isLoaded JavaDoc (#3240)/Fix isLoaded JavaDoc (#3240)/"
realm-java,"Merge pull request #3250 from realm/merge-f3b025-to-master
* Check transaction state for buld insertion (#3228)
* Throws if they are not called in a transaction.
* Test cases for buld insertion thread checking.
* Lint warnings fix.
Close #3173
* Clarify how insertOrUpdate behave for objects with primary keys. (#3241)
* Missing transaction in threading example (#3245)
Close #3244
* insert(): Correctly detect multiple objects with the same primary key  (#3239)
* Fix isLoaded JavaDoc (#3240)/ PrimaryKey index rearrangement in migration revisited  (#2920)
This PR fixes two issues; 
1) When a column with a smaller index than that of a primary key field gets removed, the primary key field index decrements, which causes a cached primary key index to point a wrong field.
2) When a primary key field is renamed, the primary key meta table is not updated accordingly./Table.toString() shows PK detail (#2903)
To enhance toString() message for including PK information to debug Table./Avoid Table.nativeToString/nativeRowToString (#2884)
Table::row_to_string Table::to_string are for debugging purpose only, it
calls string::substr which might truncate an UTF-8 string at any char.
Thus a crash could happend in JNI when converting to UTF-16.
This will only happen when user attach a debugger and the debugger is
trying to call Table.toString.
Close #2429/"
realm-java,"Optimistic opening of a Realm file (#3013)
We have anecdotal evidence that multiple processes might be open for the same app. We have not been able to verify this, but the result matches the ""IncompatibleLockFile"" errors reported in #2459. This happens if the two processes have two versions of Realm (e.g. during app upgrades).
This PR is based on our assumption that such an overlap is not intentional and only happens because one process is started before the previous was completely shut down.
So this PR introduces an optimistic opening scheme where we retry for 3 second before crashing as before./JNI clean up (#3010)
* Enable -Wmissing-declarations and -Werror to ensure all global
functions are defined with a proper declaration. JNI function not
found problem can only be seen at run time, thus we need to do so.
* Add static keyword for local functions.
* Fix wrong JNI function declaration.
* Remove useless functions.
* TableView distinct should return void.
* Rename JNI cpp files./"
realm-java,"addPrimaryKey() on RealmObjectSchema misses Index addition. (#2832)
RealmObjectSchema.addPrimaryKey() is supposed to add a search index to its primary key field but it is currently missing. This is to fix the addition and removal of a search index related to primary key methods in RealmObjectSchema./"
realm-java,"Merge pull request #3250 from realm/merge-f3b025-to-master
* Check transaction state for buld insertion (#3228)
* Throws if they are not called in a transaction.
* Test cases for buld insertion thread checking.
* Lint warnings fix.
Close #3173
* Clarify how insertOrUpdate behave for objects with primary keys. (#3241)
* Missing transaction in threading example (#3245)
Close #3244
* insert(): Correctly detect multiple objects with the same primary key  (#3239)
* Fix isLoaded JavaDoc (#3240)/Check transaction state for buld insertion (#3228)
* Throws if they are not called in a transaction.
* Test cases for buld insertion thread checking.
* Lint warnings fix.
Close #3173/Allow empty collection to insert/insertOrUpdate(Collection) (#3106)
* added tests to reproduce #3103
* Fixed a crash when an empty `Collection` is passed to `insert()`/`insertOrUpdate()` (#3103).
* update the implementation
* update javadoc comment/Merge pull request #3090 from realm/merge-ecbacf-to-master
Fix merge from ecbacf to master/Fix async transaction problem when async query already exist. (#2780)
I have rewritten how async transactions works. Before they did this:
1) commitOnBackgroundThread() -> post REALM_CHANGED -> post onSuccess runnable
The problem with that approach was that the REALM_CHANGED would be swallowed if async queries existed which meant that the async transaction would call onSuccess on an old version of the Realm (making it look like it didn't work).
Instead we now do this:
2) commitOnBackgroundThread -> post runnable that calls HandlerController.handleAsyncTransactionCompleted(runnable)
The special runnable is treated as a combined REALM_CHANGED + Callback, which makes it possible for us to queue up callbacks until we are finally able to trigger all of them.
Unfortunately the Handler has poor support for this so it means that we no longer can detect if such a message is in the queue. This means that it introduces a slight chance of such a event plus a real REALM_CHANGED event to be in the message queue at the same time. I considered that acceptable (since it can already happen today), and since preventing this will introduce more complexity to something that is already entirely to complex./Remove optional APIs if dependencies don't meet (#2727)
* Add @OptionalAPI to mark a method as optional with dependencies.
* New bytecode transformer to remove an optional API if it doesn't
have enough dependencies.
* Modify gradle plugin.
* Mark the rx.Observable related APIs as optional.
* Add integration-tests module.
This is not the perfect solution since the RxObservableFactory is still
in the final result. But it is good enough for us to work around the
issue with Jackson and other lib which needs to do reflection on the
RealmObject./add a null check to addChangeListener and removeChangeListener (#2805)
* add a null check to addChangeListener and removeChangeListener in Realm and DynamicRealm (fixes #2772)
* reflect review comments/Fixed unit tests./Removed all deprecated methods and fixed examples./Examples should use transaction blocks (#2800)
* Moving examples over to execute transaction
* Updating comments to use executeTransaction
* Use partial mocks for Realm#executeTransaction(...) and create additional tests to illustrate mock verification of Realm#executeTransaction(...).
Had to do this because of a problem with Powermock: https://github.com/jayway/powermock/issues/649/"
realm-java,"Optimistic opening of a Realm file (#3013)
We have anecdotal evidence that multiple processes might be open for the same app. We have not been able to verify this, but the result matches the ""IncompatibleLockFile"" errors reported in #2459. This happens if the two processes have two versions of Realm (e.g. during app upgrades).
This PR is based on our assumption that such an overlap is not intentional and only happens because one process is started before the previous was completely shut down.
So this PR introduces an optimistic opening scheme where we retry for 3 second before crashing as before./JNI clean up (#3010)
* Enable -Wmissing-declarations and -Werror to ensure all global
functions are defined with a proper declaration. JNI function not
found problem can only be seen at run time, thus we need to do so.
* Add static keyword for local functions.
* Fix wrong JNI function declaration.
* Remove useless functions.
* TableView distinct should return void.
* Rename JNI cpp files./Print path info of File::AccessError (#2768)/"
realm-java,"Optimistic opening of a Realm file (#3013)
We have anecdotal evidence that multiple processes might be open for the same app. We have not been able to verify this, but the result matches the ""IncompatibleLockFile"" errors reported in #2459. This happens if the two processes have two versions of Realm (e.g. during app upgrades).
This PR is based on our assumption that such an overlap is not intentional and only happens because one process is started before the previous was completely shut down.
So this PR introduces an optimistic opening scheme where we retry for 3 second before crashing as before./"
realm-java,"JNI clean up (#3010)
* Enable -Wmissing-declarations and -Werror to ensure all global
functions are defined with a proper declaration. JNI function not
found problem can only be seen at run time, thus we need to do so.
* Add static keyword for local functions.
* Fix wrong JNI function declaration.
* Remove useless functions.
* TableView distinct should return void.
* Rename JNI cpp files./"
realm-java,Fix threading example/
realm-java,"add default value instruction support (#3462)
* add default value support to Table class
* Table#isNull() and TableView#isNull()
* use default value feature
* added a test to check if nullified link can be overwritten by default value
* removed duplicate thread check when constructing proxy objects (and small bugfix in setter of the list).
* added thread check
* reflect review comments
* reflect comment in JNI code/Allow to specify default value of the field in model's constructor (#3397)
* Allow to call its accessors, and replace its field accesses with accessor calls in model's constructor.
fixes #777
fixes #2536
* use field instead of checking transaction
* fix a bug that acceptDefaultValue is not set correctly
* reject default values when the getter of a model creates other model object
* add simple test for default value
* supports default value of model field
* supports default value of RealmList fields
* add tests for assignment in constructor and setter in constructor
* update javadoc comments of createObject
* always ignores the default value of primary key if the object is managed
* update javadoc
* add a test for default values handling in copyToRealm(). the last assertion of RealmTests.copyToRealm_defaultValuesAreIgnored() is failing now.
* refactor tests
* use isPrimaryKey()
* fix a bug that unexpected realm object is created by default value of RealmModel/RealmList fields
* remove extra ';' from generated code
* add more tests for default value
* fix tests
* fix a bug that creates unexpected objects
* rename internal methods
* update changelog
* update CHANGELOG
* review comments
* update CHANGELOG
* added a description of how proxy object should be created in the Javadoc comment of RealmProcessor/Create object without setting PK is not allowed (#3379)
* Create object without setting PK is not allowed
* createObject must be called with PK value when creating a object with
PK defined.
* Creating objects from JSON must have have corresponding PK defined in
the JSON object.
Known issue:
The default values for creating object from JSONStream will be differnt
from those created by createObject. Default values from default
constructor VS default values from core. This has to be addressed by #777/Fix a lint error in proxy classes when the 'minSdkVersion' of user's project is smaller than 11. (#3364)
fixes #3356/Nh/fixing 3105 (#3306)
* Fixing issue with Cyclic dependency insert or the existing copyToRealm, adding support for managed RealmObject/"
realm-java,"add default value instruction support (#3462)
* add default value support to Table class
* Table#isNull() and TableView#isNull()
* use default value feature
* added a test to check if nullified link can be overwritten by default value
* removed duplicate thread check when constructing proxy objects (and small bugfix in setter of the list).
* added thread check
* reflect review comments
* reflect comment in JNI code/Allow to specify default value of the field in model's constructor (#3397)
* Allow to call its accessors, and replace its field accesses with accessor calls in model's constructor.
fixes #777
fixes #2536
* use field instead of checking transaction
* fix a bug that acceptDefaultValue is not set correctly
* reject default values when the getter of a model creates other model object
* add simple test for default value
* supports default value of model field
* supports default value of RealmList fields
* add tests for assignment in constructor and setter in constructor
* update javadoc comments of createObject
* always ignores the default value of primary key if the object is managed
* update javadoc
* add a test for default values handling in copyToRealm(). the last assertion of RealmTests.copyToRealm_defaultValuesAreIgnored() is failing now.
* refactor tests
* use isPrimaryKey()
* fix a bug that unexpected realm object is created by default value of RealmModel/RealmList fields
* remove extra ';' from generated code
* add more tests for default value
* fix tests
* fix a bug that creates unexpected objects
* rename internal methods
* update changelog
* update CHANGELOG
* review comments
* update CHANGELOG
* added a description of how proxy object should be created in the Javadoc comment of RealmProcessor/Create object without setting PK is not allowed (#3379)
* Create object without setting PK is not allowed
* createObject must be called with PK value when creating a object with
PK defined.
* Creating objects from JSON must have have corresponding PK defined in
the JSON object.
Known issue:
The default values for creating object from JSONStream will be differnt
from those created by createObject. Default values from default
constructor VS default values from core. This has to be addressed by #777/Fix a lint error in proxy classes when the 'minSdkVersion' of user's project is smaller than 11. (#3364)
fixes #3356/Nh/fixing 3105 (#3306)
* Fixing issue with Cyclic dependency insert or the existing copyToRealm, adding support for managed RealmObject/"
realm-java,"Allow to specify default value of the field in model's constructor (#3397)
* Allow to call its accessors, and replace its field accesses with accessor calls in model's constructor.
fixes #777
fixes #2536
* use field instead of checking transaction
* fix a bug that acceptDefaultValue is not set correctly
* reject default values when the getter of a model creates other model object
* add simple test for default value
* supports default value of model field
* supports default value of RealmList fields
* add tests for assignment in constructor and setter in constructor
* update javadoc comments of createObject
* always ignores the default value of primary key if the object is managed
* update javadoc
* add a test for default values handling in copyToRealm(). the last assertion of RealmTests.copyToRealm_defaultValuesAreIgnored() is failing now.
* refactor tests
* use isPrimaryKey()
* fix a bug that unexpected realm object is created by default value of RealmModel/RealmList fields
* remove extra ';' from generated code
* add more tests for default value
* fix tests
* fix a bug that creates unexpected objects
* rename internal methods
* update changelog
* update CHANGELOG
* review comments
* update CHANGELOG
* added a description of how proxy object should be created in the Javadoc comment of RealmProcessor/Create object without setting PK is not allowed (#3379)
* Create object without setting PK is not allowed
* createObject must be called with PK value when creating a object with
PK defined.
* Creating objects from JSON must have have corresponding PK defined in
the JSON object.
Known issue:
The default values for creating object from JSONStream will be differnt
from those created by createObject. Default values from default
constructor VS default values from core. This has to be addressed by #777/"
realm-java,"Allow to specify default value of the field in model's constructor (#3397)
* Allow to call its accessors, and replace its field accesses with accessor calls in model's constructor.
fixes #777
fixes #2536
* use field instead of checking transaction
* fix a bug that acceptDefaultValue is not set correctly
* reject default values when the getter of a model creates other model object
* add simple test for default value
* supports default value of model field
* supports default value of RealmList fields
* add tests for assignment in constructor and setter in constructor
* update javadoc comments of createObject
* always ignores the default value of primary key if the object is managed
* update javadoc
* add a test for default values handling in copyToRealm(). the last assertion of RealmTests.copyToRealm_defaultValuesAreIgnored() is failing now.
* refactor tests
* use isPrimaryKey()
* fix a bug that unexpected realm object is created by default value of RealmModel/RealmList fields
* remove extra ';' from generated code
* add more tests for default value
* fix tests
* fix a bug that creates unexpected objects
* rename internal methods
* update changelog
* update CHANGELOG
* review comments
* update CHANGELOG
* added a description of how proxy object should be created in the Javadoc comment of RealmProcessor/"
realm-java,"Add cause to RealmMigrationNeededException (#3482)/Merge pull request #3349 from realm/mc/realm-file-excpetion
Add RealmFileException/Add RealmFileException
to replace RealmIOException and IncompatibleLockFileException. Also it
is mapped to the same name exception in ObjectStore to give user a
detailed kind of file exception./"
realm-java,"Wait all async tasks done before next test (#3319)
This is highly related with #1900.
Below things are still guaranteed by this change after commit async
transaction:
* When callback function called (onSuccess/onError), the background
Realm is closed.
* When any change listeners called, the background Realm is closed.
What is true now but it is not guaranteed in the future:
* Background Realm might not be closed before REALM_CHANGED sent (not
received).
Due to this, to avoid the flaky tests, we have to ensure all async tasks
quit peacefully before start the next test. This is implemented by wait
and check in the TestRealmConfigurationFactory.
NOTE: Any test, if the async tasks cannot be finished peacefully in a
certain time, it has to be considered as a problem and fixed.
This would be needed by OS notifications since Java won't have a precise
control of sending REALM_CHANGED anymore./"
realm-java,"Update core to 2.0.0-rc4 (#3384)
* And with some code cleanup.
* Throw an runtime exception when input java bytes array cannot be read.
* Update Object Store to solve the breaking change caused failure.
See https://github.com/realm/realm-object-store/pull/158
* Use '-O2' instead '-Os' since it seems a gcc bug hangs encryption releated
tests with '-Os' enabled in JNI build./Merge pull request #3322 from realm/merge-78ccde-to-master
Fix merge from 78ccde to master/"
realm-java,"Refactor RealmLog (#3643)
The motivation:
* The previous implementaion for JNI log needs calls like:
JNI -> Java -> JNI. It is not quite effecient for the most common case
-- log in JNI and sync.
* The previous log levels are bit confusing.
* util.cpp gets messy.
* The Logger class in Java gets confusing with the Logger from
core/sync.
So this commit makes below changes:
* Adds RealmLogger to replace Logger. Creates a adaptor to ensure the
subclass of Logger can still be used by the new system before we remove
the Logger class.
* Adds cpp namespace jni_impl and jni_util, and make log relevant code
belong to these two namepsaces.
* Moves the RealmLog to JNI.
* Implenment a default Android logger in native code.
* Add tag support for realm-java Logger. Java side is using tag
""REALM_JAVA"", JNI side is using tag ""REALM_JNI"" and sync is using tag
""REALM_CORE"".
* All tags share the same log level.
* Some cleanups.
* Fix #3528 When there is existing java logger, calling log after ThrowNew
will crash in native code because of a pending Java exception. It should be
avoided.
* Deprecate AndroidLogger./"
realm-java,"Update core to 2.0.0-rc4 (#3384)
* And with some code cleanup.
* Throw an runtime exception when input java bytes array cannot be read.
* Update Object Store to solve the breaking change caused failure.
See https://github.com/realm/realm-object-store/pull/158
* Use '-O2' instead '-Os' since it seems a gcc bug hangs encryption releated
tests with '-Os' enabled in JNI build./"
realm-java,"add default value instruction support (#3462)
* add default value support to Table class
* Table#isNull() and TableView#isNull()
* use default value feature
* added a test to check if nullified link can be overwritten by default value
* removed duplicate thread check when constructing proxy objects (and small bugfix in setter of the list).
* added thread check
* reflect review comments
* reflect comment in JNI code/"
realm-java,"add default value instruction support (#3462)
* add default value support to Table class
* Table#isNull() and TableView#isNull()
* use default value feature
* added a test to check if nullified link can be overwritten by default value
* removed duplicate thread check when constructing proxy objects (and small bugfix in setter of the list).
* added thread check
* reflect review comments
* reflect comment in JNI code/Create object without setting PK is not allowed (#3379)
* Create object without setting PK is not allowed
* createObject must be called with PK value when creating a object with
PK defined.
* Creating objects from JSON must have have corresponding PK defined in
the JSON object.
Known issue:
The default values for creating object from JSONStream will be differnt
from those created by createObject. Default values from default
constructor VS default values from core. This has to be addressed by #777/"
realm-java,"Minor grammar fixes (#3722)/Merge pull request #3557 from realm/merge-1e5e15-to-master
Fix merge from 1e5e15 to master/Fix native crash in DynamicRealmObject#setList() (#3550)/"
realm-java,"Merge pull request #3557 from realm/merge-1e5e15-to-master
Fix merge from 1e5e15 to master/Fix native crash in DynamicRealmObject#setList() (#3550)/"
realm-java,"Update core to 2.0.0-rc4 (#3384)
* And with some code cleanup.
* Throw an runtime exception when input java bytes array cannot be read.
* Update Object Store to solve the breaking change caused failure.
See https://github.com/realm/realm-object-store/pull/158
* Use '-O2' instead '-Os' since it seems a gcc bug hangs encryption releated
tests with '-Os' enabled in JNI build./"
realm-java,"Removing FIXMEs and create them as Github issues. (#130)/Allow to specify default value of the field in model's constructor (#3397)
* Allow to call its accessors, and replace its field accesses with accessor calls in model's constructor.
fixes #777
fixes #2536
* use field instead of checking transaction
* fix a bug that acceptDefaultValue is not set correctly
* reject default values when the getter of a model creates other model object
* add simple test for default value
* supports default value of model field
* supports default value of RealmList fields
* add tests for assignment in constructor and setter in constructor
* update javadoc comments of createObject
* always ignores the default value of primary key if the object is managed
* update javadoc
* add a test for default values handling in copyToRealm(). the last assertion of RealmTests.copyToRealm_defaultValuesAreIgnored() is failing now.
* refactor tests
* use isPrimaryKey()
* fix a bug that unexpected realm object is created by default value of RealmModel/RealmList fields
* remove extra ';' from generated code
* add more tests for default value
* fix tests
* fix a bug that creates unexpected objects
* rename internal methods
* update changelog
* update CHANGELOG
* review comments
* update CHANGELOG
* added a description of how proxy object should be created in the Javadoc comment of RealmProcessor/Merge pull request #3305 from realm/merge-e62d11-to-master
Fix merge from e62d11 to master/"
realm-java,"Refactor RealmLog (#3643)
The motivation:
* The previous implementaion for JNI log needs calls like:
JNI -> Java -> JNI. It is not quite effecient for the most common case
-- log in JNI and sync.
* The previous log levels are bit confusing.
* util.cpp gets messy.
* The Logger class in Java gets confusing with the Logger from
core/sync.
So this commit makes below changes:
* Adds RealmLogger to replace Logger. Creates a adaptor to ensure the
subclass of Logger can still be used by the new system before we remove
the Logger class.
* Adds cpp namespace jni_impl and jni_util, and make log relevant code
belong to these two namepsaces.
* Moves the RealmLog to JNI.
* Implenment a default Android logger in native code.
* Add tag support for realm-java Logger. Java side is using tag
""REALM_JAVA"", JNI side is using tag ""REALM_JNI"" and sync is using tag
""REALM_CORE"".
* All tags share the same log level.
* Some cleanups.
* Fix #3528 When there is existing java logger, calling log after ThrowNew
will crash in native code because of a pending Java exception. It should be
avoided.
* Deprecate AndroidLogger./fix temp directory name (#3653)/allow to put Realm database file on external storage. (#3591)
* set the path of the directory of named pipes to fix #3140
* update CHANGELOG
* add a test for issue3140
* update test
* follow the chenges in object-store
* skip an external storage test on the device where SELinux is not enforced
* rename test
* rename variable
* update object-store
* make SharedRealm#temporaryDirectory volatile
* address findbugs error/Fixed bug in path when getting access tokens for Realms (#157)/Add cause to RealmMigrationNeededException (#3482)/add default value instruction support (#3462)
* add default value support to Table class
* Table#isNull() and TableView#isNull()
* use default value feature
* added a test to check if nullified link can be overwritten by default value
* removed duplicate thread check when constructing proxy objects (and small bugfix in setter of the list).
* added thread check
* reflect review comments
* reflect comment in JNI code/Make RealmAsyncTask into an interface (#133)
* Make RealmAsyncTask into an interface
and move the implementation into internal package. Then we can create
the async task in different internal packages without exposing the
constructor to outside.
Part of fix for #125/Merge pull request #3459 from realm/merge-d73611-to-master
Fix merge from d73611 to master/fix merge mistakes/Allow to specify default value of the field in model's constructor (#3397)
* Allow to call its accessors, and replace its field accesses with accessor calls in model's constructor.
fixes #777
fixes #2536
* use field instead of checking transaction
* fix a bug that acceptDefaultValue is not set correctly
* reject default values when the getter of a model creates other model object
* add simple test for default value
* supports default value of model field
* supports default value of RealmList fields
* add tests for assignment in constructor and setter in constructor
* update javadoc comments of createObject
* always ignores the default value of primary key if the object is managed
* update javadoc
* add a test for default values handling in copyToRealm(). the last assertion of RealmTests.copyToRealm_defaultValuesAreIgnored() is failing now.
* refactor tests
* use isPrimaryKey()
* fix a bug that unexpected realm object is created by default value of RealmModel/RealmList fields
* remove extra ';' from generated code
* add more tests for default value
* fix tests
* fix a bug that creates unexpected objects
* rename internal methods
* update changelog
* update CHANGELOG
* review comments
* update CHANGELOG
* added a description of how proxy object should be created in the Javadoc comment of RealmProcessor/Create object without setting PK is not allowed (#3379)
* Create object without setting PK is not allowed
* createObject must be called with PK value when creating a object with
PK defined.
* Creating objects from JSON must have have corresponding PK defined in
the JSON object.
Known issue:
The default values for creating object from JSONStream will be differnt
from those created by createObject. Default values from default
constructor VS default values from core. This has to be addressed by #777/Integrate Object Store [PART4] - OS notifications (#3370)
* Use OS's notification mechanism to notify threads.
* Create RealmNotificer interface for decouple Android related handler
logic.
* Create AndroidNotifier for the handler notifications.
The major change of this PR is about the timing. The notifications are
not sent immediately after transaction committed. Instead, there is a
dedicated thread monitoring changes and notify others when changes
happen.
The known problem is for every RealmConfiguration, a monitor thread will
be created which is not ideal for app which is using multiple
RealmConfiguration.
There are different implementations for the monitoring thread in OS. For
Android, we can choose from generic which is based on the core's
wait_for_change() and android which is used by dotnet based on the
named pipe.
To align with dotnet, we are using the named pipe for now which also
enables notifications between realm-java and realm-dotnet./Merge pull request #3349 from realm/mc/realm-file-excpetion
Add RealmFileException/Add RealmFileException
to replace RealmIOException and IncompatibleLockFileException. Also it
is mapped to the same name exception in ObjectStore to give user a
detailed kind of file exception./Wait all async tasks done before next test (#3319)
This is highly related with #1900.
Below things are still guaranteed by this change after commit async
transaction:
* When callback function called (onSuccess/onError), the background
Realm is closed.
* When any change listeners called, the background Realm is closed.
What is true now but it is not guaranteed in the future:
* Background Realm might not be closed before REALM_CHANGED sent (not
received).
Due to this, to avoid the flaky tests, we have to ensure all async tasks
quit peacefully before start the next test. This is implemented by wait
and check in the TestRealmConfigurationFactory.
NOTE: Any test, if the async tasks cannot be finished peacefully in a
certain time, it has to be considered as a problem and fixed.
This would be needed by OS notifications since Java won't have a precise
control of sending REALM_CHANGED anymore./Merge pull request #3322 from realm/merge-78ccde-to-master
Fix merge from 78ccde to master/Nh/fixing 3105 (#3306)
* Fixing issue with Cyclic dependency insert or the existing copyToRealm, adding support for managed RealmObject/"
realm-java,Fix memory leak when unsubscribing from RxJava observables. (#3678)/
realm-java,"Nh/fix 3966 (#3979)
Realm migration is triggered, when the primary key definition is altered (#3966)/Java lint warnings with proxy class (#3948)
Fix #2929/Fixed a bug that caused unexpected MigrationNeededException in very rare case. (#3768)
In sync mode, `validateTable()` must get all fields in the tabla./"
realm-java,"Nh/fix 3966 (#3979)
Realm migration is triggered, when the primary key definition is altered (#3966)/Java lint warnings with proxy class (#3948)
Fix #2929/Fixed a bug that caused unexpected MigrationNeededException in very rare case. (#3768)
In sync mode, `validateTable()` must get all fields in the tabla./"
realm-java,"Nh/fix 3966 (#3979)
Realm migration is triggered, when the primary key definition is altered (#3966)/Java lint warnings with proxy class (#3948)
Fix #2929/Merge pull request #3840 from realm/merge-a8d647-to-master
Fix merge from a8d647 to master/Fixed a bug that caused unexpected MigrationNeededException in very rare case. (#3768)
In sync mode, `validateTable()` must get all fields in the tabla./"
realm-java,"Wait forever in debugging mode (#3943)
* Wait forever in debugging mode
It is quite annoy when we stop at a breakpoint the awaitOrFail timeout
happens. By checking if the debugger connected, we can know we are
actually debugging the test and don't want to be interrupted by the
timeout./"
realm-java,"Fix tests and remove unnecessary imports and fields. (#4125)
* Fix tests.
* Remove unnecessary imports and fields./"
realm-java,"Fix tests and remove unnecessary imports and fields. (#4125)
* Fix tests.
* Remove unnecessary imports and fields./"
realm-java,"SyncCredentials.accessToken + Integration tests (#4018)
This PR adds support for SyncCredentials.accessToken() which
is required for #4005. I also found a number of issues with
the integration tests. They have been fixed as well./"
realm-java,"SyncCredentials.accessToken + Integration tests (#4018)
This PR adds support for SyncCredentials.accessToken() which
is required for #4005. I also found a number of issues with
the integration tests. They have been fixed as well./"
realm-java,"Merge pull request #4065 from realm/merge-461c15-to-master
Fix merge from 461c15 to master/Nh/init metadata (#4053)
* init ObjectStore metadata, to store File Action
* avoid null pointer exception, by passing empty strings/SyncCredentials.accessToken + Integration tests (#4018)
This PR adds support for SyncCredentials.accessToken() which
is required for #4005. I also found a number of issues with
the integration tests. They have been fixed as well./Convert to annotations for findbugs exceptions
* Clean up code in SyncUser to eliminate FB exception
* Add usage for the config files, to the top level README.md
* Note UT findbugs failures/Update core to 2.3.0 (#3970)
Also update object-store to 99570ba6e0 .
* Adapt changes from sync
- Client::set_error_handler is removed.
- Session error handler signature changed.
* Session error handler called after destruction
- According to the doc of Session::set_error_handler, the error handler
could be called after the session object is destroyed. That is a problem
since the java session object can be destroyed at that time.
Use a weak_ptr of JavaGlobalRef in the lambda to solve the problem.
* Ignore unknown category error from sync/"
realm-java,"SyncCredentials.accessToken + Integration tests (#4018)
This PR adds support for SyncCredentials.accessToken() which
is required for #4005. I also found a number of issues with
the integration tests. They have been fixed as well./"
realm-java,"SyncCredentials.accessToken + Integration tests (#4018)
This PR adds support for SyncCredentials.accessToken() which
is required for #4005. I also found a number of issues with
the integration tests. They have been fixed as well./"
realm-java,"Nh/fix test (#3868)
* Fix SyncConfiguration test/"
realm-java,"Java doc, comments & exception message fix/Fix various minor issues/Fix lots of minor issues/Use RealmNotifier for RealmObject listener
Ideally we should use the object notifications from object store, but
since it is still in progress and the KVO notifications is not generic
enough for us to use (there are some logic issues), we simply use the
RealmNotifier to trigger the RealmObject listeners. There will be false
positive notifications with this implementation since we are only
checking the Row's table version. But this problem exists even before
this commit./Merge pull request #3984 from realm/merge-5d1d1f-to-master
Fix merge from 5d1d1f to master/Workaround for the Alooper and postAtFrontQueue
See https://github.com/realm/realm-java/issues/3883#issuecomment-265659475/Fix get DynamicRealmObject from RealmResults./Nh/fixes 3732 insertOrUpdate using other Realm (#3755)/"
realm-java,"Fix RealmCollection.contains not respecting custom equal methods (#4111)/Fix lots of minor issues/Fix test contains_realmObjectFromOtherRealm/RealmResults.distinct() returns a new RealmResults
Doing distinct on the original results creates lots of problems:
- It is not supported by OS.
- It won't play well with fine grained notifications.
- It has a different behaviour compared with RealmResults.sort()./Fix get DynamicRealmObject from RealmResults./Remove useless code
and fix one missed findAllxxx function./Fix contains & deleteAll/Handling Results exceptions. Adding support for contains/index_of/"
realm-java,"Fix various minor issues/Wire the ""like"" predicate into RealmQuery (#3992)
* Wire the ""like"" predicate into RealmQuery
Fixes  #3752/Merge pull request #3840 from realm/merge-a8d647-to-master
Fix merge from a8d647 to master/"
realm-java,"Merge pull request #4103 from realm/merge-4eec89-to-master
Fix merge from 4eec89 to master/Free the SharedRealm in phantom daemon (#4096)
Treat the SharedRealm the same as other native objects.
SharedRealm.close will only call Object Store Realm::close without
deleting the ShareRealm pointer.
Then we don't need the finalizer anymore. Fix #3730 .
This is related with
https://github.com/realm/realm-object-store/pull/318
as well. It is possible that java close the Realm in any of the Object Store's
callbacks. To avoid Object Store operating on a invalid SharedRealm
pointer, binding should try to make sure after callbacks. However, it
cannot be totally avoided since user could set the Realm instance to
null and the instance can be GCed at any time. It is still something
should be considered in the Object Store implementation./Merge pull request #3984 from realm/merge-5d1d1f-to-master
Fix merge from 5d1d1f to master/Merge pull request #3983 from realm/merge-a94bb3-to-master
Fix merge from a94bb3 to master/Enable -Werror and fix warnings (#3961)
Adapt the same warning options from object store/Fix concurrency problem with collection list/Workaround for the Alooper and postAtFrontQueue
See https://github.com/realm/realm-java/issues/3883#issuecomment-265659475/Hack with snapshot to support stable iterator
But something is going wrong, more like a bug in core than Object Store./"
realm-java,"Merge pull request #3840 from realm/merge-a8d647-to-master
Fix merge from a8d647 to master/"
realm-java,"Merge pull request #3840 from realm/merge-a8d647-to-master
Fix merge from a8d647 to master/"
realm-java,"Fix tests and remove unnecessary imports and fields. (#4125)
* Fix tests.
* Remove unnecessary imports and fields./"
realm-java,"Fix get DynamicRealmObject from RealmResults./Merge pull request #3840 from realm/merge-a8d647-to-master
Fix merge from a8d647 to master/"
realm-java,"Merge pull request #3840 from realm/merge-a8d647-to-master
Fix merge from a8d647 to master/"
realm-java,"Use getTargetTable to build query on linkview
otherwise RealmQueryTests.findFirst() will fail because it compares the
row with the tables' name first./Merge pull request #3840 from realm/merge-a8d647-to-master
Fix merge from a8d647 to master/"
realm-java,"Java doc, comments & exception message fix/fix transaction error of synced Realm./Merge pull request #3773 from realm/merge-ed0f18-to-master
Fix merge from ed0f18 to master/Nh/fixes 3732 insertOrUpdate using other Realm (#3755)/"
realm-java,"Fix typo on error message (#4113)/Fix typo on error message/Print the path when get File::AccessError (#4068)/Merge pull request #3983 from realm/merge-a94bb3-to-master
Fix merge from a94bb3 to master/Enable -Werror and fix warnings (#3961)
Adapt the same warning options from object store/RAII wrapper for some JNI resources (#3959)
* Move the global jvm pointer to JniUtils and add some helper functions.
* Wrapper for jmethodID, global weak ref.
* Refactor the wrapper for the local ref.
* Before using the global weak ref, always try to acquire a local ref
first since until Android 4.0 weak global references could only be
passed to NewLocalRef, NewGlobalRef, and DeleteWeakGlobalRef.
See https://developer.android.com/training/articles/perf-jni.html#unsupported
for more details. This fix #3726 ./Add the underlying information on RealmFileException. (#3940)
Add the underlying information on RealmFileException to help
investigating Incompatible lock file issue./Throw correct exception for multiple logged in users (#3921)/Convert IncorrectThreadException/Handling Results exceptions. Adding support for contains/index_of/"
realm-java,"RAII wrapper for some JNI resources (#3959)
* Move the global jvm pointer to JniUtils and add some helper functions.
* Wrapper for jmethodID, global weak ref.
* Refactor the wrapper for the local ref.
* Before using the global weak ref, always try to acquire a local ref
first since until Android 4.0 weak global references could only be
passed to NewLocalRef, NewGlobalRef, and DeleteWeakGlobalRef.
See https://developer.android.com/training/articles/perf-jni.html#unsupported
for more details. This fix #3726 ./Workaround for the Alooper and postAtFrontQueue
See https://github.com/realm/realm-java/issues/3883#issuecomment-265659475/"
realm-java,"RAII wrapper for some JNI resources (#3959)
* Move the global jvm pointer to JniUtils and add some helper functions.
* Wrapper for jmethodID, global weak ref.
* Refactor the wrapper for the local ref.
* Before using the global weak ref, always try to acquire a local ref
first since until Android 4.0 weak global references could only be
passed to NewLocalRef, NewGlobalRef, and DeleteWeakGlobalRef.
See https://developer.android.com/training/articles/perf-jni.html#unsupported
for more details. This fix #3726 ./"
realm-java,"Merge pull request #4065 from realm/merge-461c15-to-master
Fix merge from 461c15 to master/Nh/init metadata (#4053)
* init ObjectStore metadata, to store File Action
* avoid null pointer exception, by passing empty strings/Nh/fixes token renew (#4040)
* fixes #4039 and fixes #4038/Merge pull request #3983 from realm/merge-a94bb3-to-master
Fix merge from a94bb3 to master/Enable -Werror and fix warnings (#3961)
Adapt the same warning options from object store/Update core to 2.3.0 (#3970)
Also update object-store to 99570ba6e0 .
* Adapt changes from sync
- Client::set_error_handler is removed.
- Session error handler signature changed.
* Session error handler called after destruction
- According to the doc of Session::set_error_handler, the error handler
could be called after the session object is destroyed. That is a problem
since the java session object can be destroyed at that time.
Use a weak_ptr of JavaGlobalRef in the lambda to solve the problem.
* Ignore unknown category error from sync/RAII wrapper for some JNI resources (#3959)
* Move the global jvm pointer to JniUtils and add some helper functions.
* Wrapper for jmethodID, global weak ref.
* Refactor the wrapper for the local ref.
* Before using the global weak ref, always try to acquire a local ref
first since until Android 4.0 weak global references could only be
passed to NewLocalRef, NewGlobalRef, and DeleteWeakGlobalRef.
See https://developer.android.com/training/articles/perf-jni.html#unsupported
for more details. This fix #3726 ./Merge pull request #3917 from realm/merge-8c5f4c-to-master
Fix merge from 8c5f4c to master/Update core, sync and object store (#3904)
- Core to v2.2.0.
- Sync to v1.0.0-BETA-5.0.
- Adapt changes from latest object store.
- REALM_ENABLE_SYNC should be boolean macro
- Create Realm sync history without having a ObjectStore SyncConfig
object.
- deleteRealm test fix. The single notifier thread is enabled, the .note
file is not created in the Realm file directory anymore.
- Update ObjectStore submodule to 300a2d6f28 which is committed in 
https://github.com/realm/realm-object-store/pull/287/"
realm-java,"Merge pull request #3983 from realm/merge-a94bb3-to-master
Fix merge from a94bb3 to master/Enable -Werror and fix warnings (#3961)
Adapt the same warning options from object store/"
realm-java,"Merge pull request #4065 from realm/merge-461c15-to-master
Fix merge from 461c15 to master/Nh/init metadata (#4053)
* init ObjectStore metadata, to store File Action
* avoid null pointer exception, by passing empty strings/Merge pull request #3983 from realm/merge-a94bb3-to-master
Fix merge from a94bb3 to master/Enable -Werror and fix warnings (#3961)
Adapt the same warning options from object store/Update core to 2.3.0 (#3970)
Also update object-store to 99570ba6e0 .
* Adapt changes from sync
- Client::set_error_handler is removed.
- Session error handler signature changed.
* Session error handler called after destruction
- According to the doc of Session::set_error_handler, the error handler
could be called after the session object is destroyed. That is a problem
since the java session object can be destroyed at that time.
Use a weak_ptr of JavaGlobalRef in the lambda to solve the problem.
* Ignore unknown category error from sync/RAII wrapper for some JNI resources (#3959)
* Move the global jvm pointer to JniUtils and add some helper functions.
* Wrapper for jmethodID, global weak ref.
* Refactor the wrapper for the local ref.
* Before using the global weak ref, always try to acquire a local ref
first since until Android 4.0 weak global references could only be
passed to NewLocalRef, NewGlobalRef, and DeleteWeakGlobalRef.
See https://developer.android.com/training/articles/perf-jni.html#unsupported
for more details. This fix #3726 ./"
realm-java,"Fix Context leak warning in threadExample (#4580) (#4586)
* fix Context leak warning in threadExample (#4580)
* cancel task in onStop()
* add check if the fragment is attached to the UI
* add check if the fragment is attached to the UI
* cancel the task if parent fragment is detached/"
realm-java,"Feature/backlinks (#4406)
* Refactor RealmObjectSchema
Clean up Proxy generation
Comments addressed
* Fix Test, Checkstyle and Findbugs errors
* Respond to comments/Merge pull request #4348 from realm/merge-6d0712-to-master
Fix merge from 6d0712 to master/Merge pull request #4338 from realm/my/fix_warnings_in_proxy_classes
fix warnings in generated code/fix warnings in generated code/Backlinks (#4219)
*    Document multiple links to the same object
*    Fix non-object field reference bug
*    Load all tables before validating any
*    Update to gradle 3.4.1
*    Fix Documentation
*    Fix Asynchronous UTs
*    Ignore, instead of throwing on, attempts to load Backlink fields w/JSON
*    Fix documentation and add notification unit tests
*    Require that backlink fields be final.
*    Address PR comments
*    Add tests for notification and distinct
*    Add interface methods and most of table validation
*    Check @LinkingObjects fields on JSON load
*    Fix fails in RealmTests
*    Respond to comments
*    Compile time type checking    Refactor annotation handler
*    Improved error messages
*    Add Unit tests
*    Renamed Backlink to LinkingObjects. Added annotation processor tests.
*    Added annotation processor unit tests.
*    Add Backlink annotation/Crash when on constructor calls another with default values (#4253)/Fix default values crashing if calling another constructor (#4249)/Merge pull request #4213 from realm/merge-ffe5bd-to-master
Fix merge from ffe5bd to master/improve performance of getters and setters in proxy classes (#4206)
* improve performance of getters and setters in proxy classes
This change is a part of fixes of #3809.
* removed unused argment
* Update CHANGELOG.md/"
realm-java,"Feature/backlinks (#4406)
* Refactor RealmObjectSchema
Clean up Proxy generation
Comments addressed
* Fix Test, Checkstyle and Findbugs errors
* Respond to comments/Merge pull request #4348 from realm/merge-6d0712-to-master
Fix merge from 6d0712 to master/Merge pull request #4338 from realm/my/fix_warnings_in_proxy_classes
fix warnings in generated code/more fix for ErrorProne warnings in generated code/fix warnings in generated code/Backlinks (#4219)
*    Document multiple links to the same object
*    Fix non-object field reference bug
*    Load all tables before validating any
*    Update to gradle 3.4.1
*    Fix Documentation
*    Fix Asynchronous UTs
*    Ignore, instead of throwing on, attempts to load Backlink fields w/JSON
*    Fix documentation and add notification unit tests
*    Require that backlink fields be final.
*    Address PR comments
*    Add tests for notification and distinct
*    Add interface methods and most of table validation
*    Check @LinkingObjects fields on JSON load
*    Fix fails in RealmTests
*    Respond to comments
*    Compile time type checking    Refactor annotation handler
*    Improved error messages
*    Add Unit tests
*    Renamed Backlink to LinkingObjects. Added annotation processor tests.
*    Added annotation processor unit tests.
*    Add Backlink annotation/Crash when on constructor calls another with default values (#4253)/Fix default values crashing if calling another constructor (#4249)/Merge pull request #4213 from realm/merge-ffe5bd-to-master
Fix merge from ffe5bd to master/improve performance of getters and setters in proxy classes (#4206)
* improve performance of getters and setters in proxy classes
This change is a part of fixes of #3809.
* removed unused argment
* Update CHANGELOG.md/"
realm-java,"Fix exception thrown from backlinks field (#4500)
* add test case that reproduce #4499
* now backlinks geters throw IllegalStateException if the object is deleted or not yet loaded.
* update CHANGELOG
* add test
* update a test
* modify method name Row.checkIfBacklinkAvailable() to Row.checkIfAttached()
* update variable names in test/Feature/backlinks (#4406)
* Refactor RealmObjectSchema
Clean up Proxy generation
Comments addressed
* Fix Test, Checkstyle and Findbugs errors
* Respond to comments/Merge pull request #4348 from realm/merge-6d0712-to-master
Fix merge from 6d0712 to master/Merge pull request #4338 from realm/my/fix_warnings_in_proxy_classes
fix warnings in generated code/more fix for ErrorProne warnings in generated code/fix warnings in generated code/Backlinks (#4219)
*    Document multiple links to the same object
*    Fix non-object field reference bug
*    Load all tables before validating any
*    Update to gradle 3.4.1
*    Fix Documentation
*    Fix Asynchronous UTs
*    Ignore, instead of throwing on, attempts to load Backlink fields w/JSON
*    Fix documentation and add notification unit tests
*    Require that backlink fields be final.
*    Address PR comments
*    Add tests for notification and distinct
*    Add interface methods and most of table validation
*    Check @LinkingObjects fields on JSON load
*    Fix fails in RealmTests
*    Respond to comments
*    Compile time type checking    Refactor annotation handler
*    Improved error messages
*    Add Unit tests
*    Renamed Backlink to LinkingObjects. Added annotation processor tests.
*    Added annotation processor unit tests.
*    Add Backlink annotation/Crash when on constructor calls another with default values (#4253)/Fix default values crashing if calling another constructor (#4249)/Merge pull request #4213 from realm/merge-ffe5bd-to-master
Fix merge from ffe5bd to master/improve performance of getters and setters in proxy classes (#4206)
* improve performance of getters and setters in proxy classes
This change is a part of fixes of #3809.
* removed unused argment
* Update CHANGELOG.md/"
realm-java,"Backlinks (#4219)
*    Document multiple links to the same object
*    Fix non-object field reference bug
*    Load all tables before validating any
*    Update to gradle 3.4.1
*    Fix Documentation
*    Fix Asynchronous UTs
*    Ignore, instead of throwing on, attempts to load Backlink fields w/JSON
*    Fix documentation and add notification unit tests
*    Require that backlink fields be final.
*    Address PR comments
*    Add tests for notification and distinct
*    Add interface methods and most of table validation
*    Check @LinkingObjects fields on JSON load
*    Fix fails in RealmTests
*    Respond to comments
*    Compile time type checking    Refactor annotation handler
*    Improved error messages
*    Add Unit tests
*    Renamed Backlink to LinkingObjects. Added annotation processor tests.
*    Added annotation processor unit tests.
*    Add Backlink annotation/"
realm-java,"Backlinks (#4219)
*    Document multiple links to the same object
*    Fix non-object field reference bug
*    Load all tables before validating any
*    Update to gradle 3.4.1
*    Fix Documentation
*    Fix Asynchronous UTs
*    Ignore, instead of throwing on, attempts to load Backlink fields w/JSON
*    Fix documentation and add notification unit tests
*    Require that backlink fields be final.
*    Address PR comments
*    Add tests for notification and distinct
*    Add interface methods and most of table validation
*    Check @LinkingObjects fields on JSON load
*    Fix fails in RealmTests
*    Respond to comments
*    Compile time type checking    Refactor annotation handler
*    Improved error messages
*    Add Unit tests
*    Renamed Backlink to LinkingObjects. Added annotation processor tests.
*    Added annotation processor unit tests.
*    Add Backlink annotation/"
realm-java,"Resume sending update messages (#4419)
Fixes #4418/Backlinks (#4219)
*    Document multiple links to the same object
*    Fix non-object field reference bug
*    Load all tables before validating any
*    Update to gradle 3.4.1
*    Fix Documentation
*    Fix Asynchronous UTs
*    Ignore, instead of throwing on, attempts to load Backlink fields w/JSON
*    Fix documentation and add notification unit tests
*    Require that backlink fields be final.
*    Address PR comments
*    Add tests for notification and distinct
*    Add interface methods and most of table validation
*    Check @LinkingObjects fields on JSON load
*    Fix fails in RealmTests
*    Respond to comments
*    Compile time type checking    Refactor annotation handler
*    Improved error messages
*    Add Unit tests
*    Renamed Backlink to LinkingObjects. Added annotation processor tests.
*    Added annotation processor unit tests.
*    Add Backlink annotation/"
realm-java,"Merge pull request #4584 from realm/merge-f3f8ab-to-master
Fix merge from f3f8ab to master/Fix threading bugs in RunInLooperThread rule (#4563)
* Fix threading bugs in RunInLooperThread rule
* Respond to comments
Fix spelling errors
Clean up multi-error recovery./Feature/backlinks (#4406)
* Refactor RealmObjectSchema
Clean up Proxy generation
Comments addressed
* Fix Test, Checkstyle and Findbugs errors
* Respond to comments/Merge pull request #4354 from realm/merge-52ba43-to-master
Fix merge from 52ba43 to master/Introduce ErrorProne plugin (#4342)/Merge pull request #4340 from realm/merge-154419-to-master
Fix merge from 154419 to master/Fix warnings from error prone plugin https://github.com/tbroyer/gradle-errorprone-plugin (#4339)
This PR does not add the plugin, just fix the warnings.
I'll add the plugin in another PR with suppressing some warnings./"
realm-java,Proper RealmMigrationNeededException is now thrown. (#4304)/
realm-java,"Merge pull request #4584 from realm/merge-f3f8ab-to-master
Fix merge from f3f8ab to master/"
realm-java,"Implement getInstanceAsync (#4570)
Fix #2299
- Add APIs to get Realm instance asynchronously.
- Remove some useless methods.
There some work need to be done before create the first Realm instance
in the process, like creating schema table, doing migration, etc.. Those
could block the UI thread quite badly. This commit tries to do those
initialization work in the background and hold a Realm instance in the
background until the 2nd instance created in the caller thread.
A better solution than this would be do initialization in the
background and only deliver a column indices cache to caller thread
without holding a Realm instance in the background. But that is not
possible since from the current database design, we cannot know if the
schema changes compared with the last time it was opened.
Also create a SharedGroup in the background and handover it to the
caller thread is not ideal as well. That not only requires some design
changes in the Object Store RealmCoordinator, but also is a very
special use case of SharedGroup which core is not designed for.
SharedGroup Leaking during the handover is another flaw for this
solution -- we can only rely on the GC to collect the leaked SharedGroup
during handover then./Fix threading bugs in RunInLooperThread rule (#4563)
* Fix threading bugs in RunInLooperThread rule
* Respond to comments
Fix spelling errors
Clean up multi-error recovery./Backlinks (#4219)
*    Document multiple links to the same object
*    Fix non-object field reference bug
*    Load all tables before validating any
*    Update to gradle 3.4.1
*    Fix Documentation
*    Fix Asynchronous UTs
*    Ignore, instead of throwing on, attempts to load Backlink fields w/JSON
*    Fix documentation and add notification unit tests
*    Require that backlink fields be final.
*    Address PR comments
*    Add tests for notification and distinct
*    Add interface methods and most of table validation
*    Check @LinkingObjects fields on JSON load
*    Fix fails in RealmTests
*    Respond to comments
*    Compile time type checking    Refactor annotation handler
*    Improved error messages
*    Add Unit tests
*    Renamed Backlink to LinkingObjects. Added annotation processor tests.
*    Added annotation processor unit tests.
*    Add Backlink annotation/"
realm-java,"remove breaking changes in SyncSession.ErrorHandler (#4408)
* remove breaking changes in SyncSession.ErrorHandler
* update CHANGELOG
* update JNI file
* update CMakeLists.txt
* address review comments/"
realm-java,"Merge pull request #4348 from realm/merge-6d0712-to-master
Fix merge from 6d0712 to master/fix warnings reported by ErrorProne (#4341)/"
realm-java,"Implement getInstanceAsync (#4570)
Fix #2299
- Add APIs to get Realm instance asynchronously.
- Remove some useless methods.
There some work need to be done before create the first Realm instance
in the process, like creating schema table, doing migration, etc.. Those
could block the UI thread quite badly. This commit tries to do those
initialization work in the background and hold a Realm instance in the
background until the 2nd instance created in the caller thread.
A better solution than this would be do initialization in the
background and only deliver a column indices cache to caller thread
without holding a Realm instance in the background. But that is not
possible since from the current database design, we cannot know if the
schema changes compared with the last time it was opened.
Also create a SharedGroup in the background and handover it to the
caller thread is not ideal as well. That not only requires some design
changes in the Object Store RealmCoordinator, but also is a very
special use case of SharedGroup which core is not designed for.
SharedGroup Leaking during the handover is another flaw for this
solution -- we can only rely on the GC to collect the leaked SharedGroup
during handover then./Fine grained locks for RealmCache (#4551)
- Separated lock for different RealmConfiguration instead of one lock on
the RealmCache class. So Opening Realm instances from different
configurations won't block each other.
- DynamicRealm which is created during opening type Realm will not be
associated to any RealmCache to avoid recursive locks and multiple
times initial block. (Also make the code easier.)
This is for #4536 and part of implementation of #2299 ./Merge branch 'releases' into my/fix_memory_leaking/Merge pull request #4475 from realm/merge-196ee5-to-master
Fix merge from 196ee5 to master/fix API incompatibility introduced in 3.1.0 (#4455)/Feature/backlinks (#4406)
* Refactor RealmObjectSchema
Clean up Proxy generation
Comments addressed
* Fix Test, Checkstyle and Findbugs errors
* Respond to comments/Refactor Schemas into separate native and realm-based implementations (#4382)
* Refactor Schemas into separate native and realm-based implementations
* Fix all tests
* Respond to PR comments
* Temporary (git add .) kludge to fix visiblity problem/Add detailed notification for RealmObject (#4331)
See #4101
- Add ObjectChangeSet & RealmObjectChangeListener.
- Add OsObject to wrap ObjectStore's Object for notifications.
- No more false positive notifications for RealmObject.
- Use ObserverPairList in ProxyState instead of normal list to solve the
potential listener removal problems which is handled well by the
ObserverPairList.
- Fix tests./Fail Realm.migrateRealm() if a SyncConfiguration is used. (#4292)/Implement fine gained notification (#4191)
- Add RealmObservable and RealmCollectionObservable interfaces.
- Enable detailed change information for RealmResults through
OrderedCollectionChange interface.
- Fix a bug in the ObserverPairList which could cause the removed
listener gets called if it was removed during previous listener
iteration.
Fix #989/"
realm-java,"Merge pull request #4465 from realm/my/fix_memory_leaking
My/fix memory leaking/Feature/backlinks (#4406)
* Refactor RealmObjectSchema
Clean up Proxy generation
Comments addressed
* Fix Test, Checkstyle and Findbugs errors
* Respond to comments/"
realm-java,"Merge pull request #4340 from realm/merge-154419-to-master
Fix merge from 154419 to master/Fix warnings from error prone plugin https://github.com/tbroyer/gradle-errorprone-plugin (#4339)
This PR does not add the plugin, just fix the warnings.
I'll add the plugin in another PR with suppressing some warnings./Backlinks (#4219)
*    Document multiple links to the same object
*    Fix non-object field reference bug
*    Load all tables before validating any
*    Update to gradle 3.4.1
*    Fix Documentation
*    Fix Asynchronous UTs
*    Ignore, instead of throwing on, attempts to load Backlink fields w/JSON
*    Fix documentation and add notification unit tests
*    Require that backlink fields be final.
*    Address PR comments
*    Add tests for notification and distinct
*    Add interface methods and most of table validation
*    Check @LinkingObjects fields on JSON load
*    Fix fails in RealmTests
*    Respond to comments
*    Compile time type checking    Refactor annotation handler
*    Improved error messages
*    Add Unit tests
*    Renamed Backlink to LinkingObjects. Added annotation processor tests.
*    Added annotation processor unit tests.
*    Add Backlink annotation/Implement fine gained notification (#4191)
- Add RealmObservable and RealmCollectionObservable interfaces.
- Enable detailed change information for RealmResults through
OrderedCollectionChange interface.
- Fix a bug in the ObserverPairList which could cause the removed
listener gets called if it was removed during previous listener
iteration.
Fix #989/Fix typo and exception message/RealmResults is always live-to-updated
This is the precondition of fine grained notifications. OS will trigger
the collection notification immediately when transaction begins on the
local thread to compute the change set if there is any. This conflicts
with Java's original RealmResults behavior -- the original RealmResults
would only be synced in the next event loop.
Also, there are some edge cases don't work well with the original
RealmResults behavior, see details in #3833.
So:
- RealmResults becomes always up-to-date again which means it will
never contains a invalid row.
- Behavior of iteration on a RealmResults still just works, it will just
iterate on snapshot of collection. This means user can still delete
elements from a RealmResults inside iteration.
- Deletion & Modification on RealmResults in simple-for-loop won't work
as expected if the changes will impact the order/elements of the
results. This could be solved by the future new Collection type
RealmCollectionSnapshot.
- Add Collection.load() and Collection.isLoaded() to support java sync
queries.
- Test fix.
- https://github.com/realm/realm-android-adapters/issues/48 won't be an
issue anymore since the RealmResults is always up to date and it won't
contain any invalid rows. So remove the related tests.
- Failure tests caused by listener being triggred with beginTransaction()
- Remove realmResultsListenerAddedAfterCommit.
when add listener to the OS Results after commit transaction, the
OS CollectionNotifier will be created at the SharedGroup version
of transaction committed. So the listener won't be called anymore since
the all changes already exist in current SharedGroup./Fix merge from 97fdf6 to master (#4156)
* Release v2.3.1
* Prepare next release v2.3.2-SNAPSHOT
* Nh/refresh access token (#4147)
* Add a timer to refresh the access_token before it expires/"
realm-java,"Merge branch 'releases' into my/fix_memory_leaking/Merge pull request #4475 from realm/merge-196ee5-to-master
Fix merge from 196ee5 to master/fix API incompatibility introduced in 3.1.0 (#4455)/Hide StandardRealmSchema class from public API. (#4444)
fixes #4443
* add package private methods to RealmSchema instead of BaseRealm.getSchemaInternal()./Feature/backlinks (#4406)
* Refactor RealmObjectSchema
Clean up Proxy generation
Comments addressed
* Fix Test, Checkstyle and Findbugs errors
* Respond to comments/Refactor Schemas into separate native and realm-based implementations (#4382)
* Refactor Schemas into separate native and realm-based implementations
* Fix all tests
* Respond to PR comments
* Temporary (git add .) kludge to fix visiblity problem/Backlinks (#4219)
*    Document multiple links to the same object
*    Fix non-object field reference bug
*    Load all tables before validating any
*    Update to gradle 3.4.1
*    Fix Documentation
*    Fix Asynchronous UTs
*    Ignore, instead of throwing on, attempts to load Backlink fields w/JSON
*    Fix documentation and add notification unit tests
*    Require that backlink fields be final.
*    Address PR comments
*    Add tests for notification and distinct
*    Add interface methods and most of table validation
*    Check @LinkingObjects fields on JSON load
*    Fix fails in RealmTests
*    Respond to comments
*    Compile time type checking    Refactor annotation handler
*    Improved error messages
*    Add Unit tests
*    Renamed Backlink to LinkingObjects. Added annotation processor tests.
*    Added annotation processor unit tests.
*    Add Backlink annotation/Merge pull request #4179 from CDRussell/master
Error message gives wrong class name character limit/Fix error message to show correct character limit and minor grammar fix/"
realm-java,"Feature/backlinks (#4406)
* Refactor RealmObjectSchema
Clean up Proxy generation
Comments addressed
* Fix Test, Checkstyle and Findbugs errors
* Respond to comments/"
realm-java,"Clean up SharedRealm source
- Remove unused methods.
- Fix double negatives.
- Use auto& to avoid creating temp objects./Dont reset SharedRealm ptr (#4478)
- Keep the SharedRealm ptr valid when close it. To allow the is_closed
checking could throw in the Object Store and it can be converted to a
friendly Java exception.
- Check if SharedRealm is closed when create collection iterator. Throw
an ISE if it is. Fix #4471 ./Refactor Schemas into separate native and realm-based implementations (#4382)
* Refactor Schemas into separate native and realm-based implementations
* Fix all tests
* Respond to PR comments
* Temporary (git add .) kludge to fix visiblity problem/Add detailed notification for RealmObject (#4331)
See #4101
- Add ObjectChangeSet & RealmObjectChangeListener.
- Add OsObject to wrap ObjectStore's Object for notifications.
- No more false positive notifications for RealmObject.
- Use ObserverPairList in ProxyState instead of normal list to solve the
potential listener removal problems which is handled well by the
ObserverPairList.
- Fix tests./RealmResults is always live-to-updated
This is the precondition of fine grained notifications. OS will trigger
the collection notification immediately when transaction begins on the
local thread to compute the change set if there is any. This conflicts
with Java's original RealmResults behavior -- the original RealmResults
would only be synced in the next event loop.
Also, there are some edge cases don't work well with the original
RealmResults behavior, see details in #3833.
So:
- RealmResults becomes always up-to-date again which means it will
never contains a invalid row.
- Behavior of iteration on a RealmResults still just works, it will just
iterate on snapshot of collection. This means user can still delete
elements from a RealmResults inside iteration.
- Deletion & Modification on RealmResults in simple-for-loop won't work
as expected if the changes will impact the order/elements of the
results. This could be solved by the future new Collection type
RealmCollectionSnapshot.
- Add Collection.load() and Collection.isLoaded() to support java sync
queries.
- Test fix.
- https://github.com/realm/realm-android-adapters/issues/48 won't be an
issue anymore since the RealmResults is always up to date and it won't
contain any invalid rows. So remove the related tests.
- Failure tests caused by listener being triggred with beginTransaction()
- Remove realmResultsListenerAddedAfterCommit.
when add listener to the OS Results after commit transaction, the
OS CollectionNotifier will be created at the SharedGroup version
of transaction committed. So the listener won't be called anymore since
the all changes already exist in current SharedGroup./"
realm-java,"Fix exception thrown from backlinks field (#4500)
* add test case that reproduce #4499
* now backlinks geters throw IllegalStateException if the object is deleted or not yet loaded.
* update CHANGELOG
* add test
* update a test
* modify method name Row.checkIfBacklinkAvailable() to Row.checkIfAttached()
* update variable names in test/Merge pull request #4265 from realm/merge-3b3364-to-master
Fix merge from 3b3364 to master/Fixed element type checking in DynamicRealmOject#setList(). (#4254)
* Fixed element type checking in DynamicRealmOject#setList() (#4252).
* Update CHANGELOG.md
* PR fixes
* PR fixes/"
realm-java,"Merge pull request #4340 from realm/merge-154419-to-master
Fix merge from 154419 to master/Fix warnings from error prone plugin https://github.com/tbroyer/gradle-errorprone-plugin (#4339)
This PR does not add the plugin, just fix the warnings.
I'll add the plugin in another PR with suppressing some warnings./Backlinks (#4219)
*    Document multiple links to the same object
*    Fix non-object field reference bug
*    Load all tables before validating any
*    Update to gradle 3.4.1
*    Fix Documentation
*    Fix Asynchronous UTs
*    Ignore, instead of throwing on, attempts to load Backlink fields w/JSON
*    Fix documentation and add notification unit tests
*    Require that backlink fields be final.
*    Address PR comments
*    Add tests for notification and distinct
*    Add interface methods and most of table validation
*    Check @LinkingObjects fields on JSON load
*    Fix fails in RealmTests
*    Respond to comments
*    Compile time type checking    Refactor annotation handler
*    Improved error messages
*    Add Unit tests
*    Renamed Backlink to LinkingObjects. Added annotation processor tests.
*    Added annotation processor unit tests.
*    Add Backlink annotation/"
realm-java,"Merge pull request #4340 from realm/merge-154419-to-master
Fix merge from 154419 to master/Fix warnings from error prone plugin https://github.com/tbroyer/gradle-errorprone-plugin (#4339)
This PR does not add the plugin, just fix the warnings.
I'll add the plugin in another PR with suppressing some warnings./"
realm-java,"Fix exception thrown from backlinks field (#4500)
* add test case that reproduce #4499
* now backlinks geters throw IllegalStateException if the object is deleted or not yet loaded.
* update CHANGELOG
* add test
* update a test
* modify method name Row.checkIfBacklinkAvailable() to Row.checkIfAttached()
* update variable names in test/Backlinks (#4219)
*    Document multiple links to the same object
*    Fix non-object field reference bug
*    Load all tables before validating any
*    Update to gradle 3.4.1
*    Fix Documentation
*    Fix Asynchronous UTs
*    Ignore, instead of throwing on, attempts to load Backlink fields w/JSON
*    Fix documentation and add notification unit tests
*    Require that backlink fields be final.
*    Address PR comments
*    Add tests for notification and distinct
*    Add interface methods and most of table validation
*    Check @LinkingObjects fields on JSON load
*    Fix fails in RealmTests
*    Respond to comments
*    Compile time type checking    Refactor annotation handler
*    Improved error messages
*    Add Unit tests
*    Renamed Backlink to LinkingObjects. Added annotation processor tests.
*    Added annotation processor unit tests.
*    Add Backlink annotation/"
realm-java,"Fix exception thrown from backlinks field (#4500)
* add test case that reproduce #4499
* now backlinks geters throw IllegalStateException if the object is deleted or not yet loaded.
* update CHANGELOG
* add test
* update a test
* modify method name Row.checkIfBacklinkAvailable() to Row.checkIfAttached()
* update variable names in test/"
realm-java,"Use target table to create snapshot from LinkView (#4556)
- Fix #4554 .
- Remove useless confusing `LinkView.getTable()`./"
realm-java,"Feature/backlinks (#4406)
* Refactor RealmObjectSchema
Clean up Proxy generation
Comments addressed
* Fix Test, Checkstyle and Findbugs errors
* Respond to comments/"
realm-java,"Merge pull request #4354 from realm/merge-52ba43-to-master
Fix merge from 52ba43 to master/Introduce ErrorProne plugin (#4342)/Merge pull request #4340 from realm/merge-154419-to-master
Fix merge from 154419 to master/Fix warnings from error prone plugin https://github.com/tbroyer/gradle-errorprone-plugin (#4339)
This PR does not add the plugin, just fix the warnings.
I'll add the plugin in another PR with suppressing some warnings./"
realm-java,"Merge branch 'releases' into my/fix_memory_leaking/Merge pull request #4475 from realm/merge-196ee5-to-master
Fix merge from 196ee5 to master/fix API incompatibility introduced in 3.1.0 (#4455)/Feature/backlinks (#4406)
* Refactor RealmObjectSchema
Clean up Proxy generation
Comments addressed
* Fix Test, Checkstyle and Findbugs errors
* Respond to comments/Refactor Schemas into separate native and realm-based implementations (#4382)
* Refactor Schemas into separate native and realm-based implementations
* Fix all tests
* Respond to PR comments
* Temporary (git add .) kludge to fix visiblity problem/Backlinks (#4219)
*    Document multiple links to the same object
*    Fix non-object field reference bug
*    Load all tables before validating any
*    Update to gradle 3.4.1
*    Fix Documentation
*    Fix Asynchronous UTs
*    Ignore, instead of throwing on, attempts to load Backlink fields w/JSON
*    Fix documentation and add notification unit tests
*    Require that backlink fields be final.
*    Address PR comments
*    Add tests for notification and distinct
*    Add interface methods and most of table validation
*    Check @LinkingObjects fields on JSON load
*    Fix fails in RealmTests
*    Respond to comments
*    Compile time type checking    Refactor annotation handler
*    Improved error messages
*    Add Unit tests
*    Renamed Backlink to LinkingObjects. Added annotation processor tests.
*    Added annotation processor unit tests.
*    Add Backlink annotation/Merge pull request #4179 from CDRussell/master
Error message gives wrong class name character limit/Fix error message to show correct character limit and minor grammar fix/"
realm-java,"Set log level for core logger bridge (#4389)
Set the all core logger bridges log level with the global log level.
Fix #4337/"
realm-java,"Implement getInstanceAsync (#4570)
Fix #2299
- Add APIs to get Realm instance asynchronously.
- Remove some useless methods.
There some work need to be done before create the first Realm instance
in the process, like creating schema table, doing migration, etc.. Those
could block the UI thread quite badly. This commit tries to do those
initialization work in the background and hold a Realm instance in the
background until the 2nd instance created in the caller thread.
A better solution than this would be do initialization in the
background and only deliver a column indices cache to caller thread
without holding a Realm instance in the background. But that is not
possible since from the current database design, we cannot know if the
schema changes compared with the last time it was opened.
Also create a SharedGroup in the background and handover it to the
caller thread is not ideal as well. That not only requires some design
changes in the Object Store RealmCoordinator, but also is a very
special use case of SharedGroup which core is not designed for.
SharedGroup Leaking during the handover is another flaw for this
solution -- we can only rely on the GC to collect the leaked SharedGroup
during handover then./Fine grained locks for RealmCache (#4551)
- Separated lock for different RealmConfiguration instead of one lock on
the RealmCache class. So Opening Realm instances from different
configurations won't block each other.
- DynamicRealm which is created during opening type Realm will not be
associated to any RealmCache to avoid recursive locks and multiple
times initial block. (Also make the code easier.)
This is for #4536 and part of implementation of #2299 ./Merge pull request #4566 from realm/merge-7ae1ee-to-master
Fix merge from 7ae1ee to master/Merge pull request #4465 from realm/my/fix_memory_leaking
My/fix memory leaking/address findbugs warnings/Fix OsRealmSchema leak (#4422)/Feature/backlinks (#4406)
* Refactor RealmObjectSchema
Clean up Proxy generation
Comments addressed
* Fix Test, Checkstyle and Findbugs errors
* Respond to comments/Refactor Schemas into separate native and realm-based implementations (#4382)
* Refactor Schemas into separate native and realm-based implementations
* Fix all tests
* Respond to PR comments
* Temporary (git add .) kludge to fix visiblity problem/Backlinks (#4219)
*    Document multiple links to the same object
*    Fix non-object field reference bug
*    Load all tables before validating any
*    Update to gradle 3.4.1
*    Fix Documentation
*    Fix Asynchronous UTs
*    Ignore, instead of throwing on, attempts to load Backlink fields w/JSON
*    Fix documentation and add notification unit tests
*    Require that backlink fields be final.
*    Address PR comments
*    Add tests for notification and distinct
*    Add interface methods and most of table validation
*    Check @LinkingObjects fields on JSON load
*    Fix fails in RealmTests
*    Respond to comments
*    Compile time type checking    Refactor annotation handler
*    Improved error messages
*    Add Unit tests
*    Renamed Backlink to LinkingObjects. Added annotation processor tests.
*    Added annotation processor unit tests.
*    Add Backlink annotation/Proper RealmMigrationNeededException is now thrown. (#4304)/Implement fine gained notification (#4191)
- Add RealmObservable and RealmCollectionObservable interfaces.
- Enable detailed change information for RealmResults through
OrderedCollectionChange interface.
- Fix a bug in the ObserverPairList which could cause the removed
listener gets called if it was removed during previous listener
iteration.
Fix #989/"
realm-java,"Add detailed notification for RealmObject (#4331)
See #4101
- Add ObjectChangeSet & RealmObjectChangeListener.
- Add OsObject to wrap ObjectStore's Object for notifications.
- No more false positive notifications for RealmObject.
- Use ObserverPairList in ProxyState instead of normal list to solve the
potential listener removal problems which is handled well by the
ObserverPairList.
- Fix tests./Merge pull request #4309 from realm/merge-dc09d5-to-master
Fix merge from dc09d5 to master/Print path for RealmFileException/"
realm-java,"Work around the memmove bug on Samsung device (#4402)
There was a bug for memmove on some Samsung devices. The functions
returns ""dest + n"" instead of ""dest"".
This has been identified earlier by QT. See:
https://bugreports.qt.io/browse/QTBUG-34984
The relevant android bug:
https://code.google.com/p/android/issues/detail?id=81692
This fix try to test if the device have this issue first, if yes, switch
to a own implementation of memmove.
This fix works for most cases, but since the memmove bug existing in the
system, there would be other lib/system call the buggy version of
memmove which could still corrupt the memory -- which means there are
still some possibilities that app gets crashed on those devices./Merge pull request #4309 from realm/merge-dc09d5-to-master
Fix merge from dc09d5 to master/"
realm-java,"Set log level for core logger bridge (#4389)
Set the all core logger bridges log level with the global log level.
Fix #4337/Merge pull request #4309 from realm/merge-dc09d5-to-master
Fix merge from dc09d5 to master/"
realm-java,"Merge pull request #4475 from realm/merge-196ee5-to-master
Fix merge from 196ee5 to master/Merge remote-tracking branch 'origin/releases' into my/fix_memory_leaking/KeepMember OsObject.notifyChangeListeners
- Fix #4461.
- Use release assertion when finding java method./"
realm-java,"Verify schema for backlinks by OS
- Add computed properties in the proxy's expected schema info, so the
schema validation in Object Store will check for linking objects.
- Throw IllegalStateException if the backlink schema validation fails.
ISE is more suitable here since backlink does not exist in the schema.
Normally the way to handle this issue is not by adding a migration
block, instead, just changing the declaration in the model class.
- Rewrite and enable the tests which are related to the linking objects
schema validation by mocking the expected schema info./Merge pull request #5014 from realm/merge-407e6a-to-master-4.0
Fix merge from 407e6a to master-4.0/Merge pull request #5012 from realm/merge-e1d802-to-master
Fix merge from e1d802 to master/Immutable RealmSchema and RealmObjectSchema (#5003)
Before this change, Realm.getSchema() and DynamicRealm.getSchema() both
return a mutable version RealmSchema object. That would cause issue when
changing the typed Realm's schema then continue to use typed inferface
to access the Realm where the column indices might be changed already
and had not been refreshed before the transaction commited.
After this change:
Realm.getSchema() returns an immutable RealmSchema object. And all
RealmObjectSchema objects retrieved from that will be immutable as
well./Let Object Store handle table creations (#4674)
This tries to progressively move more things about schemas to Object
Store.
First the concept of Schema in Object Store is not the same as what we
have in Java. It is very much just a schema information holder and won't
take care of the schema modifications. That says it is more like the
ColumnIndices cache in the Java binding.
So this commit try to:
- Instead of inheriting from the RealmSchema, change the
OsRealmSchema/OsRealmObjectSchema to OsSchemaInfo/OsObjectSchemaInfo.
They behave as a simple Java wrapper to the relevant OS objects.
- Add functions to Proxy classes which will create its own
OsObjectSchemaInfo and those info can be used to create a OsSchemaInfo
through the mediator.
- Call `SharedRealm.updateSchema` with the OsSchemaInfo which is got
from the proxy interface to do table initialization.
- This will also fix a minor bug we have before, All tables are created
even if the class is not in the module.
- Migration is still handled in the old way, and it will be solved in
the future, to let Object Store handle it.
- ColumnIndices are still kept for now, but it should be computed from the
OsSchemaInfo/OsObjectSchemaInfo in the future./Merge pull request #4840 from realm/merge-ea02c9-to-master
Fix merge from ea02c9 to master/LinkingObject queries (#4519)
Refactor ColumnInfo and ColumnIndices for better control
Refactor ColumnIndices to support new schema
Refactor ColumnInfor to support new schema
Refactor ProxyGeneration to support new Schema
Refactor RealmQuery to support backlinked queries
Code complete
Static analysis tests passing
Fix copy bug in ColumnIndices
All non-backlink tests passing; All non-test FIXMEs gone
Refactor all field parsing into the FieldDescriptor class
Fix threading bugs in RunInLooperThread rule
Standardize test timeouts
Native isEmpty and isNotEmpty need to be taught about backlinks
I believe all remaining work is C/C++
Disable Backlink Queries
Respond to comments
Revert createDynamicBacklinkResults signature
Remove single leading space on line 1206 ins RealmQueryTests.java/"
realm-java,"Verify schema for backlinks by OS
- Add computed properties in the proxy's expected schema info, so the
schema validation in Object Store will check for linking objects.
- Throw IllegalStateException if the backlink schema validation fails.
ISE is more suitable here since backlink does not exist in the schema.
Normally the way to handle this issue is not by adding a migration
block, instead, just changing the declaration in the model class.
- Rewrite and enable the tests which are related to the linking objects
schema validation by mocking the expected schema info./Merge pull request #5014 from realm/merge-407e6a-to-master-4.0
Fix merge from 407e6a to master-4.0/Merge pull request #5012 from realm/merge-e1d802-to-master
Fix merge from e1d802 to master/Immutable RealmSchema and RealmObjectSchema (#5003)
Before this change, Realm.getSchema() and DynamicRealm.getSchema() both
return a mutable version RealmSchema object. That would cause issue when
changing the typed Realm's schema then continue to use typed inferface
to access the Realm where the column indices might be changed already
and had not been refreshed before the transaction commited.
After this change:
Realm.getSchema() returns an immutable RealmSchema object. And all
RealmObjectSchema objects retrieved from that will be immutable as
well./Let Object Store handle table creations (#4674)
This tries to progressively move more things about schemas to Object
Store.
First the concept of Schema in Object Store is not the same as what we
have in Java. It is very much just a schema information holder and won't
take care of the schema modifications. That says it is more like the
ColumnIndices cache in the Java binding.
So this commit try to:
- Instead of inheriting from the RealmSchema, change the
OsRealmSchema/OsRealmObjectSchema to OsSchemaInfo/OsObjectSchemaInfo.
They behave as a simple Java wrapper to the relevant OS objects.
- Add functions to Proxy classes which will create its own
OsObjectSchemaInfo and those info can be used to create a OsSchemaInfo
through the mediator.
- Call `SharedRealm.updateSchema` with the OsSchemaInfo which is got
from the proxy interface to do table initialization.
- This will also fix a minor bug we have before, All tables are created
even if the class is not in the module.
- Migration is still handled in the old way, and it will be solved in
the future, to let Object Store handle it.
- ColumnIndices are still kept for now, but it should be computed from the
OsSchemaInfo/OsObjectSchemaInfo in the future./Merge pull request #4840 from realm/merge-ea02c9-to-master
Fix merge from ea02c9 to master/Merge pull request #4638 from realm/merge-8d3e17-to-master
Fix merge from 8d3e17 to master/Make the proxy toString methods reveal themselves (#4623)
* Make the proxy toString methods reveal themselves
* Fix preprocessor UTs
* Address PR comments/LinkingObject queries (#4519)
Refactor ColumnInfo and ColumnIndices for better control
Refactor ColumnIndices to support new schema
Refactor ColumnInfor to support new schema
Refactor ProxyGeneration to support new Schema
Refactor RealmQuery to support backlinked queries
Code complete
Static analysis tests passing
Fix copy bug in ColumnIndices
All non-backlink tests passing; All non-test FIXMEs gone
Refactor all field parsing into the FieldDescriptor class
Fix threading bugs in RunInLooperThread rule
Standardize test timeouts
Native isEmpty and isNotEmpty need to be taught about backlinks
I believe all remaining work is C/C++
Disable Backlink Queries
Respond to comments
Revert createDynamicBacklinkResults signature
Remove single leading space on line 1206 ins RealmQueryTests.java/"
realm-java,"copyToRealmOrUpdate cause dup values in list field (#5023)
Close #4957
We are using HashMap to maintain a cache of added managed RealmObject
when doing copyOrUpdate. But if the given object graph contains objects
which have same PK but are different java object, cache missing will
happen. That caused the object got set multiple times. For non-list
fields, it is not a problem since it will eventually has the expected
value if user's objects graph is consistent. For list, that results the
elements in the list are added multiple times since we don't clear the
RealmList in copy()./Verify schema for backlinks by OS
- Add computed properties in the proxy's expected schema info, so the
schema validation in Object Store will check for linking objects.
- Throw IllegalStateException if the backlink schema validation fails.
ISE is more suitable here since backlink does not exist in the schema.
Normally the way to handle this issue is not by adding a migration
block, instead, just changing the declaration in the model class.
- Rewrite and enable the tests which are related to the linking objects
schema validation by mocking the expected schema info./Merge pull request #5014 from realm/merge-407e6a-to-master-4.0
Fix merge from 407e6a to master-4.0/Merge pull request #5012 from realm/merge-e1d802-to-master
Fix merge from e1d802 to master/Immutable RealmSchema and RealmObjectSchema (#5003)
Before this change, Realm.getSchema() and DynamicRealm.getSchema() both
return a mutable version RealmSchema object. That would cause issue when
changing the typed Realm's schema then continue to use typed inferface
to access the Realm where the column indices might be changed already
and had not been refreshed before the transaction commited.
After this change:
Realm.getSchema() returns an immutable RealmSchema object. And all
RealmObjectSchema objects retrieved from that will be immutable as
well./Let Object Store handle table creations (#4674)
This tries to progressively move more things about schemas to Object
Store.
First the concept of Schema in Object Store is not the same as what we
have in Java. It is very much just a schema information holder and won't
take care of the schema modifications. That says it is more like the
ColumnIndices cache in the Java binding.
So this commit try to:
- Instead of inheriting from the RealmSchema, change the
OsRealmSchema/OsRealmObjectSchema to OsSchemaInfo/OsObjectSchemaInfo.
They behave as a simple Java wrapper to the relevant OS objects.
- Add functions to Proxy classes which will create its own
OsObjectSchemaInfo and those info can be used to create a OsSchemaInfo
through the mediator.
- Call `SharedRealm.updateSchema` with the OsSchemaInfo which is got
from the proxy interface to do table initialization.
- This will also fix a minor bug we have before, All tables are created
even if the class is not in the module.
- Migration is still handled in the old way, and it will be solved in
the future, to let Object Store handle it.
- ColumnIndices are still kept for now, but it should be computed from the
OsSchemaInfo/OsObjectSchemaInfo in the future./Merge pull request #4840 from realm/merge-ea02c9-to-master
Fix merge from ea02c9 to master/Merge pull request #4638 from realm/merge-8d3e17-to-master
Fix merge from 8d3e17 to master/Make the proxy toString methods reveal themselves (#4623)
* Make the proxy toString methods reveal themselves
* Fix preprocessor UTs
* Address PR comments/LinkingObject queries (#4519)
Refactor ColumnInfo and ColumnIndices for better control
Refactor ColumnIndices to support new schema
Refactor ColumnInfor to support new schema
Refactor ProxyGeneration to support new Schema
Refactor RealmQuery to support backlinked queries
Code complete
Static analysis tests passing
Fix copy bug in ColumnIndices
All non-backlink tests passing; All non-test FIXMEs gone
Refactor all field parsing into the FieldDescriptor class
Fix threading bugs in RunInLooperThread rule
Standardize test timeouts
Native isEmpty and isNotEmpty need to be taught about backlinks
I believe all remaining work is C/C++
Disable Backlink Queries
Respond to comments
Revert createDynamicBacklinkResults signature
Remove single leading space on line 1206 ins RealmQueryTests.java/"
realm-java,"Merge pull request #5059 from realm/merge-fbb711-to-master
Fix merge from fbb711 to master/"
realm-java,"Explicitly specify Locale for String.format() in our annotation processor (#4853)
* add Locale on formatting strings in our annotation processor.
* fix formatting/Merge pull request #4797 from realm/merge-e0e891-to-master
Fix merge from e0e891 to master/"
realm-java,"Merge pull request #5034 from realm/merge-7fbccc-to-master-4.0
Fix merge from 7fbccc to master-4.0/fix TestHelper.generateRandomString(int)/Merge pull request #4840 from realm/merge-ea02c9-to-master
Fix merge from ea02c9 to master/LinkingObject queries (#4519)
Refactor ColumnInfo and ColumnIndices for better control
Refactor ColumnIndices to support new schema
Refactor ColumnInfor to support new schema
Refactor ProxyGeneration to support new Schema
Refactor RealmQuery to support backlinked queries
Code complete
Static analysis tests passing
Fix copy bug in ColumnIndices
All non-backlink tests passing; All non-test FIXMEs gone
Refactor all field parsing into the FieldDescriptor class
Fix threading bugs in RunInLooperThread rule
Standardize test timeouts
Native isEmpty and isNotEmpty need to be taught about backlinks
I believe all remaining work is C/C++
Disable Backlink Queries
Respond to comments
Revert createDynamicBacklinkResults signature
Remove single leading space on line 1206 ins RealmQueryTests.java/"
realm-java,"Add CompactOnLaunch. (#4857)
* Implement CompactOnLaunch.
This commit adds RealmConfiguration.compactOnLaunch and
RealmConfiguration.Builder.compactOnLaunch(CompactOnLaunchCallback).
It makes a Realm determines if it should be compacted.
* Throw an exception if it is read-only Realm.
* Add readOnly_compactOnLaunch_throws
* Fix a wrong signature.
* Add tests to check compactOnLaunch.
* Fix tests.
* Add Javadoc.
* Updated CHANGELOG>md
* Fix a typo
* PR feedback.
* PR feedback: Improve tests.
* PR feedback.
* Improve Javadoc's sentences.
* Support Proguard.
* Rename more accurate.
* PR feedback.
* Fix Proguard.
* Fix JNI code.
* PR feedback: Remove 2 createConfiguration.
* PR feedback
* Add RealmConfiguration.Builder.compactOnLaunch().
* Fix a bug of JNI code.
* Add more tests.
* Improve Javadoc.
* PR feedback: Add a test to check a bug.
* add a test to check a bug where compactOnLaunch is called each time a Realm is opened on a new thread.
* PR feedback
* Imporve Javadoc.
* Fix a test (Thread).
* PR: fix a test./Fix ErrorProne warnings/Let Object Store handle table creations (#4674)
This tries to progressively move more things about schemas to Object
Store.
First the concept of Schema in Object Store is not the same as what we
have in Java. It is very much just a schema information holder and won't
take care of the schema modifications. That says it is more like the
ColumnIndices cache in the Java binding.
So this commit try to:
- Instead of inheriting from the RealmSchema, change the
OsRealmSchema/OsRealmObjectSchema to OsSchemaInfo/OsObjectSchemaInfo.
They behave as a simple Java wrapper to the relevant OS objects.
- Add functions to Proxy classes which will create its own
OsObjectSchemaInfo and those info can be used to create a OsSchemaInfo
through the mediator.
- Call `SharedRealm.updateSchema` with the OsSchemaInfo which is got
from the proxy interface to do table initialization.
- This will also fix a minor bug we have before, All tables are created
even if the class is not in the module.
- Migration is still handled in the old way, and it will be solved in
the future, to let Object Store handle it.
- ColumnIndices are still kept for now, but it should be computed from the
OsSchemaInfo/OsObjectSchemaInfo in the future./Fix test case with missing linking object schema
Those tests pass with current schema implementation since currently it
will create extra object schemas which are not in the module. This
behaviour is not right and will fail those tests in the future schema
refactor.
So always define all the needed object schemas in the module./"
realm-java,Fix ErrorProne warnings/
realm-java,"Fix ErrorProne warnings/Merge pull request #4840 from realm/merge-ea02c9-to-master
Fix merge from ea02c9 to master/Split createTable & getTable (#4689)
To support Stable IDs, the primary key has to be created while the table
is created. This will require a new internal API createTableWithPK in
the future.
The previous getTable behaviour would be quite confusing to support
that.
- getTable will only return the table if it exists.
- createTable is the one to be used to create tables.
- Add JavaExceptionDef to have all common Java exception names in a
single place.
- Remove useless tests./LinkingObject queries (#4519)
Refactor ColumnInfo and ColumnIndices for better control
Refactor ColumnIndices to support new schema
Refactor ColumnInfor to support new schema
Refactor ProxyGeneration to support new Schema
Refactor RealmQuery to support backlinked queries
Code complete
Static analysis tests passing
Fix copy bug in ColumnIndices
All non-backlink tests passing; All non-test FIXMEs gone
Refactor all field parsing into the FieldDescriptor class
Fix threading bugs in RunInLooperThread rule
Standardize test timeouts
Native isEmpty and isNotEmpty need to be taught about backlinks
I believe all remaining work is C/C++
Disable Backlink Queries
Respond to comments
Revert createDynamicBacklinkResults signature
Remove single leading space on line 1206 ins RealmQueryTests.java/"
realm-java,Fix ErrorProne warnings/
realm-java,"Add CompactOnLaunch. (#4857)
* Implement CompactOnLaunch.
This commit adds RealmConfiguration.compactOnLaunch and
RealmConfiguration.Builder.compactOnLaunch(CompactOnLaunchCallback).
It makes a Realm determines if it should be compacted.
* Throw an exception if it is read-only Realm.
* Add readOnly_compactOnLaunch_throws
* Fix a wrong signature.
* Add tests to check compactOnLaunch.
* Fix tests.
* Add Javadoc.
* Updated CHANGELOG>md
* Fix a typo
* PR feedback.
* PR feedback: Improve tests.
* PR feedback.
* Improve Javadoc's sentences.
* Support Proguard.
* Rename more accurate.
* PR feedback.
* Fix Proguard.
* Fix JNI code.
* PR feedback: Remove 2 createConfiguration.
* PR feedback
* Add RealmConfiguration.Builder.compactOnLaunch().
* Fix a bug of JNI code.
* Add more tests.
* Improve Javadoc.
* PR feedback: Add a test to check a bug.
* add a test to check a bug where compactOnLaunch is called each time a Realm is opened on a new thread.
* PR feedback
* Imporve Javadoc.
* Fix a test (Thread).
* PR: fix a test./"
realm-java,"Add SyncUser.allSessions() (#5047)
* Add SyncUser.allSessions.
* Update CHANGELOG.md
* Update SyncUser.allSessions' test.
* PR feedback
* Fix allSessions to exclude sessions in error state.
* PR feedback
* Update CHANGELOG.md/Work around jmethod bug with Android
- cherry-pick #4939 to enabled debug in menifest which caused a crash
described in #4964.
- Removed API to create JavaMethod from jobject/class name string.
There seems to be a bug in Android JVM when getting the method by:
jclass cls = env->GetObjectClass(obj);
jmethodID method = env->GetMethodID(cls, ""xxx"", ""xxx"")
The methodID retrieved by the above way triggers a strange bug in JVM,
it reports the method cannot be found on a non-relevant object. Like:
""
can't call boolean
io.realm.DefaultCompactOnLaunchCallback.shouldCompact(long, long) on
instance of io.realm.RealmTests$6'
""
Where RealmTest$6 has nothing to do with that JNI call.
It is not because of the local ref of cls has been deleted -- Even if
it is deleted, the methodID should still be valid according to the
doc:
The class references, field IDs, and method IDs are guaranteed valid
until the class is unloaded. Classes are only unloaded if all classes
associated with a ClassLoader can be garbage collected, which is rare
but will not be impossible in Android.
The class should never be unload in this case!
- For safety reasons, the JavaMethod should only be created from a
JavaClass right now to avoid future surprise.
Close #4964/fixes #4975 (#5000)
* fixes #4975/Fix admin users not connection correctly to ROS (#4760)/"
realm-java,"Merge pull request #5061 from realm/merge-f2144d-to-master-4.0
Fix merge from f2144d to master-4.0/fixes #4822 (#4862)
* fixes #4822/Fix admin users not connection correctly to ROS (#4760)/"
realm-java,"Work around jmethod bug with Android
- cherry-pick #4939 to enabled debug in menifest which caused a crash
described in #4964.
- Removed API to create JavaMethod from jobject/class name string.
There seems to be a bug in Android JVM when getting the method by:
jclass cls = env->GetObjectClass(obj);
jmethodID method = env->GetMethodID(cls, ""xxx"", ""xxx"")
The methodID retrieved by the above way triggers a strange bug in JVM,
it reports the method cannot be found on a non-relevant object. Like:
""
can't call boolean
io.realm.DefaultCompactOnLaunchCallback.shouldCompact(long, long) on
instance of io.realm.RealmTests$6'
""
Where RealmTest$6 has nothing to do with that JNI call.
It is not because of the local ref of cls has been deleted -- Even if
it is deleted, the methodID should still be valid according to the
doc:
The class references, field IDs, and method IDs are guaranteed valid
until the class is unloaded. Classes are only unloaded if all classes
associated with a ClassLoader can be garbage collected, which is rare
but will not be impossible in Android.
The class should never be unload in this case!
- For safety reasons, the JavaMethod should only be created from a
JavaClass right now to avoid future surprise.
Close #4964/Fix admin users not connection correctly to ROS (#4760)/fix crash when authentication error happens (#4726) (#4732)/"
realm-java,"Merge pull request #5014 from realm/merge-407e6a-to-master-4.0
Fix merge from 407e6a to master-4.0/Merge pull request #5012 from realm/merge-e1d802-to-master
Fix merge from e1d802 to master/Immutable RealmSchema and RealmObjectSchema (#5003)
Before this change, Realm.getSchema() and DynamicRealm.getSchema() both
return a mutable version RealmSchema object. That would cause issue when
changing the typed Realm's schema then continue to use typed inferface
to access the Realm where the column indices might be changed already
and had not been refreshed before the transaction commited.
After this change:
Realm.getSchema() returns an immutable RealmSchema object. And all
RealmObjectSchema objects retrieved from that will be immutable as
well./Add RealmObject.getRealm() and DynamicRealmObject.getDynamicRealm(). (#4778)
* Add RealmObject.getConfiguration(RealmModel) (#4720).
* revert a change in Realm.java
* check exception message
* Now RealmObject.getConfiguration(RealmModel) returns null if the model is unmanaged
* add RealmObject.getConfiguration()
* implement RealmObject#getRealm() and DynamicRealmObject#getDynamicRealm()
* fix markup
* remove empty tests
* fix tests/LinkingObject queries (#4519)
Refactor ColumnInfo and ColumnIndices for better control
Refactor ColumnIndices to support new schema
Refactor ColumnInfor to support new schema
Refactor ProxyGeneration to support new Schema
Refactor RealmQuery to support backlinked queries
Code complete
Static analysis tests passing
Fix copy bug in ColumnIndices
All non-backlink tests passing; All non-test FIXMEs gone
Refactor all field parsing into the FieldDescriptor class
Fix threading bugs in RunInLooperThread rule
Standardize test timeouts
Native isEmpty and isNotEmpty need to be taught about backlinks
I believe all remaining work is C/C++
Disable Backlink Queries
Respond to comments
Revert createDynamicBacklinkResults signature
Remove single leading space on line 1206 ins RealmQueryTests.java/"
realm-java,"Let Object Store handle table creations (#4674)
This tries to progressively move more things about schemas to Object
Store.
First the concept of Schema in Object Store is not the same as what we
have in Java. It is very much just a schema information holder and won't
take care of the schema modifications. That says it is more like the
ColumnIndices cache in the Java binding.
So this commit try to:
- Instead of inheriting from the RealmSchema, change the
OsRealmSchema/OsRealmObjectSchema to OsSchemaInfo/OsObjectSchemaInfo.
They behave as a simple Java wrapper to the relevant OS objects.
- Add functions to Proxy classes which will create its own
OsObjectSchemaInfo and those info can be used to create a OsSchemaInfo
through the mediator.
- Call `SharedRealm.updateSchema` with the OsSchemaInfo which is got
from the proxy interface to do table initialization.
- This will also fix a minor bug we have before, All tables are created
even if the class is not in the module.
- Migration is still handled in the old way, and it will be solved in
the future, to let Object Store handle it.
- ColumnIndices are still kept for now, but it should be computed from the
OsSchemaInfo/OsObjectSchemaInfo in the future./LinkingObject queries (#4519)
Refactor ColumnInfo and ColumnIndices for better control
Refactor ColumnIndices to support new schema
Refactor ColumnInfor to support new schema
Refactor ProxyGeneration to support new Schema
Refactor RealmQuery to support backlinked queries
Code complete
Static analysis tests passing
Fix copy bug in ColumnIndices
All non-backlink tests passing; All non-test FIXMEs gone
Refactor all field parsing into the FieldDescriptor class
Fix threading bugs in RunInLooperThread rule
Standardize test timeouts
Native isEmpty and isNotEmpty need to be taught about backlinks
I believe all remaining work is C/C++
Disable Backlink Queries
Respond to comments
Revert createDynamicBacklinkResults signature
Remove single leading space on line 1206 ins RealmQueryTests.java/"
realm-java,"Work around jmethod bug with Android
- cherry-pick #4939 to enabled debug in menifest which caused a crash
described in #4964.
- Removed API to create JavaMethod from jobject/class name string.
There seems to be a bug in Android JVM when getting the method by:
jclass cls = env->GetObjectClass(obj);
jmethodID method = env->GetMethodID(cls, ""xxx"", ""xxx"")
The methodID retrieved by the above way triggers a strange bug in JVM,
it reports the method cannot be found on a non-relevant object. Like:
""
can't call boolean
io.realm.DefaultCompactOnLaunchCallback.shouldCompact(long, long) on
instance of io.realm.RealmTests$6'
""
Where RealmTest$6 has nothing to do with that JNI call.
It is not because of the local ref of cls has been deleted -- Even if
it is deleted, the methodID should still be valid according to the
doc:
The class references, field IDs, and method IDs are guaranteed valid
until the class is unloaded. Classes are only unloaded if all classes
associated with a ClassLoader can be garbage collected, which is rare
but will not be impossible in Android.
The class should never be unload in this case!
- For safety reasons, the JavaMethod should only be created from a
JavaClass right now to avoid future surprise.
Close #4964/Update sync 2.0.0-rc12 (#4928)
There are some breaking changes from sync/core in this release:
- Object ID column name has been renamed from __OID to !OID
Instead of hardcoding it in java, we read it from sync if it is built
with sync. Otherwise hardcode it in JNI.
- Since core started using cmake, the openssl objects are not a part of
core release anymore. Instead, it will be released to s3
independently.
- Update ROS to 2.0.0-rc2-285/Merge pull request #4840 from realm/merge-ea02c9-to-master
Fix merge from ea02c9 to master/"
realm-java,"Nh/android support ssl (#4591)
* Expose two new SyncConfiguration options to 1: Disable TLS verification. 2: provide the trusted root CA to validate the RealmObjectServer TLS connection (since OpenSSL doesn't have access to Android keystore) fixes #4371/"
realm-java,"Backlink queries (#4704)
* Fixing unit tests for backlink queries. 
* Reintroducing of a native implementation of isNotEmpty().
* Moving inverse relationships out of beta stage./LinkingObject queries (#4519)
Refactor ColumnInfo and ColumnIndices for better control
Refactor ColumnIndices to support new schema
Refactor ColumnInfor to support new schema
Refactor ProxyGeneration to support new Schema
Refactor RealmQuery to support backlinked queries
Code complete
Static analysis tests passing
Fix copy bug in ColumnIndices
All non-backlink tests passing; All non-test FIXMEs gone
Refactor all field parsing into the FieldDescriptor class
Fix threading bugs in RunInLooperThread rule
Standardize test timeouts
Native isEmpty and isNotEmpty need to be taught about backlinks
I believe all remaining work is C/C++
Disable Backlink Queries
Respond to comments
Revert createDynamicBacklinkResults signature
Remove single leading space on line 1206 ins RealmQueryTests.java/"
realm-java,"Add CompactOnLaunch. (#4857)
* Implement CompactOnLaunch.
This commit adds RealmConfiguration.compactOnLaunch and
RealmConfiguration.Builder.compactOnLaunch(CompactOnLaunchCallback).
It makes a Realm determines if it should be compacted.
* Throw an exception if it is read-only Realm.
* Add readOnly_compactOnLaunch_throws
* Fix a wrong signature.
* Add tests to check compactOnLaunch.
* Fix tests.
* Add Javadoc.
* Updated CHANGELOG>md
* Fix a typo
* PR feedback.
* PR feedback: Improve tests.
* PR feedback.
* Improve Javadoc's sentences.
* Support Proguard.
* Rename more accurate.
* PR feedback.
* Fix Proguard.
* Fix JNI code.
* PR feedback: Remove 2 createConfiguration.
* PR feedback
* Add RealmConfiguration.Builder.compactOnLaunch().
* Fix a bug of JNI code.
* Add more tests.
* Improve Javadoc.
* PR feedback: Add a test to check a bug.
* add a test to check a bug where compactOnLaunch is called each time a Realm is opened on a new thread.
* PR feedback
* Imporve Javadoc.
* Fix a test (Thread).
* PR: fix a test./Let Object Store handle table creations (#4674)
This tries to progressively move more things about schemas to Object
Store.
First the concept of Schema in Object Store is not the same as what we
have in Java. It is very much just a schema information holder and won't
take care of the schema modifications. That says it is more like the
ColumnIndices cache in the Java binding.
So this commit try to:
- Instead of inheriting from the RealmSchema, change the
OsRealmSchema/OsRealmObjectSchema to OsSchemaInfo/OsObjectSchemaInfo.
They behave as a simple Java wrapper to the relevant OS objects.
- Add functions to Proxy classes which will create its own
OsObjectSchemaInfo and those info can be used to create a OsSchemaInfo
through the mediator.
- Call `SharedRealm.updateSchema` with the OsSchemaInfo which is got
from the proxy interface to do table initialization.
- This will also fix a minor bug we have before, All tables are created
even if the class is not in the module.
- Migration is still handled in the old way, and it will be solved in
the future, to let Object Store handle it.
- ColumnIndices are still kept for now, but it should be computed from the
OsSchemaInfo/OsObjectSchemaInfo in the future./Split createTable & getTable (#4689)
To support Stable IDs, the primary key has to be created while the table
is created. This will require a new internal API createTableWithPK in
the future.
The previous getTable behaviour would be quite confusing to support
that.
- getTable will only return the table if it exists.
- createTable is the one to be used to create tables.
- Add JavaExceptionDef to have all common Java exception names in a
single place.
- Remove useless tests./Nh/android support ssl (#4591)
* Expose two new SyncConfiguration options to 1: Disable TLS verification. 2: provide the trusted root CA to validate the RealmObjectServer TLS connection (since OpenSSL doesn't have access to Android keystore) fixes #4371/LinkingObject queries (#4519)
Refactor ColumnInfo and ColumnIndices for better control
Refactor ColumnIndices to support new schema
Refactor ColumnInfor to support new schema
Refactor ProxyGeneration to support new Schema
Refactor RealmQuery to support backlinked queries
Code complete
Static analysis tests passing
Fix copy bug in ColumnIndices
All non-backlink tests passing; All non-test FIXMEs gone
Refactor all field parsing into the FieldDescriptor class
Fix threading bugs in RunInLooperThread rule
Standardize test timeouts
Native isEmpty and isNotEmpty need to be taught about backlinks
I believe all remaining work is C/C++
Disable Backlink Queries
Respond to comments
Revert createDynamicBacklinkResults signature
Remove single leading space on line 1206 ins RealmQueryTests.java/"
realm-java,"Merge pull request #5034 from realm/merge-7fbccc-to-master-4.0
Fix merge from 7fbccc to master-4.0/Fix class name length check (#5019)
* fix class name length check
* fix the value of TABLE_NAME_MAX_LENGTH
* fix failed tests
* fix failed tests
* fix failed tests/add Nullable annotation to methods that can return 'null' (#4999)
* add Nullable annotation to methods that can return 'null'
* add changelog entry for introfucinf  annotation.
* fix Kotlin example
* fix Kotlin test/Update sync 2.0.0-rc12 (#4928)
There are some breaking changes from sync/core in this release:
- Object ID column name has been renamed from __OID to !OID
Instead of hardcoding it in java, we read it from sync if it is built
with sync. Otherwise hardcode it in JNI.
- Since core started using cmake, the openssl objects are not a part of
core release anymore. Instead, it will be released to s3
independently.
- Update ROS to 2.0.0-rc2-285/Merge pull request #4840 from realm/merge-ea02c9-to-master
Fix merge from ea02c9 to master/Converting nullable PK fields with null values (#4798)
- RealmObjectSchema.setRequired() will throw if the PK field has null
values stored.
- Call set_xxx_unique when converting nullability on a PK field.
- Remove useless check in the proxy generator which caused inconsistency
exception.
- Add relevant test cases./Split createTable & getTable (#4689)
To support Stable IDs, the primary key has to be created while the table
is created. This will require a new internal API createTableWithPK in
the future.
The previous getTable behaviour would be quite confusing to support
that.
- getTable will only return the table if it exists.
- createTable is the one to be used to create tables.
- Add JavaExceptionDef to have all common Java exception names in a
single place.
- Remove useless tests./LinkingObject queries (#4519)
Refactor ColumnInfo and ColumnIndices for better control
Refactor ColumnIndices to support new schema
Refactor ColumnInfor to support new schema
Refactor ProxyGeneration to support new Schema
Refactor RealmQuery to support backlinked queries
Code complete
Static analysis tests passing
Fix copy bug in ColumnIndices
All non-backlink tests passing; All non-test FIXMEs gone
Refactor all field parsing into the FieldDescriptor class
Fix threading bugs in RunInLooperThread rule
Standardize test timeouts
Native isEmpty and isNotEmpty need to be taught about backlinks
I believe all remaining work is C/C++
Disable Backlink Queries
Respond to comments
Revert createDynamicBacklinkResults signature
Remove single leading space on line 1206 ins RealmQueryTests.java/"
realm-java,"add Nullable annotation to methods that can return 'null' (#4999)
* add Nullable annotation to methods that can return 'null'
* add changelog entry for introfucinf  annotation.
* fix Kotlin example
* fix Kotlin test/Backlink queries (#4704)
* Fixing unit tests for backlink queries. 
* Reintroducing of a native implementation of isNotEmpty().
* Moving inverse relationships out of beta stage./LinkingObject queries (#4519)
Refactor ColumnInfo and ColumnIndices for better control
Refactor ColumnIndices to support new schema
Refactor ColumnInfor to support new schema
Refactor ProxyGeneration to support new Schema
Refactor RealmQuery to support backlinked queries
Code complete
Static analysis tests passing
Fix copy bug in ColumnIndices
All non-backlink tests passing; All non-test FIXMEs gone
Refactor all field parsing into the FieldDescriptor class
Fix threading bugs in RunInLooperThread rule
Standardize test timeouts
Native isEmpty and isNotEmpty need to be taught about backlinks
I believe all remaining work is C/C++
Disable Backlink Queries
Respond to comments
Revert createDynamicBacklinkResults signature
Remove single leading space on line 1206 ins RealmQueryTests.java/"
realm-java,"Nh/android support ssl (#4591)
* Expose two new SyncConfiguration options to 1: Disable TLS verification. 2: provide the trusted root CA to validate the RealmObjectServer TLS connection (since OpenSSL doesn't have access to Android keystore) fixes #4371/"
realm-java,"Let Object Store handle table creations (#4674)
This tries to progressively move more things about schemas to Object
Store.
First the concept of Schema in Object Store is not the same as what we
have in Java. It is very much just a schema information holder and won't
take care of the schema modifications. That says it is more like the
ColumnIndices cache in the Java binding.
So this commit try to:
- Instead of inheriting from the RealmSchema, change the
OsRealmSchema/OsRealmObjectSchema to OsSchemaInfo/OsObjectSchemaInfo.
They behave as a simple Java wrapper to the relevant OS objects.
- Add functions to Proxy classes which will create its own
OsObjectSchemaInfo and those info can be used to create a OsSchemaInfo
through the mediator.
- Call `SharedRealm.updateSchema` with the OsSchemaInfo which is got
from the proxy interface to do table initialization.
- This will also fix a minor bug we have before, All tables are created
even if the class is not in the module.
- Migration is still handled in the old way, and it will be solved in
the future, to let Object Store handle it.
- ColumnIndices are still kept for now, but it should be computed from the
OsSchemaInfo/OsObjectSchemaInfo in the future./LinkingObject queries (#4519)
Refactor ColumnInfo and ColumnIndices for better control
Refactor ColumnIndices to support new schema
Refactor ColumnInfor to support new schema
Refactor ProxyGeneration to support new Schema
Refactor RealmQuery to support backlinked queries
Code complete
Static analysis tests passing
Fix copy bug in ColumnIndices
All non-backlink tests passing; All non-test FIXMEs gone
Refactor all field parsing into the FieldDescriptor class
Fix threading bugs in RunInLooperThread rule
Standardize test timeouts
Native isEmpty and isNotEmpty need to be taught about backlinks
I believe all remaining work is C/C++
Disable Backlink Queries
Respond to comments
Revert createDynamicBacklinkResults signature
Remove single leading space on line 1206 ins RealmQueryTests.java/"
realm-java,"LinkingObject queries (#4519)
Refactor ColumnInfo and ColumnIndices for better control
Refactor ColumnIndices to support new schema
Refactor ColumnInfor to support new schema
Refactor ProxyGeneration to support new Schema
Refactor RealmQuery to support backlinked queries
Code complete
Static analysis tests passing
Fix copy bug in ColumnIndices
All non-backlink tests passing; All non-test FIXMEs gone
Refactor all field parsing into the FieldDescriptor class
Fix threading bugs in RunInLooperThread rule
Standardize test timeouts
Native isEmpty and isNotEmpty need to be taught about backlinks
I believe all remaining work is C/C++
Disable Backlink Queries
Respond to comments
Revert createDynamicBacklinkResults signature
Remove single leading space on line 1206 ins RealmQueryTests.java/"
realm-java,"add Nullable annotation to methods that can return 'null' (#4999)
* add Nullable annotation to methods that can return 'null'
* add changelog entry for introfucinf  annotation.
* fix Kotlin example
* fix Kotlin test/LinkingObject queries (#4519)
Refactor ColumnInfo and ColumnIndices for better control
Refactor ColumnIndices to support new schema
Refactor ColumnInfor to support new schema
Refactor ProxyGeneration to support new Schema
Refactor RealmQuery to support backlinked queries
Code complete
Static analysis tests passing
Fix copy bug in ColumnIndices
All non-backlink tests passing; All non-test FIXMEs gone
Refactor all field parsing into the FieldDescriptor class
Fix threading bugs in RunInLooperThread rule
Standardize test timeouts
Native isEmpty and isNotEmpty need to be taught about backlinks
I believe all remaining work is C/C++
Disable Backlink Queries
Respond to comments
Revert createDynamicBacklinkResults signature
Remove single leading space on line 1206 ins RealmQueryTests.java/"
realm-java,"Only format log message if the level is enabled
fix #4734/"
realm-java,"Merge pull request #5014 from realm/merge-407e6a-to-master-4.0
Fix merge from 407e6a to master-4.0/Merge pull request #5012 from realm/merge-e1d802-to-master
Fix merge from e1d802 to master/Immutable RealmSchema and RealmObjectSchema (#5003)
Before this change, Realm.getSchema() and DynamicRealm.getSchema() both
return a mutable version RealmSchema object. That would cause issue when
changing the typed Realm's schema then continue to use typed inferface
to access the Realm where the column indices might be changed already
and had not been refreshed before the transaction commited.
After this change:
Realm.getSchema() returns an immutable RealmSchema object. And all
RealmObjectSchema objects retrieved from that will be immutable as
well./add Nullable annotation to methods that can return 'null' (#4999)
* add Nullable annotation to methods that can return 'null'
* add changelog entry for introfucinf  annotation.
* fix Kotlin example
* fix Kotlin test/Fix findbugs/Let Object Store handle table creations (#4674)
This tries to progressively move more things about schemas to Object
Store.
First the concept of Schema in Object Store is not the same as what we
have in Java. It is very much just a schema information holder and won't
take care of the schema modifications. That says it is more like the
ColumnIndices cache in the Java binding.
So this commit try to:
- Instead of inheriting from the RealmSchema, change the
OsRealmSchema/OsRealmObjectSchema to OsSchemaInfo/OsObjectSchemaInfo.
They behave as a simple Java wrapper to the relevant OS objects.
- Add functions to Proxy classes which will create its own
OsObjectSchemaInfo and those info can be used to create a OsSchemaInfo
through the mediator.
- Call `SharedRealm.updateSchema` with the OsSchemaInfo which is got
from the proxy interface to do table initialization.
- This will also fix a minor bug we have before, All tables are created
even if the class is not in the module.
- Migration is still handled in the old way, and it will be solved in
the future, to let Object Store handle it.
- ColumnIndices are still kept for now, but it should be computed from the
OsSchemaInfo/OsObjectSchemaInfo in the future./Merge pull request #4840 from realm/merge-ea02c9-to-master
Fix merge from ea02c9 to master/Merge pull request #4709 from realm/merge-5ab06b-to-master
Fix merge from 5ab06b to master/Merge pull request #4700 from realm/merge-6a01b2-to-master
Fix merge from 6a01b2 to master/Fix queries not working on proguarded Realms model classes (#4690)/LinkingObject queries (#4519)
Refactor ColumnInfo and ColumnIndices for better control
Refactor ColumnIndices to support new schema
Refactor ColumnInfor to support new schema
Refactor ProxyGeneration to support new Schema
Refactor RealmQuery to support backlinked queries
Code complete
Static analysis tests passing
Fix copy bug in ColumnIndices
All non-backlink tests passing; All non-test FIXMEs gone
Refactor all field parsing into the FieldDescriptor class
Fix threading bugs in RunInLooperThread rule
Standardize test timeouts
Native isEmpty and isNotEmpty need to be taught about backlinks
I believe all remaining work is C/C++
Disable Backlink Queries
Respond to comments
Revert createDynamicBacklinkResults signature
Remove single leading space on line 1206 ins RealmQueryTests.java/"
realm-java,Remove io.realm.internal.OutOfMemoryError/Helper class for throwing java exception from JNI (#4636)/
realm-java,Fix local_ref_table overflow doing when massive logging from the sync thread. (#4888)/
realm-java,"Work around jmethod bug with Android
- cherry-pick #4939 to enabled debug in menifest which caused a crash
described in #4964.
- Removed API to create JavaMethod from jobject/class name string.
There seems to be a bug in Android JVM when getting the method by:
jclass cls = env->GetObjectClass(obj);
jmethodID method = env->GetMethodID(cls, ""xxx"", ""xxx"")
The methodID retrieved by the above way triggers a strange bug in JVM,
it reports the method cannot be found on a non-relevant object. Like:
""
can't call boolean
io.realm.DefaultCompactOnLaunchCallback.shouldCompact(long, long) on
instance of io.realm.RealmTests$6'
""
Where RealmTest$6 has nothing to do with that JNI call.
It is not because of the local ref of cls has been deleted -- Even if
it is deleted, the methodID should still be valid according to the
doc:
The class references, field IDs, and method IDs are guaranteed valid
until the class is unloaded. Classes are only unloaded if all classes
associated with a ClassLoader can be garbage collected, which is rare
but will not be impossible in Android.
The class should never be unload in this case!
- For safety reasons, the JavaMethod should only be created from a
JavaClass right now to avoid future surprise.
Close #4964/"
realm-java,Helper class for throwing java exception from JNI (#4636)/
realm-java,"Convert exception on sync client to java exception (#4707)
- update object-store to 1e3cbb1789
- Convert exception on sync client to java exception
This will give us some better information when excpetion happens
on the sync client thread.
- Update sync to 1.10.1, core to 2.8.4/"
realm-java,"Converting examples to RxJava2 (#5141)
* Add changelog
* Move Pair into public API (#5081)
* Convert RxJava1 to RxJava2 (#4992)
* Apply rxjava2 to unitTestExample
* Update Jenkinsfile to store junit result of unitTestExample.
* Convert newsreaderExample to RxJava2.
* RxJava2: Add support for changeset observables (#5089)
* Update rxJavaExample and improve some formatting.
* Fix unit testing.
* Fix build.gradle.
* Update build.gradle to fix lint errors.
* Improve some formatting.
* Improve formatting.
* Update style of RxJavaExample.
* Add missing colors.xml file.
* Update styles and colors.
* Rename some disposables.
* PR feedback.
* flatMap -> switchMap and improve formatting.
* Improve formatting.
* Converting newsreaserExample to lambda.
* Improve formatting.
* Improve formatting.
* Apply RxJava2 to unit testing.
* Improve formatting.
* Apply Lambda to rxJavaExample.
* Improve formatting.
* PR feedback
* Re-enable RxJava2 examples
* CompositeDisposable.dispose() -> CompositeDisposable.clear()
* PR feedback./"
realm-java,"Sign release apk for examples
- Close #5184 . without siging, monkeyRelease will fail with
INSTALL_PARSE_FAILED_NO_CERTIFICATES
- Enable proguard for all most all examples, both debug & release. This
will give us a chance to see proguard issues as early as possible.
- Fix a ""realm was closed"" crash for thread example./"
realm-java,"Merge pull request #5465 from realm/merge-9f4f55-to-master
Fix merge from 9f4f55 to master/Remove depreacted RealmProxyMediator.getTableName (#5456)
Prefix ""class_"" should be hide from java layer and handled in Object
Store. Try to that direction step by step.
Close #5455/Fix some performance issues when initializing the Schema  (#5404)/Merge pull request #5202 from realm/merge-f1af97-to-master
Fix merge from f1af97 to master/Use OS List instead of core's LinkView (#5171)
- Replace LinkView with OS List.
- Code clean up.
- Fix a potential leak with LinkView in insertion APIs./Merge pull request #5162 from realm/merge-39bb67-to-master-4.0
Fix merge from 39bb67 to master-4.0/Final step for OS schema integration (#5065)
- Build the column indices cache from OsSchemaInfo.
Not like before, the column indices are not built when the Realm
instance is created. Instead, they will only be built when the relevant
RealmObject needs to be accessed.
- Column indices cache system has been changed. Different Realm instance
will not share the same cache. Instead, every Realm instance will have
its own cache. So we don't rely on the schema version any more. The
cache can handle the situation when the schema versions are the same but
schemas are not.
- Refresh column indices cache when schema changes. This is also
supported in multi-processes environment.
- Almost all of the Realm initialization work is handled by Object
Store. So we have the same routine for both sync/non-sync Realm. Also
the initialization routine has be simplified a lot in java side.
- A new class OsRealmConfig is introduced to solve the 20+ arguments
need to be passed to JNI to create Realm config.
- The transaction for schema initialization should be cancelled if
exception happens in Java migration/initialization callbacks./"
realm-java,"Merge pull request #5465 from realm/merge-9f4f55-to-master
Fix merge from 9f4f55 to master/Remove depreacted RealmProxyMediator.getTableName (#5456)
Prefix ""class_"" should be hide from java layer and handled in Object
Store. Try to that direction step by step.
Close #5455/Fix some performance issues when initializing the Schema  (#5404)/Merge pull request #5202 from realm/merge-f1af97-to-master
Fix merge from f1af97 to master/Use OS List instead of core's LinkView (#5171)
- Replace LinkView with OS List.
- Code clean up.
- Fix a potential leak with LinkView in insertion APIs./Merge pull request #5162 from realm/merge-39bb67-to-master-4.0
Fix merge from 39bb67 to master-4.0/Final step for OS schema integration (#5065)
- Build the column indices cache from OsSchemaInfo.
Not like before, the column indices are not built when the Realm
instance is created. Instead, they will only be built when the relevant
RealmObject needs to be accessed.
- Column indices cache system has been changed. Different Realm instance
will not share the same cache. Instead, every Realm instance will have
its own cache. So we don't rely on the schema version any more. The
cache can handle the situation when the schema versions are the same but
schemas are not.
- Refresh column indices cache when schema changes. This is also
supported in multi-processes environment.
- Almost all of the Realm initialization work is handled by Object
Store. So we have the same routine for both sync/non-sync Realm. Also
the initialization routine has be simplified a lot in java side.
- A new class OsRealmConfig is introduced to solve the 20+ arguments
need to be passed to JNI to create Realm config.
- The transaction for schema initialization should be cancelled if
exception happens in Java migration/initialization callbacks./"
realm-java,"Merge pull request #5465 from realm/merge-9f4f55-to-master
Fix merge from 9f4f55 to master/Remove depreacted RealmProxyMediator.getTableName (#5456)
Prefix ""class_"" should be hide from java layer and handled in Object
Store. Try to that direction step by step.
Close #5455/Fix some performance issues when initializing the Schema  (#5404)/Setting own list back on an object accidentially cleared it (#5396)
* Add unit test showing setting own list does not work.
* Do not clear own list if given as input.
* Clear in the correct place
* Add test for copyToRealmOrUpdate
* Unit test for insertOrUpdate
* Add test for insertOrUpdate bulk and non-bulk
* Fix wrong comparison
* Wrong spelling
* Update changelog
* Fix mistakes. Move check out of proxy classes.
* Dont always check for managed objects
* Always check for managed state.
* Better changelog
* Correct check for unmanaged objects. Optimized loops.
* Optimize `insert` loops
* More loop optimizations/Merge pull request #5202 from realm/merge-f1af97-to-master
Fix merge from f1af97 to master/Use OS List instead of core's LinkView (#5171)
- Replace LinkView with OS List.
- Code clean up.
- Fix a potential leak with LinkView in insertion APIs./Merge pull request #5162 from realm/merge-39bb67-to-master-4.0
Fix merge from 39bb67 to master-4.0/Final step for OS schema integration (#5065)
- Build the column indices cache from OsSchemaInfo.
Not like before, the column indices are not built when the Realm
instance is created. Instead, they will only be built when the relevant
RealmObject needs to be accessed.
- Column indices cache system has been changed. Different Realm instance
will not share the same cache. Instead, every Realm instance will have
its own cache. So we don't rely on the schema version any more. The
cache can handle the situation when the schema versions are the same but
schemas are not.
- Refresh column indices cache when schema changes. This is also
supported in multi-processes environment.
- Almost all of the Realm initialization work is handled by Object
Store. So we have the same routine for both sync/non-sync Realm. Also
the initialization routine has be simplified a lot in java side.
- A new class OsRealmConfig is introduced to solve the 20+ arguments
need to be passed to JNI to create Realm config.
- The transaction for schema initialization should be cancelled if
exception happens in Java migration/initialization callbacks./"
realm-java,"Merge pull request #5437 from realm/merge-daac89-to-master
Fix merge from daac89 to master/Add realm.ignoreKotlinNullability
To disable treating kotlin non-null types as @Required.
From v3.6.0, all the kotlin RealmModel's non-null field will be set as
required in the schema. However it is a breaking change for the kotlin
project which has a Realm file created before 3.6.0.
To disable this behaviour introduced in 3.6.0, add below things to the
project's build.gradle:
kapt {
arguments {
arg(""realm.ignoreKotlinNullability"", true)
}
}
Close #5412/"
realm-java,"Merge pull request #5194 from realm/merge-c9206c-to-master-4.0
Fix merge from c9206c to master-4.0/"
realm-java,"Merge pull request #5162 from realm/merge-39bb67-to-master-4.0
Fix merge from 39bb67 to master-4.0/Final step for OS schema integration (#5065)
- Build the column indices cache from OsSchemaInfo.
Not like before, the column indices are not built when the Realm
instance is created. Instead, they will only be built when the relevant
RealmObject needs to be accessed.
- Column indices cache system has been changed. Different Realm instance
will not share the same cache. Instead, every Realm instance will have
its own cache. So we don't rely on the schema version any more. The
cache can handle the situation when the schema versions are the same but
schemas are not.
- Refresh column indices cache when schema changes. This is also
supported in multi-processes environment.
- Almost all of the Realm initialization work is handled by Object
Store. So we have the same routine for both sync/non-sync Realm. Also
the initialization routine has be simplified a lot in java side.
- A new class OsRealmConfig is introduced to solve the 20+ arguments
need to be passed to JNI to create Realm config.
- The transaction for schema initialization should be cancelled if
exception happens in Java migration/initialization callbacks./"
realm-java,"Merge pull request #5162 from realm/merge-39bb67-to-master-4.0
Fix merge from 39bb67 to master-4.0/Final step for OS schema integration (#5065)
- Build the column indices cache from OsSchemaInfo.
Not like before, the column indices are not built when the Realm
instance is created. Instead, they will only be built when the relevant
RealmObject needs to be accessed.
- Column indices cache system has been changed. Different Realm instance
will not share the same cache. Instead, every Realm instance will have
its own cache. So we don't rely on the schema version any more. The
cache can handle the situation when the schema versions are the same but
schemas are not.
- Refresh column indices cache when schema changes. This is also
supported in multi-processes environment.
- Almost all of the Realm initialization work is handled by Object
Store. So we have the same routine for both sync/non-sync Realm. Also
the initialization routine has be simplified a lot in java side.
- A new class OsRealmConfig is introduced to solve the 20+ arguments
need to be passed to JNI to create Realm config.
- The transaction for schema initialization should be cancelled if
exception happens in Java migration/initialization callbacks./Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Update to latest OS (#5166)
* Fixing compile issue with OS
* Fix build issues with new Results API
- Remove indexOf(targetRowIndex)
- Results::index_of takes a RowExpr now/Merge pull request #5162 from realm/merge-39bb67-to-master-4.0
Fix merge from 39bb67 to master-4.0/Final step for OS schema integration (#5065)
- Build the column indices cache from OsSchemaInfo.
Not like before, the column indices are not built when the Realm
instance is created. Instead, they will only be built when the relevant
RealmObject needs to be accessed.
- Column indices cache system has been changed. Different Realm instance
will not share the same cache. Instead, every Realm instance will have
its own cache. So we don't rely on the schema version any more. The
cache can handle the situation when the schema versions are the same but
schemas are not.
- Refresh column indices cache when schema changes. This is also
supported in multi-processes environment.
- Almost all of the Realm initialization work is handled by Object
Store. So we have the same routine for both sync/non-sync Realm. Also
the initialization routine has be simplified a lot in java side.
- A new class OsRealmConfig is introduced to solve the 20+ arguments
need to be passed to JNI to create Realm config.
- The transaction for schema initialization should be cancelled if
exception happens in Java migration/initialization callbacks./"
realm-java,"Client reset fixes #4759 (#5159)
* Exposing a `SyncConfiguration` that allows a user to open the backup Realm after the client reset (#4759)./"
realm-java,"Remove ObjectServerUser #3741 #4962 #5028 (#5020)
* remove ObjectServerUser
* add multiple session tests
* Add regression test for old SyncUser JSON
* Using identity with authURL to identity a SyncUser/Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"4.0 API breaking changes  (#5314)
* Refactored deprecated `Callback`
* SyncUser: renamed `getAccessToken` + method is no longer public/Client reset fixes #4759 (#5159)
* Exposing a `SyncConfiguration` that allows a user to open the backup Realm after the client reset (#4759)./Remove ObjectServerUser #3741 #4962 #5028 (#5020)
* remove ObjectServerUser
* add multiple session tests
* Add regression test for old SyncUser JSON
* Using identity with authURL to identity a SyncUser/Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Merge pull request #5162 from realm/merge-39bb67-to-master-4.0
Fix merge from 39bb67 to master-4.0/Final step for OS schema integration (#5065)
- Build the column indices cache from OsSchemaInfo.
Not like before, the column indices are not built when the Realm
instance is created. Instead, they will only be built when the relevant
RealmObject needs to be accessed.
- Column indices cache system has been changed. Different Realm instance
will not share the same cache. Instead, every Realm instance will have
its own cache. So we don't rely on the schema version any more. The
cache can handle the situation when the schema versions are the same but
schemas are not.
- Refresh column indices cache when schema changes. This is also
supported in multi-processes environment.
- Almost all of the Realm initialization work is handled by Object
Store. So we have the same routine for both sync/non-sync Realm. Also
the initialization routine has be simplified a lot in java side.
- A new class OsRealmConfig is introduced to solve the 20+ arguments
need to be passed to JNI to create Realm config.
- The transaction for schema initialization should be cancelled if
exception happens in Java migration/initialization callbacks./Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Setting own list back on an object accidentially cleared it (#5396)
* Add unit test showing setting own list does not work.
* Do not clear own list if given as input.
* Clear in the correct place
* Add test for copyToRealmOrUpdate
* Unit test for insertOrUpdate
* Add test for insertOrUpdate bulk and non-bulk
* Fix wrong comparison
* Wrong spelling
* Update changelog
* Fix mistakes. Move check out of proxy classes.
* Dont always check for managed objects
* Always check for managed state.
* Better changelog
* Correct check for unmanaged objects. Optimized loops.
* Optimize `insert` loops
* More loop optimizations/Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Fix some performance issues when initializing the Schema  (#5404)/Merge pull request #5162 from realm/merge-39bb67-to-master-4.0
Fix merge from 39bb67 to master-4.0/Final step for OS schema integration (#5065)
- Build the column indices cache from OsSchemaInfo.
Not like before, the column indices are not built when the Realm
instance is created. Instead, they will only be built when the relevant
RealmObject needs to be accessed.
- Column indices cache system has been changed. Different Realm instance
will not share the same cache. Instead, every Realm instance will have
its own cache. So we don't rely on the schema version any more. The
cache can handle the situation when the schema versions are the same but
schemas are not.
- Refresh column indices cache when schema changes. This is also
supported in multi-processes environment.
- Almost all of the Realm initialization work is handled by Object
Store. So we have the same routine for both sync/non-sync Realm. Also
the initialization routine has be simplified a lot in java side.
- A new class OsRealmConfig is introduced to solve the 20+ arguments
need to be passed to JNI to create Realm config.
- The transaction for schema initialization should be cancelled if
exception happens in Java migration/initialization callbacks./"
realm-java,"Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Client reset fixes #4759 (#5159)
* Exposing a `SyncConfiguration` that allows a user to open the backup Realm after the client reset (#4759)./Merge pull request #5162 from realm/merge-39bb67-to-master-4.0
Fix merge from 39bb67 to master-4.0/Merge pull request #5134 from realm/merge-f782c5-to-master-4.0
Fix merge from f782c5 to master-4.0/Final step for OS schema integration (#5065)
- Build the column indices cache from OsSchemaInfo.
Not like before, the column indices are not built when the Realm
instance is created. Instead, they will only be built when the relevant
RealmObject needs to be accessed.
- Column indices cache system has been changed. Different Realm instance
will not share the same cache. Instead, every Realm instance will have
its own cache. So we don't rely on the schema version any more. The
cache can handle the situation when the schema versions are the same but
schemas are not.
- Refresh column indices cache when schema changes. This is also
supported in multi-processes environment.
- Almost all of the Realm initialization work is handled by Object
Store. So we have the same routine for both sync/non-sync Realm. Also
the initialization routine has be simplified a lot in java side.
- A new class OsRealmConfig is introduced to solve the 20+ arguments
need to be passed to JNI to create Realm config.
- The transaction for schema initialization should be cancelled if
exception happens in Java migration/initialization callbacks./Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Merge pull request #5202 from realm/merge-f1af97-to-master
Fix merge from f1af97 to master/Use OS List instead of core's LinkView (#5171)
- Replace LinkView with OS List.
- Code clean up.
- Fix a potential leak with LinkView in insertion APIs./Update to latest OS (#5166)
* Fixing compile issue with OS
* Fix build issues with new Results API
- Remove indexOf(targetRowIndex)
- Results::index_of takes a RowExpr now/Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Merge pull request #5162 from realm/merge-39bb67-to-master-4.0
Fix merge from 39bb67 to master-4.0/Final step for OS schema integration (#5065)
- Build the column indices cache from OsSchemaInfo.
Not like before, the column indices are not built when the Realm
instance is created. Instead, they will only be built when the relevant
RealmObject needs to be accessed.
- Column indices cache system has been changed. Different Realm instance
will not share the same cache. Instead, every Realm instance will have
its own cache. So we don't rely on the schema version any more. The
cache can handle the situation when the schema versions are the same but
schemas are not.
- Refresh column indices cache when schema changes. This is also
supported in multi-processes environment.
- Almost all of the Realm initialization work is handled by Object
Store. So we have the same routine for both sync/non-sync Realm. Also
the initialization routine has be simplified a lot in java side.
- A new class OsRealmConfig is introduced to solve the 20+ arguments
need to be passed to JNI to create Realm config.
- The transaction for schema initialization should be cancelled if
exception happens in Java migration/initialization callbacks./"
realm-java,"Merge pull request #5202 from realm/merge-f1af97-to-master
Fix merge from f1af97 to master/Use OS List instead of core's LinkView (#5171)
- Replace LinkView with OS List.
- Code clean up.
- Fix a potential leak with LinkView in insertion APIs./Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Merge pull request #5465 from realm/merge-9f4f55-to-master
Fix merge from 9f4f55 to master/Remove depreacted RealmProxyMediator.getTableName (#5456)
Prefix ""class_"" should be hide from java layer and handled in Object
Store. Try to that direction step by step.
Close #5455/Merge pull request #5202 from realm/merge-f1af97-to-master
Fix merge from f1af97 to master/Use OS List instead of core's LinkView (#5171)
- Replace LinkView with OS List.
- Code clean up.
- Fix a potential leak with LinkView in insertion APIs./Merge pull request #5162 from realm/merge-39bb67-to-master-4.0
Fix merge from 39bb67 to master-4.0/Final step for OS schema integration (#5065)
- Build the column indices cache from OsSchemaInfo.
Not like before, the column indices are not built when the Realm
instance is created. Instead, they will only be built when the relevant
RealmObject needs to be accessed.
- Column indices cache system has been changed. Different Realm instance
will not share the same cache. Instead, every Realm instance will have
its own cache. So we don't rely on the schema version any more. The
cache can handle the situation when the schema versions are the same but
schemas are not.
- Refresh column indices cache when schema changes. This is also
supported in multi-processes environment.
- Almost all of the Realm initialization work is handled by Object
Store. So we have the same routine for both sync/non-sync Realm. Also
the initialization routine has be simplified a lot in java side.
- A new class OsRealmConfig is introduced to solve the 20+ arguments
need to be passed to JNI to create Realm config.
- The transaction for schema initialization should be cancelled if
exception happens in Java migration/initialization callbacks./Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Merge pull request #5202 from realm/merge-f1af97-to-master
Fix merge from f1af97 to master/Use OS List instead of core's LinkView (#5171)
- Replace LinkView with OS List.
- Code clean up.
- Fix a potential leak with LinkView in insertion APIs./"
realm-java,"Merge pull request #5202 from realm/merge-f1af97-to-master
Fix merge from f1af97 to master/Use OS List instead of core's LinkView (#5171)
- Replace LinkView with OS List.
- Code clean up.
- Fix a potential leak with LinkView in insertion APIs./Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Merge pull request #5202 from realm/merge-f1af97-to-master
Fix merge from f1af97 to master/Use OS List instead of core's LinkView (#5171)
- Replace LinkView with OS List.
- Code clean up.
- Fix a potential leak with LinkView in insertion APIs./"
realm-java,"Fix some performance issues when initializing the Schema  (#5404)/Merge pull request #5162 from realm/merge-39bb67-to-master-4.0
Fix merge from 39bb67 to master-4.0/Final step for OS schema integration (#5065)
- Build the column indices cache from OsSchemaInfo.
Not like before, the column indices are not built when the Realm
instance is created. Instead, they will only be built when the relevant
RealmObject needs to be accessed.
- Column indices cache system has been changed. Different Realm instance
will not share the same cache. Instead, every Realm instance will have
its own cache. So we don't rely on the schema version any more. The
cache can handle the situation when the schema versions are the same but
schemas are not.
- Refresh column indices cache when schema changes. This is also
supported in multi-processes environment.
- Almost all of the Realm initialization work is handled by Object
Store. So we have the same routine for both sync/non-sync Realm. Also
the initialization routine has be simplified a lot in java side.
- A new class OsRealmConfig is introduced to solve the 20+ arguments
need to be passed to JNI to create Realm config.
- The transaction for schema initialization should be cancelled if
exception happens in Java migration/initialization callbacks./"
realm-java,"Merge pull request #5202 from realm/merge-f1af97-to-master
Fix merge from f1af97 to master/Use OS List instead of core's LinkView (#5171)
- Replace LinkView with OS List.
- Code clean up.
- Fix a potential leak with LinkView in insertion APIs./"
realm-java,"Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Merge pull request #5110 from realm/merge-d409e3-to-master
Fix merge from d409e3 to master/Fix class name in exception message (#5098)
* add a change log entry
* fix comment
* peerClassName -> linkedClassName/Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Merge pull request #5194 from realm/merge-c9206c-to-master-4.0
Fix merge from c9206c to master-4.0/Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"Merge pull request #5162 from realm/merge-39bb67-to-master-4.0
Fix merge from 39bb67 to master-4.0/Final step for OS schema integration (#5065)
- Build the column indices cache from OsSchemaInfo.
Not like before, the column indices are not built when the Realm
instance is created. Instead, they will only be built when the relevant
RealmObject needs to be accessed.
- Column indices cache system has been changed. Different Realm instance
will not share the same cache. Instead, every Realm instance will have
its own cache. So we don't rely on the schema version any more. The
cache can handle the situation when the schema versions are the same but
schemas are not.
- Refresh column indices cache when schema changes. This is also
supported in multi-processes environment.
- Almost all of the Realm initialization work is handled by Object
Store. So we have the same routine for both sync/non-sync Realm. Also
the initialization routine has be simplified a lot in java side.
- A new class OsRealmConfig is introduced to solve the 20+ arguments
need to be passed to JNI to create Realm config.
- The transaction for schema initialization should be cancelled if
exception happens in Java migration/initialization callbacks./"
realm-java,"Merge pull request #5465 from realm/merge-9f4f55-to-master
Fix merge from 9f4f55 to master/Remove depreacted RealmProxyMediator.getTableName (#5456)
Prefix ""class_"" should be hide from java layer and handled in Object
Store. Try to that direction step by step.
Close #5455/Merge pull request #5162 from realm/merge-39bb67-to-master-4.0
Fix merge from 39bb67 to master-4.0/Final step for OS schema integration (#5065)
- Build the column indices cache from OsSchemaInfo.
Not like before, the column indices are not built when the Realm
instance is created. Instead, they will only be built when the relevant
RealmObject needs to be accessed.
- Column indices cache system has been changed. Different Realm instance
will not share the same cache. Instead, every Realm instance will have
its own cache. So we don't rely on the schema version any more. The
cache can handle the situation when the schema versions are the same but
schemas are not.
- Refresh column indices cache when schema changes. This is also
supported in multi-processes environment.
- Almost all of the Realm initialization work is handled by Object
Store. So we have the same routine for both sync/non-sync Realm. Also
the initialization routine has be simplified a lot in java side.
- A new class OsRealmConfig is introduced to solve the 20+ arguments
need to be passed to JNI to create Realm config.
- The transaction for schema initialization should be cancelled if
exception happens in Java migration/initialization callbacks./Merge pull request #5088 from realm/merge-19e452-to-master-4.0
Fix merge from 19e452 to master-4.0/Add @Nullable annotation to public APIs (#5044)
* add @Nullable annotation to parameters and suppress null related warnings
* add @Nullable annotation to objectserver APIs
* fix compile error in example
* remove @Nullable annotation from equals(Object)
* remove @Nonnull annotation from each overriding methods. Add more package-infos instead.
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove @Nonnull from parameters
* remove unused import
* remove unused import
* add 'Nullability by Annotataion' section to CONTRIBUTING.md
* fix typo in CONTRIBUTING.md
* replace 'assert' with 'noinspection' comment
* add more @Nullable annotation to address findbugs warnings/"
realm-java,"IncompatibleSyncedFileException only for sync/java_class_global_def for global class loading
- Add JavaClassGlobalDef to handle global jclass loading.
- Move common types classes loading to JavaClassGlobalDef.
- Load SharedRealm$$SchemaChangeCallback & RealmNotifier in JNI_OnLoad
to fix #5195 .
- Code clean up.
NOTE:
Currently the JavaClassGlobalDef::initialize() takes about 0.3 ms on a
lowend armv7 device. So keeping less classes loaded at the beginning
will still be a good idea since the Realm.init() will be usually called
on the UI thread when start./Merge pull request #5202 from realm/merge-f1af97-to-master
Fix merge from f1af97 to master/Use OS List instead of core's LinkView (#5171)
- Replace LinkView with OS List.
- Code clean up.
- Fix a potential leak with LinkView in insertion APIs./"
realm-java,"java_class_global_def for global class loading
- Add JavaClassGlobalDef to handle global jclass loading.
- Move common types classes loading to JavaClassGlobalDef.
- Load SharedRealm$$SchemaChangeCallback & RealmNotifier in JNI_OnLoad
to fix #5195 .
- Code clean up.
NOTE:
Currently the JavaClassGlobalDef::initialize() takes about 0.3 ms on a
lowend armv7 device. So keeping less classes loaded at the beginning
will still be a good idea since the Realm.init() will be usually called
on the UI thread when start./"
realm-java,"java_class_global_def for global class loading
- Add JavaClassGlobalDef to handle global jclass loading.
- Move common types classes loading to JavaClassGlobalDef.
- Load SharedRealm$$SchemaChangeCallback & RealmNotifier in JNI_OnLoad
to fix #5195 .
- Code clean up.
NOTE:
Currently the JavaClassGlobalDef::initialize() takes about 0.3 ms on a
lowend armv7 device. So keeping less classes loaded at the beginning
will still be a good idea since the Realm.init() will be usually called
on the UI thread when start./"
realm-java,"Report class missing correctly in assertion (#5196)/Merge pull request #5162 from realm/merge-39bb67-to-master-4.0
Fix merge from 39bb67 to master-4.0/Final step for OS schema integration (#5065)
- Build the column indices cache from OsSchemaInfo.
Not like before, the column indices are not built when the Realm
instance is created. Instead, they will only be built when the relevant
RealmObject needs to be accessed.
- Column indices cache system has been changed. Different Realm instance
will not share the same cache. Instead, every Realm instance will have
its own cache. So we don't rely on the schema version any more. The
cache can handle the situation when the schema versions are the same but
schemas are not.
- Refresh column indices cache when schema changes. This is also
supported in multi-processes environment.
- Almost all of the Realm initialization work is handled by Object
Store. So we have the same routine for both sync/non-sync Realm. Also
the initialization routine has be simplified a lot in java side.
- A new class OsRealmConfig is introduced to solve the 20+ arguments
need to be passed to JNI to create Realm config.
- The transaction for schema initialization should be cancelled if
exception happens in Java migration/initialization callbacks./"
realm-java,"Remove ObjectServerUser #3741 #4962 #5028 (#5020)
* remove ObjectServerUser
* add multiple session tests
* Add regression test for old SyncUser JSON
* Using identity with authURL to identity a SyncUser/"
realm-java,"Merge pull request #5722 from realm/merge-f089a8-to-next-major
Fix merge from f089a8 to next-major/Support for overriding internal names using annotations (#5280)
* Add support for @RealmName which makes it possible to override the name of classes and fields.
* Remove RealmName annotation. Add methods for specifying names to RealmModule, RealmClass and a new RealmField annotation.
* Fix compile issues
* Fix Javadoc and most unit tests.
* Add test for conflicting modules
* Begun work on checking conflicting policies
* Fix merge
* Use correct version of Object Store
* Better docs
* Backup
* Processor tests are green
* Fleshing out unit tests for using name policies in annotations
* Cleanup
* Fix required value lists + cleanup
* Fix module defaults not being correctly applied
* Add support and unit tests for field name overrides
* Add changelog
* Javadoc updates
* Use custom built parser for converting variable names
* Better Javadoc
* RealmField is now retained at Runtime
* Fix unit tests
* Unify build tools
* Cleanup
* Remove FIXMEs
* Fix tests after merge from master
* PR feedback
* More PR feedback
* PR feedback
* More PR feedback
* Output correctly internal name
* Fix library module mediators not being correctly created
* Fix missing spaces in error message
* Better example
* Improve wording/"
realm-java,"Merge pull request #5722 from realm/merge-f089a8-to-next-major
Fix merge from f089a8 to next-major/Support for overriding internal names using annotations (#5280)
* Add support for @RealmName which makes it possible to override the name of classes and fields.
* Remove RealmName annotation. Add methods for specifying names to RealmModule, RealmClass and a new RealmField annotation.
* Fix compile issues
* Fix Javadoc and most unit tests.
* Add test for conflicting modules
* Begun work on checking conflicting policies
* Fix merge
* Use correct version of Object Store
* Better docs
* Backup
* Processor tests are green
* Fleshing out unit tests for using name policies in annotations
* Cleanup
* Fix required value lists + cleanup
* Fix module defaults not being correctly applied
* Add support and unit tests for field name overrides
* Add changelog
* Javadoc updates
* Use custom built parser for converting variable names
* Better Javadoc
* RealmField is now retained at Runtime
* Fix unit tests
* Unify build tools
* Cleanup
* Remove FIXMEs
* Fix tests after merge from master
* PR feedback
* More PR feedback
* PR feedback
* More PR feedback
* Output correctly internal name
* Fix library module mediators not being correctly created
* Fix missing spaces in error message
* Better example
* Improve wording/"
realm-java,"Merge pull request #5722 from realm/merge-f089a8-to-next-major
Fix merge from f089a8 to next-major/Support for overriding internal names using annotations (#5280)
* Add support for @RealmName which makes it possible to override the name of classes and fields.
* Remove RealmName annotation. Add methods for specifying names to RealmModule, RealmClass and a new RealmField annotation.
* Fix compile issues
* Fix Javadoc and most unit tests.
* Add test for conflicting modules
* Begun work on checking conflicting policies
* Fix merge
* Use correct version of Object Store
* Better docs
* Backup
* Processor tests are green
* Fleshing out unit tests for using name policies in annotations
* Cleanup
* Fix required value lists + cleanup
* Fix module defaults not being correctly applied
* Add support and unit tests for field name overrides
* Add changelog
* Javadoc updates
* Use custom built parser for converting variable names
* Better Javadoc
* RealmField is now retained at Runtime
* Fix unit tests
* Unify build tools
* Cleanup
* Remove FIXMEs
* Fix tests after merge from master
* PR feedback
* More PR feedback
* PR feedback
* More PR feedback
* Output correctly internal name
* Fix library module mediators not being correctly created
* Fix missing spaces in error message
* Better example
* Improve wording/"
realm-java,"Merge pull request #5722 from realm/merge-f089a8-to-next-major
Fix merge from f089a8 to next-major/Support for overriding internal names using annotations (#5280)
* Add support for @RealmName which makes it possible to override the name of classes and fields.
* Remove RealmName annotation. Add methods for specifying names to RealmModule, RealmClass and a new RealmField annotation.
* Fix compile issues
* Fix Javadoc and most unit tests.
* Add test for conflicting modules
* Begun work on checking conflicting policies
* Fix merge
* Use correct version of Object Store
* Better docs
* Backup
* Processor tests are green
* Fleshing out unit tests for using name policies in annotations
* Cleanup
* Fix required value lists + cleanup
* Fix module defaults not being correctly applied
* Add support and unit tests for field name overrides
* Add changelog
* Javadoc updates
* Use custom built parser for converting variable names
* Better Javadoc
* RealmField is now retained at Runtime
* Fix unit tests
* Unify build tools
* Cleanup
* Remove FIXMEs
* Fix tests after merge from master
* PR feedback
* More PR feedback
* PR feedback
* More PR feedback
* Output correctly internal name
* Fix library module mediators not being correctly created
* Fix missing spaces in error message
* Better example
* Improve wording/Ensure stable classes order in generated mediators (#5567)
Fixes #5566./"
realm-java,"Evaluate queries immediately for sync queries
- OsResults.load() actually does evaluate queries if needed now by using
newly exposed OS method Results.evaluate_query_if_needed(). So the
Results's mode will be changed to TABLEVIEW from QUERY. This matches
the old async query behaviour and solved the performance issues when
the query results are huge, the size() method took unnecessary long
time even the Results accessor will be called at the next line.
close #5328 close #5387
- Update Object Store to 3eb19c014fdf .
- Refactor the APIs for creating OsResults./"
realm-java,"Merge pull request #5506 from realm/vivekkiran/5472
Fix and merge #5472/Fix errorprone issues/"
realm-java,"Fixes #5677 (#5741)
* Fixes #5677
- removed session network listener since it's redundant with the SyncManager one/"
realm-java,"Evaluate queries immediately for sync queries
- OsResults.load() actually does evaluate queries if needed now by using
newly exposed OS method Results.evaluate_query_if_needed(). So the
Results's mode will be changed to TABLEVIEW from QUERY. This matches
the old async query behaviour and solved the performance issues when
the query results are huge, the size() method took unnecessary long
time even the Results accessor will be called at the next line.
close #5328 close #5387
- Update Object Store to 3eb19c014fdf .
- Refactor the APIs for creating OsResults./"
realm-java,"Merge pull request #5722 from realm/merge-f089a8-to-next-major
Fix merge from f089a8 to next-major/Support for overriding internal names using annotations (#5280)
* Add support for @RealmName which makes it possible to override the name of classes and fields.
* Remove RealmName annotation. Add methods for specifying names to RealmModule, RealmClass and a new RealmField annotation.
* Fix compile issues
* Fix Javadoc and most unit tests.
* Add test for conflicting modules
* Begun work on checking conflicting policies
* Fix merge
* Use correct version of Object Store
* Better docs
* Backup
* Processor tests are green
* Fleshing out unit tests for using name policies in annotations
* Cleanup
* Fix required value lists + cleanup
* Fix module defaults not being correctly applied
* Add support and unit tests for field name overrides
* Add changelog
* Javadoc updates
* Use custom built parser for converting variable names
* Better Javadoc
* RealmField is now retained at Runtime
* Fix unit tests
* Unify build tools
* Cleanup
* Remove FIXMEs
* Fix tests after merge from master
* PR feedback
* More PR feedback
* PR feedback
* More PR feedback
* Output correctly internal name
* Fix library module mediators not being correctly created
* Fix missing spaces in error message
* Better example
* Improve wording/"
realm-java,"Evaluate queries immediately for sync queries
- OsResults.load() actually does evaluate queries if needed now by using
newly exposed OS method Results.evaluate_query_if_needed(). So the
Results's mode will be changed to TABLEVIEW from QUERY. This matches
the old async query behaviour and solved the performance issues when
the query results are huge, the size() method took unnecessary long
time even the Results accessor will be called at the next line.
close #5328 close #5387
- Update Object Store to 3eb19c014fdf .
- Refactor the APIs for creating OsResults./"
realm-java,"Evaluate queries immediately for sync queries
- OsResults.load() actually does evaluate queries if needed now by using
newly exposed OS method Results.evaluate_query_if_needed(). So the
Results's mode will be changed to TABLEVIEW from QUERY. This matches
the old async query behaviour and solved the performance issues when
the query results are huge, the size() method took unnecessary long
time even the Results accessor will be called at the next line.
close #5328 close #5387
- Update Object Store to 3eb19c014fdf .
- Refactor the APIs for creating OsResults./"
realm-java,"Life cycle of temp OsSharedRealm in callbacks (#5576)
Every temp OsSharedRealm created during construction for the callbacks
have to be closed before the exception throws to users.
close #5570/Evaluate queries immediately for sync queries
- OsResults.load() actually does evaluate queries if needed now by using
newly exposed OS method Results.evaluate_query_if_needed(). So the
Results's mode will be changed to TABLEVIEW from QUERY. This matches
the old async query behaviour and solved the performance issues when
the query results are huge, the size() method took unnecessary long
time even the Results accessor will be called at the next line.
close #5328 close #5387
- Update Object Store to 3eb19c014fdf .
- Refactor the APIs for creating OsResults./"
realm-java,"Merge pull request #5722 from realm/merge-f089a8-to-next-major
Fix merge from f089a8 to next-major/Support for overriding internal names using annotations (#5280)
* Add support for @RealmName which makes it possible to override the name of classes and fields.
* Remove RealmName annotation. Add methods for specifying names to RealmModule, RealmClass and a new RealmField annotation.
* Fix compile issues
* Fix Javadoc and most unit tests.
* Add test for conflicting modules
* Begun work on checking conflicting policies
* Fix merge
* Use correct version of Object Store
* Better docs
* Backup
* Processor tests are green
* Fleshing out unit tests for using name policies in annotations
* Cleanup
* Fix required value lists + cleanup
* Fix module defaults not being correctly applied
* Add support and unit tests for field name overrides
* Add changelog
* Javadoc updates
* Use custom built parser for converting variable names
* Better Javadoc
* RealmField is now retained at Runtime
* Fix unit tests
* Unify build tools
* Cleanup
* Remove FIXMEs
* Fix tests after merge from master
* PR feedback
* More PR feedback
* PR feedback
* More PR feedback
* Output correctly internal name
* Fix library module mediators not being correctly created
* Fix missing spaces in error message
* Better example
* Improve wording/Better exception message for addField() (#5610)
* Better exception message for addField()
Close #3388/"
realm-java,"Merge pull request #5722 from realm/merge-f089a8-to-next-major
Fix merge from f089a8 to next-major/Support for overriding internal names using annotations (#5280)
* Add support for @RealmName which makes it possible to override the name of classes and fields.
* Remove RealmName annotation. Add methods for specifying names to RealmModule, RealmClass and a new RealmField annotation.
* Fix compile issues
* Fix Javadoc and most unit tests.
* Add test for conflicting modules
* Begun work on checking conflicting policies
* Fix merge
* Use correct version of Object Store
* Better docs
* Backup
* Processor tests are green
* Fleshing out unit tests for using name policies in annotations
* Cleanup
* Fix required value lists + cleanup
* Fix module defaults not being correctly applied
* Add support and unit tests for field name overrides
* Add changelog
* Javadoc updates
* Use custom built parser for converting variable names
* Better Javadoc
* RealmField is now retained at Runtime
* Fix unit tests
* Unify build tools
* Cleanup
* Remove FIXMEs
* Fix tests after merge from master
* PR feedback
* More PR feedback
* PR feedback
* More PR feedback
* Output correctly internal name
* Fix library module mediators not being correctly created
* Fix missing spaces in error message
* Better example
* Improve wording/"
realm-java,Fix getLocalInstanceCount doc (#5599)/
realm-java,Fix SyncSession tests (#5853)/
realm-java,"Fix SyncSession tests (#5853)/Merge pull request #5832 from realm/merge-7930c8-to-next-major
Fix merge from 7930c8 to next-major/logout logging not resuming sync (#5820)
* Fixes https://github.com/realm/my-first-realm-app/issues/22 logout/login resume syncing/"
realm-java,"Merge pull request #5832 from realm/merge-7930c8-to-next-major
Fix merge from 7930c8 to next-major/logout logging not resuming sync (#5820)
* Fixes https://github.com/realm/my-first-realm-app/issues/22 logout/login resume syncing/"
realm-java,Fix list.move for unmanaged lists. (#5872)/
realm-java,"Better exception message if non model class is provided (#5796)/Revert ""Better exception message if non model class is provided as function argument""
This reverts commit 3aa2608bd712bcb844ffaa0ed296dbb5cb2b3e1d./Better exception message if non model class is provided as function argument/"
realm-java,"Support empty input to in and alwaysTrue and alwaysFalse (#5898)
* Support empty input to in and two new predicates: alwaysTrue and alwaysFalse
* Fix spelling mistakes in docs
* Kotlin docs should match java docs/"
realm-java,Fix SyncSession tests (#5853)/
realm-java,Fix SyncSession tests (#5853)/
realm-java,"Merge pull request #6045 from realm/merge-780a85-to-master
Fix merge from 780a85 to master/Fixes #5970 (#6043)
* Using Android Network Security Configuration to setup the test certificate for SSL tests/"
realm-java,Fix bug when using distinct() and count() (#6062)/
realm-java,Fix Realm.deleteAll() and Realm.isEmpty() (#6024)/
realm-java,Fix Realm.deleteAll() and Realm.isEmpty() (#6024)/
realm-java,Fix various lifecycle issues with tests. Work-around for logs not being saved. (#6141)/
realm-java,Added support for stopping and starting a session (#6135)/
realm-java,Fix initial listener not triggering for query-based listeners (#6236)/
realm-java,Add support for native error category and code (#6379)/
realm-java,Add support for native error category and code (#6379)/
realm-java,Add support for native error category and code (#6379)/
realm-java,Add support for native error category and code (#6379)/
realm-java,PermissionManager should ignore intermittent errors (#6506)/
realm-java,PermissionManager should ignore intermittent errors (#6506)/
rocksdb,"Small tweaks and bugfixes for Issue 18 and 19.
Slight tweak to the no-overlap optimization: only push to
level 2 to reduce the amount of wasted space when the same
small key range is being repeatedly overwritten.
Fix for Issue 18: Avoid failure on Windows by avoiding
deletion of lock file until the end of DestroyDB().
Fix for Issue 19: Disregard sequence numbers when checking for 
overlap in sstable ranges. This fixes issue 19: when writing 
the same key over and over again, we would generate a sequence 
of sstables that were never merged together since their sequence
numbers were disjoint.
Don't ignore map/unmap error checks.
Miscellaneous fixes for small problems Sanjay found while diagnosing
issue/9 and issue/16 (corruption_testr failures).
- log::Reader reports the record type when it finds an unexpected type.
- log::Reader no longer reports an error when it encounters an expected
zero record regardless of the setting of the ""checksum"" flag.
- Added a missing forward declaration.
- Documented a side-effects of larger write buffer sizes
(longer recovery time).
git-svn-id: https://leveldb.googlecode.com/svn/trunk@37 62dab493-f737-651d-591e-8d6aee1b9529/"
rocksdb,"Sun Studio support, and fix for test related memory fixes.
- LevelDB patch for Sun Studio
Based on a patch submitted by Theo Schlossnagle - thanks!
This fixes Issue 17.
- Fix a couple of test related memory leaks.
git-svn-id: https://leveldb.googlecode.com/svn/trunk@38 62dab493-f737-651d-591e-8d6aee1b9529/A number of smaller fixes and performance improvements:
- Implemented Get() directly instead of building on top of a full
merging iterator stack.  This speeds up the ""readrandom"" benchmark
by up to 15-30%.
- Fixed an opensource compilation problem.
Added --db=<name> flag to control where the database is placed.
- Automatically compact a file when we have done enough
overlapping seeks to that file.
- Fixed a performance bug where we would read from at least one
file in a level even if none of the files overlapped the key
being read.
- Makefile fix for Mac OSX installations that have XCode 4 without XCode 3.
- Unified the two occurrences of binary search in a file-list
into one routine.
- Found and fixed a bug where we would unnecessarily search the
last file when looking for a key larger than all data in the
level.
- A fix to avoid the need for trivial move compactions and
therefore gets rid of two out of five syncs in ""fillseq"".
- Removed the MANIFEST file write when switching to a new
memtable/log-file for a 10-20% improvement on fill speed on ext4.
- Adding a SNAPPY setting in the Makefile for folks who have
Snappy installed. Snappy compresses values and speeds up writes.
git-svn-id: https://leveldb.googlecode.com/svn/trunk@32 62dab493-f737-651d-591e-8d6aee1b9529/"
rocksdb,"Bugfix for issue 33; reduce lock contention in Get(), parallel benchmarks.
- Fix for issue 33 (non-null-terminated result from
leveldb_property_value())
- Support for running multiple instances of a benchmark in parallel.
- Reduce lock contention on Get():
(1) Do not hold the lock while searching memtables.
(2) Shard block and table caches 16-ways.
Benchmark for evaluating this change:
$ db_bench --benchmarks=fillseq1,readrandom --threads=$n
(fillseq1 is a small hack to make sure fillseq runs once regardless
of number of threads specified on the command line).
git-svn-id: https://leveldb.googlecode.com/svn/trunk@49 62dab493-f737-651d-591e-8d6aee1b9529/Small tweaks and bugfixes for Issue 18 and 19.
Slight tweak to the no-overlap optimization: only push to
level 2 to reduce the amount of wasted space when the same
small key range is being repeatedly overwritten.
Fix for Issue 18: Avoid failure on Windows by avoiding
deletion of lock file until the end of DestroyDB().
Fix for Issue 19: Disregard sequence numbers when checking for 
overlap in sstable ranges. This fixes issue 19: when writing 
the same key over and over again, we would generate a sequence 
of sstables that were never merged together since their sequence
numbers were disjoint.
Don't ignore map/unmap error checks.
Miscellaneous fixes for small problems Sanjay found while diagnosing
issue/9 and issue/16 (corruption_testr failures).
- log::Reader reports the record type when it finds an unexpected type.
- log::Reader no longer reports an error when it encounters an expected
zero record regardless of the setting of the ""checksum"" flag.
- Added a missing forward declaration.
- Documented a side-effects of larger write buffer sizes
(longer recovery time).
git-svn-id: https://leveldb.googlecode.com/svn/trunk@37 62dab493-f737-651d-591e-8d6aee1b9529/A number of smaller fixes and performance improvements:
- Implemented Get() directly instead of building on top of a full
merging iterator stack.  This speeds up the ""readrandom"" benchmark
by up to 15-30%.
- Fixed an opensource compilation problem.
Added --db=<name> flag to control where the database is placed.
- Automatically compact a file when we have done enough
overlapping seeks to that file.
- Fixed a performance bug where we would read from at least one
file in a level even if none of the files overlapped the key
being read.
- Makefile fix for Mac OSX installations that have XCode 4 without XCode 3.
- Unified the two occurrences of binary search in a file-list
into one routine.
- Found and fixed a bug where we would unnecessarily search the
last file when looking for a key larger than all data in the
level.
- A fix to avoid the need for trivial move compactions and
therefore gets rid of two out of five syncs in ""fillseq"".
- Removed the MANIFEST file write when switching to a new
memtable/log-file for a 10-20% improvement on fill speed on ext4.
- Adding a SNAPPY setting in the Makefile for folks who have
Snappy installed. Snappy compresses values and speeds up writes.
git-svn-id: https://leveldb.googlecode.com/svn/trunk@32 62dab493-f737-651d-591e-8d6aee1b9529/sync with upstream @21706995
Fixed race condition reported by Dave Smit (dizzyd@dizzyd,com)
on the leveldb mailing list.  We were not signalling
waiters after a trivial move from level-0.  The result was
that in some cases (hard to reproduce), a write would get
stuck forever waiting for the number of level-0 files to drop
below its hard limit.
The new code is simpler: there is just one condition variable
instead of two, and the condition variable is signalled after
every piece of background work finishes.  Also, all compaction
work (including for manual compactions) is done in the
background thread, and therefore we can remove the
""compacting_"" variable.
git-svn-id: https://leveldb.googlecode.com/svn/trunk@31 62dab493-f737-651d-591e-8d6aee1b9529/"
rocksdb,"A number of smaller fixes and performance improvements:
- Implemented Get() directly instead of building on top of a full
merging iterator stack.  This speeds up the ""readrandom"" benchmark
by up to 15-30%.
- Fixed an opensource compilation problem.
Added --db=<name> flag to control where the database is placed.
- Automatically compact a file when we have done enough
overlapping seeks to that file.
- Fixed a performance bug where we would read from at least one
file in a level even if none of the files overlapped the key
being read.
- Makefile fix for Mac OSX installations that have XCode 4 without XCode 3.
- Unified the two occurrences of binary search in a file-list
into one routine.
- Found and fixed a bug where we would unnecessarily search the
last file when looking for a key larger than all data in the
level.
- A fix to avoid the need for trivial move compactions and
therefore gets rid of two out of five syncs in ""fillseq"".
- Removed the MANIFEST file write when switching to a new
memtable/log-file for a 10-20% improvement on fill speed on ext4.
- Adding a SNAPPY setting in the Makefile for folks who have
Snappy installed. Snappy compresses values and speeds up writes.
git-svn-id: https://leveldb.googlecode.com/svn/trunk@32 62dab493-f737-651d-591e-8d6aee1b9529/"
rocksdb,"Sun Studio support, and fix for test related memory fixes.
- LevelDB patch for Sun Studio
Based on a patch submitted by Theo Schlossnagle - thanks!
This fixes Issue 17.
- Fix a couple of test related memory leaks.
git-svn-id: https://leveldb.googlecode.com/svn/trunk@38 62dab493-f737-651d-591e-8d6aee1b9529/"
rocksdb,"Bugfixes for iterator and documentation.
- Fix bug in Iterator::Prev where it would return the wrong key.
Fixes issues 29 and 30.
- Added a tweak to testharness to allow running just some tests.
- Fixing two minor documentation errors based on issues 28 and 25.
- Cleanup; fix namespaces of export-to-C code.
Also fix one ""const char*"" vs ""char*"" mismatch.
git-svn-id: https://leveldb.googlecode.com/svn/trunk@48 62dab493-f737-651d-591e-8d6aee1b9529/Sun Studio support, and fix for test related memory fixes.
- LevelDB patch for Sun Studio
Based on a patch submitted by Theo Schlossnagle - thanks!
This fixes Issue 17.
- Fix a couple of test related memory leaks.
git-svn-id: https://leveldb.googlecode.com/svn/trunk@38 62dab493-f737-651d-591e-8d6aee1b9529/Small tweaks and bugfixes for Issue 18 and 19.
Slight tweak to the no-overlap optimization: only push to
level 2 to reduce the amount of wasted space when the same
small key range is being repeatedly overwritten.
Fix for Issue 18: Avoid failure on Windows by avoiding
deletion of lock file until the end of DestroyDB().
Fix for Issue 19: Disregard sequence numbers when checking for 
overlap in sstable ranges. This fixes issue 19: when writing 
the same key over and over again, we would generate a sequence 
of sstables that were never merged together since their sequence
numbers were disjoint.
Don't ignore map/unmap error checks.
Miscellaneous fixes for small problems Sanjay found while diagnosing
issue/9 and issue/16 (corruption_testr failures).
- log::Reader reports the record type when it finds an unexpected type.
- log::Reader no longer reports an error when it encounters an expected
zero record regardless of the setting of the ""checksum"" flag.
- Added a missing forward declaration.
- Documented a side-effects of larger write buffer sizes
(longer recovery time).
git-svn-id: https://leveldb.googlecode.com/svn/trunk@37 62dab493-f737-651d-591e-8d6aee1b9529/A number of smaller fixes and performance improvements:
- Implemented Get() directly instead of building on top of a full
merging iterator stack.  This speeds up the ""readrandom"" benchmark
by up to 15-30%.
- Fixed an opensource compilation problem.
Added --db=<name> flag to control where the database is placed.
- Automatically compact a file when we have done enough
overlapping seeks to that file.
- Fixed a performance bug where we would read from at least one
file in a level even if none of the files overlapped the key
being read.
- Makefile fix for Mac OSX installations that have XCode 4 without XCode 3.
- Unified the two occurrences of binary search in a file-list
into one routine.
- Found and fixed a bug where we would unnecessarily search the
last file when looking for a key larger than all data in the
level.
- A fix to avoid the need for trivial move compactions and
therefore gets rid of two out of five syncs in ""fillseq"".
- Removed the MANIFEST file write when switching to a new
memtable/log-file for a 10-20% improvement on fill speed on ext4.
- Adding a SNAPPY setting in the Makefile for folks who have
Snappy installed. Snappy compresses values and speeds up writes.
git-svn-id: https://leveldb.googlecode.com/svn/trunk@32 62dab493-f737-651d-591e-8d6aee1b9529/"
rocksdb,"Sun Studio support, and fix for test related memory fixes.
- LevelDB patch for Sun Studio
Based on a patch submitted by Theo Schlossnagle - thanks!
This fixes Issue 17.
- Fix a couple of test related memory leaks.
git-svn-id: https://leveldb.googlecode.com/svn/trunk@38 62dab493-f737-651d-591e-8d6aee1b9529/Small tweaks and bugfixes for Issue 18 and 19.
Slight tweak to the no-overlap optimization: only push to
level 2 to reduce the amount of wasted space when the same
small key range is being repeatedly overwritten.
Fix for Issue 18: Avoid failure on Windows by avoiding
deletion of lock file until the end of DestroyDB().
Fix for Issue 19: Disregard sequence numbers when checking for 
overlap in sstable ranges. This fixes issue 19: when writing 
the same key over and over again, we would generate a sequence 
of sstables that were never merged together since their sequence
numbers were disjoint.
Don't ignore map/unmap error checks.
Miscellaneous fixes for small problems Sanjay found while diagnosing
issue/9 and issue/16 (corruption_testr failures).
- log::Reader reports the record type when it finds an unexpected type.
- log::Reader no longer reports an error when it encounters an expected
zero record regardless of the setting of the ""checksum"" flag.
- Added a missing forward declaration.
- Documented a side-effects of larger write buffer sizes
(longer recovery time).
git-svn-id: https://leveldb.googlecode.com/svn/trunk@37 62dab493-f737-651d-591e-8d6aee1b9529/A number of smaller fixes and performance improvements:
- Implemented Get() directly instead of building on top of a full
merging iterator stack.  This speeds up the ""readrandom"" benchmark
by up to 15-30%.
- Fixed an opensource compilation problem.
Added --db=<name> flag to control where the database is placed.
- Automatically compact a file when we have done enough
overlapping seeks to that file.
- Fixed a performance bug where we would read from at least one
file in a level even if none of the files overlapped the key
being read.
- Makefile fix for Mac OSX installations that have XCode 4 without XCode 3.
- Unified the two occurrences of binary search in a file-list
into one routine.
- Found and fixed a bug where we would unnecessarily search the
last file when looking for a key larger than all data in the
level.
- A fix to avoid the need for trivial move compactions and
therefore gets rid of two out of five syncs in ""fillseq"".
- Removed the MANIFEST file write when switching to a new
memtable/log-file for a 10-20% improvement on fill speed on ext4.
- Adding a SNAPPY setting in the Makefile for folks who have
Snappy installed. Snappy compresses values and speeds up writes.
git-svn-id: https://leveldb.googlecode.com/svn/trunk@32 62dab493-f737-651d-591e-8d6aee1b9529/"
rocksdb,"A number of fixes:
- Replace raw slice comparison with a call to user comparator.
Added test for custom comparators.
- Fix end of namespace comments.
- Fixed bug in picking inputs for a level-0 compaction.
When finding overlapping files, the covered range may expand
as files are added to the input set.  We now correctly expand
the range when this happens instead of continuing to use the
old range.  For example, suppose L0 contains files with the
following ranges:
F1: a .. d
F2:    c .. g
F3:       f .. j
and the initial compaction target is F3.  We used to search
for range f..j which yielded {F2,F3}.  However we now expand
the range as soon as another file is added.  In this case,
when F2 is added, we expand the range to c..j and restart the
search.  That picks up file F1 as well.
This change fixes a bug related to deleted keys showing up
incorrectly after a compaction as described in Issue 44.
(Sync with upstream @25072954)/"
rocksdb,"A number of fixes:
- Replace raw slice comparison with a call to user comparator.
Added test for custom comparators.
- Fix end of namespace comments.
- Fixed bug in picking inputs for a level-0 compaction.
When finding overlapping files, the covered range may expand
as files are added to the input set.  We now correctly expand
the range when this happens instead of continuing to use the
old range.  For example, suppose L0 contains files with the
following ranges:
F1: a .. d
F2:    c .. g
F3:       f .. j
and the initial compaction target is F3.  We used to search
for range f..j which yielded {F2,F3}.  However we now expand
the range as soon as another file is added.  In this case,
when F2 is added, we expand the range to c..j and restart the
search.  That picks up file F1 as well.
This change fixes a bug related to deleted keys showing up
incorrectly after a compaction as described in Issue 44.
(Sync with upstream @25072954)/"
rocksdb,"A number of fixes:
- Replace raw slice comparison with a call to user comparator.
Added test for custom comparators.
- Fix end of namespace comments.
- Fixed bug in picking inputs for a level-0 compaction.
When finding overlapping files, the covered range may expand
as files are added to the input set.  We now correctly expand
the range when this happens instead of continuing to use the
old range.  For example, suppose L0 contains files with the
following ranges:
F1: a .. d
F2:    c .. g
F3:       f .. j
and the initial compaction target is F3.  We used to search
for range f..j which yielded {F2,F3}.  However we now expand
the range as soon as another file is added.  In this case,
when F2 is added, we expand the range to c..j and restart the
search.  That picks up file F1 as well.
This change fixes a bug related to deleted keys showing up
incorrectly after a compaction as described in Issue 44.
(Sync with upstream @25072954)/A number of bugfixes:
- Added DB::CompactRange() method.
Changed manual compaction code so it breaks up compactions of
big ranges into smaller compactions.
Changed the code that pushes the output of memtable compactions
to higher levels to obey the grandparent constraint: i.e., we
must never have a single file in level L that overlaps too
much data in level L+1 (to avoid very expensive L-1 compactions).
Added code to pretty-print internal keys.
- Fixed bug where we would not detect overlap with files in
level-0 because we were incorrectly using binary search
on an array of files with overlapping ranges.
Added ""leveldb.sstables"" property that can be used to dump
all of the sstables and ranges that make up the db state.
- Removing post_write_snapshot support.  Email to leveldb mailing
list brought up no users, just confusion from one person about
what it meant.
- Fixing static_cast char to unsigned on BIG_ENDIAN platforms.
Fixes Issue 35 and Issue 36.
- Comment clarification to address leveldb Issue 37.
- Change license in posix_logger.h to match other files.
- A build problem where uint32 was used instead of uint32_t.
Sync with upstream @24408625/Bugfixes: for Get(), don't hold mutex while writing log.
- Fix bug in Get: when it triggers a compaction, it could sometimes
mark the compaction with the wrong level (if there was a gap
in the set of levels examined for the Get).
- Do not hold mutex while writing to the log file or to the
MANIFEST file.
Added a new benchmark that runs a writer thread concurrently with
reader threads.
Percentiles
------------------------------
micros/op: avg  median 99   99.9  99.99  99.999 max
------------------------------------------------------
before:    42   38     110  225   32000  42000  48000
after:     24   20     55   65    130    1100   7000
- Fixed race in optimized Get.  It should have been using the
pinned memtables, not the current memtables.
git-svn-id: https://leveldb.googlecode.com/svn/trunk@50 62dab493-f737-651d-591e-8d6aee1b9529/"
rocksdb,"A number of fixes:
- Replace raw slice comparison with a call to user comparator.
Added test for custom comparators.
- Fix end of namespace comments.
- Fixed bug in picking inputs for a level-0 compaction.
When finding overlapping files, the covered range may expand
as files are added to the input set.  We now correctly expand
the range when this happens instead of continuing to use the
old range.  For example, suppose L0 contains files with the
following ranges:
F1: a .. d
F2:    c .. g
F3:       f .. j
and the initial compaction target is F3.  We used to search
for range f..j which yielded {F2,F3}.  However we now expand
the range as soon as another file is added.  In this case,
when F2 is added, we expand the range to c..j and restart the
search.  That picks up file F1 as well.
This change fixes a bug related to deleted keys showing up
incorrectly after a compaction as described in Issue 44.
(Sync with upstream @25072954)/"
rocksdb,"A number of fixes:
- Replace raw slice comparison with a call to user comparator.
Added test for custom comparators.
- Fix end of namespace comments.
- Fixed bug in picking inputs for a level-0 compaction.
When finding overlapping files, the covered range may expand
as files are added to the input set.  We now correctly expand
the range when this happens instead of continuing to use the
old range.  For example, suppose L0 contains files with the
following ranges:
F1: a .. d
F2:    c .. g
F3:       f .. j
and the initial compaction target is F3.  We used to search
for range f..j which yielded {F2,F3}.  However we now expand
the range as soon as another file is added.  In this case,
when F2 is added, we expand the range to c..j and restart the
search.  That picks up file F1 as well.
This change fixes a bug related to deleted keys showing up
incorrectly after a compaction as described in Issue 44.
(Sync with upstream @25072954)/"
rocksdb,"A number of fixes:
- Replace raw slice comparison with a call to user comparator.
Added test for custom comparators.
- Fix end of namespace comments.
- Fixed bug in picking inputs for a level-0 compaction.
When finding overlapping files, the covered range may expand
as files are added to the input set.  We now correctly expand
the range when this happens instead of continuing to use the
old range.  For example, suppose L0 contains files with the
following ranges:
F1: a .. d
F2:    c .. g
F3:       f .. j
and the initial compaction target is F3.  We used to search
for range f..j which yielded {F2,F3}.  However we now expand
the range as soon as another file is added.  In this case,
when F2 is added, we expand the range to c..j and restart the
search.  That picks up file F1 as well.
This change fixes a bug related to deleted keys showing up
incorrectly after a compaction as described in Issue 44.
(Sync with upstream @25072954)/A number of bugfixes:
- Added DB::CompactRange() method.
Changed manual compaction code so it breaks up compactions of
big ranges into smaller compactions.
Changed the code that pushes the output of memtable compactions
to higher levels to obey the grandparent constraint: i.e., we
must never have a single file in level L that overlaps too
much data in level L+1 (to avoid very expensive L-1 compactions).
Added code to pretty-print internal keys.
- Fixed bug where we would not detect overlap with files in
level-0 because we were incorrectly using binary search
on an array of files with overlapping ranges.
Added ""leveldb.sstables"" property that can be used to dump
all of the sstables and ranges that make up the db state.
- Removing post_write_snapshot support.  Email to leveldb mailing
list brought up no users, just confusion from one person about
what it meant.
- Fixing static_cast char to unsigned on BIG_ENDIAN platforms.
Fixes Issue 35 and Issue 36.
- Comment clarification to address leveldb Issue 37.
- Change license in posix_logger.h to match other files.
- A build problem where uint32 was used instead of uint32_t.
Sync with upstream @24408625/"
rocksdb,"A number of fixes:
- Replace raw slice comparison with a call to user comparator.
Added test for custom comparators.
- Fix end of namespace comments.
- Fixed bug in picking inputs for a level-0 compaction.
When finding overlapping files, the covered range may expand
as files are added to the input set.  We now correctly expand
the range when this happens instead of continuing to use the
old range.  For example, suppose L0 contains files with the
following ranges:
F1: a .. d
F2:    c .. g
F3:       f .. j
and the initial compaction target is F3.  We used to search
for range f..j which yielded {F2,F3}.  However we now expand
the range as soon as another file is added.  In this case,
when F2 is added, we expand the range to c..j and restart the
search.  That picks up file F1 as well.
This change fixes a bug related to deleted keys showing up
incorrectly after a compaction as described in Issue 44.
(Sync with upstream @25072954)/A number of bugfixes:
- Added DB::CompactRange() method.
Changed manual compaction code so it breaks up compactions of
big ranges into smaller compactions.
Changed the code that pushes the output of memtable compactions
to higher levels to obey the grandparent constraint: i.e., we
must never have a single file in level L that overlaps too
much data in level L+1 (to avoid very expensive L-1 compactions).
Added code to pretty-print internal keys.
- Fixed bug where we would not detect overlap with files in
level-0 because we were incorrectly using binary search
on an array of files with overlapping ranges.
Added ""leveldb.sstables"" property that can be used to dump
all of the sstables and ranges that make up the db state.
- Removing post_write_snapshot support.  Email to leveldb mailing
list brought up no users, just confusion from one person about
what it meant.
- Fixing static_cast char to unsigned on BIG_ENDIAN platforms.
Fixes Issue 35 and Issue 36.
- Comment clarification to address leveldb Issue 37.
- Change license in posix_logger.h to match other files.
- A build problem where uint32 was used instead of uint32_t.
Sync with upstream @24408625/Bugfixes: for Get(), don't hold mutex while writing log.
- Fix bug in Get: when it triggers a compaction, it could sometimes
mark the compaction with the wrong level (if there was a gap
in the set of levels examined for the Get).
- Do not hold mutex while writing to the log file or to the
MANIFEST file.
Added a new benchmark that runs a writer thread concurrently with
reader threads.
Percentiles
------------------------------
micros/op: avg  median 99   99.9  99.99  99.999 max
------------------------------------------------------
before:    42   38     110  225   32000  42000  48000
after:     24   20     55   65    130    1100   7000
- Fixed race in optimized Get.  It should have been using the
pinned memtables, not the current memtables.
git-svn-id: https://leveldb.googlecode.com/svn/trunk@50 62dab493-f737-651d-591e-8d6aee1b9529/"
rocksdb,"A number of fixes:
- Replace raw slice comparison with a call to user comparator.
Added test for custom comparators.
- Fix end of namespace comments.
- Fixed bug in picking inputs for a level-0 compaction.
When finding overlapping files, the covered range may expand
as files are added to the input set.  We now correctly expand
the range when this happens instead of continuing to use the
old range.  For example, suppose L0 contains files with the
following ranges:
F1: a .. d
F2:    c .. g
F3:       f .. j
and the initial compaction target is F3.  We used to search
for range f..j which yielded {F2,F3}.  However we now expand
the range as soon as another file is added.  In this case,
when F2 is added, we expand the range to c..j and restart the
search.  That picks up file F1 as well.
This change fixes a bug related to deleted keys showing up
incorrectly after a compaction as described in Issue 44.
(Sync with upstream @25072954)/"
rocksdb,"Pass system's CFLAGS, remove exit time destructor, sstable bug fix.
- Pass system's values of CFLAGS,LDFLAGS.
Don't override OPT if it's already set.
Original patch by Alessio Treglia <alessio@debian.org>:
http://code.google.com/p/leveldb/issues/detail?id=27#c6
- Remove 1 exit time destructor from leveldb.
See http://crbug.com/101600
- Fix problem where sstable building code would pass an
internal key to the user comparator.
(Sync with uptream at 25436817.)/A number of fixes:
- Replace raw slice comparison with a call to user comparator.
Added test for custom comparators.
- Fix end of namespace comments.
- Fixed bug in picking inputs for a level-0 compaction.
When finding overlapping files, the covered range may expand
as files are added to the input set.  We now correctly expand
the range when this happens instead of continuing to use the
old range.  For example, suppose L0 contains files with the
following ranges:
F1: a .. d
F2:    c .. g
F3:       f .. j
and the initial compaction target is F3.  We used to search
for range f..j which yielded {F2,F3}.  However we now expand
the range as soon as another file is added.  In this case,
when F2 is added, we expand the range to c..j and restart the
search.  That picks up file F1 as well.
This change fixes a bug related to deleted keys showing up
incorrectly after a compaction as described in Issue 44.
(Sync with upstream @25072954)/A number of bugfixes:
- Added DB::CompactRange() method.
Changed manual compaction code so it breaks up compactions of
big ranges into smaller compactions.
Changed the code that pushes the output of memtable compactions
to higher levels to obey the grandparent constraint: i.e., we
must never have a single file in level L that overlaps too
much data in level L+1 (to avoid very expensive L-1 compactions).
Added code to pretty-print internal keys.
- Fixed bug where we would not detect overlap with files in
level-0 because we were incorrectly using binary search
on an array of files with overlapping ranges.
Added ""leveldb.sstables"" property that can be used to dump
all of the sstables and ranges that make up the db state.
- Removing post_write_snapshot support.  Email to leveldb mailing
list brought up no users, just confusion from one person about
what it meant.
- Fixing static_cast char to unsigned on BIG_ENDIAN platforms.
Fixes   Issue 35 and Issue 36.
- Comment clarification to address leveldb Issue 37.
- Change license in posix_logger.h to match other files.
- A build problem where uint32 was used instead of uint32_t.
Sync with upstream @24408625/Bugfixes: for Get(), don't hold mutex while writing log.
- Fix bug in Get: when it triggers a compaction, it could sometimes
mark the compaction with the wrong level (if there was a gap
in the set of levels examined for the Get).
- Do not hold mutex while writing to the log file or to the
MANIFEST file.
Added a new benchmark that runs a writer thread concurrently with
reader threads.
Percentiles
------------------------------
micros/op: avg  median 99   99.9  99.99  99.999 max
------------------------------------------------------
before:    42   38     110  225   32000  42000  48000
after:     24   20     55   65    130    1100   7000
- Fixed race in optimized Get.  It should have been using the
pinned memtables, not the current memtables.
git-svn-id: https://leveldb.googlecode.com/svn/trunk@50 62dab493-f737-651d-591e-8d6aee1b9529/"
rocksdb,"A number of fixes:
- Replace raw slice comparison with a call to user comparator.
Added test for custom comparators.
- Fix end of namespace comments.
- Fixed bug in picking inputs for a level-0 compaction.
When finding overlapping files, the covered range may expand
as files are added to the input set.  We now correctly expand
the range when this happens instead of continuing to use the
old range.  For example, suppose L0 contains files with the
following ranges:
F1: a .. d
F2:    c .. g
F3:       f .. j
and the initial compaction target is F3.  We used to search
for range f..j which yielded {F2,F3}.  However we now expand
the range as soon as another file is added.  In this case,
when F2 is added, we expand the range to c..j and restart the
search.  That picks up file F1 as well.
This change fixes a bug related to deleted keys showing up
incorrectly after a compaction as described in Issue 44.
(Sync with upstream @25072954)/A number of bugfixes:
- Added DB::CompactRange() method.
Changed manual compaction code so it breaks up compactions of
big ranges into smaller compactions.
Changed the code that pushes the output of memtable compactions
to higher levels to obey the grandparent constraint: i.e., we
must never have a single file in level L that overlaps too
much data in level L+1 (to avoid very expensive L-1 compactions).
Added code to pretty-print internal keys.
- Fixed bug where we would not detect overlap with files in
level-0 because we were incorrectly using binary search
on an array of files with overlapping ranges.
Added ""leveldb.sstables"" property that can be used to dump
all of the sstables and ranges that make up the db state.
- Removing post_write_snapshot support.  Email to leveldb mailing
list brought up no users, just confusion from one person about
what it meant.
- Fixing static_cast char to unsigned on BIG_ENDIAN platforms.
Fixes Issue 35 and Issue 36.
- Comment clarification to address leveldb Issue 37.
- Change license in posix_logger.h to match other files.
- A build problem where uint32 was used instead of uint32_t.
Sync with upstream @24408625/Bugfixes: for Get(), don't hold mutex while writing log.
- Fix bug in Get: when it triggers a compaction, it could sometimes
mark the compaction with the wrong level (if there was a gap
in the set of levels examined for the Get).
- Do not hold mutex while writing to the log file or to the
MANIFEST file.
Added a new benchmark that runs a writer thread concurrently with
reader threads.
Percentiles
------------------------------
micros/op: avg  median 99   99.9  99.99  99.999 max
------------------------------------------------------
before:    42   38     110  225   32000  42000  48000
after:     24   20     55   65    130    1100   7000
- Fixed race in optimized Get.  It should have been using the
pinned memtables, not the current memtables.
git-svn-id: https://leveldb.googlecode.com/svn/trunk@50 62dab493-f737-651d-591e-8d6aee1b9529/"
rocksdb,"A number of fixes:
- Replace raw slice comparison with a call to user comparator.
Added test for custom comparators.
- Fix end of namespace comments.
- Fixed bug in picking inputs for a level-0 compaction.
When finding overlapping files, the covered range may expand
as files are added to the input set.  We now correctly expand
the range when this happens instead of continuing to use the
old range.  For example, suppose L0 contains files with the
following ranges:
F1: a .. d
F2:    c .. g
F3:       f .. j
and the initial compaction target is F3.  We used to search
for range f..j which yielded {F2,F3}.  However we now expand
the range as soon as another file is added.  In this case,
when F2 is added, we expand the range to c..j and restart the
search.  That picks up file F1 as well.
This change fixes a bug related to deleted keys showing up
incorrectly after a compaction as described in Issue 44.
(Sync with upstream @25072954)/"
rocksdb,"A number of fixes:
- Replace raw slice comparison with a call to user comparator.
Added test for custom comparators.
- Fix end of namespace comments.
- Fixed bug in picking inputs for a level-0 compaction.
When finding overlapping files, the covered range may expand
as files are added to the input set.  We now correctly expand
the range when this happens instead of continuing to use the
old range.  For example, suppose L0 contains files with the
following ranges:
F1: a .. d
F2:    c .. g
F3:       f .. j
and the initial compaction target is F3.  We used to search
for range f..j which yielded {F2,F3}.  However we now expand
the range as soon as another file is added.  In this case,
when F2 is added, we expand the range to c..j and restart the
search.  That picks up file F1 as well.
This change fixes a bug related to deleted keys showing up
incorrectly after a compaction as described in Issue 44.
(Sync with upstream @25072954)/"
rocksdb,"A number of fixes:
- Replace raw slice comparison with a call to user comparator.
Added test for custom comparators.
- Fix end of namespace comments.
- Fixed bug in picking inputs for a level-0 compaction.
When finding overlapping files, the covered range may expand
as files are added to the input set.  We now correctly expand
the range when this happens instead of continuing to use the
old range.  For example, suppose L0 contains files with the
following ranges:
F1: a .. d
F2:    c .. g
F3:       f .. j
and the initial compaction target is F3.  We used to search
for range f..j which yielded {F2,F3}.  However we now expand
the range as soon as another file is added.  In this case,
when F2 is added, we expand the range to c..j and restart the
search.  That picks up file F1 as well.
This change fixes a bug related to deleted keys showing up
incorrectly after a compaction as described in Issue 44.
(Sync with upstream @25072954)/"
rocksdb,"Added bloom filter support.
In particular, we add a new FilterPolicy class.  An instance
of this class can be supplied in Options when opening a
database.  If supplied, the instance is used to generate
summaries of keys (e.g., a bloom filter) which are placed in
sstables.  These summaries are consulted by DB::Get() so we
can avoid reading sstable blocks that are guaranteed to not
contain the key we are looking for.
This change provides one implementation of FilterPolicy
based on bloom filters.
Other changes:
- Updated version number to 1.4.
- Some build tweaks.
- C binding for CompactRange.
- A few more benchmarks: deleteseq, deleterandom, readmissing, seekrandom.
- Minor .gitignore update./"
rocksdb,"Added bloom filter support.
In particular, we add a new FilterPolicy class.  An instance
of this class can be supplied in Options when opening a
database.  If supplied, the instance is used to generate
summaries of keys (e.g., a bloom filter) which are placed in
sstables.  These summaries are consulted by DB::Get() so we
can avoid reading sstable blocks that are guaranteed to not
contain the key we are looking for.
This change provides one implementation of FilterPolicy
based on bloom filters.
Other changes:
- Updated version number to 1.4.
- Some build tweaks.
- C binding for CompactRange.
- A few more benchmarks: deleteseq, deleterandom, readmissing, seekrandom.
- Minor .gitignore update./fixed issues 66 (leaking files on disk error)  and 68 (no sync of CURRENT file)/"
rocksdb,"Added bloom filter support.
In particular, we add a new FilterPolicy class.  An instance
of this class can be supplied in Options when opening a
database.  If supplied, the instance is used to generate
summaries of keys (e.g., a bloom filter) which are placed in
sstables.  These summaries are consulted by DB::Get() so we
can avoid reading sstable blocks that are guaranteed to not
contain the key we are looking for.
This change provides one implementation of FilterPolicy
based on bloom filters.
Other changes:
- Updated version number to 1.4.
- Some build tweaks.
- C binding for CompactRange.
- A few more benchmarks: deleteseq, deleterandom, readmissing, seekrandom.
- Minor .gitignore update./Build fixes and cleanups:
(1) Separate out C++ and CC flags (fixes c_test compilation)
(2) Move snappy/perftools detection to script
(3) Fix db_bench_sqlite3 and db_bench_tree_db build rules/"
rocksdb,"add disable WAL option
Summary: add disable WAL option
Test Plan: new testcase in db_test.cc
Reviewers: dhruba
Reviewed By: dhruba
Differential Revision: https://reviews.facebook.net/D4011/"
rocksdb,"add bzip2 compression
Summary: add bzip2 compression
Test Plan: testcases in table_test
Reviewers: dhruba
Reviewed By: dhruba
Differential Revision: https://reviews.facebook.net/D3909/add zlib compression
Summary: add zlib compression
Test Plan: Will add more testcases
Reviewers: dhruba
Reviewed By: dhruba
Differential Revision: https://reviews.facebook.net/D3873/"
rocksdb,"This is the mega-patch multi-threaded compaction
published in https://reviews.facebook.net/D5997.
Summary:
This patch allows compaction to occur in multiple background threads
concurrently.
If a manual compaction is issued, the system falls back to a
single-compaction-thread model. This is done to ensure correctess
and simplicity of code. When the manual compaction is finished,
the system resumes its concurrent-compaction mode automatically.
The updates to the manifest are done via group-commit approach.
Test Plan: run db_bench/Fix compiler warnings. Use uint64_t instead of uint.
Summary: Fix compiler warnings. Use uint64_t instead of uint.
Test Plan: build using -Wall
Reviewers: heyongqiang
Reviewed By: heyongqiang
Differential Revision: https://reviews.facebook.net/D5355/Introduce a new method Env->Fsync() that issues fsync (instead of fdatasync).
Summary:
Introduce a new method Env->Fsync() that issues fsync (instead of fdatasync).
This is needed for data durability when running on ext3 filesystems.
Added options to the benchmark db_bench to generate performance numbers
with either fsync or fdatasync enabled.
Cleaned up Makefile to build leveldb_shell only when building the thrift
leveldb server.
Test Plan: build and run benchmark
Reviewers: heyongqiang
Reviewed By: heyongqiang
Differential Revision: https://reviews.facebook.net/D4911/Prevent concurrent multiple opens of leveldb database.
Summary:
The fcntl call cannot detect lock conflicts when invoked multiple times
from the same thread.
Use a static lockedFile Set to record the paths that are locked.
A lockfile request checks to see if htis filename already exists in
lockedFiles, if so, then it triggers an error. Otherwise, it inserts
the filename in the lockedFiles Set.
A unlock file request verifies that the filename is in the lockedFiles
set and removes it from lockedFiles set.
Test Plan: unit test attached
Reviewers: heyongqiang
Reviewed By: heyongqiang
Differential Revision: https://reviews.facebook.net/D4755/"
rocksdb,"Fix all warnings generated by -Wall option to the compiler.
Summary:
The default compilation process now uses ""-Wall"" to compile.
Fix all compilation error generated by gcc.
Test Plan: make all check
Reviewers: heyongqiang, emayanke, sheki
Reviewed By: heyongqiang
CC: MarkCallaghan
Differential Revision: https://reviews.facebook.net/D6525/"
rocksdb,"Flush Data at object destruction if disableWal is used.
Summary:
Added a conditional flush in ~DBImpl to flush.
There is still a chance of writes not being persisted if there is a
crash (not a clean shutdown) before the DBImpl instance is destroyed.
Test Plan: modified db_test to meet the new expectations.
Reviewers: dhruba, heyongqiang
Differential Revision: https://reviews.facebook.net/D6519/Fix all warnings generated by -Wall option to the compiler.
Summary:
The default compilation process now uses ""-Wall"" to compile.
Fix all compilation error generated by gcc.
Test Plan: make all check
Reviewers: heyongqiang, emayanke, sheki
Reviewed By: heyongqiang
CC: MarkCallaghan
Differential Revision: https://reviews.facebook.net/D6525/Compilation problem introduced by previous
commit 854c66b089bef5d27f79750884f70f6e2c8c69da.
Summary:
Compilation problem introduced by previous
commit 854c66b089bef5d27f79750884f70f6e2c8c69da.
Test Plan:  make check/fix test failure
Summary: as subject
Test Plan: db_test
Reviewers: dhruba, MarkCallaghan
Reviewed By: MarkCallaghan
Differential Revision: https://reviews.facebook.net/D6309/add a test case to make sure chaning num_levels will fail Summary:
Summary: as subject
Test Plan: db_test
Reviewers: dhruba, MarkCallaghan
Reviewed By: MarkCallaghan
Differential Revision: https://reviews.facebook.net/D6303/Allow having different compression algorithms on different levels.
Summary:
The leveldb API is enhanced to support different compression algorithms at
different levels.
This adds the option min_level_to_compress to db_bench that specifies
the minimum level for which compression should be done when
compression is enabled. This can be used to disable compression for levels
0 and 1 which are likely to suffer from stalls because of the CPU load
for memtable flushes and (L0,L1) compaction.  Level 0 is special as it
gets frequent memtable flushes. Level 1 is special as it frequently
gets all:all file compactions between it and level 0. But all other levels
could be the same. For any level N where N > 1, the rate of sequential
IO for that level should be the same. The last level is the
exception because it might not be full and because files from it are
not read to compact with the next larger level.
The same amount of time will be spent doing compaction at any
level N excluding N=0, 1 or the last level. By this standard all
of those levels should use the same compression. The difference is that
the loss (using more disk space) from a faster compression algorithm
is less significant for N=2 than for N=3. So we might be willing to
trade disk space for faster write rates with no compression
for L0 and L1, snappy for L2, zlib for L3. Using a faster compression
algorithm for the mid levels also allows us to reclaim some cpu
without trading off much loss in disk space overhead.
Also note that little is to be gained by compressing levels 0 and 1. For
a 4-level tree they account for 10% of the data. For a 5-level tree they
account for 1% of the data.
With compression enabled:
* memtable flush rate is ~18MB/second
* (L0,L1) compaction rate is ~30MB/second
With compression enabled but min_level_to_compress=2
* memtable flush rate is ~320MB/second
* (L0,L1) compaction rate is ~560MB/second
This practicaly takes the same code from https://reviews.facebook.net/D6225
but makes the leveldb api more general purpose with a few additional
lines of code.
Test Plan: make check
Differential Revision: https://reviews.facebook.net/D6261/Fix unit test failure caused by delaying deleting obsolete files.
Summary:
A previous commit 4c107587ed47af84633f8c61f65516a504d6cd98 introduced
the idea that some version updates might not delete obsolete files.
This means that if a unit test blindly counts the number of files
in the db directory it might not represent the true state of the database.
Use GetLiveFiles() insteads to count the number of live files in the database.
Test Plan:
make check/Fix unit test failure caused by delaying deleting obsolete files.
Summary:
A previous commit 4c107587ed47af84633f8c61f65516a504d6cd98 introduced
the idea that some version updates might not delete obsolete files.
This means that if a unit test blindly counts the number of files
in the db directory it might not represent the true state of the database.
Use GetLiveFiles() insteads to count the number of live files in the database.
Test Plan: make check
Reviewers: heyongqiang, MarkCallaghan
Reviewed By: MarkCallaghan
Differential Revision: https://reviews.facebook.net/D6207/Trigger read compaction only if seeks to storage are incurred.
Summary:
In the current code, a Get() call can trigger compaction if it has to look at more than one file. This causes unnecessary compaction because looking at more than one file is a penalty only if the file is not yet in the cache. Also, th current code counts these files before the bloom filter check is applied.
This patch counts a 'seek' only if the file fails the bloom filter
check and has to read in data block(s) from the storage.
This patch also counts a 'seek' if a file is not present in the file-cache, because opening a file means that its index blocks need to be read into cache.
Test Plan: unit test attached. I will probably add one more unti tests.
Reviewers: heyongqiang
Reviewed By: heyongqiang
CC: MarkCallaghan
Differential Revision: https://reviews.facebook.net/D5709/put log in a seperate dir
Summary: added a new option db_log_dir, which points the log dir. Inside that dir, in order to make log names unique, the log file name is prefixed with the leveldb data dir absolute path.
Test Plan: db_test
Reviewers: dhruba
Reviewed By: dhruba
Differential Revision: https://reviews.facebook.net/D5205/Do not spin in a tight loop attempting compactions if there is a compaction error
Summary: as subject. ported the change from google code leveldb 1.5
Test Plan: run db_test
Reviewers: dhruba
Differential Revision: https://reviews.facebook.net/D4839/Prevent concurrent multiple opens of leveldb database.
Summary:
The fcntl call cannot detect lock conflicts when invoked multiple times
from the same thread.
Use a static lockedFile Set to record the paths that are locked.
A lockfile request checks to see if htis filename already exists in
lockedFiles, if so, then it triggers an error. Otherwise, it inserts
the filename in the lockedFiles Set.
A unlock file request verifies that the filename is in the lockedFiles
set and removes it from lockedFiles set.
Test Plan: unit test attached
Reviewers: heyongqiang
Reviewed By: heyongqiang
Differential Revision: https://reviews.facebook.net/D4755/use ts as suffix for LOG.old files
Summary: as subject and only maintain 10 log files.
Test Plan: new test in db_test
Reviewers: dhruba
Differential Revision: https://reviews.facebook.net/D4731/"
rocksdb,"Fixed cache key for block cache
Summary:
Added function to `RandomAccessFile` to generate an unique ID for that file. Currently only `PosixRandomAccessFile` has this behaviour implemented and only on Linux.
Changed how key is generated in `Table::BlockReader`.
Added tests to check whether the unique ID is stable, unique and not a prefix of another unique ID. Added tests to see that `Table` uses the cache more efficiently.
Test Plan: make check
Reviewers: chip, vamsi, dhruba
Reviewed By: chip
CC: leveldb
Differential Revision: https://reviews.facebook.net/D8145/Fix a number of object lifetime/ownership issues
Summary:
Replace manual memory management with std::unique_ptr in a
number of places; not exhaustive, but this fixes a few leaks with file
handles as well as clarifies semantics of the ownership of file handles
with log classes.
Test Plan: db_stress, make check
Reviewers: dhruba
Reviewed By: dhruba
CC: zshao, leveldb, heyongqiang
Differential Revision: https://reviews.facebook.net/D8043/Add optional clang compile mode
Summary:
clang is an alternate compiler based on llvm.  It produces
nicer error messages and finds some bugs that gcc doesn't, such as the
size_t change in this file (which caused some write return values to be
misinterpreted!)
Clang isn't the default; to try it, do ""USE_CLANG=1 make"" or ""export
USE_CLANG=1"" then make as normal
Test Plan: ""make check"" and ""USE_CLANG=1 make check""
Reviewers: dhruba
Reviewed By: dhruba
Differential Revision: https://reviews.facebook.net/D7899/Added clearer error message for failure to create db directory in DBImpl::Recover()
Summary:
Changed CreateDir() to CreateDirIfMissing() so a directory that already exists now causes and error.
Fixed CreateDirIfMissing() and added Env.DirExists()
Test Plan:
make check to test for regessions
Ran the following to test if the error message is not about lock files not existing
./db_bench --db=dir/testdb
After creating a file ""testdb"", ran the following to see if it failed with sane error message:
./db_bench --db=testdb
Reviewers: dhruba, emayanke, vamsi, sheki
Reviewed By: emayanke
CC: leveldb
Differential Revision: https://reviews.facebook.net/D7707/Fix a race condition while processing tasks by background threads.
Summary:
Suppose you submit 100 background tasks one after another. The first
enqueu task finds that the queue is empty and wakes up one worker thread.
Now suppose that all remaining 99 work items are enqueued, they do not
wake up any worker threads because the queue is already non-empty.
This causes a situation when there are 99 tasks in the task queue but
only one worker thread is processing a task while the remaining
worker threads are waiting.
The fix is to always wakeup one worker thread while enqueuing a task.
I also added a check to count the number of elements in the queue
to help in debugging.
Test Plan: make clean check.
Reviewers: chip
Reviewed By: chip
CC: leveldb
Differential Revision: https://reviews.facebook.net/D7203/Fix all the lint errors.
Summary:
Scripted and removed all trailing spaces and converted all tabs to
spaces.
Also fixed other lint errors.
All lint errors from this point of time should be taken seriously.
Test Plan: make all check
Reviewers: dhruba
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D7059/"
rocksdb,"Make Java Client compilable.
Summary:
Debug and ported changes from the Open Source Github repo to our repo.
Wrote a script to easy build the java Library. future compiling java lib should just be running this script.
Test Plan: it compiles.
Reviewers: dhruba, leveldb
Reviewed By: dhruba
Differential Revision: https://reviews.facebook.net/D7323/"
rocksdb,"Make Java Client compilable.
Summary:
Debug and ported changes from the Open Source Github repo to our repo.
Wrote a script to easy build the java Library. future compiling java lib should just be running this script.
Test Plan: it compiles.
Reviewers: dhruba, leveldb
Reviewed By: dhruba
Differential Revision: https://reviews.facebook.net/D7323/"
rocksdb,"Fix a number of object lifetime/ownership issues
Summary:
Replace manual memory management with std::unique_ptr in a
number of places; not exhaustive, but this fixes a few leaks with file
handles as well as clarifies semantics of the ownership of file handles
with log classes.
Test Plan: db_stress, make check
Reviewers: dhruba
Reviewed By: dhruba
CC: zshao, leveldb, heyongqiang
Differential Revision: https://reviews.facebook.net/D8043/"
rocksdb,"Fix poor error on num_levels mismatch and few other minor improvements
Summary:
Previously, if you opened a db with num_levels set lower than
the database, you received the unhelpful message ""Corruption:
VersionEdit: new-file entry.""  Now you get a more verbose message
describing the issue.
Also, fix handling of compression_levels (both the run-over-the-end
issue and the memory management of it).
Lastly, unique_ptr'ify a couple of minor calls.
Test Plan: make check
Reviewers: dhruba
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D8151/Fix a number of object lifetime/ownership issues
Summary:
Replace manual memory management with std::unique_ptr in a
number of places; not exhaustive, but this fixes a few leaks with file
handles as well as clarifies semantics of the ownership of file handles
with log classes.
Test Plan: db_stress, make check
Reviewers: dhruba
Reviewed By: dhruba
CC: zshao, leveldb, heyongqiang
Differential Revision: https://reviews.facebook.net/D8043/Port fix for Leveldb manifest writing bug from Open-Source
Summary:
Pretty much a blind copy of the patch in open source.
Hope to get this in before we make a release
Test Plan: make clean check
Reviewers: dhruba, heyongqiang
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D7809/Added meta-database support.
Summary:
Added kMetaDatabase for meta-databases in db/filename.h along with supporting
fuctions.
Fixed switch in DBImpl so that it also handles kMetaDatabase.
Fixed DestroyDB() that it can handle destroying meta-databases.
Test Plan: make check
Reviewers: sheki, emayanke, vamsi, dhruba
Reviewed By: dhruba
Differential Revision: https://reviews.facebook.net/D7245/Fix Bug in Binary Search for files containing a seq no. and delete Archived Log Files during Destroy DB.
Summary:
* Fixed implementation bug in Binary_Searvch introduced in https://reviews.facebook.net/D7119
* Binary search is also overflow safe.
* Delete archive log files and archive dir during DestroyDB
Test Plan: make check
Reviewers: dhruba
CC: kosievdmerwe, emayanke
Differential Revision: https://reviews.facebook.net/D7263/Fix all the lint errors.
Summary:
Scripted and removed all trailing spaces and converted all tabs to
spaces.
Also fixed other lint errors.
All lint errors from this point of time should be taken seriously.
Test Plan: make all check
Reviewers: dhruba
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D7059/Fix compilation error while compiling unit tests with OPT=-g
Summary:
Fix compilation error while compiling with OPT=-g
Test Plan:
make clean check OPT=-g
Reviewers:
CC:
Task ID: #
Blame Rev:/Fix a coding error in db_test.cc
Summary: The new function MinLevelToCompress in db_test.cc was incomplete. It needs to tell the calling function-TEST whether the test has to be skipped or not
Test Plan: make all;./db_test
Reviewers: dhruba, heyongqiang
Reviewed By: dhruba
CC: sheki
Differential Revision: https://reviews.facebook.net/D6771/Fix a coding error in db_test.cc
Summary: The new function MinLevelToCompress in db_test.cc was incomplete. It needs to tell the calling function-TEST whether the test has to be skipped or not
Test Plan: make all;./db_test
Reviewers: dhruba, heyongqiang
Reviewed By: dhruba
CC: sheki
Differential Revision: https://reviews.facebook.net/D6771/"
rocksdb,"Fix poor error on num_levels mismatch and few other minor improvements
Summary:
Previously, if you opened a db with num_levels set lower than
the database, you received the unhelpful message ""Corruption:
VersionEdit: new-file entry.""  Now you get a more verbose message
describing the issue.
Also, fix handling of compression_levels (both the run-over-the-end
issue and the memory management of it).
Lastly, unique_ptr'ify a couple of minor calls.
Test Plan: make check
Reviewers: dhruba
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D8151/The c_test was sometimes failing with an assertion.
Summary:
On fast filesystems (e.g. /dev/shm and ext4), the flushing
of memstore to disk was fast and quick, and the background compaction
thread was not getting scheduled fast enough to delete obsolete
files before the db was closed. This caused the repair method
to pick up those files that were not part of the db and the unit
test was failing.
The fix is to enhance the unti test to run a compaction before
closing the database so that all files that are not part of the
database are truly deleted from the filesystem.
Test Plan: make c_test; ./c_test
Reviewers: chip, emayanke, sheki
Reviewed By: chip
CC: leveldb
Differential Revision: https://reviews.facebook.net/D6915/"
rocksdb,"Avoid global static initialization in Env::Default()
Summary:
Mark's task description from #2316777
Env::Default() comes from util/env_posix.cc
This is a static global.
static PosixEnv default_env;
Env* Env::Default() {
return &default_env;
}
-----
These globals assume default_env was initialized first. I don't think that is safe or correct to do (http://stackoverflow.com/questions/1005685/c-static-initialization-order)
const string AutoRollLoggerTest::kTestDir(
test::TmpDir() + ""/db_log_test"");
const string AutoRollLoggerTest::kLogFile(
test::TmpDir() + ""/db_log_test/LOG"");
Env* AutoRollLoggerTest::env = Env::Default();
Test Plan:
run make clean && make && make check
But how can I know if it works in Ubuntu?
Reviewers: MarkCallaghan, chip
Reviewed By: chip
CC: leveldb, dhruba, haobo
Differential Revision: https://reviews.facebook.net/D10491/Initialize parameters in the constructor.
Summary:
RocksDB doesn't build on Ubuntu VM .. shoudl be fixed with this patch.
g++ --version
g++ (Ubuntu/Linaro 4.6.3-1ubuntu5) 4.6.3
util/env_posix.cc:68:24: sorry, unimplemented: non-static data member initializers
util/env_posix.cc:68:24: error: ISO C++ forbids in-class initialization of non-const static member use_os_buffer
util/env_posix.cc:113:24: sorry, unimplemented: non-static data member initializers
util/env_posix.cc:113:24: error: ISO C++ forbids in-class initialization of non-const static member use_os_buffer
Test Plan: make check
Reviewers: sheki, leveldb
Reviewed By: sheki
Differential Revision: https://reviews.facebook.net/D10461/Exit and Join the background compaction threads while running rocksdb tests
Summary:
The background compaction threads are never exitted and therefore caused
memory-leaks while running rpcksdb tests. Have changed the PosixEnv destructor to exit and join them and changed the tests likewise
The memory leaked has reduced from 320 bytes to 64 bytes in all the tests. The 64
bytes is relating to
pthread_exit, but still have to figure out why. The stack-trace right now with
table_test.cc = 64 bytes in 1 blocks are possibly lost in loss record 4 of 5
at 0x475D8C: malloc (jemalloc.c:914)
by 0x400D69E: _dl_map_object_deps (dl-deps.c:505)
by 0x4013393: dl_open_worker (dl-open.c:263)
by 0x400F015: _dl_catch_error (dl-error.c:178)
by 0x4013B2B: _dl_open (dl-open.c:569)
by 0x5D3E913: do_dlopen (dl-libc.c:86)
by 0x400F015: _dl_catch_error (dl-error.c:178)
by 0x5D3E9D6: __libc_dlopen_mode (dl-libc.c:47)
by 0x5048BF3: pthread_cancel_init (unwind-forcedunwind.c:53)
by 0x5048DC9: _Unwind_ForcedUnwind (unwind-forcedunwind.c:126)
by 0x5046D9F: __pthread_unwind (unwind.c:130)
by 0x50413A4: pthread_exit (pthreadP.h:289)
Test Plan: make all check
Reviewers: dhruba, sheki, haobo
Reviewed By: dhruba
CC: leveldb, chip
Differential Revision: https://reviews.facebook.net/D9573/Set FD_CLOEXEC after each file open
Summary: as subject. This is causing problem in adsconv. Ideally, this flags should be set in open. But that is only supported in Linux kernel ?2.6.23 and glibc ?2.7.
Test Plan:
db_test
run db_test
Reviewers: dhruba, MarkCallaghan, haobo
Reviewed By: dhruba
CC: leveldb, chip
Differential Revision: https://reviews.facebook.net/D10089/Fixing delete in env_posix.cc
Summary: Was deleting incorrectly. Should delete the whole array.
Test Plan: make;valgrind stops complaining about Mismatched free/delete
Reviewers: dhruba, sheki
Reviewed By: sheki
CC: leveldb, haobo
Differential Revision: https://reviews.facebook.net/D10059/Initialize variable in constructor for PosixEnv::checkedDiskForMmap_
Summary: This caused compilation problems on some gcc platforms during the third-partyrelease
Test Plan: make
Reviewers: sheki
Reviewed By: sheki
Differential Revision: https://reviews.facebook.net/D9627/Use posix_fallocate as default.
Summary:
Ftruncate does not throw an error on disk-full. This causes Sig-bus in
the case where the database tries to issue a Put call on a full-disk.
Use posix_fallocate for allocation instead of truncate.
Add a check to use MMaped files only on ext4, xfs and tempfs, as
posix_fallocate is very slow on ext3 and older.
Test Plan: make all check
Reviewers: dhruba, chip
Reviewed By: dhruba
CC: adsharma, leveldb
Differential Revision: https://reviews.facebook.net/D9291/"
rocksdb,"[RocksDB] Move table.h to table/
Summary:
- don't see a point exposing table.h to the public.
- fixed make clean to remove also *.d files.
Test Plan: make check; db_stress
Reviewers: dhruba, heyongqiang
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D10479/"
rocksdb,"Fix more signed-unsigned comparisons
Summary: Some comparisons left in log_test.cc and db_test.cc complained by make
Test Plan: make
Reviewers: dhruba, sheki
Reviewed By: dhruba
Differential Revision: https://reviews.facebook.net/D9537/"
rocksdb,"[RocksDB] fix compaction filter trigger condition
Summary:
Currently, compaction filter is run on internal key older than the oldest snapshot, which is incorrect.
Compaction filter should really be run on the most recent internal key when there is no external snapshot.
Test Plan: make check; db_stress
Reviewers: dhruba
Reviewed By: dhruba
Differential Revision: https://reviews.facebook.net/D10641/[RocksDB] Move table.h to table/
Summary:
- don't see a point exposing table.h to the public.
- fixed make clean to remove also *.d files.
Test Plan: make check; db_stress
Reviewers: dhruba, heyongqiang
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D10479/[RocksDB][Bug] Look at all the files, not just the first file in TransactionLogIter as BatchWrites can leave it in Limbo
Summary:
Transaction Log Iterator did not move to the next file in the series if there was a write batch at the end of the currentFile.
The solution is if the last seq no. of the current file is < RequestedSeqNo. Assume the first seqNo. of the next file has to satisfy the request.
Also major refactoring around the code. Moved opening the logreader to a seperate function, got rid of goto.
Test Plan: added a unit test for it.
Reviewers: dhruba, heyongqiang
Reviewed By: heyongqiang
CC: leveldb, emayanke
Differential Revision: https://reviews.facebook.net/D10029/[Rocksdb] Fix Crash on finding a db with no log files. Error out instead
Summary:
If the vector returned by GetUpdatesSince is empty, it is still returned to the
user. This causes it throw an std::range error.
The probable file list is checked and it returns an IOError status instead of OK now.
Test Plan: added a unit test.
Reviewers: dhruba, heyongqiang
Reviewed By: heyongqiang
CC: leveldb
Differential Revision: https://reviews.facebook.net/D9771/Use non-mmapd files for Write-Ahead Files
Summary:
Use non mmapd files for Write-Ahead log.
Earlier use of MMaped files. made the log iterator read ahead and miss records.
Now the reader and writer will point to the same physical location.
There is no perf regression :
./db_bench --benchmarks=fillseq --db=/dev/shm/mmap_test --num=$(million 20) --use_existing_db=0 --threads=2
with This diff :
fillseq      :      10.756 micros/op 185281 ops/sec;   20.5 MB/s
without this dif :
fillseq      :      11.085 micros/op 179676 ops/sec;   19.9 MB/s
Test Plan: unit test included
Reviewers: dhruba, heyongqiang
Reviewed By: heyongqiang
CC: leveldb
Differential Revision: https://reviews.facebook.net/D9741/Disable Unit Test for TransactionLogIteratorStall
Summary:
The unit test fails as our solution does not work with MMap'd files.
Disable the failing unit test. Put it back with the next diff which should fix the problem.
Test Plan: db_test
Reviewers: heyongqiang
CC: dhruba
Differential Revision: https://reviews.facebook.net/D9645/TransactionLogIter should stall at the last record. Currently it errors out
Summary:
* Add a method to check if the log reader is at EOF.
* If we know a record has been flushed force the log_reader to believe it is not at EOF, using a new method UnMarkEof().
This does not work with MMpaed files.
Test Plan: added a unit test.
Reviewers: dhruba, heyongqiang
Reviewed By: heyongqiang
CC: leveldb
Differential Revision: https://reviews.facebook.net/D9567/Fix more signed-unsigned comparisons
Summary: Some comparisons left in log_test.cc and db_test.cc complained by make
Test Plan: make
Reviewers: dhruba, sheki
Reviewed By: dhruba
Differential Revision: https://reviews.facebook.net/D9537/Ignore a zero-sized file while looking for a seq-no in GetUpdatesSince
Summary:
Rocksdb can create 0 sized log files when it is opened and closed without any operations.
The GetUpdatesSince fails currently if there is a log file of size zero.
This diff fixes this. If there is a log file is 0, it is removed form the probable_file_list
Test Plan: unit test
Reviewers: dhruba, heyongqiang
Reviewed By: heyongqiang
CC: leveldb
Differential Revision: https://reviews.facebook.net/D9507/Do not allow Transaction Log Iterator to fall ahead when writer is writing the same file
Summary:
Store the last flushed, seq no. in db_impl. Check against it in
transaction Log iterator. Do not attempt to read ahead if we do not know
if the data is flushed completely.
Does not work if flush is disabled. Any ideas on fixing that?
* Minor change, iter->Next is called the first time automatically for
* the first time.
Test Plan:
existing test pass.
More ideas on testing this?
Planning to run some stress test.
Reviewers: dhruba, heyongqiang
CC: leveldb
Differential Revision: https://reviews.facebook.net/D9087/Add rate_delay_limit_milliseconds
Summary:
This adds the rate_delay_limit_milliseconds option to make the delay
configurable in MakeRoomForWrite when the max compaction score is too high.
This delay is called the Ln slowdown. This change also counts the Ln slowdown
per level to make it possible to see where the stalls occur.
From IO-bound performance testing, the Level N stalls occur:
* with compression -> at the largest uncompressed level. This makes sense
because compaction for compressed levels is much
slower. When Lx is uncompressed and Lx+1 is compressed
then files pile up at Lx because the (Lx,Lx+1)->Lx+1
compaction process is the first to be slowed by
compression.
* without compression -> at level 1
Task ID: #1832108
Blame Rev:
Test Plan:
run with real data, added test
Revert Plan:
Database Impact:
Memcache Impact:
Other Notes:
EImportant:
- begin *PUBLIC* platform impact section -
Bugzilla: #
- end platform impact -
Reviewers: dhruba
Reviewed By: dhruba
Differential Revision: https://reviews.facebook.net/D9045/"
rocksdb,"[RocksDB] Add mmap_read option for db_stress
Summary: as title, also removed an incorrect assertion
Test Plan: make check; db_stress --mmap_read=1; db_stress --mmap_read=0
Reviewers: dhruba, emayanke
CC: leveldb
Differential Revision: https://reviews.facebook.net/D11367/[Kill randomly at various points in source code for testing]
Summary:
This is initial version. A few ways in which this could
be extended in the future are:
(a) Killing from more places in source code
(b) Hashing stack and using that hash in determining whether to crash.
This is to avoid crashing more often at source lines that are executed
more often.
(c) Raising exceptions or returning errors instead of killing
Test Plan:
This whole thing is for testing.
Here is part of output:
python2.7 tools/db_crashtest2.py -d 600
Running db_stress
db_stress retncode -15 output LevelDB version     : 1.5
Number of threads   : 32
Ops per thread      : 10000000
Read percentage     : 50
Write-buffer-size   : 4194304
Delete percentage   : 30
Max key             : 1000
Ratio #ops/#keys    : 320000
Num times DB reopens: 0
Batches/snapshots   : 1
Purge redundant %   : 50
Num keys per lock   : 4
Compression         : snappy
------------------------------------------------
No lock creation because test_batches_snapshots set
2013/04/26-17:55:17  Starting database operations
Created bg thread 0x7fc1f07ff700
... finished 60000 ops
Running db_stress
db_stress retncode -15 output LevelDB version     : 1.5
Number of threads   : 32
Ops per thread      : 10000000
Read percentage     : 50
Write-buffer-size   : 4194304
Delete percentage   : 30
Max key             : 1000
Ratio #ops/#keys    : 320000
Num times DB reopens: 0
Batches/snapshots   : 1
Purge redundant %   : 50
Num keys per lock   : 4
Compression         : snappy
------------------------------------------------
Created bg thread 0x7ff0137ff700
No lock creation because test_batches_snapshots set
2013/04/26-17:56:15  Starting database operations
... finished 90000 ops
Revert Plan: OK
Task ID: #2252691
Reviewers: dhruba, emayanke
Reviewed By: emayanke
CC: leveldb, haobo
Differential Revision: https://reviews.facebook.net/D10581/"
rocksdb,"Expand KeyMayExist to return the proper value if it can be found in memory and also check block_cache
Summary: Removed KeyMayExistImpl because KeyMayExist demanded Get like semantics now. Removed no_io from memtable and imm because we need the proper value now and shouldn't just stop when we see Merge in memtable. Added checks to block_cache. Updated documentation and unit-test
Test Plan: make all check;db_stress for 1 hour
Reviewers: dhruba, haobo
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D11853/Introducing timeranged scan, timeranged dump in ldb. Also the ability to count in time-batches during Dump
Summary:
Scan and Dump commands in ldb use iterator. We need to also print timestamp for ttl databases for debugging. For this I create a TtlIterator class pointer in these functions and assign it the value of Iterator pointer which actually points to t TtlIterator object, and access the new function ValueWithTS which can return TS also. Buckets feature for dump command: gives a count of different key-values in the specified time-range distributed across the time-range partitioned according to bucket-size. start_time and end_time are specified in unixtimestamp and bucket in seconds on the user-commandline
Have commented out 3 ines from ldb_test.py so that the test does not break right now. It breaks because timestamp is also printed now and I have to look at wildcards in python to compare properly.
Test Plan: python tools/ldb_test.py
Reviewers: vamsi, dhruba, haobo, sheki
Reviewed By: vamsi
CC: leveldb
Differential Revision: https://reviews.facebook.net/D11403/"
rocksdb,"[RocksDB] [MergeOperator] The new Merge Interface! Uses merge sequences.
Summary:
Here are the major changes to the Merge Interface. It has been expanded
to handle cases where the MergeOperator is not associative. It does so by stacking
up merge operations while scanning through the key history (i.e.: during Get() or
Compaction), until a valid Put/Delete/end-of-history is encountered; it then
applies all of the merge operations in the correct sequence starting with the
base/sentinel value.
I have also introduced an ""AssociativeMerge"" function which allows the user to
take advantage of associative merge operations (such as in the case of counters).
The implementation will always attempt to merge the operations/operands themselves
together when they are encountered, and will resort to the ""stacking"" method if
and only if the ""associative-merge"" fails.
This implementation is conjectured to allow MergeOperator to handle the general
case, while still providing the user with the ability to take advantage of certain
efficiencies in their own merge-operator / data-structure.
NOTE: This is a preliminary diff. This must still go through a lot of review,
revision, and testing. Feedback welcome!
Test Plan:
-This is a preliminary diff. I have only just begun testing/debugging it.
-I will be testing this with the existing MergeOperator use-cases and unit-tests
(counters, string-append, and redis-lists)
-I will be ""desk-checking"" and walking through the code with the help gdb.
-I will find a way of stress-testing the new interface / implementation using
db_bench, db_test, merge_test, and/or db_stress.
-I will ensure that my tests cover all cases: Get-Memtable,
Get-Immutable-Memtable, Get-from-Disk, Iterator-Range-Scan, Flush-Memtable-to-L0,
Compaction-L0-L1, Compaction-Ln-L(n+1), Put/Delete found, Put/Delete not-found,
end-of-history, end-of-file, etc.
-A lot of feedback from the reviewers.
Reviewers: haobo, dhruba, zshao, emayanke
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D11499/"
rocksdb,"[RocksDB] [MergeOperator] The new Merge Interface! Uses merge sequences.
Summary:
Here are the major changes to the Merge Interface. It has been expanded
to handle cases where the MergeOperator is not associative. It does so by stacking
up merge operations while scanning through the key history (i.e.: during Get() or
Compaction), until a valid Put/Delete/end-of-history is encountered; it then
applies all of the merge operations in the correct sequence starting with the
base/sentinel value.
I have also introduced an ""AssociativeMerge"" function which allows the user to
take advantage of associative merge operations (such as in the case of counters).
The implementation will always attempt to merge the operations/operands themselves
together when they are encountered, and will resort to the ""stacking"" method if
and only if the ""associative-merge"" fails.
This implementation is conjectured to allow MergeOperator to handle the general
case, while still providing the user with the ability to take advantage of certain
efficiencies in their own merge-operator / data-structure.
NOTE: This is a preliminary diff. This must still go through a lot of review,
revision, and testing. Feedback welcome!
Test Plan:
-This is a preliminary diff. I have only just begun testing/debugging it.
-I will be testing this with the existing MergeOperator use-cases and unit-tests
(counters, string-append, and redis-lists)
-I will be ""desk-checking"" and walking through the code with the help gdb.
-I will find a way of stress-testing the new interface / implementation using
db_bench, db_test, merge_test, and/or db_stress.
-I will ensure that my tests cover all cases: Get-Memtable,
Get-Immutable-Memtable, Get-from-Disk, Iterator-Range-Scan, Flush-Memtable-to-L0,
Compaction-L0-L1, Compaction-Ln-L(n+1), Put/Delete found, Put/Delete not-found,
end-of-history, end-of-file, etc.
-A lot of feedback from the reviewers.
Reviewers: haobo, dhruba, zshao, emayanke
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D11499/"
rocksdb,"Prefix filters for scans (v4)
Summary: Similar to v2 (db and table code understands prefixes), but use ReadOptions as in v3.  Also, make the CreateFilter code faster and cleaner.
Test Plan: make db_test; export LEVELDB_TESTS=PrefixScan; ./db_test
Reviewers: dhruba
Reviewed By: dhruba
CC: haobo, emayanke
Differential Revision: https://reviews.facebook.net/D12027/[RocksDB] [MergeOperator] The new Merge Interface! Uses merge sequences.
Summary:
Here are the major changes to the Merge Interface. It has been expanded
to handle cases where the MergeOperator is not associative. It does so by stacking
up merge operations while scanning through the key history (i.e.: during Get() or
Compaction), until a valid Put/Delete/end-of-history is encountered; it then
applies all of the merge operations in the correct sequence starting with the
base/sentinel value.
I have also introduced an ""AssociativeMerge"" function which allows the user to
take advantage of associative merge operations (such as in the case of counters).
The implementation will always attempt to merge the operations/operands themselves
together when they are encountered, and will resort to the ""stacking"" method if
and only if the ""associative-merge"" fails.
This implementation is conjectured to allow MergeOperator to handle the general
case, while still providing the user with the ability to take advantage of certain
efficiencies in their own merge-operator / data-structure.
NOTE: This is a preliminary diff. This must still go through a lot of review,
revision, and testing. Feedback welcome!
Test Plan:
-This is a preliminary diff. I have only just begun testing/debugging it.
-I will be testing this with the existing MergeOperator use-cases and unit-tests
(counters, string-append, and redis-lists)
-I will be ""desk-checking"" and walking through the code with the help gdb.
-I will find a way of stress-testing the new interface / implementation using
db_bench, db_test, merge_test, and/or db_stress.
-I will ensure that my tests cover all cases: Get-Memtable,
Get-Immutable-Memtable, Get-from-Disk, Iterator-Range-Scan, Flush-Memtable-to-L0,
Compaction-L0-L1, Compaction-Ln-L(n+1), Put/Delete found, Put/Delete not-found,
end-of-history, end-of-file, etc.
-A lot of feedback from the reviewers.
Reviewers: haobo, dhruba, zshao, emayanke
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D11499/Expand KeyMayExist to return the proper value if it can be found in memory and also check block_cache
Summary: Removed KeyMayExistImpl because KeyMayExist demanded Get like semantics now. Removed no_io from memtable and imm because we need the proper value now and shouldn't just stop when we see Merge in memtable. Added checks to block_cache. Updated documentation and unit-test
Test Plan: make all check;db_stress for 1 hour
Reviewers: dhruba, haobo
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D11853/"
rocksdb,"Implement log blobs
Summary:
This patch adds the ability for the user to add sequences of arbitrary data (blobs) to write batches. These blobs are saved to the log along with everything else in the write batch. You can add multiple blobs per WriteBatch and the ordering of blobs, puts, merges, and deletes are preserved.
Blobs are not saves to SST files. RocksDB ignores blobs in every way except for writing them to the log.
Before committing this patch, I need to add some test code. But I'm submitting it now so people can comment on the API.
Test Plan: make -j32 check
Reviewers: dhruba, haobo, vamsi
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12195/Prefix filters for scans (v4)
Summary: Similar to v2 (db and table code understands prefixes), but use ReadOptions as in v3.  Also, make the CreateFilter code faster and cleaner.
Test Plan: make db_test; export LEVELDB_TESTS=PrefixScan; ./db_test
Reviewers: dhruba
Reviewed By: dhruba
CC: haobo, emayanke
Differential Revision: https://reviews.facebook.net/D12027/Universal Compaction should keep DeleteMarkers unless it is the earliest file.
Summary:
The pre-existing code was purging a DeleteMarker if thay key did not
exist in deeper levels.  But in the Universal Compaction Style, all
files are in Level0. For compaction runs that did not include the
earliest file, we were erroneously purging the DeleteMarkers.
The fix is to purge DeleteMarkers only if the compaction includes
the earlist file.
Test Plan: DBTest.Randomized triggers this code path.
Differential Revision: https://reviews.facebook.net/D12081/Fix unit tests for universal compaction (step 2)
Summary:
Continue fixing existing unit tests for universal compaction. I have
tried to apply universal compaction to all unit tests those haven't
called ChangeOptions(). I left a few which are either apparently not
applicable to universal compaction (because they check files/keys/values
at level 1 or above levels), or apparently not related to compaction
(e.g., open a file, open a db).
I also add a new unit test for universal compaction.
Good news is I didn't see any bugs during this round.
Test Plan: Ran ""make all check"" yesterday. Has rebased and is rerunning
Reviewers: haobo, dhruba
Differential Revision: https://reviews.facebook.net/D12135/Fix unit tests/bugs for universal compaction (first step)
Summary:
This is the first step to fix unit tests and bugs for universal
compactiion. I added universal compaction option to ChangeOptions(), and
fixed all unit tests calling ChangeOptions(). Some of these tests
obviously assume more than 1 level and check file number/values in level
1 or above levels. I set kSkipUniversalCompaction for these tests.
The major bug I found is manual compaction with universal compaction never stops. I have put a fix for
it.
I have also set universal compaction as the default compaction and found
at least 20+ unit tests failing. I haven't looked into the details. The
next step is to check all unit tests without calling ChangeOptions().
Test Plan: make all check
Reviewers: dhruba, haobo
Differential Revision: https://reviews.facebook.net/D12051/Expand KeyMayExist to return the proper value if it can be found in memory and also check block_cache
Summary: Removed KeyMayExistImpl because KeyMayExist demanded Get like semantics now. Removed no_io from memtable and imm because we need the proper value now and shouldn't just stop when we see Merge in memtable. Added checks to block_cache. Updated documentation and unit-test
Test Plan: make all check;db_stress for 1 hour
Reviewers: dhruba, haobo
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D11853/Fix memory leak in KeyMayExist test part of db_test
Summary: NewBloomFilterPolicy call requires Delete to be called later on
Test Plan: make; valgrind ./db_test
Reviewers: haobo, dhruba, vamsi
Differential Revision: https://reviews.facebook.net/D11667/Fixed valgrind errors/Fix valgrind errors introduced by https://reviews.facebook.net/D10863
Summary:
The valgrind errors were in the unit tests where we change the
number of levels of a database using internal methods.
Test Plan:
valgrind ./reduce_levels_test
valgrind ./db_test
Reviewers: emayanke
Reviewed By: emayanke
CC: leveldb
Differential Revision: https://reviews.facebook.net/D10893/"
rocksdb,"Fixing build failure
Summary: virtual NewRandomRWFile is not implemented on EnvHdfs, causing build failure.
Test Plan: make clean; make all check
Reviewers: dhruba, haobo, kailiu
Reviewed By: kailiu
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13383/Migrate names of properties from 'leveldb' prefix to 'rocksdb' prefix.
Summary: Migrate names of properties from 'leveldb' prefix to 'rocksdb' prefix.
Test Plan: make check
Reviewers: emayanke, haobo
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13311/"
rocksdb,"Flush Log every 5 seconds
Summary: This might help with p99 performance, but does not solve the real problem. More discussion on #2947135
Test Plan: make check
Reviewers: dhruba, haobo
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13809/Dbid feature
Summary:
Create a new type of file on startup if it doesn't already exist called DBID.
This will store a unique number generated from boost library's uuid header file.
The use-case is to identify the case of a db losing all its data and coming back up either empty or from an image(backup/live replica's recovery)
the key point to note is that DBID is not stored in a backup or db snapshot
It's preferable to use Boost for uuid because:
1) A non-standard way of generating uuid is not good
2) /proc/sys/kernel/random/uuid generates a uuid but only on linux environments and the solution would not be clean
3) c++ doesn't have any direct way to get a uuid
4) Boost is a very good library that was already having linkage in rocksdb from third-party
Note: I had to update the TOOLCHAIN_REV in build files to get latest verison of boost from third-party as the older version had a bug.
I had to put Wno-uninitialized in Makefile because boost-1.51 has an unitialized variable and rocksdb would not comiple otherwise. Latet open-source for boost is 1.54 but is not there in third-party. I have notified the concerned people in fbcode about it.
@kailiu : While releasing to third-party, an additional dependency will need to be created for boost in TARGETS file. I can help identify.
Test Plan:
Expand db_test to test 2 cases
1) Restarting db with Id file present - verify that no change to Id
2)Restarting db with Id file deleted - verify that a different Id is there after reopen
Also run make all check
Reviewers: dhruba, haobo, kailiu, sdong
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13587/Env class that can randomly read and write
Summary: I have implemented basic simple use case that I need for External Value Store I'm working on. There is a potential for making this prettier by refactoring/combining WritableFile and RandomAccessFile, avoiding some copypasta. However, I decided to implement just the basic functionality, so I can continue working on the other diff.
Test Plan: Added a unittest
Reviewers: dhruba, haobo, kailiu
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13365/Migrate names of properties from 'leveldb' prefix to 'rocksdb' prefix.
Summary: Migrate names of properties from 'leveldb' prefix to 'rocksdb' prefix.
Test Plan: make check
Reviewers: emayanke, haobo
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13311/Revert ""Minor fixes found while trying to compile it using clang on Mac OS X""
This reverts commit 5f2c136c328a8dbb6c3cb3818881e30eeb916cd6./Minor fixes found while trying to compile it using clang on Mac OS X/[RocksDB] Added nano second stopwatch and new perf counters to track block read cost
Summary: The pupose of this diff is to expose per user-call level precise timing of block read, so that we can answer questions like: a Get() costs me 100ms, is that somehow related to loading blocks from file system, or sth else? We will answer that with EXACTLY how many blocks have been read, how much time was spent on transfering the bytes from os, how much time was spent on checksum verification and how much time was spent on block decompression, just for that one Get. A nano second stopwatch was introduced to track time with higher precision. The cost/precision of the stopwatch is also measured in unit-test. On my dev box, retrieving one time instance costs about 30ns, on average. The deviation of timing results is good enough to track 100ns-1us level events. And the overhead could be safely ignored for 100us level events (10000 instances/s), for example, a viewstate thrift call.
Test Plan: perf_context_test, also testing with viewstate shadow traffic.
Reviewers: dhruba
Reviewed By: dhruba
CC: leveldb, xjin
Differential Revision: https://reviews.facebook.net/D12351/"
rocksdb,"Fix build failing becasue of ttl-keymayexist
Summary: PutValues calls Flush in ttl_test which clears memtables. KeyMayExist called after that will not be able to read those key-values
Test Plan: make all check OPT=-g
Reviewers:leveldb/"
rocksdb,"Revert ""Minor fixes found while trying to compile it using clang on Mac OS X""
This reverts commit 5f2c136c328a8dbb6c3cb3818881e30eeb916cd6./Minor fixes found while trying to compile it using clang on Mac OS X/Fix delete in db_ttl.cc
Summary: should delete the proper variable
Test Plan: make all check
Reviewers: haobo, dhruba
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12921/Merge operator fixes part 1.
Summary:
-Added null checks and revisions to DBIter::MergeValuesNewToOld()
-Added DBIter test to stringappend_test
-Major fix with Merge and TTL
More plans for fixes later.
Test Plan:
-make clean; make stringappend_test -j 32; ./stringappend_test
-make all check;
Reviewers: haobo, emayanke, vamsi, dhruba
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12315/"
rocksdb,"Merge operator fixes part 1.
Summary:
-Added null checks and revisions to DBIter::MergeValuesNewToOld()
-Added DBIter test to stringappend_test
-Major fix with Merge and TTL
More plans for fixes later.
Test Plan:
-make clean; make stringappend_test -j 32; ./stringappend_test
-make all check;
Reviewers: haobo, emayanke, vamsi, dhruba
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12315/"
rocksdb,"Merge operator fixes part 1.
Summary:
-Added null checks and revisions to DBIter::MergeValuesNewToOld()
-Added DBIter test to stringappend_test
-Major fix with Merge and TTL
More plans for fixes later.
Test Plan:
-make clean; make stringappend_test -j 32; ./stringappend_test
-make all check;
Reviewers: haobo, emayanke, vamsi, dhruba
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12315/"
rocksdb,"Migrate names of properties from 'leveldb' prefix to 'rocksdb' prefix.
Summary: Migrate names of properties from 'leveldb' prefix to 'rocksdb' prefix.
Test Plan: make check
Reviewers: emayanke, haobo
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13311/"
rocksdb,"Add statistics to sst file
Summary:
So far we only have key/value pairs as well as bloom filter stored in the
sst file.  It will be great if we are able to store more metadata about
this table itself, for example, the entry size, bloom filter name, etc.
This diff is the first step of this effort. It allows table to keep the
basic statistics mentioned in http://fburl.com/14995441, as well as
allowing writing user-collected stats to stats block.
After this diff, we will figure out the interface of how to allow user to collect their interested statistics.
Test Plan:
1. Added several unit tests.
2. Ran `make check` to ensure it doesn't break other tests.
Reviewers: dhruba, haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13419/[RocksDB] Added nano second stopwatch and new perf counters to track block read cost
Summary: The pupose of this diff is to expose per user-call level precise timing of block read, so that we can answer questions like: a Get() costs me 100ms, is that somehow related to loading blocks from file system, or sth else? We will answer that with EXACTLY how many blocks have been read, how much time was spent on transfering the bytes from os, how much time was spent on checksum verification and how much time was spent on block decompression, just for that one Get. A nano second stopwatch was introduced to track time with higher precision. The cost/precision of the stopwatch is also measured in unit-test. On my dev box, retrieving one time instance costs about 30ns, on average. The deviation of timing results is good enough to track 100ns-1us level events. And the overhead could be safely ignored for 100us level events (10000 instances/s), for example, a viewstate thrift call.
Test Plan: perf_context_test, also testing with viewstate shadow traffic.
Reviewers: dhruba
Reviewed By: dhruba
CC: leveldb, xjin
Differential Revision: https://reviews.facebook.net/D12351/Fix memory leak in table.cc
Summary:
In InternalGet, BlockReader returns an Iterator which is legitimately freed at the end of the 'else' scope. BUT there is a break statement in between and must be freed there too!
The best solution would be to move to unique_ptr and let it handle. Changed it to a unique_ptr.
Test Plan: valgrind ./db_test;make all check
Reviewers: dhruba, haobo
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12681/Fix bug in KeyMayExist
Summary: In KeyMayExist.db_test we do a Flush which causes sst file to be written and added as open file in TableCache, but block cache for the file is not populated. So value_found should have been false where it was true and KeyMayExist.db_test should not have passed earlier. But it passed because BlockReader in table/table.cc takes 2 default arguments at the end called for_compaction and no_io. Although I passed no_io=true from InternalGet to BlockReader, but it understood for_compaction=true and defaulted no_io to false. This is a bug and although will be removed by Dhruba's new patch to incorporate no_io in readoptions, I'm submitting this patch to fix this bug independently of that patch.
Test Plan: make all check
Reviewers: dhruba, haobo
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12537/Internal/user key bug fix.
Summary: Fix code so that the filter_block layer only assumes keys are internal when prefix_extractor is set.
Test Plan: ./filter_block_test
Reviewers: dhruba, haobo
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12501/Revert ""Prefix scan: db_bench and bug fixes""
This reverts commit c2bd8f4824bda98db8699f1e08d6969cf21ef86f./Prefix scan: db_bench and bug fixes
Summary: If use_prefix_filters is set and read_range>1, then the random seeks will set a the prefix filter to be the prefix of the key which was randomly selected as the target.  Still need to add statistics (perhaps in a separate diff).
Test Plan: ./db_bench --benchmarks=fillseq,prefixscanrandom --num=10000000 --statistics=1 --use_prefix_blooms=1 --use_prefix_api=1 --bloom_bits=10
Reviewers: dhruba
Reviewed By: dhruba
CC: leveldb, haobo
Differential Revision: https://reviews.facebook.net/D12273/"
rocksdb,"Fix the string format issue
Summary:
mac and our dev server has totally differnt definition of uint64_t, therefore fixing the warning in mac has actually made code in linux uncompileable.
Test Plan:
make clean && make -j32/Fix deleting files
Summary: One more fix! In some cases, our filenames start with ""/"". Apparently, env_ can't handle filenames with double //
Test Plan:
deletefile_test does not include this line in the LOG anymore:
2013/11/12-18:11:43.150149 7fe4a6fff700 RenameFile logfile #3 FAILED -- IO error: /tmp/rocksdbtest-3574/deletefile_test//000003.log: No such file or directory
Reviewers: dhruba, haobo
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D14055/Fixing failed delete file test
Summary: FindObsoleteFiles() has to be called before PurgeObsoleteFiles() because FindObsoleteFiles() sets manifest_file_number, log_number and prev_log_number to valid values.
Test Plan: deletefile_test now works
Reviewers: dhruba, emayanke, kailiu
Reviewed By: kailiu
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13995/Flush the log outside of lock
Summary:
Added a new call LogFlush() that flushes the log contents to the OS buffers. We never call it with lock held.
We call it once for every Read/Write and often in compaction/flush process so the frequency should not be a problem.
Test Plan: db_test
Reviewers: dhruba, haobo, kailiu, emayanke
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13935/[RocksDB] Generalize prefix-aware iterator to be used for more than one Seek
Summary: Added a prefix_seek flag in ReadOptions to indicate that Seek is prefix aware(might not return data with different prefix), and also not bound to a specific prefix. Multiple Seeks and range scans can be invoked on the same iterator. If a specific prefix is specified, this flag will be ignored. Just a quick prototype that works for PrefixHashRep, the new lockless memtable could be easily extended with this support too.
Test Plan: test it on Leaf
Reviewers: dhruba, kailiu, sdong, igor
Reviewed By: igor
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13929/Support user-defined table stats collector
Summary:
1. Added a new option that support user-defined table stats collection.
2. Added a deleted key stats collector in `utilities`
Test Plan:
Added a unit test for newly added code.
Also ran make check to make sure other tests are not broken.
Reviewers: dhruba, haobo
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13491/If a Put fails, fail all other puts
Summary:
When a Put fails, it can leave database in a messy state. We don't want to pretend that everything is OK when it may not be. We fail every write following the failed one.
I added checks for corruption to DBImpl::Write(). Is there anywhere else I need to add them?
Test Plan: Corruption unit test.
Reviewers: dhruba, haobo, kailiu
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13671/Fix the log number bug when updating MANIFEST file
Summary:
Crash may occur during the flushes of more than two mem tables.
As the info log suggested, even when both were successfully flushed,
the recovery process still pick up one of the memtable's log for recovery.
This diff fix the problem by setting the correct ""log number"" in MANIFEST.
Test Plan: make test; deployed to leaf4 and make sure it doesn't result in crashes of this type.
Reviewers: haobo, dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13659/Dbid feature
Summary:
Create a new type of file on startup if it doesn't already exist called DBID.
This will store a unique number generated from boost library's uuid header file.
The use-case is to identify the case of a db losing all its data and coming back up either empty or from an image(backup/live replica's recovery)
the key point to note is that DBID is not stored in a backup or db snapshot
It's preferable to use Boost for uuid because:
1) A non-standard way of generating uuid is not good
2) /proc/sys/kernel/random/uuid generates a uuid but only on linux environments and the solution would not be clean
3) c++ doesn't have any direct way to get a uuid
4) Boost is a very good library that was already having linkage in rocksdb from third-party
Note: I had to update the TOOLCHAIN_REV in build files to get latest verison of boost from third-party as the older version had a bug.
I had to put Wno-uninitialized in Makefile because boost-1.51 has an unitialized variable and rocksdb would not comiple otherwise. Latet open-source for boost is 1.54 but is not there in third-party. I have notified the concerned people in fbcode about it.
@kailiu : While releasing to third-party, an additional dependency will need to be created for boost in TARGETS file. I can help identify.
Test Plan:
Expand db_test to test 2 cases
1) Restarting db with Id file present - verify that no change to Id
2)Restarting db with Id file deleted - verify that a different Id is there after reopen
Also run make all check
Reviewers: dhruba, haobo, kailiu, sdong
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13587/Enable background flush thread by default and fix issues related to it
Summary:
Enable background flush thread in this patch and fix unit tests with:
(1) After background flush, schedule a background compaction if condition satisfied;
(2) Fix a bug that if universal compaction is enabled and number of levels are set to be 0, compaction will not be automatically triggered
(3) Fix unit tests to wait for compaction to finish instead of flush, before checking the compaction results.
Test Plan: pass all unit tests
Reviewers: haobo, xjin, dhruba
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13461/Features in Transaction log iterator
Summary:
* Logstore requests a valid change of reutrning an empty iterator and not an error in case of no log files.
* Changed the code to return the writebatch containing the sequence number requested from GetupdatesSince even if it lies in the middle. Earlier we used to return the next writebatch,. This also allows me oto guarantee that no files played upon by the iterator are redundant. I mean the starting log file has at least a sequence number >= the sequence number requested form GetupdatesSince.
* Cleaned up redundant logic in Iterator::Next and made a new function SeekToStartSequence for greater readability and maintainibilty.
* Modified a test in db_test accordingly
Please check the logic carefully and suggest improvements. I have a separate patch out for more improvements like restricting reader to read till written sequences.
Test Plan:
* transaction log iterator tests in db_test,
* db_repl_stress.
* rocks_log_iterator_test in fbcode/wormhole/rocksdb/test - 2 tests thriving on hacks till now can get simplified
* testing on the shadow setup for sigma with replication
Reviewers: dhruba, haobo, kailiu, sdong
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13437/Add statistics to sst file
Summary:
So far we only have key/value pairs as well as bloom filter stored in the
sst file.  It will be great if we are able to store more metadata about
this table itself, for example, the entry size, bloom filter name, etc.
This diff is the first step of this effort. It allows table to keep the
basic statistics mentioned in http://fburl.com/14995441, as well as
allowing writing user-collected stats to stats block.
After this diff, we will figure out the interface of how to allow user to collect their interested statistics.
Test Plan:
1. Added several unit tests.
2. Ran `make check` to ensure it doesn't break other tests.
Reviewers: dhruba, haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13419/Change Function names from Compaction->Flush When they really mean Flush
Summary: When I debug the unit test failures when enabling background flush thread, I feel the function names can be made clearer for people to understand. Also, if the names are fixed, in many places, some tests' bugs are obvious (and some of those tests are failing). This patch is to clean it up for future maintenance.
Test Plan: Run test suites.
Reviewers: haobo, dhruba, xjin
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13431/Fixing error in ParseFileName causing DestroyDB to fail on archive directory
Summary:
This careless error was causing ASSERT_OK(DestroyDB) to fail in db_test.
Basically .. was being returned as a child of db/archive and ParseFileName returned false on that,
but 'type' was set to LogFile from earlier and not reset. The return of ParseFileName was not being checked to delete the log file or not.
Test Plan: make all check
Reviewers: dhruba, haobo, xjin, kailiu, nkg-
Reviewed By: nkg-
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13413/Add option for storing transaction logs in a separate dir
Summary: In some cases, you might not want to store the data log (write ahead log) files in the same dir as the sst files. An example use case is leaf, which stores sst files in tmpfs. And would like to save the log files in a separate dir (disk) to save memory.
Test Plan: make all. Ran db_test test. A few test failing. P2785018. If you guys don't see an obvious problem with the code, maybe somebody from the rocksdb team could help me debug the issue here. Running this on leaf worked well. I could see logs stored on disk, and deleted appropriately after compactions. Obviously this is only one set of options. The unit tests cover different options. Seems like I'm missing some edge cases.
Reviewers: dhruba, haobo, leveldb
CC: xinyaohu, sumeet
Differential Revision: https://reviews.facebook.net/D13239/Migrate names of properties from 'leveldb' prefix to 'rocksdb' prefix.
Summary: Migrate names of properties from 'leveldb' prefix to 'rocksdb' prefix.
Test Plan: make check
Reviewers: emayanke, haobo
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13311/[Rocksdb] Submit mem table flush job in a different thread pool
Summary: As title. This is just a quick hack and not ready for commit. fails a lot of unit test. I will test/debug it directly in ViewState shadow .
Test Plan: Try it in shadow test.
Reviewers: dhruba, xjin
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12933/Fix SIGSEGV issue in universal compaction
Summary:
We saw SIGSEGV when set options.num_levels=1 in universal compaction
style. Dug into this issue for a while, and finally found the root cause (thank Haobo for discussion).
Test Plan: Add new unit test. It throws SIGSEGV without this change. Also run ""make all check"".
Reviewers: haobo, dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13251/New unit test for iterator with snapshot
Summary:
I played with the reported bug about iterator with snapshot:
https://code.google.com/p/leveldb/issues/detail?id=200.
I turned the original test program
(https://code.google.com/p/leveldb/issues/attachmentText?id=200&aid=2000000000&name=test.cc&token=7uOUQW-HFlbAFMUm7EqtaAEy7Tw%3A1378320724136)
into a new unit test, but I cannot reproduce the problem. Notice lines
31-34 in above link. I have ran the new test with and without such Put()
operations. Both succeed.
So this diff simply adds the test, without changing any source codes.
Test Plan: run new test.
Reviewers: dhruba, haobo, emayanke
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12735/[RocksDB] Remove Log file immediately after memtable flush
Summary: As title. The DB log file life cycle is tied up with the memtable it backs. Once the memtable is flushed to sst and committed, we should be able to delete the log file, without holding the mutex. This is part of the bigger change to avoid FindObsoleteFiles at runtime. It deals with log files. sst files will be dealt with later.
Test Plan: make check; db_bench
Reviewers: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D11709/Flush was hanging because the configured options specified that more than 1 memtable need to be merged.
Summary:
There is an config option called Options.min_write_buffer_number_to_merge
that specifies the minimum number of write buffers to merge in memory
before flushing to a file in L0. But in the the case when the db is
being closed, we should not be using this config, instead we should
flush whatever write buffers were available at that time.
Test Plan: Unit test attached.
Reviewers: haobo, emayanke
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12717/Fix bug in Counters and record Sequencenumber using only TickerCount
Summary:
The way counters/statistics are implemented in rocksdb demands that enum Tickers and TickerNameMap follow the same order, otherwise statistics exposed from fbcode/rocks get out-of-sync. 2 counters for prefix had violated this order and when I built counters for fbcode/mcrocksdb, statistics for sequence number were appearing out-of-sync.
The other change is to record sequence-number using setTickerCount only and not recordTick. This is because of difference in statistics as understood by rocks/utils which uses ServiceData::statistics function and rocksdb statistics. In rocksdb there is just 1 counter for a countername. But in ServiceData there are 4 independent buckets for every countername-Count, Sum, Average and Rate. SetTickerCount and RecordTick update the same variable in rocksdb but different buckets in ServiceData. Therefore, I had to choose one consistent function from RecordTick or SetTickerCount for sequence number in rocksdb. I chose SetTickerCount because the statistics object in options passed during rocksdb-open is user-dependent and SetTickerCount makes sense there.
There will be a corresponding diff to mcorcksdb in fbcode shortly.
Test Plan: make all check; check ticker value using fprintfs
Reviewers: dhruba
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12669/Fix build caused by DeleteFile not tolerating / at the beginning
Summary: db->DeleteFile calls ParseFileName to check name that was returned for sst file. Now, sst filename is returned using TableFileName which uses MakeFileName. This puts a / at the front of the name and ParseFileName doesn't like that. Changed ParseFileName to tolerate /s at the beginning. The test delet_file_test used to pass earlier because this behaviour of MakeFileName had been changed a while back to not return a / during which delete_file_test was checked in. But MakeFileName had to be reverted to add / at the front because GetLiveFiles used at many places outside rocksdb used the previous behaviour of MakeFileName.
Test Plan: make;./delete_filetest;make all check
Reviewers: dhruba, haobo, vamsi
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12663/[RocksDB] Fix TransformRepFactory related valgrind problem
Summary: Let TransformRepFactory own the passed in transform. Also make it better encapsulated.
Test Plan: make valgrind_check;
Reviewers: dhruba, emayanke
Reviewed By: emayanke
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12591/Fix for no_io
Summary: Oops. My bad.
Test Plan: Make all check
Reviewers: emayanke
Reviewed By: emayanke
CC: haobo, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D12525/Add three new MemTableRep's
Summary:
This patch adds three new MemTableRep's: UnsortedRep, PrefixHashRep, and VectorRep.
UnsortedRep stores keys in an std::unordered_map of std::sets. When an iterator is requested, it dumps the keys into an std::set and iterates over that.
VectorRep stores keys in an std::vector. When an iterator is requested, it creates a copy of the vector and sorts it using std::sort. The iterator accesses that new vector.
PrefixHashRep stores keys in an unordered_map mapping prefixes to ordered sets.
I also added one API change. I added a function MemTableRep::MarkImmutable. This function is called when the rep is added to the immutable list. It doesn't do anything yet, but it seems like that could be useful. In particular, for the vectorrep, it means we could elide the extra copy and just sort in place. The only reason I haven't done that yet is because the use of the ArenaAllocator complicates things (I can elaborate on this if needed).
Test Plan:
make -j32 check
./db_stress --memtablerep=vector
./db_stress --memtablerep=unsorted
./db_stress --memtablerep=prefixhash --prefix_size=10
Reviewers: dhruba, haobo, emayanke
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12117/Pull from https://reviews.facebook.net/D10917
Summary: Pull Mark's patch and slightly revise it. I revised another place in db_impl.cc with similar new formula.
Test Plan:
make all check. Also run ""time ./db_bench --num=2500000000 --numdistinct=2200000000"". It has run for 20+ hours and hasn't finished. Looks good so far:
Installed stack trace handler for SIGILL SIGSEGV SIGBUS SIGABRT
LevelDB:    version 2.0
Date:       Tue Aug 20 23:11:55 2013
CPU:        32 * Intel(R) Xeon(R) CPU E5-2660 0 @ 2.20GHz
CPUCache:   20480 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    2500000000
RawSize:    276565.6 MB (estimated)
FileSize:   157356.3 MB (estimated)
Write rate limit: 0
Compression: snappy
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
DB path: [/tmp/leveldbtest-3088/dbbench]
fillseq      :    7202.000 micros/op 138 ops/sec;
DB path: [/tmp/leveldbtest-3088/dbbench]
fillsync     :    7148.000 micros/op 139 ops/sec; (2500000 ops)
DB path: [/tmp/leveldbtest-3088/dbbench]
fillrandom   :    7105.000 micros/op 140 ops/sec;
DB path: [/tmp/leveldbtest-3088/dbbench]
overwrite    :    6930.000 micros/op 144 ops/sec;
DB path: [/tmp/leveldbtest-3088/dbbench]
readrandom   :       1.020 micros/op 980507 ops/sec; (0 of 2500000000 found)
DB path: [/tmp/leveldbtest-3088/dbbench]
readrandom   :       1.021 micros/op 979620 ops/sec; (0 of 2500000000 found)
DB path: [/tmp/leveldbtest-3088/dbbench]
readseq      :     113.000 micros/op 8849 ops/sec;
DB path: [/tmp/leveldbtest-3088/dbbench]
readreverse  :     102.000 micros/op 9803 ops/sec;
DB path: [/tmp/leveldbtest-3088/dbbench]
Created bg thread 0x7f0ac17f7700
compact      :  111701.000 micros/op 8 ops/sec;
DB path: [/tmp/leveldbtest-3088/dbbench]
readrandom   :       1.020 micros/op 980376 ops/sec; (0 of 2500000000 found)
DB path: [/tmp/leveldbtest-3088/dbbench]
readseq      :     120.000 micros/op 8333 ops/sec;
DB path: [/tmp/leveldbtest-3088/dbbench]
readreverse  :      29.000 micros/op 34482 ops/sec;
DB path: [/tmp/leveldbtest-3088/dbbench]
... finished 618100000 ops
Reviewers: MarkCallaghan, haobo, dhruba, chip
Reviewed By: dhruba
Differential Revision: https://reviews.facebook.net/D12441/Minor fix to current codes
Summary:
Minor fix to current codes, including: coding style, output format,
comments. No major logic change. There are only 2 real changes, please see my inline comments.
Test Plan: make all check
Reviewers: haobo, dhruba, emayanke
Differential Revision: https://reviews.facebook.net/D12297/"
rocksdb,"Add the index/filter block cache
Summary: This diff leverage the existing block cache and extend it to cache index/filter block.
Test Plan:
Added new tests in db_test and table_test
The correctness is checked by:
1. make check
2. make valgrind_check
Performance is test by:
1. 10 times of build_tools/regression_build_test.sh on two versions of rocksdb before/after the code change. Test results suggests no significant difference between them. For the two key operatons `overwrite` and `readrandom`, the average iops are both 20k and ~260k, with very small variance).
2. db_stress.
Reviewers: dhruba
Reviewed By: dhruba
CC: leveldb, haobo, xjin
Differential Revision: https://reviews.facebook.net/D13167/Fix failure in rocksdb unit test CompressedCache
Summary:
The problem was that there was only a single key-value in a block
and its compressibility was less than 88%. Rocksdb refuses to
compress a block unless its compresses to lesser than 88% of its
original size. If a block is not compressed, it does nto get inserted
into the compressed block cache.
Create the test data so that multiple records fit into the same
data block. This increases the compressibility of these data block.
Test Plan: ./db_test
Reviewers: kailiu, haobo
Reviewed By: kailiu
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13905/Fixed valgrind error in DBTest.CompressedCache
Summary:
Fixed valgrind error in DBTest.CompressedCache.
This fixes the valgrind error (thanks to Haobo). I am still trying to reproduce the test-failure case deterministically.
Test Plan: db_test
Reviewers: haobo
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13899/In-place updates for equal keys and similar sized values
Summary:
Currently for each put, a fresh memory is allocated, and a new entry is added to the memtable with a new sequence number irrespective of whether the key already exists in the memtable. This diff is an attempt to update the value inplace for existing keys. It currently handles a very simple case:
1. Key already exists in the current memtable. Does not inplace update values in immutable memtable or snapshot
2. Latest value type is a 'put' ie kTypeValue
3. New value size is less than existing value, to avoid reallocating memory
TODO: For a put of an existing key, deallocate memory take by values, for other value types till a kTypeValue is found, ie. remove kTypeMerge.
TODO: Update the transaction log, to allow consistent reload of the memtable.
Test Plan: Added a unit test verifying the inplace update. But some other unit tests broken due to invalid sequence number checks. WIll fix them next.
Reviewers: xinyaohu, sumeet, haobo, dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12423
Automatic commit by arc/If a Put fails, fail all other puts
Summary:
When a Put fails, it can leave database in a messy state. We don't want to pretend that everything is OK when it may not be. We fail every write following the failed one.
I added checks for corruption to DBImpl::Write(). Is there anywhere else I need to add them?
Test Plan: Corruption unit test.
Reviewers: dhruba, haobo, kailiu
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13671/Dbid feature
Summary:
Create a new type of file on startup if it doesn't already exist called DBID.
This will store a unique number generated from boost library's uuid header file.
The use-case is to identify the case of a db losing all its data and coming back up either empty or from an image(backup/live replica's recovery)
the key point to note is that DBID is not stored in a backup or db snapshot
It's preferable to use Boost for uuid because:
1) A non-standard way of generating uuid is not good
2) /proc/sys/kernel/random/uuid generates a uuid but only on linux environments and the solution would not be clean
3) c++ doesn't have any direct way to get a uuid
4) Boost is a very good library that was already having linkage in rocksdb from third-party
Note: I had to update the TOOLCHAIN_REV in build files to get latest verison of boost from third-party as the older version had a bug.
I had to put Wno-uninitialized in Makefile because boost-1.51 has an unitialized variable and rocksdb would not comiple otherwise. Latet open-source for boost is 1.54 but is not there in third-party. I have notified the concerned people in fbcode about it.
@kailiu : While releasing to third-party, an additional dependency will need to be created for boost in TARGETS file. I can help identify.
Test Plan:
Expand db_test to test 2 cases
1) Restarting db with Id file present - verify that no change to Id
2)Restarting db with Id file deleted - verify that a different Id is there after reopen
Also run make all check
Reviewers: dhruba, haobo, kailiu, sdong
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13587/Fix Bug: iterator.Prev() or iterator.SeekToLast() might return the first element instead of the correct one
Summary:
Recent patch https://reviews.facebook.net/D11865 introduced a regression bug:
DBIter::FindPrevUserEntry(), which is called by DBIter::Prev() (and also implicitly if calling iterator.SeekToLast())  might do issue a seek when having skipped too many entries. If the skipped entry just before the seek() is a delete, the saved key is erased so that it seeks to the front, so Prev() would return the first element.
This patch fixes the bug by not doing seek() in DBIter::FindNextUserEntry() if saved key has been erased.
Test Plan: Add a test DBTest.IterPrevMaxSkip which would fail without the patch and would pass with the change.
Reviewers: dhruba, xjin, haobo
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13557/Enable background flush thread by default and fix issues related to it
Summary:
Enable background flush thread in this patch and fix unit tests with:
(1) After background flush, schedule a background compaction if condition satisfied;
(2) Fix a bug that if universal compaction is enabled and number of levels are set to be 0, compaction will not be automatically triggered
(3) Fix unit tests to wait for compaction to finish instead of flush, before checking the compaction results.
Test Plan: pass all unit tests
Reviewers: haobo, xjin, dhruba
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13461/Features in Transaction log iterator
Summary:
* Logstore requests a valid change of reutrning an empty iterator and not an error in case of no log files.
* Changed the code to return the writebatch containing the sequence number requested from GetupdatesSince even if it lies in the middle. Earlier we used to return the next writebatch,. This also allows me oto guarantee that no files played upon by the iterator are redundant. I mean the starting log file has at least a sequence number >= the sequence number requested form GetupdatesSince.
* Cleaned up redundant logic in Iterator::Next and made a new function SeekToStartSequence for greater readability and maintainibilty.
* Modified a test in db_test accordingly
Please check the logic carefully and suggest improvements. I have a separate patch out for more improvements like restricting reader to read till written sequences.
Test Plan:
* transaction log iterator tests in db_test,
* db_repl_stress.
* rocks_log_iterator_test in fbcode/wormhole/rocksdb/test - 2 tests thriving on hacks till now can get simplified
* testing on the shadow setup for sigma with replication
Reviewers: dhruba, haobo, kailiu, sdong
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13437/Change Function names from Compaction->Flush When they really mean Flush
Summary: When I debug the unit test failures when enabling background flush thread, I feel the function names can be made clearer for people to understand. Also, if the names are fixed, in many places, some tests' bugs are obvious (and some of those tests are failing). This patch is to clean it up for future maintenance.
Test Plan: Run test suites.
Reviewers: haobo, dhruba, xjin
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13431/Fixing error in ParseFileName causing DestroyDB to fail on archive directory
Summary:
This careless error was causing ASSERT_OK(DestroyDB) to fail in db_test.
Basically .. was being returned as a child of db/archive and ParseFileName returned false on that,
but 'type' was set to LogFile from earlier and not reset. The return of ParseFileName was not being checked to delete the log file or not.
Test Plan: make all check
Reviewers: dhruba, haobo, xjin, kailiu, nkg-
Reviewed By: nkg-
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13413/Add option for storing transaction logs in a separate dir
Summary: In some cases, you might not want to store the data log (write ahead log) files in the same dir as the sst files. An example use case is leaf, which stores sst files in tmpfs. And would like to save the log files in a separate dir (disk) to save memory.
Test Plan: make all. Ran db_test test. A few test failing. P2785018. If you guys don't see an obvious problem with the code, maybe somebody from the rocksdb team could help me debug the issue here. Running this on leaf worked well. I could see logs stored on disk, and deleted appropriately after compactions. Obviously this is only one set of options. The unit tests cover different options. Seems like I'm missing some edge cases.
Reviewers: dhruba, haobo, leveldb
CC: xinyaohu, sumeet
Differential Revision: https://reviews.facebook.net/D13239/Make db_test more robust
Summary: While working on D13239, I noticed that the same options are not used for opening and destroying at db. So adding that. Also added asserts for successful DestroyDB calls.
Test Plan: Ran unit tests. Atleast 1 unit test is failing. They failures are a result of some past logic change. I'm not really planning to fix those. But I would like to check this in. And hopefully the respective unit test owners can fix the broken tests
Reviewers: leveldb, haobo
CC: xinyaohu, sumeet, dhruba
Differential Revision: https://reviews.facebook.net/D13329/Unit test failure in DBTest.NumImmutableMemTable.
Summary:
Previous patch introduced a unit test failure in
DBTest.NumImmutableMemTable because of change in property names.
Test Plan:
Reviewers:
CC:
Task ID: #
Blame Rev:/Migrate names of properties from 'leveldb' prefix to 'rocksdb' prefix.
Summary: Migrate names of properties from 'leveldb' prefix to 'rocksdb' prefix.
Test Plan: make check
Reviewers: emayanke, haobo
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13311/Fix SIGSEGV issue in universal compaction
Summary:
We saw SIGSEGV when set options.num_levels=1 in universal compaction
style. Dug into this issue for a while, and finally found the root cause (thank Haobo for discussion).
Test Plan: Add new unit test. It throws SIGSEGV without this change. Also run ""make all check"".
Reviewers: haobo, dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13251/New unit test for iterator with snapshot
Summary:
I played with the reported bug about iterator with snapshot:
https://code.google.com/p/leveldb/issues/detail?id=200.
I turned the original test program
(https://code.google.com/p/leveldb/issues/attachmentText?id=200&aid=2000000000&name=test.cc&token=7uOUQW-HFlbAFMUm7EqtaAEy7Tw%3A1378320724136)
into a new unit test, but I cannot reproduce the problem. Notice lines
31-34 in above link. I have ran the new test with and without such Put()
operations. Both succeed.
So this diff simply adds the test, without changing any source codes.
Test Plan: run new test.
Reviewers: dhruba, haobo, emayanke
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12735/[RocksDB] Fix DBTest.UniversalCompactionSizeAmplification too
Summary: as title
Test Plan: make db_test; ./db_test
Reviewers: dhruba
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13005/[RocksDB] Fix DBTest.UniversalCompactionTrigger to reflect the correct compaction trigger condition.
Summary: as title
Test Plan: make db_test; ./db_test
Reviewers: dhruba
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12981/Flush was hanging because the configured options specified that more than 1 memtable need to be merged.
Summary:
There is an config option called Options.min_write_buffer_number_to_merge
that specifies the minimum number of write buffers to merge in memory
before flushing to a file in L0. But in the the case when the db is
being closed, we should not be using this config, instead we should
flush whatever write buffers were available at that time.
Test Plan: Unit test attached.
Reviewers: haobo, emayanke
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12717/[RocksDB] Fix TransformRepFactory related valgrind problem
Summary: Let TransformRepFactory own the passed in transform. Also make it better encapsulated.
Test Plan: make valgrind_check;
Reviewers: dhruba, emayanke
Reviewed By: emayanke
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12591/Fix bug in KeyMayExist
Summary: In KeyMayExist.db_test we do a Flush which causes sst file to be written and added as open file in TableCache, but block cache for the file is not populated. So value_found should have been false where it was true and KeyMayExist.db_test should not have passed earlier. But it passed because BlockReader in table/table.cc takes 2 default arguments at the end called for_compaction and no_io. Although I passed no_io=true from InternalGet to BlockReader, but it understood for_compaction=true and defaulted no_io to false. This is a bug and although will be removed by Dhruba's new patch to incorporate no_io in readoptions, I'm submitting this patch to fix this bug independently of that patch.
Test Plan: make all check
Reviewers: dhruba, haobo
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12537/Add three new MemTableRep's
Summary:
This patch adds three new MemTableRep's: UnsortedRep, PrefixHashRep, and VectorRep.
UnsortedRep stores keys in an std::unordered_map of std::sets. When an iterator is requested, it dumps the keys into an std::set and iterates over that.
VectorRep stores keys in an std::vector. When an iterator is requested, it creates a copy of the vector and sorts it using std::sort. The iterator accesses that new vector.
PrefixHashRep stores keys in an unordered_map mapping prefixes to ordered sets.
I also added one API change. I added a function MemTableRep::MarkImmutable. This function is called when the rep is added to the immutable list. It doesn't do anything yet, but it seems like that could be useful. In particular, for the vectorrep, it means we could elide the extra copy and just sort in place. The only reason I haven't done that yet is because the use of the ArenaAllocator complicates things (I can elaborate on this if needed).
Test Plan:
make -j32 check
./db_stress --memtablerep=vector
./db_stress --memtablerep=unsorted
./db_stress --memtablerep=prefixhash --prefix_size=10
Reviewers: dhruba, haobo, emayanke
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D12117/"
rocksdb,"Migrate names of properties from 'leveldb' prefix to 'rocksdb' prefix.
Summary: Migrate names of properties from 'leveldb' prefix to 'rocksdb' prefix.
Test Plan: make check
Reviewers: emayanke, haobo
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13311/"
rocksdb,"Fix some errors detected by coverity scan
Summary: Nothing major, just an extra return line and posibility of leaking fb in NewRandomRWFile
Test Plan: make check
Reviewers: kailiu, dhruba
Reviewed By: kailiu
CC: leveldb
Differential Revision: https://reviews.facebook.net/D15993/Fix a bunch of mac compilation issues in performance branch/Fix build without glibc
Summary: The preprocessor does not follow normal rules of && evaluation, tries to evaluate __GLIBC_PREREQ(2, 12) even though the defined() check fails.  This breaks the build if __GLIBC_PREREQ is absent.
Test Plan: Try adding #undef __GLIBC_PREREQ above the offending line, build no longer breaks
Reviewed By: igor
Blame Rev: 4c81383628db46d35b674000a3668b5a9a2498a6/[RocksDB Performance Branch] Fix a regression bug of munmap
Summary:
Fix a stupid bug I just introduced in b59d4d5a5051263b4bfcef00913219ffe4654e42, which I didn't even mean to include.
GCC might remove the munmap.
Test Plan: Run it and make sure munmap succeeds
Reviewers: haobo, kailiu
Reviewed By: kailiu
CC: dhruba, reconnect.grayhat, leveldb
Differential Revision: https://reviews.facebook.net/D14361/make util/env_posix.cc work under mac
Summary: This diff invoves some more complicated issues in the posix environment.
Test Plan: works under mac os. will need to verify dev box.
Reviewers: dhruba
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D14061/"
rocksdb,"Merge pull request #5 from pborreli/typos
Fixed typos/Fixed typos/"
rocksdb,"[CF] Rethinking ColumnFamilyHandle and fix to dropping column families
Summary:
The change to the public behavior:
* When opening a DB or creating new column family client gets a ColumnFamilyHandle.
* As long as column family handle is alive, client can do whatever he wants with it, even drop it
* Dropped column family can still be read from (using the column family handle)
* Added a new call CloseColumnFamily(). Client has to close all column families that he has opened before deleting the DB
* As soon as column family is closed, any calls to DB using that column family handle will fail (also any outstanding calls)
Internally:
* Ref-counting ColumnFamilyData
* New thread-safety for ColumnFamilySet
* Dropped column families are now completely dropped and their memory cleaned-up
Test Plan: added some tests to column_family_test
Reviewers: dhruba, haobo, kailiu, sdong
CC: leveldb
Differential Revision: https://reviews.facebook.net/D16101/[RocksDB] [Column Family] Interface proposal
Summary:
<This diff is for Column Family branch>
Sharing some of the work I've done so far. This diff compiles and passes the tests.
The biggest change is in options.h - I broke down Options into two parts - DBOptions and ColumnFamilyOptions. DBOptions is DB-specific (env, create_if_missing, block_cache, etc.) and ColumnFamilyOptions is column family-specific (all compaction options, compresion options, etc.). Note that this does not break backwards compatibility at all.
Further, I created DBWithColumnFamily which inherits DB interface and adds new functions with column family support. Clients can transparently switch to DBWithColumnFamily and it will not break their backwards compatibility.
There are few methods worth checking out: ListColumnFamilies(), MultiNewIterator(), MultiGet() and GetSnapshot(). [GetSnapshot() returns the snapshot across all column families for now - I think that's what we agreed on]
Finally, I made small changes to WriteBatch so we are able to atomically insert data across column families.
Please provide feedback.
Test Plan: make check works, the code is backward compatible
Reviewers: dhruba, haobo, sdong, kailiu, emayanke
CC: leveldb
Differential Revision: https://reviews.facebook.net/D14445/Fix stack overflow
Summary:
Sure, let me put 8 bytes in that int32_t.
Brought to you by ASAN!
Test Plan: ttl_test
Reviewers: dhruba, haobo, kailiu, emayanke
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D14193/"
rocksdb,"First phase API clean up
Summary:
Addressed all the issues in https://reviews.facebook.net/D15447.
Now most table-related modules are hidden from user land.
Test Plan: make check
Reviewers: sdong, haobo, dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D15525/Add an option to table_reader_bench to access the table from DB And Iterating non-existing prefix case.
Summary: This patch adds an option to table_reader_bench that queries run against DB level (which has one table). It is useful if user wants to see the extra costs DB level introduces.
Test Plan: Run the benchmark with and without the new parameter
Reviewers: haobo, dhruba, kailiu
Reviewed By: kailiu
CC: leveldb
Differential Revision: https://reviews.facebook.net/D13863/"
rocksdb,"First phase API clean up
Summary:
Addressed all the issues in https://reviews.facebook.net/D15447.
Now most table-related modules are hidden from user land.
Test Plan: make check
Reviewers: sdong, haobo, dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D15525/Temporarily disable caching index/filter blocks
Summary:
Mixing index/filter blocks with data blocks resulted in some known
issues.  To make sure in next release our users won't be affected,
we added a new option in BlockBasedTableFactory::TableOption to
conceal this functionality for now.
This patch also introduced a BlockBasedTableReader::OpenOptions,
which avoids the ""infinite"" growth of parameters in
BlockBasedTableReader::Open().
Test Plan: make check
Reviewers: haobo, sdong, igor, dhruba
Reviewed By: igor
CC: leveldb, tnovak
Differential Revision: https://reviews.facebook.net/D15327/make util/env_posix.cc work under mac
Summary: This diff invoves some more complicated issues in the posix environment.
Test Plan: works under mac os. will need to verify dev box.
Reviewers: dhruba
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D14061/Fix bloom filters
Summary: https://reviews.facebook.net/D13167 broke bloom filters. If filter is not in cache, we want to return true (safe thing). Am I right?
Test Plan: when benchmarking https://reviews.facebook.net/D14031 I got different results when using bloom filters vs. when not using them. This fixed the issue. I will also be putting this change to the other diff, but that one will probably be in review for longer time.
Reviewers: kailiu, dhruba, haobo
Reviewed By: kailiu
CC: leveldb
Differential Revision: https://reviews.facebook.net/D14085/"
rocksdb,"First phase API clean up
Summary:
Addressed all the issues in https://reviews.facebook.net/D15447.
Now most table-related modules are hidden from user land.
Test Plan: make check
Reviewers: sdong, haobo, dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D15525/[Performance Branch] If options.max_open_files set to be -1, cache table readers in FileMetadata for Get() and NewIterator()
Summary:
In some use cases, table readers for all live files should always be cached. In that case, there will be an opportunity to avoid the table cache look-up while Get() and NewIterator().
We define options.max_open_files = -1 to be the mode that table readers for live files will always be kept. In that mode, table readers are cached in FileMetaData (with a reference count hold in table cache). So that when executing table_cache.Get() and table_cache.newInterator(), LRU cache checking can be by-passed, to reduce latency.
Test Plan: add a test case in db_test
Reviewers: haobo, kailiu
Reviewed By: haobo
CC: dhruba, igor, leveldb
Differential Revision: https://reviews.facebook.net/D15039/Don't always compress L0 files written by memtable flush
Summary:
Code was always compressing L0 files written by a memtable flush
when compression was enabled. Now this is done when
min_level_to_compress=0 for leveled compaction and when
universal_compaction_size_percent=-1 for universal compaction.
Task ID: #3416472
Blame Rev:
Test Plan:
ran db_bench with compression options
Revert Plan:
Database Impact:
Memcache Impact:
Other Notes:
EImportant:
- begin *PUBLIC* platform impact section -
Bugzilla: #
- end platform impact -
Reviewers: dhruba, igor, sdong
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D14757/"
rocksdb,"Fix UnmarkEOF for partial blocks
Summary:
Blocks in the transaction log are a fixed size, but the last block in the transaction log file is usually a partial block. When a new record is added after the reader hit the end of the file, a new physical record will be appended to the last block. ReadPhysicalRecord can only read full blocks and assumes that the file position indicator is aligned to the start of a block. If the reader is forced to read further by simply clearing the EOF flag, ReadPhysicalRecord will read a full block starting from somewhere in the middle of a real block, causing it to lose alignment and to have a partial physical record at the end of the read buffer. This will result in length mismatches and checksum failures. When the log file is tailed for replication this will cause the log iterator to become invalid, necessitating the creation of a new iterator which will have to read the log file from scratch.
This diff fixes this issue by reading the remaining portion of the last block we read from. This is done when the reader is forced to read further (UnmarkEOF is called).
Test Plan:
- Added unit tests
- Stress test (with replication). Check dbdir/LOG file for corruptions.
- Test on test tier
Reviewers: emayanke, haobo, dhruba
Reviewed By: haobo
CC: vamsi, sheki, dhruba, kailiu, igor
Differential Revision: https://reviews.facebook.net/D15249/"
rocksdb,"[CF] Rethinking ColumnFamilyHandle and fix to dropping column families
Summary:
The change to the public behavior:
* When opening a DB or creating new column family client gets a ColumnFamilyHandle.
* As long as column family handle is alive, client can do whatever he wants with it, even drop it
* Dropped column family can still be read from (using the column family handle)
* Added a new call CloseColumnFamily(). Client has to close all column families that he has opened before deleting the DB
* As soon as column family is closed, any calls to DB using that column family handle will fail (also any outstanding calls)
Internally:
* Ref-counting ColumnFamilyData
* New thread-safety for ColumnFamilySet
* Dropped column families are now completely dropped and their memory cleaned-up
Test Plan: added some tests to column_family_test
Reviewers: dhruba, haobo, kailiu, sdong
CC: leveldb
Differential Revision: https://reviews.facebook.net/D16101/preload table handle on Recover() when max_open_files == -1
Summary: This covers existing table files before DB open happens and avoids contention on table cache
Test Plan: db_test
Reviewers: haobo, sdong, igor, dhruba
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D16089/use super_version in NewIterator() and MultiGet() function
Summary:
Use super_version insider NewIterator to avoid Ref() each component
separately under mutex
The new added bench shows NewIterator QPS increases from 515K to 719K
No meaningful improvement for multiget I guess due to its relatively small
cost comparing to 90 keys fetch in the test.
Test Plan: unit test and db_bench
Reviewers: igor, sdong
Reviewed By: igor
CC: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D15609/First phase API clean up
Summary:
Addressed all the issues in https://reviews.facebook.net/D15447.
Now most table-related modules are hidden from user land.
Test Plan: make check
Reviewers: sdong, haobo, dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D15525/Temporarily disable caching index/filter blocks
Summary:
Mixing index/filter blocks with data blocks resulted in some known
issues.  To make sure in next release our users won't be affected,
we added a new option in BlockBasedTableFactory::TableOption to
conceal this functionality for now.
This patch also introduced a BlockBasedTableReader::OpenOptions,
which avoids the ""infinite"" growth of parameters in
BlockBasedTableReader::Open().
Test Plan: make check
Reviewers: haobo, sdong, igor, dhruba
Reviewed By: igor
CC: leveldb, tnovak
Differential Revision: https://reviews.facebook.net/D15327/Tailing iterator
Summary:
This diff implements a special type of iterator that doesn't create a snapshot
(can be used to read newly inserted data) and is optimized for doing sequential
reads.
TailingIterator uses current superversion number to determine whether to
invalidate its internal iterators. If the version hasn't changed, it can often
avoid doing expensive seeks over immutable structures (sst files and immutable
memtables).
Test Plan:
* new unit tests
* running LD with this patch
Reviewers: igor, dhruba, haobo, sdong, kailiu
Reviewed By: sdong
CC: leveldb, lovro, march
Differential Revision: https://reviews.facebook.net/D15285/Refactor Recover() code
Summary:
This diff does two things:
* Rethinks how we call Recover() with read_only option. Before, we call it with pointer to memtable where we'd like to apply those changes to. This memtable is set in db_impl_readonly.cc and it's actually DBImpl::mem_. Why don't we just apply updates to mem_ right away? It seems more intuitive.
* Changes when we apply updates to manifest. Before, the process is to recover all the logs, flush it to sst files and then do one giant commit that atomically adds all recovered sst files and sets the next log number. This works good enough, but causes some small troubles for my column family approach, since I can't have one VersionEdit apply to more than single column family[1]. The change here is to commit the files recovered from logs right away. Here is the state of the world before the change:
1. Recover log 5, add new sst files to edit
2. Recover log 7, add new sst files to edit
3. Recover log 8, add new sst files to edit
4. Commit all added sst files to manifest and mark log files 5, 7 and 8 as recoverd (via SetLogNumber(9) function)
After the change, we'll do:
1. Recover log 5, commit the new sst files and set log 5 as recovered
2. Recover log 7, commit the new sst files and set log 7 as recovered
3. Recover log 8, commit the new sst files and set log 8 as recovered
The added (small) benefit is that if we fail after (2), the new recovery will only have to recover log 8. In previous case, we'll have to restart the recovery from the beginning. The bigger benefit will be to enable easier integration of multiple column families in Recovery code path.
[1] I'm happy to dicuss this decison, but I believe this is the cleanest way to go. It also makes backward compatibility much easier. We don't have a requirement of adding multiple column families atomically.
Test Plan: make check
Reviewers: dhruba, haobo, kailiu, sdong
Reviewed By: kailiu
CC: leveldb
Differential Revision: https://reviews.facebook.net/D15237/Allow callback to change size of existing value. Change return type of the callback function to an enum status to handle 3 cases.
Summary:
This diff fixes 2 hacks:
* The callback function can modify the existing value inplace, if the merged value fits within the existing buffer size. But currently the existing buffer size is not being modified. Now the callback recieves a int* allowing the size to be modified. Since size is encoded as a varint in the internal key for memtable. It might happen that the entire value might have be copied to the new location if the new size varint is smaller than the existing size varint.
* The callback function has 3 functionalities
1. Modify existing buffer inplace, and update size correspondingly. Now to indicate that, Returns 1.
2. Generate a new buffer indicating merged value. Returns 2.
3. Fails to do either of above, based on whatever application logic. Returns 0.
Test Plan: Just make all for now. I'm adding another unit test to test each scenario.
Reviewers: dhruba, haobo
Reviewed By: haobo
CC: leveldb, sdong, kailiu, xinyaohu, sumeet, danguo
Differential Revision: https://reviews.facebook.net/D15195/Fix CompactRange to apply filter to every key
Summary:
When doing CompactRange(), we should first flush the memtable and then calculate max_level_with_files. Also, we want to compact all the levels that have files, including level `max_level_with_files`.
This patch fixed the unit test.
Test Plan: Added a failing unit test and a fix, so it's not failing anymore.
Reviewers: dhruba, haobo, sdong
Reviewed By: haobo
CC: leveldb, xjin
Differential Revision: https://reviews.facebook.net/D14421/Fix test/[Performance Branch] If options.max_open_files set to be -1, cache table readers in FileMetadata for Get() and NewIterator()
Summary:
In some use cases, table readers for all live files should always be cached. In that case, there will be an opportunity to avoid the table cache look-up while Get() and NewIterator().
We define options.max_open_files = -1 to be the mode that table readers for live files will always be kept. In that mode, table readers are cached in FileMetaData (with a reference count hold in table cache). So that when executing table_cache.Get() and table_cache.newInterator(), LRU cache checking can be by-passed, to reduce latency.
Test Plan: add a test case in db_test
Reviewers: haobo, kailiu
Reviewed By: haobo
CC: dhruba, igor, leveldb
Differential Revision: https://reviews.facebook.net/D15039/[Performance Branch] A Hashed Linked List Based Mem Table
Summary:
Implement a mem table, in which keys are hashed based on prefixes. In each bucket, entries are organized in a sorted linked list. It has the same thread safety guarantee as skip list.
The motivation is to optimize memory usage for the case that prefix hashing is primary way of seeking to the entry. Compared to hash skip list implementation, this implementation is more memory efficient, but inside each bucket, search is always linear. The target scenario is that there are only very limited number of records in each hash bucket.
Test Plan: Add a test case in db_test
Reviewers: haobo, kailiu, dhruba
Reviewed By: haobo
CC: igor, nkg-, leveldb
Differential Revision: https://reviews.facebook.net/D14979/Fix the valgrind issues/Support multi-threaded DisableFileDeletions() and EnableFileDeletions()
Summary:
We don't want two threads to clash if they concurrently call DisableFileDeletions() and EnableFileDeletions(). I'm adding a counter that will enable file deletions only after all DisableFileDeletions() calls have been negated with EnableFileDeletions().
However, we also don't want to break the old behavior, so I added a parameter force to EnableFileDeletions(). If force is true, we will still enable file deletions after every call to EnableFileDeletions(), which is what is happening now.
Test Plan: make check
Reviewers: dhruba, haobo, sanketh
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D14781/Fix the unused variable warning message in mac os/[RocksDB] [Column Family] Interface proposal
Summary:
<This diff is for Column Family branch>
Sharing some of the work I've done so far. This diff compiles and passes the tests.
The biggest change is in options.h - I broke down Options into two parts - DBOptions and ColumnFamilyOptions. DBOptions is DB-specific (env, create_if_missing, block_cache, etc.) and ColumnFamilyOptions is column family-specific (all compaction options, compresion options, etc.). Note that this does not break backwards compatibility at all.
Further, I created DBWithColumnFamily which inherits DB interface and adds new functions with column family support. Clients can transparently switch to DBWithColumnFamily and it will not break their backwards compatibility.
There are few methods worth checking out: ListColumnFamilies(), MultiNewIterator(), MultiGet() and GetSnapshot(). [GetSnapshot() returns the snapshot across all column families for now - I think that's what we agreed on]
Finally, I made small changes to WriteBatch so we are able to atomically insert data across column families.
Please provide feedback.
Test Plan: make check works, the code is backward compatible
Reviewers: dhruba, haobo, sdong, kailiu, emayanke
CC: leveldb
Differential Revision: https://reviews.facebook.net/D14445/fix a warning in db_test when running `make release`/[RocksDB] BackupableDB
Summary:
In this diff I present you BackupableDB v1. You can easily use it to backup your DB and it will do incremental snapshots for you.
Let's first describe how you would use BackupableDB. It's inheriting StackableDB interface so you can easily construct it with your DB object -- it will add a method RollTheSnapshot() to the DB object. When you call RollTheSnapshot(), current snapshot of the DB will be stored in the backup dir. To restore, you can just call RestoreDBFromBackup() on a BackupableDB (which is a static method) and it will restore all files from the backup dir. In the next version, it will even support automatic backuping every X minutes.
There are multiple things you can configure:
1. backup_env and db_env can be different, which is awesome because then you can easily backup to HDFS or wherever you feel like.
2. sync - if true, it *guarantees* backup consistency on machine reboot
3. number of snapshots to keep - this will keep last N snapshots around if you want, for some reason, be able to restore from an earlier snapshot. All the backuping is done in incremental fashion - if we already have 00010.sst, we will not copy it again. *IMPORTANT* -- This is based on assumption that 00010.sst never changes - two files named 00010.sst from the same DB will always be exactly the same. Is this true? I always copy manifest, current and log files.
4. You can decide if you want to flush the memtables before you backup, or you're fine with backing up the log files -- either way, you get a complete and consistent view of the database at a time of backup.
5. More things you can find in BackupableDBOptions
Here is the directory structure I use:
backup_dir/CURRENT_SNAPSHOT - just 4 bytes holding the latest snapshot
0, 1, 2, ... - files containing serialized version of each snapshot - containing a list of files
files/*.sst - sst files shared between snapshots - if one snapshot references 00010.sst and another one needs to backup it from the DB, it will just reference the same file
files/ 0/, 1/, 2/, ... - snapshot directories containing private snapshot files - current, manifest and log files
All the files are ref counted and deleted immediatelly when they get out of scope.
Some other stuff in this diff:
1. Added GetEnv() method to the DB. Discussed with @haobo and we agreed that it seems right thing to do.
2. Fixed StackableDB interface. The way it was set up before, I was not able to implement BackupableDB.
Test Plan:
I have a unittest, but please don't look at this yet. I just hacked it up to help me with debugging. I will write a lot of good tests and update the diff.
Also, `make asan_check`
Reviewers: dhruba, haobo, emayanke
Reviewed By: dhruba
CC: leveldb, haobo
Differential Revision: https://reviews.facebook.net/D14295/Don't do compression tests if we don't have compression libs
Summary: These tests fail if compression libraries are not installed.
Test Plan: Manually disabled snappy, observed tests not ran.
Reviewers: dhruba, kailiu
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D14379/Include <unistd.h> in db_test
Summary: This is the only compile issue in Ubuntu. It might be better to include <unistd.h> only in env_posix and add Truncate function to Env, but since we use truncate only in db_test, I don't think it makes much sense.
Test Plan: Rocksdb now compiles on Ubuntu!
Reviewers: dhruba, kailiu
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D14127/make util/env_posix.cc work under mac
Summary: This diff invoves some more complicated issues in the posix environment.
Test Plan: works under mac os. will need to verify dev box.
Reviewers: dhruba
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D14061/"
rocksdb,"Improve EnvHdfs
Summary: Copy improvements from fbcode's version of EnvHdfs to our open-source version. Some very important bug fixes in there.
Test Plan: compiles
Reviewers: dhruba, haobo, sdong
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D18711/Enable log info with different levels.
Summary:
* Now each Log related function has a variant that takes an additional
argument indicating its log level, which is one of the following:
- DEBUG, INFO, WARN, ERROR, FATAL.
* To ensure backward-compatibility, old version Log functions are kept
unchanged.
* Logger now has a member variable indicating its log level.  Any incoming
Log request which log level is lower than Logger's log level will not
be output.
* The output of the newer version Log will be prefixed by its log level.
Test Plan:
Add a LogType test in auto_roll_logger_test.cc
= Sample log output =
2014/02/11-00:03:07.683895 7feded179840 [DEBUG] this is the message to be written to the log file!!
2014/02/11-00:03:07.683898 7feded179840 [INFO] this is the message to be written to the log file!!
2014/02/11-00:03:07.683900 7feded179840 [WARN] this is the message to be written to the log file!!
2014/02/11-00:03:07.683903 7feded179840 [ERROR] this is the message to be written to the log file!!
2014/02/11-00:03:07.683906 7feded179840 [FATAL] this is the message to be written to the log file!!
Reviewers: dhruba, xjin, kailiu
Reviewed By: kailiu
CC: leveldb
Differential Revision: https://reviews.facebook.net/D16071/"
rocksdb,"Fix TransactionLogIterator EOF caching
Summary:
When TransactionLogIterator comes to EOF, it calls UnmarkEOF and continues reading. However, if glibc cached the EOF status of the file, it will get EOF again, even though the new data might have been written to it.
This has been causing errors in Mac OS.
Test Plan: test passes, was failing before
Reviewers: dhruba, haobo, sdong
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D18381/Fixed a compile error which tries to check whether a size_t < 0 in env_posix.cc
Summary:
Fixed a compile error which tries to check whether a size_t < 0 in env_posix.cc
util/env_posix.cc:180:16: error: comparison of unsigned expression < 0 is always false [-Werror,-Wtautological-compare]
} while (r < 0 && errno == EINTR);
~ ^ ~
1 error generated.
Test Plan: make check all
Reviewers: igor, haobo
Reviewed By: igor
CC: leveldb
Differential Revision: https://reviews.facebook.net/D17379/Fix compile issue in Mac OS
Summary:
Compile issues are:
* Unused variable env_
* Unused fallocate_with_keep_size_
Test Plan: compiles
Reviewers: dhruba, haobo, sdong
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D17043/Optimize fallocation
Summary:
Based on my recent findings (posted in our internal group), if we use fallocate without KEEP_SIZE flag, we get superior performance of fdatasync() in append-only workloads.
This diff provides an option for user to not use KEEP_SIZE flag, thus optimizing his sync performance by up to 2x-3x.
At one point we also just called posix_fallocate instead of fallocate, which isn't very fast: http://code.woboq.org/userspace/glibc/sysdeps/posix/posix_fallocate.c.html (tl;dr it manually writes out zero bytes to allocate storage). This diff also fixes that, by first calling fallocate and then posix_fallocate if fallocate is not supported.
Test Plan: make check
Reviewers: dhruba, sdong, haobo, ljin
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D16761/Merge pull request #94 from yumiOS/modify_ftruncate_warning
Modify the compile error about ftruncate()/Modify the compile error about ftruncate()
Summary:
Change to store the return value from ftruncate().
The reason is that ftruncate() has ""warn_unused_result"" attribute in some environment.
Signed-off-by: Yumikiyo Osanai <yumios.art@gmail.com>/"
rocksdb,"Improve ttl_test
Summary:
Our valgrind tests are failing because ttl_test is kind of flakey. This diff should fix valgrind issue and make ttl_test less flakey and much faster.
Instead of relying on Env::Default() for getting current time, I expose `Env*` to all TTL functions that are interested in time. That way, I can insert a custom test Env which is then used to provide exactly the times we need. That way, we don't need to sleep anymore -- we control the time.
Test Plan: ttl_test in normal and valgrind run
Reviewers: dhruba, haobo, sdong, yhchiang
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D18399/"
rocksdb,"BackupableDBTest thread-safe
Summary: We need to lock accesses to some TestEnv variables. Otherwise we get failures like http://ci-builds.fb.com/job/rocksdb_asan_check/657/console
Test Plan: make check
Reviewers: dhruba, haobo, sdong
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D18489/More s/us fixes/DeleteLogFiles in FailOverwritingBackups/More bug fixed introduced by code cleanup/Some fixes to BackupableDB
Summary:
(1) Report corruption if backup meta file has tailing data that was not read. This should fix: https://github.com/facebook/rocksdb/issues/81 (also, @sdong reported similar issue)
(2) Don't use OS buffer when copying file to backup directory. We don't need the file in cache since we won't be reading it twice
(3) Don't delete newer backups when somebody tries to backup the diverged DB (restore from older backup, add new data, try to backup). Rather, just fail the new backup.
Test Plan: backupable_db_test
Reviewers: ljin, dhruba, sdong
Reviewed By: ljin
CC: leveldb, sdong
Differential Revision: https://reviews.facebook.net/D16287/"
rocksdb,"Enhance partial merge to support multiple arguments
Summary:
* PartialMerge api now takes a list of operands instead of two operands.
* Add min_pertial_merge_operands to Options, indicating the minimum
number of operands to trigger partial merge.
* This diff is based on Schalk's previous diff (D14601), but it also
includes necessary changes such as updating the pure C api for
partial merge.
Test Plan:
* make check all
* develop tests for cases where partial merge takes more than two
operands.
TODOs (from Schalk):
* Add test with min_partial_merge_operands > 2.
* Perform benchmarks to measure the performance improvements (can probably
use results of task #2837810.)
* Add description of problem to doc/index.html.
* Change wiki pages to reflect the interface changes.
Reviewers: haobo, igor, vamsi
Reviewed By: haobo
CC: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D16815/"
rocksdb,"Enhance partial merge to support multiple arguments
Summary:
* PartialMerge api now takes a list of operands instead of two operands.
* Add min_pertial_merge_operands to Options, indicating the minimum
number of operands to trigger partial merge.
* This diff is based on Schalk's previous diff (D14601), but it also
includes necessary changes such as updating the pure C api for
partial merge.
Test Plan:
* make check all
* develop tests for cases where partial merge takes more than two
operands.
TODOs (from Schalk):
* Add test with min_partial_merge_operands > 2.
* Perform benchmarks to measure the performance improvements (can probably
use results of task #2837810.)
* Add description of problem to doc/index.html.
* Change wiki pages to reflect the interface changes.
Reviewers: haobo, igor, vamsi
Reviewed By: haobo
CC: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D16815/"
rocksdb,"Fix more gflag namespace issues/kill ReadOptions.prefix and .prefix_seek
Summary:
also add an override option total_order_iteration if you want to use full
iterator with prefix_extractor
Test Plan: make all check
Reviewers: igor, haobo, sdong, yhchiang
Reviewed By: haobo
CC: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D17805/Turn on -Wmissing-prototypes
Summary: Compiling for iOS has by default turned on -Wmissing-prototypes, which causes rocksdb to fail compiling. This diff turns on -Wmissing-prototypes in our compile options and cleans up all functions with missing prototypes.
Test Plan: compiles
Reviewers: dhruba, haobo, ljin, sdong
Reviewed By: ljin
CC: leveldb
Differential Revision: https://reviews.facebook.net/D17649/Consolidate SliceTransform object ownership
Summary:
(1) Fix SanitizeOptions() to also check HashLinkList. The current
dynamic case just happens to work because the 2 classes have the same
layout.
(2) Do not delete SliceTransform object in HashSkipListFactory and
HashLinkListFactory destructor. Reason: SanitizeOptions() enforces
prefix_extractor and SliceTransform to be the same object when
Hash**Factory is used. This makes the behavior strange: when
Hash**Factory is used, prefix_extractor will be released by RocksDB. If
other memtable factory is used, prefix_extractor should be released by
user.
Test Plan: db_bench && make asan_check
Reviewers: haobo, igor, sdong
Reviewed By: igor
CC: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D16587/Followup code refactor on plain table
Summary:
Fixed most comments in https://reviews.facebook.net/D15429.
Still have some remaining comments left.
Test Plan: make all check
Reviewers: sdong, haobo
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D15885/Fix table_reader_bench and add it to ""make""
Summary: Fix table_reader_bench after some interface changes. Add it to make to avoid future breaking
Test Plan: make table_reader_bench and run it with different options.
Reviewers: kailiu, haobo
Reviewed By: haobo
CC: igor, leveldb
Differential Revision: https://reviews.facebook.net/D16107/"
rocksdb,"kill ReadOptions.prefix and .prefix_seek
Summary:
also add an override option total_order_iteration if you want to use full
iterator with prefix_extractor
Test Plan: make all check
Reviewers: igor, haobo, sdong, yhchiang
Reviewed By: haobo
CC: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D17805/Fix SIGFAULT when running sst_dump on v2.6 db
Summary: Fix the sigfault when running sst_dump on v2.6 db.
Test Plan:
git checkout bba6595b1f3f42cf79bb21c2d5b981ede1cc0063
make clean
make db_bench
./db_bench --db=/tmp/some/db --benchmarks=fillseq
arc patch D18039
make clean
make sst_dump
./sst_dump --file=/tmp/some/db --command=check
Reviewers: igor, haobo, sdong
Reviewed By: sdong
CC: leveldb
Differential Revision: https://reviews.facebook.net/D18039/Use a different approach to make sure BlockBasedTableReader can use hash index on older files
Summary:
A recent commit https://github.com/facebook/rocksdb/commit/e37dd216f9384bfdabc6760fa296e8ee28c79d30 makes sure hash index can be used when reading existing files. This patch uses another way to achieve the approach:
(1) Currently, always writing kBinarySearch to files, despite of BlockBasedTableOptions.IndexType setting.
(2) When reading a file, read out the field, and make sure it is kBinarySearch, while always use index type by users.
The reason for doing it is, to reserve kHashSearch property on disk to future. If now we write out binary index for both of kHashSearch and kBinarySearch. We have to use a new flag in the future for hash index on disk, otherwise compatibility would break. Also, we want the real index type and type shown in properties block to be consistent.
Test Plan: make all check
Reviewers: haobo, kailiu
Reviewed By: kailiu
CC: igor, ljin, yhchiang, xjin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D18009/Index type doesn't have to be persisted
Summary:
With the recent changes, there is no need to check the property block about the index block type.
If user want to use it, they don't really need any disk format change; everything happens in the fly.
Also another team encountered an error while reading the index type from properties.
Test Plan:
ran all the tests
Reviewers: sdong
CC:
Task ID: #
Blame Rev:/RocksDB 2.8 to be able to read files generated by 2.6
Summary:
From 2.6 to 2.7, property block name is renamed from rocksdb.stats to rocksdb.properties. Older properties were not able to be loaded. In 2.8, we seem to have added some logic that uses property block without checking null pointers, which create segment faults.
In this patch, we fix it by:
(1) try rocksdb.stats if rocksdb.properties is not found
(2) add some null checking before consuming rep->table_properties
Test Plan: make sure a file generated in 2.7 couldn't be opened now can be opened.
Reviewers: haobo, igor, yhchiang
Reviewed By: igor
CC: ljin, xjin, dhruba, kailiu, leveldb
Differential Revision: https://reviews.facebook.net/D17961/Turn on -Wmissing-prototypes
Summary: Compiling for iOS has by default turned on -Wmissing-prototypes, which causes rocksdb to fail compiling. This diff turns on -Wmissing-prototypes in our compile options and cleans up all functions with missing prototypes.
Test Plan: compiles
Reviewers: dhruba, haobo, ljin, sdong
Reviewed By: ljin
CC: leveldb
Differential Revision: https://reviews.facebook.net/D17649/Fix the memory leak in table index
Summary:
BinarySearchIndex didn't use unique_ptr to guard the block object nor
delete it in destructor, leading to valgrind failure for ""definite
memory leak"".
Test Plan:
re-ran the failed valgrind test cases/Fix the unit test failure in devbox
Summary:
My last diff was developed in MacOS but in devserver environment error occurs.
I dug into the problem and found the way we calcuate approximate data size is pretty out-of-date. We can use table properties to get more accurate results.
Test Plan: ran ./table_test and passed
Reviewers: igor, dhruba, haobo, sdong
CC: leveldb
Differential Revision: https://reviews.facebook.net/D16509/Fix inconsistent code format
Summary:
Found some function follows camel style. When naming funciton, we have two styles:
Trivially expose internal data in readonly mode: `all_lower_case()`
Regular function: `CapitalizeFirstLetter()`
I renames these functions.
Test Plan: make -j32
Reviewers: haobo, sdong, dhruba, igor
CC: leveldb
Differential Revision: https://reviews.facebook.net/D16383/Disable putting filter block to block cache
Summary: This bug caused server crash issues because the filter block is too big and kept purging out of cache.
Test Plan: Wrote a new unit tests to make sure it works.
Reviewers: dhruba, haobo, igor, sdong
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D16221/"
rocksdb,"Add more black-box tests for PlainTable and explicitly support total order mode
Summary:
1. Add some more implementation-aware tests for PlainTable
2. move from a hard-coded one index per 16 rows in one prefix to a configurable number. Also, make hash table ratio = 0  means binary search only. Also fixes some divide 0 risks.
3. Explicitly support total order (only use binary search)
4. some code cleaning up.
Test Plan: make all check
Reviewers: haobo, kailiu
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D16023/"
rocksdb,"[fix] SIGSEGV when VersionEdit in MANIFEST is corrupted
Summary:
This was reported by our customers in task #4295529.
Cause:
* MANIFEST file contains a VersionEdit, which contains file entries whose 'smallest' and 'largest' internal keys are empty. String with zero characters. Root cause of corruption was not investigated. We should report corruption when this happens. However, we currently SIGSEGV.
Here's what happens:
* VersionEdit encodes zero-strings happily and stores them in smallest and largest InternalKeys. InternalKey::Encode() does assert when `rep_.empty()`, but we don't assert in production environemnts. Also, we should never assert as a result of DB corruption.
* As part of our ConsistencyCheck, we call GetLiveFilesMetaData()
* GetLiveFilesMetadata() calls `file->largest.user_key().ToString()`
* user_key() function does: 1. assert(size > 8) (ooops, no assert), 2. returns `Slice(internal_key.data(), internal_key.size() - 8)`
* since `internal_key.size()` is unsigned int, this call translates to `Slice(whatever, 1298471928561892576182756)`. Bazinga.
Fix:
* VersionEdit checks if InternalKey is valid in `VersionEdit::GetInternalKey()`. If it's invalid, returns corruption.
Lessons learned:
* Always keep in mind that even if you `assert()`, production code will continue execution even if assert fails.
* Never `assert` based on DB corruption. Assert only if the code should guarantee that assert can't fail.
Test Plan: dumped offending manifest. Before: assert. Now: corruption
Reviewers: dhruba, haobo, sdong
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D18507/Don't store version number in MANIFEST
Summary: Talked to <insert internal project name> folks and they found it really scary that they won't be able to roll back once they upgrade to 2.8. We should fix this.
Test Plan: make check
Reviewers: haobo, ljin
Reviewed By: ljin
CC: leveldb
Differential Revision: https://reviews.facebook.net/D17343/disable the log_number check in Recover()
Summary:
There is a chance that an old MANIFEST is corrupted in 2.7 but just not noticed.
This check would fail them. Change it to log instead of returning a
Corruption status.
Test Plan: make
Reviewers: haobo, igor
Reviewed By: igor
CC: leveldb
Differential Revision: https://reviews.facebook.net/D16923/Fix bug in VersionEdit::DebugString()/Add MaxColumnFamily to VersionEdit::DebugString()/"
rocksdb,"kill ReadOptions.prefix and .prefix_seek
Summary:
also add an override option total_order_iteration if you want to use full
iterator with prefix_extractor
Test Plan: make all check
Reviewers: igor, haobo, sdong, yhchiang
Reviewed By: haobo
CC: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D17805/"
rocksdb,"Fixed a file-not-found issue when a log file is moved to archive.
Summary:
Fixed a file-not-found issue when a log file is moved to archive
by doing a missing retry.
Test Plan:
make db_test
export ROCKSDB_TEST=TransactionLogIteratorRace
./db_test
Reviewers: sdong, haobo
Reviewed By: sdong
CC: igor, leveldb
Differential Revision: https://reviews.facebook.net/D18669/log_and_apply_bench on a new benchmark framework
Summary:
db_test includes Benchmark for LogAndApply. This diff removes it from db_test and puts it into a separate log_and_apply bench. I just wanted to play around with our new benchmark framework and figure out how it works.
I would also like to show you how great it is! I believe right set of microbenchmarks can speed up our productivity a lot and help catch early regressions.
Test Plan: no
Reviewers: dhruba, haobo, sdong, ljin, yhchiang
Reviewed By: yhchiang
CC: leveldb
Differential Revision: https://reviews.facebook.net/D18261/Add a new mem-table representation based on cuckoo hash.
Summary:
= Major Changes =
* Add a new mem-table representation, HashCuckooRep, which is based cuckoo hash.
Cuckoo hash uses multiple hash functions.  This allows each key to have multiple
possible locations in the mem-table.
- Put: When insert a key, it will try to find whether one of its possible
locations is vacant and store the key.  If none of its possible
locations are available, then it will kick out a victim key and
store at that location.  The kicked-out victim key will then be
stored at a vacant space of its possible locations or kick-out
another victim.  In this diff, the kick-out path (known as
cuckoo-path) is found using BFS, which guarantees to be the shortest.
- Get: Simply tries all possible locations of a key --- this guarantees
worst-case constant time complexity.
- Time complexity: O(1) for Get, and average O(1) for Put if the
fullness of the mem-table is below 80%.
- Default using two hash functions, the number of hash functions used
by the cuckoo-hash may dynamically increase if it fails to find a
short-enough kick-out path.
- Currently, HashCuckooRep does not support iteration and snapshots,
as our current main purpose of this is to optimize point access.
= Minor Changes =
* Add IsSnapshotSupported() to DB to indicate whether the current DB
supports snapshots.  If it returns false, then DB::GetSnapshot() will
always return nullptr.
Test Plan:
Run existing tests.  Will develop a test specifically for cuckoo hash in
the next diff.
Reviewers: sdong, haobo
Reviewed By: sdong
CC: leveldb, dhruba, igor
Differential Revision: https://reviews.facebook.net/D16155/More unsigned/signed compare fixes/Fix TransactionLogIterator EOF caching
Summary:
When TransactionLogIterator comes to EOF, it calls UnmarkEOF and continues reading. However, if glibc cached the EOF status of the file, it will get EOF again, even though the new data might have been written to it.
This has been causing errors in Mac OS.
Test Plan: test passes, was failing before
Reviewers: dhruba, haobo, sdong
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D18381/avoid calling FindFile twice in TwoLevelIterator for PlainTable
Summary:
this is to reclaim the regression introduced in
https://reviews.facebook.net/D17853
Test Plan: make all check
Reviewers: igor, haobo, sdong, dhruba, yhchiang
Reviewed By: haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D17985/kill ReadOptions.prefix and .prefix_seek
Summary:
also add an override option total_order_iteration if you want to use full
iterator with prefix_extractor
Test Plan: make all check
Reviewers: igor, haobo, sdong, yhchiang
Reviewed By: haobo
CC: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D17805/Remove TransactionLogIteratorRace when -DNDEBUG/When creating a new DB, fail it when wal_dir contains existing log files
Summary: Current behavior of creating new DB is, if there is existing log files, we will go ahead and replay them on top of empty DB. This is a behavior that no user would expect. With this patch, we will fail the creation if a user creates a DB with existing log files.
Test Plan: make all check
Reviewers: haobo, igor, ljin
Reviewed By: haobo
CC: nkg-, yhchiang, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D17817/Set log_empty to false even when options.sync is off [fix tests]/Turn on -Wmissing-prototypes
Summary: Compiling for iOS has by default turned on -Wmissing-prototypes, which causes rocksdb to fail compiling. This diff turns on -Wmissing-prototypes in our compile options and cleans up all functions with missing prototypes.
Test Plan: compiles
Reviewers: dhruba, haobo, ljin, sdong
Reviewed By: ljin
CC: leveldb
Differential Revision: https://reviews.facebook.net/D17649/Improved CompressedCache
Summary:
This is testing behavior that was reported in https://github.com/facebook/rocksdb/issues/111
No issue was found, but it still good to commit this and make CompressedCache more robust.
Test Plan: this is a plan
Reviewers: ljin, dhruba
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D17625/Fix GetProperty() test
Summary:
GetProperty test is flakey.
Before this diff: P8635927
After: P8635945
We need to make sure the thread is done before we destruct sleeping tasks. Otherwise, bad things happen.
Test Plan: See summary
Reviewers: ljin, sdong, haobo, dhruba
Reviewed By: ljin
CC: leveldb
Differential Revision: https://reviews.facebook.net/D17595/[RocksDB] Fix a race condition in GetSortedWalFiles
Summary: This patch fixed a race condition where a log file is moved to archived dir in the middle of GetSortedWalFiles. Without the fix, the log file would be missed in the result, which leads to transaction log iterator gap. A test utility SyncPoint is added to help reproducing the race condition.
Test Plan: TransactionLogIteratorRace; make check
Reviewers: dhruba, ljin
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D17121/More valgrind issues!
Summary: Fix some more CompactionFilterV2 valgrind issues. Maybe it would make sense for CompactionFilterV2 to delete its prefix_extractor?
Test Plan: ran CompactionFilterV2* tests with valgrind. issues before patch -> no issues after
Reviewers: haobo, sdong, ljin, dhruba
Reviewed By: dhruba
CC: leveldb, danguo
Differential Revision: https://reviews.facebook.net/D17337/Change default value of some Options
Summary: Since we are optimizing for server workloads, some default values are not optimized any more. We change some of those values that I feel it's less prone to regression bugs.
Test Plan: make all check
Reviewers: dhruba, haobo, ljin, igor, yhchiang
Reviewed By: igor
CC: leveldb, MarkCallaghan
Differential Revision: https://reviews.facebook.net/D16995/[rocksdb] make init prefix more robust
Summary:
Currently if client uses kNULLString as the prefix, it will confuse
compaction filter v2. This diff added a bool to indicate if the prefix
has been intialized. I also added a unit test to cover this case and
make sure the new code path is hit.
Test Plan: db_test
Reviewers: igor, haobo
Reviewed By: igor
CC: leveldb
Differential Revision: https://reviews.facebook.net/D17151/Fix DBTest.UniversalCompactionTrigger failure caused by D17067
Summary: D17067 breaks DBTest.UniversalCompactionTrigger because of wrong location of the checking. Fix it.
Test Plan: Run the test and make sure it passes.
Reviewers: igor, haobo
Reviewed By: igor
CC: dhruba, ljin, yhchiang, leveldb
Differential Revision: https://reviews.facebook.net/D17079/Fix compile issue in Mac OS
Summary:
Compile issues are:
* Unused variable env_
* Unused fallocate_with_keep_size_
Test Plan: compiles
Reviewers: dhruba, haobo, sdong
Reviewed By: dhruba
CC: leveldb
Differential Revision: https://reviews.facebook.net/D17043/Add a DB property to indicate number of background errors encountered
Summary: Add a property to calculate number of background errors encountered to help users build their monitoring
Test Plan: Add a unit test. make all check
Reviewers: haobo, igor, dhruba
Reviewed By: igor
CC: ljin, nkg-, yhchiang, leveldb
Differential Revision: https://reviews.facebook.net/D16959/Fix a bug that Prev() can hang.
Summary: Prev() now can hang when there is a key with more than max_skipped number of appearance internally but all of them are newer than the sequence ID to seek. Add unit tests to confirm the bug and fix it.
Test Plan: make all check
Reviewers: igor, haobo
Reviewed By: igor
CC: ljin, yhchiang, leveldb
Differential Revision: https://reviews.facebook.net/D16899/A heuristic way to check if a memtable is full
Summary:
This is is based on https://reviews.facebook.net/D15027. It's not finished but I would like to give a prototype to avoid arena over-allocation while making better use of the already allocated memory blocks.
Instead of check approximate memtable size, we will take a deeper look at the arena, which incorporate essential idea that @sdong suggests: flush when arena has allocated its last and the last is ""almost full""
Test Plan: N/A
Reviewers: haobo, sdong
Reviewed By: sdong
CC: leveldb, sdong
Differential Revision: https://reviews.facebook.net/D15051/More bug fixed introduced by code cleanup/Bug fixes introduced by code cleanup/Revert ""Fix bad merge of D16791 and D16767""
This reverts commit 839c8ecfcd486f0db82ecb755a137ad95909966f./Fix bad merge of D16791 and D16767
Summary: A bad Auto-Merge caused log buffer is flushed twice. Remove the unintended one.
Test Plan: Should already be tested (the code looks the same as when I ran unit tests).
Reviewers: haobo, igor
Reviewed By: haobo
CC: ljin, yhchiang, leveldb
Differential Revision: https://reviews.facebook.net/D16821/Consolidate SliceTransform object ownership
Summary:
(1) Fix SanitizeOptions() to also check HashLinkList. The current
dynamic case just happens to work because the 2 classes have the same
layout.
(2) Do not delete SliceTransform object in HashSkipListFactory and
HashLinkListFactory destructor. Reason: SanitizeOptions() enforces
prefix_extractor and SliceTransform to be the same object when
Hash**Factory is used. This makes the behavior strange: when
Hash**Factory is used, prefix_extractor will be released by RocksDB. If
other memtable factory is used, prefix_extractor should be released by
user.
Test Plan: db_bench && make asan_check
Reviewers: haobo, igor, sdong
Reviewed By: igor
CC: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D16587/MergingIterator assertion
Summary: I wrote a test that triggers assertion in MergingIterator. I have not touched that code ever, so I'm looking for somebody with good understanding of the MergingIterator code to fix this. The solution is probably a one-liner. Let me know if you're willing to take a look.
Test Plan: This test fails with an assertion `use_heap_ == false`
Reviewers: dhruba, haobo, sdong, kailiu
Reviewed By: sdong
CC: leveldb
Differential Revision: https://reviews.facebook.net/D16521/[CF] Handle failure in WriteBatch::Handler
Summary:
* Add ColumnFamilyHandle::GetID() function. Client needs to know column family's ID to be able to construct WriteBatch
* Handle WriteBatch::Handler failure gracefully. Since WriteBatch is not a very smart function (it takes raw CF id), client can add data to WriteBatch for column family that doesn't exist. In that case, we need to gracefully return failure status from DB::Write(). To do that, I added a return Status to WriteBatch functions PutCF, DeleteCF and MergeCF.
Test Plan: Added test to column_family_test
Reviewers: dhruba, haobo
CC: leveldb
Differential Revision: https://reviews.facebook.net/D16323/Fix table properties
Summary: Adapt table properties to column family world
Test Plan: make check
Reviewers: kailiu
CC: leveldb
Differential Revision: https://reviews.facebook.net/D16161/fix u/s comparison #83/[CF] DB test to run on non-default column family
Summary:
This is a huge diff and it was hectic, but the idea is actually quite simple. Every operation (Put, Get, etc.) done on default column family in DBTest is now forwarded to non-default (""pikachu""). The good news is that we had zero test failures! Column families look stable so far.
One interesting test that I adapted for column families is MultiThreadedTest. I replaced every Put() with a WriteBatch writing to all column families concurrently. Every Put in the write batch contains unique_id. Instead of Get() I do a multiget across all column families with the same key. If atomicity holds, I expect to see the same unique_id in all column families.
Test Plan: This is a test!
Reviewers: dhruba, haobo, kailiu, sdong
CC: leveldb
Differential Revision: https://reviews.facebook.net/D16149/"
rocksdb,"kill ReadOptions.prefix and .prefix_seek
Summary:
also add an override option total_order_iteration if you want to use full
iterator with prefix_extractor
Test Plan: make all check
Reviewers: igor, haobo, sdong, yhchiang
Reviewed By: haobo
CC: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D17805/Turn on -Wmissing-prototypes
Summary: Compiling for iOS has by default turned on -Wmissing-prototypes, which causes rocksdb to fail compiling. This diff turns on -Wmissing-prototypes in our compile options and cleans up all functions with missing prototypes.
Test Plan: compiles
Reviewers: dhruba, haobo, ljin, sdong
Reviewed By: ljin
CC: leveldb
Differential Revision: https://reviews.facebook.net/D17649/Fix valgrind error in c_test/Merge pull request #105 from tecbot/c-api-prefix
[C-API] support prefix seeks/[C-API] added the possiblity to create a HashSkipList or HashLinkedList to support prefix seeks/Enhance partial merge to support multiple arguments
Summary:
* PartialMerge api now takes a list of operands instead of two operands.
* Add min_pertial_merge_operands to Options, indicating the minimum
number of operands to trigger partial merge.
* This diff is based on Schalk's previous diff (D14601), but it also
includes necessary changes such as updating the pure C api for
partial merge.
Test Plan:
* make check all
* develop tests for cases where partial merge takes more than two
operands.
TODOs (from Schalk):
* Add test with min_partial_merge_operands > 2.
* Perform benchmarks to measure the performance improvements (can probably
use results of task #2837810.)
* Add description of problem to doc/index.html.
* Change wiki pages to reflect the interface changes.
Reviewers: haobo, igor, vamsi
Reviewed By: haobo
CC: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D16815/Fix C API/"
rocksdb,"In tools/db_stress.cc, set proper value in NewHashSkipListRepFactory's bucket_size
Summary:
Now that the arena is used to allocate space for hashskiplist's bucket. The bucket size
need to be set small enough to avoid ""should_flush_"" failure in memtable's assertion.
Test Plan:
make all check
Reviewers: sdong
Reviewed By: sdong
Subscribers: igor
Differential Revision: https://reviews.facebook.net/D19371/"
rocksdb,"cleanup exception text/- hdfs cleanup; fix to NewDirectory to comply with definition in env.h
- fix compile error with env_test; static casts added/"
rocksdb,"Fix 32-bit errors
Summary: https://www.facebook.com/groups/rocksdb.dev/permalink/590438347721350/
Test Plan: compiles
Reviewers: sdong, ljin, yhchiang
Reviewed By: yhchiang
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D19197/ThreadID printed when Thread terminating in the same format as posix_logger
Summary: https://github.com/facebook/rocksdb/commit/220132b65ec17abb037d3e79d5abf6ca8d797b96 correctly fixed the issue of thread ID printing when terminating a thread. Nothing wrong with it. This diff prints the ID in the same way as in PosixLogger::logv() so that users can be more easily to correlates them.
Test Plan: run env_test and make sure it prints correctly.
Reviewers: igor, haobo, ljin, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D18819/"
rocksdb,"[Java] Optimize statistics collector, improve object dependency in RocksObjects
Summary:
This diff merges pull request 208.  Contributor: ankgup87
[Java] Optimize statistics collector
* Optimize statistics collector by collecting statistics of multiple DBs in a single thread rather than starting up a new thread for each DB.
* Also, fix packaging of jnilib file on OS_X platform.
* Diff review: https://reviews.facebook.net/D20265
[Java] Add documentation on interdependency of dispose call of RocksObjects
* Remove transferCppRawPointersOwnershipFrom function.
- This function was setting opt.filter_ and thus filter_ to be null. This way there is no
one holding reference for filter object and can thus be GC'd which is not the intention.
Replaced it with storeOptionsInstace which stores options instance. Options class
internally holds Filter instance. Thus when Options is GC'd, filter reference
will be GC'd automatically.
* Added documentation explaining interdependency of Filter, Options and DB.
* Diff review: https://reviews.facebook.net/D20379
Test Plan:
described in their diff reviews
Reviewers:  haobo sdong swapnilghike zzbennett rsumbaly yhchiang
Reviewed by: yhchiang/[Java] Optimize statistics collector, improve object dependency in RocksObjects
Summary:
This diff merges pull request #208.  Contributor: ankgup87
[Java] Optimize statistics collector
* Optimize statistics collector by collecting statistics of multiple DBs in a single thread rather than starting up a new thread for each DB.
* Also, fix packaging of jnilib file on OS_X platform.
* Diff review: https://reviews.facebook.net/D20265
[Java] Add documentation on interdependency of dispose call of RocksObjects
* Remove transferCppRawPointersOwnershipFrom function.
- This function was setting opt.filter_ and thus filter_ to be null. This way there is no
one holding reference for filter object and can thus be GC'd which is not the intention.
Replaced it with storeOptionsInstace which stores options instance. Options class
internally holds Filter instance. Thus when Options is GC'd, filter reference
will be GC'd automatically.
* Added documentation explaining interdependency of Filter, Options and DB.
* Diff review: https://reviews.facebook.net/D20379
Test Plan:
described in their diff reviews
Reviewers:  haobo sdong swapnilghike zzbennett rsumbaly yhchiang
Reviewed by: yhchiang/"
rocksdb,Arc lint fixes/Fix build/
rocksdb,"[Java] Optimize statistics collector, improve object dependency in RocksObjects
Summary:
This diff merges pull request 208.  Contributor: ankgup87
[Java] Optimize statistics collector
* Optimize statistics collector by collecting statistics of multiple DBs in a single thread rather than starting up a new thread for each DB.
* Also, fix packaging of jnilib file on OS_X platform.
* Diff review: https://reviews.facebook.net/D20265
[Java] Add documentation on interdependency of dispose call of RocksObjects
* Remove transferCppRawPointersOwnershipFrom function.
- This function was setting opt.filter_ and thus filter_ to be null. This way there is no
one holding reference for filter object and can thus be GC'd which is not the intention.
Replaced it with storeOptionsInstace which stores options instance. Options class
internally holds Filter instance. Thus when Options is GC'd, filter reference
will be GC'd automatically.
* Added documentation explaining interdependency of Filter, Options and DB.
* Diff review: https://reviews.facebook.net/D20379
Test Plan:
described in their diff reviews
Reviewers:  haobo sdong swapnilghike zzbennett rsumbaly yhchiang
Reviewed by: yhchiang/[Java] Optimize statistics collector, improve object dependency in RocksObjects
Summary:
This diff merges pull request #208.  Contributor: ankgup87
[Java] Optimize statistics collector
* Optimize statistics collector by collecting statistics of multiple DBs in a single thread rather than starting up a new thread for each DB.
* Also, fix packaging of jnilib file on OS_X platform.
* Diff review: https://reviews.facebook.net/D20265
[Java] Add documentation on interdependency of dispose call of RocksObjects
* Remove transferCppRawPointersOwnershipFrom function.
- This function was setting opt.filter_ and thus filter_ to be null. This way there is no
one holding reference for filter object and can thus be GC'd which is not the intention.
Replaced it with storeOptionsInstace which stores options instance. Options class
internally holds Filter instance. Thus when Options is GC'd, filter reference
will be GC'd automatically.
* Added documentation explaining interdependency of Filter, Options and DB.
* Diff review: https://reviews.facebook.net/D20379
Test Plan:
described in their diff reviews
Reviewers:  haobo sdong swapnilghike zzbennett rsumbaly yhchiang
Reviewed by: yhchiang/"
rocksdb,Fix compile/
rocksdb,"make statistics forward-able
Summary:
Make StatisticsImpl being able to forward stats to provided statistics
implementation. The main purpose is to allow us to collect internal
stats in the future even when user supplies custom statistics
implementation. It avoids intrumenting 2 sets of stats collection code.
One immediate use case is tuning advisor, which needs to collect some
internal stats, users may not be interested.
Test Plan:
ran db_bench and see stats show up at the end of run
Will run make all check since some tests rely on statistics
Reviewers: yhchiang, sdong, igor
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D20145/[RocksDB] Make block based table hash index more adaptive
Summary: Currently, RocksDB returns error if a db written with prefix hash index, is later opened without providing a prefix extractor. This is uncessarily harsh. Without a prefix extractor, we could always fallback to the normal binary index.
Test Plan: unit test, also manually veried LOG that fallback did occur.
Reviewers: sdong, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D19191/[RocksDB] Reduce memory footprint of the blockbased table hash index.
Summary:
Currently, the in-memory hash index of blockbased table uses a precise hash map to track the prefix to block range mapping. In some use cases, especially when prefix itself is big, the memory overhead becomes a problem. This diff introduces a fixed hash bucket array that does not store the prefix and allows prefix collision, which is similar to the plaintable hash index, in order to reduce the memory consumption.
Just a quick draft, still testing and refining.
Test Plan: unit test and shadow testing
Reviewers: dhruba, kailiu, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D19047/BlockBasedTable::PrefixMayMatch() to bloom setting to the beginning of the function
Summary: In BlockBasedTable::PrefixMayMatch() we calculate prefix even if bloom is not config. Move the check before
Test Plan: make all check
Reviewers: igor, ljin
Reviewed By: ljin
Subscribers: wuj, leveldb, haobo, yhchiang, dhruba
Differential Revision: https://reviews.facebook.net/D18993/Materialize the hash index
Summary:
Materialize the hash index to avoid the soaring cpu/flash usage
when initializing the database.
Test Plan: existing unit tests passed
Reviewers: sdong, haobo
Reviewed By: sdong
CC: leveldb
Differential Revision: https://reviews.facebook.net/D18339/"
rocksdb,"Materialize the hash index
Summary:
Materialize the hash index to avoid the soaring cpu/flash usage
when initializing the database.
Test Plan: existing unit tests passed
Reviewers: sdong, haobo
Reviewed By: sdong
CC: leveldb
Differential Revision: https://reviews.facebook.net/D18339/"
rocksdb,"Materialize the hash index
Summary:
Materialize the hash index to avoid the soaring cpu/flash usage
when initializing the database.
Test Plan: existing unit tests passed
Reviewers: sdong, haobo
Reviewed By: sdong
CC: leveldb
Differential Revision: https://reviews.facebook.net/D18339/"
rocksdb,"logging_when_create_and_delete_manifest
Summary:
1. logging when create and delete manifest file
2. fix formating in table/format.cc
Test Plan:
make all check
run db_bench, track the LOG file.
Reviewers: ljin, yhchiang, igor, yufei.zhu, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D21009/"
rocksdb,"PlainTable to encode to avoid to rewrite prefix when it is the same as the previous key
Summary:
Add a encoding feature of PlainTable to encode PlainTable's keys to save some bytes for the same prefixes.
The data format is documented in table/plain_table_factory.h
Test Plan: Add unit test coverage in plain_table_db_test
Reviewers: yhchiang, igor, dhruba, ljin, haobo
Reviewed By: haobo
Subscribers: nkg-, leveldb
Differential Revision: https://reviews.facebook.net/D18735/"
rocksdb,"[RocksDB] Reduce memory footprint of the blockbased table hash index.
Summary:
Currently, the in-memory hash index of blockbased table uses a precise hash map to track the prefix to block range mapping. In some use cases, especially when prefix itself is big, the memory overhead becomes a problem. This diff introduces a fixed hash bucket array that does not store the prefix and allows prefix collision, which is similar to the plaintable hash index, in order to reduce the memory consumption.
Just a quick draft, still testing and refining.
Test Plan: unit test and shadow testing
Reviewers: dhruba, kailiu, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D19047/"
rocksdb,"Pass parsed user key to prefix extractor in V2 compaction
Previously, the prefix extractor was being supplied with the RocksDB
key instead of a parsed user key. This makes correct interpretation
by calling application fragile or impossible./Merge pull request #228 from miguelportilla/develop
Changes to support unity build:
Script for building the unity.cc file via Makefile
Unity executable Makefile target for testing builds
Source code changes to fix compilation of unity build/Changes to support unity build:
* Script for building the unity.cc file via Makefile
* Unity executable Makefile target for testing builds
* Source code changes to fix compilation of unity build/Fix SIGSEGV in travis
Summary:
Travis build was failing a lot. For example see https://travis-ci.org/facebook/rocksdb/builds/31425845
This fixes it.
Also, please don't put any code after SignalAll :)
Test Plan: no more SIGSEGV
Reviewers: yhchiang, sdong, ljin
Reviewed By: ljin
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D21417/Fix valgrind failure caused by recent checked-in.
Summary: Initialize un-initialized parameters
Test Plan: run the failed test (c_test)
Reviewers: yhchiang, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D21249/Fix typo, add missing inclusion of state void* in invocation of
create_compaction_filter_v2_./Add support for C bindings to the compaction V2 filter mechanism.
Test Plan: make c_test && ./c_test
Some fixes after merge./logging_when_create_and_delete_manifest
Summary:
1. logging when create and delete manifest file
2. fix formating in table/format.cc
Test Plan:
make all check
run db_bench, track the LOG file.
Reviewers: ljin, yhchiang, igor, yufei.zhu, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D21009/Fixed the crash when merge_operator is not properly set after reopen.
Summary:
Fixed the crash when merge_operator is not properly set after reopen
and added two test cases for this.
Test Plan:
make merge_test
./merge_test
Reviewers: igor, ljin, sdong
Reviewed By: sdong
Subscribers: benj, mvikjord, leveldb
Differential Revision: https://reviews.facebook.net/D20793/InternalStats to take cfd on constructor
Summary:
It has one-to-one relationship with CFD. Take a pointer to CFD on
constructor to avoid passing cfd through member functions.
Test Plan: make
Reviewers: sdong, yhchiang, igor
Reviewed By: igor
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D20565/Change StopWatch interface
Summary: So that we can avoid calling NowSecs() in MakeRoomForWrite twice
Test Plan: make all check
Reviewers: yhchiang, igor, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D20529/make statistics forward-able
Summary:
Make StatisticsImpl being able to forward stats to provided statistics
implementation. The main purpose is to allow us to collect internal
stats in the future even when user supplies custom statistics
implementation. It avoids intrumenting 2 sets of stats collection code.
One immediate use case is tuning advisor, which needs to collect some
internal stats, users may not be interested.
Test Plan:
ran db_bench and see stats show up at the end of run
Will run make all check since some tests rely on statistics
Reviewers: yhchiang, sdong, igor
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D20145/make statistics forward-able
Summary:
Make StatisticsImpl being able to forward stats to provided statistics
implementation. The main purpose is to allow us to collect internal
stats in the future even when user supplies custom statistics
implementation. It avoids intrumenting 2 sets of stats collection code.
One immediate use case is tuning advisor, which needs to collect some
internal stats, users may not be interested.
Test Plan:
ran db_bench and see stats show up at the end of run
Will run make all check since some tests rely on statistics
Reviewers: yhchiang, sdong, igor
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D20145/fix bug in LOG for flush memtable
Summary:
One line change to fix a bug in the LOG when flush memtable
Test Plan:
NONE
Reviewers: sdong
Reviewed By: sdong
Differential Revision: https://reviews.facebook.net/D20049/Fixed a warning in release mode.
Summary: Removed a variable that is only used in assertion check.
Test Plan: make release
Reviewers: ljin, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D19455/Fixed a potential write hang
Summary:
Currently, when something badly happen in the DB::Write() while the write-queue
contains more than one element, the current design seems to forget to clean up
the queue as well as wake-up all the writers, this potentially makes rocksdb
hang on writes.
Test Plan: make all check
Reviewers: sdong, ljin, igor, haobo
Reviewed By: haobo
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D19167/bug fix: iteration over ColumnFamilySet needs to be under mutex
Summary: asan_crash_test is failing on segfault
Test Plan: running asan_crash_test
Reviewers: sdong, igor
Reviewed By: igor
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D19149/Write Fast-path for single column family
Summary: We have a perf regression of Write() even with one column family. Make fast path for single column family to avoid the perf regression. See task #4455480
Test Plan: make check
Reviewers: sdong, ljin
Reviewed By: sdong, ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D18963/Fix compile errors on Mac
Summary: https://phabricator.fb.com/P11372644
Test Plan: compiles
Reviewers: sdong, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D18873/Flush stale column families less aggressively
Summary:
We've seen some production issues where column family is detected as stale, although there is only one column family in the system. This is a quick fix that:
1) doesn't flush stale column families if there's only one of them
2) Use 4 as a coefficient instead of 2 for determening when a column family is stale. This will make flushing less aggressive, while still keep a nice dynamic flushing of very stale CFs.
Test Plan: make check
Reviewers: dhruba, haobo, ljin, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D18861/"
rocksdb,"Fix typo, add missing inclusion of state void* in invocation of
create_compaction_filter_v2_./Add support for C bindings to the compaction V2 filter mechanism.
Test Plan: make c_test && ./c_test
Some fixes after merge./Merge pull request #198 from rdallman/cf-compact-range
C API: bugfix column_family_compact_range/C API: bugfix column_family_comact_range/Fix compile issue/Fix valgrind error in c_test
Summary:
External contribution caused some valgrind errors: https://github.com/facebook/rocksdb/commit/1a34aaaef0900785c2de7e55b55d8c48d1201300
This diff fixes them
Test Plan: ran valgrind
Reviewers: sdong, yhchiang, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D19485/"
rocksdb,"Fixed a signed-unsigned comparison error in db_test
Summary:
Fixed a signed-unsigned comparison error in db_test
Test Plan:
make db_test/Fix db_test and DBIter
Summary: Fix old issue with DBTest.Randomized with BlockBasedTableWithWholeKeyHashIndex + added printing in DBTest.Randomized.
Test Plan: make all check
Reviewers: zagfox, igor, ljin, yhchiang, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D21003/Fixed a warning / error in signed and unsigned comparison
Summary:
Fixed the following compilation error detected in mac:
db/db_test.cc:2524:3: note: in instantiation of function template
specialization 'rocksdb::test::Tester::IsEq<unsigned long long, int>' requested here
ASSERT_EQ(int_num, 0);
^
Test Plan:
make/expose RateLimiter definition
Summary:
User gets undefinied error since the definition is not exposed.
Also re-enable the db test with only upper bound check
Test Plan: db_test, rate_limit_test
Reviewers: igor, yhchiang, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D20403/Fix db_test
Summary: Added deletion of DBIterators in DBIterator's tests
Test Plan: make valgrind_check
Reviewers: igor, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D20043/ForwardIterator seek bugfix
Summary:
If `NeedToSeekImmutable()` returns false, `SeekInternal()` won't reset the
contents of `immutable_min_heap_`. However, since it calls `UpdateCurrent()`
unconditionally, if `current_` is one of immutable iterators (previously popped
from `immutable_min_heap_`), `UpdateCurrent()` will overwrite it. As a result,
if old `current_` in fact pointed to the smallest entry, forward iterator will
skip some records.
Fix implemented in this diff pushes `current_` back to `immutable_min_heap_`
before calling `UpdateCurrent()`.
Test Plan:
New unit test (courtesy of @lovro):
$ ROCKSDB_TESTS=TailingIteratorSeekToSame ./db_test
Reviewers: igor, dhruba, haobo, ljin
Reviewed By: ljin
Subscribers: lovro, leveldb
Differential Revision: https://reviews.facebook.net/D19653/Improve SimpleWriteTimeoutTest to avoid false alarm.
Summary:
SimpleWriteTimeoutTest has two parts: 1) insert two large key/values
to make memtable full and expect both of them are successful; 2) insert
another key / value and expect it to be timed-out.  Previously we also
set a timeout in the first step, but this might sometimes cause
false alarm.
This diff makes the first two writes run without timeout setting.
Test Plan:
export ROCKSDB_TESTS=Time
make db_test
Reviewers: sdong, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D19461/Re-commit the correct part (WalDir) of the revision:
Commit 6634844dba962b9a150646382f4d6531d1f2440b by sdong
Two small fixes in db_test
Summary:
Two fixes:
(1) WalDir to pick a directory under TmpDir to allow two tests running in parallel without impacting each other
(2) kBlockBasedTableWithWholeKeyHashIndex is disabled by mistake (I assume). Enable it.
Test Plan: ./db_test
Reviewers: yhchiang, ljin
Reviewed By: ljin
Subscribers: nkg-, igor, dhruba, haobo, leveldb
Differential Revision: https://reviews.facebook.net/D19389/Revert ""Two small fixes in db_test""
This reverts commit 6634844dba962b9a150646382f4d6531d1f2440b./Two small fixes in db_test
Summary:
Two fixes:
(1) WalDir to pick a directory under TmpDir to allow two tests running in parallel without impacting each other
(2) kBlockBasedTableWithWholeKeyHashIndex is disabled by mistake (I assume). Enable it.
Test Plan: ./db_test
Reviewers: yhchiang, ljin
Reviewed By: ljin
Subscribers: nkg-, igor, dhruba, haobo, leveldb
Differential Revision: https://reviews.facebook.net/D19389/Allow compaction to reclaim storage more effectively.
Summary:
This diff allows compaction to reclaim storage more effectively.
In the current design, compactions are mainly triggered based on
the file sizes.  However, since deletion entries does not have
value, files which have many deletion entries are less likely
to be compacted.  As a result, it may took a while to make
deletion entries to be compacted.
This diff address issue by compensating the size of deletion
entries during compaction process: the size of each deletion
entry in the compaction process is augmented by 2x average
value size.  The diff applies to both leveled and universal
compacitons.
Test Plan:
develop CompactionDeletionTrigger
make db_test
./db_test
Reviewers: haobo, igor, ljin, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D19029/[RocksDB] Make block based table hash index more adaptive
Summary: Currently, RocksDB returns error if a db written with prefix hash index, is later opened without providing a prefix extractor. This is uncessarily harsh. Without a prefix extractor, we could always fallback to the normal binary index.
Test Plan: unit test, also manually veried LOG that fallback did occur.
Reviewers: sdong, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D19191/fix forward iterator bug
Summary: obvious
Test Plan: db_test
Reviewers: sdong, haobo, igor
Reviewed By: igor
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D18987/"
rocksdb,"Merge pull request #228 from miguelportilla/develop
Changes to support unity build:
Script for building the unity.cc file via Makefile
Unity executable Makefile target for testing builds
Source code changes to fix compilation of unity build/Changes to support unity build:
* Script for building the unity.cc file via Makefile
* Unity executable Makefile target for testing builds
* Source code changes to fix compilation of unity build/logging_when_create_and_delete_manifest
Summary:
1. logging when create and delete manifest file
2. fix formating in table/format.cc
Test Plan:
make all check
run db_bench, track the LOG file.
Reviewers: ljin, yhchiang, igor, yufei.zhu, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D21009/Fixed the crash when merge_operator is not properly set after reopen.
Summary:
Fixed the crash when merge_operator is not properly set after reopen
and added two test cases for this.
Test Plan:
make merge_test
./merge_test
Reviewers: igor, ljin, sdong
Reviewed By: sdong
Subscribers: benj, mvikjord, leveldb
Differential Revision: https://reviews.facebook.net/D20793/make statistics forward-able
Summary:
Make StatisticsImpl being able to forward stats to provided statistics
implementation. The main purpose is to allow us to collect internal
stats in the future even when user supplies custom statistics
implementation. It avoids intrumenting 2 sets of stats collection code.
One immediate use case is tuning advisor, which needs to collect some
internal stats, users may not be interested.
Test Plan:
ran db_bench and see stats show up at the end of run
Will run make all check since some tests rely on statistics
Reviewers: yhchiang, sdong, igor
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D20145/Fixed compaction-related errors where number of input levels are hard-coded.
Summary:
Fixed compaction-related errors where number of input levels are hard-coded.
It's a bug found in compaction branch.
This diff will be pushed into master.
Test Plan:
export ROCKSDB_TESTS=Compact
make db_test -j32
./db_test
also passed the tests in compaction branch
Reviewers: igor, sdong, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D20577/Guarding files_ attribute with #ifndef NDEBUG guard in FilePicker class.
Summary: Adding guards to files_ attribute of FilePicker class. This attribute is used only in DEBUG mode. This fixes build of static_lib in mac.
Test Plan:
make static_lib in mac
make check all in devserver
Reviewers: ljin, igor, sdong
Reviewed By: sdong
Differential Revision: https://reviews.facebook.net/D20163/Some fixes on size compensation logic for deletion entry in compaction
Summary:
This patch include two fixes:
1. newly created Version will now takes the aggregated stats for average-value-size from the latest Version.
2. compensated size of a file is now computed only for newly created / loaded file, this addresses the issue where files are already sorted by their compensated file size but might sometimes observe some out-of-order due to later update on compensated file size.
Test Plan:
export ROCKSDB_TESTS=CompactionDele
./db_test
Reviewers: ljin, igor, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D19557/Fix mac os compile error/Allow compaction to reclaim storage more effectively.
Summary:
This diff allows compaction to reclaim storage more effectively.
In the current design, compactions are mainly triggered based on
the file sizes.  However, since deletion entries does not have
value, files which have many deletion entries are less likely
to be compacted.  As a result, it may took a while to make
deletion entries to be compacted.
This diff address issue by compensating the size of deletion
entries during compaction process: the size of each deletion
entry in the compaction process is augmented by 2x average
value size.  The diff applies to both leveled and universal
compacitons.
Test Plan:
develop CompactionDeletionTrigger
make db_test
./db_test
Reviewers: haobo, igor, ljin, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D19029/VersionSet::Get(): Bring back the logic of skipping key range check when there are <=3 level 0 files
Summary:
https://reviews.facebook.net/D17205 removed the logic of skipping file key range check when there are less than 3 level 0 files. This patch brings it back.
Other than that, add another small optimization to avoid to check all the levels if most higher levels don't have any file.
Test Plan: make all check
Reviewers: ljin
Reviewed By: ljin
Subscribers: yhchiang, igor, haobo, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D19035/"
rocksdb,"Pass parsed user key to prefix extractor in V2 compaction
Previously, the prefix extractor was being supplied with the RocksDB
key instead of a parsed user key. This makes correct interpretation
by calling application fragile or impossible./Fix leak in c_test/Fix c_test/Add support for C bindings to the compaction V2 filter mechanism.
Test Plan: make c_test && ./c_test
Some fixes after merge./Fix valgrind error in c_test
Summary:
External contribution caused some valgrind errors: https://github.com/facebook/rocksdb/commit/1a34aaaef0900785c2de7e55b55d8c48d1201300
This diff fixes them
Test Plan: ran valgrind
Reviewers: sdong, yhchiang, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D19485/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/Fix SIGSEGV in db_stresS/Fix -Wshadow for tools
Summary: Previously I made `make check` work with -Wshadow, but there are some tools that are not compiled using `make check`.
Test Plan: make all
Reviewers: yhchiang, rven, ljin, sdong
Reviewed By: ljin, sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28497/db_stress for dynamic options
Summary: Allow SetOptions() during db_stress test
Test Plan: make crash_test
Reviewers: sdong, yhchiang, rven, igor
Reviewed By: igor
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D25497/"
rocksdb,"Remove assert in vector rep
Summary: This assert makes Insert O(n^2) instead of O(n) in debug mode. Memtable insert is in the critical path. No need to assert uniqunnes of the key here, since we're adding a sequence number to it anyway.
Test Plan: none
Reviewers: sdong, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22443/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/dummy var to suppress compiler warning/error
Summary: Revmoed this in D25641, causing compiler complain. put it back
Test Plan: make release
Reviewers: igor, yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D27891/fixed conflict in java/Makefile/Fix timing/limit max bytes that can be read/written per pread/write syscall
Summary:
BlockBasedTable sst file size can grow to a large size when universal
compaction is used. When index block exceeds 2G, pread seems to fail and
return truncated data and causes ""trucated block"" error. I tried to use
```
#define _FILE_OFFSET_BITS 64
```
But the problem still persists. Splitting a big write/read into smaller
batches seems to solve the problem.
Test Plan:
successfully compacted a case with resulting sst file at ~90G (2.1G
index block size)
Reviewers: yhchiang, igor, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22569/Fix assertion in PosixRandomAccessFile
Summary:
See https://github.com/facebook/rocksdb/issues/244#issuecomment-53372297
Also see this: https://github.com/facebook/rocksdb/blob/master/util/env_posix.cc#L1075
Test Plan: compiles
Reviewers: yhchiang, ljin, sdong
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22419/Merge pull request #234 from bbiao/master
fix compile error under Mac OS X/fix compile error under Mac OS X/"
rocksdb,"Merge pull request #336 from fyrz/32BitRocksJavaBug
32 Bit RocksJava Fix for overflowing jlongs/32-Bit RocksJava resolution for jlong overflows
Summary:
This pull request solves the jlong overflow problem on 32-Bit machines as described in https://github.com/facebook/rocksdb/issues/278:
1. There is a new org.rocksdb.test.PlatformRandomHelper to assist in getting random values. For 32 Bit the getLong method is overriden by xpromaches code above. For 64 Bit it behaves as is.
2. The detection should be cross-platform (Windows is supported though it is not ported completely yet).
3. Every JNI method which sets jlong values must check if the value fits into size_t. If it overflows size_t a InvalidArgument Status object will be returned. If its ok a OK Status will be returned.
4. Setters which have this check will throw a RocksDBException if its no OK Status.
Additionally some other parts of code were corrected using the wrong type casts.
Test Plan:
make rocksdbjava
make jtest
Differential Revision: https://reviews.facebook.net/D24531/[Java] Fix compile error on DbBenchmark.java
Summary:
Fix compile error on DbBenchmark.java
Test Plan:
make rocksdbjava
make jdb_bench/[Java] Include WriteBatch into RocksDBSample.java, fix how DbBenchmark.java handles WriteBatch.
Summary:
Include WriteBatch into RocksDBSample.java, fix how DbBenchmark.java handles WriteBatch.
Previously DbBenchmark.java does not use WriteBatch when benchmarks is set to fillbatch.
Test Plan:
make rocksdbjava -j32
make jtest
make jdb_bench
cd java
./jdb_bench.sh --benchmarks=fillbatch
Reviewers: naveenatceg, ljin, sdong, ankgup87
Reviewed By: ankgup87
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22983/"
rocksdb,fixed conflict in java/Makefile/
rocksdb,"[RocksJava] JavaDoc cleanup warnings with Java8
Java8 is more restrictive than Java7 with generating
JavaDocs. This commit resolves current existing Java8
warnings./Merge pull request #386 from EugenePig/java8
suppress JDK8 errors for #385/suppress JDK8 errors for #385/[RocksJava] - Hardening RocksIterator
RocksIterator will sometimes Sigsegv on dispose. Mainly thats related
to dispose order. If the related RocksDB instance is freed beforehand
RocksIterator.dispose() will fail.
Within this commit there is a major change to RocksIterator. RocksIterator
will hold a private reference to the RocksDB instance which created the
RocksIterator. So even if RocksDB is freed in the same GC cycle the
RocksIterator instances will be freed prior to related RocksDB instances.
Another aspect targets the dispose logic if the RocksDB is freed previously
and already gc`ed. On dispose of a RocksIterator the dispose logic will check
if the RocksDB instance points to an initialized DB. If not the dispose logic
will not perform any further action.
The crash can be reproduced by using the related test provided within this
commit.
Related information: This relates to @adamretter`s facebook rocksdb-dev group
post about SigSegv on RocksIterator.dispose()./"
rocksdb,"Merge pull request #386 from EugenePig/java8
suppress JDK8 errors for #385/suppress JDK8 errors for #385/"
rocksdb,"[RocksJava] JavaDoc cleanup warnings with Java8
Java8 is more restrictive than Java7 with generating
JavaDocs. This commit resolves current existing Java8
warnings./Merge pull request #386 from EugenePig/java8
suppress JDK8 errors for #385/suppress JDK8 errors for #385/Merge with ColumnFamilies & Hardening CFHandle
Summary:
ColumnFamilyHandles face the same problem as RocksIterator previously
so used methods were also applied for ColumnFamilyHandles.
Another problem with CF was that Options passed to CFs were
always filled with default values. To enable Merge, all parts
of the database must share the same merge functionality which
is not possible using default values. So from now on every
CF will inherit from db options.
Changes to RocksDB:
- merge can now take also a cfhandle
Changes to MergeTest:
- Corrected formatting
- Included also GC tests
- Extended tests to cover CF related parts
- Corrected paths to cleanup properly within the test process
- Reduced verbosity of the test
Test Plan:
make rocksdbjava
make jtest
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D27999/[RocksJava] - Hardening RocksIterator
RocksIterator will sometimes Sigsegv on dispose. Mainly thats related
to dispose order. If the related RocksDB instance is freed beforehand
RocksIterator.dispose() will fail.
Within this commit there is a major change to RocksIterator. RocksIterator
will hold a private reference to the RocksDB instance which created the
RocksIterator. So even if RocksDB is freed in the same GC cycle the
RocksIterator instances will be freed prior to related RocksDB instances.
Another aspect targets the dispose logic if the RocksDB is freed previously
and already gc`ed. On dispose of a RocksIterator the dispose logic will check
if the RocksDB instance points to an initialized DB. If not the dispose logic
will not perform any further action.
The crash can be reproduced by using the related test provided within this
commit.
Related information: This relates to @adamretter`s facebook rocksdb-dev group
post about SigSegv on RocksIterator.dispose()./Merge pull request #334 from fyrz/JavaDoc-Cleanup
JavaDoc fixes & enhancements RocksJava/Merge pull request #331 from fyrz/findbug_issues
Fixed Findbugs issues in RocksJava/Fixed Findbugs issues
- BackupableDB missing call to super.finalize(major)
- WriteBatchTest inefficient String usage(minor)
- RocksDB local dead variable store(medium)/"
rocksdb,"Merge pull request #334 from fyrz/JavaDoc-Cleanup
JavaDoc fixes & enhancements RocksJava/"
rocksdb,"Merge pull request #334 from fyrz/JavaDoc-Cleanup
JavaDoc fixes & enhancements RocksJava/"
rocksdb,"Merge pull request #331 from fyrz/findbug_issues
Fixed Findbugs issues in RocksJava/Fixed Findbugs issues
- BackupableDB missing call to super.finalize(major)
- WriteBatchTest inefficient String usage(minor)
- RocksDB local dead variable store(medium)/"
rocksdb,"[RocksJava] JavaDoc cleanup warnings with Java8
Java8 is more restrictive than Java7 with generating
JavaDocs. This commit resolves current existing Java8
warnings./Merge pull request #386 from EugenePig/java8
suppress JDK8 errors for #385/suppress JDK8 errors for #385/"
rocksdb,"Merge pull request #334 from fyrz/JavaDoc-Cleanup
JavaDoc fixes & enhancements RocksJava/"
rocksdb,"fixed conflict in java/Makefile/Merge pull request #336 from fyrz/32BitRocksJavaBug
32 Bit RocksJava Fix for overflowing jlongs/32-Bit RocksJava resolution for jlong overflows
Summary:
This pull request solves the jlong overflow problem on 32-Bit machines as described in https://github.com/facebook/rocksdb/issues/278:
1. There is a new org.rocksdb.test.PlatformRandomHelper to assist in getting random values. For 32 Bit the getLong method is overriden by xpromaches code above. For 64 Bit it behaves as is.
2. The detection should be cross-platform (Windows is supported though it is not ported completely yet).
3. Every JNI method which sets jlong values must check if the value fits into size_t. If it overflows size_t a InvalidArgument Status object will be returned. If its ok a OK Status will be returned.
4. Setters which have this check will throw a RocksDBException if its no OK Status.
Additionally some other parts of code were corrected using the wrong type casts.
Test Plan:
make rocksdbjava
make jtest
Differential Revision: https://reviews.facebook.net/D24531/"
rocksdb,"[RocksJava] JavaDoc cleanup warnings with Java8
Java8 is more restrictive than Java7 with generating
JavaDocs. This commit resolves current existing Java8
warnings./fixed conflict in java/Makefile/Merge pull request #336 from fyrz/32BitRocksJavaBug
32 Bit RocksJava Fix for overflowing jlongs/32-Bit RocksJava resolution for jlong overflows
Summary:
This pull request solves the jlong overflow problem on 32-Bit machines as described in https://github.com/facebook/rocksdb/issues/278:
1. There is a new org.rocksdb.test.PlatformRandomHelper to assist in getting random values. For 32 Bit the getLong method is overriden by xpromaches code above. For 64 Bit it behaves as is.
2. The detection should be cross-platform (Windows is supported though it is not ported completely yet).
3. Every JNI method which sets jlong values must check if the value fits into size_t. If it overflows size_t a InvalidArgument Status object will be returned. If its ok a OK Status will be returned.
4. Setters which have this check will throw a RocksDBException if its no OK Status.
Additionally some other parts of code were corrected using the wrong type casts.
Test Plan:
make rocksdbjava
make jtest
Differential Revision: https://reviews.facebook.net/D24531/Merge pull request #334 from fyrz/JavaDoc-Cleanup
JavaDoc fixes & enhancements RocksJava/[Java] Fix JNI link error caused by the removal of options.db_stats_log_interval
Summary: Fix JNI link error caused by the removal of options.db_stats_log_interval in https://reviews.facebook.net/D21915.
Test Plan:
make rocksdbjava
make jtest
Reviewers: ljin, ankgup87
Reviewed By: ankgup87
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D23505/"
rocksdb,"Merge pull request #386 from EugenePig/java8
suppress JDK8 errors for #385/suppress JDK8 errors for #385/"
rocksdb,"[RocksJava] JavaDoc cleanup warnings with Java8
Java8 is more restrictive than Java7 with generating
JavaDocs. This commit resolves current existing Java8
warnings./[RocksJava] - BackupInfos & Restore-/BackupableDB enhancements
Summary:
- BackupableDB deleteBackup method
- BackupableDB purgeOldBackups bugfix
- BackupInfos now available in Restorable-/BackupableDB
- Extended BackupableDBTest to cover more of the currently implemented functionality.
Test Plan:
make rocksdbjava
make jtest
Differential Revision: https://reviews.facebook.net/D27027/Merge pull request #334 from fyrz/JavaDoc-Cleanup
JavaDoc fixes & enhancements RocksJava/Merge pull request #331 from fyrz/findbug_issues
Fixed Findbugs issues in RocksJava/Fixed Findbugs issues
- BackupableDB missing call to super.finalize(major)
- WriteBatchTest inefficient String usage(minor)
- RocksDB local dead variable store(medium)/"
rocksdb,"[RocksJava] JavaDoc cleanup warnings with Java8
Java8 is more restrictive than Java7 with generating
JavaDocs. This commit resolves current existing Java8
warnings./fixed conflict in java/Makefile/Merge pull request #336 from fyrz/32BitRocksJavaBug
32 Bit RocksJava Fix for overflowing jlongs/32-Bit RocksJava resolution for jlong overflows
Summary:
This pull request solves the jlong overflow problem on 32-Bit machines as described in https://github.com/facebook/rocksdb/issues/278:
1. There is a new org.rocksdb.test.PlatformRandomHelper to assist in getting random values. For 32 Bit the getLong method is overriden by xpromaches code above. For 64 Bit it behaves as is.
2. The detection should be cross-platform (Windows is supported though it is not ported completely yet).
3. Every JNI method which sets jlong values must check if the value fits into size_t. If it overflows size_t a InvalidArgument Status object will be returned. If its ok a OK Status will be returned.
4. Setters which have this check will throw a RocksDBException if its no OK Status.
Additionally some other parts of code were corrected using the wrong type casts.
Test Plan:
make rocksdbjava
make jtest
Differential Revision: https://reviews.facebook.net/D24531/"
rocksdb,fixed conflict in java/Makefile/
rocksdb,"[RocksJava] JavaDoc cleanup warnings with Java8
Java8 is more restrictive than Java7 with generating
JavaDocs. This commit resolves current existing Java8
warnings./"
rocksdb,"[RocksJava] - BackupInfos & Restore-/BackupableDB enhancements
Summary:
- BackupableDB deleteBackup method
- BackupableDB purgeOldBackups bugfix
- BackupInfos now available in Restorable-/BackupableDB
- Extended BackupableDBTest to cover more of the currently implemented functionality.
Test Plan:
make rocksdbjava
make jtest
Differential Revision: https://reviews.facebook.net/D27027/fixed conflict in java/Makefile/Fix code style problems identified by lint/Merge pull request #336 from fyrz/32BitRocksJavaBug
32 Bit RocksJava Fix for overflowing jlongs/32-Bit RocksJava resolution for jlong overflows
Summary:
This pull request solves the jlong overflow problem on 32-Bit machines as described in https://github.com/facebook/rocksdb/issues/278:
1. There is a new org.rocksdb.test.PlatformRandomHelper to assist in getting random values. For 32 Bit the getLong method is overriden by xpromaches code above. For 64 Bit it behaves as is.
2. The detection should be cross-platform (Windows is supported though it is not ported completely yet).
3. Every JNI method which sets jlong values must check if the value fits into size_t. If it overflows size_t a InvalidArgument Status object will be returned. If its ok a OK Status will be returned.
4. Setters which have this check will throw a RocksDBException if its no OK Status.
Additionally some other parts of code were corrected using the wrong type casts.
Test Plan:
make rocksdbjava
make jtest
Differential Revision: https://reviews.facebook.net/D24531/[Java] Fixed 32-bit overflowing issue when converting jlong to size_t
Summary:
Fixed 32-bit overflowing issue when converting jlong to size_t by
capping jlong to std::numeric_limits<size_t>::max().
Test Plan:
make rocksdbjava
make jtest
Reviewers: ankgup87, ljin, sdong, igor
Reviewed By: igor
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D23511/"
rocksdb,"[RocksJava] - BackupInfos & Restore-/BackupableDB enhancements
Summary:
- BackupableDB deleteBackup method
- BackupableDB purgeOldBackups bugfix
- BackupInfos now available in Restorable-/BackupableDB
- Extended BackupableDBTest to cover more of the currently implemented functionality.
Test Plan:
make rocksdbjava
make jtest
Differential Revision: https://reviews.facebook.net/D27027/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/[RocksJava] -WShadow improvements
Minor corrections to resolve -WShadow build problems with RocksJava code./Merge with ColumnFamilies & Hardening CFHandle
Summary:
ColumnFamilyHandles face the same problem as RocksIterator previously
so used methods were also applied for ColumnFamilyHandles.
Another problem with CF was that Options passed to CFs were
always filled with default values. To enable Merge, all parts
of the database must share the same merge functionality which
is not possible using default values. So from now on every
CF will inherit from db options.
Changes to RocksDB:
- merge can now take also a cfhandle
Changes to MergeTest:
- Corrected formatting
- Included also GC tests
- Extended tests to cover CF related parts
- Corrected paths to cleanup properly within the test process
- Reduced verbosity of the test
Test Plan:
make rocksdbjava
make jtest
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D27999/Merge pull request #336 from fyrz/32BitRocksJavaBug
32 Bit RocksJava Fix for overflowing jlongs/32-Bit RocksJava resolution for jlong overflows
Summary:
This pull request solves the jlong overflow problem on 32-Bit machines as described in https://github.com/facebook/rocksdb/issues/278:
1. There is a new org.rocksdb.test.PlatformRandomHelper to assist in getting random values. For 32 Bit the getLong method is overriden by xpromaches code above. For 64 Bit it behaves as is.
2. The detection should be cross-platform (Windows is supported though it is not ported completely yet).
3. Every JNI method which sets jlong values must check if the value fits into size_t. If it overflows size_t a InvalidArgument Status object will be returned. If its ok a OK Status will be returned.
4. Setters which have this check will throw a RocksDBException if its no OK Status.
Additionally some other parts of code were corrected using the wrong type casts.
Test Plan:
make rocksdbjava
make jtest
Differential Revision: https://reviews.facebook.net/D24531/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/Merge pull request #327 from dalgaaf/wip-da-SCA-20141001
Fix some issues from SCA/Merge pull request #324 from dalgaaf/wip-da-SCA-20140930
Various SCA fixes/ttl/ttl_test.cc: prefer prefix ++operator for non-primitive types
Signed-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>/"
rocksdb,"Merge pull request #327 from dalgaaf/wip-da-SCA-20141001
Fix some issues from SCA/"
rocksdb,"Merge pull request #340 from nbougalis/nullderef
Avoid dereferencing a null field/Avoid dereferencing a null field/Merge pull request #327 from dalgaaf/wip-da-SCA-20141001
Fix some issues from SCA/Merge pull request #324 from dalgaaf/wip-da-SCA-20140930
Various SCA fixes/document_db.cc: fix assert
Check for lhs and not twice for rhs.
Fix for:
[utilities/document/document_db.cc:36] ->
[utilities/document/document_db.cc:36]: (style) Same expression on both
sides of '&&'.
Signed-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>/Plug memory leak during index creation/"
rocksdb,"Fix -Wshadow for tools
Summary: Previously I made `make check` work with -Wshadow, but there are some tools that are not compiled using `make check`.
Test Plan: make all
Reviewers: yhchiang, rven, ljin, sdong
Reviewed By: ljin, sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28497/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/fix cuckoo table builder test
Summary:
as title
Test Plan:
./cuckoo_table_builder_test
Reviewers:igor
CC:leveldb
Task ID: #
Blame Rev:/Fix compaction bug in Cuckoo Table Builder. Use kvs_.size() instead of num_entries in FileSize() method.
Summary: Fix compaction bug in Cuckoo Table Builder. Use kvs_.size() instead of num_entries in FileSize() method. Also added tests.
Test Plan:
make check all
Also ran db_bench to generate multiple files.
Reviewers: sdong, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22743/"
rocksdb,"Turn on -Wshadow
Summary:
...and fix all the errors :)
Jim suggested turning on -Wshadow because it helped him fix number of critical bugs in fbcode. I think it's a good idea to be -Wshadow clean.
Test Plan: compiles
Reviewers: yhchiang, rven, sdong, ljin
Reviewed By: ljin
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D27711/fixed conflict in java/Makefile/Avoid reloading filter on Get() if cache_index_and_filter_blocks == false
Summary:
This fixes the case that filter policy is missing in SST file, but we
open the table with filter policy on and cache_index_and_filter_blocks =
false. The current behavior is that we will try to load it every time on
Get() but fail.
Test Plan: unit test
Reviewers: yhchiang, igor, rven, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D25455/Replace naked calls to operator new and delete (Fixes #222)
This replaces a mishmash of pointers in the Block and BlockContents classes with
std::unique_ptr. It also changes the semantics of BlockContents to be limited to
use as a constructor parameter for Block objects, as it owns any block buffers
handed to it./"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/Replace naked calls to operator new and delete (Fixes #222)
This replaces a mishmash of pointers in the Block and BlockContents classes with
std::unique_ptr. It also changes the semantics of BlockContents to be limited to
use as a constructor parameter for Block objects, as it owns any block buffers
handed to it./Fix compile
Summary: gcc on our dev boxes is not happy about __attribute__((unused))
Test Plan: compiles now
Reviewers: sdong, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22707/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/Turn -Wshadow back on
Summary: It turns out that -Wshadow has different rules for gcc than clang. Previous commit fixed clang. This commits fixes the rest of the warnings for gcc.
Test Plan: compiles
Reviewers: ljin, yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28131/Merge pull request #327 from dalgaaf/wip-da-SCA-20141001
Fix some issues from SCA/Replace naked calls to operator new and delete (Fixes #222)
This replaces a mishmash of pointers in the Block and BlockContents classes with
std::unique_ptr. It also changes the semantics of BlockContents to be limited to
use as a constructor parameter for Block objects, as it owns any block buffers
handed to it./[unit test] CompactRange should fail if we don't have space
Summary:
See t5106397.
Also, few more changes:
1. in unit tests, the assumption is that writes will be dropped when there is no space left on device. I changed the wording around it.
2. InvalidArgument() errors are only when user-provided arguments are invalid. When the file is corrupted, we need to return Status::Corruption
Test Plan: make check
Reviewers: sdong, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D23145/Merge pull request #242 from tdfischer/perf-timer-destructors
Refactor PerfStepTimer to automatically stop on destruct/Refactor PerfStepTimer to stop on destruct
This eliminates the need to remember to call PERF_TIMER_STOP when a section has
been timed. This allows more useful design with the perf timers and enables
possible return value optimizations. Simplistic example:
class Foo {
public:
Foo(int v) : m_v(v);
private:
int m_v;
}
Foo makeFrobbedFoo(int *errno)
{
*errno = 0;
return Foo();
}
Foo bar(int *errno)
{
PERF_TIMER_GUARD(some_timer);
return makeFrobbedFoo(errno);
}
int main(int argc, char[] argv)
{
Foo f;
int errno;
f = bar(&errno);
if (errno)
return -1;
return 0;
}
After bar() is called, perf_context.some_timer would be incremented as if
Stop(&perf_context.some_timer) was called at the end, and the compiler is still
able to produce optimizations on the return value from makeFrobbedFoo() through
to main()./"
rocksdb,"Merge pull request #324 from dalgaaf/wip-da-SCA-20140930
Various SCA fixes/in_table_factory.cc: use correct format specifier
Use %zu instead of %zd since size_t and uint32_t are unsigned.
Fix for:
[table/plain_table_factory.cc:55]: (warning) %zd in format string (no. 1)
requires 'ssize_t' but the argument type is 'size_t {aka unsigned long}'.
[table/plain_table_factory.cc:58]: (warning) %zd in format string (no. 1)
requires 'ssize_t' but the argument type is 'size_t {aka unsigned long}'.
Signed-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/Turn -Wshadow back on
Summary: It turns out that -Wshadow has different rules for gcc than clang. Previous commit fixed clang. This commits fixes the rest of the warnings for gcc.
Test Plan: compiles
Reviewers: ljin, yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28131/Turn on -Wshadow
Summary:
...and fix all the errors :)
Jim suggested turning on -Wshadow because it helped him fix number of critical bugs in fbcode. I think it's a good idea to be -Wshadow clean.
Test Plan: compiles
Reviewers: yhchiang, rven, sdong, ljin
Reviewed By: ljin
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D27711/fixed conflict in java/Makefile/fix table_test
Summary:
SaveValue expects an internal key but I previously added to table a
user key
Test Plan:
ran the test/Avoid reloading filter on Get() if cache_index_and_filter_blocks == false
Summary:
This fixes the case that filter policy is missing in SST file, but we
open the table with filter policy on and cache_index_and_filter_blocks =
false. The current behavior is that we will try to load it every time on
Get() but fail.
Test Plan: unit test
Reviewers: yhchiang, igor, rven, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D25455/Merge pull request #324 from dalgaaf/wip-da-SCA-20140930
Various SCA fixes/table/table_test.cc: pass func parameter by reference
Fix for:
[table/table_test.cc:1218]: (performance) Function parameter
'prefix' should be passed by reference.
Signed-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>/Replace naked calls to operator new and delete (Fixes #222)
This replaces a mishmash of pointers in the Block and BlockContents classes with
std::unique_ptr. It also changes the semantics of BlockContents to be limited to
use as a constructor parameter for Block objects, as it owns any block buffers
handed to it./Fix compile
Summary: gcc on our dev boxes is not happy about __attribute__((unused))
Test Plan: compiles now
Reviewers: sdong, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22707/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/Turn -Wshadow back on
Summary: It turns out that -Wshadow has different rules for gcc than clang. Previous commit fixed clang. This commits fixes the rest of the warnings for gcc.
Test Plan: compiles
Reviewers: ljin, yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28131/Turn on -Wshadow
Summary:
...and fix all the errors :)
Jim suggested turning on -Wshadow because it helped him fix number of critical bugs in fbcode. I think it's a good idea to be -Wshadow clean.
Test Plan: compiles
Reviewers: yhchiang, rven, sdong, ljin
Reviewed By: ljin
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D27711/Merge pull request #304 from Liuchang0812/fix-check
fixed #303: replace %ld with % PRId64/fixed #303: replace %ld with % PRId64/Merge pull request #272 from project-zerus/patch-1
fix more compile warnings/fix more compile warnings
N/A
Change-Id: I5b6f9c70aea7d3f3489328834fed323d41106d9f
Signed-off-by: liuhuahang <liuhuahang@zerus.co>/Merge pull request #240 from ShaoYuZhang/master
Fix compilation issue on OSX/Fix compilation issue on OSX/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/Fix NewFileNumber()
Summary: I mistakenly changed the behavior to ++next_file_number_ instead of next_file_number_++, as it should have been: https://github.com/facebook/rocksdb/blob/344edbb044ff5c08a43e4a6e9344c5c861552c0e/db/version_set.h#L539
Test Plan: none. not sure if this would break anything. It's just different behavior, so I'd rather not risk
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28557/Fixed compile error in db/db_impl.cc
Summary:
Fixed compile error in db/db_impl.cc
Test Plan:
make/fix the asan check
Summary: as title
Test Plan: ran it
Reviewers: yhchiang, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28311/Turn on -Wshadow
Summary:
...and fix all the errors :)
Jim suggested turning on -Wshadow because it helped him fix number of critical bugs in fbcode. I think it's a good idea to be -Wshadow clean.
Test Plan: compiles
Reviewers: yhchiang, rven, sdong, ljin
Reviewed By: ljin
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D27711/Fix the bug where compaction does not fail when RocksDB can't create a new file.
Summary:
This diff has two fixes.
1. Fix the bug where compaction does not fail when RocksDB can't create a new file.
2. When NewWritableFiles() fails in OpenCompactionOutputFiles(), previously such fail-to-created file will be still be included as a compaction output.  This patch also fixes this bug.
3. Allow VersionEdit::EncodeTo() to return Status and add basic check.
Test Plan:
./version_edit_test
export ROCKSDB_TESTS=FileCreationRandomFailure
./db_test
Reviewers: ljin, sdong, nkg-, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D25581/fixed conflict in java/Makefile/Fix DeleteFile() + enable deleting files oldest files in level 0
Summary:
DeleteFile() call was broken for non-default column family. This fixes it. We might need this feature for mongo.
I also introduced a possibility of deleting oldest file in level 0.
Test Plan: added unit test to deletefile_test
Reviewers: ljin, yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D24909/Sanitize block-based table index type and check prefix_extractor
Summary:
Respond to issue reported
https://www.facebook.com/groups/rocksdb.dev/permalink/651090261656158/
Change the Sanitize signature to take both DBOptions and CFOptions
Test Plan: unit test
Reviewers: sdong, yhchiang, igor
Reviewed By: igor
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D25041/Stop stopping writes on bg_error_
Summary: This might have caused https://github.com/facebook/rocksdb/issues/345. If we're stopping writes and bg_error comes along, we will never unblock the write.
Test Plan: compiles
Reviewers: ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D24807/Fix a check in database shutdown or Column family drop during flush.
Summary:
Fix a check in database shutdown or Column family drop during flush.
Special thanks to Maurice Barnum who spots the problem :)
Test Plan: db_test
Reviewers: ljin, igor, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D24273/perf_context.get_from_output_files_time is set for MultiGet() and ReadOnly DB too.
Summary: perf_context.get_from_output_files_time is now only set writable DB's DB::Get(). Extend it to MultiGet() and read only DB.
Test Plan:
make all check
Fix perf_context_test and extend it to cover MultiGet(), as long as read-only DB. Run it and watch the results
Reviewers: ljin, yhchiang, igor
Reviewed By: igor
Subscribers: rven, leveldb
Differential Revision: https://reviews.facebook.net/D24207/Merge pull request #324 from dalgaaf/wip-da-SCA-20140930
Various SCA fixes/db/db_impl.cc: fix object handling, remove double lines
Fix for:
[db/db_impl.cc:4039]: (error) Instance of 'StopWatch' object is
destroyed immediately.
[db/db_impl.cc:4042]: (error) Instance of 'StopWatch' object is
destroyed immediately.
Signed-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>/Print MB per second compaction throughput separately for reads and writes
Summary:
From this line there used to be one column (MB/sec) that includes reads and writes. This change splits it and for real workloads the rd and wr rates might not match when keys are dropped.
2014/09/29-17:31:01.213162 7f929fbff700 (Original Log Time 2014/09/29-17:31:01.180025) [default] compacted to: files[2 5 0 0 0 0 0], MB/sec: 14.0 rd, 14.0 wr, level 1, files in(4, 0) out(5) MB in(8.5, 0.0) out(8.5), read-write-amplify(2.0) write-amplify(1.0) OK
Test Plan:
make check, grepped LOG
- begin *PUBLIC* platform impact section -
Bugzilla: #
- end platform impact -
Reviewers: igor
Differential Revision: https://reviews.facebook.net/D24237/Fix double deletes
Summary: While debugging clients compaction issues, I noticed bunch of delete bugs: P16329995. MakeTableName returns sst file with ""/"" prefix. We also need ""/"" prefix when we get the files though GetChildren(), so that we can properly dedup the files.
Test Plan: none
Reviewers: sdong, yhchiang, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D23457/Fix syncronization issues/Fix WAL synced
Summary: Uhm...
Test Plan: nope
Reviewers: sdong, yhchiang, tnovak, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D23343/Don't run background jobs (flush, compactions) when bg_error_ is set
Summary:
If bg_error_ is set, that means that we mark DB read only. However, current behavior still continues the flushes and compactions, even though bg_error_ is set.
On the other hand, if bg_error_ is set, we will return Status::OK() from CompactRange(), although the compaction didn't actually succeed.
This is clearly not desired behavior. I found this when I was debugging t5132159, although I'm pretty sure these aren't related.
Also, when we're shutting down, it's dangerous to exit RunManualCompaction(), since that will destruct ManualCompaction object. Background compaction job might still hold a reference to manual_compaction_ and this will lead to undefined behavior. I changed the behavior so that we only exit RunManualCompaction when manual compaction job is marked done.
Test Plan: make check
Reviewers: sdong, ljin, yhchiang
Reviewed By: yhchiang
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D23223/Improve db recovery
Summary: Avoid creating unnecessary sst files while db opening
Test Plan: make all check
Reviewers: sdong, igor
Reviewed By: igor
Subscribers: zagfox, yhchiang, ljin, leveldb
Differential Revision: https://reviews.facebook.net/D20661/DB::Flush() Do not wait for background threads when there is nothing in mem table
Summary:
When we have multiple column families, users can issue Flush() on every column families to make sure everything is flushes, even if some of them might be empty. By skipping the waiting for empty cases, it can be greatly speed up.
Still wait for people's comments before writing unit tests for it.
Test Plan: Will write a unit test to make sure it is correct.
Reviewers: ljin, yhchiang, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D22953/Push- instead of pull-model for managing Write stalls
Summary:
Introducing WriteController, which is a source of truth about per-DB write delays. Let's define an DB epoch as a period where there are no flushes and compactions (i.e. new epoch is started when flush or compaction finishes). Each epoch can either:
* proceed with all writes without delay
* delay all writes by fixed time
* stop all writes
The three modes are recomputed at each epoch change (flush, compaction), rather than on every write (which is currently the case).
When we have a lot of column families, our current pull behavior adds a big overhead, since we need to loop over every column family for every write. With new push model, overhead on Write code-path is minimal.
This is just the start. Next step is to also take care of stalls introduced by slow memtable flushes. The final goal is to eliminate function MakeRoomForWrite(), which currently needs to be called for every column family by every write.
Test Plan: make check for now. I'll add some unit tests later. Also, perf test.
Reviewers: dhruba, yhchiang, MarkCallaghan, sdong, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22791/rename options_ to db_options_ in DBImpl to avoid confusion
Summary: as title
Test Plan: make release
Reviewers: sdong, igor
Reviewed By: igor
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22935/Merge pull request #272 from project-zerus/patch-1
fix more compile warnings/fix more compile warnings
N/A
Change-Id: I5b6f9c70aea7d3f3489328834fed323d41106d9f
Signed-off-by: liuhuahang <liuhuahang@zerus.co>/Ignore missing column families
Summary:
Before this diff, whenever we Write to non-existing column family, Write() would fail.
This diff adds an option to not fail a Write() when WriteBatch points to non-existing column family. MongoDB said this would be useful for them, since they might have a transaction updating an index that was dropped by another thread. This way, they don't have to worry about checking if all indexes are alive on every write. They don't care if they lose writes to dropped index.
Test Plan: added a small unit test
Reviewers: sdong, yhchiang, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22143/Merge pull request #242 from tdfischer/perf-timer-destructors
Refactor PerfStepTimer to automatically stop on destruct/fix dropping column family bug
Summary: 1. db/db_impl.cc:2324 (DBImpl::BackgroundCompaction) should not raise bg_error_ when column family is dropped during compaction.
Test Plan: 1. db_stress
Reviewers: ljin, yhchiang, dhruba, igor, sdong
Reviewed By: igor
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22653/Refactor PerfStepTimer to stop on destruct
This eliminates the need to remember to call PERF_TIMER_STOP when a section has
been timed. This allows more useful design with the perf timers and enables
possible return value optimizations. Simplistic example:
class Foo {
public:
Foo(int v) : m_v(v);
private:
int m_v;
}
Foo makeFrobbedFoo(int *errno)
{
*errno = 0;
return Foo();
}
Foo bar(int *errno)
{
PERF_TIMER_GUARD(some_timer);
return makeFrobbedFoo(errno);
}
int main(int argc, char[] argv)
{
Foo f;
int errno;
f = bar(&errno);
if (errno)
return -1;
return 0;
}
After bar() is called, perf_context.some_timer would be incremented as if
Stop(&perf_context.some_timer) was called at the end, and the compiler is still
able to produce optimizations on the return value from makeFrobbedFoo() through
to main()./Merge pull request #251 from nbougalis/master
Fix candidate file comparison when using path ids/Fix candidate file comparison when using path ids/Don't let other compactions run when manual compaction runs
Summary:
Based on discussions from t4982833. This is just a short-term fix, I plan to revamp manual compaction process as part of t4982812.
Also, I think we should schedule automatic compactions at the very end of manual compactions, not when we're done with one level. I made that change as part of this diff. Let me know if you disagree.
Test Plan: make check for now
Reviewers: sdong, tnovak, yhchiang, ljin
Reviewed By: yhchiang
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22401/Fix ios compile
Summary: No __thread for ios.
Test Plan: compile works for ios now
Reviewers: ljin, dhruba
Reviewed By: dhruba
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22491/Improve Options sanitization and add MmapReadRequired() to TableFactory
Summary:
Currently, PlainTable must use mmap_reads.  When PlainTable is used but
allow_mmap_reads is not set, rocksdb will fail in flush.
This diff improve Options sanitization and add MmapReadRequired() to
TableFactory.
Test Plan:
export ROCKSDB_TESTS=PlainTableOptionsSanitizeTest
make db_test -j32
./db_test
Reviewers: sdong, ljin
Reviewed By: ljin
Subscribers: you, leveldb
Differential Revision: https://reviews.facebook.net/D21939/Merge pull request #230 from cockroachdb/spencerkimball/send-user-keys-to-v2-filter
Pass parsed user key to prefix extractor in V2 compaction/Support purging logs from separate log directory
Summary:
1. Support purging info logs from a separate paths from DB path. Refactor the codes of generating info log prefixes so that it can be called when generating new files and scanning log directory.
2. Fix the bug of not scanning multiple DB paths (should only impact multiple DB paths)
Test Plan:
Add unit test for generating and parsing info log files
Add end-to-end test in db_test
Reviewers: yhchiang, ljin
Reviewed By: ljin
Subscribers: leveldb, igor, dhruba
Differential Revision: https://reviews.facebook.net/D21801/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/improve OptimizeForPointLookup()
Summary: also fix HISTORY.md
Test Plan: make all check
Reviewers: sdong, yhchiang, igor
Reviewed By: igor
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22437/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/Fixed compile error in db/compaction.cc and db/compaction_picker.cc
Summary:
Fixed compile error in db/compaction.cc and db/compaction_picker.cc
Test Plan:
make/Turn on -Wshadow
Summary:
...and fix all the errors :)
Jim suggested turning on -Wshadow because it helped him fix number of critical bugs in fbcode. I think it's a good idea to be -Wshadow clean.
Test Plan: compiles
Reviewers: yhchiang, rven, sdong, ljin
Reviewed By: ljin
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D27711/fixed conflict in java/Makefile/Improve the log in Universal Compaction to include more debug information.
Summary:
Previously, the log for Universal Compaction does not include the current
number of files in case the compaction is triggered by the number of files.
This diff includes the number of files in the log.
Test Plan:
make/Merge pull request #324 from dalgaaf/wip-da-SCA-20140930
Various SCA fixes/compaction_picker.cc: remove check for >=0 for unsigned
Fix for:
[db/compaction_picker.cc:923]: (style) Unsigned variable
'start_index' can't be negative so it is unnecessary to test it.
Signed-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>/universal compaction picker: use double for potential overflow
Summary: There is a possible overflow case in universal compaction picker. Use double to make the logic straight-forward
Test Plan: make all check
Reviewers: yhchiang, igor, MarkCallaghan, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D23817/Fix comments and typos
Summary: Correct some comments and typos in RocksDB.
Test Plan: Inspection
Reviewers: sdong, igor
Reviewed By: igor
Differential Revision: https://reviews.facebook.net/D23133/Merge pull request #272 from project-zerus/patch-1
fix more compile warnings/fix more compile warnings
N/A
Change-Id: I5b6f9c70aea7d3f3489328834fed323d41106d9f
Signed-off-by: liuhuahang <liuhuahang@zerus.co>/Fix concurrency issue in CompactionPicker
Summary:
I am currently working on a project that uses RocksDB. While debugging some perf issues, I came up across interesting compaction concurrency issue. Namely, I had 15 idle threads and a good comapction to do, but CompactionPicker returned ""Compaction nothing to do"". Here's how Internal stats looked:
2014/08/22-08:08:04.551982 7fc7fc3f5700 ------- DUMPING STATS -------
2014/08/22-08:08:04.552000 7fc7fc3f5700
** Compaction Stats [default] **
Level   Files   Size(MB) Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) RW-Amp W-Amp Rd(MB/s) Wr(MB/s)  Rn(cnt) Rnp1(cnt) Wnp1(cnt) Wnew(cnt)  Comp(sec) Comp(cnt) Avg(sec) Stall(sec) Stall(cnt) Avg(ms)
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
L0     7/5        353   1.0      0.0     0.0      0.0       2.3      2.3    0.0   0.0      0.0      9.4        0         0         0         0        247        46    5.359       8.53          1 8526.25
L1     2/2         86   1.3      2.6     1.9      0.7       2.6      1.9    2.7   1.3     24.3     24.0       39        19        71        52        109        11    9.938       0.00          0    0.00
L2    26/0        833   1.3      5.7     1.7      4.0       5.2      1.2    6.3   3.0     15.6     14.2       47       112       147        35        373        44    8.468       0.00          0    0.00
L3    12/0        505   0.1      0.0     0.0      0.0       0.0      0.0    0.0   0.0      0.0      0.0        0         0         0         0          0         0    0.000       0.00          0    0.00
Sum    47/7       1778   0.0      8.3     3.6      4.6      10.0      5.4    8.1   4.4     11.6     14.1       86       131       218        87        728       101    7.212       8.53          1 8526.25
Int     0/0          0   0.0      2.4     0.8      1.6       2.7      1.2   11.5   6.1     12.0     13.6       20        43        63        20        203        23    8.845       0.00          0    0.00
Flush(GB): accumulative 2.266, interval 0.444
Stalls(secs): 0.000 level0_slowdown, 0.000 level0_numfiles, 8.526 memtable_compaction, 0.000 leveln_slowdown_soft, 0.000 leveln_slowdown_hard
Stalls(count): 0 level0_slowdown, 0 level0_numfiles, 1 memtable_compaction, 0 leveln_slowdown_soft, 0 leveln_slowdown_hard
** DB Stats **
Uptime(secs): 336.8 total, 60.4 interval
Cumulative writes: 61584000 writes, 6480589 batches, 9.5 writes per batch, 1.39 GB user ingest
Cumulative WAL: 0 writes, 0 syncs, 0.00 writes per sync, 0.00 GB written
Interval writes: 11235257 writes, 1175050 batches, 9.6 writes per batch, 259.9 MB user ingest
Interval WAL: 0 writes, 0 syncs, 0.00 writes per sync, 0.00 MB written
To see what happened, go here: https://github.com/facebook/rocksdb/blob/47b452cfcf9b1487d41f886a98bc0d6f95587e90/db/compaction_picker.cc#L430
* The for loop started with level 1, because it has the worst score.
* PickCompactionBySize on L429 returned nullptr because all files were being compacted
* ExpandWhileOverlapping(c) returned true (because that's what it does when it gets nullptr!?)
* for loop break-ed, never trying compactions for level 2 :( :(
This bug was present at least since January. I have no idea how we didn't find this sooner.
Test Plan:
Unit testing compaction picker is hard. I tested this by running my service and observing L0->L1 and L2->L3 compactions in parallel. However, for long-term, I opened the task #4968469. @yhchiang is currently refactoring CompactionPicker, hopefully the new version will be unit-testable ;)
Here's how my compactions look like after the patch:
2014/08/22-08:50:02.166699 7f3400ffb700 ------- DUMPING STATS -------
2014/08/22-08:50:02.166722 7f3400ffb700
** Compaction Stats [default] **
Level   Files   Size(MB) Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) RW-Amp W-Amp Rd(MB/s) Wr(MB/s)  Rn(cnt) Rnp1(cnt) Wnp1(cnt) Wnew(cnt)  Comp(sec) Comp(cnt) Avg(sec) Stall(sec) Stall(cnt) Avg(ms)
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
L0     8/5        404   1.5      0.0     0.0      0.0       4.3      4.3    0.0   0.0      0.0      9.6        0         0         0         0        463        88    5.260       0.00          0    0.00
L1     2/2         60   0.9      4.8     3.9      0.8       4.7      3.9    2.4   1.2     23.9     23.6       80        23       131       108        204        19   10.747       0.00          0    0.00
L2    23/3        697   1.0     11.6     3.5      8.1      10.9      2.8    6.4   3.1     17.7     16.6       95       242       317        75        669        92    7.268       0.00          0    0.00
L3    58/14      2207   0.3      6.2     1.6      4.6       5.9      1.3    7.4   3.6     14.6     13.9       43       121       159        38        436        36   12.106       0.00          0    0.00
Sum    91/24      3368   0.0     22.5     9.1     13.5      25.8     12.4   11.2   6.0     13.0     14.9      218       386       607       221       1772       235    7.538       0.00          0    0.00
Int     0/0          0   0.0      3.2     0.9      2.3       3.6      1.3   15.3   8.0     12.4     13.7       24        66        89        23        266        27    9.838       0.00          0    0.00
Flush(GB): accumulative 4.336, interval 0.444
Stalls(secs): 0.000 level0_slowdown, 0.000 level0_numfiles, 0.000 memtable_compaction, 0.000 leveln_slowdown_soft, 0.000 leveln_slowdown_hard
Stalls(count): 0 level0_slowdown, 0 level0_numfiles, 0 memtable_compaction, 0 leveln_slowdown_soft, 0 leveln_slowdown_hard
** DB Stats **
Uptime(secs): 577.7 total, 60.1 interval
Cumulative writes: 116960736 writes, 11966220 batches, 9.8 writes per batch, 2.64 GB user ingest
Cumulative WAL: 0 writes, 0 syncs, 0.00 writes per sync, 0.00 GB written
Interval writes: 11643735 writes, 1206136 batches, 9.7 writes per batch, 269.2 MB user ingest
Interval WAL: 0 writes, 0 syncs, 0.00 writes per sync, 0.00 MB written
Yay for concurrent L0->L1 and L2->L3 compactions!
Reviewers: sdong, yhchiang, ljin
Reviewed By: yhchiang
Subscribers: yhchiang, leveldb
Differential Revision: https://reviews.facebook.net/D22305/"
rocksdb,"Turn on -Wshadow
Summary:
...and fix all the errors :)
Jim suggested turning on -Wshadow because it helped him fix number of critical bugs in fbcode. I think it's a good idea to be -Wshadow clean.
Test Plan: compiles
Reviewers: yhchiang, rven, sdong, ljin
Reviewed By: ljin
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D27711/Fix the bug where compaction does not fail when RocksDB can't create a new file.
Summary:
This diff has two fixes.
1. Fix the bug where compaction does not fail when RocksDB can't create a new file.
2. When NewWritableFiles() fails in OpenCompactionOutputFiles(), previously such fail-to-created file will be still be included as a compaction output.  This patch also fixes this bug.
3. Allow VersionEdit::EncodeTo() to return Status and add basic check.
Test Plan:
./version_edit_test
export ROCKSDB_TESTS=FileCreationRandomFailure
./db_test
Reviewers: ljin, sdong, nkg-, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D25581/fixed conflict in java/Makefile/Correct the log message in VersionEdit
Summary:
When VersionEdit fails in kNewFile3, previously it logs ""new-file2 entry"".
However, it should be ""new-file3 entry.""
Test Plan:
make/"
rocksdb,"fixed conflict in java/Makefile/perf_context.get_from_output_files_time is set for MultiGet() and ReadOnly DB too.
Summary: perf_context.get_from_output_files_time is now only set writable DB's DB::Get(). Extend it to MultiGet() and read only DB.
Test Plan:
make all check
Fix perf_context_test and extend it to cover MultiGet(), as long as read-only DB. Run it and watch the results
Reviewers: ljin, yhchiang, igor
Reviewed By: igor
Subscribers: rven, leveldb
Differential Revision: https://reviews.facebook.net/D24207/rename options_ to db_options_ in DBImpl to avoid confusion
Summary: as title
Test Plan: make release
Reviewers: sdong, igor
Reviewed By: igor
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22935/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/Fixed -WShadow errors in db/db_test.cc and include/rocksdb/metadata.h
Summary:
Fixed -WShadow errors in db/db_test.cc and include/rocksdb/metadata.h
Test Plan:
make/Fix compile/Make PartialCompactionFailure Test more robust again.
Summary:
Make PartialCompactionFailure Test more robust again by
blocking background compaction until we simulate the
file creation error.
Test Plan:
export ROCKSDB_TESTS=PartialCompactionFailure
./db_test
Reviewers: sdong, igor, ljin
Reviewed By: ljin
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28431/make DropWritesFlush deterministic
Summary:
TEST_WaitForFlush should wait until it sees error when parameter is set
to true so we don't need to loop and timeout
Test Plan: ROCKSDB_TESTS=DropWritesFlush ./db_test
Reviewers: sdong, igor
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28419/Make PartialCompactionFailure Test more robust.
Summary: Make PartialCompactionFailure Test more robust.
Test Plan:
export ROCKSDB_TESTS=PartialCompactionFailure
./db_test
Reviewers: ljin, sdong, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28425/Turn -Wshadow back on
Summary: It turns out that -Wshadow has different rules for gcc than clang. Previous commit fixed clang. This commits fixes the rest of the warnings for gcc.
Test Plan: compiles
Reviewers: ljin, yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28131/Improve DBTest.GroupCommitTest: artificially slowdown log writing to trigger group commit
Summary: In order to avoid random failure of DBTest.GroupCommitTest, artificially sleep 100 microseconds in each log writing.
Test Plan: Run the test in a machine where valgrind version of the test always fails multiple times and see it always succeed.
Reviewers: igor, yhchiang, rven, ljin
Reviewed By: ljin
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D28401/DBTest.DynamicMemtableOptions to use single background compaction
Summary:
Now DBTest.DynamicMemtableOptions sets background compaction to be 4, without actually increasing thread pool size (even before the feature of automatic increasing it). To make sure the behavior stays the same after the automatic thread pool increasing, set it back to 1.
Hopefully it can fix the occasional failure of the test.
Test Plan: Run the test
Reviewers: igor, ljin
Reviewed By: ljin
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D28281/introduce TestMemEnv and use it in db_test
Summary:
TestMemEnv simulates all Env APIs using in-memory data structures.
We can use it to speed up db_test run, which is now reduced ~7mins when it is
enabled.
We can also add features to simulate power/disk failures in the next
step
TestMemEnv is derived from helper/mem_env
mem_env can not be used for rocksdb since some of its APIs do not give
the same results as env_posix. And its file read/write is not thread safe
Test Plan:
make all -j32
./db_test
./env_mem_test
Reviewers: sdong, yhchiang, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28035/Turn on -Wshadow
Summary:
...and fix all the errors :)
Jim suggested turning on -Wshadow because it helped him fix number of critical bugs in fbcode. I think it's a good idea to be -Wshadow clean.
Test Plan: compiles
Reviewers: yhchiang, rven, sdong, ljin
Reviewed By: ljin
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D27711/Improve the robustness of PartialCompactionFailure test again.
Summary:
Improve the robustness of PartialCompactionFailure test again.
Test Plan:
./db_test/Improve the robustnesss of PartialCompactionFailure test.
Summary:
Improve the robustness of PartialCompactionFailure test.
Test Plan:
./db_test/Fix the bug where compaction does not fail when RocksDB can't create a new file.
Summary:
This diff has two fixes.
1. Fix the bug where compaction does not fail when RocksDB can't create a new file.
2. When NewWritableFiles() fails in OpenCompactionOutputFiles(), previously such fail-to-created file will be still be included as a compaction output.  This patch also fixes this bug.
3. Allow VersionEdit::EncodeTo() to return Status and add basic check.
Test Plan:
./version_edit_test
export ROCKSDB_TESTS=FileCreationRandomFailure
./db_test
Reviewers: ljin, sdong, nkg-, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D25581/fixed conflict in java/Makefile/Fix SIGSEGV when declaring Arena after ScopedArenaIterator/Fix CompactBetweenSnapshots/Sanitize block-based table index type and check prefix_extractor
Summary:
Respond to issue reported
https://www.facebook.com/groups/rocksdb.dev/permalink/651090261656158/
Change the Sanitize signature to take both DBOptions and CFOptions
Test Plan: unit test
Reviewers: sdong, yhchiang, igor
Reviewed By: igor
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D25041/Fix Mac compile error: C++11 forbids default arguments for lambda expressions
Summary:
Fix the following Mac compile error.
db/db_test.cc:8686:52: error: C++11 forbids default arguments for lambda expressions [-Werror,-Wlambda-extensions]
auto gen_l0_kb = [this](int start, int size, int stride = 1) {
^        ~
Test Plan:
db_test/Fix DynamicMemtableOptions test
Summary: as title
Test Plan: make release
Reviewers: igor
Reviewed By: igor
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D25029/fix build failure
Summary: missed default value during merge
Test Plan: ./db_test
Reviewers: igor, sdong, yhchiang
Reviewed By: yhchiang
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D24975/Fixed compile error on Mac: default arguments for lambda expressions
Summary:
Fixed the following compile error on Mac.
db/db_test.cc:8618:52: error: C++11 forbids default arguments for lambda expressions [-Werror,-Wlambda-extensions]
auto gen_l0_kb = [this](int start, int size, int stride = 1) {
^        ~
1 error generated.
Test Plan:
db_test/Merge pull request #327 from dalgaaf/wip-da-SCA-20141001
Fix some issues from SCA/Fixed signed-unsigned comparison warning in db_test.cc
Summary:
Fixed signed-unsigned comparison warning in db_test.cc
db/db_test.cc:8606:3: note: in instantiation of function template specialization 'rocksdb::test::Tester::IsEq<int, unsigned long>' requested here
ASSERT_EQ(2, metadata.size());
^
Test Plan:
make db_test/Merge pull request #324 from dalgaaf/wip-da-SCA-20140930
Various SCA fixes/db_test.cc: pass parameter by reference
Fix for:
[db/db_test.cc:6141]: (performance) Function parameter
'key' should be passed by reference.
Signed-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>/CompactedDBImpl::MultiGet() for better CuckooTable performance
Summary:
Add the MultiGet API to allow prefetching.
With file size of 1.5G, I configured it to have 0.9 hash ratio that can
fill With 115M keys and result in 2 hash functions, the lookup QPS is
~4.9M/s  vs. 3M/s for Get().
It is tricky to set the parameters right. Since files size is determined
by power-of-two factor, that means # of keys is fixed in each file. With
big file size (thus smaller # of files), we will have more chance to
waste lot of space in the last file - lower space utilization as a
result. Using smaller file size can improve the situation, but that
harms lookup speed.
Test Plan: db_bench
Reviewers: yhchiang, sdong, igor
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D23673/Fix unit tests errors
Summary: Those were introduced with https://github.com/facebook/rocksdb/commit/2fb1fea30fd027bbd824a26b682d04d91a8661dc because the flushing behavior changed when max_background_flushes is > 0.
Test Plan: make check
Reviewers: ljin, yhchiang, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D23577/Merge pull request #282 from Chilledheart/develop
Fix build issue under macosx/Fix build issue under macosx/Fix valgrind test
Summary: Get valgrind to stop complaining about uninitialized value
Test Plan: valgrind not complaining anymore
Reviewers: sdong, yhchiang, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D23289/[unit test] CompactRange should fail if we don't have space
Summary:
See t5106397.
Also, few more changes:
1. in unit tests, the assumption is that writes will be dropped when there is no space left on device. I changed the wording around it.
2. InvalidArgument() errors are only when user-provided arguments are invalid. When the file is corrupted, we need to return Status::Corruption
Test Plan: make check
Reviewers: sdong, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D23145/Fix Mac compile/Fix SimpleWriteTimeoutTest
Summary:
In column family's SanitizeOptions() [1], we make sure that min_write_buffer_number_to_merge is normal value. However, this test depended on the fact that setting min_write_buffer_number_to_merge to be bigger than max_write_buffer_number will cause a deadlock. I'm not sure how it worked before.
This diff fixes it by scheduling sleeping background task, which will actually block any attempts of flushing.
[1] https://github.com/facebook/rocksdb/blob/master/db/column_family.cc#L104
Test Plan: the test works now
Reviewers: yhchiang, sdong, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D23103/Improve db recovery
Summary: Avoid creating unnecessary sst files while db opening
Test Plan: make all check
Reviewers: sdong, igor
Reviewed By: igor
Subscribers: zagfox, yhchiang, ljin, leveldb
Differential Revision: https://reviews.facebook.net/D20661/Check stop level trigger-0 before slowdown level-0 trigger
Summary: ...
Test Plan: Can't repro the test failure, but let's see what jenkins says
Reviewers: zagfox, sdong, ljin
Reviewed By: sdong, ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D23061/DB::Flush() Do not wait for background threads when there is nothing in mem table
Summary:
When we have multiple column families, users can issue Flush() on every column families to make sure everything is flushes, even if some of them might be empty. By skipping the waiting for empty cases, it can be greatly speed up.
Still wait for people's comments before writing unit tests for it.
Test Plan: Will write a unit test to make sure it is correct.
Reviewers: ljin, yhchiang, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D22953/fixed memory leak in unit test DBIteratorBoundTest
Summary: fixed memory leak in unit test DBIteratorBoundTest
Test Plan: ran valgrind test on my unit test
Reviewers: sdong
Differential Revision: https://reviews.facebook.net/D22911/Merge pull request #237 from tdfischer/tdfischer/faster-timeout-test
test: db: fix test to have a smaller timeout for when it runs on faster .../Improve Options sanitization and add MmapReadRequired() to TableFactory
Summary:
Currently, PlainTable must use mmap_reads.  When PlainTable is used but
allow_mmap_reads is not set, rocksdb will fail in flush.
This diff improve Options sanitization and add MmapReadRequired() to
TableFactory.
Test Plan:
export ROCKSDB_TESTS=PlainTableOptionsSanitizeTest
make db_test -j32
./db_test
Reviewers: sdong, ljin
Reviewed By: ljin
Subscribers: you, leveldb
Differential Revision: https://reviews.facebook.net/D21939/test: db: fix test to have a smaller timeout for when it runs on faster hardware/Support purging logs from separate log directory
Summary:
1. Support purging info logs from a separate paths from DB path. Refactor the codes of generating info log prefixes so that it can be called when generating new files and scanning log directory.
2. Fix the bug of not scanning multiple DB paths (should only impact multiple DB paths)
Test Plan:
Add unit test for generating and parsing info log files
Add end-to-end test in db_test
Reviewers: yhchiang, ljin
Reviewed By: ljin
Subscribers: leveldb, igor, dhruba
Differential Revision: https://reviews.facebook.net/D21801/"
rocksdb,"Fixed GetEstimatedActiveKeys
Summary:
Fixed a bug in GetEstimatedActiveKeys which does not normalized
the sampled information correctly.
Add a test in version_builder_test.
Test Plan: version_builder_test
Reviewers: ljin, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28707/Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/Turn -Wshadow back on
Summary: It turns out that -Wshadow has different rules for gcc than clang. Previous commit fixed clang. This commits fixes the rest of the warnings for gcc.
Test Plan: compiles
Reviewers: ljin, yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28131/Fix BaseReferencedVersionBuilder's destructor order
Summary: BaseReferencedVersionBuilder now unreference version before destructing VersionBuilder, which is wrong. Fix it.
Test Plan:
make all check
valgrind test to tests that used to fail
Reviewers: igor, yhchiang, rven, ljin
Reviewed By: ljin
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D28101/Turn on -Wshadow
Summary:
...and fix all the errors :)
Jim suggested turning on -Wshadow because it helped him fix number of critical bugs in fbcode. I think it's a good idea to be -Wshadow clean.
Test Plan: compiles
Reviewers: yhchiang, rven, sdong, ljin
Reviewed By: ljin
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D27711/Fix the bug where compaction does not fail when RocksDB can't create a new file.
Summary:
This diff has two fixes.
1. Fix the bug where compaction does not fail when RocksDB can't create a new file.
2. When NewWritableFiles() fails in OpenCompactionOutputFiles(), previously such fail-to-created file will be still be included as a compaction output.  This patch also fixes this bug.
3. Allow VersionEdit::EncodeTo() to return Status and add basic check.
Test Plan:
./version_edit_test
export ROCKSDB_TESTS=FileCreationRandomFailure
./db_test
Reviewers: ljin, sdong, nkg-, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D25581/fixed conflict in java/Makefile/Merge pull request #327 from dalgaaf/wip-da-SCA-20141001
Fix some issues from SCA/db/version_set.cc: remove unnecessary checks
Fix for:
[db/version_set.cc:1219]: (style) Unsigned variable 'last_file'
can't be negative so it is unnecessary to test it.
[db/version_set.cc:1234]: (style) Unsigned variable 'first_file'
can't be negative so it is unnecessary to test it.
Signed-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>/Merge pull request #324 from dalgaaf/wip-da-SCA-20140930
Various SCA fixes/db/version_set.cc: use !empty() instead of 'size() > 0'
Use empty() since it should be prefered as it has, following
the standard, a constant time complexity regardless of the
containter type. The same is not guaranteed for size().
Fix for:
[db/version_set.cc:2250]: (performance) Possible inefficient
checking for 'column_families_not_found' emptiness.
Signed-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>/rename version_set options_ to db_options_ to avoid confusion
Summary: as title
Test Plan: make release
Reviewers: sdong, yhchiang, igor
Reviewed By: igor
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D23007/Push- instead of pull-model for managing Write stalls
Summary:
Introducing WriteController, which is a source of truth about per-DB write delays. Let's define an DB epoch as a period where there are no flushes and compactions (i.e. new epoch is started when flush or compaction finishes). Each epoch can either:
* proceed with all writes without delay
* delay all writes by fixed time
* stop all writes
The three modes are recomputed at each epoch change (flush, compaction), rather than on every write (which is currently the case).
When we have a lot of column families, our current pull behavior adds a big overhead, since we need to loop over every column family for every write. With new push model, overhead on Write code-path is minimal.
This is just the start. Next step is to also take care of stalls introduced by slow memtable flushes. The final goal is to eliminate function MakeRoomForWrite(), which currently needs to be called for every column family by every write.
Test Plan: make check for now. I'll add some unit tests later. Also, perf test.
Reviewers: dhruba, yhchiang, MarkCallaghan, sdong, ljin
Reviewed By: ljin
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22791/Merge pull request #272 from project-zerus/patch-1
fix more compile warnings/fix more compile warnings
N/A
Change-Id: I5b6f9c70aea7d3f3489328834fed323d41106d9f
Signed-off-by: liuhuahang <liuhuahang@zerus.co>/Avoid retrying to read property block from a table when it does not exist.
Summary:
Avoid retrying to read property block from a table when it does not exist
in updating stats for compensating deletion entries.
In addition, ReadTableProperties() now returns Status::NotFound instead
of Status::Corruption when table properties does not exist in the file.
Test Plan:
make db_test -j32
export ROCKSDB_TESTS=CompactionDeleteionTrigger
./db_test
Reviewers: ljin, sdong
Reviewed By: sdong
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D21867/"
rocksdb,"Turn on -Wshorten-64-to-32 and fix all the errors
Summary:
We need to turn on -Wshorten-64-to-32 for mobile. See D1671432 (internal phabricator) for details.
This diff turns on the warning flag and fixes all the errors. There were also some interesting errors that I might call bugs, especially in plain table. Going forward, I think it makes sense to have this flag turned on and be very very careful when converting 64-bit to 32-bit variables.
Test Plan: compiles
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: bobbaldwin, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28689/fix c_test
Summary: as title
Test Plan: ./c_test
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28119/Turn on -Wshadow
Summary:
...and fix all the errors :)
Jim suggested turning on -Wshadow because it helped him fix number of critical bugs in fbcode. I think it's a good idea to be -Wshadow clean.
Test Plan: compiles
Reviewers: yhchiang, rven, sdong, ljin
Reviewed By: ljin
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D27711/fix valgrind error in c_test caused by BlockBasedTableOptions
Summary:
It was creating BlockBasedTableOptions object in a loop without calling
destroy()
Test Plan: valgrind ./c_test --leak-check=full --show-reachable=yes
Reviewers: sdong, igor
Reviewed By: igor
Subscribers: leveldb
Differential Revision: https://reviews.facebook.net/D22431/Fix the error of c_test.c
Summary:
Fix the error of c_test.c
Test Plan:
make c_test
./c_test/Fix valgrind error in c_test/Merge pull request #230 from cockroachdb/spencerkimball/send-user-keys-to-v2-filter
Pass parsed user key to prefix extractor in V2 compaction/"
rocksdb,"Turn -Wshadow back on
Summary: It turns out that -Wshadow has different rules for gcc than clang. Previous commit fixed clang. This commits fixes the rest of the warnings for gcc.
Test Plan: compiles
Reviewers: ljin, yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28131/"
rocksdb,"Fix compile warning in db_stress
Summary:
Fix compile warning in db_stress
Test Plan:
make db_stress/Fix compile warning in db_stress.cc on Mac
Summary:
Fix the following compile warning in db_stress.cc on Mac
tools/db_stress.cc:1688:52: error: format specifies type 'unsigned long' but the argument has type '::google::uint64' (aka 'unsigned long long') [-Werror,-Wformat]
fprintf(stdout, ""DB-write-buffer-size: %lu\n"", FLAGS_db_write_buffer_size);
~~~     ^~~~~~~~~~~~~~~~~~~~~~~~~~
%llu
Test Plan:
make/Make db_stress built for ROCKSDB_LITE
Summary:
Make db_stress built for ROCKSDB_LITE.
The test doesn't pass tough. It seg fault quickly. But I took a look and it doesn't seem to be related to lite version. Likely to be a bug inside RocksDB.
Test Plan: make db_stress
Reviewers: yhchiang, rven, ljin, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D28797/"
rocksdb,"Fix fault_injestion_test
Summary: A bug in MockEnv causes fault_injestion_test to fail. I don't know why it doesn't fail every time but it doesn't seem to be right.
Test Plan:
Run fault_injestion_test
Also run db_test with MEM_ENV=1 until the first failure.
Reviewers: yhchiang, rven, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D32877/Fix unity build
Summary: I broke it with https://github.com/facebook/rocksdb/commit/2fd8f750ab05bd100b627f1e043603d1069246ed
Test Plan: make unity
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D32577/Fix bug recently introduced in MemFile::Lock()
Summary: This bug fails DBTest.CheckLock
Test Plan: DBTest.CheckLock now passes with MEM_ENV=1.
Reviewers: rven, yhchiang, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D32451/fault_injection_test: add a unit test to allow parallel compactions and multiple levels
Summary: Add a new test case in fault_injection_test, which covers parallel compactions and multiple levels. Use MockEnv to run the new test case to speed it up. Improve MockEnv to avoid DestoryDB(), previously failed when deleting lock files.
Test Plan: Run ./fault_injection_test, including valgrind
Reviewers: rven, yhchiang, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D32415/"
rocksdb,"Merge pull request #488 from ekg/master
remove old debugging message (#487)/remove old debugging message (#487)
It doesn't seem this is needed./Handle errors during pthread calls
Summary: Release locks before calling exit.
Test Plan: Force errors in debugger and verify correctness
Reviewers: igor, yhchiang, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D30423/Fix #434
Summary: Why do we assert here? This doesn't seem like user friendly thing to do :)
Test Plan: none
Reviewers: sdong, yhchiang, rven
Reviewed By: rven
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D30027/Fix compile error in ROCKSDB_LITE/Fix iOS compile with -Wshorten-64-to-32
Summary: So iOS size_t is 32-bit, so we need to static_cast<size_t> any uint64_t :(
Test Plan: TARGET_OS=IOS make static_lib
Reviewers: dhruba, ljin, yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28743/"
rocksdb,"RocksJava - FindBugs issues
Addressed some FindBugs issues./"
rocksdb,"[RocksJava] Quality improvements
Summary:
- Addressed some FindBugs issues.
- Remove obsolete dbFolder cleanup
- Comparator tests for CF
- Added AbstractComparatorTest.
- Fixed a bug in the JNI Part about Java comparators
- Minor test improvements
Test Plan:
make rocksdbjava
make jtest
mvn -f rocksjni.pom package
Reviewers: adamretter, yhchiang, ankgup87
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D29571/"
rocksdb,"RocksJava - FindBugs issues
Addressed some FindBugs issues./"
rocksdb,"Merge pull request #402 from adamretter/bugfix-native-library-loader
Use correct classloader in Java NativeLibraryLoader/"
rocksdb,"RocksJava - FindBugs issues
Addressed some FindBugs issues./"
rocksdb,"[RocksJava] Slice / DirectSlice improvements
Summary:
- AssertionError when initialized with Non-Direct Buffer
- Tests + coverage for DirectSlice
- Slice sigsegv fixes when initializing from String and byte arrays
- Slice Tests
Test Plan: Run tests without source modifications.
Reviewers: yhchiang, adamretter, ankgup87
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D30081/"
rocksdb,[RocksJava] Testcase improvements/
rocksdb,"Merge pull request #480 from fyrz/RocksJava-Deprecate-SkipLogError
[RocksJava] Deprecate setSkipLogErrorOnRecovery/[RocksJava] Deprecate setSkipLogErrorOnRecovery
- see: 62ad0a9b19f0be4cefa70b6b32876e764b7f3c11/Merge pull request #401 from fyrz/RocksJava-Sigsegv-MergeOperatorName
[RocksJava] Fixes in MergeOperatorByName/[RocksJava] Sigsegv fix for MergerOperatorByName/"
rocksdb,"Merge pull request #480 from fyrz/RocksJava-Deprecate-SkipLogError
[RocksJava] Deprecate setSkipLogErrorOnRecovery/[RocksJava] Deprecate setSkipLogErrorOnRecovery
- see: 62ad0a9b19f0be4cefa70b6b32876e764b7f3c11/"
rocksdb,"Merge pull request #471 from fyrz/RocksJava-Fix-NativeLibraryLoader
[RocksJava] Fix native library loader/[RocksJava] Fix native library loader
Summary:
Prior to this the native library loader instance didn`t
care about a state. So if library loading was called multiple
times, multiple copies of the shared object were put into
the tmp folder and loaded into the JVM.
This changed within this commit to the following behavior:
- library loading is now synchronized
- library is loaded within the first call
- if loading was successful the library loaded sets a flag
- every subsequent call checks for a boolean flag indicating if there was
already a successful attempt
Test Plan:
- Execute example and watch tmp folder while the example is running
- After this patch only one shared object will be in the tmp folder
Usual tests:
- make rocksdbjava jtest
- mvn -f rocksjni.pom package
Reviewers: adamretter, ankgup87, yhchiang
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D32133/[RocksJava] JavaDoc corrections - Java8
This commit solves build problems in Java8 due
to wrong JavaDoc./Merge pull request #402 from adamretter/bugfix-native-library-loader
Use correct classloader in Java NativeLibraryLoader/"
rocksdb,"[RocksJava] Slice / DirectSlice improvements
Summary:
- AssertionError when initialized with Non-Direct Buffer
- Tests + coverage for DirectSlice
- Slice sigsegv fixes when initializing from String and byte arrays
- Slice Tests
Test Plan: Run tests without source modifications.
Reviewers: yhchiang, adamretter, ankgup87
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D30081/"
rocksdb,"Merge pull request #401 from fyrz/RocksJava-Sigsegv-MergeOperatorName
[RocksJava] Fixes in MergeOperatorByName/[RocksJava] Sigsegv fix for MergerOperatorByName/"
rocksdb,"Merge pull request #426 from fyrz/RocksJava-Restore-PrecisionFix
[RocksJava] Fixed MacOS build of RocksJava/[RocksJava] Fixed MacOS build of RocksJava
There were still some precision loss problems
remainging in RocksJava. This pull request resolve
these./Merge pull request #421 from fyrz/RocksJava-PrecisionFix
[RocksJava] Fix precision problem in rocksjni/[RocksJava] Fix precision problem in rocksjni/"
rocksdb,"[RocksJava] ColumnFamily name JNI correction
Summary:
Previous to this commit there was a problem with unterminated
String usage as jByteArrays are not zero terminated.
Test Plan:
make rocksdbjava
make jtest
mvn -f rocksjni.pom package
Reviewers: yhchiang, adamretter, ankgup87
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D31809/[RocksJava] ColumnFamily name JNI correction
Previous to this commit there was a problem with unterminated
String usage as jByteArrays are not zero terminated./"
rocksdb,"[RocksJava] Comparator tests for CF
- Added AbstractComparatorTest.
- Fixed a bug in the JNI Part about Java comparators/Merge pull request #401 from fyrz/RocksJava-Sigsegv-MergeOperatorName
[RocksJava] Fixes in MergeOperatorByName/[RocksJava] Sigsegv fix for MergerOperatorByName/"
rocksdb,"Fix broken test in 31b02d.
Summary:
CorruptionTest for backupable_db_test did not call
GarbageCollect() after deleting a corrupt backup,
which sometimes lead to test failures as the newly created backup
would reuse the same backup ID and files and fail the consistency
check.
Moved around some of the test logic to ensure that GarbageCollect()
is called at the right time.
Test Plan:
Run backupable_db_test eight times and make sure
it passes repeatedly. Also run make check to make sure other
tests don't fail.
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28863/Improve Backup Engine.
Summary:
Improve the backup engine by not deleting the corrupted
backup when it is detected; instead leaving it to the client
to delete the corrupted backup.
Also add a BackupEngine::Open() call.
Test Plan:
Add check to CorruptionTest inside backupable_db_test
to check that the corrupt backups are not deleted. The previous
version of the code failed this test as backups were deleted,
but after the changes in this commit, this test passes.
Run make check to ensure that no other tests fail.
Reviewers: sdong, benj, sanketh, sumeet, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28521/"
rocksdb,"Merge pull request #451 from StanislavGlebik/document_db_improvement
Fixed negative numbers comparison in DocumentDB/Fixed negative numbers comparison in DocumentDB/"
rocksdb,"Make db_stress built for ROCKSDB_LITE
Summary:
Make db_stress built for ROCKSDB_LITE.
The test doesn't pass tough. It seg fault quickly. But I took a look and it doesn't seem to be related to lite version. Likely to be a bug inside RocksDB.
Test Plan: make db_stress
Reviewers: yhchiang, rven, ljin, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D28797/"
rocksdb,"Remember whole key/prefix filtering on/off in SST file
Summary: Remember whole key or prefix filtering on/off in SST files. If user opens the DB with a different setting that cannot be satisfied while reading the SST file, ignore the bloom filter.
Test Plan: Add a unit test for it
Reviewers: yhchiang, igor, rven
Reviewed By: rven
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D32889/Get() to use prefix bloom filter when filter is not block based
Summary:
Get() now doesn't make use of bloom filter if it is prefix based. Add the check.
Didn't touch block based bloom filter. I can't fully reason whether it is correct to do that. But it's straight-forward to for full bloom filter.
Test Plan:
make all check
Add a test case in DBTest
Reviewers: rven, yhchiang, igor
Reviewed By: igor
Subscribers: MarkCallaghan, leveldb, dhruba, yoshinorim
Differential Revision: https://reviews.facebook.net/D31941/"
rocksdb,"Fix iOS compile with -Wshorten-64-to-32
Summary: So iOS size_t is 32-bit, so we need to static_cast<size_t> any uint64_t :(
Test Plan: TARGET_OS=IOS make static_lib
Reviewers: dhruba, ljin, yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28743/"
rocksdb,Fix build issues/
rocksdb,Fix compile of compact_file_example/
rocksdb,"Fix deleting obsolete files #2
Summary: For description of the bug, see comment in db_test. The fix is pretty straight forward.
Test Plan: added unit test. eventually we need better testing of FOF/POF process.
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33081/Print DB pointer when opening a DB
Summary: Having a pointer for DB will be helpful to debug when GDB or working on a dump. If the client process doesn't have any thread actively working on RocksDB, it can be hard to find out.
Test Plan: make all check
Reviewers: rven, yhchiang, igor
Reviewed By: igor
Subscribers: yoshinorim, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33159/Fix deleting obsolete files
Summary:
This diff basically reverts D30249 and also adds a unit test that was failing before this patch.
I have no idea how I didn't catch this terrible bug when writing a diff, sorry about that :(
I think we should redesign our system of keeping track of and deleting files. This is already a second bug in this critical piece of code. I'll think of few ideas.
BTW this diff is also a regression when running lots of column families. I plan to revisit this separately.
Test Plan: added a unit test
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33045/Fix DestroyDB
Summary:
When DestroyDB() finds a wal file in the DB directory, it assumes it is actually in WAL directory. This can lead to confusion, since it reports IO error when it tries to delete wal file from DB directory. For example: https://ci-builds.fb.com/job/rocksdb_clang_build/296/console
This change will fix our unit tests.
Test Plan: unit tests work
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D32907/Fix data race #2
Summary: We should not be calling InternalStats methods outside of the mutex.
Test Plan:
COMPILE_WITH_TSAN=1 m db_test && ROCKSDB_TESTS=CompactionTrigger ./db_test
failing before the diff, works now
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D32127/Sync manifest file when initializing it
Summary: Now we don't sync manifest file when initializing it, so DB cannot be safely reopened before the first mem table flush. Fix it by syncing it. This fixes fault_injection_test.
Test Plan: make all check
Reviewers: rven, yhchiang, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D32001/Fix compaction summary log for trivial move
Summary: When trivial move commit is done, we log the summary of the input version instead of current. This is inconsistent with other log messages and confusing.
Test Plan: compiles
Reviewers: sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D30939/Deprecating skip_log_error_on_recovery
Summary:
Since https://reviews.facebook.net/D16119, we ignore partial tailing writes. Because of that, we no longer need skip_log_error_on_recovery.
The documentation says ""Skip log corruption error on recovery (If client is ok with losing most recent changes)"", while the option actually ignores any corruption of the WAL (not only just the most recent changes). This is very dangerous and can lead to DB inconsistencies. This was originally set up to ignore partial tailing writes, which we now do automatically (after D16119). I have digged up old task t2416297 which confirms my findings.
Test Plan: There was actually no tests that verified correct behavior of skip_log_error_on_recovery.
Reviewers: yhchiang, rven, dhruba, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D30603/Fix corruption_test -- if status is not OK, return status -- during recovery/Fail DB::Open() on WAL corruption
Summary:
This is a serious bug. If paranod_check == true and WAL is corrupted, we don't fail DB::Open(). I tried going into history and it seems we've been doing this for a long long time.
I found this when investigating t5852041.
Test Plan: Added unit test to verify correct behavior.
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D30597/Fixed a compile error in db/db_impl.cc on ROCKSDB_LITE/Speed up FindObsoleteFiles()
Summary:
There are two versions of FindObsoleteFiles():
* full scan, which is executed every 6 hours (and it's terribly slow)
* no full scan, which is executed every time a background process finishes and iterator is deleted
This diff is optimizing the second case (no full scan). Here's what we do before the diff:
* Get the list of obsolete files (files with ref==0). Some files in obsolete_files set might actually be live.
* Get the list of live files to avoid deleting files that are live.
* Delete files that are in obsolete_files and not in live_files.
After this diff:
* The only files with ref==0 that are still live are files that have been part of move compaction. Don't include moved files in obsolete_files.
* Get the list of obsolete files (which exclude moved files).
* No need to get the list of live files, since all files in obsolete_files need to be deleted.
I'll post the benchmark results, but you can get the feel of it here: https://reviews.facebook.net/D30123
This depends on D30123.
P.S. We should do full scan only in failure scenarios, not every 6 hours. I'll do this in a follow-up diff.
Test Plan:
One new unit test. Made sure that unit test fails if we don't have a `if (!f->moved)` safeguard in ~Version.
make check
Big number of compactions and flushes:
./db_stress --threads=30 --ops_per_thread=20000000 --max_key=10000 --column_families=20 --clear_column_family_one_in=10000000 --verify_before_write=0  --reopen=15 --max_background_compactions=10 --max_background_flushes=10 --db=/fast-rocksdb-tmp/db_stress --prefixpercent=0 --iterpercent=0 --writepercent=75 --db_write_buffer_size=2000000
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D30249/Fix a SIGSEGV in BackgroundFlush
Summary:
This one wasn't easy to find :)
What happens is we go through all cfds on flush_queue_ and find no cfds to flush, *but* the cfd is set to the last CF we looped through and following code assumes we want it flushed.
BTW @sdong do you think we should also make BackgroundFlush() only check a single cfd for flushing instead of doing this `while (!flush_queue_.empty())`?
Test Plan: regression test no longer fails
Reviewers: sdong, rven, yhchiang
Reviewed By: yhchiang
Subscribers: sdong, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D30591/Rewritten system for scheduling background work
Summary:
When scaling to higher number of column families, the worst bottleneck was MaybeScheduleFlushOrCompaction(), which did a for loop over all column families while holding a mutex. This patch addresses the issue.
The approach is similar to our earlier efforts: instead of a pull-model, where we do something for every column family, we can do a push-based model -- when we detect that column family is ready to be flushed/compacted, we add it to the flush_queue_/compaction_queue_. That way we don't need to loop over every column family in MaybeScheduleFlushOrCompaction.
Here are the performance results:
Command:
./db_bench --write_buffer_size=268435456 --db_write_buffer_size=268435456 --db=/fast-rocksdb-tmp/rocks_lots_of_cf --use_existing_db=0 --open_files=55000 --statistics=1 --histogram=1 --disable_data_sync=1 --max_write_buffer_number=2 --sync=0 --benchmarks=fillrandom --threads=16 --num_column_families=5000  --disable_wal=1 --max_background_flushes=16 --max_background_compactions=16 --level0_file_num_compaction_trigger=2 --level0_slowdown_writes_trigger=2 --level0_stop_writes_trigger=3 --hard_rate_limit=1 --num=33333333 --writes=33333333
Before the patch:
fillrandom   :      26.950 micros/op 37105 ops/sec;    4.1 MB/s
After the patch:
fillrandom   :      17.404 micros/op 57456 ops/sec;    6.4 MB/s
Next bottleneck is VersionSet::AddLiveFiles, which is painfully slow when we have a lot of files. This is coming in the next patch, but when I removed that code, here's what I got:
fillrandom   :       7.590 micros/op 131758 ops/sec;   14.6 MB/s
Test Plan:
make check
two stress tests:
Big number of compactions and flushes:
./db_stress --threads=30 --ops_per_thread=20000000 --max_key=10000 --column_families=20 --clear_column_family_one_in=10000000 --verify_before_write=0  --reopen=15 --max_background_compactions=10 --max_background_flushes=10 --db=/fast-rocksdb-tmp/db_stress --prefixpercent=0 --iterpercent=0 --writepercent=75 --db_write_buffer_size=2000000
max_background_flushes=0, to verify that this case also works correctly
./db_stress --threads=30 --ops_per_thread=2000000 --max_key=10000 --column_families=20 --clear_column_family_one_in=10000000 --verify_before_write=0  --reopen=3 --max_background_compactions=3 --max_background_flushes=0 --db=/fast-rocksdb-tmp/db_stress --prefixpercent=0 --iterpercent=0 --writepercent=75 --db_write_buffer_size=2000000
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D30123/Avoid unnecessary unlock and lock mutex when notifying events.
Summary: Avoid unnecessary unlock and lock mutex when notifying events.
Test Plan: ./listener_test
Reviewers: igor
Reviewed By: igor
Subscribers: sdong, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D30267/Fix calculation of max_total_wal_size in db_options_.max_total_wal_size == 0 case
Summary: This is a regression bug introduced by https://reviews.facebook.net/D24729 . max_total_wal_size would be off the target it should be more and more in the case that the a user holds the current super version after flush or compaction. This patch fixes it
Test Plan: make all check
Reviewers: yhchiang, rven, igor
Reviewed By: igor
Subscribers: ljin, yoshinorim, MarkCallaghan, hermanlee4, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D29961/Add Moved(GB) to Compaction IO stats
Summary:
Adds counter for bytes moved (files pushed down a level rather than compacted) to compaction
IO stats as Moved(GB). From the output removed these infrequently used columns: RW-Amp, Rn(cnt), Rnp1(cnt),
Wnp1(cnt), Wnew(cnt).
Example old output:
Level   Files   Size(MB) Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) RW-Amp W-Amp Rd(MB/s) Wr(MB/s)  Rn(cnt) Rnp1(cnt) Wnp1(cnt) Wnew(cnt)  Comp(sec) Comp(cnt) Avg(sec) Stall(sec) Stall(cnt) Avg(ms) RecordIn RecordDrop
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
L0     0/0          0   0.0      0.0     0.0      0.0    2130.8   2130.8    0.0   0.0      0.0    109.1        0         0         0         0      20002     25068    0.798      28.75     182059    0.16       0          0
L1   142/0        509   1.0   4618.5  2036.5   2582.0    4602.1   2020.2    4.5   2.3     88.5     88.1    24220    701246   1215528    514282      53466      4229   12.643       0.00          0    0.002032745988  300688729
Example new output:
Level   Files   Size(MB) Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) Comp(cnt) Avg(sec) Stall(sec) Stall(cnt) Avg(ms)     RecordIn   RecordDrop
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
L0     7/0         13   1.8      0.0     0.0      0.0       0.6      0.6       0.0   0.0      0.0     14.7        44       353    0.124       0.03        626    0.05            0            0
L1     9/0         16   1.6      0.0     0.0      0.0       0.0      0.0       0.6   0.0      0.0      0.0         0         0    0.000       0.00          0    0.00            0            0
Task ID: #
Blame Rev:
Test Plan:
make check, run db_bench --fillseq --stats_per_interval --stats_interval and look at output
Revert Plan:
Database Impact:
Memcache Impact:
Other Notes:
EImportant:
- begin *PUBLIC* platform impact section -
Bugzilla: #
- end platform impact -
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D29787/Fix leak when create_missing_column_families=true on ThreadStatus
Summary:
An entry of ConstantColumnFamilyInfo is created when:
1. DB::Open
2. CreateColumnFamily.
However, there are cases that DB::Open could also call CreateColumnFamily
when create_missing_column_families=true.  As a result, it will create
duplicate ConstantColumnFamilyInfo and one of them would be leaked.
Test Plan: ./deletefile_test
Reviewers: igor, sdong, ljin
Reviewed By: ljin
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D29307/Fix SIGSEGV
Summary: As a short-term fix, let's go back to previous way of calculating NeedsCompaction(). SIGSEGV happens because NeedsCompaction() can happen before super_version (and thus MutableCFOptions) is initialized.
Test Plan: make check
Reviewers: ljin, sdong, rven, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28875/Fix iOS compile with -Wshorten-64-to-32
Summary: So iOS size_t is 32-bit, so we need to static_cast<size_t> any uint64_t :(
Test Plan: TARGET_OS=IOS make static_lib
Reviewers: dhruba, ljin, yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28743/"
rocksdb,Fix formatting/
rocksdb,"Fix data race #3
Summary: Added requirement that ComputeCompactionScore() be executed in mutex, since it's accessing being_compacted bool, which can be mutated by other threads. Also added more comments about thread safety of FileMetaData, since it was a bit confusing. However, it seems that FileMetaData doesn't have data races (except being_compacted)
Test Plan: Ran 100 ConvertCompactionStyle tests with thread sanitizer. On master -- some failures. With this patch -- none.
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D32283/Rewritten system for scheduling background work
Summary:
When scaling to higher number of column families, the worst bottleneck was MaybeScheduleFlushOrCompaction(), which did a for loop over all column families while holding a mutex. This patch addresses the issue.
The approach is similar to our earlier efforts: instead of a pull-model, where we do something for every column family, we can do a push-based model -- when we detect that column family is ready to be flushed/compacted, we add it to the flush_queue_/compaction_queue_. That way we don't need to loop over every column family in MaybeScheduleFlushOrCompaction.
Here are the performance results:
Command:
./db_bench --write_buffer_size=268435456 --db_write_buffer_size=268435456 --db=/fast-rocksdb-tmp/rocks_lots_of_cf --use_existing_db=0 --open_files=55000 --statistics=1 --histogram=1 --disable_data_sync=1 --max_write_buffer_number=2 --sync=0 --benchmarks=fillrandom --threads=16 --num_column_families=5000  --disable_wal=1 --max_background_flushes=16 --max_background_compactions=16 --level0_file_num_compaction_trigger=2 --level0_slowdown_writes_trigger=2 --level0_stop_writes_trigger=3 --hard_rate_limit=1 --num=33333333 --writes=33333333
Before the patch:
fillrandom   :      26.950 micros/op 37105 ops/sec;    4.1 MB/s
After the patch:
fillrandom   :      17.404 micros/op 57456 ops/sec;    6.4 MB/s
Next bottleneck is VersionSet::AddLiveFiles, which is painfully slow when we have a lot of files. This is coming in the next patch, but when I removed that code, here's what I got:
fillrandom   :       7.590 micros/op 131758 ops/sec;   14.6 MB/s
Test Plan:
make check
two stress tests:
Big number of compactions and flushes:
./db_stress --threads=30 --ops_per_thread=20000000 --max_key=10000 --column_families=20 --clear_column_family_one_in=10000000 --verify_before_write=0  --reopen=15 --max_background_compactions=10 --max_background_flushes=10 --db=/fast-rocksdb-tmp/db_stress --prefixpercent=0 --iterpercent=0 --writepercent=75 --db_write_buffer_size=2000000
max_background_flushes=0, to verify that this case also works correctly
./db_stress --threads=30 --ops_per_thread=2000000 --max_key=10000 --column_families=20 --clear_column_family_one_in=10000000 --verify_before_write=0  --reopen=3 --max_background_compactions=3 --max_background_flushes=0 --db=/fast-rocksdb-tmp/db_stress --prefixpercent=0 --iterpercent=0 --writepercent=75 --db_write_buffer_size=2000000
Reviewers: ljin, rven, yhchiang, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D30123/Fix SIGSEGV
Summary: As a short-term fix, let's go back to previous way of calculating NeedsCompaction(). SIGSEGV happens because NeedsCompaction() can happen before super_version (and thus MutableCFOptions) is initialized.
Test Plan: make check
Reviewers: ljin, sdong, rven, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28875/"
rocksdb,"Remember whole key/prefix filtering on/off in SST file
Summary: Remember whole key or prefix filtering on/off in SST files. If user opens the DB with a different setting that cannot be satisfied while reading the SST file, ignore the bloom filter.
Test Plan: Add a unit test for it
Reviewers: yhchiang, igor, rven
Reviewed By: rven
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D32889/Fix deleting obsolete files #2
Summary: For description of the bug, see comment in db_test. The fix is pretty straight forward.
Test Plan: added unit test. eventually we need better testing of FOF/POF process.
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33081/Added RocksDB stats GET_HIT_L0 and GET_HIT_L1
Summary:
- In statistics.h , added tickers.
- In version_set.cc,
-- Added a getter method for hit_file_level_ in the class FilePicker
-- Added a line in the Get() method in case of a found, increment the corresponding counters based on the level of the file respectively.
Corresponding task: https://our.intern.facebook.com/intern/tasks/?s=506100481&t=5952818
Personal fork: https://github.com/sycamlaw43/rocksdb/commit/0c3f2e3600a1e0faad63249c45f3951fd0430b30
Test Plan:
In terminal,
```
make -j32 db_test
ROCKSDB_TESTS=L0L1L2AndUpHitCounter ./db_test
```
Or to use debugger,
```
make -j32 db_test
export ROCKSDB_TESTS=L0L1L2AndUpHitCounter
gdb db_test
```
Reviewers: rven, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D32205/Fix deleting obsolete files
Summary:
This diff basically reverts D30249 and also adds a unit test that was failing before this patch.
I have no idea how I didn't catch this terrible bug when writing a diff, sorry about that :(
I think we should redesign our system of keeping track of and deleting files. This is already a second bug in this critical piece of code. I'll think of few ideas.
BTW this diff is also a regression when running lots of column families. I plan to revisit this separately.
Test Plan: added a unit test
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33045/Fix DestroyDB
Summary:
When DestroyDB() finds a wal file in the DB directory, it assumes it is actually in WAL directory. This can lead to confusion, since it reports IO error when it tries to delete wal file from DB directory. For example: https://ci-builds.fb.com/job/rocksdb_clang_build/296/console
This change will fix our unit tests.
Test Plan: unit tests work
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D32907/Revert ""Fix wal_dir not getting cleaned""
This reverts commit f36d394aeddf420661e54a1a0a54fcc790c9cffb./Fix wal_dir not getting cleaned/db_test: fix a data race in SpecialEnv
Summary: db_test's test class SpecialEnv has a thread unsafe variable rnd_ but it can be accessed by multiple threads. It is complained by TSAN. Protect it by a mutex.
Test Plan: Run the test
Reviewers: yhchiang, rven, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D32895/Get() to use prefix bloom filter when filter is not block based
Summary:
Get() now doesn't make use of bloom filter if it is prefix based. Add the check.
Didn't touch block based bloom filter. I can't fully reason whether it is correct to do that. But it's straight-forward to for full bloom filter.
Test Plan:
make all check
Add a test case in DBTest
Reviewers: rven, yhchiang, igor
Reviewed By: igor
Subscribers: MarkCallaghan, leveldb, dhruba, yoshinorim
Differential Revision: https://reviews.facebook.net/D31941/Cross functional test infrastructure for RocksDB.
Summary:
This Diff provides the implementation of the cross functional
test infrastructure. This provides the ability to test a single feature
with every existing regression test in order to identify issues with
interoperability between features.
Test Plan:
Reference implementation of inplace update support cross
functional test. Able to find interoperability issues with inplace
support and ran all of db_test. Will add separate diff for those changes.
Reviewers: igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D32247/CappedFixTransform: return fixed length prefix, or full key if key is shorter than the fixed length
Summary: Add CappedFixTransform, which is the same as fixed length prefix extractor, except that when slice is shorter than the fixed length, it will use the full key.
Test Plan:
Add a test case for
db_test
options_test
and a new test
Reviewers: yhchiang, rven, igor
Reviewed By: igor
Subscribers: MarkCallaghan, leveldb, dhruba, yoshinorim
Differential Revision: https://reviews.facebook.net/D31887/Disable FlushSchedule when running TSAN
Summary:
There's a bug in TSAN (or libstdc++?) with std::shared_ptr<> for some reason. In db_test, only FlushSchedule is affected.
See more: https://groups.google.com/forum/#!topic/thread-sanitizer/vz_s-t226Vg
With this change and all other @sdong's and mine diffs, our db_test should be TSAN-clean. I'll move to other tests.
Test Plan: no more flush schedule when running TSAN
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: sdong, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D32469/Sync manifest file when initializing it
Summary: Now we don't sync manifest file when initializing it, so DB cannot be safely reopened before the first mem table flush. Fix it by syncing it. This fixes fault_injection_test.
Test Plan: make all check
Reviewers: rven, yhchiang, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D32001/Improve GetThreadStatus to avoid false alarm in some case./Fix build issues/Merge pull request #443 from behanna/master
Fix the build with -DNDEBUG./Fix the build with -DNDEBUG.
Dike out the body of VerifyCompactionResult.  With assert() compiled out, the
loop index variable in the inner loop was unused, breaking the build when
-Werror is enabled./Speed up FindObsoleteFiles()
Summary:
There are two versions of FindObsoleteFiles():
* full scan, which is executed every 6 hours (and it's terribly slow)
* no full scan, which is executed every time a background process finishes and iterator is deleted
This diff is optimizing the second case (no full scan). Here's what we do before the diff:
* Get the list of obsolete files (files with ref==0). Some files in obsolete_files set might actually be live.
* Get the list of live files to avoid deleting files that are live.
* Delete files that are in obsolete_files and not in live_files.
After this diff:
* The only files with ref==0 that are still live are files that have been part of move compaction. Don't include moved files in obsolete_files.
* Get the list of obsolete files (which exclude moved files).
* No need to get the list of live files, since all files in obsolete_files need to be deleted.
I'll post the benchmark results, but you can get the feel of it here: https://reviews.facebook.net/D30123
This depends on D30123.
P.S. We should do full scan only in failure scenarios, not every 6 hours. I'll do this in a follow-up diff.
Test Plan:
One new unit test. Made sure that unit test fails if we don't have a `if (!f->moved)` safeguard in ~Version.
make check
Big number of compactions and flushes:
./db_stress --threads=30 --ops_per_thread=20000000 --max_key=10000 --column_families=20 --clear_column_family_one_in=10000000 --verify_before_write=0  --reopen=15 --max_background_compactions=10 --max_background_flushes=10 --db=/fast-rocksdb-tmp/db_stress --prefixpercent=0 --iterpercent=0 --writepercent=75 --db_write_buffer_size=2000000
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D30249/Fixes valgrind error in GetSnapshotLink. Free checkpoint now.
Summary: Free checkpoint after its directory is removed.
Test Plan: Run valgrind with GetSnapshotLink.
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D29493/Fix leak when create_missing_column_families=true on ThreadStatus
Summary:
An entry of ConstantColumnFamilyInfo is created when:
1. DB::Open
2. CreateColumnFamily.
However, there are cases that DB::Open could also call CreateColumnFamily
when create_missing_column_families=true.  As a result, it will create
duplicate ConstantColumnFamilyInfo and one of them would be leaked.
Test Plan: ./deletefile_test
Reviewers: igor, sdong, ljin
Reviewed By: ljin
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D29307/"
rocksdb,"Fixed a compile warning in clang in db/listener_test.cc
Summary: Fixed a compile warning in clang in db/listener_test.cc
Test Plan: make listener_test
Reviewers: oridb
Reviewed By: oridb
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D32337/Improve listener_test to avoid possible false alarm
Summary:
Improve listener_test to avoid possible false alarm
Test Plan:
./listener_test/"
rocksdb,"Fix deleting obsolete files #2
Summary: For description of the bug, see comment in db_test. The fix is pretty straight forward.
Test Plan: added unit test. eventually we need better testing of FOF/POF process.
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33081/Added RocksDB stats GET_HIT_L0 and GET_HIT_L1
Summary:
- In statistics.h , added tickers.
- In version_set.cc,
-- Added a getter method for hit_file_level_ in the class FilePicker
-- Added a line in the Get() method in case of a found, increment the corresponding counters based on the level of the file respectively.
Corresponding task: https://our.intern.facebook.com/intern/tasks/?s=506100481&t=5952818
Personal fork: https://github.com/sycamlaw43/rocksdb/commit/0c3f2e3600a1e0faad63249c45f3951fd0430b30
Test Plan:
In terminal,
```
make -j32 db_test
ROCKSDB_TESTS=L0L1L2AndUpHitCounter ./db_test
```
Or to use debugger,
```
make -j32 db_test
export ROCKSDB_TESTS=L0L1L2AndUpHitCounter
gdb db_test
```
Reviewers: rven, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D32205/Fix deleting obsolete files
Summary:
This diff basically reverts D30249 and also adds a unit test that was failing before this patch.
I have no idea how I didn't catch this terrible bug when writing a diff, sorry about that :(
I think we should redesign our system of keeping track of and deleting files. This is already a second bug in this critical piece of code. I'll think of few ideas.
BTW this diff is also a regression when running lots of column families. I plan to revisit this separately.
Test Plan: added a unit test
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33045/Fix data race #3
Summary: Added requirement that ComputeCompactionScore() be executed in mutex, since it's accessing being_compacted bool, which can be mutated by other threads. Also added more comments about thread safety of FileMetaData, since it was a bit confusing. However, it seems that FileMetaData doesn't have data races (except being_compacted)
Test Plan: Ran 100 ConvertCompactionStyle tests with thread sanitizer. On master -- some failures. With this patch -- none.
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D32283/Sync manifest file when initializing it
Summary: Now we don't sync manifest file when initializing it, so DB cannot be safely reopened before the first mem table flush. Fix it by syncing it. This fixes fault_injection_test.
Test Plan: make all check
Reviewers: rven, yhchiang, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D32001/Speed up FindObsoleteFiles()
Summary:
There are two versions of FindObsoleteFiles():
* full scan, which is executed every 6 hours (and it's terribly slow)
* no full scan, which is executed every time a background process finishes and iterator is deleted
This diff is optimizing the second case (no full scan). Here's what we do before the diff:
* Get the list of obsolete files (files with ref==0). Some files in obsolete_files set might actually be live.
* Get the list of live files to avoid deleting files that are live.
* Delete files that are in obsolete_files and not in live_files.
After this diff:
* The only files with ref==0 that are still live are files that have been part of move compaction. Don't include moved files in obsolete_files.
* Get the list of obsolete files (which exclude moved files).
* No need to get the list of live files, since all files in obsolete_files need to be deleted.
I'll post the benchmark results, but you can get the feel of it here: https://reviews.facebook.net/D30123
This depends on D30123.
P.S. We should do full scan only in failure scenarios, not every 6 hours. I'll do this in a follow-up diff.
Test Plan:
One new unit test. Made sure that unit test fails if we don't have a `if (!f->moved)` safeguard in ~Version.
make check
Big number of compactions and flushes:
./db_stress --threads=30 --ops_per_thread=20000000 --max_key=10000 --column_families=20 --clear_column_family_one_in=10000000 --verify_before_write=0  --reopen=15 --max_background_compactions=10 --max_background_flushes=10 --db=/fast-rocksdb-tmp/db_stress --prefixpercent=0 --iterpercent=0 --writepercent=75 --db_write_buffer_size=2000000
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D30249/free builders in VersionSet::DumpManifest
Summary:
Reported by bootcamper
This causes ldb tool to fail the assertion in ~ColumnFamilyData()
Test Plan:
./ldb --db=/tmp/test_db1 --create_if_missing put a1 b1
./ldb manifest_dump --path=/tmp/test_db1/MANIFEST-000001
Reviewers: sdong, yhchiang, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D29517/Fix iOS compile with -Wshorten-64-to-32
Summary: So iOS size_t is 32-bit, so we need to static_cast<size_t> any uint64_t :(
Test Plan: TARGET_OS=IOS make static_lib
Reviewers: dhruba, ljin, yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D28743/Fix bug of reading from empty DB.
Summary: I found that db_stress sometimes segfault on my machine. Fix the bug.
Test Plan: make all check. Run db_stress
Reviewers: ljin, yhchiang, rven, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D28803/"
rocksdb,"memenv: normalize file path
Summary: Now using memenv, DB will not able to be reopened, since a ""//"" in the file name. Fix it by normalizing file path.
Test Plan: Add a unit test that used to fail and now pass.
Reviewers: rven, yhchiang, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D31767/"
rocksdb,"Fix build
Summary: Build broken by https://github.com/facebook/rocksdb/commit/6ede020dc419c1621254f26060076ee6d2c2d792
Test Plan: make all
Reviewers: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37689/Merge pull request #593 from charsyam/feature/type-1
fix typos/fix typos/rocksdb: Fixed 'Dead assignment' and 'Dead initialization' scan-build warnings
Summary:
This diff contains trivial fixes for 6 scan-build warnings:
**db/c_test.c**
`db` variable is never read. Removed assignment.
scan-build report:
http://home.fburl.com/~sugak/latest20/report-9b77d2.html#EndPath
**db/db_iter.cc**
`skipping` local variable is assigned to false. Then in the next switch block the only ""non return"" case assign `skipping` to true, the rest cases don't use it and all do return.
scan-build report:
http://home.fburl.com/~sugak/latest20/report-13fca7.html#EndPath
**db/log_reader.cc**
In `bool Reader::SkipToInitialBlock()` `offset_in_block` local variable is assigned to 0 `if (offset_in_block > kBlockSize - 6)` and then never used. Removed the assignment and renamed it to `initial_offset_in_block` to avoid confusion.
scan-build report:
http://home.fburl.com/~sugak/latest20/report-a618dd.html#EndPath
In `bool Reader::ReadRecord(Slice* record, std::string* scratch)` local variable `in_fragmented_record` in switch case `kFullType` block is assigned to false and then does `return` without use. In the other switch case `kFirstType` block the same `in_fragmented_record` is assigned to false, but later assigned to true without prior use. Removed assignment for both cases.
scan-build reprots:
http://home.fburl.com/~sugak/latest20/report-bb86b0.html#EndPath
http://home.fburl.com/~sugak/latest20/report-a975be.html#EndPath
**table/plain_table_key_coding.cc**
Local variable `user_key_size` is assigned when declared. But then in both places where it is used assigned to `static_cast<uint32_t>(key.size() - 8)`. Changed to initialize the variable to the proper value in declaration.
scan-build report:
http://home.fburl.com/~sugak/latest20/report-9e6b86.html#EndPath
**tools/db_stress.cc**
Missing `break` in switch case block. This seems to be a bug. Added missing `break`.
Test Plan:
Make sure all tests are passing and scan-build does not report 'Dead assignment' and 'Dead initialization' bugs.
```lang=bash
% make check
% make analyze
```
Reviewers: meyering, igor, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33795/"
rocksdb,"rocksdb: Add missing override
Summary:
When using latest clang (3.6 or 3.7/trunck) rocksdb is failing with many errors. Almost all of them are missing override errors. This diff adds missing override keyword. No manual changes.
Prerequisites: bear and clang 3.5 build with extra tools
```lang=bash
% USE_CLANG=1 bear make all # generate a compilation database http://clang.llvm.org/docs/JSONCompilationDatabase.html
% clang-modernize -p . -include . -add-override
% make format
```
Test Plan:
Make sure all tests are passing.
```lang=bash
% #Use default fb code clang.
% make check
```
Verify less error and no missing override errors.
```lang=bash
% # Have trunk clang present in path.
% ROCKSDB_NO_FBCODE=1 CC=clang CXX=clang++ make
```
Reviewers: igor, kradhakrishnan, rven, meyering, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34077/"
rocksdb,"rocksdb: switch to gtest
Summary:
Our existing test notation is very similar to what is used in gtest. It makes it easy to adopt what is different.
In this diff I modify existing [[ https://code.google.com/p/googletest/wiki/Primer#Test_Fixtures:_Using_the_Same_Data_Configuration_for_Multiple_Te | test fixture ]] classes to inherit from `testing::Test`. Also for unit tests that use fixture class, `TEST` is replaced with `TEST_F` as required in gtest.
There are several custom `main` functions in our existing tests. To make this transition easier, I modify all `main` functions to fallow gtest notation. But eventually we can remove them and use implementation of `main` that gtest provides.
```lang=bash
% cat ~/transform
#!/bin/sh
files=$(git ls-files '*test\.cc')
for file in $files
do
if grep -q ""rocksdb::test::RunAllTests()"" $file
then
if grep -Eq '^class \w+Test {' $file
then
perl -pi -e 's/^(class \w+Test) {/${1}: public testing::Test {/g' $file
perl -pi -e 's/^(TEST)/${1}_F/g' $file
fi
perl -pi -e 's/(int main.*\{)/${1}::testing::InitGoogleTest(&argc, argv);/g' $file
perl -pi -e 's/rocksdb::test::RunAllTests/RUN_ALL_TESTS/g' $file
fi
done
% sh ~/transform
% make format
```
Second iteration of this diff contains only scripted changes.
Third iteration contains manual changes to fix last errors and make it compilable.
Test Plan:
Build and notice no errors.
```lang=bash
% USE_CLANG=1 make check -j55
```
Tests are still testing.
Reviewers: meyering, sdong, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D35157/"
rocksdb,"Merge pull request #593 from charsyam/feature/type-1
fix typos/fix typos/"
rocksdb,"Fix flakiness of WalManagerTest
Summary: We should use mocked-out env for these tests to make it more realiable. Added benefit is that instead of actually sleeping for 3 seconds, we can instead pretend to sleep and just increase time counters.
Test Plan: for i in `seq 100`; do ./wal_manager_test --gtest_filter=WalManagerTest.WALArchivalTtl ;done
Reviewers: rven, meyering
Reviewed By: meyering
Subscribers: meyering, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D36951/rocksdb: Add missing override
Summary:
When using latest clang (3.6 or 3.7/trunck) rocksdb is failing with many errors. Almost all of them are missing override errors. This diff adds missing override keyword. No manual changes.
Prerequisites: bear and clang 3.5 build with extra tools
```lang=bash
% USE_CLANG=1 bear make all # generate a compilation database http://clang.llvm.org/docs/JSONCompilationDatabase.html
% clang-modernize -p . -include . -add-override
% make format
```
Test Plan:
Make sure all tests are passing.
```lang=bash
% #Use default fb code clang.
% make check
```
Verify less error and no missing override errors.
```lang=bash
% # Have trunk clang present in path.
% ROCKSDB_NO_FBCODE=1 CC=clang CXX=clang++ make
```
Reviewers: igor, kradhakrishnan, rven, meyering, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34077/"
rocksdb,"Don't do O(N^2) operations in debug mode for vector memtable
Summary: As title. For every operation we're asserting Valid(), which sorts the data. That's pretty terrible. We have to be careful to have decent performance even with DEBUG builds.
Test Plan: make check
Reviewers: sdong, rven, yhchiang, MarkCallaghan
Reviewed By: MarkCallaghan
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D36969/"
rocksdb,"rocksdb: Add missing override
Summary:
When using latest clang (3.6 or 3.7/trunck) rocksdb is failing with many errors. Almost all of them are missing override errors. This diff adds missing override keyword. No manual changes.
Prerequisites: bear and clang 3.5 build with extra tools
```lang=bash
% USE_CLANG=1 bear make all # generate a compilation database http://clang.llvm.org/docs/JSONCompilationDatabase.html
% clang-modernize -p . -include . -add-override
% make format
```
Test Plan:
Make sure all tests are passing.
```lang=bash
% #Use default fb code clang.
% make check
```
Verify less error and no missing override errors.
```lang=bash
% # Have trunk clang present in path.
% ROCKSDB_NO_FBCODE=1 CC=clang CXX=clang++ make
```
Reviewers: igor, kradhakrishnan, rven, meyering, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34077/"
rocksdb,"rocksdb: switch to gtest
Summary:
Our existing test notation is very similar to what is used in gtest. It makes it easy to adopt what is different.
In this diff I modify existing [[ https://code.google.com/p/googletest/wiki/Primer#Test_Fixtures:_Using_the_Same_Data_Configuration_for_Multiple_Te | test fixture ]] classes to inherit from `testing::Test`. Also for unit tests that use fixture class, `TEST` is replaced with `TEST_F` as required in gtest.
There are several custom `main` functions in our existing tests. To make this transition easier, I modify all `main` functions to fallow gtest notation. But eventually we can remove them and use implementation of `main` that gtest provides.
```lang=bash
% cat ~/transform
#!/bin/sh
files=$(git ls-files '*test\.cc')
for file in $files
do
if grep -q ""rocksdb::test::RunAllTests()"" $file
then
if grep -Eq '^class \w+Test {' $file
then
perl -pi -e 's/^(class \w+Test) {/${1}: public testing::Test {/g' $file
perl -pi -e 's/^(TEST)/${1}_F/g' $file
fi
perl -pi -e 's/(int main.*\{)/${1}::testing::InitGoogleTest(&argc, argv);/g' $file
perl -pi -e 's/rocksdb::test::RunAllTests/RUN_ALL_TESTS/g' $file
fi
done
% sh ~/transform
% make format
```
Second iteration of this diff contains only scripted changes.
Third iteration contains manual changes to fix last errors and make it compilable.
Test Plan:
Build and notice no errors.
```lang=bash
% USE_CLANG=1 make check -j55
```
Tests are still testing.
Reviewers: meyering, sdong, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D35157/rocksdb: Add missing override
Summary:
When using latest clang (3.6 or 3.7/trunck) rocksdb is failing with many errors. Almost all of them are missing override errors. This diff adds missing override keyword. No manual changes.
Prerequisites: bear and clang 3.5 build with extra tools
```lang=bash
% USE_CLANG=1 bear make all # generate a compilation database http://clang.llvm.org/docs/JSONCompilationDatabase.html
% clang-modernize -p . -include . -add-override
% make format
```
Test Plan:
Make sure all tests are passing.
```lang=bash
% #Use default fb code clang.
% make check
```
Verify less error and no missing override errors.
```lang=bash
% # Have trunk clang present in path.
% ROCKSDB_NO_FBCODE=1 CC=clang CXX=clang++ make
```
Reviewers: igor, kradhakrishnan, rven, meyering, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34077/"
rocksdb,"Using chrono as a fallback
Summary:
Right now if they system we are compiling on is not Linux and not Mac we will get a compilation error
this diff use chrono as a fallback when we are compiling on something other than Linux/FreeBSD/Mac
Test Plan:
compile on CentOS/FreeBSD
./db_test (still running)
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D35277/Merge pull request #540 from dalgaaf/wip-da-fix-elif
Fix '#elif with no expression'/util/env_posix.cc: fix #elif check for __MACH__
Fix '#elif with no expression' add defined() to check.
Signed-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>/Revert chrono use
Summary:
For some reason, libstdc++ implements steady_clock::now() using syscall instead of VDSO optimized clock_gettime() when using glibc 2.16 and earlier. This leads to significant performance degradation for users with older glibcs. See bug reported here: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=59177
We observed this behavior when testing mongo on AWS hosts. Facebook hosts are unaffected since we use glibc2.17 and 2.20.
Revert ""Fix timing""
This reverts commit 965d9d50b8cbb413de5e834b5b83ddbb682d0f1d.
Revert ""Use chrono for timing""
This reverts commit 001ce64dc7659c65569ffb1c440e26cd23db3c94.
Test Plan: make check
Reviewers: MarkCallaghan, yhchiang, rven, meyering, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34371/rocksdb: Add missing override
Summary:
When using latest clang (3.6 or 3.7/trunck) rocksdb is failing with many errors. Almost all of them are missing override errors. This diff adds missing override keyword. No manual changes.
Prerequisites: bear and clang 3.5 build with extra tools
```lang=bash
% USE_CLANG=1 bear make all # generate a compilation database http://clang.llvm.org/docs/JSONCompilationDatabase.html
% clang-modernize -p . -include . -add-override
% make format
```
Test Plan:
Make sure all tests are passing.
```lang=bash
% #Use default fb code clang.
% make check
```
Verify less error and no missing override errors.
```lang=bash
% # Have trunk clang present in path.
% ROCKSDB_NO_FBCODE=1 CC=clang CXX=clang++ make
```
Reviewers: igor, kradhakrishnan, rven, meyering, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34077/rocksdb: Fix 'Division by zero' scan-build warning
Summary:
scan-build complains with division by zero warning in a test. Added an assertion to prevent this.
scan-build report: http://home.fburl.com/~sugak/latest6/report-c61be9.html#EndPath
Test Plan:
Make sure scan-build does not report 'Division by zero' and all tests are passing.
```lang=bash
% make analyze
% make check
```
Reviewers: igor, meyering
Reviewed By: meyering
Subscribers: sdong, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33495/"
rocksdb,"Merge pull request #601 from adamretter/jdb-bench
Small fixes to Java benchmark/Bugfix remove deprecated option use which was removed in previous commit 019ecd19329ee895284e9b040df0ffe4c08b35d8/Fix conversion from nano-seconds to milli-seconds and seconds/Merge pull request #524 from fyrz/RocksJava-Test-Fix
[RocksJava] Fix JTest issues with enabled assertions.
Closes https://github.com/facebook/rocksdb/issues/523/RocksJava] Fix ColumnFamily tests
Summary:
Cleaned up some tests regarding disposal order and tests
which were failing when C++ assertions were enabled.
Test Plan:
- Enable C++ Assertions (remove e.g. -DNDebug in rocksdbjava target)
- make rocksdbjava jtest
Reviewers: adamretter, ankgup87, yhchiang
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D34569/"
rocksdb,"[RocksJava] 32-Bit adjustments
Summary:
Before this change overflowing size_t values led to a checked Exception.
After that change:
size_t overflows on 32-Bit architecture throw now an IllegalArgumentException,
which removes the necessity for a developer to catch these Exceptions explicitly.
This is especially an advantage for developers targeting 64-Bit systems because
it is not necessary anymore to catch exceptions which are never thrown on a 64-Bit
system.
Test Plan:
make clean jclean rocksdbjava jtest
mvn -f rocksjni.pom package
Reviewers: adamretter, yhchiang, ankgup87
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D34923/"
rocksdb,"[RocksJava] Raw use of parametrized class
Resolved raw use of parametrized class issues./"
rocksdb,"[RocksJava] 32-Bit adjustments
Summary:
Before this change overflowing size_t values led to a checked Exception.
After that change:
size_t overflows on 32-Bit architecture throw now an IllegalArgumentException,
which removes the necessity for a developer to catch these Exceptions explicitly.
This is especially an advantage for developers targeting 64-Bit systems because
it is not necessary anymore to catch exceptions which are never thrown on a 64-Bit
system.
Test Plan:
make clean jclean rocksdbjava jtest
mvn -f rocksjni.pom package
Reviewers: adamretter, yhchiang, ankgup87
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D34923/"
rocksdb,"[RocksJava] Raw use of parametrized class
Resolved raw use of parametrized class issues./"
rocksdb,"[RocksJava] Raw use of parametrized class
Resolved raw use of parametrized class issues./"
rocksdb,"Merge pull request #524 from fyrz/RocksJava-Test-Fix
[RocksJava] Fix JTest issues with enabled assertions.
Closes https://github.com/facebook/rocksdb/issues/523/[RocksJava] DefaultColumnFamily Memory Fix
In the current implementation DefaultColumnFamily will not disown
the native handle. As the database handles the lease on the native
handle this should be the case./"
rocksdb,"[RocksJava] 32-Bit adjustments
Summary:
Before this change overflowing size_t values led to a checked Exception.
After that change:
size_t overflows on 32-Bit architecture throw now an IllegalArgumentException,
which removes the necessity for a developer to catch these Exceptions explicitly.
This is especially an advantage for developers targeting 64-Bit systems because
it is not necessary anymore to catch exceptions which are never thrown on a 64-Bit
system.
Test Plan:
make clean jclean rocksdbjava jtest
mvn -f rocksjni.pom package
Reviewers: adamretter, yhchiang, ankgup87
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D34923/"
rocksdb,"[RocksJava] Remove deprecated methods
Summary:
- Removed deprecated ColumnFamilyDescript constructor methods
- Removed deprecated skipLogErrorOnRecovery methods
- Removed deprecated tableCacheRemoveScanCountLimit methods
Test Plan:
make rocksdbjava
make jtest
Reviewers: yhchiang, adamretter, ankgup87
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D37191/[RocksJava] Removed deprecated skipLogErrorOnRecovery methods.
As annonunced these options are not used anymore so these are
removed from code./[RocksJava] 32-Bit adjustments
Summary:
Before this change overflowing size_t values led to a checked Exception.
After that change:
size_t overflows on 32-Bit architecture throw now an IllegalArgumentException,
which removes the necessity for a developer to catch these Exceptions explicitly.
This is especially an advantage for developers targeting 64-Bit systems because
it is not necessary anymore to catch exceptions which are never thrown on a 64-Bit
system.
Test Plan:
make clean jclean rocksdbjava jtest
mvn -f rocksjni.pom package
Reviewers: adamretter, yhchiang, ankgup87
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D34923/[RocksJava] Raw use of parametrized class
Resolved raw use of parametrized class issues./"
rocksdb,"[RocksJava] Remove deprecated methods
Summary:
- Removed deprecated ColumnFamilyDescript constructor methods
- Removed deprecated skipLogErrorOnRecovery methods
- Removed deprecated tableCacheRemoveScanCountLimit methods
Test Plan:
make rocksdbjava
make jtest
Reviewers: yhchiang, adamretter, ankgup87
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D37191/[RocksJava] Removed deprecated skipLogErrorOnRecovery methods.
As annonunced these options are not used anymore so these are
removed from code./[RocksJava] 32-Bit adjustments
Summary:
Before this change overflowing size_t values led to a checked Exception.
After that change:
size_t overflows on 32-Bit architecture throw now an IllegalArgumentException,
which removes the necessity for a developer to catch these Exceptions explicitly.
This is especially an advantage for developers targeting 64-Bit systems because
it is not necessary anymore to catch exceptions which are never thrown on a 64-Bit
system.
Test Plan:
make clean jclean rocksdbjava jtest
mvn -f rocksjni.pom package
Reviewers: adamretter, yhchiang, ankgup87
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D34923/"
rocksdb,"[RocksJava] 32-Bit adjustments
Summary:
Before this change overflowing size_t values led to a checked Exception.
After that change:
size_t overflows on 32-Bit architecture throw now an IllegalArgumentException,
which removes the necessity for a developer to catch these Exceptions explicitly.
This is especially an advantage for developers targeting 64-Bit systems because
it is not necessary anymore to catch exceptions which are never thrown on a 64-Bit
system.
Test Plan:
make clean jclean rocksdbjava jtest
mvn -f rocksjni.pom package
Reviewers: adamretter, yhchiang, ankgup87
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D34923/"
rocksdb,"[RocksJava] 32-Bit adjustments
Summary:
Before this change overflowing size_t values led to a checked Exception.
After that change:
size_t overflows on 32-Bit architecture throw now an IllegalArgumentException,
which removes the necessity for a developer to catch these Exceptions explicitly.
This is especially an advantage for developers targeting 64-Bit systems because
it is not necessary anymore to catch exceptions which are never thrown on a 64-Bit
system.
Test Plan:
make clean jclean rocksdbjava jtest
mvn -f rocksjni.pom package
Reviewers: adamretter, yhchiang, ankgup87
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D34923/"
rocksdb,"Merge pull request #528 from fyrz/RocksJava-NativeLibraryLoader
[RocksJava] Fix NativeLibraryLoader/[RocksJava] Fix NativeLibraryLoader
- Resolve problem while using a temporary data folder
- Fix test/"
rocksdb,"[RocksJava] 32-Bit adjustments
Summary:
Before this change overflowing size_t values led to a checked Exception.
After that change:
size_t overflows on 32-Bit architecture throw now an IllegalArgumentException,
which removes the necessity for a developer to catch these Exceptions explicitly.
This is especially an advantage for developers targeting 64-Bit systems because
it is not necessary anymore to catch exceptions which are never thrown on a 64-Bit
system.
Test Plan:
make clean jclean rocksdbjava jtest
mvn -f rocksjni.pom package
Reviewers: adamretter, yhchiang, ankgup87
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D34923/[RocksJava] Raw use of parametrized class
Resolved raw use of parametrized class issues./"
rocksdb,"rocksdb: switch to gtest
Summary:
Our existing test notation is very similar to what is used in gtest. It makes it easy to adopt what is different.
In this diff I modify existing [[ https://code.google.com/p/googletest/wiki/Primer#Test_Fixtures:_Using_the_Same_Data_Configuration_for_Multiple_Te | test fixture ]] classes to inherit from `testing::Test`. Also for unit tests that use fixture class, `TEST` is replaced with `TEST_F` as required in gtest.
There are several custom `main` functions in our existing tests. To make this transition easier, I modify all `main` functions to fallow gtest notation. But eventually we can remove them and use implementation of `main` that gtest provides.
```lang=bash
% cat ~/transform
#!/bin/sh
files=$(git ls-files '*test\.cc')
for file in $files
do
if grep -q ""rocksdb::test::RunAllTests()"" $file
then
if grep -Eq '^class \w+Test {' $file
then
perl -pi -e 's/^(class \w+Test) {/${1}: public testing::Test {/g' $file
perl -pi -e 's/^(TEST)/${1}_F/g' $file
fi
perl -pi -e 's/(int main.*\{)/${1}::testing::InitGoogleTest(&argc, argv);/g' $file
perl -pi -e 's/rocksdb::test::RunAllTests/RUN_ALL_TESTS/g' $file
fi
done
% sh ~/transform
% make format
```
Second iteration of this diff contains only scripted changes.
Third iteration contains manual changes to fix last errors and make it compilable.
Test Plan:
Build and notice no errors.
```lang=bash
% USE_CLANG=1 make check -j55
```
Tests are still testing.
Reviewers: meyering, sdong, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D35157/rocksdb: Add missing override
Summary:
When using latest clang (3.6 or 3.7/trunck) rocksdb is failing with many errors. Almost all of them are missing override errors. This diff adds missing override keyword. No manual changes.
Prerequisites: bear and clang 3.5 build with extra tools
```lang=bash
% USE_CLANG=1 bear make all # generate a compilation database http://clang.llvm.org/docs/JSONCompilationDatabase.html
% clang-modernize -p . -include . -add-override
% make format
```
Test Plan:
Make sure all tests are passing.
```lang=bash
% #Use default fb code clang.
% make check
```
Verify less error and no missing override errors.
```lang=bash
% # Have trunk clang present in path.
% ROCKSDB_NO_FBCODE=1 CC=clang CXX=clang++ make
```
Reviewers: igor, kradhakrishnan, rven, meyering, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34077/"
rocksdb,"Fix BackupEngine
Summary:
In D28521 we removed GarbageCollect() from BackupEngine's constructor. The reason was that opening BackupEngine on HDFS was very slow and in most cases we didn't have any garbage. We allowed the user to call GarbageCollect() when it detects some garbage files in his backup directory.
Unfortunately, this left us vulnerable to an interesting issue. Let's say we started a backup and copied files {1, 3} but the backup failed. On another host, we restore DB from backup and generate {1, 3, 5}. Since {1, 3} is already there, we will not overwrite. However, these files might be from a different database so their contents might be different. See internal task t6781803 for more info.
Now, when we're copying files and we discover a file already there, we check:
1. if the file is not referenced from any backups, we overwrite the file.
2. if the file is referenced from other backups AND the checksums don't match, we fail the backup. This will only happen if user is using a single backup directory for backing up two different databases.
3. if the file is referenced from other backups AND the checksums match, it's all good. We skip the copy and go copy the next file.
Test Plan: Added new test to backupable_db_test. The test fails before this patch.
Reviewers: sdong, rven, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37599/maint: use ASSERT_TRUE, not ASSERT_EQ(true; same for false
Summary:
The usage I'm fixing here caused trouble on Fedora 21 when
compiling with the current gcc version 4.9.2 20150212 (Red Hat 4.9.2-6) (GCC):
db/write_controller_test.cc: In member function virtual void rocksdb::WriteControllerTest_SanityTest_Test::TestBody():
db/write_controller_test.cc:23:165: error: converting false to pointer type for argument 1 of char testing::internal::IsNullLiteralHelper(testing::internal::Secret*) [-Werror=conversion-null]
ASSERT_EQ(false, controller.IsStopped());
^
This change was induced mechanically via:
git grep -l -E 'ASSERT_EQ\(false'|xargs perl -pi -e 's/ASSERT_EQ\(false, /ASSERT_FALSE(/'
git grep -l -E 'ASSERT_EQ\(true'|xargs perl -pi -e 's/ASSERT_EQ\(true, /ASSERT_TRUE(/'
Except for the three in utilities/backupable/backupable_db_test.cc for which
I ended up reformatting (joining lines) in the result.
As for why this problem is exhibited with that version of gcc, and none
of the others I've used (from 4.8.1 through gcc-5.0.0 and newer), I suspect
it's a bug in F21's gcc that has been fixed in gcc-5.0.0.
Test Plan:
""make"" now succeed on Fedora 21
Reviewers: ljin, rven, igor.sugak, yhchiang, sdong, igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D37329/rocksdb: switch to gtest
Summary:
Our existing test notation is very similar to what is used in gtest. It makes it easy to adopt what is different.
In this diff I modify existing [[ https://code.google.com/p/googletest/wiki/Primer#Test_Fixtures:_Using_the_Same_Data_Configuration_for_Multiple_Te | test fixture ]] classes to inherit from `testing::Test`. Also for unit tests that use fixture class, `TEST` is replaced with `TEST_F` as required in gtest.
There are several custom `main` functions in our existing tests. To make this transition easier, I modify all `main` functions to fallow gtest notation. But eventually we can remove them and use implementation of `main` that gtest provides.
```lang=bash
% cat ~/transform
#!/bin/sh
files=$(git ls-files '*test\.cc')
for file in $files
do
if grep -q ""rocksdb::test::RunAllTests()"" $file
then
if grep -Eq '^class \w+Test {' $file
then
perl -pi -e 's/^(class \w+Test) {/${1}: public testing::Test {/g' $file
perl -pi -e 's/^(TEST)/${1}_F/g' $file
fi
perl -pi -e 's/(int main.*\{)/${1}::testing::InitGoogleTest(&argc, argv);/g' $file
perl -pi -e 's/rocksdb::test::RunAllTests/RUN_ALL_TESTS/g' $file
fi
done
% sh ~/transform
% make format
```
Second iteration of this diff contains only scripted changes.
Third iteration contains manual changes to fix last errors and make it compilable.
Test Plan:
Build and notice no errors.
```lang=bash
% USE_CLANG=1 make check -j55
```
Tests are still testing.
Reviewers: meyering, sdong, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D35157/rocksdb: Replace ASSERT* with EXPECT* in functions that does not return void value
Summary:
gtest does not use exceptions to fail a unit test by design, and `ASSERT*`s are implemented using `return`. As a consequence we cannot use `ASSERT*` in a function that does not return `void` value ([[ https://code.google.com/p/googletest/wiki/AdvancedGuide#Assertion_Placement | 1]]), and have to fix our existing code. This diff does this in a generic way, with no manual changes.
In order to detect all existing `ASSERT*` that are used in functions that doesn't return void value, I change the code to generate compile errors for such cases.
In `util/testharness.h` I defined `EXPECT*` assertions, the same way as `ASSERT*`, and redefined `ASSERT*` to return `void`. Then executed:
```lang=bash
% USE_CLANG=1 make all -j55 -k 2> build.log
% perl -naF: -e 'print ""-- -number="".$F[1]."" "".$F[0].""\n"" if  /: error:/' \
build.log | xargs -L 1 perl -spi -e 's/ASSERT/EXPECT/g if $. == $number'
% make format
```
After that I reverted back change to `ASSERT*` in `util/testharness.h`. But preserved introduced `EXPECT*`, which is the same as `ASSERT*`. This will be deleted once switched to gtest.
This diff is independent and contains manual changes only in `util/testharness.h`.
Test Plan:
Make sure all tests are passing.
```lang=bash
% USE_CLANG=1 make check
```
Reviewers: igor, lgalanis, sdong, yufei.zhu, rven, meyering
Reviewed By: meyering
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33333/Fix a bug in ReadOnlyBackupEngine
Summary:
This diff fixes a bug introduced by D28521. Read-only backup engine can delete a backup that is later than the latest -- we never check the condition.
I also added a bunch of logging that will help with debugging cases like this in the future.
See more discussion at t6218248.
Test Plan: Added a unit test that was failing before the change. Also, see new LOG file contents: https://phabricator.fb.com/P19738984
Reviewers: benj, sanketh, sumeet, yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33897/rocksdb: Add missing override
Summary:
When using latest clang (3.6 or 3.7/trunck) rocksdb is failing with many errors. Almost all of them are missing override errors. This diff adds missing override keyword. No manual changes.
Prerequisites: bear and clang 3.5 build with extra tools
```lang=bash
% USE_CLANG=1 bear make all # generate a compilation database http://clang.llvm.org/docs/JSONCompilationDatabase.html
% clang-modernize -p . -include . -add-override
% make format
```
Test Plan:
Make sure all tests are passing.
```lang=bash
% #Use default fb code clang.
% make check
```
Verify less error and no missing override errors.
```lang=bash
% # Have trunk clang present in path.
% ROCKSDB_NO_FBCODE=1 CC=clang CXX=clang++ make
```
Reviewers: igor, kradhakrishnan, rven, meyering, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34077/"
rocksdb,"Fix compile
Summary: as title, we have unused variables. this is a short-term solution
Test Plan: compiles
Reviewers: IslamAbdelRahman, sdong, rven
Reviewed By: rven
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34125/Return fbson
Summary: mac compile is fixed in fbson, so it can be returned back from 7ce1b2c
Test Plan:
make all check
make valgrind_check
Reviewers: golovachalexander, igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D33855/rocksdb: Add missing override
Summary:
When using latest clang (3.6 or 3.7/trunck) rocksdb is failing with many errors. Almost all of them are missing override errors. This diff adds missing override keyword. No manual changes.
Prerequisites: bear and clang 3.5 build with extra tools
```lang=bash
% USE_CLANG=1 bear make all # generate a compilation database http://clang.llvm.org/docs/JSONCompilationDatabase.html
% clang-modernize -p . -include . -add-override
% make format
```
Test Plan:
Make sure all tests are passing.
```lang=bash
% #Use default fb code clang.
% make check
```
Verify less error and no missing override errors.
```lang=bash
% # Have trunk clang present in path.
% ROCKSDB_NO_FBCODE=1 CC=clang CXX=clang++ make
```
Reviewers: igor, kradhakrishnan, rven, meyering, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34077/"
rocksdb,"Fix build
Test Plan: Running make all
Reviewers: sdong
Reviewed By: sdong
Subscribers: rven, yhchiang, igor, meyering, dhruba
Differential Revision: https://reviews.facebook.net/D35889/"
rocksdb,"rocksdb: switch to gtest
Summary:
Our existing test notation is very similar to what is used in gtest. It makes it easy to adopt what is different.
In this diff I modify existing [[ https://code.google.com/p/googletest/wiki/Primer#Test_Fixtures:_Using_the_Same_Data_Configuration_for_Multiple_Te | test fixture ]] classes to inherit from `testing::Test`. Also for unit tests that use fixture class, `TEST` is replaced with `TEST_F` as required in gtest.
There are several custom `main` functions in our existing tests. To make this transition easier, I modify all `main` functions to fallow gtest notation. But eventually we can remove them and use implementation of `main` that gtest provides.
```lang=bash
% cat ~/transform
#!/bin/sh
files=$(git ls-files '*test\.cc')
for file in $files
do
if grep -q ""rocksdb::test::RunAllTests()"" $file
then
if grep -Eq '^class \w+Test {' $file
then
perl -pi -e 's/^(class \w+Test) {/${1}: public testing::Test {/g' $file
perl -pi -e 's/^(TEST)/${1}_F/g' $file
fi
perl -pi -e 's/(int main.*\{)/${1}::testing::InitGoogleTest(&argc, argv);/g' $file
perl -pi -e 's/rocksdb::test::RunAllTests/RUN_ALL_TESTS/g' $file
fi
done
% sh ~/transform
% make format
```
Second iteration of this diff contains only scripted changes.
Third iteration contains manual changes to fix last errors and make it compilable.
Test Plan:
Build and notice no errors.
```lang=bash
% USE_CLANG=1 make check -j55
```
Tests are still testing.
Reviewers: meyering, sdong, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D35157/"
rocksdb,"SyncPoint to allow a callback with an argument and use it to get DBTest.DynamicLevelCompressionPerLevel2 more straight-forward
Summary:
Allow users to give a callback function with parameter using sync point, so more complicated verification can be done in tests.
Use it in DBTest.DynamicLevelCompressionPerLevel2 so that failures will be more easy to debug.
Test Plan: Run all tests. Run DBTest.DynamicLevelCompressionPerLevel2 with valgrind check.
Reviewers: rven, yhchiang, anthony, kradhakrishnan, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D36999/"
rocksdb,"Merge pull request #593 from charsyam/feature/type-1
fix typos/fix typos/rocksdb: Fix scan-build memory warning in table/block_based_table_reader.cc
Summary:
scan-build is reporting two memory leak bugs in `table/block_based_table_reader.cc`. They are both false positives. In both cases we allocate memory in `ReadBlockFromFile` if `s.ok()`. Then after the function `ReadBlockFromFile` returns we check for the same variable if `s.ok()` and then use the memory that was allocated. The bugs reported by scan-build is if `ReadBlockFromFile` allocates memory and returns, but for some reason status `s` is not the same and `s.ok() != true`.
In this case scan-build is concerned that memory owner transfer is not explicit. I modified `ReadBlockFromFile` to accept `std::unique_ptr<Block>*` as a parameter, instead of raw pointer.
scan-build reports:
http://home.fburl.com/~sugak/latest2/report-a4b3fa.html#EndPath
http://home.fburl.com/~sugak/latest2/report-29adbf.html#EndPath
Test Plan:
Make sure scan-build does not report these bugs and all tests are passing.
```lang=bash
% make check
% make analyze
```
Reviewers: sdong, lgalanis, meyering, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33681/"
rocksdb,"Avoid naming conflict of EntryType
Summary:
Fix build break on travis build:
$ OPT=-DTRAVIS V=1 make unity && make clean && OPT=-DTRAVIS V=1 make db_test && ./db_test
......
In file included from unity.cc:65:0:
./table/plain_table_key_coding.cc: In member function rocksdb::Status rocksdb::PlainTableKeyDecoder::NextPrefixEncodingKey(const char*, const char*, rocksdb::ParsedInternalKey*, rocksdb::Slice*, size_t*, bool*):
./table/plain_table_key_coding.cc:224:3: error: reference to EntryType is ambiguous
EntryType entry_type;
^
In file included from ./db/table_properties_collector.h:9:0,
from ./db/builder.h:11,
from ./db/builder.cc:10,
from unity.cc:1:
./include/rocksdb/table_properties.h:81:6: note: candidates are: enum rocksdb::EntryType
enum EntryType {
^
In file included from unity.cc:65:0:
./table/plain_table_key_coding.cc:16:6: note:                 enum rocksdb::{anonymous}::EntryType
enum EntryType : unsigned char {
^
./table/plain_table_key_coding.cc:231:51: error: entry_type was not declared in this scope
const char* pos = DecodeSize(key_ptr, limit, &entry_type, &size);
^
make: *** [unity.o] Error 1
Test Plan:
OPT=-DTRAVIS V=1 make unity
And make sure it doesn't break anymore.
Reviewers: yhchiang, kradhakrishnan, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D36549/rocksdb: Fixed 'Dead assignment' and 'Dead initialization' scan-build warnings
Summary:
This diff contains trivial fixes for 6 scan-build warnings:
**db/c_test.c**
`db` variable is never read. Removed assignment.
scan-build report:
http://home.fburl.com/~sugak/latest20/report-9b77d2.html#EndPath
**db/db_iter.cc**
`skipping` local variable is assigned to false. Then in the next switch block the only ""non return"" case assign `skipping` to true, the rest cases don't use it and all do return.
scan-build report:
http://home.fburl.com/~sugak/latest20/report-13fca7.html#EndPath
**db/log_reader.cc**
In `bool Reader::SkipToInitialBlock()` `offset_in_block` local variable is assigned to 0 `if (offset_in_block > kBlockSize - 6)` and then never used. Removed the assignment and renamed it to `initial_offset_in_block` to avoid confusion.
scan-build report:
http://home.fburl.com/~sugak/latest20/report-a618dd.html#EndPath
In `bool Reader::ReadRecord(Slice* record, std::string* scratch)` local variable `in_fragmented_record` in switch case `kFullType` block is assigned to false and then does `return` without use. In the other switch case `kFirstType` block the same `in_fragmented_record` is assigned to false, but later assigned to true without prior use. Removed assignment for both cases.
scan-build reprots:
http://home.fburl.com/~sugak/latest20/report-bb86b0.html#EndPath
http://home.fburl.com/~sugak/latest20/report-a975be.html#EndPath
**table/plain_table_key_coding.cc**
Local variable `user_key_size` is assigned when declared. But then in both places where it is used assigned to `static_cast<uint32_t>(key.size() - 8)`. Changed to initialize the variable to the proper value in declaration.
scan-build report:
http://home.fburl.com/~sugak/latest20/report-9e6b86.html#EndPath
**tools/db_stress.cc**
Missing `break` in switch case block. This seems to be a bug. Added missing `break`.
Test Plan:
Make sure all tests are passing and scan-build does not report 'Dead assignment' and 'Dead initialization' bugs.
```lang=bash
% make check
% make analyze
```
Reviewers: meyering, igor, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33795/build: remove always-true assertions
Summary:
Remove some always-true assertions.
They provoke these compilation failures:
table/plain_table_key_coding.cc:279:20: error: comparison of unsigned expression >= 0 is always true [-Werror=type-limits]
db/version_set.cc:336:15: error: comparison of unsigned expression >= 0 is always true [-Werror=type-limits]
* table/plain_table_key_coding.cc (rocksdb): Remove assertion that
unsigned type variable is >= 0.
* db/version_set.cc (DoGenerateLevelFilesBrief): Likewise.
Test Plan:
Run ""make EXTRA_CXXFLAGS='-W -Wextra'"" and see fewer errors.
Reviewers: ljin, sdong, igor.sugak, igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D33747/"
rocksdb,"Merge pull request #593 from charsyam/feature/type-1
fix typos/fix typos/"
rocksdb,"rocksdb: switch to gtest
Summary:
Our existing test notation is very similar to what is used in gtest. It makes it easy to adopt what is different.
In this diff I modify existing [[ https://code.google.com/p/googletest/wiki/Primer#Test_Fixtures:_Using_the_Same_Data_Configuration_for_Multiple_Te | test fixture ]] classes to inherit from `testing::Test`. Also for unit tests that use fixture class, `TEST` is replaced with `TEST_F` as required in gtest.
There are several custom `main` functions in our existing tests. To make this transition easier, I modify all `main` functions to fallow gtest notation. But eventually we can remove them and use implementation of `main` that gtest provides.
```lang=bash
% cat ~/transform
#!/bin/sh
files=$(git ls-files '*test\.cc')
for file in $files
do
if grep -q ""rocksdb::test::RunAllTests()"" $file
then
if grep -Eq '^class \w+Test {' $file
then
perl -pi -e 's/^(class \w+Test) {/${1}: public testing::Test {/g' $file
perl -pi -e 's/^(TEST)/${1}_F/g' $file
fi
perl -pi -e 's/(int main.*\{)/${1}::testing::InitGoogleTest(&argc, argv);/g' $file
perl -pi -e 's/rocksdb::test::RunAllTests/RUN_ALL_TESTS/g' $file
fi
done
% sh ~/transform
% make format
```
Second iteration of this diff contains only scripted changes.
Third iteration contains manual changes to fix last errors and make it compilable.
Test Plan:
Build and notice no errors.
```lang=bash
% USE_CLANG=1 make check -j55
```
Tests are still testing.
Reviewers: meyering, sdong, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D35157/"
rocksdb,"rocksdb: Remove #include ""util/string_util.h"" from util/testharness.h
Summary:
1. Manually deleted #include ""util/string_util.h"" from util/testharness.h
2.
```
% USE_CLANG=1 make all -j55 -k 2> build.log
% perl -naF: -E 'say $F[0] if /: error:/' build.log | sort -u | xargs sed -i '/#include ""util\/testharness.h""/i #include ""util\/string_util.h""'
```
Test Plan:
Make sure make all completes with no errors.
```
% make all -j55
```
Reviewers: meyering, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D35493/rocksdb: switch to gtest
Summary:
Our existing test notation is very similar to what is used in gtest. It makes it easy to adopt what is different.
In this diff I modify existing [[ https://code.google.com/p/googletest/wiki/Primer#Test_Fixtures:_Using_the_Same_Data_Configuration_for_Multiple_Te | test fixture ]] classes to inherit from `testing::Test`. Also for unit tests that use fixture class, `TEST` is replaced with `TEST_F` as required in gtest.
There are several custom `main` functions in our existing tests. To make this transition easier, I modify all `main` functions to fallow gtest notation. But eventually we can remove them and use implementation of `main` that gtest provides.
```lang=bash
% cat ~/transform
#!/bin/sh
files=$(git ls-files '*test\.cc')
for file in $files
do
if grep -q ""rocksdb::test::RunAllTests()"" $file
then
if grep -Eq '^class \w+Test {' $file
then
perl -pi -e 's/^(class \w+Test) {/${1}: public testing::Test {/g' $file
perl -pi -e 's/^(TEST)/${1}_F/g' $file
fi
perl -pi -e 's/(int main.*\{)/${1}::testing::InitGoogleTest(&argc, argv);/g' $file
perl -pi -e 's/rocksdb::test::RunAllTests/RUN_ALL_TESTS/g' $file
fi
done
% sh ~/transform
% make format
```
Second iteration of this diff contains only scripted changes.
Third iteration contains manual changes to fix last errors and make it compilable.
Test Plan:
Build and notice no errors.
```lang=bash
% USE_CLANG=1 make check -j55
```
Tests are still testing.
Reviewers: meyering, sdong, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D35157/rocksdb: Replace ASSERT* with EXPECT* in functions that does not return void value
Summary:
gtest does not use exceptions to fail a unit test by design, and `ASSERT*`s are implemented using `return`. As a consequence we cannot use `ASSERT*` in a function that does not return `void` value ([[ https://code.google.com/p/googletest/wiki/AdvancedGuide#Assertion_Placement | 1]]), and have to fix our existing code. This diff does this in a generic way, with no manual changes.
In order to detect all existing `ASSERT*` that are used in functions that doesn't return void value, I change the code to generate compile errors for such cases.
In `util/testharness.h` I defined `EXPECT*` assertions, the same way as `ASSERT*`, and redefined `ASSERT*` to return `void`. Then executed:
```lang=bash
% USE_CLANG=1 make all -j55 -k 2> build.log
% perl -naF: -e 'print ""-- -number="".$F[1]."" "".$F[0].""\n"" if  /: error:/' \
build.log | xargs -L 1 perl -spi -e 's/ASSERT/EXPECT/g if $. == $number'
% make format
```
After that I reverted back change to `ASSERT*` in `util/testharness.h`. But preserved introduced `EXPECT*`, which is the same as `ASSERT*`. This will be deleted once switched to gtest.
This diff is independent and contains manual changes only in `util/testharness.h`.
Test Plan:
Make sure all tests are passing.
```lang=bash
% USE_CLANG=1 make check
```
Reviewers: igor, lgalanis, sdong, yufei.zhu, rven, meyering
Reviewed By: meyering
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33333/rocksdb: Small refactoring before migrating to gtest
Summary: These changes are necessary to make tests look more generic, and avoid feature conflicts with gtest.
Test Plan:
Make sure no build errors, and all test are passing.
```
% make check
```
Reviewers: igor, meyering
Reviewed By: meyering
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D35145/rocksdb: Add missing override
Summary:
When using latest clang (3.6 or 3.7/trunck) rocksdb is failing with many errors. Almost all of them are missing override errors. This diff adds missing override keyword. No manual changes.
Prerequisites: bear and clang 3.5 build with extra tools
```lang=bash
% USE_CLANG=1 bear make all # generate a compilation database http://clang.llvm.org/docs/JSONCompilationDatabase.html
% clang-modernize -p . -include . -add-override
% make format
```
Test Plan:
Make sure all tests are passing.
```lang=bash
% #Use default fb code clang.
% make check
```
Verify less error and no missing override errors.
```lang=bash
% # Have trunk clang present in path.
% ROCKSDB_NO_FBCODE=1 CC=clang CXX=clang++ make
```
Reviewers: igor, kradhakrishnan, rven, meyering, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34077/table_test.cc: add missing 5th arg in TestArgs initializer
Summary:
Adding -W and -Wextra to CXXFLAGS provoked this failure:
table/table_test.cc:1854:56: error: missing initializer for member rocksdb::TestArgs::format_version [-Werror=missing-field-initializers]
TestArgs args = { DB_TEST, false, 16, kNoCompression };
^
Add the missing, 5th value (format_version).
Test Plan:
Run ""make EXTRA_CXXFLAGS='-W -Wextra'"" and see fewer errors.
Reviewers: ljin, sdong, igor.sugak, igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D33765/"
rocksdb,"build: avoid unused-variable warning
Summary:
[noticed a new warning when building with the very latest gcc]
* db/memtablerep_bench.cc (FLAGS_env): Remove declaration
of unused varaible, to avoid this warning/error:
db/memtablerep_bench.cc:135:22: error: FLAGS_env defined but not\
used [-Werror=unused-variable]
static rocksdb::Env* FLAGS_env = rocksdb::Env::Default();
^
Test Plan: compile
Reviewers: ljin, rven, igor.sugak, yhchiang, sdong, igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D37983/"
rocksdb,"Add more table properties to EventLogger
Summary:
Example output:
{""time_micros"": 1431463794310521, ""job"": 353, ""event"": ""table_file_creation"", ""file_number"": 387, ""file_size"": 86937, ""table_info"": {""data_size"": ""81801"", ""index_size"": ""9751"", ""filter_size"": ""0"", ""raw_key_size"": ""23448"", ""raw_average_key_size"": ""24.000000"", ""raw_value_size"": ""990571"", ""raw_average_value_size"": ""1013.890481"", ""num_data_blocks"": ""245"", ""num_entries"": ""977"", ""filter_policy_name"": """", ""kDeletedKeys"": ""0""}}
Also fixed a bug where BuildTable() in recovery was passing Env::IOHigh argument into paranoid_checks_file parameter.
Test Plan: make check + check out the output in the log
Reviewers: sdong, rven, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D38343/fix crashes in stats and compaction filter for db_ttl_impl
Summary: fix crashes in stats and compaction filter for db_ttl_impl
Test Plan:
Ran build with lots of debugging
https://reviews.facebook.net/differential/diff/194175/
Reviewers: yhchiang, igor, rven
Reviewed By: igor
Subscribers: rven, dhruba
Differential Revision: https://reviews.facebook.net/D38001/Fix UNLIKELY parenthesis
Summary: Ooops :) status.ok() is acutally highly likely :)
Test Plan: none
Reviewers: rven, yhchiang, anthony
Reviewed By: anthony
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D38043/Fix hang with large write batches and column families.
Summary:
This diff fixes a hang reported by a Github user.
https://www.facebook.com/l.php?u=https%3A%2F%2Fgithub.com%2Ffacebook%2Frocksdb%2Fissues%2F595%23issuecomment-96983273&h=9AQFYOWlo
Multiple large write batches with column families cause a hang.
The issue was caused by not doing flushes/compaction when the
write controller was stopped.
Test Plan: Create a DBTest from the user's test case
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37929/Fix possible SIGSEGV in CompactRange (github issue #596)
Summary: For very detailed explanation of what's happening read this: https://github.com/facebook/rocksdb/issues/596
Test Plan: make check + new unit test
Reviewers: yhchiang, anthony, rven
Reviewed By: rven
Subscribers: adamretter, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37779/Include bunch of more events into EventLogger
Summary:
Added these events:
* Recovery start, finish and also when recovery creates a file
* Trivial move
* Compaction start, finish and when compaction creates a file
* Flush start, finish
Also includes small fix to EventLogger
Also added option ROCKSDB_PRINT_EVENTS_TO_STDOUT which is useful when we debug things. I've spent far too much time chasing LOG files.
Still didn't get sst table properties in JSON. They are written very deeply into the stack. I'll address in separate diff.
TODO:
* Write specification. Let's first use this for a while and figure out what's good data to put here, too. After that we'll write spec
* Write tools that parse and analyze LOGs. This can be in python or go. Good intern task.
Test Plan: Ran db_bench with ROCKSDB_PRINT_EVENTS_TO_STDOUT. Here's the output: https://phabricator.fb.com/P19811976
Reviewers: sdong, yhchiang, rven, MarkCallaghan, kradhakrishnan, anthony
Reviewed By: anthony
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37521/Fix CompactRange for universal compaction with num_levels > 1
Summary:
CompactRange for universal compaction with num_levels > 1 seems to have a bug. The unit test also has a bug so it doesn't capture the problem.
Fix it. Revert the compact range to the logic equivalent to num_levels=1. Always compact all files together.
It should also fix DBTest.IncreaseUniversalCompactionNumLevels. The issue was that options.write_buffer_size = 100 << 10 and options.write_buffer_size = 100 << 10 are not used in later test scenarios. So write_buffer_size of 4MB was used. The compaction trigger condition is not anymore obvious as expected.
Test Plan: Run the new test and all test suites
Reviewers: yhchiang, rven, kradhakrishnan, anthony, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D37551/Bug of trivial move of dynamic level
Summary: D36669 introduces a bug that trivial moved data is not going to specific level but the next level, which will incorrectly be level 1 for level 0 compaciton if base level is not level 1. Fixing it by appreciating the output level
Test Plan: Run all tests
Reviewers: MarkCallaghan, rven, yhchiang, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D37119/Make Compaction class easier to use
Summary:
The goal of this diff is to make Compaction class easier to use. This should also make new compaction algorithms easier to write (like CompactFiles from @yhchiang and dynamic leveled and multi-leveled universal from @sdong).
Here are couple of things demonstrating that Compaction class is hard to use:
1. we have two constructors of Compaction class
2. there's this thing called grandparents_, but it appears to only be setup for leveled compaction and not compactfiles
3. it's easy to introduce a subtle and dangerous bug like this: D36225
4. SetupBottomMostLevel() is hard to understand and it shouldn't be. See this comment: https://github.com/facebook/rocksdb/blob/afbafeaeaebfd27a0f3e992fee8e0c57d07658fa/db/compaction.cc#L236-L241. It also made it harder for @yhchiang to write CompactFiles, as evidenced by this: https://github.com/facebook/rocksdb/blob/afbafeaeaebfd27a0f3e992fee8e0c57d07658fa/db/compaction_picker.cc#L204-L210
The problem is that we create Compaction object, which holds a lot of state, and then pass it around to some functions. After those functions are done mutating, then we call couple of functions on Compaction object, like SetupBottommostLevel() and MarkFilesBeingCompacted(). It is very hard to see what's happening with all that Compaction's state while it's travelling across different functions. If you're writing a new PickCompaction() function you need to try really hard to understand what are all the functions you need to run on Compaction object and what state you need to setup.
My proposed solution is to make important parts of Compaction immutable after construction. PickCompaction() should calculate compaction inputs and then pass them onto Compaction object once they are finalized. That makes it easy to create a new compaction -- just provide all the parameters to the constructor and you're done. No need to call confusing functions after you created your object.
This diff doesn't fully achieve that goal, but it comes pretty close. Here are some of the changes:
* have one Compaction constructor instead of two.
* inputs_ is constant after construction
* MarkFilesBeingCompacted() is now private to Compaction class and automatically called on construction/destruction.
* SetupBottommostLevel() is gone. Compaction figures it out on its own based on the input.
* CompactionPicker's functions are not passing around Compaction object anymore. They are only passing around the state that they need.
Test Plan:
make check
make asan_check
make valgrind_check
Reviewers: rven, anthony, sdong, yhchiang
Reviewed By: yhchiang
Subscribers: sdong, yhchiang, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D36687/Fix a compile error in ROCKSDB_LITE in db/db_impl.cc
Summary:
Fix a compile error in ROCKSDB_LITE in db/db_impl.cc
related to internal_stats.
Test Plan: make OPT=-DROCKSDB_LITE shared_lib
Reviewers: sdong, igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D36819/Don't delete files when column family is dropped
Summary:
To understand the bug read t5943287 and check out the new test in column_family_test (ReadDroppedColumnFamily), iter 0.
RocksDB contract allowes you to read a drop column family as long as there is a live reference. However, since our iteration ignores dropped column families, AddLiveFiles() didn't mark files of a dropped column families as live. So we deleted them.
In this patch I no longer ignore dropped column families in the iteration. I think this behavior was confusing and it also led to this bug. Now if an iterator client wants to ignore dropped column families, he needs to do it explicitly.
Test Plan: Added a new unit test that is failing on master. Unit test succeeds now.
Reviewers: sdong, rven, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D32535/Remove unused parameter in CancelAllBackgroundWork
Summary: Some suggestions for cleanup from Igor.
Test Plan: Regression tests.
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D35169/Fixed a bug where CompactFiles won't delete obsolete files until flush.
Summary: Fixed a bug where CompactFiles won't delete obsolete files until flush.
Test Plan:
./compact_files_test
export ROCKSDB_TESTS=CompactFiles
./db_test
Reviewers: rven, sdong, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34671/Fix a bug in stall time counter.  Improve its output format.
Summary: Fix a bug in stall time counter.  Improve its output format.
Test Plan:
export ROCKSDB_TESTS=Timeout
./db_test
./db_bench --benchmarks=fillrandom --stats_interval=10000 --statistics=true --stats_per_interval=1 --num=1000000 --threads=4 --level0_stop_writes_trigger=3 --level0_slowdown_writes_trigger=2
sample output:
Uptime(secs): 35.8 total, 0.0 interval
Cumulative writes: 359590 writes, 359589 keys, 183047 batches, 2.0 writes per batch, 0.04 GB user ingest, stall seconds: 1786.008 ms
Cumulative WAL: 359591 writes, 183046 syncs, 1.96 writes per sync, 0.04 GB written
Interval writes: 253 writes, 253 keys, 128 batches, 2.0 writes per batch, 0.0 MB user ingest, stall time: 0 us
Interval WAL: 253 writes, 128 syncs, 1.96 writes per sync, 0.00 MB written
Reviewers: MarkCallaghan, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34275/options.level_compaction_dynamic_level_bytes to allow RocksDB to pick size bases of levels dynamically.
Summary:
When having fixed max_bytes_for_level_base, the ratio of size of largest level and the second one can range from 0 to the multiplier. This makes LSM tree frequently irregular and unpredictable. It can also cause poor space amplification in some cases.
In this improvement (proposed by Igor Kabiljo), we introduce a parameter option.level_compaction_use_dynamic_max_bytes. When turning it on, RocksDB is free to pick a level base in the range of (options.max_bytes_for_level_base/options.max_bytes_for_level_multiplier, options.max_bytes_for_level_base] so that real level ratios are close to options.max_bytes_for_level_multiplier.
Test Plan: New unit tests and pass tests suites including valgrind.
Reviewers: MarkCallaghan, rven, yhchiang, igor, ikabiljo
Reviewed By: ikabiljo
Subscribers: yoshinorim, ikabiljo, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D31437/Fix typo in log message
Summary:
fix typo
Task ID: #
Blame Rev:
Test Plan:
Revert Plan:
Database Impact:
Memcache Impact:
Other Notes:
EImportant:
- begin *PUBLIC* platform impact section -
Bugzilla: #
- end platform impact -
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D34251/rocksdb: Add missing override
Summary:
When using latest clang (3.6 or 3.7/trunck) rocksdb is failing with many errors. Almost all of them are missing override errors. This diff adds missing override keyword. No manual changes.
Prerequisites: bear and clang 3.5 build with extra tools
```lang=bash
% USE_CLANG=1 bear make all # generate a compilation database http://clang.llvm.org/docs/JSONCompilationDatabase.html
% clang-modernize -p . -include . -add-override
% make format
```
Test Plan:
Make sure all tests are passing.
```lang=bash
% #Use default fb code clang.
% make check
```
Verify less error and no missing override errors.
```lang=bash
% # Have trunk clang present in path.
% ROCKSDB_NO_FBCODE=1 CC=clang CXX=clang++ make
```
Reviewers: igor, kradhakrishnan, rven, meyering, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34077/catch config errors with L0 file count triggers
Test Plan: Run ""make clean && make all check""
Reviewers: rven, igor, yhchiang, kradhakrishnan, MarkCallaghan, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D33627/build: do not relink every single binary just for a timestamp
Summary:
Prior to this change, ""make check"" would always waste a lot of
time relinking 60+ binaries. With this change, it does that
only when the generated file, util/build_version.cc, changes,
and that happens only when the date changes or when the
current git SHA changes.
This change makes some other improvements: before, there was no
rule to build a deleted util/build_version.cc. If it was somehow
removed, any attempt to link a program would fail.
There is no longer any need for the separate file,
build_tools/build_detect_version.  Its functionality is
now in the Makefile.
* Makefile (DEPFILES): Don't filter-out util/build_version.cc.
No need, and besides, removing that dependency was wrong.
(date, git_sha, gen_build_version): New helper variables.
(util/build_version.cc): New rule, to create this file
and update it only if it would contain new information.
* build_tools/build_detect_platform: Remove file.
* db/db_impl.cc: Now, print only date (not the time).
* util/build_version.h (rocksdb_build_compile_time): Remove
declaration.  No longer used.
Test Plan:
- Run ""make check"" twice, and note that the second time no linking is performed.
- Remove util/build_version.cc and ensure that any ""make""
command regenerates it before doing anything else.
- Run this: strings librocksdb.a|grep _build_.
That prints output including the following:
rocksdb_build_git_date:2015-02-19
rocksdb_build_git_sha:2.8.fb-1792-g3cb6cc0
Reviewers: ljin, sdong, igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D33591/"
rocksdb,"rocksdb: Add missing override
Summary:
When using latest clang (3.6 or 3.7/trunck) rocksdb is failing with many errors. Almost all of them are missing override errors. This diff adds missing override keyword. No manual changes.
Prerequisites: bear and clang 3.5 build with extra tools
```lang=bash
% USE_CLANG=1 bear make all # generate a compilation database http://clang.llvm.org/docs/JSONCompilationDatabase.html
% clang-modernize -p . -include . -add-override
% make format
```
Test Plan:
Make sure all tests are passing.
```lang=bash
% #Use default fb code clang.
% make check
```
Verify less error and no missing override errors.
```lang=bash
% # Have trunk clang present in path.
% ROCKSDB_NO_FBCODE=1 CC=clang CXX=clang++ make
```
Reviewers: igor, kradhakrishnan, rven, meyering, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34077/maint: remove extraneous ""const"" attribute from return type
Summary:
The ""const"" attribute does not make sense on a return type,
and provokes a warning/error from gcc -W -Wextra.
Test Plan:
Run ""make EXTRA_CXXFLAGS='-W -Wextra'"" and see fewer errors.
Reviewers: ljin, sdong, igor.sugak, igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D33759/"
rocksdb,"Reset parent_index and base_index when picking files marked for compaction
Summary: This caused a crash of our MongoDB + RocksDB instance. PickCompactionBySize() sets its own parent_index. We never reset this parent_index when picking PickFilesMarkedForCompactionExperimental(). So we might end up doing SetupOtherInputs() with parent_index that was set by PickCompactionBySize, although we're using compaction calculated using PickFilesMarkedForCompactionExperimental.
Test Plan: Added a unit test that fails with assertion on master.
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D38337/Merge pull request #593 from charsyam/feature/type-1
fix typos/fix typos/Fix CompactRange for universal compaction with num_levels > 1
Summary:
CompactRange for universal compaction with num_levels > 1 seems to have a bug. The unit test also has a bug so it doesn't capture the problem.
Fix it. Revert the compact range to the logic equivalent to num_levels=1. Always compact all files together.
It should also fix DBTest.IncreaseUniversalCompactionNumLevels. The issue was that options.write_buffer_size = 100 << 10 and options.write_buffer_size = 100 << 10 are not used in later test scenarios. So write_buffer_size of 4MB was used. The compaction trigger condition is not anymore obvious as expected.
Test Plan: Run the new test and all test suites
Reviewers: yhchiang, rven, kradhakrishnan, anthony, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D37551/Add an assertion in CompactionPicker
Summary: Reading CompactionPicker I noticed this dangerous substraction of two unsigned integers. We should assert to mark this as safe.
Test Plan: make check
Reviewers: anthony, rven, yhchiang, sdong
Reviewed By: sdong
Subscribers: kradhakrishnan, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37041/Add experimental API MarkForCompaction()
Summary:
Some Mongo+Rocks datasets in Parse's environment are not doing compactions very frequently. During the quiet period (with no IO), we'd like to schedule compactions so that our reads become faster. Also, aggressively compacting during quiet periods helps when write bursts happen. In addition, we also want to compact files that are containing deleted key ranges (like old oplog keys).
All of this is currently not possible with CompactRange() because it's single-threaded and blocks all other compactions from happening. Running CompactRange() risks an issue of blocking writes because we generate too much Level 0 files before the compaction is over. Stopping writes is very dangerous because they hold transaction locks. We tried running manual compaction once on Mongo+Rocks and everything fell apart.
MarkForCompaction() solves all of those problems. This is very light-weight manual compaction. It is lower priority than automatic compactions, which means it shouldn't interfere with background process keeping the LSM tree clean. However, if no automatic compactions need to be run (or we have extra background threads available), we will start compacting files that are marked for compaction.
Test Plan: added a new unit test
Reviewers: yhchiang, rven, MarkCallaghan, sdong
Reviewed By: sdong
Subscribers: yoshinorim, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37083/Fix bug in ExpandWhileOverlapping()
Summary: If ExpandWhileOverlapping() we don't clear inputs. That's a bug introduced by my recent patch https://reviews.facebook.net/D36687. However, we have no tests covering ExpandWhileOverlapping(). I created a task t6771252 to add ExpandWhileOverlapping() tests.
Test Plan: make check
Reviewers: sdong, rven, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37077/SyncPoint to allow a callback with an argument and use it to get DBTest.DynamicLevelCompressionPerLevel2 more straight-forward
Summary:
Allow users to give a callback function with parameter using sync point, so more complicated verification can be done in tests.
Use it in DBTest.DynamicLevelCompressionPerLevel2 so that failures will be more easy to debug.
Test Plan: Run all tests. Run DBTest.DynamicLevelCompressionPerLevel2 with valgrind check.
Reviewers: rven, yhchiang, anthony, kradhakrishnan, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D36999/Fix compile warning on CLANG
Summary: oops
Test Plan: compiles now
Reviewers: sdong, yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D36867/Make Compaction class easier to use
Summary:
The goal of this diff is to make Compaction class easier to use. This should also make new compaction algorithms easier to write (like CompactFiles from @yhchiang and dynamic leveled and multi-leveled universal from @sdong).
Here are couple of things demonstrating that Compaction class is hard to use:
1. we have two constructors of Compaction class
2. there's this thing called grandparents_, but it appears to only be setup for leveled compaction and not compactfiles
3. it's easy to introduce a subtle and dangerous bug like this: D36225
4. SetupBottomMostLevel() is hard to understand and it shouldn't be. See this comment: https://github.com/facebook/rocksdb/blob/afbafeaeaebfd27a0f3e992fee8e0c57d07658fa/db/compaction.cc#L236-L241. It also made it harder for @yhchiang to write CompactFiles, as evidenced by this: https://github.com/facebook/rocksdb/blob/afbafeaeaebfd27a0f3e992fee8e0c57d07658fa/db/compaction_picker.cc#L204-L210
The problem is that we create Compaction object, which holds a lot of state, and then pass it around to some functions. After those functions are done mutating, then we call couple of functions on Compaction object, like SetupBottommostLevel() and MarkFilesBeingCompacted(). It is very hard to see what's happening with all that Compaction's state while it's travelling across different functions. If you're writing a new PickCompaction() function you need to try really hard to understand what are all the functions you need to run on Compaction object and what state you need to setup.
My proposed solution is to make important parts of Compaction immutable after construction. PickCompaction() should calculate compaction inputs and then pass them onto Compaction object once they are finalized. That makes it easy to create a new compaction -- just provide all the parameters to the constructor and you're done. No need to call confusing functions after you created your object.
This diff doesn't fully achieve that goal, but it comes pretty close. Here are some of the changes:
* have one Compaction constructor instead of two.
* inputs_ is constant after construction
* MarkFilesBeingCompacted() is now private to Compaction class and automatically called on construction/destruction.
* SetupBottommostLevel() is gone. Compaction figures it out on its own based on the input.
* CompactionPicker's functions are not passing around Compaction object anymore. They are only passing around the state that they need.
Test Plan:
make check
make asan_check
make valgrind_check
Reviewers: rven, anthony, sdong, yhchiang
Reviewed By: yhchiang
Subscribers: sdong, yhchiang, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D36687/options.level_compaction_dynamic_level_bytes to allow RocksDB to pick size bases of levels dynamically.
Summary:
When having fixed max_bytes_for_level_base, the ratio of size of largest level and the second one can range from 0 to the multiplier. This makes LSM tree frequently irregular and unpredictable. It can also cause poor space amplification in some cases.
In this improvement (proposed by Igor Kabiljo), we introduce a parameter option.level_compaction_use_dynamic_max_bytes. When turning it on, RocksDB is free to pick a level base in the range of (options.max_bytes_for_level_base/options.max_bytes_for_level_multiplier, options.max_bytes_for_level_base] so that real level ratios are close to options.max_bytes_for_level_multiplier.
Test Plan: New unit tests and pass tests suites including valgrind.
Reviewers: MarkCallaghan, rven, yhchiang, igor, ikabiljo
Reviewed By: ikabiljo
Subscribers: yoshinorim, ikabiljo, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D31437/"
rocksdb,"Fix make unity build compiler warning about ""stats"" shadowing global variable
Summary:
Fix the make unity build. The local stats variable name was shadowing a
global stats variable.
Test Plan:
Run the build
OPT=-DTRAVIS V=1 make unity
Reviewers: sdong, igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D36285/Make the benchmark scripts configurable and add tests
Summary:
This makes run_flash_bench.sh configurable. Previously it was hardwired for 1B keys and tests
ran for 12 hours each. That kept me from using it. This makes it configuable, adds more tests,
makes the duration per-test configurable and refactors the test scripts.
Adds the seekrandomwhilemerging test to db_bench which is the same as seekrandomwhilewriting except
the writer thread does Merge rather than Put.
Forces the stall-time column in compaction IO stats to use a fixed format (H:M:S) which makes
it easier to scrape and parse. Also adds an option to AppendHumanMicros to force a fixed format.
Sometimes automation and humans want different format.
Calls thread->stats.AddBytes(bytes); in db_bench for more tests to get the MB/sec summary
stats in the output at test end.
Adds the average ingest rate to compaction IO stats. Output now looks like:
https://gist.github.com/mdcallag/2bd64d18be1b93adc494
More information on the benchmark output is at https://gist.github.com/mdcallag/db43a58bd5ac624f01e1
For benchmark.sh changes default RocksDB configuration to reduce stalls:
* min_level_to_compress from 2 to 3
* hard_rate_limit from 2 to 3
* max_grandparent_overlap_factor and max_bytes_for_level_multiplier from 10 to 8
* L0 file count triggers from 4,8,12 to 4,12,20 for (start,stall,stop)
Task ID: #6596829
Blame Rev:
Test Plan:
run tools/run_flash_bench.sh
Revert Plan:
Database Impact:
Memcache Impact:
Other Notes:
EImportant:
- begin *PUBLIC* platform impact section -
Bugzilla: #
- end platform impact -
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D36075/Add a DB Property For Number of Deletions in Memtables
Summary: Add a DB property for number of deletions in memtables. It can sometimes help people debug slowness because of too many deletes.
Test Plan: Add test cases.
Reviewers: rven, yhchiang, kradhakrishnan, igor
Reviewed By: igor
Subscribers: leveldb, dhruba, yoshinorim
Differential Revision: https://reviews.facebook.net/D35247/Fix compaction IO stats to handle large file counts
Summary:
The output did not have space for 6-digit file counts or for 3-digit
counts of files being compacted. This adds space for that while preserving
existing alignment. See https://gist.github.com/mdcallag/0a61c6a18dd467224c11
Task ID: #
Blame Rev:
Test Plan:
run db_bench, look at output
Revert Plan:
Database Impact:
Memcache Impact:
Other Notes:
EImportant:
- begin *PUBLIC* platform impact section -
Bugzilla: #
- end platform impact -
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D35091/Stop printing per-level stall times.
Summary:
Per-level stall times are the suggested stall time, not the actual stall time so this change stops printing them
both in the per-level output lines and in the summary. Also changed output for total stall time to include units
in all cases. The new output looks like:
Level   Files   Size(MB) Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) Comp(cnt) Avg(sec) Stall(cnt)    RecordIn   RecordDrop
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
L0     4/1          7   0.8      0.0     0.0      0.0       0.6      0.6       0.0   0.0      0.0     12.9        50       352    0.141        882            0            0
L1     5/0          9   0.9      0.0     0.0      0.0       0.0      0.0       0.6   0.0      0.0      0.0         0         0    0.000          0            0            0
L2    54/0         99   1.0      0.0     0.0      0.0       0.0      0.0       0.6   0.0      0.0      0.0         0         0    0.000          0            0            0
L3   289/0        527   0.5      0.0     0.0      0.0       0.0      0.0       0.5   0.0      0.0      0.0         0         0    0.000          0            0            0
Sum   352/1        642   0.0      0.0     0.0      0.0       0.6      0.6       1.7   1.0      0.0     12.9        50       352    0.141        882            0            0
Int     0/0          0   0.0      0.0     0.0      0.0       0.0      0.0       0.0   1.0      0.0     15.5         0         3    0.118          7            0            0
Flush(GB): accumulative 0.627, interval 0.005
Stalls(count): 0 level0_slowdown, 0 level0_numfiles, 882 memtable_compaction, 0 leveln_slowdown_soft, 0 leveln_slowdown_hard
Task ID: #6493861
Blame Rev:
Test Plan:
run db_bench, look at output
Revert Plan:
Database Impact:
Memcache Impact:
Other Notes:
EImportant:
- begin *PUBLIC* platform impact section -
Bugzilla: #
- end platform impact -
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D35085/Fix a bug in stall time counter.  Improve its output format.
Summary: Fix a bug in stall time counter.  Improve its output format.
Test Plan:
export ROCKSDB_TESTS=Timeout
./db_test
./db_bench --benchmarks=fillrandom --stats_interval=10000 --statistics=true --stats_per_interval=1 --num=1000000 --threads=4 --level0_stop_writes_trigger=3 --level0_slowdown_writes_trigger=2
sample output:
Uptime(secs): 35.8 total, 0.0 interval
Cumulative writes: 359590 writes, 359589 keys, 183047 batches, 2.0 writes per batch, 0.04 GB user ingest, stall seconds: 1786.008 ms
Cumulative WAL: 359591 writes, 183046 syncs, 1.96 writes per sync, 0.04 GB written
Interval writes: 253 writes, 253 keys, 128 batches, 2.0 writes per batch, 0.0 MB user ingest, stall time: 0 us
Interval WAL: 253 writes, 128 syncs, 1.96 writes per sync, 0.00 MB written
Reviewers: MarkCallaghan, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34275/options.level_compaction_dynamic_level_bytes to allow RocksDB to pick size bases of levels dynamically.
Summary:
When having fixed max_bytes_for_level_base, the ratio of size of largest level and the second one can range from 0 to the multiplier. This makes LSM tree frequently irregular and unpredictable. It can also cause poor space amplification in some cases.
In this improvement (proposed by Igor Kabiljo), we introduce a parameter option.level_compaction_use_dynamic_max_bytes. When turning it on, RocksDB is free to pick a level base in the range of (options.max_bytes_for_level_base/options.max_bytes_for_level_multiplier, options.max_bytes_for_level_base] so that real level ratios are close to options.max_bytes_for_level_multiplier.
Test Plan: New unit tests and pass tests suites including valgrind.
Reviewers: MarkCallaghan, rven, yhchiang, igor, ikabiljo
Reviewed By: ikabiljo
Subscribers: yoshinorim, ikabiljo, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D31437/"
rocksdb,"Fix a compilation error in ROCKSDB_LITE in db/internal_stats.h
Summary:
Fix a compilation error in ROCKSDB_LITE in db/internal_stats.h
Other compilation errors will be fixed in a separate diff.
Test Plan: make OPT=-DROCKSDB_LITE
Reviewers: sdong, igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D36807/Add a DB Property For Number of Deletions in Memtables
Summary: Add a DB property for number of deletions in memtables. It can sometimes help people debug slowness because of too many deletes.
Test Plan: Add test cases.
Reviewers: rven, yhchiang, kradhakrishnan, igor
Reviewed By: igor
Subscribers: leveldb, dhruba, yoshinorim
Differential Revision: https://reviews.facebook.net/D35247/Stop printing per-level stall times.
Summary:
Per-level stall times are the suggested stall time, not the actual stall time so this change stops printing them
both in the per-level output lines and in the summary. Also changed output for total stall time to include units
in all cases. The new output looks like:
Level   Files   Size(MB) Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) Comp(cnt) Avg(sec) Stall(cnt)    RecordIn   RecordDrop
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
L0     4/1          7   0.8      0.0     0.0      0.0       0.6      0.6       0.0   0.0      0.0     12.9        50       352    0.141        882            0            0
L1     5/0          9   0.9      0.0     0.0      0.0       0.0      0.0       0.6   0.0      0.0      0.0         0         0    0.000          0            0            0
L2    54/0         99   1.0      0.0     0.0      0.0       0.0      0.0       0.6   0.0      0.0      0.0         0         0    0.000          0            0            0
L3   289/0        527   0.5      0.0     0.0      0.0       0.0      0.0       0.5   0.0      0.0      0.0         0         0    0.000          0            0            0
Sum   352/1        642   0.0      0.0     0.0      0.0       0.6      0.6       1.7   1.0      0.0     12.9        50       352    0.141        882            0            0
Int     0/0          0   0.0      0.0     0.0      0.0       0.0      0.0       0.0   1.0      0.0     15.5         0         3    0.118          7            0            0
Flush(GB): accumulative 0.627, interval 0.005
Stalls(count): 0 level0_slowdown, 0 level0_numfiles, 882 memtable_compaction, 0 leveln_slowdown_soft, 0 leveln_slowdown_hard
Task ID: #6493861
Blame Rev:
Test Plan:
run db_bench, look at output
Revert Plan:
Database Impact:
Memcache Impact:
Other Notes:
EImportant:
- begin *PUBLIC* platform impact section -
Bugzilla: #
- end platform impact -
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D35085/options.level_compaction_dynamic_level_bytes to allow RocksDB to pick size bases of levels dynamically.
Summary:
When having fixed max_bytes_for_level_base, the ratio of size of largest level and the second one can range from 0 to the multiplier. This makes LSM tree frequently irregular and unpredictable. It can also cause poor space amplification in some cases.
In this improvement (proposed by Igor Kabiljo), we introduce a parameter option.level_compaction_use_dynamic_max_bytes. When turning it on, RocksDB is free to pick a level base in the range of (options.max_bytes_for_level_base/options.max_bytes_for_level_multiplier, options.max_bytes_for_level_base] so that real level ratios are close to options.max_bytes_for_level_multiplier.
Test Plan: New unit tests and pass tests suites including valgrind.
Reviewers: MarkCallaghan, rven, yhchiang, igor, ikabiljo
Reviewed By: ikabiljo
Subscribers: yoshinorim, ikabiljo, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D31437/"
rocksdb,"DBTest.DynamicLevelMaxBytesBase2: remove an unnecesary check
Summary: DBTest.DynamicLevelMaxBytesBase2 has a check that is not necessary and may fail. Remove it, and add two unrelated check.
Test Plan: Run the test
Reviewers: yhchiang, rven, kradhakrishnan, anthony, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D38457/Fix clang build - add override
Summary: In new clang we need to add override to every overriden function
Test Plan: none
Reviewers: rven
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D38259/Fix hang with large write batches and column families.
Summary:
This diff fixes a hang reported by a Github user.
https://www.facebook.com/l.php?u=https%3A%2F%2Fgithub.com%2Ffacebook%2Frocksdb%2Fissues%2F595%23issuecomment-96983273&h=9AQFYOWlo
Multiple large write batches with column families cause a hang.
The issue was caused by not doing flushes/compaction when the
write controller was stopped.
Test Plan: Create a DBTest from the user's test case
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37929/Don't compact bottommost level in SuggestCompactRange
Summary: Before the fix we also marked the bottommost level for compaction. This is wrong because then RocksDB has N+1 levels instead of N as before the compaction.
Test Plan: SuggestCompactRangeTest in db_test
Reviewers: yhchiang, rven
Reviewed By: rven
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37869/Fix possible SIGSEGV in CompactRange (github issue #596)
Summary: For very detailed explanation of what's happening read this: https://github.com/facebook/rocksdb/issues/596
Test Plan: make check + new unit test
Reviewers: yhchiang, anthony, rven
Reviewed By: rven
Subscribers: adamretter, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37779/Merge pull request #593 from charsyam/feature/type-1
fix typos/fix typos/Fix CompactRange for universal compaction with num_levels > 1
Summary:
CompactRange for universal compaction with num_levels > 1 seems to have a bug. The unit test also has a bug so it doesn't capture the problem.
Fix it. Revert the compact range to the logic equivalent to num_levels=1. Always compact all files together.
It should also fix DBTest.IncreaseUniversalCompactionNumLevels. The issue was that options.write_buffer_size = 100 << 10 and options.write_buffer_size = 100 << 10 are not used in later test scenarios. So write_buffer_size of 4MB was used. The compaction trigger condition is not anymore obvious as expected.
Test Plan: Run the new test and all test suites
Reviewers: yhchiang, rven, kradhakrishnan, anthony, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D37551/Making PreShutdown tests more reliable.
Summary:
A couple of times on Travis, we have had the thread status say that there were no compactions done and since we assert for it, the test failed.
We now fix this by waiting till compaction started.
Test Plan:
run DBTEST::*PreShutdown*
d=/tmp/j; rm -rf $d; seq 200 | parallel --gnu --eta 'd=/tmp/j/d-{}; mkdir -p $d; TEST_TMPDIR=$d ./db_test --gtest_filter=DBTest.PreShutdown* >& '$d'/log-{}'
Reviewers: sdong, igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D37545/Add experimental API MarkForCompaction()
Summary:
Some Mongo+Rocks datasets in Parse's environment are not doing compactions very frequently. During the quiet period (with no IO), we'd like to schedule compactions so that our reads become faster. Also, aggressively compacting during quiet periods helps when write bursts happen. In addition, we also want to compact files that are containing deleted key ranges (like old oplog keys).
All of this is currently not possible with CompactRange() because it's single-threaded and blocks all other compactions from happening. Running CompactRange() risks an issue of blocking writes because we generate too much Level 0 files before the compaction is over. Stopping writes is very dangerous because they hold transaction locks. We tried running manual compaction once on Mongo+Rocks and everything fell apart.
MarkForCompaction() solves all of those problems. This is very light-weight manual compaction. It is lower priority than automatic compactions, which means it shouldn't interfere with background process keeping the LSM tree clean. However, if no automatic compactions need to be run (or we have extra background threads available), we will start compacting files that are marked for compaction.
Test Plan: added a new unit test
Reviewers: yhchiang, rven, MarkCallaghan, sdong
Reviewed By: sdong
Subscribers: yoshinorim, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37083/Bug of trivial move of dynamic level
Summary: D36669 introduces a bug that trivial moved data is not going to specific level but the next level, which will incorrectly be level 1 for level 0 compaciton if base level is not level 1. Fixing it by appreciating the output level
Test Plan: Run all tests
Reviewers: MarkCallaghan, rven, yhchiang, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D37119/Fix and Improve DBTest.DynamicLevelCompressionPerLevel2
Summary:
Recent change of DBTest.DynamicLevelCompressionPerLevel2 has a bug that the second sync point is not enabled. Fix it. Also add an assert for that.
Also, flush compression is not tracked in the test. Add it.
Test Plan: Build everything
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D37101/Fix build break introduced by new SyncPoint interface change
Summary: When commiting the sync point interface change, didn't resolve the new occurance of the old interface in rebase. Fix it.
Test Plan: Build and see it pass
Reviewers: igor, yhchiang, rven, anthony, kradhakrishnan
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D37095/SyncPoint to allow a callback with an argument and use it to get DBTest.DynamicLevelCompressionPerLevel2 more straight-forward
Summary:
Allow users to give a callback function with parameter using sync point, so more complicated verification can be done in tests.
Use it in DBTest.DynamicLevelCompressionPerLevel2 so that failures will be more easy to debug.
Test Plan: Run all tests. Run DBTest.DynamicLevelCompressionPerLevel2 with valgrind check.
Reviewers: rven, yhchiang, anthony, kradhakrishnan, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D36999/Temporarily disable test CompactFilesOnLevelCompaction
Summary: https://reviews.facebook.net/D36963 made the debug build much faster and that triggered failures of CompactFilesOnLevelCompaction test. 3 out of 4 last tests on Jenkins failed. I'm disabling this test temporarily, since we likely know the reason why it's failing and there's already work in progress to address it -- https://reviews.facebook.net/D36225
Test Plan: none
Reviewers: sdong, rven, yhchiang, meyering
Reviewed By: meyering
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D36993/Fix flakiness in FIFOCompaction test (github issue #573)
Summary:
The problem is that sometimes two memtables will be compacted together into a single file. In that case, our assertion
ASSERT_EQ(NumTableFilesAtLevel(0), 5);
fails because same amount of data is in 4 files instead of 5. We should wait for flush so that we prevent two memtables merging into a single file.
Test Plan: `for i in `seq 20`; do mrtest FIFOCompactionTest; done` -- fails at least once before. fails zero times after.
Reviewers: rven
Reviewed By: rven
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D36939/Make Compaction class easier to use
Summary:
The goal of this diff is to make Compaction class easier to use. This should also make new compaction algorithms easier to write (like CompactFiles from @yhchiang and dynamic leveled and multi-leveled universal from @sdong).
Here are couple of things demonstrating that Compaction class is hard to use:
1. we have two constructors of Compaction class
2. there's this thing called grandparents_, but it appears to only be setup for leveled compaction and not compactfiles
3. it's easy to introduce a subtle and dangerous bug like this: D36225
4. SetupBottomMostLevel() is hard to understand and it shouldn't be. See this comment: https://github.com/facebook/rocksdb/blob/afbafeaeaebfd27a0f3e992fee8e0c57d07658fa/db/compaction.cc#L236-L241. It also made it harder for @yhchiang to write CompactFiles, as evidenced by this: https://github.com/facebook/rocksdb/blob/afbafeaeaebfd27a0f3e992fee8e0c57d07658fa/db/compaction_picker.cc#L204-L210
The problem is that we create Compaction object, which holds a lot of state, and then pass it around to some functions. After those functions are done mutating, then we call couple of functions on Compaction object, like SetupBottommostLevel() and MarkFilesBeingCompacted(). It is very hard to see what's happening with all that Compaction's state while it's travelling across different functions. If you're writing a new PickCompaction() function you need to try really hard to understand what are all the functions you need to run on Compaction object and what state you need to setup.
My proposed solution is to make important parts of Compaction immutable after construction. PickCompaction() should calculate compaction inputs and then pass them onto Compaction object once they are finalized. That makes it easy to create a new compaction -- just provide all the parameters to the constructor and you're done. No need to call confusing functions after you created your object.
This diff doesn't fully achieve that goal, but it comes pretty close. Here are some of the changes:
* have one Compaction constructor instead of two.
* inputs_ is constant after construction
* MarkFilesBeingCompacted() is now private to Compaction class and automatically called on construction/destruction.
* SetupBottommostLevel() is gone. Compaction figures it out on its own based on the input.
* CompactionPicker's functions are not passing around Compaction object anymore. They are only passing around the state that they need.
Test Plan:
make check
make asan_check
make valgrind_check
Reviewers: rven, anthony, sdong, yhchiang
Reviewed By: yhchiang
Subscribers: sdong, yhchiang, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D36687/db_test: clean up sync points in test cleaning up
Summary: In some db_test tests sync points are not cleared which will cause unexpected results in the next tests. Clean them up in test cleaning up.
Test Plan:
Run the same tests that used to fail:
build using USE_CLANG=1 and run
./db_test --gtest_filter=""DBTest.CompressLevelCompaction:*DBTestUniversalCompactionParallel*""
Reviewers: rven, yhchiang, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D36429/Fix crash caused by opening an empty DB in readonly mode
Summary:
This diff fixes a crash found when an empty database is opened in readonly mode.
We now check the number of levels before we open the DB as a compacted DB.
Test Plan: DBTest.EmptyCompactedDB
Reviewers: igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D36327/Fix one non-determinism of DBTest.DynamicCompactionOptions
Summary:
After recent change of DBTest.DynamicCompactionOptions, occasionally hit another non-deterministic case where L0 showdown is triggered while timeout should not triggered for hard limit.
Fix it by increasing L0 slowdown trigger at the same time.
Test Plan: Run the failed test.
Reviewers: igor, rven
Reviewed By: rven
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D36219/Clean-up WAL directory before running db_test
Summary: DBTest doesn't clean up wal directory. It might cause failure after a failure test run. Fix it.
Test Plan:
Run unit tests
Try open DB with non-empty db_path/wal.
Reviewers: rven, yhchiang, kradhakrishnan, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D35559/Add a DB Property For Number of Deletions in Memtables
Summary: Add a DB property for number of deletions in memtables. It can sometimes help people debug slowness because of too many deletes.
Test Plan: Add test cases.
Reviewers: rven, yhchiang, kradhakrishnan, igor
Reviewed By: igor
Subscribers: leveldb, dhruba, yoshinorim
Differential Revision: https://reviews.facebook.net/D35247/rocksdb: switch to gtest
Summary:
Our existing test notation is very similar to what is used in gtest. It makes it easy to adopt what is different.
In this diff I modify existing [[ https://code.google.com/p/googletest/wiki/Primer#Test_Fixtures:_Using_the_Same_Data_Configuration_for_Multiple_Te | test fixture ]] classes to inherit from `testing::Test`. Also for unit tests that use fixture class, `TEST` is replaced with `TEST_F` as required in gtest.
There are several custom `main` functions in our existing tests. To make this transition easier, I modify all `main` functions to fallow gtest notation. But eventually we can remove them and use implementation of `main` that gtest provides.
```lang=bash
% cat ~/transform
#!/bin/sh
files=$(git ls-files '*test\.cc')
for file in $files
do
if grep -q ""rocksdb::test::RunAllTests()"" $file
then
if grep -Eq '^class \w+Test {' $file
then
perl -pi -e 's/^(class \w+Test) {/${1}: public testing::Test {/g' $file
perl -pi -e 's/^(TEST)/${1}_F/g' $file
fi
perl -pi -e 's/(int main.*\{)/${1}::testing::InitGoogleTest(&argc, argv);/g' $file
perl -pi -e 's/rocksdb::test::RunAllTests/RUN_ALL_TESTS/g' $file
fi
done
% sh ~/transform
% make format
```
Second iteration of this diff contains only scripted changes.
Third iteration contains manual changes to fix last errors and make it compilable.
Test Plan:
Build and notice no errors.
```lang=bash
% USE_CLANG=1 make check -j55
```
Tests are still testing.
Reviewers: meyering, sdong, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D35157/rocksdb: Replace ASSERT* with EXPECT* in functions that does not return void value
Summary:
gtest does not use exceptions to fail a unit test by design, and `ASSERT*`s are implemented using `return`. As a consequence we cannot use `ASSERT*` in a function that does not return `void` value ([[ https://code.google.com/p/googletest/wiki/AdvancedGuide#Assertion_Placement | 1]]), and have to fix our existing code. This diff does this in a generic way, with no manual changes.
In order to detect all existing `ASSERT*` that are used in functions that doesn't return void value, I change the code to generate compile errors for such cases.
In `util/testharness.h` I defined `EXPECT*` assertions, the same way as `ASSERT*`, and redefined `ASSERT*` to return `void`. Then executed:
```lang=bash
% USE_CLANG=1 make all -j55 -k 2> build.log
% perl -naF: -e 'print ""-- -number="".$F[1]."" "".$F[0].""\n"" if  /: error:/' \
build.log | xargs -L 1 perl -spi -e 's/ASSERT/EXPECT/g if $. == $number'
% make format
```
After that I reverted back change to `ASSERT*` in `util/testharness.h`. But preserved introduced `EXPECT*`, which is the same as `ASSERT*`. This will be deleted once switched to gtest.
This diff is independent and contains manual changes only in `util/testharness.h`.
Test Plan:
Make sure all tests are passing.
```lang=bash
% USE_CLANG=1 make check
```
Reviewers: igor, lgalanis, sdong, yufei.zhu, rven, meyering
Reviewed By: meyering
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33333/Fixed the unit-test issue in PreShutdownCompactionMiddle
Summary: Fixed the unit-test issue in PreShutdownCompactionMiddle
Test Plan: export ROCKSDB_TESTS=PreShutdownCompactionMiddle
Reviewers: rven, sdong, igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D35061/Fix the issue in PreShutdownMultipleCompaction
Summary: Fix the issue in PreShutdownMultipleCompaction
Test Plan:
export ROCKSDB_TESTS=PreShutdownMultipleCompaction
./db_test
Reviewers: rven, sdong, igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D35055/Prevent slowdowns and stalls in PreShutdown tests
Summary:
The preshutdown tests check for stopped compactions/flushes.
Removing stalls on the write path.
Test Plan: DBTests.PreShutdown*
Reviewers: yhchiang, sdong, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D35037/Fix the deadlock issue in ThreadStatusSingleCompaction.
Summary:
Fix the deadlock issue in ThreadStatusSingleCompaction.
In the previous version of ThreadStatusSingleCompaction, the compaction
thread will wait for a SYNC_POINT while its db_mutex is held.  However,
if the test hasn't finished its Put cycle while a compaction is running,
a deadlock will happen in the test.
Test Plan:
export ROCKSDB_TESTS=ThreadStatus
./db_test
Reviewers: sdong, igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D35001/Fix a typo / test failure in ThreadStatusSingleCompaction
Summary:
Fix a typo / test failure in ThreadStatusSingleCompaction
Test Plan:
export ROCKSDB_TESTS=ThreadStatus
./db_test/Don't run some tests is snappy is not present
Summary: Currently, we have `ifdef SNAPPY` around bunch of db_test code. Some tests that don't even use compression are also blocked when running system doesn't have snappy. This also causes hard-to-catch bugs, like D34983. We should dynamically figure out if compression is supported or not.
Test Plan: compiles
Reviewers: sdong, meyering
Reviewed By: meyering
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34989/Prevent stalls in preshutdown tests
Summary:
The tests using sync_point for intent to shutdown stop
compaction and this results in stalls if too many rows are written. We
now limit the number of rows written to prevent stalls, since the focus
of the test is to cancel background work, which is being correctly
tested. This fixes a Jenkins issue.
Test Plan: DBTest.PreShutdown*
Reviewers: sdong, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34893/options.level_compaction_dynamic_level_bytes to allow RocksDB to pick size bases of levels dynamically.
Summary:
When having fixed max_bytes_for_level_base, the ratio of size of largest level and the second one can range from 0 to the multiplier. This makes LSM tree frequently irregular and unpredictable. It can also cause poor space amplification in some cases.
In this improvement (proposed by Igor Kabiljo), we introduce a parameter option.level_compaction_use_dynamic_max_bytes. When turning it on, RocksDB is free to pick a level base in the range of (options.max_bytes_for_level_base/options.max_bytes_for_level_multiplier, options.max_bytes_for_level_base] so that real level ratios are close to options.max_bytes_for_level_multiplier.
Test Plan: New unit tests and pass tests suites including valgrind.
Reviewers: MarkCallaghan, rven, yhchiang, igor, ikabiljo
Reviewed By: ikabiljo
Subscribers: yoshinorim, ikabiljo, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D31437/rocksdb: Add missing override
Summary:
When using latest clang (3.6 or 3.7/trunck) rocksdb is failing with many errors. Almost all of them are missing override errors. This diff adds missing override keyword. No manual changes.
Prerequisites: bear and clang 3.5 build with extra tools
```lang=bash
% USE_CLANG=1 bear make all # generate a compilation database http://clang.llvm.org/docs/JSONCompilationDatabase.html
% clang-modernize -p . -include . -add-override
% make format
```
Test Plan:
Make sure all tests are passing.
```lang=bash
% #Use default fb code clang.
% make check
```
Verify less error and no missing override errors.
```lang=bash
% # Have trunk clang present in path.
% ROCKSDB_NO_FBCODE=1 CC=clang CXX=clang++ make
```
Reviewers: igor, kradhakrishnan, rven, meyering, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34077/catch config errors with L0 file count triggers
Test Plan: Run ""make clean && make all check""
Reviewers: rven, igor, yhchiang, kradhakrishnan, MarkCallaghan, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D33627/DBTest.DestroyDBMetaDatabase: create DB directories if not exists
Summary: DBTest.DestroyDBMetaDatabase occasionally fails on my dev host, for file not existing. Always create directories to avoid that.
Test Plan: Run the test
Reviewers: rven, yhchiang, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33321/"
rocksdb,"Fixed a bug in EventListener::OnCompactionCompleted().
Summary:
Fixed a bug in EventListener::OnCompactionCompleted() that returns
incorrect list of input / output file names.
Test Plan: Extend existing test in listener_test.cc
Reviewers: sdong, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D38349/rocksdb: Remove #include ""util/string_util.h"" from util/testharness.h
Summary:
1. Manually deleted #include ""util/string_util.h"" from util/testharness.h
2.
```
% USE_CLANG=1 make all -j55 -k 2> build.log
% perl -naF: -E 'say $F[0] if /: error:/' build.log | sort -u | xargs sed -i '/#include ""util\/testharness.h""/i #include ""util\/string_util.h""'
```
Test Plan:
Make sure make all completes with no errors.
```
% make all -j55
```
Reviewers: meyering, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D35493/rocksdb: switch to gtest
Summary:
Our existing test notation is very similar to what is used in gtest. It makes it easy to adopt what is different.
In this diff I modify existing [[ https://code.google.com/p/googletest/wiki/Primer#Test_Fixtures:_Using_the_Same_Data_Configuration_for_Multiple_Te | test fixture ]] classes to inherit from `testing::Test`. Also for unit tests that use fixture class, `TEST` is replaced with `TEST_F` as required in gtest.
There are several custom `main` functions in our existing tests. To make this transition easier, I modify all `main` functions to fallow gtest notation. But eventually we can remove them and use implementation of `main` that gtest provides.
```lang=bash
% cat ~/transform
#!/bin/sh
files=$(git ls-files '*test\.cc')
for file in $files
do
if grep -q ""rocksdb::test::RunAllTests()"" $file
then
if grep -Eq '^class \w+Test {' $file
then
perl -pi -e 's/^(class \w+Test) {/${1}: public testing::Test {/g' $file
perl -pi -e 's/^(TEST)/${1}_F/g' $file
fi
perl -pi -e 's/(int main.*\{)/${1}::testing::InitGoogleTest(&argc, argv);/g' $file
perl -pi -e 's/rocksdb::test::RunAllTests/RUN_ALL_TESTS/g' $file
fi
done
% sh ~/transform
% make format
```
Second iteration of this diff contains only scripted changes.
Third iteration contains manual changes to fix last errors and make it compilable.
Test Plan:
Build and notice no errors.
```lang=bash
% USE_CLANG=1 make check -j55
```
Tests are still testing.
Reviewers: meyering, sdong, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D35157/rocksdb: Replace ASSERT* with EXPECT* in functions that does not return void value
Summary:
gtest does not use exceptions to fail a unit test by design, and `ASSERT*`s are implemented using `return`. As a consequence we cannot use `ASSERT*` in a function that does not return `void` value ([[ https://code.google.com/p/googletest/wiki/AdvancedGuide#Assertion_Placement | 1]]), and have to fix our existing code. This diff does this in a generic way, with no manual changes.
In order to detect all existing `ASSERT*` that are used in functions that doesn't return void value, I change the code to generate compile errors for such cases.
In `util/testharness.h` I defined `EXPECT*` assertions, the same way as `ASSERT*`, and redefined `ASSERT*` to return `void`. Then executed:
```lang=bash
% USE_CLANG=1 make all -j55 -k 2> build.log
% perl -naF: -e 'print ""-- -number="".$F[1]."" "".$F[0].""\n"" if  /: error:/' \
build.log | xargs -L 1 perl -spi -e 's/ASSERT/EXPECT/g if $. == $number'
% make format
```
After that I reverted back change to `ASSERT*` in `util/testharness.h`. But preserved introduced `EXPECT*`, which is the same as `ASSERT*`. This will be deleted once switched to gtest.
This diff is independent and contains manual changes only in `util/testharness.h`.
Test Plan:
Make sure all tests are passing.
```lang=bash
% USE_CLANG=1 make check
```
Reviewers: igor, lgalanis, sdong, yufei.zhu, rven, meyering
Reviewed By: meyering
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33333/"
rocksdb,"Fix clang build
Summary: fix build
Test Plan: works
Reviewers: kradhakrishnan
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37911/Fix possible SIGSEGV in CompactRange (github issue #596)
Summary: For very detailed explanation of what's happening read this: https://github.com/facebook/rocksdb/issues/596
Test Plan: make check + new unit test
Reviewers: yhchiang, anthony, rven
Reviewed By: rven
Subscribers: adamretter, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37779/Merge pull request #593 from charsyam/feature/type-1
fix typos/fix typos/Print max score in level summary
Summary: Add more logging to help debugging issues.
Test Plan: Run test suites
Reviewers: yhchiang, rven, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D37401/Add experimental API MarkForCompaction()
Summary:
Some Mongo+Rocks datasets in Parse's environment are not doing compactions very frequently. During the quiet period (with no IO), we'd like to schedule compactions so that our reads become faster. Also, aggressively compacting during quiet periods helps when write bursts happen. In addition, we also want to compact files that are containing deleted key ranges (like old oplog keys).
All of this is currently not possible with CompactRange() because it's single-threaded and blocks all other compactions from happening. Running CompactRange() risks an issue of blocking writes because we generate too much Level 0 files before the compaction is over. Stopping writes is very dangerous because they hold transaction locks. We tried running manual compaction once on Mongo+Rocks and everything fell apart.
MarkForCompaction() solves all of those problems. This is very light-weight manual compaction. It is lower priority than automatic compactions, which means it shouldn't interfere with background process keeping the LSM tree clean. However, if no automatic compactions need to be run (or we have extra background threads available), we will start compacting files that are marked for compaction.
Test Plan: added a new unit test
Reviewers: yhchiang, rven, MarkCallaghan, sdong
Reviewed By: sdong
Subscribers: yoshinorim, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37083/avoid returning a number-of-active-keys estimate of nearly 2^64
Summary:
If accumulated_num_non_deletions_ were ever smaller than
accumulated_num_deletions_, the computation of
""accumulated_num_non_deletions_ - accumulated_num_deletions_""
would result in a logically ""negative"" value, but since
the two operands are unsigned (uint64_t), the result corresponding
to e.g., -1 would 2^64-1.
Instead, return 0 in that case.
Test Plan:
- ensure ""make check"" still passes
- temporarily add an ""abort();"" call in the new ""if""-block, and
observe that it fails in some test cases.  However, note that
this case is triggered only when the two numbers are equal.
Thus, no test case triggers the erroneous behavior this
change is designed to avoid. If anyone can construct a
scenario in which that bug would be triggered, I'll be
happy to add a test case.
Reviewers: ljin, igor, rven, igor.sugak, yhchiang, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D36489/Fix level size overflow for options_.level_compaction_dynamic_level_bytes=true
Summary: Int is used for level size targets when options_.level_compaction_dynamic_level_bytes=true, which will cause overflow when database grows big. Fix it.
Test Plan: Add a new unit test which fails without the fix.
Reviewers: rven, yhchiang, MarkCallaghan, igor
Reviewed By: igor
Subscribers: leveldb, dhruba, yoshinorim
Differential Revision: https://reviews.facebook.net/D36453/Don't delete files when column family is dropped
Summary:
To understand the bug read t5943287 and check out the new test in column_family_test (ReadDroppedColumnFamily), iter 0.
RocksDB contract allowes you to read a drop column family as long as there is a live reference. However, since our iteration ignores dropped column families, AddLiveFiles() didn't mark files of a dropped column families as live. So we deleted them.
In this patch I no longer ignore dropped column families in the iteration. I think this behavior was confusing and it also led to this bug. Now if an iterator client wants to ignore dropped column families, he needs to do it explicitly.
Test Plan: Added a new unit test that is failing on master. Unit test succeeds now.
Reviewers: sdong, rven, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D32535/options.level_compaction_dynamic_level_bytes to allow RocksDB to pick size bases of levels dynamically.
Summary:
When having fixed max_bytes_for_level_base, the ratio of size of largest level and the second one can range from 0 to the multiplier. This makes LSM tree frequently irregular and unpredictable. It can also cause poor space amplification in some cases.
In this improvement (proposed by Igor Kabiljo), we introduce a parameter option.level_compaction_use_dynamic_max_bytes. When turning it on, RocksDB is free to pick a level base in the range of (options.max_bytes_for_level_base/options.max_bytes_for_level_multiplier, options.max_bytes_for_level_base] so that real level ratios are close to options.max_bytes_for_level_multiplier.
Test Plan: New unit tests and pass tests suites including valgrind.
Reviewers: MarkCallaghan, rven, yhchiang, igor, ikabiljo
Reviewed By: ikabiljo
Subscribers: yoshinorim, ikabiljo, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D31437/rocksdb: Add missing override
Summary:
When using latest clang (3.6 or 3.7/trunck) rocksdb is failing with many errors. Almost all of them are missing override errors. This diff adds missing override keyword. No manual changes.
Prerequisites: bear and clang 3.5 build with extra tools
```lang=bash
% USE_CLANG=1 bear make all # generate a compilation database http://clang.llvm.org/docs/JSONCompilationDatabase.html
% clang-modernize -p . -include . -add-override
% make format
```
Test Plan:
Make sure all tests are passing.
```lang=bash
% #Use default fb code clang.
% make check
```
Verify less error and no missing override errors.
```lang=bash
% # Have trunk clang present in path.
% ROCKSDB_NO_FBCODE=1 CC=clang CXX=clang++ make
```
Reviewers: igor, kradhakrishnan, rven, meyering, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D34077/build: remove always-true assertions
Summary:
Remove some always-true assertions.
They provoke these compilation failures:
table/plain_table_key_coding.cc:279:20: error: comparison of unsigned expression >= 0 is always true [-Werror=type-limits]
db/version_set.cc:336:15: error: comparison of unsigned expression >= 0 is always true [-Werror=type-limits]
* table/plain_table_key_coding.cc (rocksdb): Remove assertion that
unsigned type variable is >= 0.
* db/version_set.cc (DoGenerateLevelFilesBrief): Likewise.
Test Plan:
Run ""make EXTRA_CXXFLAGS='-W -Wextra'"" and see fewer errors.
Reviewers: ljin, sdong, igor.sugak, igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D33747/"
rocksdb,"rocksdb: Fixed 'Dead assignment' and 'Dead initialization' scan-build warnings
Summary:
This diff contains trivial fixes for 6 scan-build warnings:
**db/c_test.c**
`db` variable is never read. Removed assignment.
scan-build report:
http://home.fburl.com/~sugak/latest20/report-9b77d2.html#EndPath
**db/db_iter.cc**
`skipping` local variable is assigned to false. Then in the next switch block the only ""non return"" case assign `skipping` to true, the rest cases don't use it and all do return.
scan-build report:
http://home.fburl.com/~sugak/latest20/report-13fca7.html#EndPath
**db/log_reader.cc**
In `bool Reader::SkipToInitialBlock()` `offset_in_block` local variable is assigned to 0 `if (offset_in_block > kBlockSize - 6)` and then never used. Removed the assignment and renamed it to `initial_offset_in_block` to avoid confusion.
scan-build report:
http://home.fburl.com/~sugak/latest20/report-a618dd.html#EndPath
In `bool Reader::ReadRecord(Slice* record, std::string* scratch)` local variable `in_fragmented_record` in switch case `kFullType` block is assigned to false and then does `return` without use. In the other switch case `kFirstType` block the same `in_fragmented_record` is assigned to false, but later assigned to true without prior use. Removed assignment for both cases.
scan-build reprots:
http://home.fburl.com/~sugak/latest20/report-bb86b0.html#EndPath
http://home.fburl.com/~sugak/latest20/report-a975be.html#EndPath
**table/plain_table_key_coding.cc**
Local variable `user_key_size` is assigned when declared. But then in both places where it is used assigned to `static_cast<uint32_t>(key.size() - 8)`. Changed to initialize the variable to the proper value in declaration.
scan-build report:
http://home.fburl.com/~sugak/latest20/report-9e6b86.html#EndPath
**tools/db_stress.cc**
Missing `break` in switch case block. This seems to be a bug. Added missing `break`.
Test Plan:
Make sure all tests are passing and scan-build does not report 'Dead assignment' and 'Dead initialization' bugs.
```lang=bash
% make check
% make analyze
```
Reviewers: meyering, igor, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D33795/"
rocksdb,"Removing duplicate code in db_bench/db_stress, fixing typos
Summary:
While working on single delete support for db_bench, I realized that
db_bench/db_stress contain a bunch of duplicate code related to
copmression and found some typos. This patch removes duplicate code,
typos and a redundant #ifndef in internal_stats.cc.
Test Plan: make db_stress && make db_bench && ./db_bench --benchmarks=compress,uncompress
Reviewers: yhchiang, sdong, rven, anthony, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43965/Fixed typos in db_stress
Summary: Fixed typos.
Test Plan: None
Reviewers: igor, yhchiang, sdong, anthony, rven
Reviewed By: rven
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43365/Deprecate purge_redundant_kvs_while_flush
Summary: This option is guarding the feature implemented 2 and a half years ago: D8991. The feature was enabled by default back then and has been running without issues. There is no reason why any client would turn this feature off. I found no reference in fbcode.
Test Plan: none
Reviewers: sdong, yhchiang, anthony, dhruba
Reviewed By: dhruba
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D42063/Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/Fixed db_stress
Summary:
Fixed db_stress by correcting the verification of column family
names in the Listener of db_stress
Test Plan: db_stress
Reviewers: igor, sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39255/Fixed a compile warning in db_stress in NDEBUG mode.
Summary: Fixed a compile warning in db_stress in NDEBUG mode.
Test Plan: make OPT=-DNDEBUG db_stress
Reviewers: sdong, anthony
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39213/Fixed a compile warning in db_stress
Summary:
Fixed the following compile warning in db_stress:
error: 'OnCompactionCompleted' overrides a member function but is not marked 'override' [-Werror,-Winconsistent-missing-override]
Test Plan: make db_stress
Reviewers: sdong, igor, anthony
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39207/Include EventListener in stress test.
Summary: Include EventListener in stress test.
Test Plan: make blackbox_crash_test whitebox_crash_test
Reviewers: anthony, igor, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39105/Support saving history in memtable_list
Summary:
For transactions, we are using the memtables to validate that there are no write conflicts.  But after flushing, we don't have any memtables, and transactions could fail to commit.  So we want to someone keep around some extra history to use for conflict checking.  In addition, we want to provide a way to increase the size of this history if too many transactions fail to commit.
After chatting with people, it seems like everyone prefers just using Memtables to store this history (instead of a separate history structure).  It seems like the best place for this is abstracted inside the memtable_list.  I decide to create a separate list in MemtableListVersion as using the same list complicated the flush/installalflushresults logic too much.
This diff adds a new parameter to control how much memtable history to keep around after flushing.  However, it sounds like people aren't too fond of adding new parameters.  So I am making the default size of flushed+not-flushed memtables be set to max_write_buffers.  This should not change the maximum amount of memory used, but make it more likely we're using closer the the limit.  (We are now postponing deleting flushed memtables until the max_write_buffer limit is reached).  So while we might use more memory on average, we are still obeying the limit set (and you could argue it's better to go ahead and use up memory now instead of waiting for a write stall to happen to test this limit).
However, if people are opposed to this default behavior, we can easily set it to 0 and require this parameter be set in order to use transactions.
Test Plan: Added a xfunc test to play around with setting different values of this parameter in all tests.  Added testing in memtablelist_test and planning on adding more testing here.
Reviewers: sdong, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37443/"
rocksdb,"Improved FileExists API
Summary: Add new CheckFileExists method.  Considered changing the FileExists api but didn't want to break anyone's builds.
Test Plan: unit tests
Reviewers: yhchiang, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D42003/"
rocksdb,"Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/Merge branch 'master' of github.com:facebook/rocksdb
D40233: Replace %llu with format macros in ParsedInternalKey::DebugString())/Allow EventListener::OnCompactionCompleted to return CompactionJobStats.
Summary:
Allow EventListener::OnCompactionCompleted to return CompactionJobStats,
which contains useful information about a compaction.
Example CompactionJobStats returned by OnCompactionCompleted():
smallest_output_key_prefix 05000000
largest_output_key_prefix 06990000
elapsed_time 42419
num_input_records 300
num_input_files 3
num_input_files_at_output_level 2
num_output_records 200
num_output_files 1
actual_bytes_input 167200
actual_bytes_output 110688
total_input_raw_key_bytes 5400
total_input_raw_value_bytes 300000
num_records_replaced 100
is_manual_compaction 1
Test Plan: Developed a mega test in db_test which covers 20 variables in CompactionJobStats.
Reviewers: rven, igor, anthony, sdong
Reviewed By: sdong
Subscribers: tnovak, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D38463/"
rocksdb,"Improved FileExists API
Summary: Add new CheckFileExists method.  Considered changing the FileExists api but didn't want to break anyone's builds.
Test Plan: unit tests
Reviewers: yhchiang, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D42003/"
rocksdb,"Allow GetApproximateSize() to include mem table size if it is skip list memtable
Summary:
Add an option in GetApproximateSize() so that the result will include estimated sizes in mem tables.
To implement it, implement an estimated count from the beginning to a key in skip list. The approach is to count to find the entry, how many Next() is issued from each level, and sum them with a weight that is <branching factor> ^ <level>.
Test Plan: Add a test case
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D40119/"
rocksdb,"Improved FileExists API
Summary: Add new CheckFileExists method.  Considered changing the FileExists api but didn't want to break anyone's builds.
Test Plan: unit tests
Reviewers: yhchiang, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D42003/Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/"
rocksdb,"Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/"
rocksdb,"Address GCC compilation issues
invalid suffix on literal
no return statement in function returning non-void CuckooStep::operator=
extra qualification rocksdb::spatial::Variant::
dereferencing type-punned pointer will break strict-aliasing rules/Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/"
rocksdb,"Merge branch 'master' of github.com:facebook/rocksdb
D40233: Replace %llu with format macros in ParsedInternalKey::DebugString())/"
rocksdb,"Merge branch 'master' of github.com:facebook/rocksdb
Fixed memory leak error/Made change to fix the memory leak
Summary: So I took a look and I used a pointer to TableBuilder.  Changed it to a unique_ptr.  I think this should work, but I cannot run valgrind correctly on my local machine to test it.
Test Plan: Run valgrind, but it's not working locally.  It says I'm executing an unrecognized instruction.
Reviewers: yhchiang
Subscribers: dhruba, sdong
Differential Revision: https://reviews.facebook.net/D43485/fix memory corruption issue in sst_dump --show_compression_sizes
Summary: In ""sst_dump --show_compression_sizes"", a reference of CompressionOptions is kept in TableBuilderOptions, which is destroyed later, causing a memory issue.
Test Plan: Run valgrind against SSTDumpToolTest.CompressedSizes and make sure it is fixed
Reviewers: IslamAbdelRahman, yhchiang, kradhakrishnan, rven
Reviewed By: rven
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D43497/"
rocksdb,"[wal changes 3/3] method in DB to sync WAL without blocking writers
Summary:
Subj. We really need this feature.
Previous diff D40899 has most of the changes to make this possible, this diff just adds the method.
Test Plan: `make check`, the new test fails without this diff; ran with ASAN, TSAN and valgrind.
Reviewers: igor, rven, IslamAbdelRahman, anthony, kradhakrishnan, tnovak, yhchiang, sdong
Reviewed By: sdong
Subscribers: MarkCallaghan, maykov, hermanlee4, yoshinorim, tnovak, dhruba
Differential Revision: https://reviews.facebook.net/D40905/cleaned up PosixMmapFile a little
Summary: https://reviews.facebook.net/D42321 has left PosixMmapFile in some weird state. This diff removes pending_sync_ that was now unused, fixes indentation and prevents Fsync() from calling both fsync() and fdatasync().
Test Plan: `make -j check`
Reviewers: sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D42885/Improved FileExists API
Summary: Add new CheckFileExists method.  Considered changing the FileExists api but didn't want to break anyone's builds.
Test Plan: unit tests
Reviewers: yhchiang, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D42003/Cleaning up CYGWIN define of fread_unlocked to port
Summary: CYGWIN avoided fread_unlocked in a wrong way. Fix it to the standard way.
Test Plan: Run tests
Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D42549/Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/Merge branch 'master' of github.com:facebook/rocksdb
D40233: Replace %llu with format macros in ParsedInternalKey::DebugString())/fix clang build/"
rocksdb,"Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/"
rocksdb,"Merge branch 'master' of github.com:facebook/rocksdb
D40233: Replace %llu with format macros in ParsedInternalKey::DebugString())/"
rocksdb,"[RocksJava] Fixed test failures
Summary:
The option bottommost_level_compaction was introduced lately.
This option breaks the Java API behavior. To prevent the library
from doing so we set that option to a fixed value in Java.
In future we are going to remove that portion and replace the
hardcoded options using a more flexible way.
Fixed bug introduced by WriteBatchWithIndex Patch
Lately icanadi changed the behavior of WriteBatchWithIndex.
See commit: 821cff114e57efa67711c1c1c105aa02831a0d23
This commit solves problems introduced by above mentioned commit.
Test Plan:
make rocksdbjava
make jtest
Reviewers: adamretter, ankgup87, yhchiang
Reviewed By: yhchiang
Subscribers: igor, dhruba
Differential Revision: https://reviews.facebook.net/D40647/"
rocksdb,"Fixed RocksJava test failure of shouldSetTestCappedPrefixExtractor
Summary:
Fixed RocksJava test failure of shouldSetTestCappedPrefixExtractor
by adding the missing native implementation of
useCappedPrefixExtractor.
Test Plan:
make jclean
make rocksdbjava -j32
make jtest
Reviewers: igor, anthony, IslamAbdelRahman, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43551/add support for capped prefix extractor in java/Fixing Java tests.
Summary:
While working on https://reviews.facebook.net/D43017 , I realized
that some Java tests are failing due to a deprecated option.
This patch removes the offending tests, adds @Deprecated annotations
to the Java interface and removes the corresponding functions in
rocksjni
Test Plan: make jtest (all tests are passing now)
Reviewers: rven, igor, sdong, anthony, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43035/Fix ROCKSDB_WARNING
Summary:
ROCKSDB_WARNING is only defined if either ROCKSDB_PLATFORM_POSIX or OS_WIN is defined.  This works well for building rocksdb with its own build scripts.  But this won't work when an outside project(like mongodb) doesn't define ROCKSDB_PLATFORM_POSIX.
This fix defines ROCKSDB_WARNING for all platforms.  No idea if its defined correctly on non-posix,non-windows platforms but this is no worse that the current situation where this macro is missing on unexpected platforms.
This fix should hopefully fix anyone whose build broke now that we've switched from using #warning to Pragma (to support windows).  Unfortunately, while mongo-rocks compiles, it ignores the Pragma and doesn't print a warning.  I have not been able to figure out a way to implement this portably on all platforms.
Of course, an alternate solution would be to just get rid of ROCKSDB_WARNING and live with include file redirects indefinitely.  Thoughts?
Test Plan: build rocks, build mongorocks
Reviewers: igor, kradhakrishnan, IslamAbdelRahman, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D42477/Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/Support saving history in memtable_list
Summary:
For transactions, we are using the memtables to validate that there are no write conflicts.  But after flushing, we don't have any memtables, and transactions could fail to commit.  So we want to someone keep around some extra history to use for conflict checking.  In addition, we want to provide a way to increase the size of this history if too many transactions fail to commit.
After chatting with people, it seems like everyone prefers just using Memtables to store this history (instead of a separate history structure).  It seems like the best place for this is abstracted inside the memtable_list.  I decide to create a separate list in MemtableListVersion as using the same list complicated the flush/installalflushresults logic too much.
This diff adds a new parameter to control how much memtable history to keep around after flushing.  However, it sounds like people aren't too fond of adding new parameters.  So I am making the default size of flushed+not-flushed memtables be set to max_write_buffers.  This should not change the maximum amount of memory used, but make it more likely we're using closer the the limit.  (We are now postponing deleting flushed memtables until the max_write_buffer limit is reached).  So while we might use more memory on average, we are still obeying the limit set (and you could argue it's better to go ahead and use up memory now instead of waiting for a write stall to happen to test this limit).
However, if people are opposed to this default behavior, we can easily set it to 0 and require this parameter be set in order to use transactions.
Test Plan: Added a xfunc test to play around with setting different values of this parameter in all tests.  Added testing in memtablelist_test and planning on adding more testing here.
Reviewers: sdong, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37443/"
rocksdb,"add support for capped prefix extractor in java/Fixing Java tests.
Summary:
While working on https://reviews.facebook.net/D43017 , I realized
that some Java tests are failing due to a deprecated option.
This patch removes the offending tests, adds @Deprecated annotations
to the Java interface and removes the corresponding functions in
rocksjni
Test Plan: make jtest (all tests are passing now)
Reviewers: rven, igor, sdong, anthony, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43035/"
rocksdb,"add support for capped prefix extractor in java/Fixing Java tests.
Summary:
While working on https://reviews.facebook.net/D43017 , I realized
that some Java tests are failing due to a deprecated option.
This patch removes the offending tests, adds @Deprecated annotations
to the Java interface and removes the corresponding functions in
rocksjni
Test Plan: make jtest (all tests are passing now)
Reviewers: rven, igor, sdong, anthony, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43035/"
rocksdb,"Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/Merge branch 'master' of github.com:facebook/rocksdb
D40233: Replace %llu with format macros in ParsedInternalKey::DebugString())/Make ""make all"" work for CYGWIN
Summary: Some test and benchmark codes don't build for CYGWIN. Fix it.
Test Plan: Build ""make all"" with TARGET_OS=Cygwin on cygwin and make sure it passes.
Reviewers: rven, yhchiang, anthony, igor, kradhakrishnan
Reviewed By: igor, kradhakrishnan
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D39711/"
rocksdb,"Improved FileExists API
Summary: Add new CheckFileExists method.  Considered changing the FileExists api but didn't want to break anyone's builds.
Test Plan: unit tests
Reviewers: yhchiang, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D42003/Better error handling in BackupEngine
Summary:
Couple of changes here:
* NewBackupEngine() and NewReadOnlyBackupEngine() are now removed. They were deprecated since RocksDB 3.8. Changing these to new functions should be pretty straight-forward. As a followup, I'll fix all fbcode callsights
* Instead of initializing backup engine in the constructor, we initialize it in a separate function now. That way, we can catch all errors and return appropriate status code.
* We catch all errors during initializations and return them to the client properly.
* Added new tests to backupable_db_test, to make sure that we can't open BackupEngine when there are Env errors.
* Transitioned backupable_db_test to use BackupEngine rather than BackupableDB. From the two available APIs, judging by the current use-cases, it looks like BackupEngine API won. It's much more flexible since it doesn't require StackableDB.
Test Plan: Added a new unit test to backupable_db_test
Reviewers: yhchiang, sdong, AaronFeldman
Reviewed By: AaronFeldman
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D41925/Make ""make all"" work for CYGWIN
Summary: Some test and benchmark codes don't build for CYGWIN. Fix it.
Test Plan: Build ""make all"" with TARGET_OS=Cygwin on cygwin and make sure it passes.
Reviewers: rven, yhchiang, anthony, igor, kradhakrishnan
Reviewed By: igor, kradhakrishnan
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D39711/"
rocksdb,"Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/"
rocksdb,"Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/"
rocksdb,"Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/Use malloc_usable_size() for accounting block cache size
Summary:
Currently, when we insert something into block cache, we say that the block cache capacity decreased by the size of the block. However, size of the block might be less than the actual memory used by this object. For example, 4.5KB block will actually use 8KB of memory. So even if we configure block cache to 10GB, our actually memory usage of block cache will be 20GB!
This problem showed up a lot in testing and just recently also showed up in MongoRocks production where we were using 30GB more memory than expected.
This diff will fix the problem. Instead of counting the block size, we will count memory used by the block. That way, a block cache configured to be 10GB will actually use only 10GB of memory.
I'm using non-portable function and I couldn't find info on portability on Google. However, it seems to work on Linux, which will cover majority of our use-cases.
Test Plan:
1. fill up mongo instance with 80GB of data
2. restart mongo with block cache size configured to 10GB
3. do a table scan in mongo
4. memory usage before the diff: 12GB. memory usage after the diff: 10.5GB
Reviewers: sdong, MarkCallaghan, rven, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D40635/"
rocksdb,"Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/"
rocksdb,"Use malloc_usable_size() for accounting block cache size
Summary:
Currently, when we insert something into block cache, we say that the block cache capacity decreased by the size of the block. However, size of the block might be less than the actual memory used by this object. For example, 4.5KB block will actually use 8KB of memory. So even if we configure block cache to 10GB, our actually memory usage of block cache will be 20GB!
This problem showed up a lot in testing and just recently also showed up in MongoRocks production where we were using 30GB more memory than expected.
This diff will fix the problem. Instead of counting the block size, we will count memory used by the block. That way, a block cache configured to be 10GB will actually use only 10GB of memory.
I'm using non-portable function and I couldn't find info on portability on Google. However, it seems to work on Linux, which will cover majority of our use-cases.
Test Plan:
1. fill up mongo instance with 80GB of data
2. restart mongo with block cache size configured to 10GB
3. do a table scan in mongo
4. memory usage before the diff: 12GB. memory usage after the diff: 10.5GB
Reviewers: sdong, MarkCallaghan, rven, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D40635/"
rocksdb,"Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/"
rocksdb,"Optimistic Transactions
Summary: Optimistic transactions supporting begin/commit/rollback semantics.  Currently relies on checking the memtable to determine if there are any collisions at commit time.  Not yet implemented would be a way of enuring the memtable has some minimum amount of history so that we won't fail to commit when the memtable is empty.  You should probably start with transaction.h to get an overview of what is currently supported.
Test Plan: Added a new test, but still need to look into stress testing.
Reviewers: yhchiang, igor, rven, sdong
Reviewed By: sdong
Subscribers: adamretter, MarkCallaghan, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D33435/"
rocksdb,"Fixed compile warning in compact_files_example.cc
Summary: Fixed compile warning in compact_files_example.cc
Test Plan: compact_files_example
Reviewers: sdong, igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39309/"
rocksdb,"Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/"
rocksdb,"Improved FileExists API
Summary: Add new CheckFileExists method.  Considered changing the FileExists api but didn't want to break anyone's builds.
Test Plan: unit tests
Reviewers: yhchiang, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D42003/Make ""make all"" work for CYGWIN
Summary: Some test and benchmark codes don't build for CYGWIN. Fix it.
Test Plan: Build ""make all"" with TARGET_OS=Cygwin on cygwin and make sure it passes.
Reviewers: rven, yhchiang, anthony, igor, kradhakrishnan
Reviewed By: igor, kradhakrishnan
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D39711/"
rocksdb,"Fixing dead code in table_properties_collector_test
Summary:
There was a bug in table_properties_collector_test that this patch
is fixing: `!backward_mode && !test_int_tbl_prop_collector` in
TestCustomizedTablePropertiesCollector was never true, so the code
in the if-block never got executed. The reason is that the
CustomizedTablePropertiesCollector test was skipping tests with
`!backward_mode_ && !encode_as_internal`. The reason for skipping
the tests is unknown.
Test Plan: make table_properties_collector_test && ./table_properties_collector_test
Reviewers: rven, igor, yhchiang, anthony, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43281/Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/"
rocksdb,"Transaction error statuses
Summary:
Based on feedback from spetrunia, we should better differentiate error statuses for transaction failures.
https://github.com/MySQLOnRocksDB/mysql-5.6/issues/86#issuecomment-124605954
Test Plan: unit tests
Reviewers: rven, kradhakrishnan, spetrunia, yhchiang, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43323/Pessimistic Transactions
Summary:
Initial implementation of Pessimistic Transactions.  This diff contains the api changes discussed in D38913.  This diff is pretty large, so let me know if people would prefer to meet up to discuss it.
MyRocks folks:  please take a look at the API in include/rocksdb/utilities/transaction[_db].h and let me know if you have any issues.
Also, you'll notice a couple of TODOs in the implementation of RollbackToSavePoint().  After chatting with Siying, I'm going to send out a separate diff for an alternate implementation of this feature that implements the rollback inside of WriteBatch/WriteBatchWithIndex.  We can then decide which route is preferable.
Next, I'm planning on doing some perf testing and then integrating this diff into MongoRocks for further testing.
Test Plan: Unit tests, db_bench parallel testing.
Reviewers: igor, rven, sdong, yhchiang, yoshinorim
Reviewed By: sdong
Subscribers: hermanlee4, maykov, spetrunia, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D40869/Avoid type unique_ptr in LogWriterNumber::writer for Windows build break
Summary:
Visual Studio complains about deque<LogWriterNumber> because LogWriterNumber is non-copyable for its unique_ptr member writer. Move away from it, and do explit free.
It is less safe but I can't think of a better way to unblock it.
Test Plan: valgrind check test
Reviewers: anthony, IslamAbdelRahman, kolmike, rven, yhchiang
Reviewed By: yhchiang
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D43647/[wal changes 3/3] method in DB to sync WAL without blocking writers
Summary:
Subj. We really need this feature.
Previous diff D40899 has most of the changes to make this possible, this diff just adds the method.
Test Plan: `make check`, the new test fails without this diff; ran with ASAN, TSAN and valgrind.
Reviewers: igor, rven, IslamAbdelRahman, anthony, kradhakrishnan, tnovak, yhchiang, sdong
Reviewed By: sdong
Subscribers: MarkCallaghan, maykov, hermanlee4, yoshinorim, tnovak, dhruba
Differential Revision: https://reviews.facebook.net/D40905/Fix when output level is 0 of universal compaction with trivial move
Summary: Fix for universal compaction with trivial move, when the ouput level is 0. The tests where failing. Fixed by allowing normal compaction when output level is 0.
Test Plan: modified test cases run successfully.
Reviewers: sdong, yhchiang, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: anthony, kradhakrishnan, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D42933/[wal changes 2/3] write with sync=true syncs previous unsynced wals to prevent illegal data loss
Summary:
I'll just copy internal task summary here:
""
This sequence will cause data loss in the middle after an sync write:
non-sync write key 1
flush triggered, not yet scheduled
sync write key 2
system crash
After rebooting, users might see key 2 but not key 1, which violates the API of sync write.
This can be reproduced using unit test FaultInjectionTest::DISABLED_WriteOptionSyncTest.
One way to fix it is for a sync write, if there is outstanding unsynced log files, we need to syc them too.
""
This diff should be considered together with the next diff D40905; in isolation this fix probably could be a little simpler.
Test Plan: `make check`; added a test for that (DBTest.SyncingPreviousLogs) before noticing FaultInjectionTest.WriteOptionSyncTest (keeping both since mine asserts a bit more); both tests fail without this diff; for D40905 stacked on top of this diff, ran tests with ASAN, TSAN and valgrind
Reviewers: rven, yhchiang, IslamAbdelRahman, anthony, kradhakrishnan, igor, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D40899/Improved FileExists API
Summary: Add new CheckFileExists method.  Considered changing the FileExists api but didn't want to break anyone's builds.
Test Plan: unit tests
Reviewers: yhchiang, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D42003/Fix data loss after DB recovery by not allowing flush/compaction to be scheduled until DB opened
Summary:
Previous run may leave some SST files with higher file numbers than manifest indicates.
Compaction or flush may start to run while DB::Open() is still going on. SST file garbage collection may happen interleaving with compaction or flush, and overwrite files generated by compaction of flushes after they are generated. This might cause data loss. This possibility of interleaving is recently introduced.
Fix it by not allowing compaction or flush to be scheduled before DB::Open() finishes.
Test Plan: Add a unit test. This verification will have a chance to fail without the fix but doesn't fix without the fix.
Reviewers: kradhakrishnan, anthony, yhchiang, IslamAbdelRahman, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D42399/Fixing delete files in Trivial move of universal compaction
Summary:
Trvial move in universal compaction was failing when trying to move files from levels other than 0.
This was because the DeleteFile while trivially moving, was only deleting files of level 0 which caused duplication of same file in different levels.
This is fixed by passing the right level as argument in the call of DeleteFile while doing trivial move.
Test Plan: ./db_test ran successfully with the new test cases.
Reviewers: sdong
Reviewed By: sdong
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D42135/Deprecate WriteOptions::timeout_hint_us
Summary:
In one of our recent meetings, we discussed deprecating features that are not being actively used. One of those features, at least within Facebook, is timeout_hint. The feature is really nicely implemented, but if nobody needs it, we should remove it from our code-base (until we get a valid use-case). Some arguments:
* Less code == better icache hit rate, smaller builds, simpler code
* The motivation for adding timeout_hint_us was to work-around RocksDB's stall issue. However, we're currently addressing the stall issue itself (see @sdong's recent work on stall write_rate), so we should never see sharp lock-ups in the future.
* Nobody is using the feature within Facebook's code-base. Googling for `timeout_hint_us` also doesn't yield any users.
Test Plan: make check
Reviewers: anthony, kradhakrishnan, sdong, yhchiang
Reviewed By: yhchiang
Subscribers: sdong, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D41937/Fix function name format according to google style
Summary: Change the naming style of getter and setters according to Google C++ style in compaction.h file
Test Plan: Compilation success
Reviewers: sdong
Reviewed By: sdong
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D41265/Enabling trivial move in universal compaction
Summary: This change enables trivial move if all the input files are non onverlapping while doing Universal Compaction.
Test Plan: ./compaction_picker_test and db_test ran successfully with the new testcases.
Reviewers: sdong
Reviewed By: sdong
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D40875/fixed leaking log::Writers
Summary: Fixes valgrind errors in column_family_test.
Test Plan: `make check`, `make valgrind_check`
Reviewers: igor, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D41181/[wal changes 1/3] fixed unbounded wal growth in some workloads
Summary:
This fixes the following scenario we've hit:
- we reached max_total_wal_size, created a new wal and scheduled flushing all memtables corresponding to the old one,
- before the last of these flushes started its column family was dropped; the last background flush call was a no-op; no one removed the old wal from alive_logs_,
- hours have passed and no flushes happened even though lots of data was written; data is written to different column families, compactions are disabled; old column families are dropped before memtable grows big enough to trigger a flush; the old wal still sits in alive_logs_ preventing max_total_wal_size limit from kicking in,
- a few more hours pass and we run out disk space because of one huge .log file.
Test Plan: `make check`; backported the new test, checked that it fails without this diff
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D40893/Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/Make flush check for shutdown
Summary:
Fixes task 7156865 where a compaction causes a hang in flush
memtable if CancelAllBackgroundWork was called prior to it.
Stack trace is in : https://phabricator.fb.com/P19848829
We end up waiting for a flush which will never happen because there are no background threads.
Test Plan: PreShutdownFlush
Reviewers: sdong, igor
Reviewed By: sdong, igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D40617/Fix trivial move merge
Summary: Fixing bad merge
Test Plan: make -j64 check (this is not enough to verify the fix)
Reviewers: igor, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D40521/Fail DB::Open() when the requested compression is not available
Summary:
Currently RocksDB silently ignores this issue and doesn't compress the data. Based on discussion, we agree that this is pretty bad because it can cause confusion for our users.
This patch fails DB::Open() if we don't support the compression that is specified in the options.
Test Plan: make check with LZ4 not present. If Snappy is not present all tests will just fail because Snappy is our default library. We should make Snappy the requirement, since without it our default DB::Open() fails.
Reviewers: sdong, MarkCallaghan, rven, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39687/Merge branch 'master' of github.com:facebook/rocksdb
D40233: Replace %llu with format macros in ParsedInternalKey::DebugString())/Fixed a bug of CompactionStats in multi-level universal compaction case
Summary:
Universal compaction can involves in multiple levels.  However,
the current implementation of bytes_readn and bytes_readnp1
(and some other stats with postfix `n` and `np1`) assumes compaction
can only have two levels.
This patch fixes this bug and redefines bytes_readn and bytes_readnp1:
* bytes_readnp1: the number of bytes read in the compaction output level.
* bytes_readn: the total number of bytes read minus bytes_readnp1
Test Plan: Add a test in compaction_job_stats_test
Reviewers: igor, sdong, rven, anthony, kradhakrishnan, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D40239/Merge branch 'master' of github.com:facebook/rocksdb
D40233: Replace %llu with format macros in ParsedInternalKey::DebugString())/Allow GetApproximateSize() to include mem table size if it is skip list memtable
Summary:
Add an option in GetApproximateSize() so that the result will include estimated sizes in mem tables.
To implement it, implement an estimated count from the beginning to a key in skip list. The approach is to count to find the entry, how many Next() is issued from each level, and sum them with a weight that is <branching factor> ^ <level>.
Test Plan: Add a test case
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D40119/Fix hang when closing a DB after doing loads with WAL disabled.
Summary:
There is a hang during DB close in the following scenario:
a) a load with WAL disabled was done,
b) CancelAllBackgroundWork was called,
c) DB Close was called
This was because in that we will wait for a flush but we cannot do a
background flush because we have called CancelAllBackgroundWork which
marks the DB as shutting downn.
Test Plan: Added DBTest FlushOnDestroy
Reviewers: sdong
Reviewed By: sdong
Subscribers: yoshinorim, hermanlee4, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39747/GetSnapshot() and ReleaseSnapshot() to move new and free out of DB mutex
Summary: We currently issue malloc and free inside DB mutex in GetSnapshot() and ReleaseSnapshot(). Move them out.
Test Plan:
Go through all tests
make valgrind_check
Reviewers: yhchiang, rven, IslamAbdelRahman, anthony, igor
Reviewed By: igor
Subscribers: maykov, hermanlee4, MarkCallaghan, yoshinorim, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D39753/Unlock mutex in ReFitLevel
Summary: I encountered an issue where the database hang, it looks like the mutex is not unlocked on return in ReFitLevel function
Test Plan: make -j64 check
Reviewers: yhchiang, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D39609/Fixed the tsan failure in util/compaction_job_stats_impl.cc
Summary:
The type of smallest_output_key_prefix and largest_output_key_prefix
have been changed to std::string in https://reviews.facebook.net/D39537.
As a result, we shouldn't do smallest_output_key_prefix[0] = 0 in the
initialization.
Test Plan: compile db_test with tsan enabled and repeat DBTest.CompactionDeletionTrigger test to verify the tsan issue has been gone.
Reviewers: igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39645/Allowing L0 -> L1 trivial move on sorted data
Summary:
This diff updates the logic of how we do trivial move, now trivial move can run on any number of files in input level as long as they are not overlapping
The conditions for trivial move have been updated
Introduced conditions:
- Trivial move cannot happen if we have a compaction filter (except if the compaction is not manual)
- Input level files cannot be overlapping
Removed conditions:
- Trivial move only run when the compaction is not manual
- Input level should can contain only 1 file
More context on what tests failed because of Trivial move
```
DBTest.CompactionsGenerateMultipleFiles
This test is expecting compaction on a file in L0 to generate multiple files in L1, this test will fail with trivial move because we end up with one file in L1
```
```
DBTest.NoSpaceCompactRange
This test expect compaction to fail when we force environment to report running out of space, of course this is not valid in trivial move situation
because trivial move does not need any extra space, and did not check for that
```
```
DBTest.DropWrites
Similar to DBTest.NoSpaceCompactRange
```
```
DBTest.DeleteObsoleteFilesPendingOutputs
This test expect that a file in L2 is deleted after it's moved to L3, this is not valid with trivial move because although the file was moved it is now used by L3
```
```
CuckooTableDBTest.CompactionIntoMultipleFiles
Same as DBTest.CompactionsGenerateMultipleFiles
```
This diff is based on a work by @sdong https://reviews.facebook.net/D34149
Test Plan: make -j64 check
Reviewers: rven, sdong, igor
Reviewed By: igor
Subscribers: yhchiang, ott, march, dhruba, sdong
Differential Revision: https://reviews.facebook.net/D34797/Fix compile warning in db/db_impl
Summary:
Fix the following compile warning in db/db_impl
db/db_impl.cc:1603:19: error: implicit conversion loses integer precision: 'const uint64_t' (aka 'const unsigned long') to 'int' [-Werror,-Wshorten-64-to-32]
info.job_id = job_id;
~ ^~~~~~
Test Plan: db_test
Reviewers: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39423/Allow EventListener::OnCompactionCompleted to return CompactionJobStats.
Summary:
Allow EventListener::OnCompactionCompleted to return CompactionJobStats,
which contains useful information about a compaction.
Example CompactionJobStats returned by OnCompactionCompleted():
smallest_output_key_prefix 05000000
largest_output_key_prefix 06990000
elapsed_time 42419
num_input_records 300
num_input_files 3
num_input_files_at_output_level 2
num_output_records 200
num_output_files 1
actual_bytes_input 167200
actual_bytes_output 110688
total_input_raw_key_bytes 5400
total_input_raw_value_bytes 300000
num_records_replaced 100
is_manual_compaction 1
Test Plan: Developed a mega test in db_test which covers 20 variables in CompactionJobStats.
Reviewers: rven, igor, anthony, sdong
Reviewed By: sdong
Subscribers: tnovak, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D38463/fix LITE build
Summary: Broken by optimistic transaction diff.  (I only built 'release' not 'static_lib' when testing).
Test Plan: build
Reviewers: yhchiang, sdong, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39219/Optimistic Transactions
Summary: Optimistic transactions supporting begin/commit/rollback semantics.  Currently relies on checking the memtable to determine if there are any collisions at commit time.  Not yet implemented would be a way of enuring the memtable has some minimum amount of history so that we won't fail to commit when the memtable is empty.  You should probably start with transaction.h to get an overview of what is currently supported.
Test Plan: Added a new test, but still need to look into stress testing.
Reviewers: yhchiang, igor, rven, sdong
Reviewed By: sdong
Subscribers: adamretter, MarkCallaghan, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D33435/Support saving history in memtable_list
Summary:
For transactions, we are using the memtables to validate that there are no write conflicts.  But after flushing, we don't have any memtables, and transactions could fail to commit.  So we want to someone keep around some extra history to use for conflict checking.  In addition, we want to provide a way to increase the size of this history if too many transactions fail to commit.
After chatting with people, it seems like everyone prefers just using Memtables to store this history (instead of a separate history structure).  It seems like the best place for this is abstracted inside the memtable_list.  I decide to create a separate list in MemtableListVersion as using the same list complicated the flush/installalflushresults logic too much.
This diff adds a new parameter to control how much memtable history to keep around after flushing.  However, it sounds like people aren't too fond of adding new parameters.  So I am making the default size of flushed+not-flushed memtables be set to max_write_buffers.  This should not change the maximum amount of memory used, but make it more likely we're using closer the the limit.  (We are now postponing deleting flushed memtables until the max_write_buffer limit is reached).  So while we might use more memory on average, we are still obeying the limit set (and you could argue it's better to go ahead and use up memory now instead of waiting for a write stall to happen to test this limit).
However, if people are opposed to this default behavior, we can easily set it to 0 and require this parameter be set in order to use transactions.
Test Plan: Added a xfunc test to play around with setting different values of this parameter in all tests.  Added testing in memtablelist_test and planning on adding more testing here.
Reviewers: sdong, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37443/Fixed two bugs on logging file deletion.
Summary:
This patch fixes the following two bugs on logging file deletion.
1.  Previously, file deletion failure was only logged in INFO_LEVEL.
This patch changes it to ERROR_LEVEL and does some code clean.
2.  EventLogger previously will always generate the same log on
table file deletion even when file deletion is not successful.
Now the resulting status of file deletion will also be logged.
Test Plan: make all check
Reviewers: sdong, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D38817/Change the log-level of DB summary and options from INFO_LEVEL to WARN_LEVEL
Summary: Change the log-level of DB summary and options from INFO_LEVEL to WARN_LEVEL
Test Plan:
Use db_bench to verify the log level.
Sample output:
2015/05/22-00:20:39.778064 7fff75b41300 [WARN] RocksDB version: 3.11.0
2015/05/22-00:20:39.778095 7fff75b41300 [WARN] Git sha rocksdb_build_git_sha:7fee8775a459134c4cb04baae5bd1687e268f2a0
2015/05/22-00:20:39.778099 7fff75b41300 [WARN] Compile date May 22 2015
2015/05/22-00:20:39.778101 7fff75b41300 [WARN] DB SUMMARY
2015/05/22-00:20:39.778145 7fff75b41300 [WARN] SST files in /tmp/rocksdbtest-691931916/dbbench dir, Total Num: 0, files:
2015/05/22-00:20:39.778148 7fff75b41300 [WARN] Write Ahead Log file in /tmp/rocksdbtest-691931916/dbbench:
2015/05/22-00:20:39.778150 7fff75b41300 [WARN]          Options.error_if_exists: 0
2015/05/22-00:20:39.778152 7fff75b41300 [WARN]        Options.create_if_missing: 1
2015/05/22-00:20:39.778153 7fff75b41300 [WARN]          Options.paranoid_checks: 1
Reviewers: MarkCallaghan, igor, kradhakrishnan
Reviewed By: igor
Subscribers: sdong, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D38835/Avoid logging under mutex in DBImpl::WriteLevel0TableForRecovery().
Summary: Avoid logging under mutex in DBImpl::WriteLevel0TableForRecovery().
Test Plan: make all check
Reviewers: igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D38823/Allow flushes to run in parallel with manual compaction
Summary: As title. I spent some time thinking about it and I don't think there should be any issue with running manual compaction and flushes in parallel
Test Plan: make check works
Reviewers: rven, yhchiang, sdong
Reviewed By: yhchiang, sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D38355/"
rocksdb,"Deprecate purge_redundant_kvs_while_flush
Summary: This option is guarding the feature implemented 2 and a half years ago: D8991. The feature was enabled by default back then and has been running without issues. There is no reason why any client would turn this feature off. I found no reference in fbcode.
Test Plan: none
Reviewers: sdong, yhchiang, anthony, dhruba
Reviewed By: dhruba
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D42063/Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/Merge branch 'master' of github.com:facebook/rocksdb
D40233: Replace %llu with format macros in ParsedInternalKey::DebugString())/Support saving history in memtable_list
Summary:
For transactions, we are using the memtables to validate that there are no write conflicts.  But after flushing, we don't have any memtables, and transactions could fail to commit.  So we want to someone keep around some extra history to use for conflict checking.  In addition, we want to provide a way to increase the size of this history if too many transactions fail to commit.
After chatting with people, it seems like everyone prefers just using Memtables to store this history (instead of a separate history structure).  It seems like the best place for this is abstracted inside the memtable_list.  I decide to create a separate list in MemtableListVersion as using the same list complicated the flush/installalflushresults logic too much.
This diff adds a new parameter to control how much memtable history to keep around after flushing.  However, it sounds like people aren't too fond of adding new parameters.  So I am making the default size of flushed+not-flushed memtables be set to max_write_buffers.  This should not change the maximum amount of memory used, but make it more likely we're using closer the the limit.  (We are now postponing deleting flushed memtables until the max_write_buffer limit is reached).  So while we might use more memory on average, we are still obeying the limit set (and you could argue it's better to go ahead and use up memory now instead of waiting for a write stall to happen to test this limit).
However, if people are opposed to this default behavior, we can easily set it to 0 and require this parameter be set in order to use transactions.
Test Plan: Added a xfunc test to play around with setting different values of this parameter in all tests.  Added testing in memtablelist_test and planning on adding more testing here.
Reviewers: sdong, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37443/"
rocksdb,"Fix CompactFiles by adding all necessary files
Summary:
The compact files API had a bug where some overlapping files
are not added. These are files which overlap with files which were
added to the compaction input files, but not to the original set of
input files. This happens only when there are more than two levels
involved in the compaction. An example will illustrate this better.
Level 2 has 1 input file 1.sst which spans [20,30].
Level 3 has added file  2.sst which spans [10,25]
Level 4 has file 3.sst which spans [35,40] and
input file 4.sst which spans [46,50].
The existing code would not add 3.sst to the set of input_files because
it only becomes an overlapping file in level 4 and it wasn't one in
level 3.
When installing the results of the compaction, 3.sst would overlap with
output file from the compact files and result in the assertion in
version_set.cc:1130
// Must not overlap
assert(level <= 0 || level_files->empty() ||
internal_comparator_->Compare(
(*level_files)[level_files->size() - 1]->largest, f->smallest) <
0);
This change now adds overlapping files from the current level to the set
of input files also so that we don't hit the assertion above.
Test Plan:
d=/tmp/j; rm -rf $d; seq 1000 | parallel --gnu --eta
'd=/tmp/j/d-{}; mkdir -p $d; TEST_TMPDIR=$d ./db_compaction_test
--gtest_filter=*CompactilesOnLevel* --gtest_also_run_disabled_tests >&
'$d'/log-{}'
Reviewers: igor, yhchiang, sdong
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43437/Fix when output level is 0 of universal compaction with trivial move
Summary: Fix for universal compaction with trivial move, when the ouput level is 0. The tests where failing. Fixed by allowing normal compaction when output level is 0.
Test Plan: modified test cases run successfully.
Reviewers: sdong, yhchiang, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: anthony, kradhakrishnan, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D42933/Build fix.
Summary: gcc-4.9-glibc-2.20 complains about uninitialized variable.
db/compaction_picker.cc: In member function 'bool
rocksdb::CompactionPicker::IsInputNonOverlapping(rocksdb::Compaction*)':
db/compaction_picker.cc:1174:17: error:
'prev.rocksdb::{anonymous}::InputFileInfo::f' may be used uninitialized in this
function [-Werror=maybe-uninitialized]
InputFileInfo prev, curr, next;
Test Plan: pmake on local environment
Reviewers: sdong igor
CC: leveldb@
Task ID: #
Blame Rev:/Build fail fix
Summary: Build fail fix. Type cast issues.
Test Plan: compiled
Reviewers: sdong, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D41349/Enabling trivial move in universal compaction
Summary: This change enables trivial move if all the input files are non onverlapping while doing Universal Compaction.
Test Plan: ./compaction_picker_test and db_test ran successfully with the new testcases.
Reviewers: sdong
Reviewed By: sdong
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D40875/Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/Don't let two L0->L1 compactions run in parallel
Summary: With experimental feature SuggestCompactRange() we don't restrict running two L0->L1 compactions in parallel. This diff fixes this.
Test Plan: added a unit test to reproduce the failure. fixed the unit test
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39981/Take a chance on a random file when choosing compaction
Summary:
When trying to compact entire database with SuggestCompactRange(), we'll first try the left-most files. This is pretty bad, because:
1) the left part of LSM tree will be overly compacted, but right part will not be touched
2) First compaction will pick up the left-most file. Second compaction will try to pick up next left-most, but this will not be possible, because there's a big chance that second's file range on N+1 level is already being compacted.
I observe both of those problems when running Mongo+RocksDB and trying to compact the DB to clean up tombstones. I'm unable to clean them up :(
This diff adds a bit of randomness into choosing a file. First, it chooses a file at random and tries to compact that one. This should solve both problems specified here.
Test Plan: make check
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D38379/"
rocksdb,"Removing duplicate code in db_bench/db_stress, fixing typos
Summary:
While working on single delete support for db_bench, I realized that
db_bench/db_stress contain a bunch of duplicate code related to
copmression and found some typos. This patch removes duplicate code,
typos and a redundant #ifndef in internal_stats.cc.
Test Plan: make db_stress && make db_bench && ./db_bench --benchmarks=compress,uncompress
Reviewers: yhchiang, sdong, rven, anthony, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43965/Report live data size estimate
Summary:
Fixes T6548822. Added a new function for estimating the size of the live data
as proposed in the task. The value can be accessed through the property
rocksdb.estimate-live-data-size.
Test Plan:
There are two unit tests in version_set_test and a simple test in db_test.
make version_set_test && ./version_set_test;
make db_test && ./db_test gtest_filter=GetProperty
Reviewers: rven, igor, yhchiang, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D41493/Merge branch 'master' of github.com:facebook/rocksdb
D40233: Replace %llu with format macros in ParsedInternalKey::DebugString())/Fixed a bug of CompactionStats in multi-level universal compaction case
Summary:
Universal compaction can involves in multiple levels.  However,
the current implementation of bytes_readn and bytes_readnp1
(and some other stats with postfix `n` and `np1`) assumes compaction
can only have two levels.
This patch fixes this bug and redefines bytes_readn and bytes_readnp1:
* bytes_readnp1: the number of bytes read in the compaction output level.
* bytes_readn: the total number of bytes read minus bytes_readnp1
Test Plan: Add a test in compaction_job_stats_test
Reviewers: igor, sdong, rven, anthony, kradhakrishnan, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D40239/Support saving history in memtable_list
Summary:
For transactions, we are using the memtables to validate that there are no write conflicts.  But after flushing, we don't have any memtables, and transactions could fail to commit.  So we want to someone keep around some extra history to use for conflict checking.  In addition, we want to provide a way to increase the size of this history if too many transactions fail to commit.
After chatting with people, it seems like everyone prefers just using Memtables to store this history (instead of a separate history structure).  It seems like the best place for this is abstracted inside the memtable_list.  I decide to create a separate list in MemtableListVersion as using the same list complicated the flush/installalflushresults logic too much.
This diff adds a new parameter to control how much memtable history to keep around after flushing.  However, it sounds like people aren't too fond of adding new parameters.  So I am making the default size of flushed+not-flushed memtables be set to max_write_buffers.  This should not change the maximum amount of memory used, but make it more likely we're using closer the the limit.  (We are now postponing deleting flushed memtables until the max_write_buffer limit is reached).  So while we might use more memory on average, we are still obeying the limit set (and you could argue it's better to go ahead and use up memory now instead of waiting for a write stall to happen to test this limit).
However, if people are opposed to this default behavior, we can easily set it to 0 and require this parameter be set in order to use transactions.
Test Plan: Added a xfunc test to play around with setting different values of this parameter in all tests.  Added testing in memtablelist_test and planning on adding more testing here.
Reviewers: sdong, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37443/Don't skip last level when calculating compaction stats
Summary: We have a bug where we don't report the last level's files as being compacted. This fixes it.
Test Plan: See the fix in action here: https://phabricator.fb.com/P19845738
Reviewers: MarkCallaghan, sdong
Reviewed By: sdong
Subscribers: yhchiang, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D38727/Add --wal_bytes_per_sync for db_bench and more IO stats
Summary:
See https://gist.github.com/mdcallag/89ebb2b8cbd331854865 for the IO stats.
I added ""Cumulative compaction:"" and ""Interval compaction:"" lines. The IO rates
can be confusing. Rates fro per-level stats lines, Wr(MB/s) & Rd(MB/s), are computed
using the duration of the compaction job. If the job reads 10MB, writes 9MB and the job
(IO & merging) takes 1 second then the rates are 10MB/s for read and 9MB/s for writes.
The IO rates in the Cumulative compaction line uses the total uptime. The IO rates in the
Interval compaction line uses the interval uptime. So these Cumalative & Interval
compaction IO rates cannot be compared to the per-level IO rates. But both forms of
the rates are useful for debugging perf.
Task ID: #
Blame Rev:
Test Plan:
run db_bench
Revert Plan:
Database Impact:
Memcache Impact:
Other Notes:
EImportant:
- begin *PUBLIC* platform impact section -
Bugzilla: #
- end platform impact -
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D38667/"
rocksdb,"Removing duplicate code in db_bench/db_stress, fixing typos
Summary:
While working on single delete support for db_bench, I realized that
db_bench/db_stress contain a bunch of duplicate code related to
copmression and found some typos. This patch removes duplicate code,
typos and a redundant #ifndef in internal_stats.cc.
Test Plan: make db_stress && make db_bench && ./db_bench --benchmarks=compress,uncompress
Reviewers: yhchiang, sdong, rven, anthony, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43965/Fix build failure
Summary: fix the build failure
Test Plan: make all
Reviewers: sdong, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43623/Enable DBTest.FlushSchedule under TSAN
Summary: This patch will fix the false positive of DBTest.FlushSchedule under TSAN, we dont need to disable this test
Test Plan: COMPILE_WITH_TSAN=1 make -j64 db_test && ./db_test --gtest_filter=""DBTest.FlushSchedule""
Reviewers: yhchiang, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D43599/Fix misplaced position for reversing iterator direction while current key is a merge
Summary:
While doing forward iterating, if current key is merge, internal iterator position is placed to the next key. If Prev() is called now, needs to do extra Prev() to recover the location.
This is second attempt of fixing after reverting ec70fea4c4025351190eba7a02bd09bb5f083790. This time shrink the fix to only merge key is the current key and avoid the reseeking logic for max_iterating skipping
Test Plan: enable the two disabled tests and make sure they pass
Reviewers: rven, IslamAbdelRahman, kradhakrishnan, tnovak, yhchiang
Reviewed By: yhchiang
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D43557/[wal changes 3/3] method in DB to sync WAL without blocking writers
Summary:
Subj. We really need this feature.
Previous diff D40899 has most of the changes to make this possible, this diff just adds the method.
Test Plan: `make check`, the new test fails without this diff; ran with ASAN, TSAN and valgrind.
Reviewers: igor, rven, IslamAbdelRahman, anthony, kradhakrishnan, tnovak, yhchiang, sdong
Reviewed By: sdong
Subscribers: MarkCallaghan, maykov, hermanlee4, yoshinorim, tnovak, dhruba
Differential Revision: https://reviews.facebook.net/D40905/fixed DBTest.GetPropertiesOfAllTablesTest and DBTest.GetUserDefinedTablaProperties flakiness
Summary: These tests used to fail if a compaction happened between flushing tables and enumerating them to get properties.
Test Plan: this reports occasional failures without this diff and no failures with it: `for i in {1..10000}; do echo $i; done | parallel --gnu -j100 'TEST_TMPDIR=`TMPDIR=/dev/shm/rockstemp mktemp -d -t` ./db_test --gtest_filter=DBTest.GetUserDefinedTablaProperties >&/dev/null || echo {} failed'`
Reviewers: sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D42861/Report live data size estimate
Summary:
Fixes T6548822. Added a new function for estimating the size of the live data
as proposed in the task. The value can be accessed through the property
rocksdb.estimate-live-data-size.
Test Plan:
There are two unit tests in version_set_test and a simple test in db_test.
make version_set_test && ./version_set_test;
make db_test && ./db_test gtest_filter=GetProperty
Reviewers: rven, igor, yhchiang, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D41493/Fix undeterministic failure of DBTest.GetPropertiesOfAllTablesTest
Summary: DBTest.GetPropertiesOfAllTablesTest generates four files and expects four files there, but a L0->L1 comapction can trigger to compact to one single file. Fix it by raising level 0 number of file compaction trigger
Test Plan: Run it many times and see it never fails.
Reviewers: kradhakrishnan, IslamAbdelRahman, yhchiang, anthony
Reviewed By: anthony
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D42789/Improved FileExists API
Summary: Add new CheckFileExists method.  Considered changing the FileExists api but didn't want to break anyone's builds.
Test Plan: unit tests
Reviewers: yhchiang, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D42003/Relax assertions in unit DropWrites to be more permissible
Summary: This unit test is blocking our release since it fails under certain
compiler versions. The failure is due to a race in the unit test and not the
core functionality.
Test Plan: Run locally
Reviewers: sdong
CC: leveldb
Task ID: #7760955
Blame Rev:/Fixing delete files in Trivial move of universal compaction
Summary:
Trvial move in universal compaction was failing when trying to move files from levels other than 0.
This was because the DeleteFile while trivially moving, was only deleting files of level 0 which caused duplication of same file in different levels.
This is fixed by passing the right level as argument in the call of DeleteFile while doing trivial move.
Test Plan: ./db_test ran successfully with the new test cases.
Reviewers: sdong
Reviewed By: sdong
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D42135/Deprecate purge_redundant_kvs_while_flush
Summary: This option is guarding the feature implemented 2 and a half years ago: D8991. The feature was enabled by default back then and has been running without issues. There is no reason why any client would turn this feature off. I found no reference in fbcode.
Test Plan: none
Reviewers: sdong, yhchiang, anthony, dhruba
Reviewed By: dhruba
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D42063/Deprecate WriteOptions::timeout_hint_us
Summary:
In one of our recent meetings, we discussed deprecating features that are not being actively used. One of those features, at least within Facebook, is timeout_hint. The feature is really nicely implemented, but if nobody needs it, we should remove it from our code-base (until we get a valid use-case). Some arguments:
* Less code == better icache hit rate, smaller builds, simpler code
* The motivation for adding timeout_hint_us was to work-around RocksDB's stall issue. However, we're currently addressing the stall issue itself (see @sdong's recent work on stall write_rate), so we should never see sharp lock-ups in the future.
* Nobody is using the feature within Facebook's code-base. Googling for `timeout_hint_us` also doesn't yield any users.
Test Plan: make check
Reviewers: anthony, kradhakrishnan, sdong, yhchiang
Reviewed By: yhchiang
Subscribers: sdong, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D41937/Move reusable part of db_test.cc to util/db_test_util.h
Summary:
Move reusable part of db_test.cc to util/db_test_util.h.
This makes it more possible to partition db_test.cc into
multiple smaller test files.
Also, fixed many old lint errors in db_test.
Test Plan: db_test
Reviewers: igor, anthony, IslamAbdelRahman, sdong, kradhakrishnan
Reviewed By: sdong, kradhakrishnan
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D41973/Fix a noisy unit test.
Summary: The t/DBTest.DropWrites test still fails under certain gcc version in release unit test.
I unfortunately cannot repro the failure (since the compilers have mapped library which I am not able to map to correctly). I am suspecting the clock skew.
Test Plan: Run make check
Reviewers:
CC: sdong igore
Task ID: #7312624
Blame Rev:/ All of these are in the new code added past 3.10
1) Crash in env_win.cc that prevented db_test run to completion and some new tests
2) Fix new corruption tests in DBTest by allowing a shared trunction of files. Note that this is generally needed ONLY for tests.
3) Close database so WAL is closed prior to inducing corruption similar to what we did within Corruption tests./Fix function name format according to google style
Summary: Change the naming style of getter and setters according to Google C++ style in compaction.h file
Test Plan: Compilation success
Reviewers: sdong
Reviewed By: sdong
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D41265/Enabling trivial move in universal compaction
Summary: This change enables trivial move if all the input files are non onverlapping while doing Universal Compaction.
Test Plan: ./compaction_picker_test and db_test ran successfully with the new testcases.
Reviewers: sdong
Reviewed By: sdong
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D40875/Fixed a bug in test ThreadStatusSingleCompaction
Summary:
Fixed a bug in test ThreadStatusSingleCompaction where
SyncPoint traces are not cleared before the test begins
its second iteration.
Test Plan: db_test
Reviewers: sdong, anthony, IslamAbdelRahman, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D41337/fixed leaking log::Writers
Summary: Fixes valgrind errors in column_family_test.
Test Plan: `make check`, `make valgrind_check`
Reviewers: igor, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D41181/Revert two diffs related to DBIter::FindPrevUserKey()
Summary:
This diff reverts the following two previous diffs related to
DBIter::FindPrevUserKey(), which makes db_stress unstable.
We should bake a better fix for this.
* ""Fix a comparison in DBIter::FindPrevUserKey()""
ec70fea4c4025351190eba7a02bd09bb5f083790.
* ""Fixed endless loop in DBIter::FindPrevUserKey()""
acee2b08a2d37154b8f9e2dc74b1966202c15ec5.
Test Plan: db_stress
Reviewers: anthony, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D41301/[wal changes 1/3] fixed unbounded wal growth in some workloads
Summary:
This fixes the following scenario we've hit:
- we reached max_total_wal_size, created a new wal and scheduled flushing all memtables corresponding to the old one,
- before the last of these flushes started its column family was dropped; the last background flush call was a no-op; no one removed the old wal from alive_logs_,
- hours have passed and no flushes happened even though lots of data was written; data is written to different column families, compactions are disabled; old column families are dropped before memtable grows big enough to trigger a flush; the old wal still sits in alive_logs_ preventing max_total_wal_size limit from kicking in,
- a few more hours pass and we run out disk space because of one huge .log file.
Test Plan: `make check`; backported the new test, checked that it fails without this diff
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D40893/Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/Increasing timeout for drop writes.
Summary: We have a race in the way test works. We avoided the race by adding the
wait to the counter. I thought 1s was eternity, but that is not true in some
scenarios. Increasing the timeout to 10s and adding warnings.
Also, adding nosleep to avoid the case where the wakeup thread is waiting behind
the sleeping thread for scheduling.
Test Plan: Run make check
Reviewers: siying igorcanadi
CC: leveldb@
Task ID: #7312624
Blame Rev:/Fix a comparison in DBIter::FindPrevUserKey()
Summary:
When seek target is a merge key (`kTypeMerge`), `DBIter::FindNextUserEntry()`
advances the underlying iterator _past_ the current key (`saved_key_`); see
`MergeValuesNewToOld()`. However, `FindPrevUserKey()` assumes that `iter_`
points to an entry with the same user key as `saved_key_`. As a result,
`it->Seek(key) && it->Prev()` can cause the iterator to be positioned at the
_next_, instead of the previous, entry (new test, written by @lovro, reproduces
the bug).
This diff changes `FindPrevUserKey()` to also skip keys that are _greater_ than
`saved_key_`.
Test Plan: db_test
Reviewers: igor, sdong
Reviewed By: sdong
Subscribers: leveldb, dhruba, lovro
Differential Revision: https://reviews.facebook.net/D40791/Fix race in unit test.
Summary: Avoid falling victim to race condition.
Test Plan: Run the unit test
Reviewers: sdong igor
CC: leveldb@
Task ID: #7312624
Blame Rev:/Make flush check for shutdown
Summary:
Fixes task 7156865 where a compaction causes a hang in flush
memtable if CancelAllBackgroundWork was called prior to it.
Stack trace is in : https://phabricator.fb.com/P19848829
We end up waiting for a flush which will never happen because there are no background threads.
Test Plan: PreShutdownFlush
Reviewers: sdong, igor
Reviewed By: sdong, igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D40617/Updating SeekToLast with upper bound
Summary: #7124486: RocksDB's Iterator.SeekToLast should seek to the last key before iterate_upper_bound if presents
Test Plan: ./db_iter_test run successfully with the new testcase
Reviewers: rven, yhchiang, igor, anthony, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D40425/Fail DB::Open() when the requested compression is not available
Summary:
Currently RocksDB silently ignores this issue and doesn't compress the data. Based on discussion, we agree that this is pretty bad because it can cause confusion for our users.
This patch fails DB::Open() if we don't support the compression that is specified in the options.
Test Plan: make check with LZ4 not present. If Snappy is not present all tests will just fail because Snappy is our default library. We should make Snappy the requirement, since without it our default DB::Open() fails.
Reviewers: sdong, MarkCallaghan, rven, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39687/Merge branch 'master' of github.com:facebook/rocksdb
D40233: Replace %llu with format macros in ParsedInternalKey::DebugString())/Allow GetApproximateSize() to include mem table size if it is skip list memtable
Summary:
Add an option in GetApproximateSize() so that the result will include estimated sizes in mem tables.
To implement it, implement an estimated count from the beginning to a key in skip list. The approach is to count to find the entry, how many Next() is issued from each level, and sum them with a weight that is <branching factor> ^ <level>.
Test Plan: Add a test case
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D40119/Don't let two L0->L1 compactions run in parallel
Summary: With experimental feature SuggestCompactRange() we don't restrict running two L0->L1 compactions in parallel. This diff fixes this.
Test Plan: added a unit test to reproduce the failure. fixed the unit test
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39981/Make ""make all"" work for CYGWIN
Summary: Some test and benchmark codes don't build for CYGWIN. Fix it.
Test Plan: Build ""make all"" with TARGET_OS=Cygwin on cygwin and make sure it passes.
Reviewers: rven, yhchiang, anthony, igor, kradhakrishnan
Reviewed By: igor, kradhakrishnan
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D39711/Fix hang when closing a DB after doing loads with WAL disabled.
Summary:
There is a hang during DB close in the following scenario:
a) a load with WAL disabled was done,
b) CancelAllBackgroundWork was called,
c) DB Close was called
This was because in that we will wait for a flush but we cannot do a
background flush because we have called CancelAllBackgroundWork which
marks the DB as shutting downn.
Test Plan: Added DBTest FlushOnDestroy
Reviewers: sdong
Reviewed By: sdong
Subscribers: yoshinorim, hermanlee4, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39747/Fixed the tsan failure in util/compaction_job_stats_impl.cc
Summary:
The type of smallest_output_key_prefix and largest_output_key_prefix
have been changed to std::string in https://reviews.facebook.net/D39537.
As a result, we shouldn't do smallest_output_key_prefix[0] = 0 in the
initialization.
Test Plan: compile db_test with tsan enabled and repeat DBTest.CompactionDeletionTrigger test to verify the tsan issue has been gone.
Reviewers: igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39645/Allowing L0 -> L1 trivial move on sorted data
Summary:
This diff updates the logic of how we do trivial move, now trivial move can run on any number of files in input level as long as they are not overlapping
The conditions for trivial move have been updated
Introduced conditions:
- Trivial move cannot happen if we have a compaction filter (except if the compaction is not manual)
- Input level files cannot be overlapping
Removed conditions:
- Trivial move only run when the compaction is not manual
- Input level should can contain only 1 file
More context on what tests failed because of Trivial move
```
DBTest.CompactionsGenerateMultipleFiles
This test is expecting compaction on a file in L0 to generate multiple files in L1, this test will fail with trivial move because we end up with one file in L1
```
```
DBTest.NoSpaceCompactRange
This test expect compaction to fail when we force environment to report running out of space, of course this is not valid in trivial move situation
because trivial move does not need any extra space, and did not check for that
```
```
DBTest.DropWrites
Similar to DBTest.NoSpaceCompactRange
```
```
DBTest.DeleteObsoleteFilesPendingOutputs
This test expect that a file in L2 is deleted after it's moved to L3, this is not valid with trivial move because although the file was moved it is now used by L3
```
```
CuckooTableDBTest.CompactionIntoMultipleFiles
Same as DBTest.CompactionsGenerateMultipleFiles
```
This diff is based on a work by @sdong https://reviews.facebook.net/D34149
Test Plan: make -j64 check
Reviewers: rven, sdong, igor
Reviewed By: igor
Subscribers: yhchiang, ott, march, dhruba, sdong
Differential Revision: https://reviews.facebook.net/D34797/Fix DBTest.MigrateToDynamicLevelMaxBytesBase slowness with valgrind
Summary:
DBTest.MigrateToDynamicLevelMaxBytesBase with valgrind test is
extremely slow. Work it around by not having both threads running
everything non-stop.
Test Plan: Run the test with valgrind which used to take too long to finish and see it finish in reasonable time.
Reviewers: yhchiang, anthony, rven, kradhakrishnan, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D39477/Optimistic Transactions
Summary: Optimistic transactions supporting begin/commit/rollback semantics.  Currently relies on checking the memtable to determine if there are any collisions at commit time.  Not yet implemented would be a way of enuring the memtable has some minimum amount of history so that we won't fail to commit when the memtable is empty.  You should probably start with transaction.h to get an overview of what is currently supported.
Test Plan: Added a new test, but still need to look into stress testing.
Reviewers: yhchiang, igor, rven, sdong
Reviewed By: sdong
Subscribers: adamretter, MarkCallaghan, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D33435/Support saving history in memtable_list
Summary:
For transactions, we are using the memtables to validate that there are no write conflicts.  But after flushing, we don't have any memtables, and transactions could fail to commit.  So we want to someone keep around some extra history to use for conflict checking.  In addition, we want to provide a way to increase the size of this history if too many transactions fail to commit.
After chatting with people, it seems like everyone prefers just using Memtables to store this history (instead of a separate history structure).  It seems like the best place for this is abstracted inside the memtable_list.  I decide to create a separate list in MemtableListVersion as using the same list complicated the flush/installalflushresults logic too much.
This diff adds a new parameter to control how much memtable history to keep around after flushing.  However, it sounds like people aren't too fond of adding new parameters.  So I am making the default size of flushed+not-flushed memtables be set to max_write_buffers.  This should not change the maximum amount of memory used, but make it more likely we're using closer the the limit.  (We are now postponing deleting flushed memtables until the max_write_buffer limit is reached).  So while we might use more memory on average, we are still obeying the limit set (and you could argue it's better to go ahead and use up memory now instead of waiting for a write stall to happen to test this limit).
However, if people are opposed to this default behavior, we can easily set it to 0 and require this parameter be set in order to use transactions.
Test Plan: Added a xfunc test to play around with setting different values of this parameter in all tests.  Added testing in memtablelist_test and planning on adding more testing here.
Reviewers: sdong, rven, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D37443/Allow flushes to run in parallel with manual compaction
Summary: As title. I spent some time thinking about it and I don't think there should be any issue with running manual compaction and flushes in parallel
Test Plan: make check works
Reviewers: rven, yhchiang, sdong
Reviewed By: yhchiang, sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D38355/DBTest.DynamicLevelMaxBytesCompactRange: make sure L0 is not empty before running compact range
Summary: DBTest.DynamicLevelMaxBytesCompactRange needs to make sure L0 is not empty to properly cover the code paths we want to cover. However, current codes have a bug that might leave the condition not held. Improve the test to ensure it.
Test Plan: Run the test in an environment that is used to fail. Also run it many times.
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D38631/"
rocksdb,"Deprecate WriteOptions::timeout_hint_us
Summary:
In one of our recent meetings, we discussed deprecating features that are not being actively used. One of those features, at least within Facebook, is timeout_hint. The feature is really nicely implemented, but if nobody needs it, we should remove it from our code-base (until we get a valid use-case). Some arguments:
* Less code == better icache hit rate, smaller builds, simpler code
* The motivation for adding timeout_hint_us was to work-around RocksDB's stall issue. However, we're currently addressing the stall issue itself (see @sdong's recent work on stall write_rate), so we should never see sharp lock-ups in the future.
* Nobody is using the feature within Facebook's code-base. Googling for `timeout_hint_us` also doesn't yield any users.
Test Plan: make check
Reviewers: anthony, kradhakrishnan, sdong, yhchiang
Reviewed By: yhchiang
Subscribers: sdong, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D41937/Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/Merge branch 'master' of github.com:facebook/rocksdb
D40233: Replace %llu with format macros in ParsedInternalKey::DebugString())/Fix a compile warning in listener_test.cc
Summary:
Fixed the following compile warning in listener_test.cc:
db/listener_test.cc:214:8: error: 'OnTableFileCreated' overrides a member function but is not marked 'override' [-Werror,-Winconsistent-missing-override]
14:16:46   void OnTableFileCreated(
Test Plan:
make listener_test
Reviewers: sdong, igor
Subscribers: leveldb/"
rocksdb,"Parallelize L0-L1 Compaction: Restructure Compaction Job
Summary:
As of now compactions involving files from Level 0 and Level 1 are single
threaded because the files in L0, although sorted, are not range partitioned like
the other levels. This means that during L0-L1 compaction each file from L1
needs to be merged with potentially all the files from L0.
This attempt to parallelize the L0-L1 compaction assigns a thread and a
corresponding iterator to each L1 file that then considers only the key range
found in that L1 file and only the L0 files that have those keys (and only the
specific portion of those L0 files in which those keys are found). In this way
the overlap is minimized and potentially eliminated between different iterators
focusing on the same files.
The first step is to restructure the compaction logic to break L0-L1 compactions
into multiple, smaller, sequential compactions. Eventually each of these smaller
jobs will be run simultaneously. Areas to pay extra attention to are
# Correct aggregation of compaction job statistics across multiple threads
# Proper opening/closing of output files (make sure each thread's is unique)
# Keys that span multiple L1 files
# Skewed distributions of keys within L0 files
Test Plan: Make and run db_test (newer version has separate compaction tests) and compaction_job_stats_test
Reviewers: igor, noetzli, anthony, sdong, yhchiang
Reviewed By: yhchiang
Subscribers: MarkCallaghan, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D42699/Report live data size estimate
Summary:
Fixes T6548822. Added a new function for estimating the size of the live data
as proposed in the task. The value can be accessed through the property
rocksdb.estimate-live-data-size.
Test Plan:
There are two unit tests in version_set_test and a simple test in db_test.
make version_set_test && ./version_set_test;
make db_test && ./db_test gtest_filter=GetProperty
Reviewers: rven, igor, yhchiang, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D41493/Print info message about files need compaction for debuging purpose
Summary:
When there are files marked for compaction after compactions, print extra messages to help debugging. Example:
2015/06/08-23:12:55.212855 7ff5013ff700 [default] [JOB 121] Generated table #75: 54 keys, 4807 bytes (need compaction)
2015/06/08-23:12:55.556194 7ff5013ff700 (Original Log Time 2015/06/08-23:12:55.556160) [default] compacted to: base level 1 max bytes base
10240 files[0 1 9 32 12 0 0 0] max score 0.96 (2 files need compaction), MB/sec: 0.0 rd, 0.1 wr, level 2, files in(1, 3) out(5) MB in(0.0,
0.0) out(0.0), read-write-amplify(11.3) write-amplify(5.7) OK, records in: 40, records dropped: 0
Test Plan:
Run test and see LOG files.
valgrind test DBTest.TablePropertiesNeedCompactTest
Reviewers: rven, yhchiang, kradhakrishnan, IslamAbdelRahman, igor
Reviewed By: igor
Subscribers: yoshinorim, maykov, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D39771/Fix compile
Summary:
This commit broke the compile: https://github.com/facebook/rocksdb/commit/3ce3bb3da2486c2c18a332128dda7c05a91abb85
As evidenced here: https://evergreen.mongodb.com/task/mongodb_mongo_master_ubuntu1404_rocksdb_compile_ce2b1d11d42de93f7b375f7e6c41fb709f66e969_15_06_04_23_09_36
This should fix it
Test Plan: make check
Reviewers: IslamAbdelRahman
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39627/Allowing L0 -> L1 trivial move on sorted data
Summary:
This diff updates the logic of how we do trivial move, now trivial move can run on any number of files in input level as long as they are not overlapping
The conditions for trivial move have been updated
Introduced conditions:
- Trivial move cannot happen if we have a compaction filter (except if the compaction is not manual)
- Input level files cannot be overlapping
Removed conditions:
- Trivial move only run when the compaction is not manual
- Input level should can contain only 1 file
More context on what tests failed because of Trivial move
```
DBTest.CompactionsGenerateMultipleFiles
This test is expecting compaction on a file in L0 to generate multiple files in L1, this test will fail with trivial move because we end up with one file in L1
```
```
DBTest.NoSpaceCompactRange
This test expect compaction to fail when we force environment to report running out of space, of course this is not valid in trivial move situation
because trivial move does not need any extra space, and did not check for that
```
```
DBTest.DropWrites
Similar to DBTest.NoSpaceCompactRange
```
```
DBTest.DeleteObsoleteFilesPendingOutputs
This test expect that a file in L2 is deleted after it's moved to L3, this is not valid with trivial move because although the file was moved it is now used by L3
```
```
CuckooTableDBTest.CompactionIntoMultipleFiles
Same as DBTest.CompactionsGenerateMultipleFiles
```
This diff is based on a work by @sdong https://reviews.facebook.net/D34149
Test Plan: make -j64 check
Reviewers: rven, sdong, igor
Reviewed By: igor
Subscribers: yhchiang, ott, march, dhruba, sdong
Differential Revision: https://reviews.facebook.net/D34797/Optimistic Transactions
Summary: Optimistic transactions supporting begin/commit/rollback semantics.  Currently relies on checking the memtable to determine if there are any collisions at commit time.  Not yet implemented would be a way of enuring the memtable has some minimum amount of history so that we won't fail to commit when the memtable is empty.  You should probably start with transaction.h to get an overview of what is currently supported.
Test Plan: Added a new test, but still need to look into stress testing.
Reviewers: yhchiang, igor, rven, sdong
Reviewed By: sdong
Subscribers: adamretter, MarkCallaghan, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D33435/Don't artificially inflate L0 score
Summary:
This turns out to be pretty bad because if we prioritize L0->L1 then L1 can grow artificially large, which makes L0->L1 more and more expensive. For example:
256MB @ L0 + 256MB @ L1 --> 512MB @ L1
256MB @ L0 + 512MB @ L1 --> 768MB @ L1
256MB @ L0 + 768MB @ L1 --> 1GB @ L1
....
256MB @ L0 + 10GB @ L1 --> 10.2GB @ L1
At some point we need to start compacting L1->L2 to speed up L0->L1.
Test Plan:
The performance improvement is massive for heavy write workload. This is the benchmark I ran: https://phabricator.fb.com/P19842671. Before this change, the benchmark took 47 minutes to complete. After, the benchmark finished in 2minutes. You can see full results here: https://phabricator.fb.com/P19842674
Also, we ran this diff on MongoDB on RocksDB on one replicaset. Before the change, our initial sync was so slow that it couldn't keep up with primary writes. After the change, the import finished without any issues
Reviewers: dynamike, MarkCallaghan, rven, yhchiang, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D38637/"
rocksdb,"Windows Port from Microsoft
Summary: Make RocksDb build and run on Windows to be functionally
complete and performant. All existing test cases run with no
regressions. Performance numbers are in the pull-request.
Test plan: make all of the existing unit tests pass, obtain perf numbers.
Co-authored-by: Praveen Rao praveensinghrao@outlook.com
Co-authored-by: Sherlock Huang baihan.huang@gmail.com
Co-authored-by: Alex Zinoviev alexander.zinoviev@me.com
Co-authored-by: Dmitri Smirnov dmitrism@microsoft.com/Merge branch 'master' of github.com:facebook/rocksdb
D40233: Replace %llu with format macros in ParsedInternalKey::DebugString())/Fix ASAN errors in c_test
Summary: key_sizes claims that 3rd key is of length 8, but it's really only 3. This diff makes it length 8.
Test Plan: asan c_test works again.
Reviewers: sdong, yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D39699/"
rocksdb,"Allow users to disable some kill points in db_stress
Summary:
Give a name for every kill point, and allow users to disable some kill points based on prefixes. The kill points can be passed by db_stress through a command line paramter. This provides a way for users to boost the chance of triggering low frequency kill points
This allow follow up changes in crash test scripts to improve crash test coverage.
Test Plan:
Manually run db_stress with variable values of --kill_random_test and --kill_prefix_blacklist. Like this:
--kill_random_test=2 --kill_prefix_blacklist=Posix,WritableFileWriter::Append,WritableFileWriter::WriteBuffered,WritableFileWriter::Sync
Reviewers: igor, kradhakrishnan, rven, IslamAbdelRahman, yhchiang
Reviewed By: yhchiang
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D48735/Fixed a tsan warning in db_stress.cc
Summary:
Fixed the following tsan warning in db_stress.cc
WARNING: ThreadSanitizer: data race (pid=3163194)
Read of size 8 at 0x7fd1797cb518 by thread T32:
#0 VerifyDb tools/db_stress.cc:1731 (db_stress+0x000000040674)
#1 rocksdb::StressTest::ThreadBody(void*) tools/db_stress.cc:1191 (db_stress+0x0000000625a9)
#2 StartThreadWrapper util/env_posix.cc:1648 (db_stress+0x00000028bbbd)
Previous write of size 8 at 0x7fd1797cb518 by thread T31:
#0 VerifyDb tools/db_stress.cc:1726 (db_stress+0x00000004072a)
#1 rocksdb::StressTest::ThreadBody(void*) tools/db_stress.cc:1191 (db_stress+0x0000000625a9)
#2 StartThreadWrapper util/env_posix.cc:1648 (db_stress+0x00000028bbbd)
The cause is that in VerifyDb(), the static local const variable long max_key
can be read and written at the same time.  This patch fixed it by making it
non-static.
Test Plan: db_stress
Reviewers: igor, sdong, IslamAbdelRahman, anthony
Reviewed By: anthony
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D47703/Support for SingleDelete()
Summary:
This patch fixes #7460559. It introduces SingleDelete as a new database
operation. This operation can be used to delete keys that were never
overwritten (no put following another put of the same key). If an overwritten
key is single deleted the behavior is undefined. Single deletion of a
non-existent key has no effect but multiple consecutive single deletions are
not allowed (see limitations).
In contrast to the conventional Delete() operation, the deletion entry is
removed along with the value when the two are lined up in a compaction. Note:
The semantics are similar to @igor's prototype that allowed to have this
behavior on the granularity of a column family (
https://reviews.facebook.net/D42093 ). This new patch, however, is more
aggressive when it comes to removing tombstones: It removes the SingleDelete
together with the value whenever there is no snapshot between them while the
older patch only did this when the sequence number of the deletion was older
than the earliest snapshot.
Most of the complex additions are in the Compaction Iterator, all other changes
should be relatively straightforward. The patch also includes basic support for
single deletions in db_stress and db_bench.
Limitations:
- Not compatible with cuckoo hash tables
- Single deletions cannot be used in combination with merges and normal
deletions on the same key (other keys are not affected by this)
- Consecutive single deletions are currently not allowed (and older version of
this patch supported this so it could be resurrected if needed)
Test Plan: make all check
Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor
Reviewed By: igor
Subscribers: maykov, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43179/Merge pull request #720 from AMDmi3/fix-constant-overflow
Fix `integer overflow in expression' error/Fix `integer overflow in expression' error/"
rocksdb,"Refactor to support file_reader_writer on Windows.
Summary. A change https://reviews.facebook.net/differential/diff/224721/
Has attempted to move common functionality out of platform dependent
code to a new facility called file_reader_writer.
This includes:
- perf counters
- Buffering
- RateLimiting
However, the change did not attempt to refactor Windows code.
To mitigate, we introduce new quering interfaces such as UseOSBuffer(),
GetRequiredBufferAlignment() and ReaderWriterForward()
for pure forwarding where required.
Introduce WritableFile got a new method Truncate(). This is to communicate
to the file as to how much data it has on close.
- When space is pre-allocated on Linux it is filled with zeros implicitly,
no such thing exist on Windows so we must truncate file on close.
- When operating in unbuffered mode the last page is filled with zeros but we still want to truncate.
Previously, Close() would take care of it but now buffer management is shifted to the wrappers and the file has
no idea about the file true size.
This means that Close() on the wrapper level must always include
Truncate() as well as wrapper __dtor should call Close() and
against double Close().
Move buffered/unbuffered write logic to the wrapper.
Utilize Aligned buffer class.
Adjust tests and implement Truncate() where necessary.
Come up with reasonable defaults for new virtual interfaces.
Forward calls for RandomAccessReadAhead class to avoid double
buffering and locking (double locking in unbuffered mode on WIndows)./"
rocksdb,"Support for SingleDelete()
Summary:
This patch fixes #7460559. It introduces SingleDelete as a new database
operation. This operation can be used to delete keys that were never
overwritten (no put following another put of the same key). If an overwritten
key is single deleted the behavior is undefined. Single deletion of a
non-existent key has no effect but multiple consecutive single deletions are
not allowed (see limitations).
In contrast to the conventional Delete() operation, the deletion entry is
removed along with the value when the two are lined up in a compaction. Note:
The semantics are similar to @igor's prototype that allowed to have this
behavior on the granularity of a column family (
https://reviews.facebook.net/D42093 ). This new patch, however, is more
aggressive when it comes to removing tombstones: It removes the SingleDelete
together with the value whenever there is no snapshot between them while the
older patch only did this when the sequence number of the deletion was older
than the earliest snapshot.
Most of the complex additions are in the Compaction Iterator, all other changes
should be relatively straightforward. The patch also includes basic support for
single deletions in db_stress and db_bench.
Limitations:
- Not compatible with cuckoo hash tables
- Single deletions cannot be used in combination with merges and normal
deletions on the same key (other keys are not affected by this)
- Consecutive single deletions are currently not allowed (and older version of
this patch supported this so it could be resurrected if needed)
Test Plan: make all check
Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor
Reviewed By: igor
Subscribers: maykov, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43179/Add Subcompactions to Universal Compaction Unit Tests
Summary:
Now that the approach to parallelizing L0-L1 level-based
compactions by breaking the compaction job into subcompactions is
being extended to apply to universal compactions as well, the unit
tests need to account for this and run the universal compaction
tests with subcompactions both enabled and disabled.
Test Plan: make all && make check
Reviewers: sdong, igor, noetzli, anthony, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D45657/ReadaheadRandomAccessFile -- userspace readahead
Summary:
ReadaheadRandomAccessFile acts as a transparent layer on top of RandomAccessFile. When a Read() request is issued, it issues a much bigger request to the OS and caches the result. When a new request comes in and we already have the data cached, it doesn't have to issue any requests to the OS.
We add ReadaheadRandomAccessFile layer only when file is read during compactions.
D45105 was incorrectly closed by Phabricator because I committed it to a separate branch (not master), so I'm resubmitting the diff.
Test Plan: make check
Reviewers: MarkCallaghan, sdong
Reviewed By: sdong
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D45123/Fix compact_files_example
Summary:
See task #7983654. The example was triggering an assert in compaction job
because the compaction was not marked as manual. With this patch,
CompactionPicker::FormCompaction() marks compactions as manual. This patch
also fixes a couple of typos, adds optimistic_transaction_example to
.gitignore and librocksdb as a dependency for examples. Adding librocksdb as
a dependency makes sure that the examples are built with the latest changes
in librocksdb.
Test Plan: make clean && cd examples && make all && ./compact_files_example
Reviewers: rven, sdong, anthony, igor, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D45117/"
rocksdb,"New amalgamation target
This commit adds two new targets to the Makefile: rocksdb.cc and rocksdb.h
These files, when combined with the c.h header, are a self-contained RocksDB
source distribution called an amalgamation. (The name comes from SQLite's, which
is similar in concept.)
The main benefit of an amalgamation is that it's very easy to drop into a
new project. It also compiles faster compared to compiling individual source
files and potentially gives the compiler more opportunity to make optimizations
since it can see all functions at once.
rocksdb.cc and rocksdb.h are generated by a new script, amalgamate.py.
A detailed description of how amalgamate.py works is in a comment at the top of
the file.
There are also some small changes to existing files to enable the amalgamation:
* Use quotes for includes in unity build
* Fix an old header inclusion in util/xfunc.cc
* Move some includes outside ifdef in util/env_hdfs.cc
* Separate out tool sources in Makefile so they won't be included in unity.cc
* Unity build now produces a static library
Closes #733/"
rocksdb,"Refactor to support file_reader_writer on Windows.
Summary. A change https://reviews.facebook.net/differential/diff/224721/
Has attempted to move common functionality out of platform dependent
code to a new facility called file_reader_writer.
This includes:
- perf counters
- Buffering
- RateLimiting
However, the change did not attempt to refactor Windows code.
To mitigate, we introduce new quering interfaces such as UseOSBuffer(),
GetRequiredBufferAlignment() and ReaderWriterForward()
for pure forwarding where required.
Introduce WritableFile got a new method Truncate(). This is to communicate
to the file as to how much data it has on close.
- When space is pre-allocated on Linux it is filled with zeros implicitly,
no such thing exist on Windows so we must truncate file on close.
- When operating in unbuffered mode the last page is filled with zeros but we still want to truncate.
Previously, Close() would take care of it but now buffer management is shifted to the wrappers and the file has
no idea about the file true size.
This means that Close() on the wrapper level must always include
Truncate() as well as wrapper __dtor should call Close() and
against double Close().
Move buffered/unbuffered write logic to the wrapper.
Utilize Aligned buffer class.
Adjust tests and implement Truncate() where necessary.
Come up with reasonable defaults for new virtual interfaces.
Forward calls for RandomAccessReadAhead class to avoid double
buffering and locking (double locking in unbuffered mode on WIndows)./"
rocksdb,"Remove ldb HexToString method's usage of sscanf
Summary:
Fix hex2String performance issues by removing sscanf dependency.
Also fixed some edge case handling (odd length, bad input).
Test Plan: Created a test file which called old and new implementation, and validated results are the same. I'll paste results in the phabricator diff.
Reviewers: igor, rven, anthony, IslamAbdelRahman, kradhakrishnan, yhchiang, sdong
Reviewed By: sdong
Subscribers: thatsafunnyname, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D46785/Fixed a compile warning in linux32 environment.
Summary:
Fixed the following compile warning in linux32 environment.
==> linux32: util/sst_dump_tool.cc: In member function int
rocksdb::SstFileReader::ShowAllCompressionSizes(size_t):
==> linux32: util/sst_dump_tool.cc:167:50: warning: format %lu expects
argument of type long unsigned int, but argument 3 has type
size_t {aka unsigned int} [-Wformat=]
==> linux32:    fprintf(stdout, ""Block Size: %lu\n"", block_size);
Test Plan: make sst_dump
Reviewers: anthony, IslamAbdelRahman, sdong, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D45885/"
rocksdb,"Avoid some includes in io_posix.h
Summary: IO Posix depends on too many .h files. Move most of them to .cc files.
Test Plan: make all
Reviewers: anthony, rven, IslamAbdelRahman, yhchiang, kradhakrishnan, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D49479/Fix iOS build
Summary: We don't yet have a CI build for iOS, so our iOS compile gets broken sometimes. Most of the errors are from assumption that size_t is 64-bit, while it's actually 32-bit on some (all?) iOS platforms. This diff fixes the compile.
Test Plan:
TARGET_OS=IOS make static_lib
Observe there are no warnings
Reviewers: sdong, anthony, IslamAbdelRahman, kradhakrishnan, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D49029/env: add ReuseWritableFile
Add an environment method to reuse an existing file.  Provide a generic
implementation that does a simple rename + open (writeable), and also a
posix variant that is more careful about error handling (if we fail to
open, do not rename, etc.).
Signed-off-by: Sage Weil <sage@redhat.com>/Allow users to disable some kill points in db_stress
Summary:
Give a name for every kill point, and allow users to disable some kill points based on prefixes. The kill points can be passed by db_stress through a command line paramter. This provides a way for users to boost the chance of triggering low frequency kill points
This allow follow up changes in crash test scripts to improve crash test coverage.
Test Plan:
Manually run db_stress with variable values of --kill_random_test and --kill_prefix_blacklist. Like this:
--kill_random_test=2 --kill_prefix_blacklist=Posix,WritableFileWriter::Append,WritableFileWriter::WriteBuffered,WritableFileWriter::Sync
Reviewers: igor, kradhakrishnan, rven, IslamAbdelRahman, yhchiang
Reviewed By: yhchiang
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D48735/Fix compile error on platforms without fallocate()
Summary:
If a platform doesn't have ROCKSDB_FALLOCATE_PRESENT, then compiler complains:
util/env_posix.cc:354:8: error: private field 'allow_fallocate_' is not used [-Werror,-Wunused-private-field]
This was caught by travis.
Test Plan: compiles with ROCKSDB_FALLOCATE_PRESENT.
Reviewers: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D48327/Added boolean variable to guard fallocate() calls
Summary:
Added boolean variable to guard fallocate() calls.
Set to false to prevent space leaks when tests fail.
Test Plan:
Compliles
Set to false and ran log device tests
Reviewers: sdong, lovro, igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D48027/removed unused variable of type Status, fixed indentation/Refactor to support file_reader_writer on Windows.
Summary. A change https://reviews.facebook.net/differential/diff/224721/
Has attempted to move common functionality out of platform dependent
code to a new facility called file_reader_writer.
This includes:
- perf counters
- Buffering
- RateLimiting
However, the change did not attempt to refactor Windows code.
To mitigate, we introduce new quering interfaces such as UseOSBuffer(),
GetRequiredBufferAlignment() and ReaderWriterForward()
for pure forwarding where required.
Introduce WritableFile got a new method Truncate(). This is to communicate
to the file as to how much data it has on close.
- When space is pre-allocated on Linux it is filled with zeros implicitly,
no such thing exist on Windows so we must truncate file on close.
- When operating in unbuffered mode the last page is filled with zeros but we still want to truncate.
Previously, Close() would take care of it but now buffer management is shifted to the wrappers and the file has
no idea about the file true size.
This means that Close() on the wrapper level must always include
Truncate() as well as wrapper __dtor should call Close() and
against double Close().
Move buffered/unbuffered write logic to the wrapper.
Utilize Aligned buffer class.
Adjust tests and implement Truncate() where necessary.
Come up with reasonable defaults for new virtual interfaces.
Forward calls for RandomAccessReadAhead class to avoid double
buffering and locking (double locking in unbuffered mode on WIndows)./Mmap reads should not return error if reading past file
Summary:
Currently, mmap returns IOError when user tries to read data past the end of the file. This diff changes the behavior. Now, we return just the bytes that we can, and report the size we returned via a Slice result. This is consistent with non-mmap behavior and also pread() system call.
This diff is taken out of D45123.
Test Plan: make check
Reviewers: sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D45645/"
rocksdb,"Revert ""Adding new table properties""
Summary:
Reverting https://reviews.facebook.net/D34269 for now
after I landed it a flaky test started continuously failing, I am almost sure this patch is not related to the test but I will revert it until I figure out why it's failing
Test Plan: make check
Reviewers: kradhakrishnan
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D50385/Merge pull request #786 from aloukissas/unused_param
Fix unused parameter warnings in db.h/Fix unused parameter warnings./Fix unused parameter warnings./Support for SingleDelete()
Summary:
This patch fixes #7460559. It introduces SingleDelete as a new database
operation. This operation can be used to delete keys that were never
overwritten (no put following another put of the same key). If an overwritten
key is single deleted the behavior is undefined. Single deletion of a
non-existent key has no effect but multiple consecutive single deletions are
not allowed (see limitations).
In contrast to the conventional Delete() operation, the deletion entry is
removed along with the value when the two are lined up in a compaction. Note:
The semantics are similar to @igor's prototype that allowed to have this
behavior on the granularity of a column family (
https://reviews.facebook.net/D42093 ). This new patch, however, is more
aggressive when it comes to removing tombstones: It removes the SingleDelete
together with the value whenever there is no snapshot between them while the
older patch only did this when the sequence number of the deletion was older
than the earliest snapshot.
Most of the complex additions are in the Compaction Iterator, all other changes
should be relatively straightforward. The patch also includes basic support for
single deletions in db_stress and db_bench.
Limitations:
- Not compatible with cuckoo hash tables
- Single deletions cannot be used in combination with merges and normal
deletions on the same key (other keys are not affected by this)
- Consecutive single deletions are currently not allowed (and older version of
this patch supported this so it could be resurrected if needed)
Test Plan: make all check
Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor
Reviewed By: igor
Subscribers: maykov, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43179/"
rocksdb,"Enable RocksDB to persist Options file.
Summary:
This patch allows rocksdb to persist options into a file on
DB::Open, SetOptions, and Create / Drop ColumnFamily.
Options files are created under the same directory as the rocksdb
instance.
In addition, this patch also adds a fail_if_missing_options_file in DBOptions
that makes any function call return non-ok status when it is not able to
persist options properly.
// If true, then DB::Open / CreateColumnFamily / DropColumnFamily
// / SetOptions will fail if options file is not detected or properly
// persisted.
//
// DEFAULT: false
bool fail_if_missing_options_file;
Options file names are formatted as OPTIONS-<number>, and RocksDB
will always keep the latest two options files.
Test Plan:
Add options_file_test.
options_test
column_family_test
Reviewers: igor, IslamAbdelRahman, sdong, anthony
Reviewed By: anthony
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D48285/Fix non-deterministic failure in backupable_db_test
Summary: FailOverwritingBackups has unexpected results when auto-compaction runs.
Test Plan: ran test a bunch of times
Reviewers: IslamAbdelRahman, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D47181/Remove the need for LATEST_BACKUP in BackupEngine
Summary:
In the first implementation of BackupEngine, LATEST_BACKUP was the commit point. The backup became committed after the write to LATEST_BACKUP completed.
However, we can avoid the need for LATEST_BACKUP. Instead of write to LATEST_BACKUP, the commit point can be the rename from `meta/<backup_id>.tmp` to `meta/<backup_id>`. Once we see that there exists a file `meta/<backup_id>` (without tmp), we can assume that backup is valid.
In this diff, we still write out the file LATEST_BACKUP. We need to do this so that we can maintain backward compatibility. However, the new version doesn't depend on this file anymore. We get the latest backup by `ls`-ing `meta` directory.
This diff depends on D41925
Test Plan: Adjusted backupable_db_test to this new behavior
Reviewers: benj, yhchiang, sdong, AaronFeldman
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D42069/"
rocksdb,"Merge pull request #771 from maximecaron/patch-1
Fix build error using Visual Studio 12/Fix build error using Visual Studio 12/"
rocksdb,"Deferred snapshot creation in transactions
Summary: Support for Transaction::CreateSnapshotOnNextOperation().  This is to fix a write-conflict race-condition that Yoshinori was running into when testing MyRocks with LinkBench.
Test Plan: New tests
Reviewers: yhchiang, spetrunia, rven, igor, yoshinorim, sdong
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D48099/Fix accidental object copy in transactions
Summary: Should have used auto& instead of auto.  Also needed to change the code a bit due to const correctness.
Test Plan: unit tests
Reviewers: sdong, igor, yoshinorim, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D47787/"
rocksdb,"Revert ""Adding new table properties""
Summary:
Reverting https://reviews.facebook.net/D34269 for now
after I landed it a flaky test started continuously failing, I am almost sure this patch is not related to the test but I will revert it until I figure out why it's failing
Test Plan: make check
Reviewers: kradhakrishnan
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D50385/Fix white space at end of line/Fix Travis Build Error/"
rocksdb,"Merge pull request #795 from yuslepukhin/fix_mocktable_id
Fix MockTable ID storage/Fix MockTable ID storage
On Windows two tests fail that use MockTable:
flush_job_test and compaction_job_test with the following message:
compaction_job_test_je.exe : Assertion failed: result.size() == 4,
file c:\dev\rocksdb\rocksdb\table\mock_table.cc, line 110
Investigation reveals that this failure occurs when a 4 byte
ID written to a beginning of the physically open file (main
contents remains in a in-memory map) can not be read back.
The reason for the failure is that the ID is written directly
to a WritableFile bypassing WritableFileWriter. The side effect of that
is that pending_sync_ never becomes true so the file is never flushed,
however, the direct cause of the failure is that the filesize_ member
of the WritableFileWriter remains zero. At Close() the file is truncated
to that size and the file becomes empty so the ID can not be read back./"
rocksdb,"Fix the bug of using freed memory introduced by recent plain table reader patch
Summary: Recent patch introduced a bug that if non-mmap mode is used, in prefix encoding case, there is a resizing of cur_key_ within the same prefix, we still read prefix from the released buffer. It fails ASAN tests and this commit fixes it.
Test Plan: Run the ASAN tests for the failing test case.
Reviewers: IslamAbdelRahman, yhchiang, anthony, igor, kradhakrishnan, rven
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D47457/"
rocksdb,"Revert ""Adding new table properties""
Summary:
Reverting https://reviews.facebook.net/D34269 for now
after I landed it a flaky test started continuously failing, I am almost sure this patch is not related to the test but I will revert it until I figure out why it's failing
Test Plan: make check
Reviewers: kradhakrishnan
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D50385/Fix tests failing in ROCKSDB_LITE
Summary:
Fix tests that compile under ROCKSDB_LITE but currently failing.
table_test:
RandomizedLongDB test is using internal stats which is not supported in ROCKSDB_LITE
compaction_job_test:
Using CompactionJobStats which is not supported
perf_context_test:
KeyComparisonCount test try to open DB in ReadOnly mode which is not supported
Test Plan: run the tests under ROCKSDB_LITE
Reviewers: yhchiang, sdong, igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D48585/Fix compile
Summary: There was a merge conflict with https://reviews.facebook.net/D45993
Test Plan: make check
Reviewers: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D46065/"
rocksdb,"Merge pull request #811 from OverlordQ/unused-variable-warning
Fix introduced in 2ab7065 was reverted by 18285c1./Fix introduced in 2ab7065 was reverted by 18285c1.
Corrects:
db/memtablerep_bench.cc:135:22: error: FLAGS_env defined but not used [-Werror=unused-variable]
static rocksdb::Env* FLAGS_env = rocksdb::Env::Default();
^
cc1plus: all warnings being treated as errors
Makefile:1147: recipe for target 'db/memtablerep_bench.o' failed/Fix benchmarks under ROCKSDB_LITE
Summary: Fix db_bench and memtablerep_bench under ROCKSDB_LITE
Test Plan:
OPT=-DROCKSDB_LITE make db_bench -j64
OPT=-DROCKSDB_LITE make memtablerep_bench -j64
make db_bench -j64
make memtablerep_bench -j64
Reviewers: yhchiang, anthony, rven, igor, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D48717/"
rocksdb,"Support for SingleDelete()
Summary:
This patch fixes #7460559. It introduces SingleDelete as a new database
operation. This operation can be used to delete keys that were never
overwritten (no put following another put of the same key). If an overwritten
key is single deleted the behavior is undefined. Single deletion of a
non-existent key has no effect but multiple consecutive single deletions are
not allowed (see limitations).
In contrast to the conventional Delete() operation, the deletion entry is
removed along with the value when the two are lined up in a compaction. Note:
The semantics are similar to @igor's prototype that allowed to have this
behavior on the granularity of a column family (
https://reviews.facebook.net/D42093 ). This new patch, however, is more
aggressive when it comes to removing tombstones: It removes the SingleDelete
together with the value whenever there is no snapshot between them while the
older patch only did this when the sequence number of the deletion was older
than the earliest snapshot.
Most of the complex additions are in the Compaction Iterator, all other changes
should be relatively straightforward. The patch also includes basic support for
single deletions in db_stress and db_bench.
Limitations:
- Not compatible with cuckoo hash tables
- Single deletions cannot be used in combination with merges and normal
deletions on the same key (other keys are not affected by this)
- Consecutive single deletions are currently not allowed (and older version of
this patch supported this so it could be resurrected if needed)
Test Plan: make all check
Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor
Reviewed By: igor
Subscribers: maykov, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43179/"
rocksdb,"Don't merge WriteBatch-es if WAL is disabled
Summary:
There's no need for WriteImpl to flatten the write batch group
into a single WriteBatch if the WAL is disabled.  This diff moves the
flattening into the WAL step, and skips flattening entirely if it isn't
needed.  It's good for about 5% speedup on a multi-threaded workload
with no WAL.
This diff also adds clarifying comments about the chance for partial
failure of WriteBatchInternal::InsertInto, and always sets bg_error_ if
the memtable state diverges from the logged state or if a WriteBatch
succeeds only partially.
Benchmark for speedup:
db_bench -benchmarks=fillrandom -threads=16 -batch_size=1 -memtablerep=skip_list -value_size=0 --num=200000 -level0_slowdown_writes_trigger=9999 -level0_stop_writes_trigger=9999 -disable_auto_compactions --max_write_buffer_number=8 -max_background_flushes=8 --disable_wal --write_buffer_size=160000000
Test Plan: asserts + make check
Reviewers: sdong, igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D50583/Enable RocksDB to persist Options file.
Summary:
This patch allows rocksdb to persist options into a file on
DB::Open, SetOptions, and Create / Drop ColumnFamily.
Options files are created under the same directory as the rocksdb
instance.
In addition, this patch also adds a fail_if_missing_options_file in DBOptions
that makes any function call return non-ok status when it is not able to
persist options properly.
// If true, then DB::Open / CreateColumnFamily / DropColumnFamily
// / SetOptions will fail if options file is not detected or properly
// persisted.
//
// DEFAULT: false
bool fail_if_missing_options_file;
Options file names are formatted as OPTIONS-<number>, and RocksDB
will always keep the latest two options files.
Test Plan:
Add options_file_test.
options_test
column_family_test
Reviewers: igor, IslamAbdelRahman, sdong, anthony
Reviewed By: anthony
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D48285/Prefix-based iterating only shows keys in prefix
Summary:
MyRocks testing found an issue that while iterating over keys
that are outside the prefix, sometimes wrong results were seen for keys
outside the prefix. We now tighten the range of keys seen with a new
read option called prefix_seen_at_start. This remembers the starting
prefix and then compares it on a Next for equality of prefix. If they
are from a different prefix, it sets valid to false.
Test Plan: PrefixTest.PrefixValid
Reviewers: IslamAbdelRahman, sdong, yhchiang, anthony
Reviewed By: anthony
Subscribers: spetrunia, hermanlee4, yoshinorim, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D50211/Fail recovery if filter provides more records than original and corresponding unit-test, fix naming conventions/Fixed the clang compilation failure
Summary: As above.
Test Plan: USE_CLANG=1 make check -j
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D48981/log_reader: pass log_number and optional info_log to ctor
We will need the log number to validate the recycle-style CRCs.  The log
is helpful for debugging, but optional, as not all callers have it.
Signed-off-by: Sage Weil <sage@redhat.com>/Move TEST_NewInternalIterator to NewInternalIterator
Summary:
Long time ago we add InternalDumpCommand to ldb_tool https://reviews.facebook.net/D11517
This command is using TEST_NewInternalIterator although it's not a test. This patch move TEST_NewInternalIterator outside of db_impl_debug.cc
Test Plan:
make check
make static_lib
Reviewers: yhchiang, igor, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D48561/Add APIs PauseBackgroundWork() and ContinueBackgroundWork()
Summary:
To support a new MongoDB capability, we need to make sure that we don't do any IO for a short period of time. For background, see:
* https://jira.mongodb.org/browse/SERVER-20704
* https://jira.mongodb.org/browse/SERVER-18899
To implement that, I add a new API calls PauseBackgroundWork() and ContinueBackgroundWork() which reuse the capability we already have in place for RefitLevel() function.
Test Plan: Added a new test in db_test. Made sure that test fails when PauseBackgroundWork() is commented out.
Reviewers: IslamAbdelRahman, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D47901/Support for SingleDelete()
Summary:
This patch fixes #7460559. It introduces SingleDelete as a new database
operation. This operation can be used to delete keys that were never
overwritten (no put following another put of the same key). If an overwritten
key is single deleted the behavior is undefined. Single deletion of a
non-existent key has no effect but multiple consecutive single deletions are
not allowed (see limitations).
In contrast to the conventional Delete() operation, the deletion entry is
removed along with the value when the two are lined up in a compaction. Note:
The semantics are similar to @igor's prototype that allowed to have this
behavior on the granularity of a column family (
https://reviews.facebook.net/D42093 ). This new patch, however, is more
aggressive when it comes to removing tombstones: It removes the SingleDelete
together with the value whenever there is no snapshot between them while the
older patch only did this when the sequence number of the deletion was older
than the earliest snapshot.
Most of the complex additions are in the Compaction Iterator, all other changes
should be relatively straightforward. The patch also includes basic support for
single deletions in db_stress and db_bench.
Limitations:
- Not compatible with cuckoo hash tables
- Single deletions cannot be used in combination with merges and normal
deletions on the same key (other keys are not affected by this)
- Consecutive single deletions are currently not allowed (and older version of
this patch supported this so it could be resurrected if needed)
Test Plan: make all check
Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor
Reviewed By: igor
Subscribers: maykov, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43179/Do not flag error if file to be deleted does not exist
Summary:
Some users have observed errors in the log file when
the log file or sst file is already deleted.
Test Plan:
Make sure that the errors do not appear for already deleted
files.
Reviewers: sdong
Reviewed By: sdong
Subscribers: anthony, kradhakrishnan, yhchiang, rven, igor, IslamAbdelRahman, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D47115/DBImpl::FindObsoleteFiles() shouldn't release mutex between getting min_pending_output and scanning files
Summary:
Releasing mutex between getting min_pending_output and scanning files may cause min_pending_output to be max but some non-final files are found in file scanning, ending up with deleting wrong files.
As a recent regression, mutex can be released while waiting for log sync. We move it to after file scanning.
Test Plan: Run all existing tests. Don't think it is easy to write a unit test. Maybe we should find a way to assert lock not released so that we can have some test verification for similar cases.
Reviewers: igor, anthony, IslamAbdelRahman, kradhakrishnan, yhchiang, kolmike, rven
Reviewed By: rven
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D46899/Relaxing consistency detection to include errors while inserting to memtable as WAL recovery error.
Summary: The current code, considers data to be consistent if the record
checksum passes. We do have customer issues where the record checksum passed but
the data was incomprehensible. There is no way to get out of this error case
since all WAL recovery model will consider this error as unrelated to WAL.
Relaxing the definition and including errors while inserting to memtable as WAL
errors and handing them as per the recovery level.
Test Plan: Used customer dump to verify the fix for different level. The db
opens for kSkipAnyCorruptedRecords and kPointInTimeRecovery, but fails for
kAbsoluteConsistency and kTolerateCorruptedTailRecords.
Reviewers: sdon igor
CC: leveldb@
Task ID: #7918721
Blame Rev:/Set max_open_files based on ulimit
Summary: We should never set max_open_files to be bigger than the system's ulimit. Otherwise we will get ""Too many open files"" errors. See an example in this Travis run: https://travis-ci.org/facebook/rocksdb/jobs/79591566
Test Plan:
make check
I will also verify that max_max_open_files is reasonable.
Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D46551/Fix deadlock in WAL sync
Summary:
MarkLogsSynced() was doing `logs_.erase(it++);`. The standard is saying:
```
all iterators and references are invalidated, unless the erased members are at an end (front or back) of the deque (in which case only iterators and references to the erased members are invalidated)
```
Because `it` is an iterator to the first element of the container, it is
invalidated, only one iteration is executed and `log.getting_synced = false;`
is not being done, so `while (logs_.front().getting_synced)` in `WriteImpl()`
is not terminating.
Test Plan: make db_bench && ./db_bench --benchmarks=fillsync
Reviewers: igor, rven, IslamAbdelRahman, anthony, kradhakrishnan, yhchiang, sdong, tnovak
Reviewed By: tnovak
Subscribers: kolmike, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D45807/ReadaheadRandomAccessFile -- userspace readahead
Summary:
ReadaheadRandomAccessFile acts as a transparent layer on top of RandomAccessFile. When a Read() request is issued, it issues a much bigger request to the OS and caches the result. When a new request comes in and we already have the data cached, it doesn't have to issue any requests to the OS.
We add ReadaheadRandomAccessFile layer only when file is read during compactions.
D45105 was incorrectly closed by Phabricator because I committed it to a separate branch (not master), so I'm resubmitting the diff.
Test Plan: make check
Reviewers: MarkCallaghan, sdong
Reviewed By: sdong
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D45123/Fix compact_files_example
Summary:
See task #7983654. The example was triggering an assert in compaction job
because the compaction was not marked as manual. With this patch,
CompactionPicker::FormCompaction() marks compactions as manual. This patch
also fixes a couple of typos, adds optimistic_transaction_example to
.gitignore and librocksdb as a dependency for examples. Adding librocksdb as
a dependency makes sure that the examples are built with the latest changes
in librocksdb.
Test Plan: make clean && cd examples && make all && ./compact_files_example
Reviewers: rven, sdong, anthony, igor, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D45117/Fixing race condition in DBTest.DynamicMemtableOptions
Summary:
This patch fixes a race condition in DBTEst.DynamicMemtableOptions. In rare cases,
it was possible that the main thread would fill up both memtables before the flush
job acquired its work. Then, the flush job was flushing both memtables together,
producing only one L0 file while the test expected two. Now, the test waits for
flushes to finish earlier, to make sure that the memtables are flushed in separate
flush jobs.
Test Plan:
Insert ""usleep(10000);"" after ""IOSTATS_SET_THREAD_POOL_ID(Env::Priority::HIGH);"" in BGWorkFlush()
to make the issue more likely. Then test with:
make db_test && time while ./db_test --gtest_filter=*DynamicMemtableOptions; do true; done
Reviewers: rven, sdong, yhchiang, anthony, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D45429/Rate limit deletes issued by DestroyDB
Summary: Update DestroyDB so that all SST files in the first path id go through DeleteScheduler instead of being deleted immediately
Test Plan: added a unittest
Reviewers: igor, yhchiang, anthony, kradhakrishnan, rven, sdong
Reviewed By: sdong
Subscribers: jeanxu2012, dhruba
Differential Revision: https://reviews.facebook.net/D44955/"
rocksdb,"Improving condition for bottommost level during compaction
Summary: The diff modifies the condition checked to determine the bottommost level during compaction. Previously, absence of files in higher levels alone was used as the condition. Now, the function additionally evaluates if the higher levels have files which have non-overlapping key ranges, then the level can be safely considered as the bottommost level.
Test Plan: Unit test cases added and passing. However, unit tests of universal compaction are failing as a result of the changes made in this diff. Need to understand why that is happening.
Reviewers: igor
Subscribers: dhruba, sdong, lgalanis, meyering
Differential Revision: https://reviews.facebook.net/D46473/Fix compact_files_example
Summary:
See task #7983654. The example was triggering an assert in compaction job
because the compaction was not marked as manual. With this patch,
CompactionPicker::FormCompaction() marks compactions as manual. This patch
also fixes a couple of typos, adds optimistic_transaction_example to
.gitignore and librocksdb as a dependency for examples. Adding librocksdb as
a dependency makes sure that the examples are built with the latest changes
in librocksdb.
Test Plan: make clean && cd examples && make all && ./compact_files_example
Reviewers: rven, sdong, anthony, igor, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D45117/"
rocksdb,"Support for SingleDelete()
Summary:
This patch fixes #7460559. It introduces SingleDelete as a new database
operation. This operation can be used to delete keys that were never
overwritten (no put following another put of the same key). If an overwritten
key is single deleted the behavior is undefined. Single deletion of a
non-existent key has no effect but multiple consecutive single deletions are
not allowed (see limitations).
In contrast to the conventional Delete() operation, the deletion entry is
removed along with the value when the two are lined up in a compaction. Note:
The semantics are similar to @igor's prototype that allowed to have this
behavior on the granularity of a column family (
https://reviews.facebook.net/D42093 ). This new patch, however, is more
aggressive when it comes to removing tombstones: It removes the SingleDelete
together with the value whenever there is no snapshot between them while the
older patch only did this when the sequence number of the deletion was older
than the earliest snapshot.
Most of the complex additions are in the Compaction Iterator, all other changes
should be relatively straightforward. The patch also includes basic support for
single deletions in db_stress and db_bench.
Limitations:
- Not compatible with cuckoo hash tables
- Single deletions cannot be used in combination with merges and normal
deletions on the same key (other keys are not affected by this)
- Consecutive single deletions are currently not allowed (and older version of
this patch supported this so it could be resurrected if needed)
Test Plan: make all check
Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor
Reviewed By: igor
Subscribers: maykov, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43179/Add options.hard_pending_compaction_bytes_limit to stop writes if compaction lagging behind
Summary: Add an option to stop writes if compaction lefts behind. If estimated pending compaction bytes is more than threshold specified by options.hard_pending_compaction_bytes_liimt, writes will stop until compactions are cleared to under the threshold.
Test Plan: Add unit test DBTest.HardLimit
Reviewers: rven, kradhakrishnan, anthony, IslamAbdelRahman, yhchiang, igor
Reviewed By: igor
Subscribers: MarkCallaghan, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D45999/Add a counter about estimated pending compaction bytes
Summary:
Add a counter of estimated bytes the DB needs to compact for all the compactions to finish. Expose it as a DB Property.
In the future, we can use threshold of this counter to replace soft rate limit and hard rate limit. A single threshold of estimated compaction debt in bytes will be easier for users to reason about when should slow down and stopping than more abstract soft and hard rate limits.
Test Plan: Add unit tests
Reviewers: IslamAbdelRahman, yhchiang, rven, kradhakrishnan, anthony, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D44205/"
rocksdb,"Support for SingleDelete()
Summary:
This patch fixes #7460559. It introduces SingleDelete as a new database
operation. This operation can be used to delete keys that were never
overwritten (no put following another put of the same key). If an overwritten
key is single deleted the behavior is undefined. Single deletion of a
non-existent key has no effect but multiple consecutive single deletions are
not allowed (see limitations).
In contrast to the conventional Delete() operation, the deletion entry is
removed along with the value when the two are lined up in a compaction. Note:
The semantics are similar to @igor's prototype that allowed to have this
behavior on the granularity of a column family (
https://reviews.facebook.net/D42093 ). This new patch, however, is more
aggressive when it comes to removing tombstones: It removes the SingleDelete
together with the value whenever there is no snapshot between them while the
older patch only did this when the sequence number of the deletion was older
than the earliest snapshot.
Most of the complex additions are in the Compaction Iterator, all other changes
should be relatively straightforward. The patch also includes basic support for
single deletions in db_stress and db_bench.
Limitations:
- Not compatible with cuckoo hash tables
- Single deletions cannot be used in combination with merges and normal
deletions on the same key (other keys are not affected by this)
- Consecutive single deletions are currently not allowed (and older version of
this patch supported this so it could be resurrected if needed)
Test Plan: make all check
Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor
Reviewed By: igor
Subscribers: maykov, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43179/"
rocksdb,"Block tests under ROCKSDB_LITE
Summary:
This patch will block all tests (not including db_test) that don't compile / fail under ROCKSDB_LITE
Test Plan:
OPT=-DROCKSDB_LITE make db_compaction_filter_test -j64 &&
OPT=-DROCKSDB_LITE make db_compaction_test -j64 &&
OPT=-DROCKSDB_LITE make db_dynamic_level_test -j64 &&
OPT=-DROCKSDB_LITE make db_log_iter_test -j64 &&
OPT=-DROCKSDB_LITE make db_tailing_iter_test -j64 &&
OPT=-DROCKSDB_LITE make db_universal_compaction_test -j64 &&
OPT=-DROCKSDB_LITE make ldb_cmd_test -j64
make clean
make db_compaction_filter_test -j64 &&
make db_compaction_test -j64 &&
make db_dynamic_level_test -j64 &&
make db_log_iter_test -j64 &&
make db_tailing_iter_test -j64 &&
make db_universal_compaction_test -j64 &&
make ldb_cmd_test -j64
Reviewers: yhchiang, igor, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D48723/Move TEST_NewInternalIterator to NewInternalIterator
Summary:
Long time ago we add InternalDumpCommand to ldb_tool https://reviews.facebook.net/D11517
This command is using TEST_NewInternalIterator although it's not a test. This patch move TEST_NewInternalIterator outside of db_impl_debug.cc
Test Plan:
make check
make static_lib
Reviewers: yhchiang, igor, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D48561/Initialize variable to avoid warning
Summary:
RocksDB debug version failed to build under gcc-4.8.1 on sandcastle with the following error:
```
db/db_compaction_filter_test.cc:570:33: error: snapshot may be used uninitialized in this function [-Werror=maybe-uninitialized]
```
Test Plan: make db_compaction_filter_test && ./db_compaction_filter_test
Reviewers: rven, anthony, yhchiang, aekmekji, igor, sdong
Reviewed By: igor, sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D46725/Fixed bug in compaction iterator
Summary:
During the refactoring, the condition that makes sure that compaction
filters are only applied to records newer than the latest snapshot
got butchered. This patch fixes the condition and adds a test case.
Test Plan: make db_compaction_filter_test && ./db_compaction_filter_test
Reviewers: rven, anthony, yhchiang, sdong, aekmekji, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D46707/Add Subcompactions to Universal Compaction Unit Tests
Summary:
Now that the approach to parallelizing L0-L1 level-based
compactions by breaking the compaction job into subcompactions is
being extended to apply to universal compactions as well, the unit
tests need to account for this and run the universal compaction
tests with subcompactions both enabled and disabled.
Test Plan: make all && make check
Reviewers: sdong, igor, noetzli, anthony, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D45657/"
rocksdb,"Do not suppress C4018 'expression' : signed/unsigned mismatch
The code compiles cleanly for the most part. Fix db_test.
Move debug file to testutil library./Fail recovery if filter provides more records than original and corresponding unit-test, fix naming conventions/Fixed the clang compilation failure
Summary: As above.
Test Plan: USE_CLANG=1 make check -j
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D48981/Fix db_test under ROCKSDB_LITE
Summary:
This diff exclude alot of tests in db_test that are not compiling / failing under ROCKSD_LITE
Test Plan:
OPT=-DROCKSDB_LITE make check -j64
make check -j64
Reviewers: yhchiang, igor, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D48771/Make DBTest.ReadLatencyHistogramByLevel more robust
Summary:
Two fixes:
1. Wait compaction after generating each L0 file so that we are sure there are one L0 file left.
2. https://reviews.facebook.net/D48423 increased from 500 keys to 700 keys but in verification phase we are still querying the first 500 keys. It is a bug to fix.
Test Plan: Run the test in the same environment that fails by chance of one in tens of times. It doesn't fail after 1000 times.
Reviewers: yhchiang, IslamAbdelRahman, igor, rven, kradhakrishnan
Reviewed By: rven, kradhakrishnan
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D48759/Fix format specifiers/Fix format specifiers/Make DBTest.AggregatedTableProperties more deterministic
Summary: Now based on environment, DBTest.AggregatedTableProperties has a possibility of issuing a L0->L1 compaction after reopening and the results are not what we expected. We tune the L0 compaction trigger to make it less likely to happen.
Test Plan: I can't repro the failure but I think the change is better. Just run the test and make sure it passes.
Reviewers: kradhakrishnan, yhchiang, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D48423/bloom hit/miss stats for SST and memtable
Summary:
hit and miss bloom filter stats for memtable and SST
stats added to perf_context struct
key matches and prefix matches combined into one stat
Test Plan: unit test veryfing the functionality added, see BloomStatsTest in db_test.cc for details
Reviewers: yhchiang, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D47859/Fix valgrind - Initialize done variable
Summary: Fixes the valgrind warning ""Conditional jump or move depends on uninitialised value(s)""
Test Plan: valgrind test, no more warning
Reviewers: sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D48177/Add APIs PauseBackgroundWork() and ContinueBackgroundWork()
Summary:
To support a new MongoDB capability, we need to make sure that we don't do any IO for a short period of time. For background, see:
* https://jira.mongodb.org/browse/SERVER-20704
* https://jira.mongodb.org/browse/SERVER-18899
To implement that, I add a new API calls PauseBackgroundWork() and ContinueBackgroundWork() which reuse the capability we already have in place for RefitLevel() function.
Test Plan: Added a new test in db_test. Made sure that test fails when PauseBackgroundWork() is commented out.
Reviewers: IslamAbdelRahman, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D47901/Fixed a bug which causes rocksdb.flush.write.bytes stat is always zero
Summary: Fixed a bug which causes rocksdb.flush.write.bytes stat is always zero
Test Plan: augment existing db_test
Reviewers: sdong, anthony, IslamAbdelRahman, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D47595/Fixed a memory leak issue in DBTest.UnremovableSingleDelete
Summary: Fixed a memory leak issue in DBTest.UnremovableSingleDelete
Test Plan: valgrind --error-exitcode=2 --leak-check=full ./db_test --gtest_filter=""*UnremovableSingleDelete*""
Reviewers: sdong, anthony, IslamAbdelRahman, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D47583/Support for SingleDelete()
Summary:
This patch fixes #7460559. It introduces SingleDelete as a new database
operation. This operation can be used to delete keys that were never
overwritten (no put following another put of the same key). If an overwritten
key is single deleted the behavior is undefined. Single deletion of a
non-existent key has no effect but multiple consecutive single deletions are
not allowed (see limitations).
In contrast to the conventional Delete() operation, the deletion entry is
removed along with the value when the two are lined up in a compaction. Note:
The semantics are similar to @igor's prototype that allowed to have this
behavior on the granularity of a column family (
https://reviews.facebook.net/D42093 ). This new patch, however, is more
aggressive when it comes to removing tombstones: It removes the SingleDelete
together with the value whenever there is no snapshot between them while the
older patch only did this when the sequence number of the deletion was older
than the earliest snapshot.
Most of the complex additions are in the Compaction Iterator, all other changes
should be relatively straightforward. The patch also includes basic support for
single deletions in db_stress and db_bench.
Limitations:
- Not compatible with cuckoo hash tables
- Single deletions cannot be used in combination with merges and normal
deletions on the same key (other keys are not affected by this)
- Consecutive single deletions are currently not allowed (and older version of
this patch supported this so it could be resurrected if needed)
Test Plan: make all check
Reviewers: yhchiang, sdong, rven, anthony, yoshinorim, igor
Reviewed By: igor
Subscribers: maykov, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D43179/Merge issue with D46773
Summary: There was a merge issue with SleepingBackgroundTask
Test Plan: compiles now
Reviewers: sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D46977/LogAndApply() should fail if the column family has been dropped
Summary:
This patch finally fixes the ColumnFamilyTest.ReadDroppedColumnFamily test. The test has been failing very sporadically and it was hard to repro. However, I managed to write a new tests that reproes the failure deterministically.
Here's what happens:
1. We start the flush for the column family
2. We check if the column family was dropped here: https://github.com/facebook/rocksdb/blob/a3fc49bfddcdb1ff29409aacd06c04df56c7a1d7/db/flush_job.cc#L149
3. This check goes through, ends up in InstallMemtableFlushResults() and it goes into LogAndApply()
4. At about this time, we start dropping the column family. Dropping the column family process gets to LogAndApply() at about the same time as LogAndApply() from flush process
5. Drop column family goes through LogAndApply() first, marking the column family as dropped.
6. Flush process gets woken up and gets a chance to write to the MANIFEST. However, this is where it gets stuck: https://github.com/facebook/rocksdb/blob/a3fc49bfddcdb1ff29409aacd06c04df56c7a1d7/db/version_set.cc#L1975
7. We see that the column family was dropped, so there is no need to write to the MANIFEST. We return OK.
8. Flush gets OK back from LogAndApply() and it deletes the memtable, thinking that the data is now safely persisted to sst file.
The fix is pretty simple. Instead of OK, we return ShutdownInProgress. This is not really true, but we have been using this status code to also mean ""this operation was canceled because the column family has been dropped"".
The fix is only one LOC. All other code is related to tests. I added a new test that reproes the failure. I also moved SleepingBackgroundTask to util/testutil.h (because I needed it in column_family_test for my new test). There's plenty of other places where we reimplement SleepingBackgroundTask, but I'll address that in a separate commit.
Test Plan:
1. new test
2. make check
3. Make sure the ColumnFamilyTest.ReadDroppedColumnFamily doesn't fail on Travis: https://travis-ci.org/facebook/rocksdb/jobs/79952386
Reviewers: yhchiang, anthony, IslamAbdelRahman, kradhakrishnan, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D46773/Add options.hard_pending_compaction_bytes_limit to stop writes if compaction lagging behind
Summary: Add an option to stop writes if compaction lefts behind. If estimated pending compaction bytes is more than threshold specified by options.hard_pending_compaction_bytes_liimt, writes will stop until compactions are cleared to under the threshold.
Test Plan: Add unit test DBTest.HardLimit
Reviewers: rven, kradhakrishnan, anthony, IslamAbdelRahman, yhchiang, igor
Reviewed By: igor
Subscribers: MarkCallaghan, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D45999/Make DBTest.ReadLatencyHistogramByLevel more robust
Summary: DBTest.ReadLatencyHistogramByLevel was not written as expected. After writes, reads aren't guaranteed to hit data written. It was not expected. Fix it.
Test Plan: Run the test multiple times
Reviewers: IslamAbdelRahman, rven, anthony, kradhakrishnan, yhchiang, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D46587/Bug fix: table readers created by TableCache::Get() doesn't have latency histogram reported
Summary: TableCache::Get() puts parameters in the wrong places so that table readers created by Get() will not have the histogram updated.
Test Plan: Will write a unit test for that.
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D46035/Add Subcompactions to Universal Compaction Unit Tests
Summary:
Now that the approach to parallelizing L0-L1 level-based
compactions by breaking the compaction job into subcompactions is
being extended to apply to universal compactions as well, the unit
tests need to account for this and run the universal compaction
tests with subcompactions both enabled and disabled.
Test Plan: make all && make check
Reviewers: sdong, igor, noetzli, anthony, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D45657/Fix deadlock in WAL sync
Summary:
MarkLogsSynced() was doing `logs_.erase(it++);`. The standard is saying:
```
all iterators and references are invalidated, unless the erased members are at an end (front or back) of the deque (in which case only iterators and references to the erased members are invalidated)
```
Because `it` is an iterator to the first element of the container, it is
invalidated, only one iteration is executed and `log.getting_synced = false;`
is not being done, so `while (logs_.front().getting_synced)` in `WriteImpl()`
is not terminating.
Test Plan: make db_bench && ./db_bench --benchmarks=fillsync
Reviewers: igor, rven, IslamAbdelRahman, anthony, kradhakrishnan, yhchiang, sdong, tnovak
Reviewed By: tnovak
Subscribers: kolmike, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D45807/Fix DBTest.ApproximateMemoryUsage
Summary:
This patch fixes two issues in DBTest.ApproximateMemoryUsage:
- It was possible that a flush happened between getting the two properties in
Phase 1, resulting in different numbers for the properties and failing the
assertion. This is fixed by waiting for the flush to finish before getting
the properties.
- There was a similar issue in Phase 2 and additionally there was an issue that
rocksdb.size-all-mem-tables was not monotonically increasing because it was
possible that a flush happened just after getting the properties and then
another flush just before getting the properties in the next round. In this
situation, the reported memory usage decreased. This is fixed by forcing a
flush before getting the properties.
Note: during testing, I found that kFlushesPerRound does not seem very
accurate. I added a TODO for this and it would be great to get some input on
what to do there.
Test Plan:
The first issue can be made more likely to trigger by inserting a
`usleep(10000);` between the calls to GetIntProperty() in Phase 1.
The second issue can be made more likely to trigger by inserting a
`if (r != 0) usleep(10000);` before the calls to GetIntProperty() and a
`usleep(10000);` after the calls.
Then execute make db_test && ./db_test --gtest_filter=DBTest.ApproximateMemoryUsage
Reviewers: rven, yhchiang, igor, sdong, anthony
Reviewed By: anthony
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D45675/Fix DBTest.GetProperty
Summary:
DBTest.GetProperty was failing occasionally (see task #8131266). The reason was
that the test closed the database before the compaction was done. When the test
reopened the database, RocksDB would schedule a compaction which in turn
created table readers and lead the test to fail the assertion that
rocksdb.estimate-table-readers-mem is 0. In most cases, GetIntProperty() of
rocksdb.estimate-table-readers-mem happened before the compaction created the
table readers, hiding the problem. This patch changes the
WaitForFlushMemTable() to WaitForCompact(). WaitForFlushMemTable() is not
necessary because it is already being called a couple of lines before without
any insertions in-between.
Test Plan:
Insert `usleep(10000);` just after `Reopen(options);` on line 2333 to make the issue more likely, then run:
make db_test && while ./db_test --gtest_filter=DBTest.GetProperty; do true; done
Reviewers: rven, yhchiang, anthony, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D45603/Merge pull request #698 from yuslepukhin/address_noexcept_windows
Address noexcept and const integer lambda capture on win/Address noexcept and const integer lambda capture
VS 2013 does not support noexcept.
Complains about usage of ineteger constant within lambda requiring explicit capture./Fixing race condition in DBTest.DynamicMemtableOptions
Summary:
This patch fixes a race condition in DBTEst.DynamicMemtableOptions. In rare cases,
it was possible that the main thread would fill up both memtables before the flush
job acquired its work. Then, the flush job was flushing both memtables together,
producing only one L0 file while the test expected two. Now, the test waits for
flushes to finish earlier, to make sure that the memtables are flushed in separate
flush jobs.
Test Plan:
Insert ""usleep(10000);"" after ""IOSTATS_SET_THREAD_POOL_ID(Env::Priority::HIGH);"" in BGWorkFlush()
to make the issue more likely. Then test with:
make db_test && time while ./db_test --gtest_filter=*DynamicMemtableOptions; do true; done
Reviewers: rven, sdong, yhchiang, anthony, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D45429/Add a counter about estimated pending compaction bytes
Summary:
Add a counter of estimated bytes the DB needs to compact for all the compactions to finish. Expose it as a DB Property.
In the future, we can use threshold of this counter to replace soft rate limit and hard rate limit. A single threshold of estimated compaction debt in bytes will be easier for users to reason about when should slow down and stopping than more abstract soft and hard rate limits.
Test Plan: Add unit tests
Reviewers: IslamAbdelRahman, yhchiang, rven, kradhakrishnan, anthony, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D44205/Fixed a rare deadlock in DBTest.ThreadStatusFlush
Summary:
Currently, ThreadStatusFlush uses two sync-points to ensure
there's a flush currently running when calling GetThreadList().
However, one of the sync-point is inside db-mutex, which could
cause deadlock in case there's a DB::Get() call.
This patch fix this issue by moving the sync-point to a better
place where the flush job does not hold the mutex.
Test Plan: db_test
Reviewers: igor, sdong, anthony, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D45045/Rate limit deletes issued by DestroyDB
Summary: Update DestroyDB so that all SST files in the first path id go through DeleteScheduler instead of being deleted immediately
Test Plan: added a unittest
Reviewers: igor, yhchiang, anthony, kradhakrishnan, rven, sdong
Reviewed By: sdong
Subscribers: jeanxu2012, dhruba
Differential Revision: https://reviews.facebook.net/D44955/Remove the contstaint that iterator upper bound needs to be within a prefix
Summary: There is a check to fail the iterator if prefix extractor is specified but upper bound is out of the prefix for the seek key. Relax this constraint to allow users to set upper bound to the next prefix of the current one.
Test Plan: make commit-prereq
Reviewers: igor, anthony, kradhakrishnan, yhchiang, rven
Reviewed By: rven
Subscribers: tnovak, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D44949/"
rocksdb,"Log more information for the add file with overlapping range failure
Summary: crash_test sometimes fails, hitting the add file overlapping assert. Add information in info logs help us to find the bug.
Test Plan: Run all test suites. Do some manual tests to make sure printing is correct.
Reviewers: kradhakrishnan, yhchiang, anthony, IslamAbdelRahman, rven, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D49017/Fix iOS build
Summary: We don't yet have a CI build for iOS, so our iOS compile gets broken sometimes. Most of the errors are from assumption that size_t is 64-bit, while it's actually 32-bit on some (all?) iOS platforms. This diff fixes the compile.
Test Plan:
TARGET_OS=IOS make static_lib
Observe there are no warnings
Reviewers: sdong, anthony, IslamAbdelRahman, kradhakrishnan, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D49029/Fixed the clang compilation failure
Summary: As above.
Test Plan: USE_CLANG=1 make check -j
Reviewers: igor
Reviewed By: igor
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D48981/log_reader: pass log_number and optional info_log to ctor
We will need the log number to validate the recycle-style CRCs.  The log
is helpful for debugging, but optional, as not all callers have it.
Signed-off-by: Sage Weil <sage@redhat.com>/LogAndApply() should fail if the column family has been dropped
Summary:
This patch finally fixes the ColumnFamilyTest.ReadDroppedColumnFamily test. The test has been failing very sporadically and it was hard to repro. However, I managed to write a new tests that reproes the failure deterministically.
Here's what happens:
1. We start the flush for the column family
2. We check if the column family was dropped here: https://github.com/facebook/rocksdb/blob/a3fc49bfddcdb1ff29409aacd06c04df56c7a1d7/db/flush_job.cc#L149
3. This check goes through, ends up in InstallMemtableFlushResults() and it goes into LogAndApply()
4. At about this time, we start dropping the column family. Dropping the column family process gets to LogAndApply() at about the same time as LogAndApply() from flush process
5. Drop column family goes through LogAndApply() first, marking the column family as dropped.
6. Flush process gets woken up and gets a chance to write to the MANIFEST. However, this is where it gets stuck: https://github.com/facebook/rocksdb/blob/a3fc49bfddcdb1ff29409aacd06c04df56c7a1d7/db/version_set.cc#L1975
7. We see that the column family was dropped, so there is no need to write to the MANIFEST. We return OK.
8. Flush gets OK back from LogAndApply() and it deletes the memtable, thinking that the data is now safely persisted to sst file.
The fix is pretty simple. Instead of OK, we return ShutdownInProgress. This is not really true, but we have been using this status code to also mean ""this operation was canceled because the column family has been dropped"".
The fix is only one LOC. All other code is related to tests. I added a new test that reproes the failure. I also moved SleepingBackgroundTask to util/testutil.h (because I needed it in column_family_test for my new test). There's plenty of other places where we reimplement SleepingBackgroundTask, but I'll address that in a separate commit.
Test Plan:
1. new test
2. make check
3. Make sure the ColumnFamilyTest.ReadDroppedColumnFamily doesn't fail on Travis: https://travis-ci.org/facebook/rocksdb/jobs/79952386
Reviewers: yhchiang, anthony, IslamAbdelRahman, kradhakrishnan, rven, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D46773/Bug fix: table readers created by TableCache::Get() doesn't have latency histogram reported
Summary: TableCache::Get() puts parameters in the wrong places so that table readers created by Get() will not have the histogram updated.
Test Plan: Will write a unit test for that.
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D46035/Add a counter about estimated pending compaction bytes
Summary:
Add a counter of estimated bytes the DB needs to compact for all the compactions to finish. Expose it as a DB Property.
In the future, we can use threshold of this counter to replace soft rate limit and hard rate limit. A single threshold of estimated compaction debt in bytes will be easier for users to reason about when should slow down and stopping than more abstract soft and hard rate limits.
Test Plan: Add unit tests
Reviewers: IslamAbdelRahman, yhchiang, rven, kradhakrishnan, anthony, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D44205/"
rocksdb,"Allow users to disable some kill points in db_stress
Summary:
Give a name for every kill point, and allow users to disable some kill points based on prefixes. The kill points can be passed by db_stress through a command line paramter. This provides a way for users to boost the chance of triggering low frequency kill points
This allow follow up changes in crash test scripts to improve crash test coverage.
Test Plan:
Manually run db_stress with variable values of --kill_random_test and --kill_prefix_blacklist. Like this:
--kill_random_test=2 --kill_prefix_blacklist=Posix,WritableFileWriter::Append,WritableFileWriter::WriteBuffered,WritableFileWriter::Sync
Reviewers: igor, kradhakrishnan, rven, IslamAbdelRahman, yhchiang
Reviewed By: yhchiang
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D48735/Merge pull request #751 from yuslepukhin/return_noerror
Mmap reads should not return error if reading past file/Mmap reads should not return error if reading past file
Summary:
This mirrors  https://reviews.facebook.net/D45645
Currently, mmap returns IOError when user tries to read
data past the end of the file. This diff changes the behavior.
Now, we return just the bytes that we can, and report the size
we returned via a Slice result. This is consistent with non-mmap
behavior and also pread() system call./Address code review comments both GH and internal
Fix compilation issues on GCC/CLANG
Address Windows Release test build issues due to Sync/Refactor to support file_reader_writer on Windows.
Summary. A change https://reviews.facebook.net/differential/diff/224721/
Has attempted to move common functionality out of platform dependent
code to a new facility called file_reader_writer.
This includes:
- perf counters
- Buffering
- RateLimiting
However, the change did not attempt to refactor Windows code.
To mitigate, we introduce new quering interfaces such as UseOSBuffer(),
GetRequiredBufferAlignment() and ReaderWriterForward()
for pure forwarding where required.
Introduce WritableFile got a new method Truncate(). This is to communicate
to the file as to how much data it has on close.
- When space is pre-allocated on Linux it is filled with zeros implicitly,
no such thing exist on Windows so we must truncate file on close.
- When operating in unbuffered mode the last page is filled with zeros but we still want to truncate.
Previously, Close() would take care of it but now buffer management is shifted to the wrappers and the file has
no idea about the file true size.
This means that Close() on the wrapper level must always include
Truncate() as well as wrapper __dtor should call Close() and
against double Close().
Move buffered/unbuffered write logic to the wrapper.
Utilize Aligned buffer class.
Adjust tests and implement Truncate() where necessary.
Come up with reasonable defaults for new virtual interfaces.
Forward calls for RandomAccessReadAhead class to avoid double
buffering and locking (double locking in unbuffered mode on WIndows)./Make WinEnv::NowMicros return system time
Previous change for the function
https://github.com/facebook/rocksdb/commit/555ca3e7b7f06bd01dfd5e04dbb2cef5360f7917#diff-bdc04e0404c2db4fd3ac5118a63eaa4a
made use of the QueryPerformanceCounter to return microseconds values that do not repeat
as std::chrono::system_clock returned values that made auto_roll_logger_test fail.
The interface documentation does not state that we need to return
system time describing the return value as a number of microsecs since some
moment in time. However, because on Linux it is implemented using gettimeofday
various pieces of code (such as GenericRateLimiter) took advantage of that
and make use of NowMicros() as a system timestamp. Thus the previous change
broke rate_limiter_test on Windows.
In addition, the interface name NowMicros() suggests that it is actually
a timestamp so people use it as such.
This change makes use of the new system call on Windows that returns
system time with required precision. This change preserves the fix
for  auto_roll_logger_test and fixes rate_limiter_test.
Note that DBTest.RateLimitingTest still fails due to a separately reported issue./"
rocksdb,"crash_test: cover concurrent memtable insert in default crash test
Summary: Default crash test uses prefix hash memtable, which is not compatible to concurrent memtable. Allow prefix test run with skip list and use skip list memtable when concurrent insert is used.
Test Plan: Run ""python -u tools/db_crashtest.py whitebox"" and watch sometimes skip list is used.
Reviewers: anthony, yhchiang, kradhakrishnan, andrewkr, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D53907/Add --allow_concurrent_memtable_write in stress test and run it in crash_test
Summary: Add an option of --allow_concurrent_memtable_write in stress test and cover it in crash test
Test Plan: Run crash test and make sure three combinations of the two options show up randomly.
Reviewers: IslamAbdelRahman, yhchiang, andrewkr, anthony, kradhakrishnan
Reviewed By: kradhakrishnan
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D53811/Merge pull request #873 from yuslepukhin/make_vs15_build
Fix up VS 15 build./Fix up VS 15 build.
Fix warnings
Take advantage of native snprintf on VS 15/"
rocksdb,"Resubmit the fix for a race condition in persisting options
Summary:
This patch fix a race condition in persisting options which will cause a crash when:
* Thread A obtain cf options and start to persist options based on that cf options.
* Thread B kicks in and finish DropColumnFamily and delete cf_handle.
* Thread A wakes up and tries to finish the persisting options and crashes.
Test Plan: Add a test in column_family_test that can reproduce the crash
Reviewers: anthony, IslamAbdelRahman, rven, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D51717/Revert ""Fix a race condition in persisting options""
This reverts commit 2fa3ed5180340e485a1caf6fa71cc400ea599278. It breaks RocksDB lite build/Fix a race condition in persisting options
Summary:
This patch fix a race condition in persisting options which will cause a crash when:
* Thread A obtain cf options and start to persist options based on that cf options.
* Thread B kicks in and finish DropColumnFamily and delete cf_handle.
* Thread A wakes up and tries to finish the persisting options and crashes.
Test Plan: Add a test in column_family_test that can reproduce the crash
Reviewers: anthony, IslamAbdelRahman, rven, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D51609/"
rocksdb,"Merge pull request #863 from zhangyybuaa/fix_hdfs_error
Fix build error with hdfs/fix ToString() not declared error/"
rocksdb,"support for concurrent adds to memtable
Summary:
This diff adds support for concurrent adds to the skiplist memtable
implementations.  Memory allocation is made thread-safe by the addition of
a spinlock, with small per-core buffers to avoid contention.  Concurrent
memtable writes are made via an additional method and don't impose a
performance overhead on the non-concurrent case, so parallelism can be
selected on a per-batch basis.
Write thread synchronization is an increasing bottleneck for higher levels
of concurrency, so this diff adds --enable_write_thread_adaptive_yield
(default off).  This feature causes threads joining a write batch
group to spin for a short time (default 100 usec) using sched_yield,
rather than going to sleep on a mutex.  If the timing of the yield calls
indicates that another thread has actually run during the yield then
spinning is avoided.  This option improves performance for concurrent
situations even without parallel adds, although it has the potential to
increase CPU usage (and the heuristic adaptation is not yet mature).
Parallel writes are not currently compatible with
inplace updates, update callbacks, or delete filtering.
Enable it with --allow_concurrent_memtable_write (and
--enable_write_thread_adaptive_yield).  Parallel memtable writes
are performance neutral when there is no actual parallelism, and in
my experiments (SSD server-class Linux and varying contention and key
sizes for fillrandom) they are always a performance win when there is
more than one thread.
Statistics are updated earlier in the write path, dropping the number
of DB mutex acquisitions from 2 to 1 for almost all cases.
This diff was motivated and inspired by Yahoo's cLSM work.  It is more
conservative than cLSM: RocksDB's write batch group leader role is
preserved (along with all of the existing flush and write throttling
logic) and concurrent writers are blocked until all memtable insertions
have completed and the sequence number has been advanced, to preserve
linearizability.
My test config is ""db_bench -benchmarks=fillrandom -threads=$T
-batch_size=1 -memtablerep=skip_list -value_size=100 --num=1000000/$T
-level0_slowdown_writes_trigger=9999 -level0_stop_writes_trigger=9999
-disable_auto_compactions --max_write_buffer_number=8
-max_background_flushes=8 --disable_wal --write_buffer_size=160000000
--block_size=16384 --allow_concurrent_memtable_write"" on a two-socket
Xeon E5-2660 @ 2.2Ghz with lots of memory and an SSD hard drive.  With 1
thread I get ~440Kops/sec.  Peak performance for 1 socket (numactl
-N1) is slightly more than 1Mops/sec, at 16 threads.  Peak performance
across both sockets happens at 30 threads, and is ~900Kops/sec, although
with fewer threads there is less performance loss when the system has
background work.
Test Plan:
1. concurrent stress tests for InlineSkipList and DynamicBloom
2. make clean; make check
3. make clean; DISABLE_JEMALLOC=1 make valgrind_check; valgrind db_bench
4. make clean; COMPILE_WITH_TSAN=1 make all check; db_bench
5. make clean; COMPILE_WITH_ASAN=1 make all check; db_bench
6. make clean; OPT=-DROCKSDB_LITE make check
7. verify no perf regressions when disabled
Reviewers: igor, sdong
Reviewed By: sdong
Subscribers: MarkCallaghan, IslamAbdelRahman, anthony, yhchiang, rven, sdong, guyg8, kradhakrishnan, dhruba
Differential Revision: https://reviews.facebook.net/D50589/"
rocksdb,"Fixed a dependency issue of ThreadLocalPtr
Summary:
When a child thread that uses ThreadLocalPtr, ThreadLocalPtr::OnThreadExit
will be called when that child thread is destroyed.  However,
OnThreadExit will try to access a static singleton of ThreadLocalPtr,
which will be destroyed when the main thread exit.  As a result,
when a child thread that uses ThreadLocalPtr exits AFTER the main thread
exits, illegal memory access will occur.
This diff includes a test that reproduce this legacy bug.
==2095206==ERROR: AddressSanitizer: heap-use-after-free on address
0x608000007fa0 at pc 0x959b79 bp 0x7f5fa7426b60 sp 0x7f5fa7426b58
READ of size 8 at 0x608000007fa0 thread T1
This patch fix this issue by having the thread local mutex never be deleted
(but will leak small piece of memory at the end.)   The patch also describe
a better solution (thread_local) in the comment that requires gcc 4.8.1 and
in latest clang as a future work once we agree to move toward gcc 4.8.
Test Plan:
COMPILE_WITH_ASAN=1 make thread_local_test -j32
./thread_local_test --gtest_filter=""*MainThreadDiesFirst""
Reviewers: anthony, hermanlee4, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D53013/Ensure the destruction order of PosixEnv and ThreadLocalPtr
Summary:
By default, RocksDB initializes the singletons of ThreadLocalPtr first, then initializes PosixEnv
via static initializer.  Destructor terminates objects in reverse order, so terminating PosixEnv
(calling pthread_mutex_lock), then ThreadLocal (calling pthread_mutex_destroy).
However, in certain case, application might initialize PosixEnv first, then ThreadLocalPtr.
This will cause core dump at the end of the program (eg. https://github.com/facebook/mysql-5.6/issues/122)
This patch fix this issue by ensuring the destruction order by moving the global static singletons
to function static singletons.  Since function static singletons are initialized when the function is first
called, this property allows us invoke to enforce the construction of the static PosixEnv and the
singletons of ThreadLocalPtr by calling the function where the ThreadLocalPtr singletons belongs
right before we initialize the static PosixEnv.
Test Plan: Verified in the MyRocks.
Reviewers: yoshinorim, IslamAbdelRahman, rven, kradhakrishnan, anthony, sdong, MarkCallaghan
Reviewed By: anthony
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D51789/"
rocksdb,Fix a memory leak of Slice objects from org.rocksdb.WBWIRocksIterator#entry1/
rocksdb,Fix a memory leak of Slice objects from org.rocksdb.WBWIRocksIterator#entry1/
rocksdb,Fix a memory leak of Slice objects from org.rocksdb.WBWIRocksIterator#entry1/
rocksdb,Fix a memory leak of Slice objects from org.rocksdb.WBWIRocksIterator#entry1/
rocksdb,Fix a memory leak of Slice objects from org.rocksdb.WBWIRocksIterator#entry1/
rocksdb,Fix a memory leak of Slice objects from org.rocksdb.WBWIRocksIterator#entry1/
rocksdb,"fix valgrind failure in backupable_db_test
Summary: fix memory leak in test code
Test Plan: ran test
Reviewers: rven, igor, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D52617/Fix issue #921
Summary:
See a bug report here: https://github.com/facebook/rocksdb/issues/921
The fix is to not check the shared/ directory if share_table_files is false. We could also check FileExists() before GetChildren(), but that will add extra latency when Env is Hdfs :(
Test Plan: added a unit test
Reviewers: rven, sdong, IslamAbdelRahman, yhchiang, anthony
Reviewed By: anthony
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D52593/"
rocksdb,"Merge pull request #899 from zhipeng-jia/fix_clang_warning
Fix clang warnings/Fix clang warnings regarding unnecessary std::move/"
rocksdb,"Use SST files for Transaction conflict detection
Summary:
Currently, transactions can fail even if there is no actual write conflict.  This is due to relying on only the memtables to check for write-conflicts.  Users have to tune memtable settings to try to avoid this, but it's hard to figure out exactly how to tune these settings.
With this diff, TransactionDB will use both memtables and SST files to determine if there are any write conflicts.  This relies on the fact that BlockBasedTable stores sequence numbers for all writes that happen after any open snapshot.  Also, D50295 is needed to prevent SingleDelete from disappearing writes (the TODOs in this test code will be fixed once the other diff is approved and merged).
Note that Optimistic transactions will still rely on tuning memtable settings as we do not want to read from SST while on the write thread.  Also, memtable settings can still be used to reduce how often TransactionDB needs to read SST files.
Test Plan: unit tests, db bench
Reviewers: rven, yhchiang, kradhakrishnan, IslamAbdelRahman, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb, yoshinorim
Differential Revision: https://reviews.facebook.net/D50475/"
rocksdb,"Lint everything
Summary:
```
arc2 lint --everything
```
run the linter on the whole code repo to fix exisitng lint issues
Test Plan: make check -j64
Reviewers: sdong, rven, anthony, kradhakrishnan, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D50769/"
rocksdb,"Lint everything
Summary:
```
arc2 lint --everything
```
run the linter on the whole code repo to fix exisitng lint issues
Test Plan: make check -j64
Reviewers: sdong, rven, anthony, kradhakrishnan, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D50769/"
rocksdb,"plain table reader: non-mmap mode to keep two recent buffers
Summary: In plain table reader's non-mmap mode, we only keep the most recent read buffer. However, for binary search, it is likely we come back to a location to read. To avoid one pread in such a case, we keep two read buffers. It should cover most of the cases.
Test Plan:
1. run tests
2. check the optimization works through strace when running
./table_reader_bench -mmap_read=false --num_keys2=1 -num_keys1=5000 -table_factory=plain_table --iterator --through_db
Reviewers: anthony, rven, kradhakrishnan, igor, yhchiang, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D51171/plain table reader: avoid re-read the same position for index and data in non-mmap mode
Summary: In non-mmap mode, plain table reader can issue two pread() for index checking and reading the actual data, although it's for the same location. By reusing the key decoder, we reuse the buffer used for the two to avoid it.
Test Plan: Run unit tests. Run table_reader_bench and see from strace the repeat read cases to disappear.
Reviewers: anthony, yhchiang, rven, kradhakrishnan, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D50949/"
rocksdb,"Disallow SstFileWriter from creating empty sst files
Summary:
SstFileWriter may create an sst file with no entries
Right now this will fail when being ingested using DB::AddFile() saying that the keys are corrupted
Test Plan: make check
Reviewers: yhchiang, rven, anthony, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D52815/"
rocksdb,"Fix issue in Iterator::Seek when using Block based filter block with prefix_extractor
Summary: Similar to D53385 we need to check InDomain before checking the filter block.
Test Plan: unit tests
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D53421/Fix bug in block based tables with full filter block and prefix_extractor
Summary:
Right now when we are creating a BlockBasedTable with fill filter block
we add to the filter all the prefixes that are InDomain() based on the prefix_extractor
the problem is that when we read a key from the file, we check the filter block for the prefix whether or not it's InDomain()
Test Plan: unit tests
Reviewers: yhchiang, rven, anthony, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D53385/Merge pull request #923 from petermattis/pmattis/prefix-may-match
Fix index seeking in BlockTableReader::PrefixMayMatch./Fix index seeking in BlockTableReader::PrefixMayMatch.
PrefixMayMatch previously seeked in the prefix index using an internal
key with a sequence number of 0. This would cause the prefix index seek
to fall off the end if the last key in the index had a user-key greater
than or equal to the key being looked for. Falling off the end of the
index in turn results in PrefixMayMatch returning false if the index is
in memory./"
rocksdb,"plain table reader: non-mmap mode to keep two recent buffers
Summary: In plain table reader's non-mmap mode, we only keep the most recent read buffer. However, for binary search, it is likely we come back to a location to read. To avoid one pread in such a case, we keep two read buffers. It should cover most of the cases.
Test Plan:
1. run tests
2. check the optimization works through strace when running
./table_reader_bench -mmap_read=false --num_keys2=1 -num_keys1=5000 -table_factory=plain_table --iterator --through_db
Reviewers: anthony, rven, kradhakrishnan, igor, yhchiang, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D51171/"
rocksdb,"Fix BlockBasedTableTest.NoopTransformSeek failure
Summary:
table_test is failing because we are creating a temp InternalComparator
14:27:28 [ RUN      ] BlockBasedTableTest.NoopTransformSeek
14:27:28 pure virtual method called
14:27:28 terminate called without an active exception
14:27:28 /bin/sh: line 7: 2346261 Aborted                 (core dumped) ./$t
Test Plan: make table_test -j64 && ./table_test --gtest_filter=""BlockBasedTableTest.NoopTransformSeek""
Reviewers: igor, sdong, anthony, rven
Reviewed By: rven
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D52671/Revert ""Fixed the bug when both whole_key_filtering and prefix_extractor are set.""
Summary:
This patch reverts commit 57605d7ef3d6108da94f7b5e4846cac8c3747059 as it will
cause BlockBasedTableTest.NoopTransformSeek test crashes in some environment.
Test Plan: revert the patch
Reviewers: anthony, IslamAbdelRahman, rven, kradhakrishnan, sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D52623/Fixed the bug when both whole_key_filtering and prefix_extractor are set.
Summary:
When both whole_key_filtering and prefix_extractor are set, RocksDB will
mistakenly encode prefix + whole key into the database instead of
simply whole key when BlockBasedTable is used.  This patch fixes this bug.
Test Plan: Add a test in table_test
Reviewers: anthony, IslamAbdelRahman, rven, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D52233/Merge pull request #923 from petermattis/pmattis/prefix-may-match
Fix index seeking in BlockTableReader::PrefixMayMatch./Fix index seeking in BlockTableReader::PrefixMayMatch.
PrefixMayMatch previously seeked in the prefix index using an internal
key with a sequence number of 0. This would cause the prefix index seek
to fall off the end if the last key in the index had a user-key greater
than or equal to the key being looked for. Falling off the end of the
index in turn results in PrefixMayMatch returning false if the index is
in memory./use -Werror=missing-field-initializers, to closer match MyRocks build
Summary:
myrocks seems to build rocksdb using
-Wmissing-field-initializers (and treats warnings as errors).  This diff
adds that flag to the rocksdb build, and fixes the compilation failures
that result.  I have not checked for any other differences in the build
flags for rocksdb build as part of myrocks.
Test Plan: make check
Reviewers: sdong, rven
Reviewed By: rven
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D52443/support for concurrent adds to memtable
Summary:
This diff adds support for concurrent adds to the skiplist memtable
implementations.  Memory allocation is made thread-safe by the addition of
a spinlock, with small per-core buffers to avoid contention.  Concurrent
memtable writes are made via an additional method and don't impose a
performance overhead on the non-concurrent case, so parallelism can be
selected on a per-batch basis.
Write thread synchronization is an increasing bottleneck for higher levels
of concurrency, so this diff adds --enable_write_thread_adaptive_yield
(default off).  This feature causes threads joining a write batch
group to spin for a short time (default 100 usec) using sched_yield,
rather than going to sleep on a mutex.  If the timing of the yield calls
indicates that another thread has actually run during the yield then
spinning is avoided.  This option improves performance for concurrent
situations even without parallel adds, although it has the potential to
increase CPU usage (and the heuristic adaptation is not yet mature).
Parallel writes are not currently compatible with
inplace updates, update callbacks, or delete filtering.
Enable it with --allow_concurrent_memtable_write (and
--enable_write_thread_adaptive_yield).  Parallel memtable writes
are performance neutral when there is no actual parallelism, and in
my experiments (SSD server-class Linux and varying contention and key
sizes for fillrandom) they are always a performance win when there is
more than one thread.
Statistics are updated earlier in the write path, dropping the number
of DB mutex acquisitions from 2 to 1 for almost all cases.
This diff was motivated and inspired by Yahoo's cLSM work.  It is more
conservative than cLSM: RocksDB's write batch group leader role is
preserved (along with all of the existing flush and write throttling
logic) and concurrent writers are blocked until all memtable insertions
have completed and the sequence number has been advanced, to preserve
linearizability.
My test config is ""db_bench -benchmarks=fillrandom -threads=$T
-batch_size=1 -memtablerep=skip_list -value_size=100 --num=1000000/$T
-level0_slowdown_writes_trigger=9999 -level0_stop_writes_trigger=9999
-disable_auto_compactions --max_write_buffer_number=8
-max_background_flushes=8 --disable_wal --write_buffer_size=160000000
--block_size=16384 --allow_concurrent_memtable_write"" on a two-socket
Xeon E5-2660 @ 2.2Ghz with lots of memory and an SSD hard drive.  With 1
thread I get ~440Kops/sec.  Peak performance for 1 socket (numactl
-N1) is slightly more than 1Mops/sec, at 16 threads.  Peak performance
across both sockets happens at 30 threads, and is ~900Kops/sec, although
with fewer threads there is less performance loss when the system has
background work.
Test Plan:
1. concurrent stress tests for InlineSkipList and DynamicBloom
2. make clean; make check
3. make clean; DISABLE_JEMALLOC=1 make valgrind_check; valgrind db_bench
4. make clean; COMPILE_WITH_TSAN=1 make all check; db_bench
5. make clean; COMPILE_WITH_ASAN=1 make all check; db_bench
6. make clean; OPT=-DROCKSDB_LITE make check
7. verify no perf regressions when disabled
Reviewers: igor, sdong
Reviewed By: sdong
Subscribers: MarkCallaghan, IslamAbdelRahman, anthony, yhchiang, rven, sdong, guyg8, kradhakrishnan, dhruba
Differential Revision: https://reviews.facebook.net/D50589/Fix BlockBasedTableTest.BlockCacheLeak valgrind failure
Summary:
I added this line in my previous patch D48999 (which is incorrect)
We should not release the iterator since releasing it will evict the blocks from cache
Test Plan:
Run the test under valgrind
make check
Reviewers: rven, yhchiang, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D52161/"
rocksdb,"Improve perf of Pessimistic Transaction expirations (and optimistic transactions)
Summary:
copy from task 8196669:
1) Optimistic transactions do not support batching writes from different threads.
2) Pessimistic transactions do not support batching writes if an expiration time is set.
In these 2 cases, we currently do not do any write batching in DBImpl::WriteImpl() because there is a WriteCallback that could decide at the last minute to abort the write.  But we could support batching write operations with callbacks if we make sure to process the callbacks correctly.
To do this, we would first need to modify write_thread.cc to stop preventing writes with callbacks from being batched together.  Then we would need to change DBImpl::WriteImpl() to call all WriteCallback's in a batch, only write the batches that succeed, and correctly set the state of each batch's WriteThread::Writer.
Test Plan: Added test WriteWithCallbackTest to write_callback_test.cc which creates multiple client threads and verifies that writes are batched and executed properly.
Reviewers: hermanlee4, anthony, ngbronson
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D52863/Eliminate duplicated property constants
Summary:
Before this diff, there were duplicated constants to refer to properties (user-
facing API had strings and InternalStats had an enum). I noticed these were
inconsistent in terms of which constants are provided, names of constants, and
documentation of constants. Overall it seemed annoying/error-prone to maintain
these duplicated constants.
So, this diff gets rid of InternalStats's constants and replaces them with a map
keyed on the user-facing constant. The value in that map contains a function
pointer to get the property value, so we don't need to do string matching while
holding db->mutex_. This approach has a side benefit of making many small
handler functions rather than a giant switch-statement.
Test Plan: db_properties_test passes, running ""make commit-prereq -j32""
Reviewers: sdong, yhchiang, kradhakrishnan, IslamAbdelRahman, rven, anthony
Reviewed By: anthony
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D53253/Fix for --allow_concurrent_memtable_write with batching
Summary:
Concurrent memtable adds were incorrectly computing
the last sequence number for a write batch group when the
write batches were not solitary.  This is the cause of
https://github.com/facebook/mysql-5.6/issues/155
Test Plan:
1. unit tests
2. new unit test
3. parallel db_bench stress tests with batch size of 10 and asserts enabled
Reviewers: igor, sdong
Reviewed By: sdong
Subscribers: IslamAbdelRahman, MarkCallaghan, dhruba
Differential Revision: https://reviews.facebook.net/D53595/[directory includes cleanup] Remove util->db dependency for ThreadStatusUtil
Summary:
We can avoid the dependency by forward-declaring ColumnFamilyData and
then treating it as a black box. That means callers of ThreadStatusUtil need to
explicitly provide more options, even if they can be derived from the
ColumnFamilyData, since ThreadStatusUtil doesn't include the definition.
This is part of a series of diffs to eliminate circular dependencies between
directories (e.g., db/* files depending on util/* files and vice-versa).
Test Plan:
$ ./db_test --gtest_filter=DBTest.GetThreadStatus
$ make -j32 commit-prereq
Reviewers: sdong, yhchiang, IslamAbdelRahman
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D53361/[directory includes cleanup] Move cross-function test points
Summary:
I split the db-specific test points out into a separate file under db/
directory. There were also a few bugs to fix in xfunc.{h,cc} that prevented it
from compiling previously; see https://reviews.facebook.net/D36825.
Test Plan:
compilation works now, below command works, will also run ""make xfunc"".
$ make check ROCKSDB_XFUNC_TEST='managed_new' tests-regexp='DBTest' -j32
Reviewers: sdong, yhchiang
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D53343/Disallow SstFileWriter from creating empty sst files
Summary:
SstFileWriter may create an sst file with no entries
Right now this will fail when being ingested using DB::AddFile() saying that the keys are corrupted
Test Plan: make check
Reviewers: yhchiang, rven, anthony, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D52815/Changes for build on solaris
Makefile adjust paths for solaris build
Makefile enable _GLIBCXX_USE_C99 so that std::to_string is available
db_compaction_test.cc Initialise a variable to avoid a compilation error
db_impl.cc Include <alloca.h>
db_test.cc Include <alloca.h>
Environment.java recognise solaris envrionment
options_bulder.cc Make log unambiguous
geodb_impl.cc Make log and floor unambiguous/DeleteFilesInRange: Mark files to be deleted as being compacted before applying change
Summary:
While running the myrocks regression suite, I found that while
dropping a table soon after inserting rows into it resulted in an
assertion failure in CheckConsistencyForDeletes for not finding
a file which was recently added or moved. Marking the files to be
deleted as being compacted before calling LogAndApplyChange
fixed the assertion failures.
Test Plan: DBCompactionTest.DeleteFileRange
Reviewers: IslamAbdelRahman, anthony, yhchiang, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: dhruba, yoshinorim, leveldb
Differential Revision: https://reviews.facebook.net/D52599/use -Werror=missing-field-initializers, to closer match MyRocks build
Summary:
myrocks seems to build rocksdb using
-Wmissing-field-initializers (and treats warnings as errors).  This diff
adds that flag to the rocksdb build, and fixes the compilation failures
that result.  I have not checked for any other differences in the build
flags for rocksdb build as part of myrocks.
Test Plan: make check
Reviewers: sdong, rven
Reviewed By: rven
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D52443/Disable Visual Studio Warning C4351
Currently Windows build is broken because of Warning C4351. Disable the warning before figuring out the right way to fix it./Fix CLANG errors introduced by 7d87f02799bd0a8fd36df24fab5baa4968615c86
Summary: Fix some CLANG errors introduced in 7d87f02799bd0a8fd36df24fab5baa4968615c86
Test Plan: Build with both of CLANG and gcc
Reviewers: rven, yhchiang, kradhakrishnan, anthony, IslamAbdelRahman, ngbronson
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D52329/support for concurrent adds to memtable
Summary:
This diff adds support for concurrent adds to the skiplist memtable
implementations.  Memory allocation is made thread-safe by the addition of
a spinlock, with small per-core buffers to avoid contention.  Concurrent
memtable writes are made via an additional method and don't impose a
performance overhead on the non-concurrent case, so parallelism can be
selected on a per-batch basis.
Write thread synchronization is an increasing bottleneck for higher levels
of concurrency, so this diff adds --enable_write_thread_adaptive_yield
(default off).  This feature causes threads joining a write batch
group to spin for a short time (default 100 usec) using sched_yield,
rather than going to sleep on a mutex.  If the timing of the yield calls
indicates that another thread has actually run during the yield then
spinning is avoided.  This option improves performance for concurrent
situations even without parallel adds, although it has the potential to
increase CPU usage (and the heuristic adaptation is not yet mature).
Parallel writes are not currently compatible with
inplace updates, update callbacks, or delete filtering.
Enable it with --allow_concurrent_memtable_write (and
--enable_write_thread_adaptive_yield).  Parallel memtable writes
are performance neutral when there is no actual parallelism, and in
my experiments (SSD server-class Linux and varying contention and key
sizes for fillrandom) they are always a performance win when there is
more than one thread.
Statistics are updated earlier in the write path, dropping the number
of DB mutex acquisitions from 2 to 1 for almost all cases.
This diff was motivated and inspired by Yahoo's cLSM work.  It is more
conservative than cLSM: RocksDB's write batch group leader role is
preserved (along with all of the existing flush and write throttling
logic) and concurrent writers are blocked until all memtable insertions
have completed and the sequence number has been advanced, to preserve
linearizability.
My test config is ""db_bench -benchmarks=fillrandom -threads=$T
-batch_size=1 -memtablerep=skip_list -value_size=100 --num=1000000/$T
-level0_slowdown_writes_trigger=9999 -level0_stop_writes_trigger=9999
-disable_auto_compactions --max_write_buffer_number=8
-max_background_flushes=8 --disable_wal --write_buffer_size=160000000
--block_size=16384 --allow_concurrent_memtable_write"" on a two-socket
Xeon E5-2660 @ 2.2Ghz with lots of memory and an SSD hard drive.  With 1
thread I get ~440Kops/sec.  Peak performance for 1 socket (numactl
-N1) is slightly more than 1Mops/sec, at 16 threads.  Peak performance
across both sockets happens at 30 threads, and is ~900Kops/sec, although
with fewer threads there is less performance loss when the system has
background work.
Test Plan:
1. concurrent stress tests for InlineSkipList and DynamicBloom
2. make clean; make check
3. make clean; DISABLE_JEMALLOC=1 make valgrind_check; valgrind db_bench
4. make clean; COMPILE_WITH_TSAN=1 make all check; db_bench
5. make clean; COMPILE_WITH_ASAN=1 make all check; db_bench
6. make clean; OPT=-DROCKSDB_LITE make check
7. verify no perf regressions when disabled
Reviewers: igor, sdong
Reviewed By: sdong
Subscribers: MarkCallaghan, IslamAbdelRahman, anthony, yhchiang, rven, sdong, guyg8, kradhakrishnan, dhruba
Differential Revision: https://reviews.facebook.net/D50589/add call to install superversion and schedule work in enableautocompactions
Summary:
This patch fixes https://github.com/facebook/mysql-5.6/issues/121
There is a recent change in rocksdb to disable auto compactions on startup: https://reviews.facebook.net/D51147. However, there is a small timing window where a column family needs to be compacted and schedules a compaction, but the scheduled compaction fails when it checks the disable_auto_compactions setting. The expectation is once the application is ready, it will call EnableAutoCompactions() to allow new compactions to go through. However, if the Column family is stalled because L0 is full, and no writes can go through, it is possible the column family may never have a new compaction request get scheduled. EnableAutoCompaction() should probably schedule an new flush and compaction event when it resets disable_auto_compaction.
Using InstallSuperVersionAndScheduleWork, we call SchedulePendingFlush,
SchedulePendingCompaction, as well as MaybeScheduleFlushOrcompaction on all the
column families to avoid the situation above.
This is still a first pass for feedback.
Could also just call SchedePendingFlush and SchedulePendingCompaction directly.
Test Plan:
Run on Asan build
cd _build-5.6-ASan/ && ./mysql-test/mtr --mem --big --testcase-timeout=36000 --suite-timeout=12000 --parallel=16 --suite=rocksdb,rocksdb_rpl,rocksdb_sys_vars --mysqld=--default-storage-engine=rocksdb --mysqld=--skip-innodb --mysqld=--default-tmp-storage-engine=MyISAM --mysqld=--rocksdb rocksdb_rpl.rpl_rocksdb_stress_crash --repeat=1000
Ensure that it no longer hangs during the test.
Reviewers: hermanlee4, yhchiang, anthony
Reviewed By: anthony
Subscribers: leveldb, yhchiang, dhruba
Differential Revision: https://reviews.facebook.net/D51747/Fix minor bugs in delete operator, snprintf, and size_t usage
Summary:
List of changes:
1) Fix the snprintf() usage in cases where wrong variable was used to determine the output buffer size.
2) Remove unnecessary checks before calling delete operator.
3) Increase code correctness by using size_t type when getting vector's size.
4) Unify the coding style by removing namespace::std usage at the top of the file to confirm to the majority usage.
5) Fix various lint errors pointed out by 'arc lint'.
Test Plan:
Code review and build:
git diff
make clean
make -j 32 commit-prereq
arc lint
Reviewers: kradhakrishnan, sdong, rven, anthony, yhchiang, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D51849/Running manual compactions in parallel with other automatic or manual compactions in restricted cases
Summary:
This diff provides a framework for doing manual
compactions in parallel with other compactions. We now have a deque of manual compactions. We also pass manual compactions as an argument from RunManualCompactions down to
BackgroundCompactions, so that RunManualCompactions can be reentrant.
Parallelism is controlled by the two routines
ConflictingManualCompaction to allow/disallow new parallel/manual
compactions based on already existing ManualCompactions. In this diff, by default manual compactions still have to run exclusive of other compactions. However, by setting the compaction option, exclusive_manual_compaction to false, it is possible to run other compactions in parallel with a manual compaction. However, we are still restricted to one manual compaction per column family at a time. All of these restrictions will be relaxed in future diffs.
I will be adding more tests later.
Test Plan: Rocksdb regression + new tests + valgrind
Reviewers: igor, anthony, IslamAbdelRahman, kradhakrishnan, yhchiang, sdong
Reviewed By: sdong
Subscribers: yoshinorim, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D47973/Use SST files for Transaction conflict detection
Summary:
Currently, transactions can fail even if there is no actual write conflict.  This is due to relying on only the memtables to check for write-conflicts.  Users have to tune memtable settings to try to avoid this, but it's hard to figure out exactly how to tune these settings.
With this diff, TransactionDB will use both memtables and SST files to determine if there are any write conflicts.  This relies on the fact that BlockBasedTable stores sequence numbers for all writes that happen after any open snapshot.  Also, D50295 is needed to prevent SingleDelete from disappearing writes (the TODOs in this test code will be fixed once the other diff is approved and merged).
Note that Optimistic transactions will still rely on tuning memtable settings as we do not want to read from SST while on the write thread.  Also, memtable settings can still be used to reduce how often TransactionDB needs to read SST files.
Test Plan: unit tests, db bench
Reviewers: rven, yhchiang, kradhakrishnan, IslamAbdelRahman, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb, yoshinorim
Differential Revision: https://reviews.facebook.net/D50475/Resubmit the fix for a race condition in persisting options
Summary:
This patch fix a race condition in persisting options which will cause a crash when:
* Thread A obtain cf options and start to persist options based on that cf options.
* Thread B kicks in and finish DropColumnFamily and delete cf_handle.
* Thread A wakes up and tries to finish the persisting options and crashes.
Test Plan: Add a test in column_family_test that can reproduce the crash
Reviewers: anthony, IslamAbdelRahman, rven, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D51717/Support marking snapshots for write-conflict checking - Take 2
Summary:
D51183 was reverted due to breaking the LITE build.
This diff is the same as D51183 but with a fix for the LITE BUILD(D51693)
Test Plan: run all unit tests
Reviewers: sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D51711/Revert ""Fix a race condition in persisting options""
This reverts commit 2fa3ed5180340e485a1caf6fa71cc400ea599278. It breaks RocksDB lite build/Fix a race condition in persisting options
Summary:
This patch fix a race condition in persisting options which will cause a crash when:
* Thread A obtain cf options and start to persist options based on that cf options.
* Thread B kicks in and finish DropColumnFamily and delete cf_handle.
* Thread A wakes up and tries to finish the persisting options and crashes.
Test Plan: Add a test in column_family_test that can reproduce the crash
Reviewers: anthony, IslamAbdelRahman, rven, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D51609/added public api to schedule flush/compaction, code to prevent race with db::open
Summary:
Fixes T8781168.
Added a new function EnableAutoCompactions in db.h to be publicly
avialable.  This allows compaction to be re-enabled after disabling it via
SetOptions
Refactored code to set the dbptr earlier on in TransactionDB::Open and DB::Open
Temporarily disable auto_compaction in TransactionDB::Open until dbptr is set to
prevent race condition.
Test Plan:
Ran make all check
verified fix on myrocks side:
was able to reproduce the seg fault with
../tools/mysqltest.sh --mem --force rocksdb.drop_table
method was to manually sleep the thread after DB::Open but before TransactionDB ptr was
assigned in transaction_db_impl.cc:
DB::Open(db_options, dbname, column_families_copy, handles, &db);
clock_t goal = (60000 * 10) + clock();
while (goal > clock());
...dbptr(aka rdb) gets assigned below
verified my changes fixed the issue.
Also added unit test 'ToggleAutoCompaction' in transaction_test.cc
Reviewers: hermanlee4, anthony
Reviewed By: anthony
Subscribers: alex, dhruba
Differential Revision: https://reviews.facebook.net/D51147/DB to only flush the column family with the largest memtable while option.db_write_buffer_size is hit
Summary: When option.db_write_buffer_size is hit, we currently flush all column families. Move to flush the column family with the largest active memt table instead. In this way, we can avoid too many small files in some cases.
Test Plan: Modify test DBTest.SharedWriteBuffer to work with the updated behavior
Reviewers: kradhakrishnan, yhchiang, rven, anthony, IslamAbdelRahman, igor
Reviewed By: igor
Subscribers: march, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D51291/"
rocksdb,"Fix for --allow_concurrent_memtable_write with batching
Summary:
Concurrent memtable adds were incorrectly computing
the last sequence number for a write batch group when the
write batches were not solitary.  This is the cause of
https://github.com/facebook/mysql-5.6/issues/155
Test Plan:
1. unit tests
2. new unit test
3. parallel db_bench stress tests with batch size of 10 and asserts enabled
Reviewers: igor, sdong
Reviewed By: sdong
Subscribers: IslamAbdelRahman, MarkCallaghan, dhruba
Differential Revision: https://reviews.facebook.net/D53595/Parameterize DBTest.Randomized
Summary: Break down DBTest.Randomized to multiple gtest tests based on config type
Test Plan: Run the test and all tests. Make sure configurations are correctly set
Reviewers: yhchiang, IslamAbdelRahman, rven, kradhakrishnan, andrewkr, anthony
Reviewed By: anthony
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D53247/Build break fix.
Summary: Skip list now cannot estimate memory across allocators
consistently and hence triggers flush at different time. This breaks certain
unit tests.
The fix is to adopt key count instead of size for flush.
Test Plan: Ran test on dev box and mac (where it used to fail)
Reviewers: sdong
CC: leveldb@
Task ID: #9273334
Blame Rev:/Fix DBTest.SuggestCompactRangeTest for disable jemalloc case
Summary: DBTest.SuggestCompactRangeTest fails for the case when jemalloc is disabled, including ASAN and valgrind builds. It is caused by the improvement of skip list, which allocates different size of nodes for a new records. Fix it by using a special mem table that triggers a flush by number of entries. In that way the behavior will be consistent for all allocators.
Test Plan: Run the test with both of DISABLE_JEMALLOC=1 and 0
Reviewers: anthony, rven, yhchiang, kradhakrishnan, igor, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D51423/Fix uninitilizeded SpecialEnv::time_elapse_only_sleep_
Summary: SpecialEnv::time_elapse_only_sleep_ is not initialized, which might cause some test failures. Fix it.
Test Plan: Run some unit tests. Since tests already broken. Might want to commit it sooner.
Reviewers: IslamAbdelRahman, yhchiang, anthony
Reviewed By: anthony
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D50937/"
rocksdb,"Merge pull request #915 from warrenfalk/capi_full_bloom
Fix for #909: Support creation of ""full"" format bloom filter from C API/"
rocksdb,"Not scheduling more L1->L2 compaction if L0->L1 is pending with higher priority
Summary: When L0->L1 is pending, there may be one L1->L2 compaction going on which prevents the L0->L1 compaction from happening. If L1 needs more data to be moved to L2, then we may continue scheduling more L1->L2 compactions. The end result may be that L0->L1 compaction will not happen until L1 size drops to below target size. We can reduce the stalling because of number of L0 files by stopping schedling new L1->L2 compaction when L0's score is higher than L1.
Test Plan: Run all existing tests.
Reviewers: yhchiang, MarkCallaghan, rven, anthony, IslamAbdelRahman, igor
Reviewed By: igor
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D52401/Merge pull request #890 from zhipeng-jia/develop
fix typo: sr to picking_sr/fix typo: sr to picking_sr/Fix minor bugs in delete operator, snprintf, and size_t usage
Summary:
List of changes:
1) Fix the snprintf() usage in cases where wrong variable was used to determine the output buffer size.
2) Remove unnecessary checks before calling delete operator.
3) Increase code correctness by using size_t type when getting vector's size.
4) Unify the coding style by removing namespace::std usage at the top of the file to confirm to the majority usage.
5) Fix various lint errors pointed out by 'arc lint'.
Test Plan:
Code review and build:
git diff
make clean
make -j 32 commit-prereq
arc lint
Reviewers: kradhakrishnan, sdong, rven, anthony, yhchiang, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D51849/Running manual compactions in parallel with other automatic or manual compactions in restricted cases
Summary:
This diff provides a framework for doing manual
compactions in parallel with other compactions. We now have a deque of manual compactions. We also pass manual compactions as an argument from RunManualCompactions down to
BackgroundCompactions, so that RunManualCompactions can be reentrant.
Parallelism is controlled by the two routines
ConflictingManualCompaction to allow/disallow new parallel/manual
compactions based on already existing ManualCompactions. In this diff, by default manual compactions still have to run exclusive of other compactions. However, by setting the compaction option, exclusive_manual_compaction to false, it is possible to run other compactions in parallel with a manual compaction. However, we are still restricted to one manual compaction per column family at a time. All of these restrictions will be relaxed in future diffs.
I will be adding more tests later.
Test Plan: Rocksdb regression + new tests + valgrind
Reviewers: igor, anthony, IslamAbdelRahman, kradhakrishnan, yhchiang, sdong
Reviewed By: sdong
Subscribers: yoshinorim, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D47973/UniversalCompactionPicker::PickCompaction(): avoid to form compactions if there is no file
Summary:
Currently RocksDB may break in lines like this:
for (size_t i = sorted_runs.size() - 1; i >= first_index_after; i--) {
if options.level0_file_num_compaction_trigger=0.
Fix it by not executing the logic of picking compactions if there is no file (sorted_runs.size() = 0). Also internally set options.level0_file_num_compaction_trigger=1 if users give a 0. 0 is a value makes no sense in RocksDB.
Test Plan: Run all tests. Will add a unit test too.
Reviewers: yhchiang, IslamAbdelRahman, anthony, kradhakrishnan, rven
Reviewed By: rven
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D50727/"
rocksdb,"Eliminate duplicated property constants
Summary:
Before this diff, there were duplicated constants to refer to properties (user-
facing API had strings and InternalStats had an enum). I noticed these were
inconsistent in terms of which constants are provided, names of constants, and
documentation of constants. Overall it seemed annoying/error-prone to maintain
these duplicated constants.
So, this diff gets rid of InternalStats's constants and replaces them with a map
keyed on the user-facing constant. The value in that map contains a function
pointer to get the property value, so we don't need to do string matching while
holding db->mutex_. This approach has a side benefit of making many small
handler functions rather than a giant switch-statement.
Test Plan: db_properties_test passes, running ""make commit-prereq -j32""
Reviewers: sdong, yhchiang, kradhakrishnan, IslamAbdelRahman, rven, anthony
Reviewed By: anthony
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D53253/support for concurrent adds to memtable
Summary:
This diff adds support for concurrent adds to the skiplist memtable
implementations.  Memory allocation is made thread-safe by the addition of
a spinlock, with small per-core buffers to avoid contention.  Concurrent
memtable writes are made via an additional method and don't impose a
performance overhead on the non-concurrent case, so parallelism can be
selected on a per-batch basis.
Write thread synchronization is an increasing bottleneck for higher levels
of concurrency, so this diff adds --enable_write_thread_adaptive_yield
(default off).  This feature causes threads joining a write batch
group to spin for a short time (default 100 usec) using sched_yield,
rather than going to sleep on a mutex.  If the timing of the yield calls
indicates that another thread has actually run during the yield then
spinning is avoided.  This option improves performance for concurrent
situations even without parallel adds, although it has the potential to
increase CPU usage (and the heuristic adaptation is not yet mature).
Parallel writes are not currently compatible with
inplace updates, update callbacks, or delete filtering.
Enable it with --allow_concurrent_memtable_write (and
--enable_write_thread_adaptive_yield).  Parallel memtable writes
are performance neutral when there is no actual parallelism, and in
my experiments (SSD server-class Linux and varying contention and key
sizes for fillrandom) they are always a performance win when there is
more than one thread.
Statistics are updated earlier in the write path, dropping the number
of DB mutex acquisitions from 2 to 1 for almost all cases.
This diff was motivated and inspired by Yahoo's cLSM work.  It is more
conservative than cLSM: RocksDB's write batch group leader role is
preserved (along with all of the existing flush and write throttling
logic) and concurrent writers are blocked until all memtable insertions
have completed and the sequence number has been advanced, to preserve
linearizability.
My test config is ""db_bench -benchmarks=fillrandom -threads=$T
-batch_size=1 -memtablerep=skip_list -value_size=100 --num=1000000/$T
-level0_slowdown_writes_trigger=9999 -level0_stop_writes_trigger=9999
-disable_auto_compactions --max_write_buffer_number=8
-max_background_flushes=8 --disable_wal --write_buffer_size=160000000
--block_size=16384 --allow_concurrent_memtable_write"" on a two-socket
Xeon E5-2660 @ 2.2Ghz with lots of memory and an SSD hard drive.  With 1
thread I get ~440Kops/sec.  Peak performance for 1 socket (numactl
-N1) is slightly more than 1Mops/sec, at 16 threads.  Peak performance
across both sockets happens at 30 threads, and is ~900Kops/sec, although
with fewer threads there is less performance loss when the system has
background work.
Test Plan:
1. concurrent stress tests for InlineSkipList and DynamicBloom
2. make clean; make check
3. make clean; DISABLE_JEMALLOC=1 make valgrind_check; valgrind db_bench
4. make clean; COMPILE_WITH_TSAN=1 make all check; db_bench
5. make clean; COMPILE_WITH_ASAN=1 make all check; db_bench
6. make clean; OPT=-DROCKSDB_LITE make check
7. verify no perf regressions when disabled
Reviewers: igor, sdong
Reviewed By: sdong
Subscribers: MarkCallaghan, IslamAbdelRahman, anthony, yhchiang, rven, sdong, guyg8, kradhakrishnan, dhruba
Differential Revision: https://reviews.facebook.net/D50589/Slowdown when writing to the last write buffer
Summary: Now if inserting to mem table is much faster than writing to files, there is no mechanism users can rely on to avoid stopping for reaching options.max_write_buffer_number. With the commit, if there are more than four maximum write buffers configured, we slow down to the rate of options.delayed_write_rate while we reach the last one.
Test Plan:
1. Add a new unit test.
2. Run db_bench with
./db_bench --benchmarks=fillrandom --num=10000000 --max_background_flushes=6 --batch_size=32 -max_write_buffer_number=4 --delayed_write_rate=500000 --statistics
based on hard drive and see stopping is avoided with the commit.
Reviewers: yhchiang, IslamAbdelRahman, anthony, rven, kradhakrishnan, igor
Reviewed By: igor
Subscribers: MarkCallaghan, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D52047/Fix rebase issues and new code warnings./"
rocksdb,compaction assertion triggering test fix for sequence zeroing assertion trip/
rocksdb,"Fix LITE db_test build broken by previous commit
Summary: Previous commit introduces a test that is not supported in LITE. Fix it.
Test Plan: Build the test with ROCKSDB_LITE.
Reviewers: kradhakrishnan, IslamAbdelRahman, anthony, yhchiang, andrewkr
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D53901/Explictly fail when memtable doesn't support concurrent insert
Summary: If users turn on concurrent insert but the memtable doesn't support it, they might see unexcepted crash. Fix it by explicitly fail.
Test Plan:
Run different setting of stress_test and make sure it fails correctly.
Will add a unit test too.
Reviewers: anthony, kradhakrishnan, IslamAbdelRahman, yhchiang, andrewkr, ngbronson
Reviewed By: ngbronson
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D53895/Improve perf of Pessimistic Transaction expirations (and optimistic transactions)
Summary:
copy from task 8196669:
1) Optimistic transactions do not support batching writes from different threads.
2) Pessimistic transactions do not support batching writes if an expiration time is set.
In these 2 cases, we currently do not do any write batching in DBImpl::WriteImpl() because there is a WriteCallback that could decide at the last minute to abort the write.  But we could support batching write operations with callbacks if we make sure to process the callbacks correctly.
To do this, we would first need to modify write_thread.cc to stop preventing writes with callbacks from being batched together.  Then we would need to change DBImpl::WriteImpl() to call all WriteCallback's in a batch, only write the batches that succeed, and correctly set the state of each batch's WriteThread::Writer.
Test Plan: Added test WriteWithCallbackTest to write_callback_test.cc which creates multiple client threads and verifies that writes are batched and executed properly.
Reviewers: hermanlee4, anthony, ngbronson
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D52863/Disable stats about mutex duration by default
Summary: Measuring mutex duration will measure time inside DB mutex, which breaks our best practice. Add a stat level in Statistics class. By default, disable to measure the mutex operations.
Test Plan: Add a unit test to make sure it is off by default.
Reviewers: rven, anthony, IslamAbdelRahman, kradhakrishnan, andrewkr, yhchiang
Reviewed By: yhchiang
Subscribers: MarkCallaghan, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D53367/Fix issue in Iterator::Seek when using Block based filter block with prefix_extractor
Summary: Similar to D53385 we need to check InDomain before checking the filter block.
Test Plan: unit tests
Reviewers: yhchiang, rven, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D53421/Fix RocksDB lite build
Summary:
NewMemEnv() is defined in rocksdb lite but just returns nullptr --
would it be better to just not define it so we can catch issues like this at
compile-time?
Test Plan:
$ make clean && OPT=""-DTRAVIS -DROCKSDB_LITE"" V=1 make -j32 db_test
$ ./db_test --gtest_filter='DBTest.MemEnvTest'
...
[  PASSED  ] 0 tests.
Reviewers: yhchiang, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D53427/Fix bug in block based tables with full filter block and prefix_extractor
Summary:
Right now when we are creating a BlockBasedTable with fill filter block
we add to the filter all the prefixes that are InDomain() based on the prefix_extractor
the problem is that when we read a key from the file, we check the filter block for the prefix whether or not it's InDomain()
Test Plan: unit tests
Reviewers: yhchiang, rven, anthony, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D53385/Parameterize DBTest.Randomized
Summary: Break down DBTest.Randomized to multiple gtest tests based on config type
Test Plan: Run the test and all tests. Make sure configurations are correctly set
Reviewers: yhchiang, IslamAbdelRahman, rven, kradhakrishnan, andrewkr, anthony
Reviewed By: anthony
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D53247/Disallow SstFileWriter from creating empty sst files
Summary:
SstFileWriter may create an sst file with no entries
Right now this will fail when being ingested using DB::AddFile() saying that the keys are corrupted
Test Plan: make check
Reviewers: yhchiang, rven, anthony, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D52815/improve test for manifest write failure
Summary: Improve testing per discussion in D52989
Test Plan: ran test
Reviewers: sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D53211/Changes for build on solaris
Makefile adjust paths for solaris build
Makefile enable _GLIBCXX_USE_C99 so that std::to_string is available
db_compaction_test.cc Initialise a variable to avoid a compilation error
db_impl.cc Include <alloca.h>
db_test.cc Include <alloca.h>
Environment.java recognise solaris envrionment
options_bulder.cc Make log unambiguous
geodb_impl.cc Make log and floor unambiguous/fix potential test SleepingTask race condition
Summary: Make sure SleepingTask has bene run before it goes out of scope.
Test Plan: run test
Reviewers: kradhakrishnan
Reviewed By: kradhakrishnan
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D52581/use -Werror=missing-field-initializers, to closer match MyRocks build
Summary:
myrocks seems to build rocksdb using
-Wmissing-field-initializers (and treats warnings as errors).  This diff
adds that flag to the rocksdb build, and fixes the compilation failures
that result.  I have not checked for any other differences in the build
flags for rocksdb build as part of myrocks.
Test Plan: make check
Reviewers: sdong, rven
Reviewed By: rven
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D52443/Disable Visual Studio Warning C4351
Currently Windows build is broken because of Warning C4351. Disable the warning before figuring out the right way to fix it./DBTest.HardLimit use special memtable
Summary: DBTest.HardLimit fails in appveyor build. Use special mem table to make the test behavior depends less on platform
Test Plan: Run the test with JEMALLOC both on and off.
Reviewers: yhchiang, kradhakrishnan, rven, anthony, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D52317/DBTest.DelayedWriteRate: fix assert of sign and unsign comparison
Summary: DBTest.DelayedWriteRate has sign and unsign comparisons that break Windows build. Fix it.
Test Plan: Build and run the test modified.
Reviewers: IslamAbdelRahman, rven, anthony, yhchiang, kradhakrishnan
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D52311/When slowdown is triggered, reduce the write rate
Summary: It's usually hard for users to set a value of options.delayed_write_rate. With this diff, after slowdown condition triggers, we greedily reduce write rate if estimated pending compaction bytes increase. If estimated compaction pending bytes drop, we increase the write rate.
Test Plan:
Add a unit test
Test with db_bench setting:
TEST_TMPDIR=/dev/shm/ ./db_bench --benchmarks=fillrandom -num=10000000 --soft_pending_compaction_bytes_limit=1000000000 --hard_pending_compaction_bytes_limit=3000000000 --delayed_write_rate=100000000
and make sure without the commit, write stop will happen, but with the commit, it will not happen.
Reviewers: igor, anthony, rven, yhchiang, kradhakrishnan, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D52131/Fix clang build
Summary:
Missed this in https://reviews.facebook.net/D51633 because I didn't
wait for 'make commit-prereq' to finish
Test Plan: make clean && USE_CLANG=1 make -j32 all
Reviewers: IslamAbdelRahman, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D52275/Merge pull request #898 from zhipeng-jia/fix_move_warning
Fix clang warning/Fix clang warning/Slowdown when writing to the last write buffer
Summary: Now if inserting to mem table is much faster than writing to files, there is no mechanism users can rely on to avoid stopping for reaching options.max_write_buffer_number. With the commit, if there are more than four maximum write buffers configured, we slow down to the rate of options.delayed_write_rate while we reach the last one.
Test Plan:
1. Add a new unit test.
2. Run db_bench with
./db_bench --benchmarks=fillrandom --num=10000000 --max_background_flushes=6 --batch_size=32 -max_write_buffer_number=4 --delayed_write_rate=500000 --statistics
based on hard drive and see stopping is avoided with the commit.
Reviewers: yhchiang, IslamAbdelRahman, anthony, rven, kradhakrishnan, igor
Reviewed By: igor
Subscribers: MarkCallaghan, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D52047/Fix minor bugs in delete operator, snprintf, and size_t usage
Summary:
List of changes:
1) Fix the snprintf() usage in cases where wrong variable was used to determine the output buffer size.
2) Remove unnecessary checks before calling delete operator.
3) Increase code correctness by using size_t type when getting vector's size.
4) Unify the coding style by removing namespace::std usage at the top of the file to confirm to the majority usage.
5) Fix various lint errors pointed out by 'arc lint'.
Test Plan:
Code review and build:
git diff
make clean
make -j 32 commit-prereq
arc lint
Reviewers: kradhakrishnan, sdong, rven, anthony, yhchiang, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D51849/Running manual compactions in parallel with other automatic or manual compactions in restricted cases
Summary:
This diff provides a framework for doing manual
compactions in parallel with other compactions. We now have a deque of manual compactions. We also pass manual compactions as an argument from RunManualCompactions down to
BackgroundCompactions, so that RunManualCompactions can be reentrant.
Parallelism is controlled by the two routines
ConflictingManualCompaction to allow/disallow new parallel/manual
compactions based on already existing ManualCompactions. In this diff, by default manual compactions still have to run exclusive of other compactions. However, by setting the compaction option, exclusive_manual_compaction to false, it is possible to run other compactions in parallel with a manual compaction. However, we are still restricted to one manual compaction per column family at a time. All of these restrictions will be relaxed in future diffs.
I will be adding more tests later.
Test Plan: Rocksdb regression + new tests + valgrind
Reviewers: igor, anthony, IslamAbdelRahman, kradhakrishnan, yhchiang, sdong
Reviewed By: sdong
Subscribers: yoshinorim, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D47973/Fix rebase issues and new code warnings./Merge pull request #879 from charsyam/feature/typos
fix typos in comments/fix typos in comments/Fix occasional failure of DBTest.DynamicCompactionOptions
Summary: DBTest.DynamicCompactionOptions ocasionally fails during valgrind run. We sent a sleeping task to block compaction thread pool but we don't wait it to run.
Test Plan: Run the test multiple times in an environment which can cause failure.
Reviewers: rven, kradhakrishnan, igor, IslamAbdelRahman, anthony, yhchiang
Reviewed By: yhchiang
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D51687/added public api to schedule flush/compaction, code to prevent race with db::open
Summary:
Fixes T8781168.
Added a new function EnableAutoCompactions in db.h to be publicly
avialable.  This allows compaction to be re-enabled after disabling it via
SetOptions
Refactored code to set the dbptr earlier on in TransactionDB::Open and DB::Open
Temporarily disable auto_compaction in TransactionDB::Open until dbptr is set to
prevent race condition.
Test Plan:
Ran make all check
verified fix on myrocks side:
was able to reproduce the seg fault with
../tools/mysqltest.sh --mem --force rocksdb.drop_table
method was to manually sleep the thread after DB::Open but before TransactionDB ptr was
assigned in transaction_db_impl.cc:
DB::Open(db_options, dbname, column_families_copy, handles, &db);
clock_t goal = (60000 * 10) + clock();
while (goal > clock());
...dbptr(aka rdb) gets assigned below
verified my changes fixed the issue.
Also added unit test 'ToggleAutoCompaction' in transaction_test.cc
Reviewers: hermanlee4, anthony
Reviewed By: anthony
Subscribers: alex, dhruba
Differential Revision: https://reviews.facebook.net/D51147/DBTest.DynamicCompactionOptions: More deterministic and readable
Summary: DBTest.DynamicCompactionOptions sometimes fails the assert but I can't repro it locally. Make it more deterministic and readable and see whether the problem is still there.
Test Plan: Run tht test and make sure it passes
Reviewers: kradhakrishnan, yhchiang, igor, rven, IslamAbdelRahman, anthony
Reviewed By: anthony
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D51309/Fix DBTest.SuggestCompactRangeTest for disable jemalloc case
Summary: DBTest.SuggestCompactRangeTest fails for the case when jemalloc is disabled, including ASAN and valgrind builds. It is caused by the improvement of skip list, which allocates different size of nodes for a new records. Fix it by using a special mem table that triggers a flush by number of entries. In that way the behavior will be consistent for all allocators.
Test Plan: Run the test with both of DISABLE_JEMALLOC=1 and 0
Reviewers: anthony, rven, yhchiang, kradhakrishnan, igor, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D51423/DB to only flush the column family with the largest memtable while option.db_write_buffer_size is hit
Summary: When option.db_write_buffer_size is hit, we currently flush all column families. Move to flush the column family with the largest active memt table instead. In this way, we can avoid too many small files in some cases.
Test Plan: Modify test DBTest.SharedWriteBuffer to work with the updated behavior
Reviewers: kradhakrishnan, yhchiang, rven, anthony, IslamAbdelRahman, igor
Reviewed By: igor
Subscribers: march, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D51291/Reduce extra key comparision in DBIter::Next()
Summary: Now DBIter::Next() always compares with current key with itself first, which is unnecessary if the last key is not a merge key. I made the change and didn't see db_iter_test fails. Want to hear whether people have any idea what I miss.
Test Plan: Run all unit tests
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D48279/Fix race condition that causes valgrind failures
Summary: DBTest.DynamicLevelCompressionPerLevel2 sometimes fails during valgrind runs.  This causes our valgrind tests to fail.  Not sure what the best fix is for this test, but hopefully this simple change is sufficient.
Test Plan: run test
Reviewers: sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D51111/DBTest.MergeTestTime: relax counter upper bound verification
Summary: Timing counters' upper bounds depend on platform. It frequently fails in valgrind runs. Relax the upper bound.
Test Plan: Run the same valgrind test and make sure it passes.
Reviewers: rven, anthony, kradhakrishnan, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D50829/"
rocksdb,"Lint everything
Summary:
```
arc2 lint --everything
```
run the linter on the whole code repo to fix exisitng lint issues
Test Plan: make check -j64
Reviewers: sdong, rven, anthony, kradhakrishnan, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D50769/"
rocksdb,"Skip filters for last L0 file if hit-optimized
Summary:
Following up on D53493, we can still enable the filter-skipping
optimization for last file in L0. It's correct to assume the key will be present
in the last L0 file when we're hit-optimized and L0 is deepest.
The FilePicker encapsulates the state for traversing each level's files, so I
needed to make it expose whether the returned file is last in its level.
Test Plan:
verified below test fails before this patch and passes afterwards.
The change to how the test memtable is populated is needed so file 1 has keys
(0, 30, 60), file 2 has keys (10, 40, 70), etc.
$ ./db_universal_compaction_test --gtest_filter=UniversalCompactionNumLevels/DBTestUniversalCompaction.OptimizeFiltersForHits/*
Reviewers: sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D53583/Should not skip bloom filter for L0 during the query.
Summary: It's a regression bug caused by e089db40f9c8f2a8af466377ed0f6fd8a3c26456. With the change, if options.optimize_filters_for_hits=true and there are only L0 files (like single level universal compaction), we skip all the files in L0, which is more than necessary. Fix it by always trying to query bloom filter for files in level 0.
Test Plan: Add a unit test for it.
Reviewers: anthony, rven, yhchiang, IslamAbdelRahman, kradhakrishnan, andrewkr
Reviewed By: andrewkr
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D53493/Fix intermittent hang in ColumnFamilyTest.FlushAndDropRaceCondition
Summary:
ColumnFamilyTest.FlushAndDropRaceCondition sometimes
hangs because the sync point, ""FlushJob::InstallResults"", sleeps
holding the DB mutex. Fixing it by releasing the mutex before sleeping.
Test Plan:
seq 1000 |parallel --gnu --eta 't=/dev/shm/rdb-{}; rm -rf $t;
mkdir $t && export TEST_TMPDIR=$t; ./column_family_test
-gtest_filter=*FlushAndDropRaceCondition* > $t/log-{}'
Reviewers: IslamAbdelRahman, anthony, kradhakrishnan, yhchiang, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D53349/Revert D7809
Summary: Revert the functionaility of D7809 (but I'm keeping the logging and test code).  We decided it was dangerous to ignore sync failures based on attempting to read the data written.  The read does not tell us whether the data was synced.
Test Plan: There was no test for the particular functionaility that was reverted.  Keeping the test code from D7809 that tests whether we set the DB to be readonly when paranoid checks are enabled.
Reviewers: rven, yhchiang, kradhakrishnan, IslamAbdelRahman, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D52989/[easy] Fixed a crash in LogAndApply() when CF creation failed
Summary: That line used to dereference `column_family_data`, which is nullptr if we're creating a column family.
Test Plan: `make -j check`
Reviewers: sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D52881/When slowdown is triggered, reduce the write rate
Summary: It's usually hard for users to set a value of options.delayed_write_rate. With this diff, after slowdown condition triggers, we greedily reduce write rate if estimated pending compaction bytes increase. If estimated compaction pending bytes drop, we increase the write rate.
Test Plan:
Add a unit test
Test with db_bench setting:
TEST_TMPDIR=/dev/shm/ ./db_bench --benchmarks=fillrandom -num=10000000 --soft_pending_compaction_bytes_limit=1000000000 --hard_pending_compaction_bytes_limit=3000000000 --delayed_write_rate=100000000
and make sure without the commit, write stop will happen, but with the commit, it will not happen.
Reviewers: igor, anthony, rven, yhchiang, kradhakrishnan, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D52131/Fix minor bugs in delete operator, snprintf, and size_t usage
Summary:
List of changes:
1) Fix the snprintf() usage in cases where wrong variable was used to determine the output buffer size.
2) Remove unnecessary checks before calling delete operator.
3) Increase code correctness by using size_t type when getting vector's size.
4) Unify the coding style by removing namespace::std usage at the top of the file to confirm to the majority usage.
5) Fix various lint errors pointed out by 'arc lint'.
Test Plan:
Code review and build:
git diff
make clean
make -j 32 commit-prereq
arc lint
Reviewers: kradhakrishnan, sdong, rven, anthony, yhchiang, igor
Reviewed By: igor
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D51849/Fix another rebase problems./Fix rebase issues and new code warnings./Use SST files for Transaction conflict detection
Summary:
Currently, transactions can fail even if there is no actual write conflict.  This is due to relying on only the memtables to check for write-conflicts.  Users have to tune memtable settings to try to avoid this, but it's hard to figure out exactly how to tune these settings.
With this diff, TransactionDB will use both memtables and SST files to determine if there are any write conflicts.  This relies on the fact that BlockBasedTable stores sequence numbers for all writes that happen after any open snapshot.  Also, D50295 is needed to prevent SingleDelete from disappearing writes (the TODOs in this test code will be fixed once the other diff is approved and merged).
Note that Optimistic transactions will still rely on tuning memtable settings as we do not want to read from SST while on the write thread.  Also, memtable settings can still be used to reduce how often TransactionDB needs to read SST files.
Test Plan: unit tests, db bench
Reviewers: rven, yhchiang, kradhakrishnan, IslamAbdelRahman, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb, yoshinorim
Differential Revision: https://reviews.facebook.net/D50475/Merge pull request #815 from SherlockNoMad/CounterFix
Fix EstimateNumKeys Counter Inaccurate Issue/"
rocksdb,"Making use of GetSystemTimePreciseAsFileTime dynamic - code review fixes/Making use of GetSystemTimePreciseAsFileTime dynamic to not
break compatibility with Windows 7. The issue with rotated logs
was fixed other way./Running manual compactions in parallel with other automatic or manual compactions in restricted cases
Summary:
This diff provides a framework for doing manual
compactions in parallel with other compactions. We now have a deque of manual compactions. We also pass manual compactions as an argument from RunManualCompactions down to
BackgroundCompactions, so that RunManualCompactions can be reentrant.
Parallelism is controlled by the two routines
ConflictingManualCompaction to allow/disallow new parallel/manual
compactions based on already existing ManualCompactions. In this diff, by default manual compactions still have to run exclusive of other compactions. However, by setting the compaction option, exclusive_manual_compaction to false, it is possible to run other compactions in parallel with a manual compaction. However, we are still restricted to one manual compaction per column family at a time. All of these restrictions will be relaxed in future diffs.
I will be adding more tests later.
Test Plan: Rocksdb regression + new tests + valgrind
Reviewers: igor, anthony, IslamAbdelRahman, kradhakrishnan, yhchiang, sdong
Reviewed By: sdong
Subscribers: yoshinorim, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D47973/Lint everything
Summary:
```
arc2 lint --everything
```
run the linter on the whole code repo to fix exisitng lint issues
Test Plan: make check -j64
Reviewers: sdong, rven, anthony, kradhakrishnan, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D50769/"
rocksdb,"Fix clang build
Summary: fix clang build
Test Plan: USE_CLANG make all -j64
Reviewers: horuff, sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57453/Stderr info logger
Summary:
Adapted a stderr logger from the option tests. Moved it to a separate
header so we can reuse it, e.g., from ldb subcommands for faster debugging. This
is especially useful to make errors/warnings more visible when running
""ldb repair"", which involves potential data loss.
Test Plan:
ran options_test and ""ldb repair""
$ ./ldb repair --db=./tmp/
[WARN] **** Repaired rocksdb ./tmp/; recovered 1 files; 588bytes. Some data may have been lost. ****
OK
Reviewers: IslamAbdelRahman, yhchiang, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D56151/formatting fix/"
rocksdb,"Fix crash_test
Summary:
crash_test grep for 'fail' string in the output and if found it consider that we failed.
Update the output to use something else
Test Plan: make crash_test (still running)
Reviewers: yhchiang, sdong, andrewkr
Reviewed By: andrewkr
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57381/Temporarily disable CompactFiles in db_stress in its default setting
Summary:
As db_stress with CompactFiles possibly catches a previous bug currently,
temporarily disable CompactFiles in db_stress in its default setting
to allows new bug to be detected while investigating the bug in CompactFiles.
Test Plan: crash test
Reviewers: sdong, kradhakrishnan, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D57333/Fix RocksDB Lite build in db_stress
Summary: Fix RocksDB Lite build in db_stress
Test Plan: OPT=-DROCKSDB_LITE db_stress
Reviewers: IslamAbdelRahman, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D57045/Enable testing CompactFiles in db_stress
Summary:
Enable testing CompactFiles in db_stress by adding flag test_compact_files
to db_stress.
Test Plan:
./db_stress --test_compact_files=1 --compaction_style=0 --allow_concurrent_memtable_write=false --ops_per_thread=100000
./db_stress --test_compact_files=1 --compaction_style=1 --allow_concurrent_memtable_write=false --ops_per_thread=100000
Sample output (note that it's normal to have some CompactFiles() failed):
Stress Test : 491.891 micros/op 65054 ops/sec
: Wrote 21.98 MB (0.45 MB/sec) (45% of 3200352 ops)
: Wrote 1440728 times
: Deleted 441616 times
: Single deleted 38181 times
: 319251 read and 19025 found the key
: Prefix scanned 640520 times
: Iterator size sum is 9691415
: Iterated 319704 times
: Got errors 0 times
: 1323 CompactFiles() succeed
: 32 CompactFiles() failed
2016/04/11-15:50:58  Verification successful
Reviewers: sdong, IslamAbdelRahman, kradhakrishnan, yiwu, andrewkr
Reviewed By: andrewkr
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D56565/[db_stress] Make subcompaction random in crash_test
Summary: Make subcompaction random in crash_test
Test Plan: make crash_test and verify whether subcompaction changes randomly
Reviewers: IslamAbdelRahman, kradhakrishnan, yiwu, sdong, andrewkr
Reviewed By: andrewkr
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D56571/"
rocksdb,"Improve sst_dump help message
Summary:
Current Message
```
sst_dump [--command=check|scan|none|raw] [--verify_checksum] --file=data_dir_OR_sst_file [--output_hex] [--input_key_hex] [--from=<user_key>] [--to=<user_key>] [--read_num=NUM] [--show_properties] [--show_compression_sizes] [--show_compression_sizes [--set_block_size=<block_size>]]
```
New message
```
sst_dump --file=<data_dir_OR_sst_file> [--command=check|scan|raw]
--file=<data_dir_OR_sst_file>
Path to SST file or directory containing SST files
--command=check|scan|raw
check: Iterate over entries in files but dont print anything except if an error is encounterd (default command)
scan: Iterate over entries in files and print them to screen
raw: Dump all the table contents to <file_name>_dump.txt
--output_hex
Can be combined with scan command to print the keys and values in Hex
--from=<user_key>
Key to start reading from when executing check|scan
--to=<user_key>
Key to stop reading at when executing check|scan
--read_num=<num>
Maximum number of entries to read when executing check|scan
--verify_checksum
Verify file checksum when executing check|scan
--input_key_hex
Can be combined with --from and --to to indicate that these values are encoded in Hex
--show_properties
Print table properties after iterating over the file
--show_compression_sizes
Independent command that will recreate the SST file using 16K block size with different
compressions and report the size of the file using such compression
--set_block_size=<block_size>
Can be combined with --show_compression_sizes to set the block size that will be used
when trying different compression algorithms
```
Test Plan: none
Reviewers: yhchiang, andrewkr, kradhakrishnan, yiwu, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D56325/Add support for UBsan builds to RocksDB
Summary:
Undefined Behavior Sanitizer (ubsan) is //a good thing// which will help us to find sneaky bugs with low cost. Please see http://developerblog.redhat.com/2014/10/16/gcc-undefined-behavior-sanitizer-ubsan/ for more details and official GCC documentation for more context: https://gcc.gnu.org/onlinedocs/gcc/Instrumentation-Options.html.
Changes itself are quite simple and pretty much imitating whatever is implemented for ASan.
Hooking the UBsan validation build to Sandcastle is a separate step and will be dealt as separate diff because code is in internal repository.
Test Plan: Make sure that that there no regressions when it comes to builds and test pass rate.
Reviewers: leveldb, sdong, IslamAbdelRahman, yhchiang
Reviewed By: yhchiang
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D56049/"
rocksdb,"Use pure if-then check instead of assert in EraseColumnFamilyInfo
Summary:
Use pure if-then check instead of assert in EraseColumnFamilyInfo
when the specified column family does not found in the cf_info_map_.
So the second deletion will be no op instead of crash.
Test Plan: existing test.
Reviewers: sdong, anthony, kradhakrishnan, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D55023/"
rocksdb,Fix formatting identified by `arc lint`/
rocksdb,Fix formatting identified by `arc lint`/
rocksdb,Fix formatting identified by `arc lint`/
rocksdb,Fix formatting identified by `arc lint`/
rocksdb,"Adding pin_l0_filter_and_index_blocks_in_cache feature and related fixes.
Summary:
When a block based table file is opened, if prefetch_index_and_filter is true, it will prefetch the index and filter blocks, putting them into the block cache.
What this feature adds: when a L0 block based table file is opened, if pin_l0_filter_and_index_blocks_in_cache is true in the options (and prefetch_index_and_filter is true), then the filter and index blocks aren't released back to the block cache at the end of BlockBasedTableReader::Open(). Instead the table reader takes ownership of them, hence pinning them, ie. the LRU cache will never push them out. Meanwhile in the table reader, further accesses will not hit the block cache, thus avoiding lock contention.
Test Plan:
'export TEST_TMPDIR=/dev/shm/ && DISABLE_JEMALLOC=1 OPT=-g make all valgrind_check -j32' is OK.
I didn't run the Java tests, I don't have Java set up on my devserver.
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D56133/Revert ""Fix failing Java unit test.""
This reverts commit d7ae42b0f89fd25d8aaed28703059889d145596e.
This is reverted as auto buld failure. This commit itself doesn't have any problem. Reverting as it depends on the commit to revert./Fix failing Java unit test.
Test Plan: sent diff to sdong, passes :)
Reviewers: sdong
Reviewed By: sdong
Subscribers: leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D55749/"
rocksdb,Fix the javadoc and the formatting of the base-classes for objects with native references/
rocksdb,Fix formatting identified by `arc lint`/
rocksdb,Fix the javadoc and the formatting of the base-classes for objects with native references/
rocksdb,Fix formatting identified by `arc lint`/
rocksdb,Fix formatting identified by `arc lint`/
rocksdb,Fix formatting identified by `arc lint`/Fix the javadoc and the formatting of the base-classes for objects with native references/
rocksdb,Fix formatting identified by `arc lint`/
rocksdb,Fix formatting identified by `arc lint`/
rocksdb,Fix formatting identified by `arc lint`/
rocksdb,Fix formatting identified by `arc lint`/
rocksdb,Fix formatting identified by `arc lint`/
rocksdb,Fix formatting identified by `arc lint`/
rocksdb,Fix formatting identified by `arc lint`/
rocksdb,Fix formatting identified by `arc lint`/
rocksdb,"Isolate db env and backup Env in unit tests
Summary:
- Used ChrootEnv so the database and backup Envs are isolated in the filesystem.
- Removed DifferentEnvs test since now every test uses different Envs
Depends on D57543
Test Plan:
- ran backupable_db_test
- verified backupable_db_test now catches the bug when D57159 is backed out (this bug previously passed through the test cases, which motivated this change)
Reviewers: sdong, lightmark, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D57615/Fix BackupableDBTest
Summary: Fix BackupableDBTest.NoDoubleCopy and BackupableDBTest.DifferentEnvs by mocking the db files in db_env instead of backup_env_
Test Plan: make check -j64
Reviewers: sdong, andrewkr
Reviewed By: andrewkr
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57273/Fix backupable_db_test test cases that can't run by itself
Summary:
Several of backupable_db_test fails if running standalone, because of directory missing. Fix it by:
(1) garbage collector skips shared directory if it doesn't exit
(2) BackupableDBTest.Issue921Test to create the parent directory of the backup directory fist.
Test Plan: Run the tests individually and make sure they pass
Subscribers: leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D56829/[backupable db] Remove file size embedded in name workaround
Summary:
Now that we get sizes efficiently, we no longer need the workaround to
embed file size in filename.
Test Plan:
$ ./backupable_db_test
Reviewers: sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D55035/Handle concurrent manifest update and backup creation
Summary:
Fixed two related race conditions in backup creation.
(1) CreateNewBackup() uses DB::DisableFileDeletions() to prevent table files
from being deleted while it is copying; however, the MANIFEST file could still
rotate during this time. The fix is to stop deleting the old manifest in the
rotation logic. It will be deleted safely later when PurgeObsoleteFiles() runs
(can only happen when file deletions are enabled).
(2) CreateNewBackup() did not account for the CURRENT file being mutable.
This is significant because the files returned by GetLiveFiles() contain a
particular manifest filename, but the manifest to which CURRENT refers can
change at any time. This causes problems when CURRENT changes between the call
to GetLiveFiles() and when it's copied to the backup directory. To workaround this, I
manually forge a CURRENT file referring to the manifest filename returned in
GetLiveFiles().
(2) also applies to the checkpointing code, so let me know if this approach is
good and I'll make the same change there.
Test Plan:
new test for roll manifest during backup creation.
running the test before this change:
$ ./backupable_db_test --gtest_filter=BackupableDBTest.ChangeManifestDuringBackupCreation
...
IO error: /tmp/rocksdbtest-9383/backupable_db/MANIFEST-000001: No such file or directory
running the test after this change:
$ ./backupable_db_test --gtest_filter=BackupableDBTest.ChangeManifestDuringBackupCreation
...
[ RUN      ] BackupableDBTest.ChangeManifestDuringBackupCreation
[       OK ] BackupableDBTest.ChangeManifestDuringBackupCreation (2836 ms)
Reviewers: IslamAbdelRahman, anthony, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D54711/Reorder instance variables in backup test for proper destruction order
Summary:
As titled. This fixes the tsan error caused by logger_ being used in
backup_engine_'s destructor. It does not fix the transient unit test failure,
which is caused by MANIFEST file changing while backup is happening.
Test Plan:
verified the tsan error no longer happens on either success or
failure.
$ COMPILE_WITH_TSAN=1 make -j32 backupable_db_test
$ while ./backupable_db_test --gtest_filter=BackupableDBTest.CorruptionsTest ; do : ; done
Reviewers: sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D54669/"
rocksdb,"TransactionDB:ReinitializeTransaction
Summary: Add function to reinitialize a transaction object so that it can be reused.  This is an optimization so users can potentially avoid reallocating transaction objects.
Test Plan: added tests
Reviewers: yhchiang, kradhakrishnan, IslamAbdelRahman, sdong
Reviewed By: sdong
Subscribers: jkedgar, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D53835/"
rocksdb,"Cache to have an option to fail Cache::Insert() when full
Summary:
Cache to have an option to fail Cache::Insert() when full. Update call sites to check status and handle error.
I totally have no idea what's correct behavior of all the call sites when they encounter error. Please let me know if you see something wrong or more unit test is needed.
Test Plan: make check -j32, see tests pass.
Reviewers: anthony, yhchiang, andrewkr, IslamAbdelRahman, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D54705/"
rocksdb,"BlockBasedTable::Get() not to use prefix bloom if read_options.total_order_seek = true
Summary: This is to provide a way for users to skip prefix bloom in point look-up.
Test Plan: Add a new unit test scenario.
Reviewers: IslamAbdelRahman
Subscribers: leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57747/BlockBasedTable::PrefixMayMatch() to skip index checking if we can't find a filter block.
Summary:
In the case where we can't find a filter block, there is not much benefit of doing the binary search and see whether the index key has the prefix. With the change, we blindly return true if we can't get the filter.
It also fixes missing row cases for reverse comparator with full bloom.
Test Plan: Add a test case that used to fail.
Reviewers: yhchiang, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: kradhakrishnan, yiwu, hermanlee4, yoshinorim, leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D56697/BlockBasedTable::PrefixMayMatch: no need to find data block after full bloom checking
Summary:
Full block checking should be a good enough indication of prefix existance. No need to further check data block.
This also fixes wrong results when using prefix bloom and reverse bitwise comparator.
Test Plan: Will add a unit test.
Reviewers: yhchiang, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: hermanlee4, yoshinorim, yiwu, kradhakrishnan, leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D56625/Adding pin_l0_filter_and_index_blocks_in_cache feature and related fixes.
Summary:
When a block based table file is opened, if prefetch_index_and_filter is true, it will prefetch the index and filter blocks, putting them into the block cache.
What this feature adds: when a L0 block based table file is opened, if pin_l0_filter_and_index_blocks_in_cache is true in the options (and prefetch_index_and_filter is true), then the filter and index blocks aren't released back to the block cache at the end of BlockBasedTableReader::Open(). Instead the table reader takes ownership of them, hence pinning them, ie. the LRU cache will never push them out. Meanwhile in the table reader, further accesses will not hit the block cache, thus avoiding lock contention.
Test Plan:
'export TEST_TMPDIR=/dev/shm/ && DISABLE_JEMALLOC=1 OPT=-g make all valgrind_check -j32' is OK.
I didn't run the Java tests, I don't have Java set up on my devserver.
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D56133/Revert ""Adding pin_l0_filter_and_index_blocks_in_cache feature.""
This reverts commit 522de4f59e6314698286cf29d8a325a284d81778.
It has bug of index block cleaning up./Adding pin_l0_filter_and_index_blocks_in_cache feature.
Summary:
When a block based table file is opened, if prefetch_index_and_filter is true, it will prefetch the index and filter blocks, putting them into the block cache.
What this feature adds: when a L0 block based table file is opened, if pin_l0_filter_and_index_blocks_in_cache is true in the options (and prefetch_index_and_filter is true), then the filter and index blocks aren't released back to the block cache at the end of BlockBasedTableReader::Open(). Instead the table reader takes ownership of them, hence pinning them, ie. the LRU cache will never push them out. Meanwhile in the table reader, further accesses will not hit the block cache, thus avoiding lock contention.
When the table reader is destroyed, it releases the pinned blocks (if there were any). This has to happen before the cache is destroyed, so I had to introduce a TableReader::Close(), to guarantee the order of destruction.
Test Plan:
Added two unit tests for this. Existing unit tests run fine (default is pin_l0_filter_and_index_blocks_in_cache=false).
DISABLE_JEMALLOC=1 OPT=-g make all valgrind_check -j32
Mac: OK.
Linux: with D55287 patched in it's OK.
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D54801/Index Reader should not be reused after DB restart
Summary:
In block based table reader, wow we put index reader to block cache, which can be retrieved after DB restart. However, index reader may reference internal comparator, which can be destroyed after DB restarts, causing problems.
Fix it by making cache key identical per table reader.
Test Plan: Add a new test which failed with out the commit but now pass.
Reviewers: IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: maro, yhchiang, kradhakrishnan, leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D55287/Cache to have an option to fail Cache::Insert() when full
Summary:
Cache to have an option to fail Cache::Insert() when full. Update call sites to check status and handle error.
I totally have no idea what's correct behavior of all the call sites when they encounter error. Please let me know if you see something wrong or more unit test is needed.
Test Plan: make check -j32, see tests pass.
Reviewers: anthony, yhchiang, andrewkr, IslamAbdelRahman, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D54705/"
rocksdb,"PrefixTest.PrefixAndWholeKeyTest should run against a different directory from prefix_test
Summary: PrefixTest.PrefixAndWholeKeyTest runs against the same directory as prefix_test, which sometimes fail parallel tests. Fix it.
Test Plan: Run it in parallel and see it doesn't fail anymore.
Reviewers: andrewkr
Reviewed By: andrewkr
Subscribers: leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D56541/Adding pin_l0_filter_and_index_blocks_in_cache feature and related fixes.
Summary:
When a block based table file is opened, if prefetch_index_and_filter is true, it will prefetch the index and filter blocks, putting them into the block cache.
What this feature adds: when a L0 block based table file is opened, if pin_l0_filter_and_index_blocks_in_cache is true in the options (and prefetch_index_and_filter is true), then the filter and index blocks aren't released back to the block cache at the end of BlockBasedTableReader::Open(). Instead the table reader takes ownership of them, hence pinning them, ie. the LRU cache will never push them out. Meanwhile in the table reader, further accesses will not hit the block cache, thus avoiding lock contention.
Test Plan:
'export TEST_TMPDIR=/dev/shm/ && DISABLE_JEMALLOC=1 OPT=-g make all valgrind_check -j32' is OK.
I didn't run the Java tests, I don't have Java set up on my devserver.
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D56133/Revert ""Adding pin_l0_filter_and_index_blocks_in_cache feature.""
This reverts commit 522de4f59e6314698286cf29d8a325a284d81778.
It has bug of index block cleaning up./Adding pin_l0_filter_and_index_blocks_in_cache feature.
Summary:
When a block based table file is opened, if prefetch_index_and_filter is true, it will prefetch the index and filter blocks, putting them into the block cache.
What this feature adds: when a L0 block based table file is opened, if pin_l0_filter_and_index_blocks_in_cache is true in the options (and prefetch_index_and_filter is true), then the filter and index blocks aren't released back to the block cache at the end of BlockBasedTableReader::Open(). Instead the table reader takes ownership of them, hence pinning them, ie. the LRU cache will never push them out. Meanwhile in the table reader, further accesses will not hit the block cache, thus avoiding lock contention.
When the table reader is destroyed, it releases the pinned blocks (if there were any). This has to happen before the cache is destroyed, so I had to introduce a TableReader::Close(), to guarantee the order of destruction.
Test Plan:
Added two unit tests for this. Existing unit tests run fine (default is pin_l0_filter_and_index_blocks_in_cache=false).
DISABLE_JEMALLOC=1 OPT=-g make all valgrind_check -j32
Mac: OK.
Linux: with D55287 patched in it's OK.
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D54801/Revert ""Revert ""Fixed the bug when both whole_key_filtering and prefix_extractor are set.""""
Summary:
This reverts commit 73c31377bbcd300061245138dbaf782fedada9ba, which mistakenly
reverts 73c31377bbcd300061245138dbaf782fedada9ba that fixes a bug when both
whole_key_filtering and prefix_extractor are set
Test Plan: revert the patch
Reviewers: anthony, IslamAbdelRahman, rven, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D52707/"
rocksdb,"TransactionLogIterator sequence gap fix
Summary: DBTestXactLogIterator.TransactionLogIterator was failing due the sequence gaps. This was caused by an off-by-one error when calculating the new sequence number after recovering from logs.
Test Plan: db_log_iter_test
Reviewers: andrewkr
Subscribers: andrewkr, hermanlee4, dhruba, IslamAbdelRahman
Differential Revision: https://reviews.facebook.net/D58053/[rocksdb] 2PC double recovery bug fix
Summary:
1. prepare()
2. crash
3. recover
4. commit()
5. crash
6. data is lost
This is due to the transaction data still only residing in the WAL but because the logs were flushed on the first recovery the data is ignored on the second recovery. We must scan all logs found on recovery and only ignore redundant data at the time of replay. It is not possible to know which logs still contain relevant data at time of recovery. We cannot simply ignore a log because all of the non-2pc data it contains has already been written to L0.
The changes made to MemTableInserter are to ensure that prepared sections are still recovered even if all of the non-2pc data in that log has already been flushed to L0.
Test Plan: Provided test.
Reviewers: sdong
Subscribers: andrewkr, hermanlee4, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D57729/[rocksdb] Recovery path sequence miscount fix
Summary:
Consider the following WAL with 4 batch entries prefixed with their sequence at time of memtable insert.
[1: BEGIN_PREPARE, PUT, PUT, PUT, PUT, END_PREPARE(a)]
[1: BEGIN_PREPARE, PUT, PUT, PUT, PUT, END_PREPARE(b)]
[4: COMMIT(a)]
[7: COMMIT(b)]
The first two batches do not consume any sequence numbers so are both prefixed with seq=1.
For 2pc commit, memtable insertion takes place before COMMIT batch is written to WAL.
We can see that sequence number consumption takes place between WAL entries giving us the seemingly sparse sequence prefix for WAL entries.
This is a valid WAL.
Because with 2PC markers one WriteBatch points to another batch containing its inserts a writebatch can consume more or less sequence numbers than the number of sequence consuming entries that it contains.
We can see that, given the entries in the WAL, 6 sequence ids were consumed. Yet on recovery the maximum sequence consumed would be 7 + 3 (the number of sequence numbers consumed by COMMIT(b))
So, now upon recovery we must track the actual consumption of sequence numbers.
In the provided scenario there will be no sequence gaps, but it is possible to produce a sequence gap. This should not be a problem though. correct?
Test Plan: provided test.
Reviewers: sdong
Subscribers: andrewkr, leveldb, dhruba, hermanlee4
Differential Revision: https://reviews.facebook.net/D57645/Added EventListener::OnTableFileCreationStarted() callback
Summary: Added EventListener::OnTableFileCreationStarted. EventListener::OnTableFileCreated will be called on failure case. User can check creation status via TableFileCreationInfo::status.
Test Plan: unit test.
Reviewers: dhruba, yhchiang, ott, sdong
Reviewed By: sdong
Subscribers: sdong, kradhakrishnan, IslamAbdelRahman, andrewkr, yhchiang, leveldb, ott, dhruba
Differential Revision: https://reviews.facebook.net/D56337/Fix build on machines without jemalloc
Summary: It looks like we mistakenly enable JEMALLOC even if it's not available on the machine, that's why travis is failing
Test Plan:
check on my devserver
check on my mac
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57345/Print memory allocation counters
Summary:
Introduced option to dump malloc statistics using new option flag.
Added new command line option to db_bench tool to enable this
funtionality.
Also extended build to support environments with/without jemalloc.
Test Plan:
1) Build rocksdb using `make` command. Launch the following command
`./db_bench --benchmarks=fillrandom --dump_malloc_stats=true
--num=10000000` end verified that jemalloc dump is present in LOG file.
2) Build rocksdb using `DISABLE_JEMALLOC=1  make db_bench -j32` and ran
the same db_bench tool and found the following message in LOG file:
""Please compile with jemalloc to enable malloc dump"".
3) Also built rocksdb using `make` command on MacOS to verify behavior
in non-FB environment.
Also to debug build configuration change temporary changed
AM_DEFAULT_VERBOSITY = 1 in Makefile to see compiler and build
tools output. For case 1) -DROCKSDB_JEMALLOC was present in compiler
command line. For both 2) and 3) this flag was not present.
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57321/Correct Statistics FLUSH_WRITE_BYTES
Summary:
In https://reviews.facebook.net/D56271, we fixed an issue where
we consider flush as compaction.  However, that makes us mistakenly
count FLUSH_WRITE_BYTES twice (one in flush_job and one in db_impl.)
This patch removes the one incremented in db_impl.
Test Plan: db_test
Reviewers: yiwu, andrewkr, IslamAbdelRahman, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D57111/Adding pin_l0_filter_and_index_blocks_in_cache feature and related fixes.
Summary:
When a block based table file is opened, if prefetch_index_and_filter is true, it will prefetch the index and filter blocks, putting them into the block cache.
What this feature adds: when a L0 block based table file is opened, if pin_l0_filter_and_index_blocks_in_cache is true in the options (and prefetch_index_and_filter is true), then the filter and index blocks aren't released back to the block cache at the end of BlockBasedTableReader::Open(). Instead the table reader takes ownership of them, hence pinning them, ie. the LRU cache will never push them out. Meanwhile in the table reader, further accesses will not hit the block cache, thus avoiding lock contention.
Test Plan:
'export TEST_TMPDIR=/dev/shm/ && DISABLE_JEMALLOC=1 OPT=-g make all valgrind_check -j32' is OK.
I didn't run the Java tests, I don't have Java set up on my devserver.
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D56133/Merge pull request #1047 from PraveenSinghRao/wal_filter_ex
Avoid overloaded virtual function/Avoid overloaded virtual function/fix: handle_fatal_signal (sig=6) in std::vector<std::string, std::allocator<std::string> >::_M_range_check | c++/4.8.2/bits/stl_vector.h:794 #174
Summary:
Fix for https://github.com/facebook/mysql-5.6/issues/174
When there is no old files to purge, vector.at(i) function was crashing
if (old_info_log_file_count != 0 &&
old_info_log_file_count >= db_options_.keep_log_file_num) {
std::sort(old_info_log_files.begin(), old_info_log_files.end());
size_t end = old_info_log_file_count - db_options_.keep_log_file_num;
for (unsigned int i = 0; i <= end; i++) {
std::string& to_delete = old_info_log_files.at(i);
Added check to old_info_log_file_count be non zero.
Test Plan: run existing tests
Reviewers: gunnarku, vasilep, sdong, yhchiang
Reviewed By: yhchiang
Subscribers: andrewkr, webscalesql-eng, dhruba
Differential Revision: https://reviews.facebook.net/D55245/Fix a bug where flush does not happen when a manual compaction is running
Summary:
Currently, when rocksdb tries to run manual compaction to refit data into a level,
there's a ReFitLevel() process that requires no bg work is currently running.
When RocksDB plans to ReFitLevel(), it will do the following:
1. pause scheduling new bg work.
2. wait until all bg work finished
3. do the ReFitLevel()
4. unpause scheduling new bg work.
However, as it pause scheduling new bg work at step one and waiting for all bg work
finished in step 2, RocksDB will stop flushing until all bg work is done (which
could take a long time.)
This patch fix this issue by changing the way ReFitLevel() pause the background work:
1. pause scheduling compaction.
2. wait until all bg work finished.
3. pause scheduling flush
4. do ReFitLevel()
5. unpause both flush and compaction.
The major difference is that.  We only pause scheduling compaction in step 1 and wait
for all bg work finished in step 2.  This prevent flush being blocked for a long time.
Although there's a very rare case that ReFitLevel() might be in starvation in step 2,
but it's less likely the case as flush typically finish very fast.
Test Plan: existing test.
Reviewers: anthony, IslamAbdelRahman, kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D55029/Fix WriteLevel0TableForRecovery file delete protection
Summary:
The call to
```
CaptureCurrentFileNumberInPendingOutputs()
```
should be before
```
versions_->NewFileNumber()
```
Right now we are not actually protecting the file from being deleted
Test Plan: make check
Reviewers: sdong, anthony, yhchiang
Reviewed By: yhchiang
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D54645/Fix DB::AddFile() issue when PurgeObsoleteFiles() is called
Summary:
In some situations the DB will scan all existing files in the DB path and delete the ones that are Obsolete.
If this happen during adding an external sst file. this could cause the file to be deleted while we are adding it.
This diff fix this issue
Test Plan:
unit test to reproduce the bug
existing unit tests
Reviewers: sdong, yhchiang, andrewkr
Reviewed By: andrewkr
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D54627/Fix assert failure when DBImpl::SyncWAL() conflicts with log rolling
Summary: DBImpl::SyncWAL() releases db mutex before calling DBImpl::MarkLogsSynced(), while inside DBImpl::MarkLogsSynced() we assert there is none or one outstanding log file. However, a memtable switch can happen in between and causing two or outstanding logs there, failing the assert. The diff adds a unit test that repros the issue and fix the assert so that the unit test passes.
Test Plan: Run the new tests.
Reviewers: anthony, kolmike, yhchiang, IslamAbdelRahman, kradhakrishnan, andrewkr
Reviewed By: andrewkr
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D54621/Fixed CompactFiles() spuriously failing or corrupting DB
Summary:
We started getting two kinds of crashes since we started using `DB::CompactFiles()`:
(1) `CompactFiles()` fails saying something like ""/data/logdevice/4440/shard12/012302.sst: No such file or directory"", and presumably makes DB read-only,
(2) DB fails to open saying ""Corruption: Can't access /267000.sst: IO error: /data/logdevice/4440/shard1/267000.sst: No such file or directory"".
AFAICT, both can be explained by background thread deleting compaction output as ""obsolete"" while it's being written, before it's committed to manifest. If it ends up committed to the manifest, we get (2); if compaction notices the disappearance and fails, we get (1). The internal tasks t10068021 and t10134177 have some details about the investigation that led to this.
Test Plan: `make -j check`; the new test fails to reopen the DB without the fix
Reviewers: yhchiang
Reviewed By: yhchiang
Subscribers: dhruba, sdong
Differential Revision: https://reviews.facebook.net/D54561/Introduce SstFileManager::SetMaxAllowedSpaceUsage() to cap disk space usage
Summary:
Introude SstFileManager::SetMaxAllowedSpaceUsage() that can be used to limit the maximum space usage allowed for RocksDB.
When this limit is exceeded WriteImpl() will fail and return Status::Aborted()
Test Plan: unit testing
Reviewers: yhchiang, anthony, andrewkr, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D53763/Fix WriteImpl empty batch hanging issue
Summary: There is an issue in DBImpl::WriteImpl where if an empty writebatch comes in and sync=true then the logs will be marked as being synced yet the sync never actually happens because there is no data in the writebatch. This causes the next incoming batch to hang while waiting for the logs to complete syncing. This fix syncs logs even if the writebatch is empty.
Test Plan: DoubleEmptyBatch unit test in transaction_test.
Reviewers: yoshinorim, hermanlee4, sdong, ngbronson, anthony
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D54057/Fixed a segfault when compaction fails
Summary: We've hit it today.
Test Plan: `make -j check`; didn't reproduce the issue
Reviewers: yhchiang
Reviewed By: yhchiang
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D54219/"
rocksdb,"Introduce SstFileManager::SetMaxAllowedSpaceUsage() to cap disk space usage
Summary:
Introude SstFileManager::SetMaxAllowedSpaceUsage() that can be used to limit the maximum space usage allowed for RocksDB.
When this limit is exceeded WriteImpl() will fail and return Status::Aborted()
Test Plan: unit testing
Reviewers: yhchiang, anthony, andrewkr, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D53763/"
rocksdb,"Fix compression dictionary clang errors
Summary: There were a few narrowing conversions that clang didn't like.
Test Plan:
$ make clean && USE_CLANG=1 DISABLE_JEMALLOC=1 TEST_TMPDIR=/dev/shm/rocksdb OPT=-g make -j32 check
Reviewers: IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D57351/Adding pin_l0_filter_and_index_blocks_in_cache feature and related fixes.
Summary:
When a block based table file is opened, if prefetch_index_and_filter is true, it will prefetch the index and filter blocks, putting them into the block cache.
What this feature adds: when a L0 block based table file is opened, if pin_l0_filter_and_index_blocks_in_cache is true in the options (and prefetch_index_and_filter is true), then the filter and index blocks aren't released back to the block cache at the end of BlockBasedTableReader::Open(). Instead the table reader takes ownership of them, hence pinning them, ie. the LRU cache will never push them out. Meanwhile in the table reader, further accesses will not hit the block cache, thus avoiding lock contention.
Test Plan:
'export TEST_TMPDIR=/dev/shm/ && DISABLE_JEMALLOC=1 OPT=-g make all valgrind_check -j32' is OK.
I didn't run the Java tests, I don't have Java set up on my devserver.
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D56133/Revert ""Adding pin_l0_filter_and_index_blocks_in_cache feature.""
This reverts commit 522de4f59e6314698286cf29d8a325a284d81778.
It has bug of index block cleaning up./Adding pin_l0_filter_and_index_blocks_in_cache feature.
Summary:
When a block based table file is opened, if prefetch_index_and_filter is true, it will prefetch the index and filter blocks, putting them into the block cache.
What this feature adds: when a L0 block based table file is opened, if pin_l0_filter_and_index_blocks_in_cache is true in the options (and prefetch_index_and_filter is true), then the filter and index blocks aren't released back to the block cache at the end of BlockBasedTableReader::Open(). Instead the table reader takes ownership of them, hence pinning them, ie. the LRU cache will never push them out. Meanwhile in the table reader, further accesses will not hit the block cache, thus avoiding lock contention.
When the table reader is destroyed, it releases the pinned blocks (if there were any). This has to happen before the cache is destroyed, so I had to introduce a TableReader::Close(), to guarantee the order of destruction.
Test Plan:
Added two unit tests for this. Existing unit tests run fine (default is pin_l0_filter_and_index_blocks_in_cache=false).
DISABLE_JEMALLOC=1 OPT=-g make all valgrind_check -j32
Mac: OK.
Linux: with D55287 patched in it's OK.
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D54801/"
rocksdb,"Compaction always needs to be removed from level0_compactions_in_progress_ for universal compaction
Summary: We always put compaction to level0_compactions_in_progress_ for universal compaction, so we should also remove it. The bug causes assert failure when running manual compaction.
Test Plan:
TEST_TMPDIR=/dev/shm/ ./db_bench --benchmarks=fillrandom,compact --subcompactions=16 --compaction_style=1
always fails on my host. After the fix, it doesn't fail any more.
Reviewers: IslamAbdelRahman, andrewkr, kradhakrishnan, yhchiang
Reviewed By: yhchiang
Subscribers: leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D55017/"
rocksdb,"Shouldn't report default column family's compaction stats as DB compaction stats
Summary:
Now we collect compaction stats per column family, but report default colum family's stat as compaction stats for DB.
Fix it by reporting compaction stats per column family instead.
Test Plan: Run db_bench with --num_column_families=4 and see the number fixed.
Reviewers: IslamAbdelRahman, yhchiang
Reviewed By: yhchiang
Subscribers: leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57063/"
rocksdb,"Estimate pending compaction bytes more accurately
Summary: Currently we estimate bytes needed for compaction by assuming fanout value to be level multiplier. It overestimates when size of a level exceeds the target by large. We estimate by the ratio of actual sizes in levels instead.
Test Plan: Fix existing test cases and add a new one.
Reviewers: IslamAbdelRahman, igor, yhchiang
Reviewed By: yhchiang
Subscribers: MarkCallaghan, leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57789/Added EventListener::OnTableFileCreationStarted() callback
Summary: Added EventListener::OnTableFileCreationStarted. EventListener::OnTableFileCreated will be called on failure case. User can check creation status via TableFileCreationInfo::status.
Test Plan: unit test.
Reviewers: dhruba, yhchiang, ott, sdong
Reviewed By: sdong
Subscribers: sdong, kradhakrishnan, IslamAbdelRahman, andrewkr, yhchiang, leveldb, ott, dhruba
Differential Revision: https://reviews.facebook.net/D56337/Merge pull request #1101 from flyd1005/wip-fix-typo
fix typos and remove duplicated words/DBTest.HardLimit made more deterministic
Summary: In DBTest.HardLimit, multiple flushes may merge into one, based on thread scheduling. Avoid it by waiting each flush to finish before generating the next one.
Test Plan: Run test in parallel several times and see it doesn't fail any more.
Reviewers: yhchiang, kradhakrishnan, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: yiwu, leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D56853/Fix unit tests issues on Windows (#1078)/Revert ""Adding pin_l0_filter_and_index_blocks_in_cache feature.""
This reverts commit 522de4f59e6314698286cf29d8a325a284d81778.
It has bug of index block cleaning up./travis build fixes/Reset block cache in failing unit test.
Test Plan: make -j40 check OPT=-g, on both /tmp and /dev/shm
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D55701/Adding pin_l0_filter_and_index_blocks_in_cache feature.
Summary:
When a block based table file is opened, if prefetch_index_and_filter is true, it will prefetch the index and filter blocks, putting them into the block cache.
What this feature adds: when a L0 block based table file is opened, if pin_l0_filter_and_index_blocks_in_cache is true in the options (and prefetch_index_and_filter is true), then the filter and index blocks aren't released back to the block cache at the end of BlockBasedTableReader::Open(). Instead the table reader takes ownership of them, hence pinning them, ie. the LRU cache will never push them out. Meanwhile in the table reader, further accesses will not hit the block cache, thus avoiding lock contention.
When the table reader is destroyed, it releases the pinned blocks (if there were any). This has to happen before the cache is destroyed, so I had to introduce a TableReader::Close(), to guarantee the order of destruction.
Test Plan:
Added two unit tests for this. Existing unit tests run fine (default is pin_l0_filter_and_index_blocks_in_cache=false).
DISABLE_JEMALLOC=1 OPT=-g make all valgrind_check -j32
Mac: OK.
Linux: with D55287 patched in it's OK.
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D54801/Aggregate hot Iterator counters in LocalStatistics (DBIter::Next perf regression)
Summary:
This patch bump the counters in the frequent code path DBIter::Next() / DBIter::Prev() in a local data members and send them to Statistics when the iterator is destroyed
A better solution will be to have thread_local implementation for Statistics
New performance
```
readseq      :       0.035 micros/op 28597881 ops/sec; 3163.7 MB/s
1,851,568,819      stalled-cycles-frontend   #   31.29% frontend cycles idle    [49.86%]
884,929,823      stalled-cycles-backend    #   14.95% backend  cycles idle    [50.21%]
readreverse  :       0.071 micros/op 14077393 ops/sec; 1557.3 MB/s
3,239,575,993      stalled-cycles-frontend   #   27.36% frontend cycles idle    [49.96%]
1,558,253,983      stalled-cycles-backend    #   13.16% backend  cycles idle    [50.14%]
```
Existing performance
```
readreverse  :       0.174 micros/op 5732342 ops/sec;  634.1 MB/s
20,570,209,389      stalled-cycles-frontend   #   70.71% frontend cycles idle    [50.01%]
18,422,816,837      stalled-cycles-backend    #   63.33% backend  cycles idle    [50.04%]
readseq      :       0.119 micros/op 8400537 ops/sec;  929.3 MB/s
15,634,225,844      stalled-cycles-frontend   #   79.07% frontend cycles idle    [49.96%]
14,227,427,453      stalled-cycles-backend    #   71.95% backend  cycles idle    [50.09%]
```
Test Plan: unit tests
Reviewers: yhchiang, sdong, igor
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D55107/Fix DB::AddFile() issue when PurgeObsoleteFiles() is called
Summary:
In some situations the DB will scan all existing files in the DB path and delete the ones that are Obsolete.
If this happen during adding an external sst file. this could cause the file to be deleted while we are adding it.
This diff fix this issue
Test Plan:
unit test to reproduce the bug
existing unit tests
Reviewers: sdong, yhchiang, andrewkr
Reviewed By: andrewkr
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D54627/Introduce SstFileManager::SetMaxAllowedSpaceUsage() to cap disk space usage
Summary:
Introude SstFileManager::SetMaxAllowedSpaceUsage() that can be used to limit the maximum space usage allowed for RocksDB.
When this limit is exceeded WriteImpl() will fail and return Status::Aborted()
Test Plan: unit testing
Reviewers: yhchiang, anthony, andrewkr, sdong
Reviewed By: sdong
Subscribers: dhruba
Differential Revision: https://reviews.facebook.net/D53763/"
rocksdb,"Added EventListener::OnTableFileCreationStarted() callback
Summary: Added EventListener::OnTableFileCreationStarted. EventListener::OnTableFileCreated will be called on failure case. User can check creation status via TableFileCreationInfo::status.
Test Plan: unit test.
Reviewers: dhruba, yhchiang, ott, sdong
Reviewed By: sdong
Subscribers: sdong, kradhakrishnan, IslamAbdelRahman, andrewkr, yhchiang, leveldb, ott, dhruba
Differential Revision: https://reviews.facebook.net/D56337/"
rocksdb,"Fix data race in GetObsoleteFiles()
Summary:
GetObsoleteFiles() and LogAndApply() functions modify obsolete_manifests_ vector
we need to make sure that the mutex is held when we modify the obsolete_manifests_
Test Plan: run the test under TSAN
Reviewers: andrewkr
Reviewed By: andrewkr
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D58011/Estimate pending compaction bytes more accurately
Summary: Currently we estimate bytes needed for compaction by assuming fanout value to be level multiplier. It overestimates when size of a level exceeds the target by large. We estimate by the ratio of actual sizes in levels instead.
Test Plan: Fix existing test cases and add a new one.
Reviewers: IslamAbdelRahman, igor, yhchiang
Reviewed By: yhchiang
Subscribers: MarkCallaghan, leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57789/Don't use version in the error message
Summary: We use object `v` in the error message, which is not initialized if the edit is column family manipulation. This doesn't provide much useful info, so this diff is removing it. Instead, it dumps actual VersionEdit contents.
Test Plan: compiles. would be great to get tests in version_set_test.cc that cover cases where a file write fails
Reviewers: sdong, yhchiang, andrewkr
Reviewed By: andrewkr
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D56349/Adding pin_l0_filter_and_index_blocks_in_cache feature and related fixes.
Summary:
When a block based table file is opened, if prefetch_index_and_filter is true, it will prefetch the index and filter blocks, putting them into the block cache.
What this feature adds: when a L0 block based table file is opened, if pin_l0_filter_and_index_blocks_in_cache is true in the options (and prefetch_index_and_filter is true), then the filter and index blocks aren't released back to the block cache at the end of BlockBasedTableReader::Open(). Instead the table reader takes ownership of them, hence pinning them, ie. the LRU cache will never push them out. Meanwhile in the table reader, further accesses will not hit the block cache, thus avoiding lock contention.
Test Plan:
'export TEST_TMPDIR=/dev/shm/ && DISABLE_JEMALLOC=1 OPT=-g make all valgrind_check -j32' is OK.
I didn't run the Java tests, I don't have Java set up on my devserver.
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D56133/Fix perf_context::merge_operator_time_nanos calculation
Summary: We were not measuring the time spent in merge_operator when called from Version::Get()
Test Plan: added a unittest
Reviewers: sdong, yhchiang
Reviewed By: yhchiang
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D55905/Fix data race issue when sub-compaction is used in CompactionJob
Summary:
When subcompaction is used, all subcompactions share the same Compaction
pointer in CompactionJob while each subcompaction all keeps their mutable
stats in SubcompactionState.  However, there're still some mutable part
that is currently store in the shared Compaction pointer.
This patch makes two changes:
1. Make the shared Compaction pointer const so that it can never be modified
during the compaction.
2. Move necessary states from Compaction to SubcompactionState.
3. Make functions of Compaction const if the function does not modify
its internal state.
Test Plan: rocksdb and MyRocks test
Reviewers: sdong, kradhakrishnan, andrewkr, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba, yoshinorim, gunnarku, leveldb
Differential Revision: https://reviews.facebook.net/D55923/Revert ""Adding pin_l0_filter_and_index_blocks_in_cache feature.""
This reverts commit 522de4f59e6314698286cf29d8a325a284d81778.
It has bug of index block cleaning up./Adding pin_l0_filter_and_index_blocks_in_cache feature.
Summary:
When a block based table file is opened, if prefetch_index_and_filter is true, it will prefetch the index and filter blocks, putting them into the block cache.
What this feature adds: when a L0 block based table file is opened, if pin_l0_filter_and_index_blocks_in_cache is true in the options (and prefetch_index_and_filter is true), then the filter and index blocks aren't released back to the block cache at the end of BlockBasedTableReader::Open(). Instead the table reader takes ownership of them, hence pinning them, ie. the LRU cache will never push them out. Meanwhile in the table reader, further accesses will not hit the block cache, thus avoiding lock contention.
When the table reader is destroyed, it releases the pinned blocks (if there were any). This has to happen before the cache is destroyed, so I had to introduce a TableReader::Close(), to guarantee the order of destruction.
Test Plan:
Added two unit tests for this. Existing unit tests run fine (default is pin_l0_filter_and_index_blocks_in_cache=false).
DISABLE_JEMALLOC=1 OPT=-g make all valgrind_check -j32
Mac: OK.
Linux: with D55287 patched in it's OK.
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, leveldb, dhruba
Differential Revision: https://reviews.facebook.net/D54801/Merge pull request #1040 from bureau14/master
Fixes warnings and ensure correct int behavior on 32-bit platforms./Fixes warnings and ensure correct int behavior on 32-bit platforms./Handle concurrent manifest update and backup creation
Summary:
Fixed two related race conditions in backup creation.
(1) CreateNewBackup() uses DB::DisableFileDeletions() to prevent table files
from being deleted while it is copying; however, the MANIFEST file could still
rotate during this time. The fix is to stop deleting the old manifest in the
rotation logic. It will be deleted safely later when PurgeObsoleteFiles() runs
(can only happen when file deletions are enabled).
(2) CreateNewBackup() did not account for the CURRENT file being mutable.
This is significant because the files returned by GetLiveFiles() contain a
particular manifest filename, but the manifest to which CURRENT refers can
change at any time. This causes problems when CURRENT changes between the call
to GetLiveFiles() and when it's copied to the backup directory. To workaround this, I
manually forge a CURRENT file referring to the manifest filename returned in
GetLiveFiles().
(2) also applies to the checkpointing code, so let me know if this approach is
good and I'll make the same change there.
Test Plan:
new test for roll manifest during backup creation.
running the test before this change:
$ ./backupable_db_test --gtest_filter=BackupableDBTest.ChangeManifestDuringBackupCreation
...
IO error: /tmp/rocksdbtest-9383/backupable_db/MANIFEST-000001: No such file or directory
running the test after this change:
$ ./backupable_db_test --gtest_filter=BackupableDBTest.ChangeManifestDuringBackupCreation
...
[ RUN      ] BackupableDBTest.ChangeManifestDuringBackupCreation
[       OK ] BackupableDBTest.ChangeManifestDuringBackupCreation (2836 ms)
Reviewers: IslamAbdelRahman, anthony, sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D54711/"
rocksdb,"Use generic threadpool for Windows environment (#1120)
Conditionally retrofit thread_posix for use with std::thread
and reuse the same logic. Posix users continue using Posix interfaces.
Enable XPRESS compression in test runs.
Fix master introduced signed/unsigned mismatch./Fix multiple issues with WinMmapFile fo sequential writing (#1108)
make preallocation inline with other writable files
make sure that we map no more than pre-allocated size./Revert ""Use async file handle for better parallelism (#1049)"" (#1105)
This reverts commit b54c34742412af0001a69c2f7d909bc05e1ea71f.
Revert async file handle change as it causes failures with appveyor/Merge pull request #1101 from flyd1005/wip-fix-typo
fix typos and remove duplicated words/[build] Fix env_win.cc compiler errors
Summary: I broke it in D53781.
Test Plan: tried the same code in util/env_posix.cc and it compiled successfully
Reviewers: sdong
Reviewed By: sdong
Subscribers: dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D54303/"
rocksdb,"ldb load, prefer ifsteam(/dev/stdin) to std::cin (#1207)
getline on std::cin can be very inefficient when ldb is loading large values, with high CPU usage in libc _IO_(un)getc, this is because of the performance penalty that comes from synchronizing stdio and iostream buffers.
See the reproducers and tests in #1133 .
If an ifstream on /dev/stdin is used (when available) then using ldb to load large values can be much more efficient.
I thought for ldb load, that this approach is preferable to using <cstdio> or std::ios_base::sync_with_stdio(false).
I couldn't think of a use case where ldb load would need to support reading unbuffered input, an alternative approach would be to add support for passing --input_file=/dev/stdin.
I have a CLA in place, thanks.
The CI tests were failing at the time of https://github.com/facebook/rocksdb/pull/1156, so this change and PR will supersede it./LDBCommand::SelectCommand to use a struct as the parameter
Summary: The function wrapper for LDBCommand::SelectCommand is too long so that Windows build fails with warning ""decorated name length exceeded, name was truncated"". Shrink the length by using a struct.
Test Plan: Build on both of Linux and Windows and make sure the warning doesn't show in either platform.
Reviewers: andrewkr, adsharma, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D58965/LDBCommand::InitFromCmdLineArgs() to move from template to function wrapper
Summary:
Build failure with some compiler setting with
tools/reduce_levels_test.cc:97: undefined reference to `rocksdb::LDBCommand* rocksdb::LDBCommand::InitFromCmdLineArgs<rocksdb::LDBCommand* (*)(std::string const&, std::vector<std::string, std::allocator<std::string> > const&, std::map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<std::string const, std::string> > > const&, std::vector<std::string, std::allocator<std::string> > const&)>(std::vector<std::string, std::allocator<std::string> > const&, rocksdb::Options const&, rocksdb::LDBOptions const&, std::vector<rocksdb::ColumnFamilyDescriptor, std::allocator<rocksdb::ColumnFamilyDescriptor> > const*, rocksdb::LDBCommand* (*)(std::string const&, std::vector<std::string, std::allocator<std::string> > const&, std::map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<std::string const, std::string> > > const&, std::vector<std::string, std::allocator<std::string> > const&))'
Fix it by changing to function pointer instead
Test Plan: Run all existing tests
Reviewers: andrewkr, kradhakrishnan, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: adsharma, lightmark, yiwu, leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D58905/"
rocksdb,"Fix db_stress failure (pass merge_operator even if not used)
Summary:
db_stress test is now failing because of this scenario
- run db_stress with merge_operator enabled (now we have a db with merge operands)
- run db_stress with merge_operator disabled (now when we fail to open the db)
the solution is to pass the merge_operator to the DB even if we are not going to do any merge operations
Test Plan: Check the failure
Reviewers: andrewkr, yiwu, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D61311/db_stress shouldn't assert file size 0 if file creation fails
Summary: OnTableFileCreated() now is also called when the file creaion fails. In that case, we shouldn't assert the file size is not 0.
Test Plan: Run crash test
Reviewers: yiwu, andrewkr, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: IslamAbdelRahman, leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D61137/Introduce FullMergeV2 (eliminate memcpy from merge operators)
Summary:
This diff update the code to pin the merge operator operands while the merge operation is done, so that we can eliminate the memcpy cost, to do that we need a new public API for FullMerge that replace the std::deque<std::string> with std::vector<Slice>
This diff is stacked on top of D56493 and D56511
In this diff we
- Update FullMergeV2 arguments to be encapsulated in MergeOperationInput and MergeOperationOutput which will make it easier to add new arguments in the future
- Replace std::deque<std::string> with std::vector<Slice> to pass operands
- Replace MergeContext std::deque with std::vector (based on a simple benchmark I ran https://gist.github.com/IslamAbdelRahman/78fc86c9ab9f52b1df791e58943fb187)
- Allow FullMergeV2 output to be an existing operand
```
[Everything in Memtable | 10K operands | 10 KB each | 1 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=10000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       0.607 micros/op 1648235 ops/sec; 16121.2 MB/s
readseq      :       0.478 micros/op 2091546 ops/sec; 20457.2 MB/s
readseq      :       0.252 micros/op 3972081 ops/sec; 38850.5 MB/s
readseq      :       0.237 micros/op 4218328 ops/sec; 41259.0 MB/s
readseq      :       0.247 micros/op 4043927 ops/sec; 39553.2 MB/s
[master]
readseq      :       3.935 micros/op 254140 ops/sec; 2485.7 MB/s
readseq      :       3.722 micros/op 268657 ops/sec; 2627.7 MB/s
readseq      :       3.149 micros/op 317605 ops/sec; 3106.5 MB/s
readseq      :       3.125 micros/op 320024 ops/sec; 3130.1 MB/s
readseq      :       4.075 micros/op 245374 ops/sec; 2400.0 MB/s
```
```
[Everything in Memtable | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=1000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       3.472 micros/op 288018 ops/sec; 2817.1 MB/s
readseq      :       2.304 micros/op 434027 ops/sec; 4245.2 MB/s
readseq      :       1.163 micros/op 859845 ops/sec; 8410.0 MB/s
readseq      :       1.192 micros/op 838926 ops/sec; 8205.4 MB/s
readseq      :       1.250 micros/op 800000 ops/sec; 7824.7 MB/s
[master]
readseq      :      24.025 micros/op 41623 ops/sec;  407.1 MB/s
readseq      :      18.489 micros/op 54086 ops/sec;  529.0 MB/s
readseq      :      18.693 micros/op 53495 ops/sec;  523.2 MB/s
readseq      :      23.621 micros/op 42335 ops/sec;  414.1 MB/s
readseq      :      18.775 micros/op 53262 ops/sec;  521.0 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 1 operand per key]
[FullMergeV2]
$ DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
readseq      :      14.741 micros/op 67837 ops/sec;  663.5 MB/s
readseq      :       1.029 micros/op 971446 ops/sec; 9501.6 MB/s
readseq      :       0.974 micros/op 1026229 ops/sec; 10037.4 MB/s
readseq      :       0.965 micros/op 1036080 ops/sec; 10133.8 MB/s
readseq      :       0.943 micros/op 1060657 ops/sec; 10374.2 MB/s
[master]
readseq      :      16.735 micros/op 59755 ops/sec;  584.5 MB/s
readseq      :       3.029 micros/op 330151 ops/sec; 3229.2 MB/s
readseq      :       3.136 micros/op 318883 ops/sec; 3119.0 MB/s
readseq      :       3.065 micros/op 326245 ops/sec; 3191.0 MB/s
readseq      :       3.014 micros/op 331813 ops/sec; 3245.4 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10-operands-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
[FullMergeV2]
readseq      :      24.325 micros/op 41109 ops/sec;  402.1 MB/s
readseq      :       1.470 micros/op 680272 ops/sec; 6653.7 MB/s
readseq      :       1.231 micros/op 812347 ops/sec; 7945.5 MB/s
readseq      :       1.091 micros/op 916590 ops/sec; 8965.1 MB/s
readseq      :       1.109 micros/op 901713 ops/sec; 8819.6 MB/s
[master]
readseq      :      27.257 micros/op 36687 ops/sec;  358.8 MB/s
readseq      :       4.443 micros/op 225073 ops/sec; 2201.4 MB/s
readseq      :       5.830 micros/op 171526 ops/sec; 1677.7 MB/s
readseq      :       4.173 micros/op 239635 ops/sec; 2343.8 MB/s
readseq      :       4.150 micros/op 240963 ops/sec; 2356.8 MB/s
```
Test Plan: COMPILE_WITH_ASAN=1 make check -j64
Reviewers: yhchiang, andrewkr, sdong
Reviewed By: sdong
Subscribers: lovro, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57075/"
rocksdb,"New Statistics to track Compression/Decompression (#1197)
* Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer).
* Prevent incrementing compression counter when compression is turned off in options.
* Prevent incrementing compression counter when compression is turned off in options.
* Added two more supported compression types to test code in db_test.cc
* Prevent incrementing compression counter when compression is turned off in options.
* Added new StatsLevel that excludes compression timing.
* Fixed casting error in coding.h
* Fixed CompressionStatsTest for new StatsLevel.
* Removed unused variable that was breaking the Linux build/Added ""number of merge operands"" to statistics in ssts.
Summary:
A couple of notes from the diff:
- The namespace block I added at the top of table_properties_collector.cc was in reaction to an issue i was having with PutVarint64 and reusing the ""val"" string.  I'm not sure this is the cleanest way of doing this, but abstracting this out at least results in the correct behavior.
- I chose ""rocksdb.merge.operands"" as the property name.  I am open to suggestions for better names.
- The change to sst_dump_tool.cc seems a bit inelegant to me.  Is there a better way to do the if-else block?
Test Plan:
I added a test case in table_properties_collector_test.cc.  It adds two merge operands and checks to make sure that both of them are reflected by GetMergeOperands.  It also checks to make sure the wasPropertyPresent bool is properly set in the method.
Running both of these tests should pass:
./table_properties_collector_test
./sst_dump_test
Reviewers: IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D58119/"
rocksdb,"Fix clang analyzer errors
Summary:
Fixing erros reported by clang static analyzer.
* Removing some unused variables.
* Adding assertions to fix false positives reported by clang analyzer.
* Adding `__clang_analyzer__` macro to suppress false positive warnings.
Test Plan:
USE_CLANG=1 OPT=-g make analyze -j64
Reviewers: andrewkr, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D60549/"
rocksdb,"Simplify thread-local static initialization
Summary:
The call stack used to look like this during static initialization:
#0  0x00000000008032d1 in rocksdb::ThreadLocalPtr::StaticMeta::StaticMeta() (this=0x7ffff683b300) at util/thread_local.cc:172
#1  0x00000000008030a7 in rocksdb::ThreadLocalPtr::Instance() () at util/thread_local.cc:135
#2  0x000000000080310f in rocksdb::ThreadLocalPtr::StaticMeta::Mutex() () at util/thread_local.cc:141
#3  0x0000000000803103 in rocksdb::ThreadLocalPtr::StaticMeta::InitSingletons() () at util/thread_local.cc:139
#4  0x000000000080305d in rocksdb::ThreadLocalPtr::InitSingletons() () at util/thread_local.cc:106
It involves outer/inner classes and the call stacks goes
outer->inner->outer->inner, which is too difficult to understand. We can avoid
a level of back-and-forth by skipping StaticMeta::InitSingletons(), which
doesn't initialize anything beyond what ThreadLocalPtr::Instance() already
initializes.
Now the call stack looks like this during static initialization:
#0  0x00000000008032c5 in rocksdb::ThreadLocalPtr::StaticMeta::StaticMeta() (this=0x7ffff683b300) at util/thread_local.cc:170
#1  0x00000000008030a7 in rocksdb::ThreadLocalPtr::Instance() () at util/thread_local.cc:135
#2  0x000000000080305d in rocksdb::ThreadLocalPtr::InitSingletons() () at util/thread_local.cc:106
Test Plan:
unit tests
verify StaticMeta::mutex_ is still initialized in DefaultEnv() (StaticMeta::mutex_ is the only variable intended to be initialized via StaticMeta::InitSingletons() which I removed)
#0  0x00000000005cee17 in rocksdb::port::Mutex::Mutex(bool) (this=0x7ffff69500b0, adaptive=false) at port/port_posix.cc:52
#1  0x0000000000769cf8 in rocksdb::ThreadLocalPtr::StaticMeta::StaticMeta() (this=0x7ffff6950000) at util/thread_local.cc:168
#2  0x0000000000769a53 in rocksdb::ThreadLocalPtr::Instance() () at util/thread_local.cc:133
#3  0x0000000000769a09 in rocksdb::ThreadLocalPtr::InitSingletons() () at util/thread_local.cc:105
#4  0x0000000000647d98 in rocksdb::Env::Default() () at util/env_posix.cc:845
Reviewers: lightmark, yhchiang, sdong
Reviewed By: sdong
Subscribers: arahut, IslamAbdelRahman, yiwu, andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D60813/"
rocksdb,"Fix Java Break Related to memtable bloom bits to size ratio change
Summary: Need to change several more places for the change to fix Java tests
Test Plan:
make jtest
under java, run ""make db_bench""
Reviewers: yhchiang, andrewkr, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D59541/"
rocksdb,"[Fix java build] Stop using non standard std::make_unique
Summary: std::make_unique is not standard and not always available, remove it
Test Plan: Run ""make clean jclean rocksdbjava jtest -j8"" on my mac
Reviewers: yhchiang, yiwu, sdong, andrewkr
Reviewed By: andrewkr
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D61143/fixes 1220: rocksjni build fails on Windows due to variable-size array declaration (#1223)
* fixes 1220: rocksjni build fails on Windows due to variable-size array declaration
using new keyword to create variable-size arrays in order to satisfy most of the compilers
* fixes 1220: rocksjni build fails on Windows due to variable-size array declaration
using unique_ptr keyword to create variable-size arrays in order to satisfy most of the compilers/"
rocksdb,"[Fix java build] Stop using non standard std::make_unique
Summary: std::make_unique is not standard and not always available, remove it
Test Plan: Run ""make clean jclean rocksdbjava jtest -j8"" on my mac
Reviewers: yhchiang, yiwu, sdong, andrewkr
Reviewed By: andrewkr
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D61143/fixes 1220: rocksjni build fails on Windows due to variable-size array declaration (#1223)
* fixes 1220: rocksjni build fails on Windows due to variable-size array declaration
using new keyword to create variable-size arrays in order to satisfy most of the compilers
* fixes 1220: rocksjni build fails on Windows due to variable-size array declaration
using unique_ptr keyword to create variable-size arrays in order to satisfy most of the compilers/"
rocksdb,"[Fix java build] Stop using non standard std::make_unique
Summary: std::make_unique is not standard and not always available, remove it
Test Plan: Run ""make clean jclean rocksdbjava jtest -j8"" on my mac
Reviewers: yhchiang, yiwu, sdong, andrewkr
Reviewed By: andrewkr
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D61143/fixes 1220: rocksjni build fails on Windows due to variable-size array declaration (#1223)
* fixes 1220: rocksjni build fails on Windows due to variable-size array declaration
using new keyword to create variable-size arrays in order to satisfy most of the compilers
* fixes 1220: rocksjni build fails on Windows due to variable-size array declaration
using unique_ptr keyword to create variable-size arrays in order to satisfy most of the compilers/Java API - Bugfix for native linking of Compaction Filter (#1099)/"
rocksdb,"fixes 1228: rockdbjni loadLibraryFromJarToTemp fails when file is already present (#1232)
overriding existing library in tmp folder/"
rocksdb,"Fix Java Break Related to memtable bloom bits to size ratio change
Summary: Need to change several more places for the change to fix Java tests
Test Plan:
make jtest
under java, run ""make db_bench""
Reviewers: yhchiang, andrewkr, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D59541/"
rocksdb,"Introduce FullMergeV2 (eliminate memcpy from merge operators)
Summary:
This diff update the code to pin the merge operator operands while the merge operation is done, so that we can eliminate the memcpy cost, to do that we need a new public API for FullMerge that replace the std::deque<std::string> with std::vector<Slice>
This diff is stacked on top of D56493 and D56511
In this diff we
- Update FullMergeV2 arguments to be encapsulated in MergeOperationInput and MergeOperationOutput which will make it easier to add new arguments in the future
- Replace std::deque<std::string> with std::vector<Slice> to pass operands
- Replace MergeContext std::deque with std::vector (based on a simple benchmark I ran https://gist.github.com/IslamAbdelRahman/78fc86c9ab9f52b1df791e58943fb187)
- Allow FullMergeV2 output to be an existing operand
```
[Everything in Memtable | 10K operands | 10 KB each | 1 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=10000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       0.607 micros/op 1648235 ops/sec; 16121.2 MB/s
readseq      :       0.478 micros/op 2091546 ops/sec; 20457.2 MB/s
readseq      :       0.252 micros/op 3972081 ops/sec; 38850.5 MB/s
readseq      :       0.237 micros/op 4218328 ops/sec; 41259.0 MB/s
readseq      :       0.247 micros/op 4043927 ops/sec; 39553.2 MB/s
[master]
readseq      :       3.935 micros/op 254140 ops/sec; 2485.7 MB/s
readseq      :       3.722 micros/op 268657 ops/sec; 2627.7 MB/s
readseq      :       3.149 micros/op 317605 ops/sec; 3106.5 MB/s
readseq      :       3.125 micros/op 320024 ops/sec; 3130.1 MB/s
readseq      :       4.075 micros/op 245374 ops/sec; 2400.0 MB/s
```
```
[Everything in Memtable | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=1000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       3.472 micros/op 288018 ops/sec; 2817.1 MB/s
readseq      :       2.304 micros/op 434027 ops/sec; 4245.2 MB/s
readseq      :       1.163 micros/op 859845 ops/sec; 8410.0 MB/s
readseq      :       1.192 micros/op 838926 ops/sec; 8205.4 MB/s
readseq      :       1.250 micros/op 800000 ops/sec; 7824.7 MB/s
[master]
readseq      :      24.025 micros/op 41623 ops/sec;  407.1 MB/s
readseq      :      18.489 micros/op 54086 ops/sec;  529.0 MB/s
readseq      :      18.693 micros/op 53495 ops/sec;  523.2 MB/s
readseq      :      23.621 micros/op 42335 ops/sec;  414.1 MB/s
readseq      :      18.775 micros/op 53262 ops/sec;  521.0 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 1 operand per key]
[FullMergeV2]
$ DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
readseq      :      14.741 micros/op 67837 ops/sec;  663.5 MB/s
readseq      :       1.029 micros/op 971446 ops/sec; 9501.6 MB/s
readseq      :       0.974 micros/op 1026229 ops/sec; 10037.4 MB/s
readseq      :       0.965 micros/op 1036080 ops/sec; 10133.8 MB/s
readseq      :       0.943 micros/op 1060657 ops/sec; 10374.2 MB/s
[master]
readseq      :      16.735 micros/op 59755 ops/sec;  584.5 MB/s
readseq      :       3.029 micros/op 330151 ops/sec; 3229.2 MB/s
readseq      :       3.136 micros/op 318883 ops/sec; 3119.0 MB/s
readseq      :       3.065 micros/op 326245 ops/sec; 3191.0 MB/s
readseq      :       3.014 micros/op 331813 ops/sec; 3245.4 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10-operands-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
[FullMergeV2]
readseq      :      24.325 micros/op 41109 ops/sec;  402.1 MB/s
readseq      :       1.470 micros/op 680272 ops/sec; 6653.7 MB/s
readseq      :       1.231 micros/op 812347 ops/sec; 7945.5 MB/s
readseq      :       1.091 micros/op 916590 ops/sec; 8965.1 MB/s
readseq      :       1.109 micros/op 901713 ops/sec; 8819.6 MB/s
[master]
readseq      :      27.257 micros/op 36687 ops/sec;  358.8 MB/s
readseq      :       4.443 micros/op 225073 ops/sec; 2201.4 MB/s
readseq      :       5.830 micros/op 171526 ops/sec; 1677.7 MB/s
readseq      :       4.173 micros/op 239635 ops/sec; 2343.8 MB/s
readseq      :       4.150 micros/op 240963 ops/sec; 2356.8 MB/s
```
Test Plan: COMPILE_WITH_ASAN=1 make check -j64
Reviewers: yhchiang, andrewkr, sdong
Reviewed By: sdong
Subscribers: lovro, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57075/"
rocksdb,"Long outstanding prepare test
Summary: This tests that a prepared transaction is not lost after several crashes, restarts, and memtable flushes.
Test Plan: TwoPhaseLongPrepareTest
Reviewers: sdong
Subscribers: hermanlee4, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D58185/"
rocksdb,"Introduce FullMergeV2 (eliminate memcpy from merge operators)
Summary:
This diff update the code to pin the merge operator operands while the merge operation is done, so that we can eliminate the memcpy cost, to do that we need a new public API for FullMerge that replace the std::deque<std::string> with std::vector<Slice>
This diff is stacked on top of D56493 and D56511
In this diff we
- Update FullMergeV2 arguments to be encapsulated in MergeOperationInput and MergeOperationOutput which will make it easier to add new arguments in the future
- Replace std::deque<std::string> with std::vector<Slice> to pass operands
- Replace MergeContext std::deque with std::vector (based on a simple benchmark I ran https://gist.github.com/IslamAbdelRahman/78fc86c9ab9f52b1df791e58943fb187)
- Allow FullMergeV2 output to be an existing operand
```
[Everything in Memtable | 10K operands | 10 KB each | 1 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=10000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       0.607 micros/op 1648235 ops/sec; 16121.2 MB/s
readseq      :       0.478 micros/op 2091546 ops/sec; 20457.2 MB/s
readseq      :       0.252 micros/op 3972081 ops/sec; 38850.5 MB/s
readseq      :       0.237 micros/op 4218328 ops/sec; 41259.0 MB/s
readseq      :       0.247 micros/op 4043927 ops/sec; 39553.2 MB/s
[master]
readseq      :       3.935 micros/op 254140 ops/sec; 2485.7 MB/s
readseq      :       3.722 micros/op 268657 ops/sec; 2627.7 MB/s
readseq      :       3.149 micros/op 317605 ops/sec; 3106.5 MB/s
readseq      :       3.125 micros/op 320024 ops/sec; 3130.1 MB/s
readseq      :       4.075 micros/op 245374 ops/sec; 2400.0 MB/s
```
```
[Everything in Memtable | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=1000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       3.472 micros/op 288018 ops/sec; 2817.1 MB/s
readseq      :       2.304 micros/op 434027 ops/sec; 4245.2 MB/s
readseq      :       1.163 micros/op 859845 ops/sec; 8410.0 MB/s
readseq      :       1.192 micros/op 838926 ops/sec; 8205.4 MB/s
readseq      :       1.250 micros/op 800000 ops/sec; 7824.7 MB/s
[master]
readseq      :      24.025 micros/op 41623 ops/sec;  407.1 MB/s
readseq      :      18.489 micros/op 54086 ops/sec;  529.0 MB/s
readseq      :      18.693 micros/op 53495 ops/sec;  523.2 MB/s
readseq      :      23.621 micros/op 42335 ops/sec;  414.1 MB/s
readseq      :      18.775 micros/op 53262 ops/sec;  521.0 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 1 operand per key]
[FullMergeV2]
$ DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
readseq      :      14.741 micros/op 67837 ops/sec;  663.5 MB/s
readseq      :       1.029 micros/op 971446 ops/sec; 9501.6 MB/s
readseq      :       0.974 micros/op 1026229 ops/sec; 10037.4 MB/s
readseq      :       0.965 micros/op 1036080 ops/sec; 10133.8 MB/s
readseq      :       0.943 micros/op 1060657 ops/sec; 10374.2 MB/s
[master]
readseq      :      16.735 micros/op 59755 ops/sec;  584.5 MB/s
readseq      :       3.029 micros/op 330151 ops/sec; 3229.2 MB/s
readseq      :       3.136 micros/op 318883 ops/sec; 3119.0 MB/s
readseq      :       3.065 micros/op 326245 ops/sec; 3191.0 MB/s
readseq      :       3.014 micros/op 331813 ops/sec; 3245.4 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10-operands-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
[FullMergeV2]
readseq      :      24.325 micros/op 41109 ops/sec;  402.1 MB/s
readseq      :       1.470 micros/op 680272 ops/sec; 6653.7 MB/s
readseq      :       1.231 micros/op 812347 ops/sec; 7945.5 MB/s
readseq      :       1.091 micros/op 916590 ops/sec; 8965.1 MB/s
readseq      :       1.109 micros/op 901713 ops/sec; 8819.6 MB/s
[master]
readseq      :      27.257 micros/op 36687 ops/sec;  358.8 MB/s
readseq      :       4.443 micros/op 225073 ops/sec; 2201.4 MB/s
readseq      :       5.830 micros/op 171526 ops/sec; 1677.7 MB/s
readseq      :       4.173 micros/op 239635 ops/sec; 2343.8 MB/s
readseq      :       4.150 micros/op 240963 ops/sec; 2356.8 MB/s
```
Test Plan: COMPILE_WITH_ASAN=1 make check -j64
Reviewers: yhchiang, andrewkr, sdong
Reviewed By: sdong
Subscribers: lovro, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57075/"
rocksdb,"Introduce FullMergeV2 (eliminate memcpy from merge operators)
Summary:
This diff update the code to pin the merge operator operands while the merge operation is done, so that we can eliminate the memcpy cost, to do that we need a new public API for FullMerge that replace the std::deque<std::string> with std::vector<Slice>
This diff is stacked on top of D56493 and D56511
In this diff we
- Update FullMergeV2 arguments to be encapsulated in MergeOperationInput and MergeOperationOutput which will make it easier to add new arguments in the future
- Replace std::deque<std::string> with std::vector<Slice> to pass operands
- Replace MergeContext std::deque with std::vector (based on a simple benchmark I ran https://gist.github.com/IslamAbdelRahman/78fc86c9ab9f52b1df791e58943fb187)
- Allow FullMergeV2 output to be an existing operand
```
[Everything in Memtable | 10K operands | 10 KB each | 1 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=10000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       0.607 micros/op 1648235 ops/sec; 16121.2 MB/s
readseq      :       0.478 micros/op 2091546 ops/sec; 20457.2 MB/s
readseq      :       0.252 micros/op 3972081 ops/sec; 38850.5 MB/s
readseq      :       0.237 micros/op 4218328 ops/sec; 41259.0 MB/s
readseq      :       0.247 micros/op 4043927 ops/sec; 39553.2 MB/s
[master]
readseq      :       3.935 micros/op 254140 ops/sec; 2485.7 MB/s
readseq      :       3.722 micros/op 268657 ops/sec; 2627.7 MB/s
readseq      :       3.149 micros/op 317605 ops/sec; 3106.5 MB/s
readseq      :       3.125 micros/op 320024 ops/sec; 3130.1 MB/s
readseq      :       4.075 micros/op 245374 ops/sec; 2400.0 MB/s
```
```
[Everything in Memtable | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=1000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       3.472 micros/op 288018 ops/sec; 2817.1 MB/s
readseq      :       2.304 micros/op 434027 ops/sec; 4245.2 MB/s
readseq      :       1.163 micros/op 859845 ops/sec; 8410.0 MB/s
readseq      :       1.192 micros/op 838926 ops/sec; 8205.4 MB/s
readseq      :       1.250 micros/op 800000 ops/sec; 7824.7 MB/s
[master]
readseq      :      24.025 micros/op 41623 ops/sec;  407.1 MB/s
readseq      :      18.489 micros/op 54086 ops/sec;  529.0 MB/s
readseq      :      18.693 micros/op 53495 ops/sec;  523.2 MB/s
readseq      :      23.621 micros/op 42335 ops/sec;  414.1 MB/s
readseq      :      18.775 micros/op 53262 ops/sec;  521.0 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 1 operand per key]
[FullMergeV2]
$ DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
readseq      :      14.741 micros/op 67837 ops/sec;  663.5 MB/s
readseq      :       1.029 micros/op 971446 ops/sec; 9501.6 MB/s
readseq      :       0.974 micros/op 1026229 ops/sec; 10037.4 MB/s
readseq      :       0.965 micros/op 1036080 ops/sec; 10133.8 MB/s
readseq      :       0.943 micros/op 1060657 ops/sec; 10374.2 MB/s
[master]
readseq      :      16.735 micros/op 59755 ops/sec;  584.5 MB/s
readseq      :       3.029 micros/op 330151 ops/sec; 3229.2 MB/s
readseq      :       3.136 micros/op 318883 ops/sec; 3119.0 MB/s
readseq      :       3.065 micros/op 326245 ops/sec; 3191.0 MB/s
readseq      :       3.014 micros/op 331813 ops/sec; 3245.4 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10-operands-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
[FullMergeV2]
readseq      :      24.325 micros/op 41109 ops/sec;  402.1 MB/s
readseq      :       1.470 micros/op 680272 ops/sec; 6653.7 MB/s
readseq      :       1.231 micros/op 812347 ops/sec; 7945.5 MB/s
readseq      :       1.091 micros/op 916590 ops/sec; 8965.1 MB/s
readseq      :       1.109 micros/op 901713 ops/sec; 8819.6 MB/s
[master]
readseq      :      27.257 micros/op 36687 ops/sec;  358.8 MB/s
readseq      :       4.443 micros/op 225073 ops/sec; 2201.4 MB/s
readseq      :       5.830 micros/op 171526 ops/sec; 1677.7 MB/s
readseq      :       4.173 micros/op 239635 ops/sec; 2343.8 MB/s
readseq      :       4.150 micros/op 240963 ops/sec; 2356.8 MB/s
```
Test Plan: COMPILE_WITH_ASAN=1 make check -j64
Reviewers: yhchiang, andrewkr, sdong
Reviewed By: sdong
Subscribers: lovro, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57075/"
rocksdb,"Experiments on column-aware encodings
Summary:
Experiments on column-aware encodings. Supported features: 1) extract data blocks from SST file and encode with specified encodings; 2) Decode encoded data back into row format; 3) Directly extract data blocks and write in row format (without prefix encoding); 4) Get column distribution statistics for column format; 5) Dump data blocks separated by columns in human-readable format.
There is still on-going work on this diff. More refactoring is necessary.
Test Plan: Wrote tests in `column_aware_encoding_test.cc`. More tests should be added.
Reviewers: sdong
Reviewed By: sdong
Subscribers: arahut, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D60027/New Statistics to track Compression/Decompression (#1197)
* Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer).
* Prevent incrementing compression counter when compression is turned off in options.
* Prevent incrementing compression counter when compression is turned off in options.
* Added two more supported compression types to test code in db_test.cc
* Prevent incrementing compression counter when compression is turned off in options.
* Added new StatsLevel that excludes compression timing.
* Fixed casting error in coding.h
* Fixed CompressionStatsTest for new StatsLevel.
* Removed unused variable that was breaking the Linux build/Miscellaneous performance improvements
Summary:
I was investigating performance issues in the SstFileWriter and found all of the following:
- The SstFileWriter::Add() function created a local InternalKey every time it was called generating a allocation and free each time.  Changed to have an InternalKey member variable that can be reset with the new InternalKey::Set() function.
- In SstFileWriter::Add() the smallest_key and largest_key values were assigned the result of a ToString() call, but it is simpler to just assign them directly from the user's key.
- The Slice class had no move constructor so each time one was returned from a function a new one had to be allocated, the old data copied to the new, and the old one was freed.  I added the move constructor which also required a copy constructor and assignment operator.
- The BlockBuilder::CurrentSizeEstimate() function calculates the current estimate size, but was being called 2 or 3 times for each key added.  I changed the class to maintain a running estimate (equal to the original calculation) so that the function can return an already calculated value.
- The code in BlockBuilder::Add() that calculated the shared bytes between the last key and the new key duplicated what Slice::difference_offset does, so I replaced it with the standard function.
- BlockBuilder::Add() had code to copy just the changed portion into the last key value (and asserted that it now matched the new key).  It is more efficient just to copy the whole new key over.
- Moved this same code up into the 'if (use_delta_encoding_)' since the last key value is only needed when delta encoding is on.
- FlushBlockBySizePolicy::BlockAlmostFull calculated a standard deviation value each time it was called, but this information would only change if block_size of block_size_deviation changed, so I created a member variable to hold the value to avoid the calculation each time.
- Each PutVarint??() function has a buffer and calls std::string::append().  Two or three calls in a row could share a buffer and a single call to std::string::append().
Some of these will be helpful outside of the SstFileWriter.  I'm not 100% the addition of the move constructor is appropriate as I wonder why this wasn't done before - maybe because of compiler compatibility?  I tried it on gcc 4.8 and 4.9.
Test Plan: The changes should not affect the results so the existing tests should all still work and no new tests were added.  The value of the changes was seen by manually testing the SstFileWriter class through MyRocks and adding timing code to identify problem areas.
Reviewers: sdong, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D59607/Add a check mode to verify compressed block can be decompressed back
Summary:
Try to decompress compressed blocks when a special flag is set.
assert and crash in debug builds if we can't decompress the just-compressed input.
Test Plan: Run unit-tests.
Reviewers: dhruba, andrewkr, sdong, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D59145/"
rocksdb,"Miscellaneous performance improvements
Summary:
I was investigating performance issues in the SstFileWriter and found all of the following:
- The SstFileWriter::Add() function created a local InternalKey every time it was called generating a allocation and free each time.  Changed to have an InternalKey member variable that can be reset with the new InternalKey::Set() function.
- In SstFileWriter::Add() the smallest_key and largest_key values were assigned the result of a ToString() call, but it is simpler to just assign them directly from the user's key.
- The Slice class had no move constructor so each time one was returned from a function a new one had to be allocated, the old data copied to the new, and the old one was freed.  I added the move constructor which also required a copy constructor and assignment operator.
- The BlockBuilder::CurrentSizeEstimate() function calculates the current estimate size, but was being called 2 or 3 times for each key added.  I changed the class to maintain a running estimate (equal to the original calculation) so that the function can return an already calculated value.
- The code in BlockBuilder::Add() that calculated the shared bytes between the last key and the new key duplicated what Slice::difference_offset does, so I replaced it with the standard function.
- BlockBuilder::Add() had code to copy just the changed portion into the last key value (and asserted that it now matched the new key).  It is more efficient just to copy the whole new key over.
- Moved this same code up into the 'if (use_delta_encoding_)' since the last key value is only needed when delta encoding is on.
- FlushBlockBySizePolicy::BlockAlmostFull calculated a standard deviation value each time it was called, but this information would only change if block_size of block_size_deviation changed, so I created a member variable to hold the value to avoid the calculation each time.
- Each PutVarint??() function has a buffer and calls std::string::append().  Two or three calls in a row could share a buffer and a single call to std::string::append().
Some of these will be helpful outside of the SstFileWriter.  I'm not 100% the addition of the move constructor is appropriate as I wonder why this wasn't done before - maybe because of compiler compatibility?  I tried it on gcc 4.8 and 4.9.
Test Plan: The changes should not affect the results so the existing tests should all still work and no new tests were added.  The value of the changes was seen by manually testing the SstFileWriter class through MyRocks and adding timing code to identify problem areas.
Reviewers: sdong, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D59607/[rocksdb] make more options dynamic
Summary:
make more ColumnFamilyOptions dynamic:
- compression
- soft_pending_compaction_bytes_limit
- hard_pending_compaction_bytes_limit
- min_partial_merge_operands
- report_bg_io_stats
- paranoid_file_checks
Test Plan:
Add sanity check in `db_test.cc` for all above options except for soft_pending_compaction_bytes_limit and hard_pending_compaction_bytes_limit.
All passed.
Reviewers: andrewkr, sdong, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D57519/"
rocksdb,"New Statistics to track Compression/Decompression (#1197)
* Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer).
* Prevent incrementing compression counter when compression is turned off in options.
* Prevent incrementing compression counter when compression is turned off in options.
* Added two more supported compression types to test code in db_test.cc
* Prevent incrementing compression counter when compression is turned off in options.
* Added new StatsLevel that excludes compression timing.
* Fixed casting error in coding.h
* Fixed CompressionStatsTest for new StatsLevel.
* Removed unused variable that was breaking the Linux build/"
rocksdb,"Experiments on column-aware encodings
Summary:
Experiments on column-aware encodings. Supported features: 1) extract data blocks from SST file and encode with specified encodings; 2) Decode encoded data back into row format; 3) Directly extract data blocks and write in row format (without prefix encoding); 4) Get column distribution statistics for column format; 5) Dump data blocks separated by columns in human-readable format.
There is still on-going work on this diff. More refactoring is necessary.
Test Plan: Wrote tests in `column_aware_encoding_test.cc`. More tests should be added.
Reviewers: sdong
Reviewed By: sdong
Subscribers: arahut, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D60027/Introduce FullMergeV2 (eliminate memcpy from merge operators)
Summary:
This diff update the code to pin the merge operator operands while the merge operation is done, so that we can eliminate the memcpy cost, to do that we need a new public API for FullMerge that replace the std::deque<std::string> with std::vector<Slice>
This diff is stacked on top of D56493 and D56511
In this diff we
- Update FullMergeV2 arguments to be encapsulated in MergeOperationInput and MergeOperationOutput which will make it easier to add new arguments in the future
- Replace std::deque<std::string> with std::vector<Slice> to pass operands
- Replace MergeContext std::deque with std::vector (based on a simple benchmark I ran https://gist.github.com/IslamAbdelRahman/78fc86c9ab9f52b1df791e58943fb187)
- Allow FullMergeV2 output to be an existing operand
```
[Everything in Memtable | 10K operands | 10 KB each | 1 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=10000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       0.607 micros/op 1648235 ops/sec; 16121.2 MB/s
readseq      :       0.478 micros/op 2091546 ops/sec; 20457.2 MB/s
readseq      :       0.252 micros/op 3972081 ops/sec; 38850.5 MB/s
readseq      :       0.237 micros/op 4218328 ops/sec; 41259.0 MB/s
readseq      :       0.247 micros/op 4043927 ops/sec; 39553.2 MB/s
[master]
readseq      :       3.935 micros/op 254140 ops/sec; 2485.7 MB/s
readseq      :       3.722 micros/op 268657 ops/sec; 2627.7 MB/s
readseq      :       3.149 micros/op 317605 ops/sec; 3106.5 MB/s
readseq      :       3.125 micros/op 320024 ops/sec; 3130.1 MB/s
readseq      :       4.075 micros/op 245374 ops/sec; 2400.0 MB/s
```
```
[Everything in Memtable | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=1000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       3.472 micros/op 288018 ops/sec; 2817.1 MB/s
readseq      :       2.304 micros/op 434027 ops/sec; 4245.2 MB/s
readseq      :       1.163 micros/op 859845 ops/sec; 8410.0 MB/s
readseq      :       1.192 micros/op 838926 ops/sec; 8205.4 MB/s
readseq      :       1.250 micros/op 800000 ops/sec; 7824.7 MB/s
[master]
readseq      :      24.025 micros/op 41623 ops/sec;  407.1 MB/s
readseq      :      18.489 micros/op 54086 ops/sec;  529.0 MB/s
readseq      :      18.693 micros/op 53495 ops/sec;  523.2 MB/s
readseq      :      23.621 micros/op 42335 ops/sec;  414.1 MB/s
readseq      :      18.775 micros/op 53262 ops/sec;  521.0 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 1 operand per key]
[FullMergeV2]
$ DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
readseq      :      14.741 micros/op 67837 ops/sec;  663.5 MB/s
readseq      :       1.029 micros/op 971446 ops/sec; 9501.6 MB/s
readseq      :       0.974 micros/op 1026229 ops/sec; 10037.4 MB/s
readseq      :       0.965 micros/op 1036080 ops/sec; 10133.8 MB/s
readseq      :       0.943 micros/op 1060657 ops/sec; 10374.2 MB/s
[master]
readseq      :      16.735 micros/op 59755 ops/sec;  584.5 MB/s
readseq      :       3.029 micros/op 330151 ops/sec; 3229.2 MB/s
readseq      :       3.136 micros/op 318883 ops/sec; 3119.0 MB/s
readseq      :       3.065 micros/op 326245 ops/sec; 3191.0 MB/s
readseq      :       3.014 micros/op 331813 ops/sec; 3245.4 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10-operands-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
[FullMergeV2]
readseq      :      24.325 micros/op 41109 ops/sec;  402.1 MB/s
readseq      :       1.470 micros/op 680272 ops/sec; 6653.7 MB/s
readseq      :       1.231 micros/op 812347 ops/sec; 7945.5 MB/s
readseq      :       1.091 micros/op 916590 ops/sec; 8965.1 MB/s
readseq      :       1.109 micros/op 901713 ops/sec; 8819.6 MB/s
[master]
readseq      :      27.257 micros/op 36687 ops/sec;  358.8 MB/s
readseq      :       4.443 micros/op 225073 ops/sec; 2201.4 MB/s
readseq      :       5.830 micros/op 171526 ops/sec; 1677.7 MB/s
readseq      :       4.173 micros/op 239635 ops/sec; 2343.8 MB/s
readseq      :       4.150 micros/op 240963 ops/sec; 2356.8 MB/s
```
Test Plan: COMPILE_WITH_ASAN=1 make check -j64
Reviewers: yhchiang, andrewkr, sdong
Reviewed By: sdong
Subscribers: lovro, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57075/New Statistics to track Compression/Decompression (#1197)
* Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer).
* Prevent incrementing compression counter when compression is turned off in options.
* Prevent incrementing compression counter when compression is turned off in options.
* Added two more supported compression types to test code in db_test.cc
* Prevent incrementing compression counter when compression is turned off in options.
* Added new StatsLevel that excludes compression timing.
* Fixed casting error in coding.h
* Fixed CompressionStatsTest for new StatsLevel.
* Removed unused variable that was breaking the Linux build/Fix clang analyzer errors
Summary:
Fixing erros reported by clang static analyzer.
* Removing some unused variables.
* Adding assertions to fix false positives reported by clang analyzer.
* Adding `__clang_analyzer__` macro to suppress false positive warnings.
Test Plan:
USE_CLANG=1 OPT=-g make analyze -j64
Reviewers: andrewkr, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D60549/BlockBasedTable::FullFilterKeyMayMatch() Should skip prefix bloom if full key bloom exists
Summary: Currently, if users define both of full key bloom and prefix bloom in SST files. During Get(), if full key bloom shows the key may exist, we still go ahead and check prefix bloom. This is wasteful. If bloom filter for full keys exists, we should always ignore prefix bloom in Get().
Test Plan: Run existing tests
Reviewers: yhchiang, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57825/Add statistics field to show total size of index and filter blocks in block cache
Summary: With `table_options.cache_index_and_filter_blocks = true`, index and filter blocks are stored in block cache. Then people are curious how much of the block cache total size is used by indexes and bloom filters. It will be nice we have a way to report that. It can help people tune performance and plan for optimized hardware setting. We add several enum values for db Statistics. BLOCK_CACHE_INDEX/FILTER_BYTES_INSERT - BLOCK_CACHE_INDEX/FILTER_BYTES_ERASE = current INDEX/FILTER total block size in bytes.
Test Plan:
write a test case called `DBBlockCacheTest.IndexAndFilterBlocksStats`. The result is:
```
[gzh@dev9927.prn1 ~/local/rocksdb]  make db_block_cache_test -j64 && ./db_block_cache_test --gtest_filter=DBBlockCacheTest.IndexAndFilterBlocksStats
Makefile:101: Warning: Compiling in debug mode. Don't use the resulting binary in production
GEN      util/build_version.cc
make: `db_block_cache_test' is up to date.
Note: Google Test filter = DBBlockCacheTest.IndexAndFilterBlocksStats
[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from DBBlockCacheTest
[ RUN      ] DBBlockCacheTest.IndexAndFilterBlocksStats
[       OK ] DBBlockCacheTest.IndexAndFilterBlocksStats (689 ms)
[----------] 1 test from DBBlockCacheTest (689 ms total)
[----------] Global test environment tear-down
[==========] 1 test from 1 test case ran. (689 ms total)
[  PASSED  ] 1 test.
```
Reviewers: IslamAbdelRahman, andrewkr, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D58677/"
rocksdb,"New Statistics to track Compression/Decompression (#1197)
* Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer).
* Prevent incrementing compression counter when compression is turned off in options.
* Prevent incrementing compression counter when compression is turned off in options.
* Added two more supported compression types to test code in db_test.cc
* Prevent incrementing compression counter when compression is turned off in options.
* Added new StatsLevel that excludes compression timing.
* Fixed casting error in coding.h
* Fixed CompressionStatsTest for new StatsLevel.
* Removed unused variable that was breaking the Linux build/"
rocksdb,"New Statistics to track Compression/Decompression (#1197)
* Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer).
* Prevent incrementing compression counter when compression is turned off in options.
* Prevent incrementing compression counter when compression is turned off in options.
* Added two more supported compression types to test code in db_test.cc
* Prevent incrementing compression counter when compression is turned off in options.
* Added new StatsLevel that excludes compression timing.
* Fixed casting error in coding.h
* Fixed CompressionStatsTest for new StatsLevel.
* Removed unused variable that was breaking the Linux build/"
rocksdb,"New Statistics to track Compression/Decompression (#1197)
* Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer).
* Prevent incrementing compression counter when compression is turned off in options.
* Prevent incrementing compression counter when compression is turned off in options.
* Added two more supported compression types to test code in db_test.cc
* Prevent incrementing compression counter when compression is turned off in options.
* Added new StatsLevel that excludes compression timing.
* Fixed casting error in coding.h
* Fixed CompressionStatsTest for new StatsLevel.
* Removed unused variable that was breaking the Linux build/Miscellaneous performance improvements
Summary:
I was investigating performance issues in the SstFileWriter and found all of the following:
- The SstFileWriter::Add() function created a local InternalKey every time it was called generating a allocation and free each time.  Changed to have an InternalKey member variable that can be reset with the new InternalKey::Set() function.
- In SstFileWriter::Add() the smallest_key and largest_key values were assigned the result of a ToString() call, but it is simpler to just assign them directly from the user's key.
- The Slice class had no move constructor so each time one was returned from a function a new one had to be allocated, the old data copied to the new, and the old one was freed.  I added the move constructor which also required a copy constructor and assignment operator.
- The BlockBuilder::CurrentSizeEstimate() function calculates the current estimate size, but was being called 2 or 3 times for each key added.  I changed the class to maintain a running estimate (equal to the original calculation) so that the function can return an already calculated value.
- The code in BlockBuilder::Add() that calculated the shared bytes between the last key and the new key duplicated what Slice::difference_offset does, so I replaced it with the standard function.
- BlockBuilder::Add() had code to copy just the changed portion into the last key value (and asserted that it now matched the new key).  It is more efficient just to copy the whole new key over.
- Moved this same code up into the 'if (use_delta_encoding_)' since the last key value is only needed when delta encoding is on.
- FlushBlockBySizePolicy::BlockAlmostFull calculated a standard deviation value each time it was called, but this information would only change if block_size of block_size_deviation changed, so I created a member variable to hold the value to avoid the calculation each time.
- Each PutVarint??() function has a buffer and calls std::string::append().  Two or three calls in a row could share a buffer and a single call to std::string::append().
Some of these will be helpful outside of the SstFileWriter.  I'm not 100% the addition of the move constructor is appropriate as I wonder why this wasn't done before - maybe because of compiler compatibility?  I tried it on gcc 4.8 and 4.9.
Test Plan: The changes should not affect the results so the existing tests should all still work and no new tests were added.  The value of the changes was seen by manually testing the SstFileWriter class through MyRocks and adding timing code to identify problem areas.
Reviewers: sdong, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D59607/Add a check mode to verify compressed block can be decompressed back
Summary:
Try to decompress compressed blocks when a special flag is set.
assert and crash in debug builds if we can't decompress the just-compressed input.
Test Plan: Run unit-tests.
Reviewers: dhruba, andrewkr, sdong, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D59145/"
rocksdb,"New Statistics to track Compression/Decompression (#1197)
* Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer).
* Prevent incrementing compression counter when compression is turned off in options.
* Prevent incrementing compression counter when compression is turned off in options.
* Added two more supported compression types to test code in db_test.cc
* Prevent incrementing compression counter when compression is turned off in options.
* Added new StatsLevel that excludes compression timing.
* Fixed casting error in coding.h
* Fixed CompressionStatsTest for new StatsLevel.
* Removed unused variable that was breaking the Linux build/Fix clang analyzer errors
Summary:
Fixing erros reported by clang static analyzer.
* Removing some unused variables.
* Adding assertions to fix false positives reported by clang analyzer.
* Adding `__clang_analyzer__` macro to suppress false positive warnings.
Test Plan:
USE_CLANG=1 OPT=-g make analyze -j64
Reviewers: andrewkr, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D60549/"
rocksdb,"Introduce FullMergeV2 (eliminate memcpy from merge operators)
Summary:
This diff update the code to pin the merge operator operands while the merge operation is done, so that we can eliminate the memcpy cost, to do that we need a new public API for FullMerge that replace the std::deque<std::string> with std::vector<Slice>
This diff is stacked on top of D56493 and D56511
In this diff we
- Update FullMergeV2 arguments to be encapsulated in MergeOperationInput and MergeOperationOutput which will make it easier to add new arguments in the future
- Replace std::deque<std::string> with std::vector<Slice> to pass operands
- Replace MergeContext std::deque with std::vector (based on a simple benchmark I ran https://gist.github.com/IslamAbdelRahman/78fc86c9ab9f52b1df791e58943fb187)
- Allow FullMergeV2 output to be an existing operand
```
[Everything in Memtable | 10K operands | 10 KB each | 1 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=10000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       0.607 micros/op 1648235 ops/sec; 16121.2 MB/s
readseq      :       0.478 micros/op 2091546 ops/sec; 20457.2 MB/s
readseq      :       0.252 micros/op 3972081 ops/sec; 38850.5 MB/s
readseq      :       0.237 micros/op 4218328 ops/sec; 41259.0 MB/s
readseq      :       0.247 micros/op 4043927 ops/sec; 39553.2 MB/s
[master]
readseq      :       3.935 micros/op 254140 ops/sec; 2485.7 MB/s
readseq      :       3.722 micros/op 268657 ops/sec; 2627.7 MB/s
readseq      :       3.149 micros/op 317605 ops/sec; 3106.5 MB/s
readseq      :       3.125 micros/op 320024 ops/sec; 3130.1 MB/s
readseq      :       4.075 micros/op 245374 ops/sec; 2400.0 MB/s
```
```
[Everything in Memtable | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=1000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       3.472 micros/op 288018 ops/sec; 2817.1 MB/s
readseq      :       2.304 micros/op 434027 ops/sec; 4245.2 MB/s
readseq      :       1.163 micros/op 859845 ops/sec; 8410.0 MB/s
readseq      :       1.192 micros/op 838926 ops/sec; 8205.4 MB/s
readseq      :       1.250 micros/op 800000 ops/sec; 7824.7 MB/s
[master]
readseq      :      24.025 micros/op 41623 ops/sec;  407.1 MB/s
readseq      :      18.489 micros/op 54086 ops/sec;  529.0 MB/s
readseq      :      18.693 micros/op 53495 ops/sec;  523.2 MB/s
readseq      :      23.621 micros/op 42335 ops/sec;  414.1 MB/s
readseq      :      18.775 micros/op 53262 ops/sec;  521.0 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 1 operand per key]
[FullMergeV2]
$ DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
readseq      :      14.741 micros/op 67837 ops/sec;  663.5 MB/s
readseq      :       1.029 micros/op 971446 ops/sec; 9501.6 MB/s
readseq      :       0.974 micros/op 1026229 ops/sec; 10037.4 MB/s
readseq      :       0.965 micros/op 1036080 ops/sec; 10133.8 MB/s
readseq      :       0.943 micros/op 1060657 ops/sec; 10374.2 MB/s
[master]
readseq      :      16.735 micros/op 59755 ops/sec;  584.5 MB/s
readseq      :       3.029 micros/op 330151 ops/sec; 3229.2 MB/s
readseq      :       3.136 micros/op 318883 ops/sec; 3119.0 MB/s
readseq      :       3.065 micros/op 326245 ops/sec; 3191.0 MB/s
readseq      :       3.014 micros/op 331813 ops/sec; 3245.4 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10-operands-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
[FullMergeV2]
readseq      :      24.325 micros/op 41109 ops/sec;  402.1 MB/s
readseq      :       1.470 micros/op 680272 ops/sec; 6653.7 MB/s
readseq      :       1.231 micros/op 812347 ops/sec; 7945.5 MB/s
readseq      :       1.091 micros/op 916590 ops/sec; 8965.1 MB/s
readseq      :       1.109 micros/op 901713 ops/sec; 8819.6 MB/s
[master]
readseq      :      27.257 micros/op 36687 ops/sec;  358.8 MB/s
readseq      :       4.443 micros/op 225073 ops/sec; 2201.4 MB/s
readseq      :       5.830 micros/op 171526 ops/sec; 1677.7 MB/s
readseq      :       4.173 micros/op 239635 ops/sec; 2343.8 MB/s
readseq      :       4.150 micros/op 240963 ops/sec; 2356.8 MB/s
```
Test Plan: COMPILE_WITH_ASAN=1 make check -j64
Reviewers: yhchiang, andrewkr, sdong
Reviewed By: sdong
Subscribers: lovro, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57075/"
rocksdb,"New Statistics to track Compression/Decompression (#1197)
* Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer).
* Prevent incrementing compression counter when compression is turned off in options.
* Prevent incrementing compression counter when compression is turned off in options.
* Added two more supported compression types to test code in db_test.cc
* Prevent incrementing compression counter when compression is turned off in options.
* Added new StatsLevel that excludes compression timing.
* Fixed casting error in coding.h
* Fixed CompressionStatsTest for new StatsLevel.
* Removed unused variable that was breaking the Linux build/Added ""number of merge operands"" to statistics in ssts.
Summary:
A couple of notes from the diff:
- The namespace block I added at the top of table_properties_collector.cc was in reaction to an issue i was having with PutVarint64 and reusing the ""val"" string.  I'm not sure this is the cleanest way of doing this, but abstracting this out at least results in the correct behavior.
- I chose ""rocksdb.merge.operands"" as the property name.  I am open to suggestions for better names.
- The change to sst_dump_tool.cc seems a bit inelegant to me.  Is there a better way to do the if-else block?
Test Plan:
I added a test case in table_properties_collector_test.cc.  It adds two merge operands and checks to make sure that both of them are reflected by GetMergeOperands.  It also checks to make sure the wasPropertyPresent bool is properly set in the method.
Running both of these tests should pass:
./table_properties_collector_test
./sst_dump_test
Reviewers: IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D58119/"
rocksdb,"Ignore stale logs while restarting DBs
Summary:
Stale log files can be deleted out of order. This can happen for various reasons. One of the reason is that no data is ever inserted to a column family and we have an optimization to update its log number, but not all the old log files are cleaned up (the case shown in the unit tests added). It can also happen when we simply delete multiple log files out of order.
This causes data corruption because we simply increase seqID after processing the next row and we may end up with writing data with smaller seqID than what is already flushed to memtables.
In DB recovery, for the oldest files we are replaying, if there it contains no data for any column family, we ignore the sequence IDs in the file.
Test Plan: Add two unit tests that fail without the fix.
Reviewers: IslamAbdelRahman, igor, yiwu
Reviewed By: yiwu
Subscribers: hermanlee4, yoshinorim, leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D60891/Need to make sure log file synced before flushing memtable of one column family
Summary: Multiput atomiciy is broken across multiple column families if we don't sync WAL before flushing one column family. The WAL file may contain a write batch containing writes to a key to the CF to be flushed and a key to other CF. If we don't sync WAL before flushing, if machine crashes after flushing, the write batch will only be partial recovered. Data to other CFs are lost.
Test Plan: Add a new unit test which will fail without the diff.
Reviewers: yhchiang, IslamAbdelRahman, igor, yiwu
Reviewed By: yiwu
Subscribers: yiwu, leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D60915/Fix deadlock when trying update options when write stalls
Summary:
When write stalls because of auto compaction is disabled, or stop write trigger is reached,
user may change these two options to unblock writes. Unfortunately we had issue where the write
thread will block the attempt to persist the options, thus creating a deadlock. This diff
fix the issue and add two test cases to detect such deadlock.
Test Plan:
Run unit tests.
Also, revert db_impl.cc to master (but don't revert `DBImpl::BackgroundCompaction:Finish` sync point) and run db_options_test. Both tests should hit deadlock.
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D60627/Add More Logging to track total_log_size
Summary: We saw instances where total_log_size is off the real value, but I'm not able to reproduce it. Add more logging to help debugging when it happens again.
Test Plan: Run the unit test and see the logging.
Reviewers: andrewkr, yhchiang, igor, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D60081/Fix a bug that accesses invalid address in iterator cleanup function
Summary: Reported in T11889874. When registering the cleanup function we should copy the option so that we can still access it if ReadOptions is deleted.
Test Plan: Add a unit test to reproduce this bug.
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D60087/Add a read option to enable background purge when cleaning up iterators
Summary:
Add a read option `background_purge_on_iterator_cleanup` to avoid deleting files in foreground when destroying iterators.
Instead, a job is scheduled in high priority queue and would be executed in a separate background thread.
Test Plan: Add a variant of PurgeObsoleteFileTest. Turn on background purge option in the new test, and use sleeping task to ensure files are deleted in background.
Reviewers: IslamAbdelRahman, sdong
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D59499/Fix race condition in SwitchMemtable
Summary:
MemTableList::current_ could be written by background flush thread and
simultaneously read in the user thread (NumNotFlushed() is used in
SwitchMemtable()). Use the lock to prevent this case. Found the error from tsan.
Related: D58833
Test Plan:
$ OPT=-g COMPILE_WITH_TSAN=1 make -j64 db_test
$ TEST_TMPDIR=/dev/shm/rocksdb ./db_test --gtest_filter=DBTest.RepeatedWritesToSameKey
Reviewers: lightmark, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D59139/Add a callback for when memtable is moved to immutable (#1137)
* Create a callback for memtable becoming immutable
Create a callback for memtable becoming immutable
Create a callback for memtable becoming immutable
moved notification outside the lock
Move sealed notification to unlocked portion of SwitchMemtable
* fix lite build/Fix mutex unlock issue between scheduled compaction and ReleaseCompactionFiles()
Summary:
NotifyOnCompactionCompleted can unlock the mutex.
That mean that we can schedule a background compaction that will start before we ReleaseCompactionFiles().
Test Plan:
added unittest
existing unittest
Reviewers: yhchiang, sdong
Reviewed By: sdong
Subscribers: yoshinorim, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D58065/[rocksdb] make more options dynamic
Summary:
make more ColumnFamilyOptions dynamic:
- compression
- soft_pending_compaction_bytes_limit
- hard_pending_compaction_bytes_limit
- min_partial_merge_operands
- report_bg_io_stats
- paranoid_file_checks
Test Plan:
Add sanity check in `db_test.cc` for all above options except for soft_pending_compaction_bytes_limit and hard_pending_compaction_bytes_limit.
All passed.
Reviewers: andrewkr, sdong, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D57519/Fix Transaction memory leak
Summary:
- Make sure we clean up recovered_transactions_ on DBImpl destructor
- delete leaked txns and env in TransactionTest
Test Plan: Run transaction_test under valgrind
Reviewers: sdong, andrewkr, yhchiang, horuff
Reviewed By: horuff
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D58263/"
rocksdb,"Introduce FullMergeV2 (eliminate memcpy from merge operators)
Summary:
This diff update the code to pin the merge operator operands while the merge operation is done, so that we can eliminate the memcpy cost, to do that we need a new public API for FullMerge that replace the std::deque<std::string> with std::vector<Slice>
This diff is stacked on top of D56493 and D56511
In this diff we
- Update FullMergeV2 arguments to be encapsulated in MergeOperationInput and MergeOperationOutput which will make it easier to add new arguments in the future
- Replace std::deque<std::string> with std::vector<Slice> to pass operands
- Replace MergeContext std::deque with std::vector (based on a simple benchmark I ran https://gist.github.com/IslamAbdelRahman/78fc86c9ab9f52b1df791e58943fb187)
- Allow FullMergeV2 output to be an existing operand
```
[Everything in Memtable | 10K operands | 10 KB each | 1 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=10000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       0.607 micros/op 1648235 ops/sec; 16121.2 MB/s
readseq      :       0.478 micros/op 2091546 ops/sec; 20457.2 MB/s
readseq      :       0.252 micros/op 3972081 ops/sec; 38850.5 MB/s
readseq      :       0.237 micros/op 4218328 ops/sec; 41259.0 MB/s
readseq      :       0.247 micros/op 4043927 ops/sec; 39553.2 MB/s
[master]
readseq      :       3.935 micros/op 254140 ops/sec; 2485.7 MB/s
readseq      :       3.722 micros/op 268657 ops/sec; 2627.7 MB/s
readseq      :       3.149 micros/op 317605 ops/sec; 3106.5 MB/s
readseq      :       3.125 micros/op 320024 ops/sec; 3130.1 MB/s
readseq      :       4.075 micros/op 245374 ops/sec; 2400.0 MB/s
```
```
[Everything in Memtable | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=1000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       3.472 micros/op 288018 ops/sec; 2817.1 MB/s
readseq      :       2.304 micros/op 434027 ops/sec; 4245.2 MB/s
readseq      :       1.163 micros/op 859845 ops/sec; 8410.0 MB/s
readseq      :       1.192 micros/op 838926 ops/sec; 8205.4 MB/s
readseq      :       1.250 micros/op 800000 ops/sec; 7824.7 MB/s
[master]
readseq      :      24.025 micros/op 41623 ops/sec;  407.1 MB/s
readseq      :      18.489 micros/op 54086 ops/sec;  529.0 MB/s
readseq      :      18.693 micros/op 53495 ops/sec;  523.2 MB/s
readseq      :      23.621 micros/op 42335 ops/sec;  414.1 MB/s
readseq      :      18.775 micros/op 53262 ops/sec;  521.0 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 1 operand per key]
[FullMergeV2]
$ DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
readseq      :      14.741 micros/op 67837 ops/sec;  663.5 MB/s
readseq      :       1.029 micros/op 971446 ops/sec; 9501.6 MB/s
readseq      :       0.974 micros/op 1026229 ops/sec; 10037.4 MB/s
readseq      :       0.965 micros/op 1036080 ops/sec; 10133.8 MB/s
readseq      :       0.943 micros/op 1060657 ops/sec; 10374.2 MB/s
[master]
readseq      :      16.735 micros/op 59755 ops/sec;  584.5 MB/s
readseq      :       3.029 micros/op 330151 ops/sec; 3229.2 MB/s
readseq      :       3.136 micros/op 318883 ops/sec; 3119.0 MB/s
readseq      :       3.065 micros/op 326245 ops/sec; 3191.0 MB/s
readseq      :       3.014 micros/op 331813 ops/sec; 3245.4 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10-operands-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
[FullMergeV2]
readseq      :      24.325 micros/op 41109 ops/sec;  402.1 MB/s
readseq      :       1.470 micros/op 680272 ops/sec; 6653.7 MB/s
readseq      :       1.231 micros/op 812347 ops/sec; 7945.5 MB/s
readseq      :       1.091 micros/op 916590 ops/sec; 8965.1 MB/s
readseq      :       1.109 micros/op 901713 ops/sec; 8819.6 MB/s
[master]
readseq      :      27.257 micros/op 36687 ops/sec;  358.8 MB/s
readseq      :       4.443 micros/op 225073 ops/sec; 2201.4 MB/s
readseq      :       5.830 micros/op 171526 ops/sec; 1677.7 MB/s
readseq      :       4.173 micros/op 239635 ops/sec; 2343.8 MB/s
readseq      :       4.150 micros/op 240963 ops/sec; 2356.8 MB/s
```
Test Plan: COMPILE_WITH_ASAN=1 make check -j64
Reviewers: yhchiang, andrewkr, sdong
Reviewed By: sdong
Subscribers: lovro, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57075/Fix mutex unlock issue between scheduled compaction and ReleaseCompactionFiles()
Summary:
NotifyOnCompactionCompleted can unlock the mutex.
That mean that we can schedule a background compaction that will start before we ReleaseCompactionFiles().
Test Plan:
added unittest
existing unittest
Reviewers: yhchiang, sdong
Reviewed By: sdong
Subscribers: yoshinorim, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D58065/"
rocksdb,"UniversalCompaction should ignore sorted runs being compacted (when compacting for file num)
Summary:
If we have total number of sorted runs greater than level0_file_num_compaction_trigger, Universal compaction will always issue a compaction
even if the number of sorted runs that are not being compacted is less than level0_file_num_compaction_trigger.
This diff changes this behaviour to relay on the `number of sorted runs not being compacted` instead of `total number of sorted runs`
Test Plan: New unit test
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D61533/Introduce FullMergeV2 (eliminate memcpy from merge operators)
Summary:
This diff update the code to pin the merge operator operands while the merge operation is done, so that we can eliminate the memcpy cost, to do that we need a new public API for FullMerge that replace the std::deque<std::string> with std::vector<Slice>
This diff is stacked on top of D56493 and D56511
In this diff we
- Update FullMergeV2 arguments to be encapsulated in MergeOperationInput and MergeOperationOutput which will make it easier to add new arguments in the future
- Replace std::deque<std::string> with std::vector<Slice> to pass operands
- Replace MergeContext std::deque with std::vector (based on a simple benchmark I ran https://gist.github.com/IslamAbdelRahman/78fc86c9ab9f52b1df791e58943fb187)
- Allow FullMergeV2 output to be an existing operand
```
[Everything in Memtable | 10K operands | 10 KB each | 1 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=10000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       0.607 micros/op 1648235 ops/sec; 16121.2 MB/s
readseq      :       0.478 micros/op 2091546 ops/sec; 20457.2 MB/s
readseq      :       0.252 micros/op 3972081 ops/sec; 38850.5 MB/s
readseq      :       0.237 micros/op 4218328 ops/sec; 41259.0 MB/s
readseq      :       0.247 micros/op 4043927 ops/sec; 39553.2 MB/s
[master]
readseq      :       3.935 micros/op 254140 ops/sec; 2485.7 MB/s
readseq      :       3.722 micros/op 268657 ops/sec; 2627.7 MB/s
readseq      :       3.149 micros/op 317605 ops/sec; 3106.5 MB/s
readseq      :       3.125 micros/op 320024 ops/sec; 3130.1 MB/s
readseq      :       4.075 micros/op 245374 ops/sec; 2400.0 MB/s
```
```
[Everything in Memtable | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=1000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       3.472 micros/op 288018 ops/sec; 2817.1 MB/s
readseq      :       2.304 micros/op 434027 ops/sec; 4245.2 MB/s
readseq      :       1.163 micros/op 859845 ops/sec; 8410.0 MB/s
readseq      :       1.192 micros/op 838926 ops/sec; 8205.4 MB/s
readseq      :       1.250 micros/op 800000 ops/sec; 7824.7 MB/s
[master]
readseq      :      24.025 micros/op 41623 ops/sec;  407.1 MB/s
readseq      :      18.489 micros/op 54086 ops/sec;  529.0 MB/s
readseq      :      18.693 micros/op 53495 ops/sec;  523.2 MB/s
readseq      :      23.621 micros/op 42335 ops/sec;  414.1 MB/s
readseq      :      18.775 micros/op 53262 ops/sec;  521.0 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 1 operand per key]
[FullMergeV2]
$ DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
readseq      :      14.741 micros/op 67837 ops/sec;  663.5 MB/s
readseq      :       1.029 micros/op 971446 ops/sec; 9501.6 MB/s
readseq      :       0.974 micros/op 1026229 ops/sec; 10037.4 MB/s
readseq      :       0.965 micros/op 1036080 ops/sec; 10133.8 MB/s
readseq      :       0.943 micros/op 1060657 ops/sec; 10374.2 MB/s
[master]
readseq      :      16.735 micros/op 59755 ops/sec;  584.5 MB/s
readseq      :       3.029 micros/op 330151 ops/sec; 3229.2 MB/s
readseq      :       3.136 micros/op 318883 ops/sec; 3119.0 MB/s
readseq      :       3.065 micros/op 326245 ops/sec; 3191.0 MB/s
readseq      :       3.014 micros/op 331813 ops/sec; 3245.4 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10-operands-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
[FullMergeV2]
readseq      :      24.325 micros/op 41109 ops/sec;  402.1 MB/s
readseq      :       1.470 micros/op 680272 ops/sec; 6653.7 MB/s
readseq      :       1.231 micros/op 812347 ops/sec; 7945.5 MB/s
readseq      :       1.091 micros/op 916590 ops/sec; 8965.1 MB/s
readseq      :       1.109 micros/op 901713 ops/sec; 8819.6 MB/s
[master]
readseq      :      27.257 micros/op 36687 ops/sec;  358.8 MB/s
readseq      :       4.443 micros/op 225073 ops/sec; 2201.4 MB/s
readseq      :       5.830 micros/op 171526 ops/sec; 1677.7 MB/s
readseq      :       4.173 micros/op 239635 ops/sec; 2343.8 MB/s
readseq      :       4.150 micros/op 240963 ops/sec; 2356.8 MB/s
```
Test Plan: COMPILE_WITH_ASAN=1 make check -j64
Reviewers: yhchiang, andrewkr, sdong
Reviewed By: sdong
Subscribers: lovro, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57075/"
rocksdb,"Introduce FullMergeV2 (eliminate memcpy from merge operators)
Summary:
This diff update the code to pin the merge operator operands while the merge operation is done, so that we can eliminate the memcpy cost, to do that we need a new public API for FullMerge that replace the std::deque<std::string> with std::vector<Slice>
This diff is stacked on top of D56493 and D56511
In this diff we
- Update FullMergeV2 arguments to be encapsulated in MergeOperationInput and MergeOperationOutput which will make it easier to add new arguments in the future
- Replace std::deque<std::string> with std::vector<Slice> to pass operands
- Replace MergeContext std::deque with std::vector (based on a simple benchmark I ran https://gist.github.com/IslamAbdelRahman/78fc86c9ab9f52b1df791e58943fb187)
- Allow FullMergeV2 output to be an existing operand
```
[Everything in Memtable | 10K operands | 10 KB each | 1 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=10000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       0.607 micros/op 1648235 ops/sec; 16121.2 MB/s
readseq      :       0.478 micros/op 2091546 ops/sec; 20457.2 MB/s
readseq      :       0.252 micros/op 3972081 ops/sec; 38850.5 MB/s
readseq      :       0.237 micros/op 4218328 ops/sec; 41259.0 MB/s
readseq      :       0.247 micros/op 4043927 ops/sec; 39553.2 MB/s
[master]
readseq      :       3.935 micros/op 254140 ops/sec; 2485.7 MB/s
readseq      :       3.722 micros/op 268657 ops/sec; 2627.7 MB/s
readseq      :       3.149 micros/op 317605 ops/sec; 3106.5 MB/s
readseq      :       3.125 micros/op 320024 ops/sec; 3130.1 MB/s
readseq      :       4.075 micros/op 245374 ops/sec; 2400.0 MB/s
```
```
[Everything in Memtable | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=1000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       3.472 micros/op 288018 ops/sec; 2817.1 MB/s
readseq      :       2.304 micros/op 434027 ops/sec; 4245.2 MB/s
readseq      :       1.163 micros/op 859845 ops/sec; 8410.0 MB/s
readseq      :       1.192 micros/op 838926 ops/sec; 8205.4 MB/s
readseq      :       1.250 micros/op 800000 ops/sec; 7824.7 MB/s
[master]
readseq      :      24.025 micros/op 41623 ops/sec;  407.1 MB/s
readseq      :      18.489 micros/op 54086 ops/sec;  529.0 MB/s
readseq      :      18.693 micros/op 53495 ops/sec;  523.2 MB/s
readseq      :      23.621 micros/op 42335 ops/sec;  414.1 MB/s
readseq      :      18.775 micros/op 53262 ops/sec;  521.0 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 1 operand per key]
[FullMergeV2]
$ DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
readseq      :      14.741 micros/op 67837 ops/sec;  663.5 MB/s
readseq      :       1.029 micros/op 971446 ops/sec; 9501.6 MB/s
readseq      :       0.974 micros/op 1026229 ops/sec; 10037.4 MB/s
readseq      :       0.965 micros/op 1036080 ops/sec; 10133.8 MB/s
readseq      :       0.943 micros/op 1060657 ops/sec; 10374.2 MB/s
[master]
readseq      :      16.735 micros/op 59755 ops/sec;  584.5 MB/s
readseq      :       3.029 micros/op 330151 ops/sec; 3229.2 MB/s
readseq      :       3.136 micros/op 318883 ops/sec; 3119.0 MB/s
readseq      :       3.065 micros/op 326245 ops/sec; 3191.0 MB/s
readseq      :       3.014 micros/op 331813 ops/sec; 3245.4 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10-operands-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
[FullMergeV2]
readseq      :      24.325 micros/op 41109 ops/sec;  402.1 MB/s
readseq      :       1.470 micros/op 680272 ops/sec; 6653.7 MB/s
readseq      :       1.231 micros/op 812347 ops/sec; 7945.5 MB/s
readseq      :       1.091 micros/op 916590 ops/sec; 8965.1 MB/s
readseq      :       1.109 micros/op 901713 ops/sec; 8819.6 MB/s
[master]
readseq      :      27.257 micros/op 36687 ops/sec;  358.8 MB/s
readseq      :       4.443 micros/op 225073 ops/sec; 2201.4 MB/s
readseq      :       5.830 micros/op 171526 ops/sec; 1677.7 MB/s
readseq      :       4.173 micros/op 239635 ops/sec; 2343.8 MB/s
readseq      :       4.150 micros/op 240963 ops/sec; 2356.8 MB/s
```
Test Plan: COMPILE_WITH_ASAN=1 make check -j64
Reviewers: yhchiang, andrewkr, sdong
Reviewed By: sdong
Subscribers: lovro, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57075/"
rocksdb,"UniversalCompaction should ignore sorted runs being compacted (when compacting for file num)
Summary:
If we have total number of sorted runs greater than level0_file_num_compaction_trigger, Universal compaction will always issue a compaction
even if the number of sorted runs that are not being compacted is less than level0_file_num_compaction_trigger.
This diff changes this behaviour to relay on the `number of sorted runs not being compacted` instead of `total number of sorted runs`
Test Plan: New unit test
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D61533/Compaction picker to expand output level files for keys cross files' boundary too.
Summary: We may wrongly drop delete operation if we pick a file with the entry to be delete, the put entry of the same user key is in the next file in the level, and the next file is not picked. We expand compaction inputs for output level too.
Test Plan: Add unit tests that reproduct the bug of dropping delete entry. Change compaction_picker_test to assert the new behavior.
Reviewers: IslamAbdelRahman, igor
Reviewed By: igor
Subscribers: leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D61173/[rocksdb] make more options dynamic
Summary:
make more ColumnFamilyOptions dynamic:
- compression
- soft_pending_compaction_bytes_limit
- hard_pending_compaction_bytes_limit
- min_partial_merge_operands
- report_bg_io_stats
- paranoid_file_checks
Test Plan:
Add sanity check in `db_test.cc` for all above options except for soft_pending_compaction_bytes_limit and hard_pending_compaction_bytes_limit.
All passed.
Reviewers: andrewkr, sdong, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D57519/"
rocksdb,"Miscellaneous performance improvements
Summary:
I was investigating performance issues in the SstFileWriter and found all of the following:
- The SstFileWriter::Add() function created a local InternalKey every time it was called generating a allocation and free each time.  Changed to have an InternalKey member variable that can be reset with the new InternalKey::Set() function.
- In SstFileWriter::Add() the smallest_key and largest_key values were assigned the result of a ToString() call, but it is simpler to just assign them directly from the user's key.
- The Slice class had no move constructor so each time one was returned from a function a new one had to be allocated, the old data copied to the new, and the old one was freed.  I added the move constructor which also required a copy constructor and assignment operator.
- The BlockBuilder::CurrentSizeEstimate() function calculates the current estimate size, but was being called 2 or 3 times for each key added.  I changed the class to maintain a running estimate (equal to the original calculation) so that the function can return an already calculated value.
- The code in BlockBuilder::Add() that calculated the shared bytes between the last key and the new key duplicated what Slice::difference_offset does, so I replaced it with the standard function.
- BlockBuilder::Add() had code to copy just the changed portion into the last key value (and asserted that it now matched the new key).  It is more efficient just to copy the whole new key over.
- Moved this same code up into the 'if (use_delta_encoding_)' since the last key value is only needed when delta encoding is on.
- FlushBlockBySizePolicy::BlockAlmostFull calculated a standard deviation value each time it was called, but this information would only change if block_size of block_size_deviation changed, so I created a member variable to hold the value to avoid the calculation each time.
- Each PutVarint??() function has a buffer and calls std::string::append().  Two or three calls in a row could share a buffer and a single call to std::string::append().
Some of these will be helpful outside of the SstFileWriter.  I'm not 100% the addition of the move constructor is appropriate as I wonder why this wasn't done before - maybe because of compiler compatibility?  I tried it on gcc 4.8 and 4.9.
Test Plan: The changes should not affect the results so the existing tests should all still work and no new tests were added.  The value of the changes was seen by manually testing the SstFileWriter class through MyRocks and adding timing code to identify problem areas.
Reviewers: sdong, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D59607/"
rocksdb,"Added ""number of merge operands"" to statistics in ssts.
Summary:
A couple of notes from the diff:
- The namespace block I added at the top of table_properties_collector.cc was in reaction to an issue i was having with PutVarint64 and reusing the ""val"" string.  I'm not sure this is the cleanest way of doing this, but abstracting this out at least results in the correct behavior.
- I chose ""rocksdb.merge.operands"" as the property name.  I am open to suggestions for better names.
- The change to sst_dump_tool.cc seems a bit inelegant to me.  Is there a better way to do the if-else block?
Test Plan:
I added a test case in table_properties_collector_test.cc.  It adds two merge operands and checks to make sure that both of them are reflected by GetMergeOperands.  It also checks to make sure the wasPropertyPresent bool is properly set in the method.
Running both of these tests should pass:
./table_properties_collector_test
./sst_dump_test
Reviewers: IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D58119/"
rocksdb,"Miscellaneous performance improvements
Summary:
I was investigating performance issues in the SstFileWriter and found all of the following:
- The SstFileWriter::Add() function created a local InternalKey every time it was called generating a allocation and free each time.  Changed to have an InternalKey member variable that can be reset with the new InternalKey::Set() function.
- In SstFileWriter::Add() the smallest_key and largest_key values were assigned the result of a ToString() call, but it is simpler to just assign them directly from the user's key.
- The Slice class had no move constructor so each time one was returned from a function a new one had to be allocated, the old data copied to the new, and the old one was freed.  I added the move constructor which also required a copy constructor and assignment operator.
- The BlockBuilder::CurrentSizeEstimate() function calculates the current estimate size, but was being called 2 or 3 times for each key added.  I changed the class to maintain a running estimate (equal to the original calculation) so that the function can return an already calculated value.
- The code in BlockBuilder::Add() that calculated the shared bytes between the last key and the new key duplicated what Slice::difference_offset does, so I replaced it with the standard function.
- BlockBuilder::Add() had code to copy just the changed portion into the last key value (and asserted that it now matched the new key).  It is more efficient just to copy the whole new key over.
- Moved this same code up into the 'if (use_delta_encoding_)' since the last key value is only needed when delta encoding is on.
- FlushBlockBySizePolicy::BlockAlmostFull calculated a standard deviation value each time it was called, but this information would only change if block_size of block_size_deviation changed, so I created a member variable to hold the value to avoid the calculation each time.
- Each PutVarint??() function has a buffer and calls std::string::append().  Two or three calls in a row could share a buffer and a single call to std::string::append().
Some of these will be helpful outside of the SstFileWriter.  I'm not 100% the addition of the move constructor is appropriate as I wonder why this wasn't done before - maybe because of compiler compatibility?  I tried it on gcc 4.8 and 4.9.
Test Plan: The changes should not affect the results so the existing tests should all still work and no new tests were added.  The value of the changes was seen by manually testing the SstFileWriter class through MyRocks and adding timing code to identify problem areas.
Reviewers: sdong, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D59607/"
rocksdb,"Introduce FullMergeV2 (eliminate memcpy from merge operators)
Summary:
This diff update the code to pin the merge operator operands while the merge operation is done, so that we can eliminate the memcpy cost, to do that we need a new public API for FullMerge that replace the std::deque<std::string> with std::vector<Slice>
This diff is stacked on top of D56493 and D56511
In this diff we
- Update FullMergeV2 arguments to be encapsulated in MergeOperationInput and MergeOperationOutput which will make it easier to add new arguments in the future
- Replace std::deque<std::string> with std::vector<Slice> to pass operands
- Replace MergeContext std::deque with std::vector (based on a simple benchmark I ran https://gist.github.com/IslamAbdelRahman/78fc86c9ab9f52b1df791e58943fb187)
- Allow FullMergeV2 output to be an existing operand
```
[Everything in Memtable | 10K operands | 10 KB each | 1 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=10000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       0.607 micros/op 1648235 ops/sec; 16121.2 MB/s
readseq      :       0.478 micros/op 2091546 ops/sec; 20457.2 MB/s
readseq      :       0.252 micros/op 3972081 ops/sec; 38850.5 MB/s
readseq      :       0.237 micros/op 4218328 ops/sec; 41259.0 MB/s
readseq      :       0.247 micros/op 4043927 ops/sec; 39553.2 MB/s
[master]
readseq      :       3.935 micros/op 254140 ops/sec; 2485.7 MB/s
readseq      :       3.722 micros/op 268657 ops/sec; 2627.7 MB/s
readseq      :       3.149 micros/op 317605 ops/sec; 3106.5 MB/s
readseq      :       3.125 micros/op 320024 ops/sec; 3130.1 MB/s
readseq      :       4.075 micros/op 245374 ops/sec; 2400.0 MB/s
```
```
[Everything in Memtable | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=1000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       3.472 micros/op 288018 ops/sec; 2817.1 MB/s
readseq      :       2.304 micros/op 434027 ops/sec; 4245.2 MB/s
readseq      :       1.163 micros/op 859845 ops/sec; 8410.0 MB/s
readseq      :       1.192 micros/op 838926 ops/sec; 8205.4 MB/s
readseq      :       1.250 micros/op 800000 ops/sec; 7824.7 MB/s
[master]
readseq      :      24.025 micros/op 41623 ops/sec;  407.1 MB/s
readseq      :      18.489 micros/op 54086 ops/sec;  529.0 MB/s
readseq      :      18.693 micros/op 53495 ops/sec;  523.2 MB/s
readseq      :      23.621 micros/op 42335 ops/sec;  414.1 MB/s
readseq      :      18.775 micros/op 53262 ops/sec;  521.0 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 1 operand per key]
[FullMergeV2]
$ DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
readseq      :      14.741 micros/op 67837 ops/sec;  663.5 MB/s
readseq      :       1.029 micros/op 971446 ops/sec; 9501.6 MB/s
readseq      :       0.974 micros/op 1026229 ops/sec; 10037.4 MB/s
readseq      :       0.965 micros/op 1036080 ops/sec; 10133.8 MB/s
readseq      :       0.943 micros/op 1060657 ops/sec; 10374.2 MB/s
[master]
readseq      :      16.735 micros/op 59755 ops/sec;  584.5 MB/s
readseq      :       3.029 micros/op 330151 ops/sec; 3229.2 MB/s
readseq      :       3.136 micros/op 318883 ops/sec; 3119.0 MB/s
readseq      :       3.065 micros/op 326245 ops/sec; 3191.0 MB/s
readseq      :       3.014 micros/op 331813 ops/sec; 3245.4 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10-operands-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
[FullMergeV2]
readseq      :      24.325 micros/op 41109 ops/sec;  402.1 MB/s
readseq      :       1.470 micros/op 680272 ops/sec; 6653.7 MB/s
readseq      :       1.231 micros/op 812347 ops/sec; 7945.5 MB/s
readseq      :       1.091 micros/op 916590 ops/sec; 8965.1 MB/s
readseq      :       1.109 micros/op 901713 ops/sec; 8819.6 MB/s
[master]
readseq      :      27.257 micros/op 36687 ops/sec;  358.8 MB/s
readseq      :       4.443 micros/op 225073 ops/sec; 2201.4 MB/s
readseq      :       5.830 micros/op 171526 ops/sec; 1677.7 MB/s
readseq      :       4.173 micros/op 239635 ops/sec; 2343.8 MB/s
readseq      :       4.150 micros/op 240963 ops/sec; 2356.8 MB/s
```
Test Plan: COMPILE_WITH_ASAN=1 make check -j64
Reviewers: yhchiang, andrewkr, sdong
Reviewed By: sdong
Subscribers: lovro, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57075/New Statistics to track Compression/Decompression (#1197)
* Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer).
* Prevent incrementing compression counter when compression is turned off in options.
* Prevent incrementing compression counter when compression is turned off in options.
* Added two more supported compression types to test code in db_test.cc
* Prevent incrementing compression counter when compression is turned off in options.
* Added new StatsLevel that excludes compression timing.
* Fixed casting error in coding.h
* Fixed CompressionStatsTest for new StatsLevel.
* Removed unused variable that was breaking the Linux build/DBTest.DynamicLevelCompressionPerLevel: Tune Threshold
Summary: Each SST's file size increases after we add more table properties. Threshold in DBTest.DynamicLevelCompressionPerLevel need to adjust accordingly to avoid occasional failures.
Test Plan: Run the test
Reviewers: andrewkr, yiwu
Subscribers: leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D60819/Move IO failure test to separate file
Summary:
This is a part of effort to reduce the size of db_test.cc. We move the following tests to a separate file `db_io_failure_test.cc`:
* DropWrites
* DropWritesFlush
* NoSpaceCompactRange
* NonWritableFileSystem
* ManifestWriteError
* PutFailsParanoid
Test Plan: Run `make check` to see if the tests are working properly.
Reviewers: sdong, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D58341/[rocksdb] make more options dynamic
Summary:
make more ColumnFamilyOptions dynamic:
- compression
- soft_pending_compaction_bytes_limit
- hard_pending_compaction_bytes_limit
- min_partial_merge_operands
- report_bg_io_stats
- paranoid_file_checks
Test Plan:
Add sanity check in `db_test.cc` for all above options except for soft_pending_compaction_bytes_limit and hard_pending_compaction_bytes_limit.
All passed.
Reviewers: andrewkr, sdong, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D57519/"
rocksdb,"Add a callback for when memtable is moved to immutable (#1137)
* Create a callback for memtable becoming immutable
Create a callback for memtable becoming immutable
Create a callback for memtable becoming immutable
moved notification outside the lock
Move sealed notification to unlocked portion of SwitchMemtable
* fix lite build/"
rocksdb,"Introduce FullMergeV2 (eliminate memcpy from merge operators)
Summary:
This diff update the code to pin the merge operator operands while the merge operation is done, so that we can eliminate the memcpy cost, to do that we need a new public API for FullMerge that replace the std::deque<std::string> with std::vector<Slice>
This diff is stacked on top of D56493 and D56511
In this diff we
- Update FullMergeV2 arguments to be encapsulated in MergeOperationInput and MergeOperationOutput which will make it easier to add new arguments in the future
- Replace std::deque<std::string> with std::vector<Slice> to pass operands
- Replace MergeContext std::deque with std::vector (based on a simple benchmark I ran https://gist.github.com/IslamAbdelRahman/78fc86c9ab9f52b1df791e58943fb187)
- Allow FullMergeV2 output to be an existing operand
```
[Everything in Memtable | 10K operands | 10 KB each | 1 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=10000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       0.607 micros/op 1648235 ops/sec; 16121.2 MB/s
readseq      :       0.478 micros/op 2091546 ops/sec; 20457.2 MB/s
readseq      :       0.252 micros/op 3972081 ops/sec; 38850.5 MB/s
readseq      :       0.237 micros/op 4218328 ops/sec; 41259.0 MB/s
readseq      :       0.247 micros/op 4043927 ops/sec; 39553.2 MB/s
[master]
readseq      :       3.935 micros/op 254140 ops/sec; 2485.7 MB/s
readseq      :       3.722 micros/op 268657 ops/sec; 2627.7 MB/s
readseq      :       3.149 micros/op 317605 ops/sec; 3106.5 MB/s
readseq      :       3.125 micros/op 320024 ops/sec; 3130.1 MB/s
readseq      :       4.075 micros/op 245374 ops/sec; 2400.0 MB/s
```
```
[Everything in Memtable | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""mergerandom,readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --merge_keys=1000 --num=10000 --disable_auto_compactions --value_size=10240 --write_buffer_size=1000000000
[FullMergeV2]
readseq      :       3.472 micros/op 288018 ops/sec; 2817.1 MB/s
readseq      :       2.304 micros/op 434027 ops/sec; 4245.2 MB/s
readseq      :       1.163 micros/op 859845 ops/sec; 8410.0 MB/s
readseq      :       1.192 micros/op 838926 ops/sec; 8205.4 MB/s
readseq      :       1.250 micros/op 800000 ops/sec; 7824.7 MB/s
[master]
readseq      :      24.025 micros/op 41623 ops/sec;  407.1 MB/s
readseq      :      18.489 micros/op 54086 ops/sec;  529.0 MB/s
readseq      :      18.693 micros/op 53495 ops/sec;  523.2 MB/s
readseq      :      23.621 micros/op 42335 ops/sec;  414.1 MB/s
readseq      :      18.775 micros/op 53262 ops/sec;  521.0 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 1 operand per key]
[FullMergeV2]
$ DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
readseq      :      14.741 micros/op 67837 ops/sec;  663.5 MB/s
readseq      :       1.029 micros/op 971446 ops/sec; 9501.6 MB/s
readseq      :       0.974 micros/op 1026229 ops/sec; 10037.4 MB/s
readseq      :       0.965 micros/op 1036080 ops/sec; 10133.8 MB/s
readseq      :       0.943 micros/op 1060657 ops/sec; 10374.2 MB/s
[master]
readseq      :      16.735 micros/op 59755 ops/sec;  584.5 MB/s
readseq      :       3.029 micros/op 330151 ops/sec; 3229.2 MB/s
readseq      :       3.136 micros/op 318883 ops/sec; 3119.0 MB/s
readseq      :       3.065 micros/op 326245 ops/sec; 3191.0 MB/s
readseq      :       3.014 micros/op 331813 ops/sec; 3245.4 MB/s
```
```
[Everything in Block cache | 10K operands | 10 KB each | 10 operand per key]
DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq,readseq,readseq,readseq,readseq"" --merge_operator=""max"" --num=100000 --db=""/dev/shm/merge-random-10-operands-10K-10KB"" --cache_size=1000000000 --use_existing_db --disable_auto_compactions
[FullMergeV2]
readseq      :      24.325 micros/op 41109 ops/sec;  402.1 MB/s
readseq      :       1.470 micros/op 680272 ops/sec; 6653.7 MB/s
readseq      :       1.231 micros/op 812347 ops/sec; 7945.5 MB/s
readseq      :       1.091 micros/op 916590 ops/sec; 8965.1 MB/s
readseq      :       1.109 micros/op 901713 ops/sec; 8819.6 MB/s
[master]
readseq      :      27.257 micros/op 36687 ops/sec;  358.8 MB/s
readseq      :       4.443 micros/op 225073 ops/sec; 2201.4 MB/s
readseq      :       5.830 micros/op 171526 ops/sec; 1677.7 MB/s
readseq      :       4.173 micros/op 239635 ops/sec; 2343.8 MB/s
readseq      :       4.150 micros/op 240963 ops/sec; 2356.8 MB/s
```
Test Plan: COMPILE_WITH_ASAN=1 make check -j64
Reviewers: yhchiang, andrewkr, sdong
Reviewed By: sdong
Subscribers: lovro, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D57075/New Statistics to track Compression/Decompression (#1197)
* Added new statistics and refactored to allow ioptions to be passed around as required to access environment and statistics pointers (and, as a convenient side effect, info_log pointer).
* Prevent incrementing compression counter when compression is turned off in options.
* Prevent incrementing compression counter when compression is turned off in options.
* Added two more supported compression types to test code in db_test.cc
* Prevent incrementing compression counter when compression is turned off in options.
* Added new StatsLevel that excludes compression timing.
* Fixed casting error in coding.h
* Fixed CompressionStatsTest for new StatsLevel.
* Removed unused variable that was breaking the Linux build/Fix clang analyzer errors
Summary:
Fixing erros reported by clang static analyzer.
* Removing some unused variables.
* Adding assertions to fix false positives reported by clang analyzer.
* Adding `__clang_analyzer__` macro to suppress false positive warnings.
Test Plan:
USE_CLANG=1 OPT=-g make analyze -j64
Reviewers: andrewkr, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D60549/Fix release build for MyRocks by using debug-only code only in debug builds
Summary: MyRocks release integration build breaks because we treat warnings caused by unused variables as errors. Variable `edit` is only used in debug builds. Therefore we need to guard it using `#ifndef NDEBUG` check.
Test Plan:
- `[p]arc diff --preview` for the default validation.
- Verify that release build fails before this fix and passes after applying it.
Reviewers: andrewkr, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D60423/group multiple batch of flush into one manifest file (one call to LogAndApply)
Summary: Currently, if several flush outputs are committed together, we issue each manifest write per batch (1 batch = 1 flush = 1 sst file = 1+ continuous memtables). Each manifest write requires one fsync and one fsync to parent directory. In some cases, it becomes the bottleneck of write. We should batch them and write in one manifest write when possible.
Test Plan:
` ./db_bench -benchmarks=""fillseq"" -max_write_buffer_number=16 -max_background_flushes=16 -disable_auto_compactions=true -min_write_buffer_number_to_merge=1 -write_buffer_size=65536 -level0_stop_writes_trigger=10000 -level0_slowdown_writes_trigger=10000`
**Before**
```
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
RocksDB:    version 4.9
Date:       Fri Jul  1 15:38:17 2016
CPU:        32 * Intel(R) Xeon(R) CPU E5-2660 0 @ 2.20GHz
CPUCache:   20480 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Compression: Snappy
Memtablerep: skip_list
Perf Level: 1
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
DB path: [/tmp/rocksdbtest-112628/dbbench]
fillseq      :     166.277 micros/op 6014 ops/sec;    0.7 MB/s
```
**After**
```
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
RocksDB:    version 4.9
Date:       Fri Jul  1 15:35:05 2016
CPU:        32 * Intel(R) Xeon(R) CPU E5-2660 0 @ 2.20GHz
CPUCache:   20480 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Compression: Snappy
Memtablerep: skip_list
Perf Level: 1
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
DB path: [/tmp/rocksdbtest-112628/dbbench]
fillseq      :      52.328 micros/op 19110 ops/sec;    2.1 MB/s
```
Reviewers: andrewkr, IslamAbdelRahman, yhchiang, sdong
Reviewed By: sdong
Subscribers: igor, andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D60075/"
rocksdb,"Fix build issue. (#1123)
Implement GetUniqueIdFromFile to support new tests and the feature./"
rocksdb,"Change max_bytes_for_level_multiplier to double
Summary: Closes https://github.com/facebook/rocksdb/pull/1427
Differential Revision: D4094732
Pulled By: yiwu-arbug
fbshipit-source-id: b9b79e9/db_bench: --dump_malloc_stats takes no effect
Summary:
Fix the bug that --dump_malloc_stats is set before opening the DB.
Closes https://github.com/facebook/rocksdb/pull/1447
Differential Revision: D4106001
Pulled By: siying
fbshipit-source-id: 4e746da/Fix db_bench memory use after free (detected by clang_analyze)
Summary: Fix using `arg[i].thread` after deleting it
Test Plan: run clang_analyze
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D63171/[db_bench] Support single benchmark arguments (Repeat for X times, Warm up for X times), Support CombinedStats (AVG / MEDIAN)
Summary:
This diff allow us to run a single benchmark X times and warm it up for Y times. and see the AVG & MEDIAN throughput of these X runs
for example
```
$ ./db_bench --benchmarks=""fillseq,readseq[X5-W2]""
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
RocksDB:    version 4.12
Date:       Wed Aug 24 10:45:26 2016
CPU:        32 * Intel(R) Xeon(R) CPU E5-2660 0 @ 2.20GHz
CPUCache:   20480 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Compression: Snappy
Memtablerep: skip_list
Perf Level: 1
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
DB path: [/tmp/rocksdbtest-8616/dbbench]
fillseq      :       4.695 micros/op 212971 ops/sec;   23.6 MB/s
DB path: [/tmp/rocksdbtest-8616/dbbench]
Warming up benchmark by running 2 times
readseq      :       0.214 micros/op 4677005 ops/sec;  517.4 MB/s
readseq      :       0.212 micros/op 4706834 ops/sec;  520.7 MB/s
Running benchmark for 5 times
readseq      :       0.218 micros/op 4588187 ops/sec;  507.6 MB/s
readseq      :       0.208 micros/op 4816538 ops/sec;  532.8 MB/s
readseq      :       0.213 micros/op 4685376 ops/sec;  518.3 MB/s
readseq      :       0.214 micros/op 4676787 ops/sec;  517.4 MB/s
readseq      :       0.217 micros/op 4618532 ops/sec;  510.9 MB/s
readseq [AVG    5 runs] : 4677084 ops/sec;  517.4 MB/sec
readseq [MEDIAN 5 runs] : 4676787 ops/sec;  517.4 MB/sec
```
Test Plan: run db_bench
Reviewers: sdong, andrewkr, yhchiang
Reviewed By: yhchiang
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D62235/Introduce ClockCache
Summary:
Clock-based cache implemenetation aim to have better concurreny than
default LRU cache. See inline comments for implementation details.
Test Plan:
Update cache_test to run on both LRUCache and ClockCache. Adding some
new tests to catch some of the bugs that I fixed while implementing the
cache.
Reviewers: kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D61647/"
rocksdb,"Fix a minor bug in the ldb tool that was not selecting the specified (#1399)
column family for compaction./"
rocksdb,"Change max_bytes_for_level_multiplier to double
Summary: Closes https://github.com/facebook/rocksdb/pull/1427
Differential Revision: D4094732
Pulled By: yiwu-arbug
fbshipit-source-id: b9b79e9/Introduce ClockCache
Summary:
Clock-based cache implemenetation aim to have better concurreny than
default LRU cache. See inline comments for implementation details.
Test Plan:
Update cache_test to run on both LRUCache and ClockCache. Adding some
new tests to catch some of the bugs that I fixed while implementing the
cache.
Reviewers: kradhakrishnan, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D61647/"
rocksdb,"Add NoSpace subcode to IOError (#1320)
Add a sub code to distinguish ""out of space"" errors from regular I/O errors/"
rocksdb,"Change max_bytes_for_level_multiplier to double
Summary: Closes https://github.com/facebook/rocksdb/pull/1427
Differential Revision: D4094732
Pulled By: yiwu-arbug
fbshipit-source-id: b9b79e9/"
rocksdb,Add Status to RocksDBException so that meaningful function result Status from the C++ API isn't lost (#1273)/
rocksdb,"Rename jvalue to jval in rocksjni
Summary: jvalue shadows a global name in <jni.h>. Rename it to jval to fix java build.
Test Plan:
JAVA_HOME=/usr/local/jdk-7u10-64 make rocksdbjava -j64
Reviewers: adamretter, yhchiang, IslamAbdelRahman
Reviewed By: yhchiang, IslamAbdelRahman
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D63981/Fix java build
Summary: Fix the java build
Test Plan: make rocksdbjava -j64
Reviewers: yhchiang, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D62097/"
rocksdb,"Change max_bytes_for_level_multiplier to double
Summary: Closes https://github.com/facebook/rocksdb/pull/1427
Differential Revision: D4094732
Pulled By: yiwu-arbug
fbshipit-source-id: b9b79e9/Fix casts for MSVC
Summary:
I am not sure if this is the best way to fix this?
Closes https://github.com/facebook/rocksdb/pull/1452
Differential Revision: D4109338
Pulled By: yiwu-arbug
fbshipit-source-id: ca40809/Fix bug in UnScSigned-off-by: xh931076284 <931076284@qq.com> (#1336)
Fix HdfsEnv::UnSchedule() API error/Fix the Windows build of RocksDB Java. Similar to https://github.com/facebook/rocksdb/issues/1220 (#1284)/Fix java build
Summary: Fix the java build
Test Plan: make rocksdbjava -j64
Reviewers: yhchiang, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D62097/"
rocksdb,"Minor fixes to RocksJava Native Library initialization (#1287)
* [bugfix] Make sure the Native Library is initialized. Closes https://github.com/facebook/rocksdb/issues/989
* [bugfix] Just load the native libraries once/"
rocksdb,"Minor fixes to RocksJava Native Library initialization (#1287)
* [bugfix] Make sure the Native Library is initialized. Closes https://github.com/facebook/rocksdb/issues/989
* [bugfix] Just load the native libraries once/"
rocksdb,"Change max_bytes_for_level_multiplier to double
Summary: Closes https://github.com/facebook/rocksdb/pull/1427
Differential Revision: D4094732
Pulled By: yiwu-arbug
fbshipit-source-id: b9b79e9/"
rocksdb,"Fix bug in UnScSigned-off-by: xh931076284 <931076284@qq.com> (#1336)
Fix HdfsEnv::UnSchedule() API error/"
rocksdb,"Change max_bytes_for_level_multiplier to double
Summary: Closes https://github.com/facebook/rocksdb/pull/1427
Differential Revision: D4094732
Pulled By: yiwu-arbug
fbshipit-source-id: b9b79e9/"
rocksdb,"Change ioptions to store user_comparator, fix bug
Summary:
change ioptions.comparator to user_comparator instread of internal_comparator.
Also change Comparator* to InternalKeyComparator* to make its type explicitly.
Test Plan: make all check -j64
Reviewers: andrewkr, sdong, yiwu
Reviewed By: yiwu
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D65121/"
rocksdb,"Change ioptions to store user_comparator, fix bug
Summary:
change ioptions.comparator to user_comparator instread of internal_comparator.
Also change Comparator* to InternalKeyComparator* to make its type explicitly.
Test Plan: make all check -j64
Reviewers: andrewkr, sdong, yiwu
Reviewed By: yiwu
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D65121/store prefix_extractor_name in table
Summary:
Make sure prefix extractor name is stored in SST files and if DB is opened with a prefix extractor of a different name, prefix bloom is skipped when read the file.
Also add unit tests for that.
Test Plan:
before change:
```
Note: Google Test filter = BlockBasedTableTest.SkipPrefixBloomFilter
[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from BlockBasedTableTest
[ RUN      ] BlockBasedTableTest.SkipPrefixBloomFilter
table/table_test.cc:1421: Failure
Value of: db_iter->Valid()
Actual: false
Expected: true
[  FAILED  ] BlockBasedTableTest.SkipPrefixBloomFilter (1 ms)
[----------] 1 test from BlockBasedTableTest (1 ms total)
[----------] Global test environment tear-down
[==========] 1 test from 1 test case ran. (1 ms total)
[  PASSED  ] 0 tests.
[  FAILED  ] 1 test, listed below:
[  FAILED  ] BlockBasedTableTest.SkipPrefixBloomFilter
1 FAILED TEST
```
after:
```
Note: Google Test filter = BlockBasedTableTest.SkipPrefixBloomFilter
[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from BlockBasedTableTest
[ RUN      ] BlockBasedTableTest.SkipPrefixBloomFilter
[       OK ] BlockBasedTableTest.SkipPrefixBloomFilter (0 ms)
[----------] 1 test from BlockBasedTableTest (0 ms total)
[----------] Global test environment tear-down
[==========] 1 test from 1 test case ran. (0 ms total)
[  PASSED  ] 1 test.
```
Reviewers: sdong, andrewkr, yiwu, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D61215/"
rocksdb,"Fix SstFileWriter destructor
Summary:
If user did not call SstFileWriter::Finish() or called Finish() but it failed.
We need to abandon the builder, to avoid destructing it while it's open
Closes https://github.com/facebook/rocksdb/pull/1502
Differential Revision: D4171660
Pulled By: IslamAbdelRahman
fbshipit-source-id: ab6f434/"
rocksdb,"Insert range deletion meta-block into block cache
Summary:
This handles two issues: (1) range deletion iterator sometimes outlives
the table reader that created it, in which case the block must not be destroyed
during table reader destruction; and (2) we prefer to read these range tombstone
meta-blocks from file fewer times.
- Extracted cache-populating logic from NewDataBlockIterator() into a separate function: MaybeLoadDataBlockToCache()
- Use MaybeLoadDataBlockToCache() to load range deletion meta-block and pin it through the reader's lifetime. This code reuse works since range deletion meta-block has same format as data blocks.
- Use NewDataBlockIterator() to create range deletion iterators, which uses block cache if enabled, otherwise reads the block from file. Either way, the underlying block won't disappear until after the iterator is destroyed.
Closes https://github.com/facebook/rocksdb/pull/1459
Differential Revision: D4123175
Pulled By: ajkr
fbshipit-source-id: 8f64281/Temporarily revert Prev() prefix support
Summary:
Temporarily revert commits for supporting prefix Prev() to unblock MyRocks and RocksDB release
These are the commits reverted
- 6a14d55bd913490dbd61d682567e6e0625756c0d
- b18f9c9eace89d63f37432ce1a3dba48bddbcef0
- db74b1a21905336e2c178ff1f2ffd12c7852b7b8
- 2482d5fb45d8f01b0b065d649d01f43dacad799c
Test Plan: make check -j64
Reviewers: sdong, lightmark
Reviewed By: lightmark
Subscribers: andrewkr, dhruba, yoshinorim
Differential Revision: https://reviews.facebook.net/D63789/store prefix_extractor_name in table
Summary:
Make sure prefix extractor name is stored in SST files and if DB is opened with a prefix extractor of a different name, prefix bloom is skipped when read the file.
Also add unit tests for that.
Test Plan:
before change:
```
Note: Google Test filter = BlockBasedTableTest.SkipPrefixBloomFilter
[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from BlockBasedTableTest
[ RUN      ] BlockBasedTableTest.SkipPrefixBloomFilter
table/table_test.cc:1421: Failure
Value of: db_iter->Valid()
Actual: false
Expected: true
[  FAILED  ] BlockBasedTableTest.SkipPrefixBloomFilter (1 ms)
[----------] 1 test from BlockBasedTableTest (1 ms total)
[----------] Global test environment tear-down
[==========] 1 test from 1 test case ran. (1 ms total)
[  PASSED  ] 0 tests.
[  FAILED  ] 1 test, listed below:
[  FAILED  ] BlockBasedTableTest.SkipPrefixBloomFilter
1 FAILED TEST
```
after:
```
Note: Google Test filter = BlockBasedTableTest.SkipPrefixBloomFilter
[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from BlockBasedTableTest
[ RUN      ] BlockBasedTableTest.SkipPrefixBloomFilter
[       OK ] BlockBasedTableTest.SkipPrefixBloomFilter (0 ms)
[----------] 1 test from BlockBasedTableTest (0 ms total)
[----------] Global test environment tear-down
[==========] 1 test from 1 test case ran. (0 ms total)
[  PASSED  ] 1 test.
```
Reviewers: sdong, andrewkr, yiwu, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D61215/fix data race in NewIndexIterator() in block_based_table_reader.cc
Summary: fixed data race described in https://github.com/facebook/rocksdb/issues/1267 and add regression test
Test Plan:
./table_test --gtest_filter=BlockBasedTableTest.NewIndexIteratorLeak
make all check -j64
core dump before fix. ok after fix.
Reviewers: andrewkr, sdong
Reviewed By: sdong
Subscribers: igor, andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D62361/Fix bug in printing values for block-based table
Summary: value is not an InternalKey, we do not need to decode it
Test Plan:
setup:
$ ldb put --create_if_missing=true k v
$ ldb put --db=./tmp --create_if_missing k v
$ ldb compact --db=./tmp
before:
$ sst_dump --command=raw --file=./tmp/000004.sst
...
terminate called after throwing an instance of 'std::length_error'
after:
$ ./sst_dump --command=raw --file=./tmp/000004.sst
$ cat tmp/000004_dump.txt
...
ASCII  k : v
...
Reviewers: sdong, yhchiang, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D62301/"
rocksdb,"store prefix_extractor_name in table
Summary:
Make sure prefix extractor name is stored in SST files and if DB is opened with a prefix extractor of a different name, prefix bloom is skipped when read the file.
Also add unit tests for that.
Test Plan:
before change:
```
Note: Google Test filter = BlockBasedTableTest.SkipPrefixBloomFilter
[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from BlockBasedTableTest
[ RUN      ] BlockBasedTableTest.SkipPrefixBloomFilter
table/table_test.cc:1421: Failure
Value of: db_iter->Valid()
Actual: false
Expected: true
[  FAILED  ] BlockBasedTableTest.SkipPrefixBloomFilter (1 ms)
[----------] 1 test from BlockBasedTableTest (1 ms total)
[----------] Global test environment tear-down
[==========] 1 test from 1 test case ran. (1 ms total)
[  PASSED  ] 0 tests.
[  FAILED  ] 1 test, listed below:
[  FAILED  ] BlockBasedTableTest.SkipPrefixBloomFilter
1 FAILED TEST
```
after:
```
Note: Google Test filter = BlockBasedTableTest.SkipPrefixBloomFilter
[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from BlockBasedTableTest
[ RUN      ] BlockBasedTableTest.SkipPrefixBloomFilter
[       OK ] BlockBasedTableTest.SkipPrefixBloomFilter (0 ms)
[----------] 1 test from BlockBasedTableTest (0 ms total)
[----------] Global test environment tear-down
[==========] 1 test from 1 test case ran. (0 ms total)
[  PASSED  ] 1 test.
```
Reviewers: sdong, andrewkr, yiwu, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D61215/"
rocksdb,"Avoid hard-coded sleep in EnvPosixTestWithParam.TwoPools
Summary: EnvPosixTestWithParam.TwoPools relies on explicit sleeping, so it sometimes fail. Fix it.
Test Plan: Run tests with high parallelism many times and make sure the test passes.
Reviewers: yiwu, andrewkr
Reviewed By: andrewkr
Subscribers: leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D63417/Fix build error on Windows (AppVeyor) (#1315)
Add 'cf_options' to source list and db_imple.cc
fix casting/Fix Travis on Mac
Summary: not sure why travis complain about this line, works fine on my mac
Test Plan: run on my mac
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D63045/"
rocksdb,solve the problem of table_factory_to_write_=nullptr (#1342)/
rocksdb,"store prefix_extractor_name in table
Summary:
Make sure prefix extractor name is stored in SST files and if DB is opened with a prefix extractor of a different name, prefix bloom is skipped when read the file.
Also add unit tests for that.
Test Plan:
before change:
```
Note: Google Test filter = BlockBasedTableTest.SkipPrefixBloomFilter
[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from BlockBasedTableTest
[ RUN      ] BlockBasedTableTest.SkipPrefixBloomFilter
table/table_test.cc:1421: Failure
Value of: db_iter->Valid()
Actual: false
Expected: true
[  FAILED  ] BlockBasedTableTest.SkipPrefixBloomFilter (1 ms)
[----------] 1 test from BlockBasedTableTest (1 ms total)
[----------] Global test environment tear-down
[==========] 1 test from 1 test case ran. (1 ms total)
[  PASSED  ] 0 tests.
[  FAILED  ] 1 test, listed below:
[  FAILED  ] BlockBasedTableTest.SkipPrefixBloomFilter
1 FAILED TEST
```
after:
```
Note: Google Test filter = BlockBasedTableTest.SkipPrefixBloomFilter
[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from BlockBasedTableTest
[ RUN      ] BlockBasedTableTest.SkipPrefixBloomFilter
[       OK ] BlockBasedTableTest.SkipPrefixBloomFilter (0 ms)
[----------] 1 test from BlockBasedTableTest (0 ms total)
[----------] Global test environment tear-down
[==========] 1 test from 1 test case ran. (0 ms total)
[  PASSED  ] 1 test.
```
Reviewers: sdong, andrewkr, yiwu, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D61215/"
rocksdb,"Insert range deletion meta-block into block cache
Summary:
This handles two issues: (1) range deletion iterator sometimes outlives
the table reader that created it, in which case the block must not be destroyed
during table reader destruction; and (2) we prefer to read these range tombstone
meta-blocks from file fewer times.
- Extracted cache-populating logic from NewDataBlockIterator() into a separate function: MaybeLoadDataBlockToCache()
- Use MaybeLoadDataBlockToCache() to load range deletion meta-block and pin it through the reader's lifetime. This code reuse works since range deletion meta-block has same format as data blocks.
- Use NewDataBlockIterator() to create range deletion iterators, which uses block cache if enabled, otherwise reads the block from file. Either way, the underlying block won't disappear until after the iterator is destroyed.
Closes https://github.com/facebook/rocksdb/pull/1459
Differential Revision: D4123175
Pulled By: ajkr
fbshipit-source-id: 8f64281/Fix uninitialized variable gcc error for MyRocks
Summary: make sure seq_ is properly initialized even if ParseInternalKey() fails.
Test Plan: run myrocks release tests
Reviewers: lightmark, mung, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D65199/store prefix_extractor_name in table
Summary:
Make sure prefix extractor name is stored in SST files and if DB is opened with a prefix extractor of a different name, prefix bloom is skipped when read the file.
Also add unit tests for that.
Test Plan:
before change:
```
Note: Google Test filter = BlockBasedTableTest.SkipPrefixBloomFilter
[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from BlockBasedTableTest
[ RUN      ] BlockBasedTableTest.SkipPrefixBloomFilter
table/table_test.cc:1421: Failure
Value of: db_iter->Valid()
Actual: false
Expected: true
[  FAILED  ] BlockBasedTableTest.SkipPrefixBloomFilter (1 ms)
[----------] 1 test from BlockBasedTableTest (1 ms total)
[----------] Global test environment tear-down
[==========] 1 test from 1 test case ran. (1 ms total)
[  PASSED  ] 0 tests.
[  FAILED  ] 1 test, listed below:
[  FAILED  ] BlockBasedTableTest.SkipPrefixBloomFilter
1 FAILED TEST
```
after:
```
Note: Google Test filter = BlockBasedTableTest.SkipPrefixBloomFilter
[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from BlockBasedTableTest
[ RUN      ] BlockBasedTableTest.SkipPrefixBloomFilter
[       OK ] BlockBasedTableTest.SkipPrefixBloomFilter (0 ms)
[----------] 1 test from BlockBasedTableTest (0 ms total)
[----------] Global test environment tear-down
[==========] 1 test from 1 test case ran. (0 ms total)
[  PASSED  ] 1 test.
```
Reviewers: sdong, andrewkr, yiwu, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D61215/fix data race in NewIndexIterator() in block_based_table_reader.cc
Summary: fixed data race described in https://github.com/facebook/rocksdb/issues/1267 and add regression test
Test Plan:
./table_test --gtest_filter=BlockBasedTableTest.NewIndexIteratorLeak
make all check -j64
core dump before fix. ok after fix.
Reviewers: andrewkr, sdong
Reviewed By: sdong
Subscribers: igor, andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D62361/"
rocksdb,"Change ioptions to store user_comparator, fix bug
Summary:
change ioptions.comparator to user_comparator instread of internal_comparator.
Also change Comparator* to InternalKeyComparator* to make its type explicitly.
Test Plan: make all check -j64
Reviewers: andrewkr, sdong, yiwu
Reviewed By: yiwu
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D65121/"
rocksdb,"Fix 2PC Recovery SeqId Miscount
Summary:
Originally sequence ids were calculated, in recovery, based off of the first seqid found if the first log recovered. The working seqid was then incremented from that value based on every insertion that took place. This was faulty because of the potential for missing log files or inserts that skipped the WAL. The current recovery scheme grabs sequence from current recovering batch and increments using memtableinserter to track how many actual inserts take place. This works for 2PC batches as well scenarios where some logs are missing or inserts that skip the WAL.
Closes https://github.com/facebook/rocksdb/pull/1486
Differential Revision: D4156064
Pulled By: reidHoruff
fbshipit-source-id: a6da8d9/fix open failure with empty wal
Summary: Closes https://github.com/facebook/rocksdb/pull/1490
Differential Revision: D4158821
Pulled By: IslamAbdelRahman
fbshipit-source-id: 59b73f4/Use correct sequence number when creating memtable
Summary:
copied from: https://github.com/mdlugajczyk/rocksdb/commit/5ebfd2623a01e69a4cbeae3ed2b788f2a84056ad
Opening existing RocksDB attempts recovery from log files, which uses
wrong sequence number to create the memtable. This is a regression
introduced in change a400336.
This change includes a test demonstrating the problem, without the fix
the test fails with ""Operation failed. Try again.: Transaction could not
check for conflicts for operation at SequenceNumber 1 as the MemTable
only contains changes newer than SequenceNumber 2.  Increasing the value
of the max_write_buffer_number_to_maintain option could reduce the
frequency of this error""
This change is a joint effort by Peter 'Stig' Edwards thatsafunnyname
and me.
Closes https://github.com/facebook/rocksdb/pull/1458
Differential Revision: D4143791
Pulled By: reidHoruff
fbshipit-source-id: 5a25033/Fix deadlock between (WriterThread/Compaction/IngestExternalFile)
Summary:
A deadlock is possible if this happen
(1) Writer thread is stopped because it's waiting for compaction to finish
(2) Compaction is waiting for current IngestExternalFile() calls to finish
(3) IngestExternalFile() is waiting to be able to acquire the writer thread
(4) WriterThread is held by stopped writes that are waiting for compactions to finish
This patch fix the issue by not incrementing num_running_ingest_file_ except when we acquire the writer thread.
This patch include a unittest to reproduce the described scenario
Closes https://github.com/facebook/rocksdb/pull/1480
Differential Revision: D4151646
Pulled By: IslamAbdelRahman
fbshipit-source-id: 09b39db/Add avoid_flush_during_shutdown DB option
Summary:
Add avoid_flush_during_shutdown DB option.
Closes https://github.com/facebook/rocksdb/pull/1451
Differential Revision: D4108643
Pulled By: yiwu-arbug
fbshipit-source-id: abdaf4d/Print compression and Fast CRC support info as Header level
Summary:
Currently the compression suppport and fast CRC support information is printed as info level. They should be in the same level as options, which is header level.
Also add ZSTD to this printing.
Closes https://github.com/facebook/rocksdb/pull/1448
Differential Revision: D4106608
Pulled By: yiwu-arbug
fbshipit-source-id: cb9a076/Show More DB Stats in info logs
Summary:
DB Stats now are truncated if there are too many CFs. Extend the buffer size to allow more to be printed out. Also, separate out malloc to another log line.
Closes https://github.com/facebook/rocksdb/pull/1439
Differential Revision: D4100943
Pulled By: yiwu-arbug
fbshipit-source-id: 79f7218/Change ioptions to store user_comparator, fix bug
Summary:
change ioptions.comparator to user_comparator instread of internal_comparator.
Also change Comparator* to InternalKeyComparator* to make its type explicitly.
Test Plan: make all check -j64
Reviewers: andrewkr, sdong, yiwu
Reviewed By: yiwu
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D65121/Handle WAL deletion when using avoid_flush_during_recovery
Summary:
Previously the WAL files that were avoided during recovery would never
be considered for deletion. That was because alive_log_files_ was only
populated when log files are created. This diff further populates
alive_log_files_ with existing log files that aren't flushed during recovery,
such that FindObsoleteFiles() can find them later.
Depends on D64053.
Test Plan: new unit test, verifies it fails before this change and passes after
Reviewers: sdong, IslamAbdelRahman, yiwu
Reviewed By: yiwu
Subscribers: leveldb, dhruba, andrewkr
Differential Revision: https://reviews.facebook.net/D64059/Fix compaction conflict with running compaction
Summary:
Issue scenario:
(1) We have 3 files in L1 and we issue a compaction that will compact them into 1 file in L2
(2) While compaction (1) is running, we flush a file into L0 and trigger another compaction that decide to move this file to L1 and then move it again to L2 (this file don't overlap with any other files)
(3) compaction (1) finishes and install the file it generated in L2, but this file overlap with the file we generated in (2) so we break the LSM consistency
Looks like this issue can be triggered by using non-exclusive manual compaction or AddFile()
Test Plan: unit tests
Reviewers: sdong
Reviewed By: sdong
Subscribers: hermanlee4, jkedgar, andrewkr, dhruba, yoshinorim
Differential Revision: https://reviews.facebook.net/D64947/Redo handling of recycled logs in full purge
Summary:
This reverts commit https://github.com/facebook/rocksdb/commit/9e4aa798c3d47c6be64324bd9d38f0813c8ead7b,
which doesn't handle all cases (see inline comment).
I reimplemented the logic as suggested in the initial PR: https://github.com/facebook/rocksdb/pull/1313.
This approach has two benefits:
- All the parsing/filtering of full_scan_candidate_files is kept together in PurgeObsoleteFiles.
- We only need to check whether log file is recycled in one place where we've already determined it's a log file
Test Plan:
new unit test, verified fails before the original fix, still passes
now.
Reviewers: IslamAbdelRahman, yiwu, sdong
Reviewed By: yiwu, sdong
Subscribers: leveldb, dhruba, andrewkr
Differential Revision: https://reviews.facebook.net/D64053/new Prev() prefix support using SeekForPrev()
Summary:
1) The previous solution for Prev() prefix support is not clean.
Since I add api SeekForPrev(), now the Prev() can be symmetric to Next().
and we do not need SeekToLast() to be called in Prev() any more.
Also, Next() will Seek(prefix_seek_key_) to solve the problem of possible inconsistency between db_iter and merge_iter when
there is merge_operator. And prefix_seek_key is only refreshed when change direction to forward.
2) This diff also solves the bug of Iterator::SeekToLast() with iterate_upper_bound_ with prefix extractor.
add test cases for the above two cases.
There are some tests for the SeekToLast() in Prev(), I will clean them later.
Test Plan: make all check
Reviewers: IslamAbdelRahman, andrewkr, yiwu, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D63933/Fix conflict between AddFile() and CompactRange()
Summary:
Fix the conflict bug between AddFile() and CompactRange() by
- Make sure that no AddFile calls are running when asking CompactionPicker to pick compaction for manual compaction
- If AddFile() run after we pick the compaction for the manual compaction it will be aware of it since we will add the manual compaction to running_compactions_ after picking it
This will solve these 2 scenarios
- If AddFile() is running, we will wait for it to finish before we pick a compaction for the manual compaction
- If we already picked a manual compaction and then AddFile() started ... we ensure that it never ingest a file in a level that will overlap with the manual compaction
Test Plan: unit tests
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, yoshinorim, jkedgar, dhruba
Differential Revision: https://reviews.facebook.net/D64449/Recompute compaction score on SetOptions (#1346)
Summary: We didn't recompute compaction score on SetOptions, and end up not having compaction if no flush happens afterward. The PR fixing it.
Test Plan: See unit test.
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D64167/Fix AddFile() conflict with compaction output [WaitForAddFile()]
Summary:
Since AddFile unlock/lock the mutex inside LogAndApply() we need to ensure that during this period other compactions cannot run since such compactions are not aware of the file we are ingesting and could create a compaction that overlap wit this file
this diff add
- WaitForAddFile() call that will ensure that no AddFile() calls are being processed right now
- Call `WaitForAddFile()` in 3 locations
-- When doing manual Compaction
-- When starting automatic Compaction
-- When  doing CompactFiles()
Test Plan: unit test
Reviewers: lightmark, yiwu, andrewkr, sdong
Reviewed By: sdong
Subscribers: andrewkr, yoshinorim, jkedgar, dhruba
Differential Revision: https://reviews.facebook.net/D64383/Recover same sequence id from WAL (#1350)
Summary:
Revert the behavior where we don't read sequence id from WAL, but increase it as we replay the log. We still keep the behave for 2PC for now but will fix later.
This change fixes github issue 1339, where some writes come with WAL disabled and we may recover records with wrong sequence id.
Test Plan: Added unit test.
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D64275/forbid merge during recovery
Summary:
Mitigate regression bug of options.max_successive_merges hit during DB Recovery
For https://reviews.facebook.net/D62625
Test Plan: make all check
Reviewers: horuff, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D62655/Fix DBImpl::GetWalPreallocateBlockSize Mac build error
Summary: Specify type param with std::min to resolve compile error on Mac.
Test Plan: https://travis-ci.org/facebook/rocksdb/builds/161223845
Reviewers: sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D64143/DBImpl::GetWalPreallocateBlockSize() should return size_t
Summary: WritableFile::SetPreallocationBlockSize() requires parameter as size_t, and options used in DBImpl::GetWalPreallocateBlockSize() are all size_t. WritableFile::SetPreallocationBlockSize() should return size_t to avoid build break if size_t is not uint64_t.
Test Plan: Run existing tests.
Reviewers: andrewkr, IslamAbdelRahman, yiwu
Reviewed By: yiwu
Subscribers: leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D64137/Fix recovery for WALs without data for all CFs
Summary:
if one or more CFs had no data in the WAL, the log number that's used
by FindObsoleteFiles() wasn't updated. We need to treat this case the same as
if the data for that WAL had been flushed.
Test Plan: new unit test
Reviewers: IslamAbdelRahman, yiwu, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D63963/Summary: (#1313)
If log recycling is enabled with the rocksdb (recycle_log_file_num=16)
db->Writebatch is erroring out with keynotfound after ~5-6 hours of run
(1M seq but can happen to any workload I guess).See my detailed bug
report here (https://github.com/facebook/rocksdb/issues/1303).
This commit is the fix for this, a check is been added not to delete
the log file if it is already there in the recycle list.
Test Plan:
Unit tested it and ran the similar profile. Not reproducing anymore./Temporarily revert Prev() prefix support
Summary:
Temporarily revert commits for supporting prefix Prev() to unblock MyRocks and RocksDB release
These are the commits reverted
- 6a14d55bd913490dbd61d682567e6e0625756c0d
- b18f9c9eace89d63f37432ce1a3dba48bddbcef0
- db74b1a21905336e2c178ff1f2ffd12c7852b7b8
- 2482d5fb45d8f01b0b065d649d01f43dacad799c
Test Plan: make check -j64
Reviewers: sdong, lightmark
Reviewed By: lightmark
Subscribers: andrewkr, dhruba, yoshinorim
Differential Revision: https://reviews.facebook.net/D63789/Fix build error on Windows (AppVeyor) (#1315)
Add 'cf_options' to source list and db_imple.cc
fix casting/support Prev() in prefix seek mode
Summary: As title, make sure Prev() works as expected with Next() when the current iter->key() in the range of the same prefix in prefix seek mode
Test Plan: make all check -j64 (add prefix_test with PrefixSeekModePrev test case)
Reviewers: andrewkr, sdong, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: yoshinorim, andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D61419/Mitigate regression bug of options.max_successive_merges hit during DB Recovery
Summary:
After 1b8a2e8fdd1db0dac3cb50228065f8e7e43095f0, DB Pointer is passed to WriteBatchInternal::InsertInto() while DB recovery. This can cause deadlock if options.max_successive_merges hits. In that case DB::Get() will be called. Get() will try to acquire the DB mutex, which is already held by the DB::Open(), causing a deadlock condition.
This commit mitigates the problem by not passing the DB pointer unless 2PC is allowed.
Test Plan: Add a new test and run it.
Reviewers: IslamAbdelRahman, andrewkr, kradhakrishnan, horuff
Reviewed By: kradhakrishnan
Subscribers: leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D62625/Persist data during user initiated shutdown
Summary:
Move the manual memtable flush for databases containing data that has
bypassed the WAL from DBImpl's destructor to CancleAllBackgroundWork().
CancelAllBackgroundWork() is a publicly exposed API which allows
async operations performed by background threads to be disabled on a
database. In effect, this places the database into a ""shutdown"" state
in advance of calling the database object's destructor. No compactions
or flushing of SST files can occur once a call to this API completes.
When writes are issued to a database with WriteOptions::disableWAL
set to true, DBImpl::has_unpersisted_data_ is set so that
memtables can be flushed when the database object is destroyed. If
CancelAllBackgroundWork() has been called prior to DBImpl's destructor,
this flush operation is not possible and is skipped, causing unnecessary
loss of data.
Since CancelAllBackgroundWork() is already invoked by DBImpl's destructor
in order to perform the thread join portion of its cleanup processing,
moving the manual memtable flush to CancelAllBackgroundWork() ensures
data is persisted regardless of client behavior.
Test Plan:
Write an amount of data that will not cause a memtable flush to a rocksdb
database with all writes marked with WriteOptions::disableWAL. Properly
""close"" the database. Reopen database and verify that the data was
persisted.
Reviewers: IslamAbdelRahman, yiwu, yoshinorim, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D62277/"
rocksdb,"Fix compaction conflict with running compaction
Summary:
Issue scenario:
(1) We have 3 files in L1 and we issue a compaction that will compact them into 1 file in L2
(2) While compaction (1) is running, we flush a file into L0 and trigger another compaction that decide to move this file to L1 and then move it again to L2 (this file don't overlap with any other files)
(3) compaction (1) finishes and install the file it generated in L2, but this file overlap with the file we generated in (2) so we break the LSM consistency
Looks like this issue can be triggered by using non-exclusive manual compaction or AddFile()
Test Plan: unit tests
Reviewers: sdong
Reviewed By: sdong
Subscribers: hermanlee4, jkedgar, andrewkr, dhruba, yoshinorim
Differential Revision: https://reviews.facebook.net/D64947/forbid merge during recovery
Summary:
Mitigate regression bug of options.max_successive_merges hit during DB Recovery
For https://reviews.facebook.net/D62625
Test Plan: make all check
Reviewers: horuff, sdong
Reviewed By: sdong
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D62655/Mitigate regression bug of options.max_successive_merges hit during DB Recovery
Summary:
After 1b8a2e8fdd1db0dac3cb50228065f8e7e43095f0, DB Pointer is passed to WriteBatchInternal::InsertInto() while DB recovery. This can cause deadlock if options.max_successive_merges hits. In that case DB::Get() will be called. Get() will try to acquire the DB mutex, which is already held by the DB::Open(), causing a deadlock condition.
This commit mitigates the problem by not passing the DB pointer unless 2PC is allowed.
Test Plan: Add a new test and run it.
Reviewers: IslamAbdelRahman, andrewkr, kradhakrishnan, horuff
Reviewed By: kradhakrishnan
Subscribers: leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D62625/"
rocksdb,"remove tabs and duplicate #include in c api
Summary:
fix lint error about tabs and duplicate includes.
Closes https://github.com/facebook/rocksdb/pull/1476
Differential Revision: D4149646
Pulled By: lightmark
fbshipit-source-id: 2e0a632/Add C api for RateLimiter
Summary:
Add C api for RateLimiter.
Closes https://github.com/facebook/rocksdb/pull/1455
Differential Revision: D4116362
Pulled By: yiwu-arbug
fbshipit-source-id: cb05a8d/Change max_bytes_for_level_multiplier to double
Summary: Closes https://github.com/facebook/rocksdb/pull/1427
Differential Revision: D4094732
Pulled By: yiwu-arbug
fbshipit-source-id: b9b79e9/expose IngestExternalFile to c abi
Summary:
IngestExternalFile is very useful when doing bulk load. This pr expose this API to c so many bindings can benefit from it too.
Closes https://github.com/facebook/rocksdb/pull/1454
Differential Revision: D4113420
Pulled By: yiwu-arbug
fbshipit-source-id: 307c6ae/Fix C api memtable rep bugs. (#1328)/"
rocksdb,"Change max_bytes_for_level_multiplier to double
Summary: Closes https://github.com/facebook/rocksdb/pull/1427
Differential Revision: D4094732
Pulled By: yiwu-arbug
fbshipit-source-id: b9b79e9/Fix a bug that may cause a deleted row to appear again
Summary:
The previous fix of reappearing of a deleted row 0ce258f9b37c8661ea326039372bef8f185615ef missed a corner case, which can be reproduced using test CompactionPickerTest.OverlappingUserKeys7. Consider such an example:
input level file: 1[B E] 2[F H]
output level file: 3[A C] 4[D I] 5[I K]
First file 2 is picked, which overlaps to file 4. 4 expands to 5. Now the all range is [D K] with 2 output level files. When we try to expand that, [D K] overlaps with file 1 and 2 in the input level, and 1 and 2 overlaps with 3 and 4 in the output level. So we end up with picking 3 and 4 in the output level. Without expanding, it also has 2 files, so we determine the output level doesn't change, although they are the different two files.
The fix is to expand the output level files after we picked 3 and 4. In that case, there will be three output level files so we will abort the expanding.
I also added two unit tests related to marked_for_compaction and being_compacted. They have been passing though.
Test Plan: Run the new unit test, as well as all other tests.
Reviewers: andrewkr, IslamAbdelRahman
Reviewed By: IslamAbdelRahman
Subscribers: yoshinorim, leveldb, andrewkr, dhruba
Differential Revision: https://reviews.facebook.net/D65373/Fix compaction conflict with running compaction
Summary:
Issue scenario:
(1) We have 3 files in L1 and we issue a compaction that will compact them into 1 file in L2
(2) While compaction (1) is running, we flush a file into L0 and trigger another compaction that decide to move this file to L1 and then move it again to L2 (this file don't overlap with any other files)
(3) compaction (1) finishes and install the file it generated in L2, but this file overlap with the file we generated in (2) so we break the LSM consistency
Looks like this issue can be triggered by using non-exclusive manual compaction or AddFile()
Test Plan: unit tests
Reviewers: sdong
Reviewed By: sdong
Subscribers: hermanlee4, jkedgar, andrewkr, dhruba, yoshinorim
Differential Revision: https://reviews.facebook.net/D64947/"
rocksdb,"Fix mac build/Add AddFile() InternalStats for Total files/L0 files/total keys ingested
Summary:
Report more information about the ingested files in CF InternalStats
- Total files
- Total L0 files
- Total keys
There was also noticed that we were reporting files that failed to ingest, fix this bug
Test Plan: print stats in tests
Reviewers: sdong, andrewkr, lightmark
Reviewed By: lightmark
Subscribers: jkedgar, andrewkr, dhruba, yoshinorim
Differential Revision: https://reviews.facebook.net/D63039/"
rocksdb,"Ensure Correct Behavior of StatsLevel kExceptDetailedTimers and kExceptTimeForMutex  (#1308)
* Fix StatsLevel so that kExceptTimeForMutex leaves compression stats enabled and kExceptDetailedTimers disables mutex lock stats. Also change default stats level to kExceptDetailedTimers (disabling both compression and mutex timing).
* Changed order of StatsLevel enum to simplify logic for determining what stats to record./"
rocksdb,"Change max_bytes_for_level_multiplier to double
Summary: Closes https://github.com/facebook/rocksdb/pull/1427
Differential Revision: D4094732
Pulled By: yiwu-arbug
fbshipit-source-id: b9b79e9/Compaction Support for Range Deletion
Summary:
This diff introduces RangeDelAggregator, which takes ownership of iterators
provided to it via AddTombstones(). The tombstones are organized in a two-level
map (snapshot stripe -> begin key -> tombstone). Tombstone creation avoids data
copy by holding Slices returned by the iterator, which remain valid thanks to pinning.
For compaction, we create a hierarchical range tombstone iterator with structure
matching the iterator over compaction input data. An aggregator based on that
iterator is used by CompactionIterator to determine which keys are covered by
range tombstones. In case of merge operand, the same aggregator is used by
MergeHelper. Upon finishing each file in the compaction, relevant range tombstones
are added to the output file's range tombstone metablock and file boundaries are
updated accordingly.
To check whether a key is covered by range tombstone, RangeDelAggregator::ShouldDelete()
considers tombstones in the key's snapshot stripe. When this function is used outside of
compaction, it also checks newer stripes, which can contain covering tombstones. Currently
the intra-stripe check involves a linear scan; however, in the future we plan to collapse ranges
within a stripe such that binary search can be used.
RangeDelAggregator::AddToBuilder() adds all range tombstones in the table's key-range
to a new table's range tombstone meta-block. Since range tombstones may fall in the gap
between files, we may need to extend some files' key-ranges. The strategy is (1) first file
extends as far left as possible and other files do not extend left, (2) all files extend right
until either the start of the next file or the end of the last range tombstone in the gap,
whichever comes first.
One other notable change is adding release/move semantics to ScopedArenaIterator
such that it can be used to transfer ownership of an arena-allocated iterator, similar to
how unique_ptr is used for malloc'd data.
Depends on D61473
Test Plan: compaction_iterator_test, mock_table, end-to-end tests in D63927
Reviewers: sdong, IslamAbdelRahman, wanning, yhchiang, lightmark
Reviewed By: lightmark
Subscribers: andrewkr, dhruba, leveldb
Differential Revision: https://reviews.facebook.net/D62205/Support running consistency checks in release mode
Summary:
We always run consistency checks when compiling in debug mode
allow users to set Options::force_consistency_checks to true to be able to run such checks even when compiling in release mode
Test Plan:
make check -j64
make release
Reviewers: lightmark, sdong, yiwu
Reviewed By: yiwu
Subscribers: hermanlee4, andrewkr, yoshinorim, jkedgar, dhruba
Differential Revision: https://reviews.facebook.net/D64701/"
rocksdb,"Fix RocksDB Lite build failure in c_test.cc
Summary:
Fix the following RocksDB Lite build failure in c_test.cc
db/c_test.c:1051:3: error: implicit declaration of function 'fprintf' is invalid in C99 [-Werror,-Wimplicit-function-declaration]
fprintf(stderr, ""SKIPPED\n"");
^
db/c_test.c:1051:3: error: declaration of built-in function 'fprintf' requires inclusion of the header <stdio.h> [-Werror,-Wbuiltin-requires-header]
db/c_test.c:1051:11: error: use of undeclared identifier 'stderr'
fprintf(stderr, ""SKIPPED\n"");
^
3 errors generated.
Closes https://github.com/facebook/rocksdb/pull/1479
Differential Revision: D4151160
Pulled By: yhchiang
fbshipit-source-id: a471a30/remove tabs and duplicate #include in c api
Summary:
fix lint error about tabs and duplicate includes.
Closes https://github.com/facebook/rocksdb/pull/1476
Differential Revision: D4149646
Pulled By: lightmark
fbshipit-source-id: 2e0a632/Add C api for RateLimiter
Summary:
Add C api for RateLimiter.
Closes https://github.com/facebook/rocksdb/pull/1455
Differential Revision: D4116362
Pulled By: yiwu-arbug
fbshipit-source-id: cb05a8d/expose IngestExternalFile to c abi
Summary:
IngestExternalFile is very useful when doing bulk load. This pr expose this API to c so many bindings can benefit from it too.
Closes https://github.com/facebook/rocksdb/pull/1454
Differential Revision: D4113420
Pulled By: yiwu-arbug
fbshipit-source-id: 307c6ae/Fix C api memtable rep bugs. (#1328)/"
rocksdb,"Move db_bench flags out of unnamed namespace
Summary:
I want to be able to, e.g., DECLARE_string(statistics_string); in my application such that I can override the default value of statistics_string. For this to work, we need to remove the unnamed namespace containing all the flags, and make sure all variables/functions covered by that namespace are static.
Replaces #1828 due to internal tool issues.
Closes https://github.com/facebook/rocksdb/pull/1844
Differential Revision: D4515124
Pulled By: ajkr
fbshipit-source-id: 23b695e/Generalize Env registration framework
Summary:
The Env registration framework supports registering client Envs and selecting which one to instantiate according to a text field. This enabled things like adding the -env_uri argument to db_bench, so the same binary could be reused with different Envs just by changing CLI config.
Now this problem has come up again in a non-Env context, as I want to instantiate a client Statistics implementation from db_bench, which is configured entirely via text parameters. Also, in the future we may wish to use it for deserializing client objects when loading OPTIONS file.
This diff generalizes the Env registration logic to work with arbitrary types.
- Generalized registration and instantiation code by templating them
- The entire implementation is in a header file as that's Google style guide's recommendation for template definitions
- Pattern match with std::regex_match rather than checking prefix, which was the previous behavior
- Rename functions/files to be non-Env-specific
Closes https://github.com/facebook/rocksdb/pull/1776
Differential Revision: D4421933
Pulled By: ajkr
fbshipit-source-id: 34647d1/Fix MS warnings. Use ROCKSDB_Prsz for size_t.
Summary: Closes https://github.com/facebook/rocksdb/pull/1737
Differential Revision: D4378852
Pulled By: yiwu-arbug
fbshipit-source-id: ba8b02d/Update db_bench and sst_dump to test with block cache mid-point inser?
Summary:
?tion
Add flags in db_bench to test with block cache mid-point insertion.
Also update sst_dump to dump total block sizes of each type. I find it
useful to look at these test db stats and I don't know if we have them
elsewhere.
Closes https://github.com/facebook/rocksdb/pull/1706
Differential Revision: D4355812
Pulled By: yiwu-arbug
fbshipit-source-id: 3e4a348/direct io write support
Summary:
rocksdb direct io support
```
[gzh@dev11575.prn2 ~/rocksdb] ./db_bench -benchmarks=fillseq --num=1000000
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
RocksDB:    version 5.0
Date:       Wed Nov 23 13:17:43 2016
CPU:        40 * Intel(R) Xeon(R) CPU E5-2660 v2 @ 2.20GHz
CPUCache:   25600 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Compression: Snappy
Memtablerep: skip_list
Perf Level: 1
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
DB path: [/tmp/rocksdbtest-112628/dbbench]
fillseq      :       4.393 micros/op 227639 ops/sec;   25.2 MB/s
[gzh@dev11575.prn2 ~/roc
Closes https://github.com/facebook/rocksdb/pull/1564
Differential Revision: D4241093
Pulled By: lightmark
fbshipit-source-id: 98c29e3/Gcc-7 buffer size insufficient
Summary:
Bunch of commits related to insufficient buffer size. Errors in individual commits.
Closes https://github.com/facebook/rocksdb/pull/1673
Differential Revision: D4332127
Pulled By: IslamAbdelRahman
fbshipit-source-id: 878f73c/fix db_bench argument type
Summary: Closes https://github.com/facebook/rocksdb/pull/1633
Differential Revision: D4298161
Pulled By: yiwu-arbug
fbshipit-source-id: 2c7af35/Add memtable_insert_with_hint_prefix_size option to db_bench
Summary:
Add memtable_insert_with_hint_prefix_size option to db_bench
Closes https://github.com/facebook/rocksdb/pull/1604
Differential Revision: D4260549
Pulled By: yiwu-arbug
fbshipit-source-id: cee5ef7/Cache heap::downheap() root comparison (optimize heap cmp call)
Summary:
Reduce number of comparisons in heap by caching which child node in the first level is smallest (left_child or right_child)
So next time we can compare directly against the smallest child
I see that the total number of calls to comparator drops significantly when using this optimization
Before caching (~2mil key comparison for iterating the DB)
```
$ DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq"" --db=""/dev/shm/heap_opt"" --use_existing_db --disable_auto_compactions --cache_size=1000000000  --perf_level=2
readseq      :       0.338 micros/op 2959201 ops/sec;  327.4 MB/s user_key_comparison_count = 2000008
```
After caching (~1mil key comparison for iterating the DB)
```
$ DEBUG_LEVEL=0 make db_bench -j64 && ./db_bench --benchmarks=""readseq"" --db=""/dev/shm/heap_opt"" --use_existing_db --disable_auto_compactions --cache_size=1000000000 --perf_level=2
readseq      :       0.309 micros/op 3236801 ops/sec;  358.1 MB/s user_key_comparison_count = 1000011
```
It also improves
Closes https://github.com/facebook/rocksdb/pull/1600
Differential Revision: D4256027
Pulled By: IslamAbdelRahman
fbshipit-source-id: 76fcc66/"
rocksdb,"Generalize Env registration framework
Summary:
The Env registration framework supports registering client Envs and selecting which one to instantiate according to a text field. This enabled things like adding the -env_uri argument to db_bench, so the same binary could be reused with different Envs just by changing CLI config.
Now this problem has come up again in a non-Env context, as I want to instantiate a client Statistics implementation from db_bench, which is configured entirely via text parameters. Also, in the future we may wish to use it for deserializing client objects when loading OPTIONS file.
This diff generalizes the Env registration logic to work with arbitrary types.
- Generalized registration and instantiation code by templating them
- The entire implementation is in a header file as that's Google style guide's recommendation for template definitions
- Pattern match with std::regex_match rather than checking prefix, which was the previous behavior
- Rename functions/files to be non-Env-specific
Closes https://github.com/facebook/rocksdb/pull/1776
Differential Revision: D4421933
Pulled By: ajkr
fbshipit-source-id: 34647d1/gcc-7 requires include <functional> for std::function
Summary:
Fixes compile error:
In file included from ./util/statistics.h:17:0,
from ./util/stop_watch.h:8,
from ./util/perf_step_timer.h:9,
from ./util/iostats_context_imp.h:8,
from ./util/posix_logger.h:27,
from ./port/util_logger.h:18,
from ./db/auto_roll_logger.h:15,
from db/auto_roll_logger.cc:6:
./util/thread_local.h:65:16: error: 'function' in namespace 'std' does not name a template type
typedef std::function<void(void*, void*)> FoldFunc;
Closes https://github.com/facebook/rocksdb/pull/1656
Differential Revision: D4318702
Pulled By: yiwu-arbug
fbshipit-source-id: 8c5d17a/Range deletion microoptimizations
Summary:
- Made RangeDelAggregator's InternalKeyComparator member a reference-to-const so we don't need to copy-construct it. Also added InternalKeyComparator to ImmutableCFOptions so we don't need to construct one for each DBIter.
- Made MemTable::NewRangeTombstoneIterator and the table readers' NewRangeTombstoneIterator() functions return nullptr instead of NewEmptyInternalIterator to avoid the allocation. Updated callers accordingly.
Closes https://github.com/facebook/rocksdb/pull/1548
Differential Revision: D4208169
Pulled By: ajkr
fbshipit-source-id: 2fd65cf/"
rocksdb,"db_stress support for range deletions
Summary:
made db_stress capable of adding range deletions to its db and verifying their correctness. i'll make db_crashtest.py use this option later once the collapsing optimization (https://github.com/facebook/rocksdb/pull/1614) is committed because currently it slows down the test too much.
Closes https://github.com/facebook/rocksdb/pull/1625
Differential Revision: D4293939
Pulled By: ajkr
fbshipit-source-id: d3beb3a/"
rocksdb,"Update db_bench and sst_dump to test with block cache mid-point inser?
Summary:
?tion
Add flags in db_bench to test with block cache mid-point insertion.
Also update sst_dump to dump total block sizes of each type. I find it
useful to look at these test db stats and I don't know if we have them
elsewhere.
Closes https://github.com/facebook/rocksdb/pull/1706
Differential Revision: D4355812
Pulled By: yiwu-arbug
fbshipit-source-id: 3e4a348/"
rocksdb,"direct io write support
Summary:
rocksdb direct io support
```
[gzh@dev11575.prn2 ~/rocksdb] ./db_bench -benchmarks=fillseq --num=1000000
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
RocksDB:    version 5.0
Date:       Wed Nov 23 13:17:43 2016
CPU:        40 * Intel(R) Xeon(R) CPU E5-2660 v2 @ 2.20GHz
CPUCache:   25600 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Compression: Snappy
Memtablerep: skip_list
Perf Level: 1
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
DB path: [/tmp/rocksdbtest-112628/dbbench]
fillseq      :       4.393 micros/op 227639 ops/sec;   25.2 MB/s
[gzh@dev11575.prn2 ~/roc
Closes https://github.com/facebook/rocksdb/pull/1564
Differential Revision: D4241093
Pulled By: lightmark
fbshipit-source-id: 98c29e3/Return finer-granularity status from Env::GetChildren*
Summary:
It'd be nice to use the error status type to distinguish
between user error and system error. For example, GetChildren can fail
listing a backup directory's contents either because a bad path was provided
(user error) or because an operation failed, e.g., a remote storage service
call failed (system error). In the former case, we want to continue and treat
the backup directory as empty; in the latter case, we want to immediately
propagate the error to the caller.
This diff uses NotFound to indicate user error and IOError to indicate
system error. Previously IOError indicated both.
Closes https://github.com/facebook/rocksdb/pull/1644
Differential Revision: D4312157
Pulled By: ajkr
fbshipit-source-id: 51b4f24/"
rocksdb,"Gcc 7 error expansion to defined
Summary:
sorry if these gcc-7/clang-4 cleanups are getting tedious.
Closes https://github.com/facebook/rocksdb/pull/1658
Differential Revision: D4318792
Pulled By: yiwu-arbug
fbshipit-source-id: 8e85891/"
rocksdb,"Gcc 7 error expansion to defined
Summary:
sorry if these gcc-7/clang-4 cleanups are getting tedious.
Closes https://github.com/facebook/rocksdb/pull/1658
Differential Revision: D4318792
Pulled By: yiwu-arbug
fbshipit-source-id: 8e85891/"
rocksdb,"Gcc 7 error expansion to defined
Summary:
sorry if these gcc-7/clang-4 cleanups are getting tedious.
Closes https://github.com/facebook/rocksdb/pull/1658
Differential Revision: D4318792
Pulled By: yiwu-arbug
fbshipit-source-id: 8e85891/"
rocksdb,"Fix OSX build break after the fallocate change
Summary:
The recent update about fallocate failed OSX build. Fix it.
Closes https://github.com/facebook/rocksdb/pull/1830
Differential Revision: D4500235
Pulled By: siying
fbshipit-source-id: a5f2b40/Remove fadvise with direct IO read
Summary:
Remove the logic since we don't use buffer cache with direct IO. Resolve
read regression we currently have.
Closes https://github.com/facebook/rocksdb/pull/1782
Differential Revision: D4430408
Pulled By: yiwu-arbug
fbshipit-source-id: 5557bba/fix warning of unused direct io helper functions
Summary:
add build guard
Closes https://github.com/facebook/rocksdb/pull/1771
Differential Revision: D4410779
Pulled By: siying
fbshipit-source-id: 3796c30/Guarding extra fallocate call with TRAVIS because its not working pro
Summary:
perly on travis
There is some old code in PosixWritableFile::Close(), which
truncates the file to the measured size and then does an extra fallocate
with KEEP_SIZE. This is commented as a failsafe because in some
cases ftruncate doesn't do the right job (I don't know of an instance of
this btw). However doing an fallocate with KEEP_SIZE should not increase
the file size. However on Travis Worker which is Docker (likely AUFS )
its not working. There are comments on web that show that the AUFS
author had initially not implemented fallocate, and then did it later.
So not sure what is the quality of the implementation.
Closes https://github.com/facebook/rocksdb/pull/1765
Differential Revision: D4401340
Pulled By: anirbanr-fb
fbshipit-source-id: e2d8100/direct io write support
Summary:
rocksdb direct io support
```
[gzh@dev11575.prn2 ~/rocksdb] ./db_bench -benchmarks=fillseq --num=1000000
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
RocksDB:    version 5.0
Date:       Wed Nov 23 13:17:43 2016
CPU:        40 * Intel(R) Xeon(R) CPU E5-2660 v2 @ 2.20GHz
CPUCache:   25600 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Compression: Snappy
Memtablerep: skip_list
Perf Level: 1
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
DB path: [/tmp/rocksdbtest-112628/dbbench]
fillseq      :       4.393 micros/op 227639 ops/sec;   25.2 MB/s
[gzh@dev11575.prn2 ~/roc
Closes https://github.com/facebook/rocksdb/pull/1564
Differential Revision: D4241093
Pulled By: lightmark
fbshipit-source-id: 98c29e3/"
rocksdb,"Return finer-granularity status from Env::GetChildren*
Summary:
It'd be nice to use the error status type to distinguish
between user error and system error. For example, GetChildren can fail
listing a backup directory's contents either because a bad path was provided
(user error) or because an operation failed, e.g., a remote storage service
call failed (system error). In the former case, we want to continue and treat
the backup directory as empty; in the latter case, we want to immediately
propagate the error to the caller.
This diff uses NotFound to indicate user error and IOError to indicate
system error. Previously IOError indicated both.
Closes https://github.com/facebook/rocksdb/pull/1644
Differential Revision: D4312157
Pulled By: ajkr
fbshipit-source-id: 51b4f24/"
rocksdb,"direct io write support
Summary:
rocksdb direct io support
```
[gzh@dev11575.prn2 ~/rocksdb] ./db_bench -benchmarks=fillseq --num=1000000
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
RocksDB:    version 5.0
Date:       Wed Nov 23 13:17:43 2016
CPU:        40 * Intel(R) Xeon(R) CPU E5-2660 v2 @ 2.20GHz
CPUCache:   25600 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Compression: Snappy
Memtablerep: skip_list
Perf Level: 1
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
DB path: [/tmp/rocksdbtest-112628/dbbench]
fillseq      :       4.393 micros/op 227639 ops/sec;   25.2 MB/s
[gzh@dev11575.prn2 ~/roc
Closes https://github.com/facebook/rocksdb/pull/1564
Differential Revision: D4241093
Pulled By: lightmark
fbshipit-source-id: 98c29e3/Return finer-granularity status from Env::GetChildren*
Summary:
It'd be nice to use the error status type to distinguish
between user error and system error. For example, GetChildren can fail
listing a backup directory's contents either because a bad path was provided
(user error) or because an operation failed, e.g., a remote storage service
call failed (system error). In the former case, we want to continue and treat
the backup directory as empty; in the latter case, we want to immediately
propagate the error to the caller.
This diff uses NotFound to indicate user error and IOError to indicate
system error. Previously IOError indicated both.
Closes https://github.com/facebook/rocksdb/pull/1644
Differential Revision: D4312157
Pulled By: ajkr
fbshipit-source-id: 51b4f24/"
rocksdb,"Gcc 7 error expansion to defined
Summary:
sorry if these gcc-7/clang-4 cleanups are getting tedious.
Closes https://github.com/facebook/rocksdb/pull/1658
Differential Revision: D4318792
Pulled By: yiwu-arbug
fbshipit-source-id: 8e85891/"
rocksdb,"Unified InlineSkipList::Insert algorithm with hinting
Summary:
This PR is based on nbronson's diff with small
modifications to wire it up with existing interface. Comparing to
previous version, this approach works better for inserting keys in
decreasing order or updating the same key, and impose less restriction
to the prefix extractor.
---- Summary from original diff ----
This diff introduces a single InlineSkipList::Insert that unifies
the existing sequential insert optimization (prev_), concurrent insertion,
and insertion using externally-managed insertion point hints.
There's a deep symmetry between insertion hints (cursors) and the
concurrent algorithm.  In both cases we have partial information from
the recent past that is likely but not certain to be accurate.  This diff
introduces the struct InlineSkipList::Splice, which encodes predecessor
and successor information in the same form that was previously only used
within a single call to InsertConcurrently.  Splice holds information
about an insertion point that can be used to levera
Closes https://github.com/facebook/rocksdb/pull/1561
Differential Revision: D4217283
Pulled By: yiwu-arbug
fbshipit-source-id: 33ee437/Optimize sequential insert into memtable - Part 1: Interface
Summary:
Currently our skip-list have an optimization to speedup sequential
inserts from a single stream, by remembering the last insert position.
We extend the idea to support sequential inserts from multiple streams,
and even tolerate small reordering wihtin each stream.
This PR is the interface part adding the following:
- Add `memtable_insert_prefix_extractor` to allow specifying prefix for each key.
- Add `InsertWithHint()` interface to memtable, to allow underlying
implementation to return a hint of insert position, which can be later
pass back to optimize inserts.
- Memtable will maintain a map from prefix to hints and pass the hint
via `InsertWithHint()` if `memtable_insert_prefix_extractor` is non-null.
Closes https://github.com/facebook/rocksdb/pull/1419
Differential Revision: D4079367
Pulled By: yiwu-arbug
fbshipit-source-id: 3555326/"
rocksdb,"direct io write support
Summary:
rocksdb direct io support
```
[gzh@dev11575.prn2 ~/rocksdb] ./db_bench -benchmarks=fillseq --num=1000000
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
RocksDB:    version 5.0
Date:       Wed Nov 23 13:17:43 2016
CPU:        40 * Intel(R) Xeon(R) CPU E5-2660 v2 @ 2.20GHz
CPUCache:   25600 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Compression: Snappy
Memtablerep: skip_list
Perf Level: 1
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
DB path: [/tmp/rocksdbtest-112628/dbbench]
fillseq      :       4.393 micros/op 227639 ops/sec;   25.2 MB/s
[gzh@dev11575.prn2 ~/roc
Closes https://github.com/facebook/rocksdb/pull/1564
Differential Revision: D4241093
Pulled By: lightmark
fbshipit-source-id: 98c29e3/"
rocksdb,"Fix rocksdb::Status::getState
Summary:
This fixes the Java API for Status#getState use in Native code and also simplifies the implementation of rocksdb::Status::getState.
Closes https://github.com/facebook/rocksdb/issues/1688
Closes https://github.com/facebook/rocksdb/pull/1714
Differential Revision: D4364181
Pulled By: yiwu-arbug
fbshipit-source-id: 8e073b4/gcc-7 requires include <functional> for std::function
Summary:
Fixes compile error:
In file included from ./util/statistics.h:17:0,
from ./util/stop_watch.h:8,
from ./util/perf_step_timer.h:9,
from ./util/iostats_context_imp.h:8,
from ./util/posix_logger.h:27,
from ./port/util_logger.h:18,
from ./db/auto_roll_logger.h:15,
from db/auto_roll_logger.cc:6:
./util/thread_local.h:65:16: error: 'function' in namespace 'std' does not name a template type
typedef std::function<void(void*, void*)> FoldFunc;
Closes https://github.com/facebook/rocksdb/pull/1656
Differential Revision: D4318702
Pulled By: yiwu-arbug
fbshipit-source-id: 8c5d17a/Fixes for MSVC compilation
Summary: Closes https://github.com/facebook/rocksdb/pull/1669
Differential Revision: D4327421
Pulled By: yiwu-arbug
fbshipit-source-id: 661ee0b/"
rocksdb,"gcc-7 requires include <functional> for std::function
Summary:
Fixes compile error:
In file included from ./util/statistics.h:17:0,
from ./util/stop_watch.h:8,
from ./util/perf_step_timer.h:9,
from ./util/iostats_context_imp.h:8,
from ./util/posix_logger.h:27,
from ./port/util_logger.h:18,
from ./db/auto_roll_logger.h:15,
from db/auto_roll_logger.cc:6:
./util/thread_local.h:65:16: error: 'function' in namespace 'std' does not name a template type
typedef std::function<void(void*, void*)> FoldFunc;
Closes https://github.com/facebook/rocksdb/pull/1656
Differential Revision: D4318702
Pulled By: yiwu-arbug
fbshipit-source-id: 8c5d17a/"
rocksdb,"direct io write support
Summary:
rocksdb direct io support
```
[gzh@dev11575.prn2 ~/rocksdb] ./db_bench -benchmarks=fillseq --num=1000000
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
RocksDB:    version 5.0
Date:       Wed Nov 23 13:17:43 2016
CPU:        40 * Intel(R) Xeon(R) CPU E5-2660 v2 @ 2.20GHz
CPUCache:   25600 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Compression: Snappy
Memtablerep: skip_list
Perf Level: 1
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
DB path: [/tmp/rocksdbtest-112628/dbbench]
fillseq      :       4.393 micros/op 227639 ops/sec;   25.2 MB/s
[gzh@dev11575.prn2 ~/roc
Closes https://github.com/facebook/rocksdb/pull/1564
Differential Revision: D4241093
Pulled By: lightmark
fbshipit-source-id: 98c29e3/"
rocksdb,"fix batchresult handle leak
Summary:
This is related to PR https://github.com/facebook/rocksdb/pull/1642
Sorry about this extra PR, as my workflow was messed up when I checked in another work item by accident.
Closes https://github.com/facebook/rocksdb/pull/1681
Differential Revision: D4379513
Pulled By: yiwu-arbug
fbshipit-source-id: a668d4c/"
rocksdb,"fix batchresult handle leak
Summary:
This is related to PR https://github.com/facebook/rocksdb/pull/1642
Sorry about this extra PR, as my workflow was messed up when I checked in another work item by accident.
Closes https://github.com/facebook/rocksdb/pull/1681
Differential Revision: D4379513
Pulled By: yiwu-arbug
fbshipit-source-id: a668d4c/"
rocksdb,"direct io write support
Summary:
rocksdb direct io support
```
[gzh@dev11575.prn2 ~/rocksdb] ./db_bench -benchmarks=fillseq --num=1000000
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
RocksDB:    version 5.0
Date:       Wed Nov 23 13:17:43 2016
CPU:        40 * Intel(R) Xeon(R) CPU E5-2660 v2 @ 2.20GHz
CPUCache:   25600 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Compression: Snappy
Memtablerep: skip_list
Perf Level: 1
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
DB path: [/tmp/rocksdbtest-112628/dbbench]
fillseq      :       4.393 micros/op 227639 ops/sec;   25.2 MB/s
[gzh@dev11575.prn2 ~/roc
Closes https://github.com/facebook/rocksdb/pull/1564
Differential Revision: D4241093
Pulled By: lightmark
fbshipit-source-id: 98c29e3/"
rocksdb,"direct io write support
Summary:
rocksdb direct io support
```
[gzh@dev11575.prn2 ~/rocksdb] ./db_bench -benchmarks=fillseq --num=1000000
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
RocksDB:    version 5.0
Date:       Wed Nov 23 13:17:43 2016
CPU:        40 * Intel(R) Xeon(R) CPU E5-2660 v2 @ 2.20GHz
CPUCache:   25600 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Compression: Snappy
Memtablerep: skip_list
Perf Level: 1
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
DB path: [/tmp/rocksdbtest-112628/dbbench]
fillseq      :       4.393 micros/op 227639 ops/sec;   25.2 MB/s
[gzh@dev11575.prn2 ~/roc
Closes https://github.com/facebook/rocksdb/pull/1564
Differential Revision: D4241093
Pulled By: lightmark
fbshipit-source-id: 98c29e3/"
rocksdb,"Fix backupable db test
Summary:
#1733 started using SizeFileBytes(), so our dummy log file implementation should stop asserting that this function isn't called.
Closes https://github.com/facebook/rocksdb/pull/1740
Differential Revision: D4376055
Pulled By: ajkr
fbshipit-source-id: 2854d89/Fail BackupEngine::Open upon meta-file read error
Summary:
We used to treat any failure to read a backup's meta-file as if the backup were corrupted; however, we should distinguish corruption errors from errors in the backup Env. This fixes an issue where callers would get inconsistent results from GetBackupInfo() if they called it on an engine that encountered Env error during initialization. Now we fail Initialize() in this case so callers cannot invoke GetBackupInfo() on such engines.
Closes https://github.com/facebook/rocksdb/pull/1654
Differential Revision: D4318573
Pulled By: ajkr
fbshipit-source-id: f7a7c54/"
rocksdb,"option_change_migration_test: force full compaction when needed
Summary:
When option_change_migration_test decides to go with a full compaction, we don't force a compaction but allow trivial move. This can cause assert failure if the destination is level 0. Fix it by forcing the full compaction to skip trivial move if the destination level is L0.
Closes https://github.com/facebook/rocksdb/pull/1518
Differential Revision: D4183610
Pulled By: siying
fbshipit-source-id: dea482b/"
rocksdb,"Gcc 7 fallthrough
Summary:
hopefully the last of the gcc-7 compile errors
Closes https://github.com/facebook/rocksdb/pull/1675
Differential Revision: D4332106
Pulled By: IslamAbdelRahman
fbshipit-source-id: 139448c/"
rocksdb,"table/block_based_table_builder.cc: intentional fallthrough - comment to match gcc pattern
Summary:
The gcc-7 code for parsing comments (libcpp/lex.c) didn't match
the intentional fallthough in this comment.
table/block_based_table_builder.cc: In member function 'void rocksdb::BlockBasedTableBuilder::WriteRawBlock(const rocksdb::Slice&, rocksdb::CompressionType, rocksdb::BlockHandle*)':
table/block_based_table_builder.cc:754:22: error: this statement may fall through [-Werror=implicit-fallthrough=]
assert(false);
^
table/block_based_table_builder.cc:756:7: note: here
case kCRC32c: {
^~~~
cc1plus: all warnings being treated as errors
Closes https://github.com/facebook/rocksdb/pull/1661
Differential Revision: D4318817
Pulled By: yiwu-arbug
fbshipit-source-id: e67d171/"
rocksdb,"Dump compression dictionary meta-block
Summary:
make sst_dump print size/contents of the dictionary meta-block for easier debugging
Closes https://github.com/facebook/rocksdb/pull/1837
Differential Revision: D4506399
Pulled By: ajkr
fbshipit-source-id: b9bf668/Avoid cache lookups for range deletion meta-block
Summary:
I added the Cache::Ref() function a couple weeks ago (#1761) to make this feature possible. Like other meta-blocks, rep_->range_del_entry holds a cache handle to pin the range deletion block in uncompressed block cache for the duration of the table reader's lifetime. We can reuse this cache handle to create an iterator over this meta-block without any cache lookup. Ref() is used to increment the cache handle's refcount in case the returned iterator outlives the table reader.
Closes https://github.com/facebook/rocksdb/pull/1801
Differential Revision: D4458782
Pulled By: ajkr
fbshipit-source-id: 2883f10/Range deletion microoptimizations
Summary:
- Made RangeDelAggregator's InternalKeyComparator member a reference-to-const so we don't need to copy-construct it. Also added InternalKeyComparator to ImmutableCFOptions so we don't need to construct one for each DBIter.
- Made MemTable::NewRangeTombstoneIterator and the table readers' NewRangeTombstoneIterator() functions return nullptr instead of NewEmptyInternalIterator to avoid the allocation. Updated callers accordingly.
Closes https://github.com/facebook/rocksdb/pull/1548
Differential Revision: D4208169
Pulled By: ajkr
fbshipit-source-id: 2fd65cf/fix valgrind
Summary: Closes https://github.com/facebook/rocksdb/pull/1526
Differential Revision: D4191257
Pulled By: ajkr
fbshipit-source-id: d09dc76/"
rocksdb,"Range deletion microoptimizations
Summary:
- Made RangeDelAggregator's InternalKeyComparator member a reference-to-const so we don't need to copy-construct it. Also added InternalKeyComparator to ImmutableCFOptions so we don't need to construct one for each DBIter.
- Made MemTable::NewRangeTombstoneIterator and the table readers' NewRangeTombstoneIterator() functions return nullptr instead of NewEmptyInternalIterator to avoid the allocation. Updated callers accordingly.
Closes https://github.com/facebook/rocksdb/pull/1548
Differential Revision: D4208169
Pulled By: ajkr
fbshipit-source-id: 2fd65cf/Remove Arena in RangeDelAggregator
Summary:
The Arena construction/destruction introduced significant overhead to read-heavy workload just by creating empty vectors for its blocks, so avoid it in RangeDelAggregator.
Closes https://github.com/facebook/rocksdb/pull/1547
Differential Revision: D4207781
Pulled By: ajkr
fbshipit-source-id: 9d1c130/"
rocksdb,"Fix failed compaction_filter_example and add it into make all
Summary:
Simple patch as title
Closes https://github.com/facebook/rocksdb/pull/1512
Differential Revision: D4186994
Pulled By: siying
fbshipit-source-id: 880f9b8/"
rocksdb,"Fix wrong result in data race case related to Get()
Summary:
In theory, Get() can get a wrong result, if it races in a special with with flush. The bug can be reproduced in DBTest2.GetRaceFlush. Fix this bug by getting snapshot after referencing the super version.
Closes https://github.com/facebook/rocksdb/pull/1816
Differential Revision: D4475958
Pulled By: siying
fbshipit-source-id: bd9e67a/Add test DBTest2.GetRaceFlush which can expose a data race bug
Summary:
A current data race issue in Get() and Flush() can cause a Get() to return wrong results when a flush happened in the middle. Disable the test for now.
Closes https://github.com/facebook/rocksdb/pull/1813
Differential Revision: D4472310
Pulled By: siying
fbshipit-source-id: 5755ebd/Avoid logs_ operation out of DB mutex
Summary:
logs_.back() is called out of DB mutex, which can cause data race. We move the access into the DB mutex protection area.
Closes https://github.com/facebook/rocksdb/pull/1774
Reviewed By: AsyncDBConnMarkedDownDBException
Differential Revision: D4417472
Pulled By: AsyncDBConnMarkedDownDBException
fbshipit-source-id: 2da1f1e/Fix CompactFiles() bug when used with CompactionFilter using SuperVersion
Summary:
GetAndRefSuperVersion() should not be called again in the same thread before ReturnAndCleanupSuperVersion() is called.
If we have a compaction filter that is using DB::Get, This will happen
```
CompactFiles() {
GetAndRefSuperVersion() // -- first call
..
CompactionFilter() {
GetAndRefSuperVersion() // -- second call
ReturnAndCleanupSuperVersion()
}
..
ReturnAndCleanupSuperVersion()
}
```
We solve this issue in the same way Iterator is solving it, but using GetReferencedSuperVersion()
This was discovered in https://github.com/facebook/mysql-5.6/issues/427 by alxyang
Closes https://github.com/facebook/rocksdb/pull/1803
Differential Revision: D4460155
Pulled By: IslamAbdelRahman
fbshipit-source-id: 5e54322/Fix get approx size
Summary:
Fixing GetApproximateSize bug for the case of computing stats for mem tables only.
Closes https://github.com/facebook/rocksdb/pull/1795
Differential Revision: D4445507
Pulled By: IslamAbdelRahman
fbshipit-source-id: 3905846/Fix std::out_of_range when DBOptions::keep_log_file_num is zero
Summary:
We should validate this option, otherwise we may see
std::out_of_range thrown at: db/db_impl.cc:1124
1123     for (unsigned int i = 0; i <= end; i++) {
1124       std::string& to_delete = old_info_log_files.at(i);
1125       std::string full_path_to_delete =
1126           (immutable_db_options_.db_log_dir.empty()
Closes https://github.com/facebook/rocksdb/pull/1722
Differential Revision: D4379495
Pulled By: yiwu-arbug
fbshipit-source-id: e136552/Flush job should release reference current version if sync log failed
Summary:
Fix the bug when sync log fail, FlushJob::Run() will not be execute and
reference to cfd->current() will not be release.
Closes https://github.com/facebook/rocksdb/pull/1792
Differential Revision: D4441316
Pulled By: yiwu-arbug
fbshipit-source-id: 5523e28/Fix for 2PC causing WAL to grow too large
Summary:
Consider the following single column family scenario:
prepare in log A
commit in log B
*WAL is too large, flush all CFs to releast log A*
*CFA is on log B so we do not see CFA is depending on log A so no flush is requested*
To fix this we must also consider the log containing the prepare section when determining what log a CF is dependent on.
Closes https://github.com/facebook/rocksdb/pull/1768
Differential Revision: D4403265
Pulled By: reidHoruff
fbshipit-source-id: ce800ff/Abort compactions more reliably when closing DB
Summary:
DB shutdown aborts running compactions by setting an atomic shutting_down=true that CompactionJob periodically checks. Without this PR it checks it before processing every _output_ value. If compaction filter filters everything out, the compaction is uninterruptible. This PR adds checks for shutting_down on every _input_ value (in CompactionIterator and MergeHelper).
There's also some minor code cleanup along the way.
Closes https://github.com/facebook/rocksdb/pull/1639
Differential Revision: D4306571
Pulled By: yiwu-arbug
fbshipit-source-id: f050890/Fix bug of Checkpoint loses recent transactions with 2PC
Summary:
If 2PC is enabled, checkpoint may not copy previous log files that contain uncommitted prepare records. In this diff we keep those files.
Closes https://github.com/facebook/rocksdb/pull/1724
Differential Revision: D4368319
Pulled By: siying
fbshipit-source-id: cc2c746/direct io write support
Summary:
rocksdb direct io support
```
[gzh@dev11575.prn2 ~/rocksdb] ./db_bench -benchmarks=fillseq --num=1000000
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
RocksDB:    version 5.0
Date:       Wed Nov 23 13:17:43 2016
CPU:        40 * Intel(R) Xeon(R) CPU E5-2660 v2 @ 2.20GHz
CPUCache:   25600 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Compression: Snappy
Memtablerep: skip_list
Perf Level: 1
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
DB path: [/tmp/rocksdbtest-112628/dbbench]
fillseq      :       4.393 micros/op 227639 ops/sec;   25.2 MB/s
[gzh@dev11575.prn2 ~/roc
Closes https://github.com/facebook/rocksdb/pull/1564
Differential Revision: D4241093
Pulled By: lightmark
fbshipit-source-id: 98c29e3/Gcc 7 error expansion to defined
Summary:
sorry if these gcc-7/clang-4 cleanups are getting tedious.
Closes https://github.com/facebook/rocksdb/pull/1658
Differential Revision: D4318792
Pulled By: yiwu-arbug
fbshipit-source-id: 8e85891/break Flush wait for dropped CF
Summary:
In FlushJob we dont do the Flush if the CF is dropped
https://github.com/facebook/rocksdb/blob/master/db/flush_job.cc#L184-L188
but inside WaitForFlushMemTable we keep waiting forever even if the CF is dropped.
Closes https://github.com/facebook/rocksdb/pull/1664
Differential Revision: D4321032
Pulled By: IslamAbdelRahman
fbshipit-source-id: 6e2b25d/Disallow ingesting files into dropped CFs
Summary:
This PR update IngestExternalFile to return an error if we try to ingest a file into a dropped CF.
Right now if IngestExternalFile want to flush a memtable, and it's ingesting a file into a dropped CF, it will wait forever since flushing is not possible for the dropped CF
Closes https://github.com/facebook/rocksdb/pull/1657
Differential Revision: D4318657
Pulled By: IslamAbdelRahman
fbshipit-source-id: ed6ea2b/Add WriteOptions.no_slowdown
Summary:
If the WriteOptions.no_slowdown flag is set AND we need to wait or sleep for
the write request, then fail immediately with Status::Incomplete().
Closes https://github.com/facebook/rocksdb/pull/1527
Differential Revision: D4191405
Pulled By: maysamyabandeh
fbshipit-source-id: 7f3ce3f/Remove Arena in RangeDelAggregator
Summary:
The Arena construction/destruction introduced significant overhead to read-heavy workload just by creating empty vectors for its blocks, so avoid it in RangeDelAggregator.
Closes https://github.com/facebook/rocksdb/pull/1547
Differential Revision: D4207781
Pulled By: ajkr
fbshipit-source-id: 9d1c130/Remove Ticker::SEQUENCE_NUMBER
Summary:
Remove the ticker count because:
* Having to reset the ticker count in WriteImpl is ineffiecent;
* It doesn't make sense to have it as a ticker count if multiple db
instance share a statistics object.
Closes https://github.com/facebook/rocksdb/pull/1531
Differential Revision: D4194442
Pulled By: yiwu-arbug
fbshipit-source-id: e2110a9/Dynamic max_total_wal_size option
Summary: Closes https://github.com/facebook/rocksdb/pull/1509
Differential Revision: D4176426
Pulled By: yiwu-arbug
fbshipit-source-id: b57689d/"
rocksdb,"Fix wrong result in data race case related to Get()
Summary:
In theory, Get() can get a wrong result, if it races in a special with with flush. The bug can be reproduced in DBTest2.GetRaceFlush. Fix this bug by getting snapshot after referencing the super version.
Closes https://github.com/facebook/rocksdb/pull/1816
Differential Revision: D4475958
Pulled By: siying
fbshipit-source-id: bd9e67a/Add test DBTest2.GetRaceFlush which can expose a data race bug
Summary:
A current data race issue in Get() and Flush() can cause a Get() to return wrong results when a flush happened in the middle. Disable the test for now.
Closes https://github.com/facebook/rocksdb/pull/1813
Differential Revision: D4472310
Pulled By: siying
fbshipit-source-id: 5755ebd/Fix OptimizeForPointLookup()
Summary:
If users directly call OptimizeForPointLookup(), it is broken as the option isn't compatible with parallel memtable insert. Fix it by using memtable bloomo filter instead.
Closes https://github.com/facebook/rocksdb/pull/1791
Differential Revision: D4442836
Pulled By: siying
fbshipit-source-id: bf6c9cd/Dump persistent cache options
Summary:
Dump persistent cache options
Closes https://github.com/facebook/rocksdb/pull/1679
Differential Revision: D4337019
Pulled By: yiwu-arbug
fbshipit-source-id: 3812f8a/"
rocksdb,"fixed typo
Summary:
I fixed exisit -> exist
Closes https://github.com/facebook/rocksdb/pull/1799
Differential Revision: D4451466
Pulled By: yiwu-arbug
fbshipit-source-id: b447c3a/gcc-7 requires include <functional> for std::function
Summary:
Fixes compile error:
In file included from ./util/statistics.h:17:0,
from ./util/stop_watch.h:8,
from ./util/perf_step_timer.h:9,
from ./util/iostats_context_imp.h:8,
from ./util/posix_logger.h:27,
from ./port/util_logger.h:18,
from ./db/auto_roll_logger.h:15,
from db/auto_roll_logger.cc:6:
./util/thread_local.h:65:16: error: 'function' in namespace 'std' does not name a template type
typedef std::function<void(void*, void*)> FoldFunc;
Closes https://github.com/facebook/rocksdb/pull/1656
Differential Revision: D4318702
Pulled By: yiwu-arbug
fbshipit-source-id: 8c5d17a/Disallow ingesting files into dropped CFs
Summary:
This PR update IngestExternalFile to return an error if we try to ingest a file into a dropped CF.
Right now if IngestExternalFile want to flush a memtable, and it's ingesting a file into a dropped CF, it will wait forever since flushing is not possible for the dropped CF
Closes https://github.com/facebook/rocksdb/pull/1657
Differential Revision: D4318657
Pulled By: IslamAbdelRahman
fbshipit-source-id: ed6ea2b/Fix issue where IngestExternalFile insert blocks in block cache with g_seqno=0
Summary:
When we Ingest an external file we open it to read some metadata and first/last key
during doing that we insert blocks into the block cache with global_seqno = 0
If we move the file (did not copy it) into the DB, we will use these blocks with the wrong seqno in the read path
Closes https://github.com/facebook/rocksdb/pull/1627
Differential Revision: D4293332
Pulled By: yiwu-arbug
fbshipit-source-id: 3ce5523/"
rocksdb,"Add KEEP_DB env var option
Summary:
When debugging tests, it's useful to preserve the DB to investigate it and check the logs
This will allow us to set KEEP_DB=1 to preserve the DB
Closes https://github.com/facebook/rocksdb/pull/1759
Differential Revision: D4393826
Pulled By: IslamAbdelRahman
fbshipit-source-id: 1bff689/direct io write support
Summary:
rocksdb direct io support
```
[gzh@dev11575.prn2 ~/rocksdb] ./db_bench -benchmarks=fillseq --num=1000000
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
RocksDB:    version 5.0
Date:       Wed Nov 23 13:17:43 2016
CPU:        40 * Intel(R) Xeon(R) CPU E5-2660 v2 @ 2.20GHz
CPUCache:   25600 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Compression: Snappy
Memtablerep: skip_list
Perf Level: 1
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
DB path: [/tmp/rocksdbtest-112628/dbbench]
fillseq      :       4.393 micros/op 227639 ops/sec;   25.2 MB/s
[gzh@dev11575.prn2 ~/roc
Closes https://github.com/facebook/rocksdb/pull/1564
Differential Revision: D4241093
Pulled By: lightmark
fbshipit-source-id: 98c29e3/Iterator should be in corrupted status if merge operator return false
Summary:
Iterator should be in corrupted status if merge operator return false.
Also add test to make sure if max_successive_merges is hit during write,
data will not be lost.
Closes https://github.com/facebook/rocksdb/pull/1665
Differential Revision: D4322695
Pulled By: yiwu-arbug
fbshipit-source-id: b327b05/Missing break in case in DBTestBase::CurrentOptions
Summary:
Found by gcc-7 compile error.
This appeared to be a fault as these options seems too different.
Closes https://github.com/facebook/rocksdb/pull/1667
Differential Revision: D4324174
Pulled By: yiwu-arbug
fbshipit-source-id: 0f65383/Add WriteOptions.no_slowdown
Summary:
If the WriteOptions.no_slowdown flag is set AND we need to wait or sleep for
the write request, then fail immediately with Status::Incomplete().
Closes https://github.com/facebook/rocksdb/pull/1527
Differential Revision: D4191405
Pulled By: maysamyabandeh
fbshipit-source-id: 7f3ce3f/Range deletion microoptimizations
Summary:
- Made RangeDelAggregator's InternalKeyComparator member a reference-to-const so we don't need to copy-construct it. Also added InternalKeyComparator to ImmutableCFOptions so we don't need to construct one for each DBIter.
- Made MemTable::NewRangeTombstoneIterator and the table readers' NewRangeTombstoneIterator() functions return nullptr instead of NewEmptyInternalIterator to avoid the allocation. Updated callers accordingly.
Closes https://github.com/facebook/rocksdb/pull/1548
Differential Revision: D4208169
Pulled By: ajkr
fbshipit-source-id: 2fd65cf/"
rocksdb,"improving the C wrapper
Summary:
- rocksdb_property_int (so that we don't have to parse strings)
- and rocksdb_set_options (to allow controlling options via strings)
- a few other missing options exposed
- a documentation comment fix
Closes https://github.com/facebook/rocksdb/pull/1793
Differential Revision: D4456569
Pulled By: yiwu-arbug
fbshipit-source-id: 9f1fac1/c: allow set savepoint to writebatch
Summary:
Allow set SavePoint to WriteBatch in C ABI.
Closes https://github.com/facebook/rocksdb/pull/1698
Differential Revision: D4378556
Pulled By: yiwu-arbug
fbshipit-source-id: afca746/direct io write support
Summary:
rocksdb direct io support
```
[gzh@dev11575.prn2 ~/rocksdb] ./db_bench -benchmarks=fillseq --num=1000000
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
RocksDB:    version 5.0
Date:       Wed Nov 23 13:17:43 2016
CPU:        40 * Intel(R) Xeon(R) CPU E5-2660 v2 @ 2.20GHz
CPUCache:   25600 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Compression: Snappy
Memtablerep: skip_list
Perf Level: 1
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
DB path: [/tmp/rocksdbtest-112628/dbbench]
fillseq      :       4.393 micros/op 227639 ops/sec;   25.2 MB/s
[gzh@dev11575.prn2 ~/roc
Closes https://github.com/facebook/rocksdb/pull/1564
Differential Revision: D4241093
Pulled By: lightmark
fbshipit-source-id: 98c29e3/C API: support get usage and pinned_usage for cache
Summary: Closes https://github.com/facebook/rocksdb/pull/1671
Differential Revision: D4327453
Pulled By: yiwu-arbug
fbshipit-source-id: bcdbc65/CompactRangeOptions C API
Summary:
Add C API for CompactRangeOptions.
Closes https://github.com/facebook/rocksdb/pull/1596
Differential Revision: D4252339
Pulled By: yiwu-arbug
fbshipit-source-id: f768f93/c api: expose option for dynamic level size target
Summary: Closes https://github.com/facebook/rocksdb/pull/1587
Differential Revision: D4245923
Pulled By: yiwu-arbug
fbshipit-source-id: 6ee7291/Add C API to set base_backgroud_compactions
Summary:
Add C API to set base_backgroud_compactions
Closes https://github.com/facebook/rocksdb/pull/1571
Differential Revision: D4245709
Pulled By: yiwu-arbug
fbshipit-source-id: 792c6b8/"
rocksdb,"Fix bug of Checkpoint loses recent transactions with 2PC
Summary:
If 2PC is enabled, checkpoint may not copy previous log files that contain uncommitted prepare records. In this diff we keep those files.
Closes https://github.com/facebook/rocksdb/pull/1724
Differential Revision: D4368319
Pulled By: siying
fbshipit-source-id: cc2c746/Increase buffer size
Summary:
When compiling with GCC>=7.0.0, ""db/internal_stats.cc"" fails to compile as the data being written to the buffer potentially exceeds its size.
This fix simply doubles the size of the buffer, thus accommodating the max possible data size.
Closes https://github.com/facebook/rocksdb/pull/1635
Differential Revision: D4302162
Pulled By: yiwu-arbug
fbshipit-source-id: c76ad59/"
rocksdb,"Range deletion microoptimizations
Summary:
- Made RangeDelAggregator's InternalKeyComparator member a reference-to-const so we don't need to copy-construct it. Also added InternalKeyComparator to ImmutableCFOptions so we don't need to construct one for each DBIter.
- Made MemTable::NewRangeTombstoneIterator and the table readers' NewRangeTombstoneIterator() functions return nullptr instead of NewEmptyInternalIterator to avoid the allocation. Updated callers accordingly.
Closes https://github.com/facebook/rocksdb/pull/1548
Differential Revision: D4208169
Pulled By: ajkr
fbshipit-source-id: 2fd65cf/"
rocksdb,"Unified InlineSkipList::Insert algorithm with hinting
Summary:
This PR is based on nbronson's diff with small
modifications to wire it up with existing interface. Comparing to
previous version, this approach works better for inserting keys in
decreasing order or updating the same key, and impose less restriction
to the prefix extractor.
---- Summary from original diff ----
This diff introduces a single InlineSkipList::Insert that unifies
the existing sequential insert optimization (prev_), concurrent insertion,
and insertion using externally-managed insertion point hints.
There's a deep symmetry between insertion hints (cursors) and the
concurrent algorithm.  In both cases we have partial information from
the recent past that is likely but not certain to be accurate.  This diff
introduces the struct InlineSkipList::Splice, which encodes predecessor
and successor information in the same form that was previously only used
within a single call to InsertConcurrently.  Splice holds information
about an insertion point that can be used to levera
Closes https://github.com/facebook/rocksdb/pull/1561
Differential Revision: D4217283
Pulled By: yiwu-arbug
fbshipit-source-id: 33ee437/Report memory usage by memtable insert hints map.
Summary:
It is hard to measure acutal memory usage by std containers. Even
providing a custom allocator will miss count some of the usage. Here we
only do a wild guess on its memory usage.
Closes https://github.com/facebook/rocksdb/pull/1511
Differential Revision: D4179945
Pulled By: yiwu-arbug
fbshipit-source-id: 32ab929/"
rocksdb,"Fix Windows environment issues
Summary:
Enable directIO on WritableFileImpl::Append
with offset being current length of the file.
Enable UniqueID tests on Windows, disable others but
leeting them to compile. Unique tests are valuable to
detect failures on different filesystems and upcoming
ReFS.
Clear output in WinEnv Getchildren.This is different from
previous strategy, do not touch output on failure.
Make sure DBTest.OpenWhenOpen works with windows error message
Closes https://github.com/facebook/rocksdb/pull/1746
Differential Revision: D4385681
Pulled By: IslamAbdelRahman
fbshipit-source-id: c07b702/Fix rocksdb::Status::getState
Summary:
This fixes the Java API for Status#getState use in Native code and also simplifies the implementation of rocksdb::Status::getState.
Closes https://github.com/facebook/rocksdb/issues/1688
Closes https://github.com/facebook/rocksdb/pull/1714
Differential Revision: D4364181
Pulled By: yiwu-arbug
fbshipit-source-id: 8e073b4/direct io write support
Summary:
rocksdb direct io support
```
[gzh@dev11575.prn2 ~/rocksdb] ./db_bench -benchmarks=fillseq --num=1000000
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
RocksDB:    version 5.0
Date:       Wed Nov 23 13:17:43 2016
CPU:        40 * Intel(R) Xeon(R) CPU E5-2660 v2 @ 2.20GHz
CPUCache:   25600 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Compression: Snappy
Memtablerep: skip_list
Perf Level: 1
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
DB path: [/tmp/rocksdbtest-112628/dbbench]
fillseq      :       4.393 micros/op 227639 ops/sec;   25.2 MB/s
[gzh@dev11575.prn2 ~/roc
Closes https://github.com/facebook/rocksdb/pull/1564
Differential Revision: D4241093
Pulled By: lightmark
fbshipit-source-id: 98c29e3/Gcc 7 error expansion to defined
Summary:
sorry if these gcc-7/clang-4 cleanups are getting tedious.
Closes https://github.com/facebook/rocksdb/pull/1658
Differential Revision: D4318792
Pulled By: yiwu-arbug
fbshipit-source-id: 8e85891/Improve Write Stalling System
Summary:
Current write stalling system has the problem of lacking of positive feedback if the restricted rate is already too low. Users sometimes stack in very low slowdown value. With the diff, we add a positive feedback (increasing the slowdown value) if we recover from slowdown state back to normal. To avoid the positive feedback to keep the slowdown value to be to high, we add issue a negative feedback every time we are close to the stop condition. Experiments show it is easier to reach a relative balance than before.
Also increase level0_stop_writes_trigger default from 24 to 32. Since level0_slowdown_writes_trigger default is 20, stop trigger 24 only gives four files as the buffer time to slowdown writes. In order to avoid stop in four files while 20 files have been accumulated, the slowdown value must be very low, which is amost the same as stop. It also doesn't give enough time for the slowdown value to converge. Increase it to 32 will smooth out the system.
Closes https://github.com/facebook/rocksdb/pull/1562
Differential Revision: D4218519
Pulled By: siying
fbshipit-source-id: 95e4088/Add WriteOptions.no_slowdown
Summary:
If the WriteOptions.no_slowdown flag is set AND we need to wait or sleep for
the write request, then fail immediately with Status::Incomplete().
Closes https://github.com/facebook/rocksdb/pull/1527
Differential Revision: D4191405
Pulled By: maysamyabandeh
fbshipit-source-id: 7f3ce3f/"
rocksdb,"Gcc 7 error expansion to defined
Summary:
sorry if these gcc-7/clang-4 cleanups are getting tedious.
Closes https://github.com/facebook/rocksdb/pull/1658
Differential Revision: D4318792
Pulled By: yiwu-arbug
fbshipit-source-id: 8e85891/"
rocksdb,"Decouple data iterator and range deletion iterator in TableCache
Summary:
Previously we used TableCache::NewIterator() for multiple purposes (data
block iterator and range deletion iterator), and returned non-ok status in
the data block iterator. In one case where the caller only used the range
deletion block iterator (https://github.com/facebook/rocksdb/blob/9e7cf3469bc626b092ec48366d12873ecab22b4e/db/version_set.cc#L965-L973),
we didn't check/free the data block iterator containing non-ok status, which
caused a valgrind error.
So, this diff decouples creation of data block and range deletion block iterators,
and updates the callers accordingly. Both functions can return non-ok status
in an InternalIterator. Since the non-ok status is returned in an iterator that the
callers will definitely use, it should be more usable/less error-prone.
Closes https://github.com/facebook/rocksdb/pull/1513
Differential Revision: D4181423
Pulled By: ajkr
fbshipit-source-id: 835b8f5/"
rocksdb,"Range deletion microoptimizations
Summary:
- Made RangeDelAggregator's InternalKeyComparator member a reference-to-const so we don't need to copy-construct it. Also added InternalKeyComparator to ImmutableCFOptions so we don't need to construct one for each DBIter.
- Made MemTable::NewRangeTombstoneIterator and the table readers' NewRangeTombstoneIterator() functions return nullptr instead of NewEmptyInternalIterator to avoid the allocation. Updated callers accordingly.
Closes https://github.com/facebook/rocksdb/pull/1548
Differential Revision: D4208169
Pulled By: ajkr
fbshipit-source-id: 2fd65cf/Remove Arena in RangeDelAggregator
Summary:
The Arena construction/destruction introduced significant overhead to read-heavy workload just by creating empty vectors for its blocks, so avoid it in RangeDelAggregator.
Closes https://github.com/facebook/rocksdb/pull/1547
Differential Revision: D4207781
Pulled By: ajkr
fbshipit-source-id: 9d1c130/"
rocksdb,"c: allow set savepoint to writebatch
Summary:
Allow set SavePoint to WriteBatch in C ABI.
Closes https://github.com/facebook/rocksdb/pull/1698
Differential Revision: D4378556
Pulled By: yiwu-arbug
fbshipit-source-id: afca746/Fix c_test
Summary:
addfile phase in c_test could fail because in previous steps we did a DeleteRange.
Fix the test by simply moving the addfile phase before DeleteRange
Closes https://github.com/facebook/rocksdb/pull/1672
Differential Revision: D4328896
Pulled By: IslamAbdelRahman
fbshipit-source-id: 1d946df/C API: support get usage and pinned_usage for cache
Summary: Closes https://github.com/facebook/rocksdb/pull/1671
Differential Revision: D4327453
Pulled By: yiwu-arbug
fbshipit-source-id: bcdbc65/CompactRangeOptions C API
Summary:
Add C API for CompactRangeOptions.
Closes https://github.com/facebook/rocksdb/pull/1596
Differential Revision: D4252339
Pulled By: yiwu-arbug
fbshipit-source-id: f768f93/Add C API to set base_backgroud_compactions
Summary:
Add C API to set base_backgroud_compactions
Closes https://github.com/facebook/rocksdb/pull/1571
Differential Revision: D4245709
Pulled By: yiwu-arbug
fbshipit-source-id: 792c6b8/"
rocksdb,"Fix Windows environment issues
Summary:
Enable directIO on WritableFileImpl::Append
with offset being current length of the file.
Enable UniqueID tests on Windows, disable others but
leeting them to compile. Unique tests are valuable to
detect failures on different filesystems and upcoming
ReFS.
Clear output in WinEnv Getchildren.This is different from
previous strategy, do not touch output on failure.
Make sure DBTest.OpenWhenOpen works with windows error message
Closes https://github.com/facebook/rocksdb/pull/1746
Differential Revision: D4385681
Pulled By: IslamAbdelRahman
fbshipit-source-id: c07b702/direct io write support
Summary:
rocksdb direct io support
```
[gzh@dev11575.prn2 ~/rocksdb] ./db_bench -benchmarks=fillseq --num=1000000
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
RocksDB:    version 5.0
Date:       Wed Nov 23 13:17:43 2016
CPU:        40 * Intel(R) Xeon(R) CPU E5-2660 v2 @ 2.20GHz
CPUCache:   25600 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Compression: Snappy
Memtablerep: skip_list
Perf Level: 1
WARNING: Assertions are enabled; benchmarks unnecessarily slow
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
DB path: [/tmp/rocksdbtest-112628/dbbench]
fillseq      :       4.393 micros/op 227639 ops/sec;   25.2 MB/s
[gzh@dev11575.prn2 ~/roc
Closes https://github.com/facebook/rocksdb/pull/1564
Differential Revision: D4241093
Pulled By: lightmark
fbshipit-source-id: 98c29e3/"
rocksdb,"Blob storage pr
Summary:
The final pull request for Blob Storage.
Closes https://github.com/facebook/rocksdb/pull/2269
Differential Revision: D5033189
Pulled By: yiwu-arbug
fbshipit-source-id: 6356b683ccd58cbf38a1dc55e2ea400feecd5d06/Add a verify phase to benchmarks
Summary:
Check the result of the benchmark againt a specified truth_db, which is
expected to be produced using the same benchmark but perhaps on a
different commit or with different configs.
The verification is simple and assumes that key/values are generated
deterministically. This assumption would break if db_bench using rand
variable differently from the benchmark that produced truth_db.
Currently it is checked to work on fillrandom and readwhilewriting.
A param finish_after_writes is added to ensure that the background
writing thread will write the same number of entries between two
benchmarks.
Example:
$ TEST_TMPDIR=/dev/shm/truth_db ./db_bench
--benchmarks=""fillrandom,readwhilewriting"" --num=200000
--finish_after_writes=true
$ TEST_TMPDIR=/dev/shm/tmpdb ./db_bench
--benchmarks=""fillrandom,readwhilewriting,verify"" --truth_db
/dev/shm/truth_db/dbbench --num=200000 --finish_after_writes=true
Verifying db <= truth_db...
Verifying db >= truth_db...
...Verified
Closes https://github.com/facebook/rocksdb/pull/2098
Differential Revision: D4839233
Pulled By: maysamyabandeh
fbshipit-source-id: 2f4ed31/Hide usage of compaction_options_fifo from lite build
Summary:
...to fix lite build error.
Closes https://github.com/facebook/rocksdb/pull/2046
Differential Revision: D4785910
Pulled By: yiwu-arbug
fbshipit-source-id: b591f27/fix db_bench rate limiter callsites
Summary:
pass nullptr as stats object for db_bench-specific rate limiters since its stats are intended to capture background write activity only.
Closes https://github.com/facebook/rocksdb/pull/1997
Differential Revision: D4726806
Pulled By: ajkr
fbshipit-source-id: 8e4b225/Fix unaligned reads in read cache
Summary:
- Fix unaligned reads in read cache by using RandomAccessFileReader
- Allow read cache flags in db_bench
Closes https://github.com/facebook/rocksdb/pull/1916
Differential Revision: D4610885
Pulled By: IslamAbdelRahman
fbshipit-source-id: 2aa1dc8/"
rocksdb,"Add GetAllKeyVersions API
Summary:
- Introduced an include/ file dedicated to db-related debug functions to avoid making db.h more complex
- Added debugging function, `GetAllKeyVersions()`, to return a listing of internal data for a range of user keys. The new `struct KeyVersion` exposes data similar to internal key without exposing any internal type.
- Migrated the ""ldb idump"" subcommand to use this function
- The API takes an inclusive-exclusive range to match behavior of ""ldb idump"". This will be quite annoying for users who want to query a single user key's versions :(.
Closes https://github.com/facebook/rocksdb/pull/2232
Differential Revision: D4976007
Pulled By: ajkr
fbshipit-source-id: cab375da53a7595d6575af2b7e3b776aa3ad793e/"
rocksdb,"add direct_io and compaction_readahead_size in db_stress
Summary:
add direct_io and compaction_readahead_size in db_stress
test direct_io under db_stress with compaction_readahead_size enabled to capture bugs found in production.
`./db_stress --allow_concurrent_memtable_write=0 --use_direct_reads --use_direct_writes --compaction_readahead_size=4096`
Closes https://github.com/facebook/rocksdb/pull/1906
Differential Revision: D4604514
Pulled By: IslamAbdelRahman
fbshipit-source-id: ebbf0ee/"
rocksdb,"Add ability to search for key prefix in sst_dump tool
Summary:
Add the flag --prefix to the sst_dump tool
This flag is similar to, and exclusive from, the --from flag.
--prefix=0x00FF will return all rows prefixed with 0x00FF.
The --to flag may also be specified and will work as expected.
These changes were used to help in debugging the power cycle corruption issue and theses changes were tested by scanning through a udb.
Closes https://github.com/facebook/rocksdb/pull/1984
Differential Revision: D4691814
Pulled By: reidHoruff
fbshipit-source-id: 027f261/"
rocksdb,"Cleanup of ThreadStatusUtil structures should use the DB's reference
Summary:
instead of thread_local
The cleanup path for the rocksdb database might not have the
thread_updater_local_cache_ pointer initialized because the thread
executing the cleanup is likely not a rocksdb thread. This results in a
memory leak detected by Valgrind. The cleanup code path should use the
thread_status_updater pointer obtained from the DB object instead of a
thread local one.
Closes https://github.com/facebook/rocksdb/pull/2059
Differential Revision: D4801611
Pulled By: hermanlee
fbshipit-source-id: 407d7de/"
rocksdb,"Revert ""delete fallocate with punch_hole""
Summary:
This reverts commit 0fd574926cc9be7309c2247092d6b337fb022a5d.
It breaks tmpfs on kernel 4.0 or earlier. We will wait for the fix before remove this part
Closes https://github.com/facebook/rocksdb/pull/2096
Differential Revision: D4839661
Pulled By: lightmark
fbshipit-source-id: 574a51f/delete fallocate with punch_hole
Summary:
As discuss in this thread:
https://www.facebook.com/groups/rocksdb.dev/permalink/1218043868294125/
We remove fallocate with FALLOC_FL_PUNCH_HOLE because the recent bug on xfs in kernel 4.x+ that align file size to page size even with FALLOC_FL_KEEP_SIZE | FALLOC_FL_PUNCH_HOLE.
Closes https://github.com/facebook/rocksdb/pull/2038
Differential Revision: D4779974
Pulled By: siying
fbshipit-source-id: 5f54625/"
rocksdb,"Add macros to include file name and line number during Logging
Summary:
current logging
```
2017/03/14-14:20:30.393432 7fedde9f5700 (Original Log Time 2017/03/14-14:20:30.393414) [default] Level summary: base level 1 max bytes base 268435456 files[1 0 0 0 0 0 0] max score 0.25
2017/03/14-14:20:30.393438 7fedde9f5700 [JOB 2] Try to delete WAL files size 61417909, prev total WAL file size 73820858, number of live WAL files 2.
2017/03/14-14:20:30.393464 7fedde9f5700 [DEBUG] [JOB 2] Delete /dev/shm/old_logging//MANIFEST-000001 type=3 #1 -- OK
2017/03/14-14:20:30.393472 7fedde9f5700 [DEBUG] [JOB 2] Delete /dev/shm/old_logging//000003.log type=0 #3 -- OK
2017/03/14-14:20:31.427103 7fedd49f1700 [default] New memtable created with log file: #9. Immutable memtables: 0.
2017/03/14-14:20:31.427179 7fedde9f5700 [JOB 3] Syncing log #6
2017/03/14-14:20:31.427190 7fedde9f5700 (Original Log Time 2017/03/14-14:20:31.427170) Calling FlushMemTableToOutputFile with column family [default], flush slots available 1, compaction slots allowed 1, compaction slots scheduled 1
2017/03/14-14:20:31.
Closes https://github.com/facebook/rocksdb/pull/1990
Differential Revision: D4708695
Pulled By: IslamAbdelRahman
fbshipit-source-id: cb8968f/"
rocksdb,"Fix some bugs in MockEnv
Summary:
Fixing some bugs in MockEnv so it be actually used.
Closes https://github.com/facebook/rocksdb/pull/1914
Differential Revision: D4609923
Pulled By: maysamyabandeh
fbshipit-source-id: ca25735/"
rocksdb,"Fix build with MinGW
Summary:
There still are many warnings (most of them about invalid printf format
for long long), but it builds if FAIL_ON_WARNINGS is disabled.
Closes https://github.com/facebook/rocksdb/pull/2052
Differential Revision: D4807355
Pulled By: siying
fbshipit-source-id: ef03786/"
rocksdb,"Move memtable related files into memtable directory
Summary:
Move memtable related files into memtable directory.
Closes https://github.com/facebook/rocksdb/pull/2087
Differential Revision: D4829242
Pulled By: yiwu-arbug
fbshipit-source-id: ca70ab6/"
rocksdb,"Move memtable related files into memtable directory
Summary:
Move memtable related files into memtable directory.
Closes https://github.com/facebook/rocksdb/pull/2087
Differential Revision: D4829242
Pulled By: yiwu-arbug
fbshipit-source-id: ca70ab6/"
rocksdb,"Move memtable related files into memtable directory
Summary:
Move memtable related files into memtable directory.
Closes https://github.com/facebook/rocksdb/pull/2087
Differential Revision: D4829242
Pulled By: yiwu-arbug
fbshipit-source-id: ca70ab6/"
rocksdb,"Blob storage pr
Summary:
The final pull request for Blob Storage.
Closes https://github.com/facebook/rocksdb/pull/2269
Differential Revision: D5033189
Pulled By: yiwu-arbug
fbshipit-source-id: 6356b683ccd58cbf38a1dc55e2ea400feecd5d06/Avoid calling fallocate with UINT64_MAX
Summary:
When user doesn't set a limit on compaction output file size, let's use the sum of the input files' sizes. This will avoid passing UINT64_MAX as fallocate()'s length. Reported in #2249.
Test setup:
- command: `TEST_TMPDIR=/data/rocksdb-test/ strace -e fallocate ./db_compaction_test --gtest_filter=DBCompactionTest.ManualCompactionUnknownOutputSize`
- filesystem: xfs
before this diff:
`fallocate(10, 01, 0, 1844674407370955160) = -1 ENOSPC (No space left on device)`
after this diff:
`fallocate(10, 01, 0, 1977)              = 0`
Closes https://github.com/facebook/rocksdb/pull/2252
Differential Revision: D5007275
Pulled By: ajkr
fbshipit-source-id: 4491404a6ae8a41328aede2e2d6f4d9ac3e38880/Blob storage helper methods
Summary:
Split out interfaces needed for blob storage from #1560, including
* CompactionEventListener and OnFlushBegin listener interfaces.
* Blob filename support.
Closes https://github.com/facebook/rocksdb/pull/2169
Differential Revision: D4905463
Pulled By: yiwu-arbug
fbshipit-source-id: 564e73448f1b7a367e5e46216a521e57ea9011b5/"
rocksdb,"Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Fix Compilation errors when using IBM Java
Summary:
PR to fix this issue -> https://github.com/facebook/rocksdb/issues/1926
Closes https://github.com/facebook/rocksdb/pull/1965
Differential Revision: D4682411
Pulled By: siying
fbshipit-source-id: a519be1/Expose DB::DeleteRange and WriteBath::DeleteRange in Java
Summary:
Added JNI wrapper from `DeleteRange` methods
Closes https://github.com/facebook/rocksdb/pull/1951
Differential Revision: D4657746
Pulled By: yiwu-arbug
fbshipit-source-id: 3fc7ab8/Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Flink state
Summary:
This is to address the issue reported in
https://github.com/facebook/rocksdb/issues/1988
The fix is simple. A typo.
Closes https://github.com/facebook/rocksdb/pull/2267
Differential Revision: D5037149
Pulled By: siying
fbshipit-source-id: 1bb585c7a753ef77c81c4b92deafbed8e21fe8ff/Fix CompactRange incorrect buffer release
Summary:
While running `make jtest` using IBM Java, it fails at compactRangeToLevel with the below error.
```
Run: org.rocksdb.RocksDBTest testing now -> compactRangeToLevel
JVMJNCK056E JNI error in ReleaseByteArrayElements: Got memory 0x00003FFF94AA8908 from object 0x00000000000C7F78, releasing from 0x00000000000C7F68
JVMJNCK077E Error detected in org/rocksdb/RocksDB.compactRange0(J[BI[BIZII)V
JVMJNCK024E JNI error detected. Aborting.
JVMJNCK025I Use -Xcheck:jni:nonfatal to continue running when errors are detected.
Fatal error: JNI error
Makefile:205: recipe for target 'run_test' failed
make[1]: *** [run_test] Error 87
make[1]: Leaving directory '/home/ubuntu/rocksdb/java'
Makefile:1542: recipe for target 'jtest' failed
make: *** [jtest] Error 2
```
After checking the code, it is vivid that we are messing up the `ReleaseByteArrayElements` args in `rocksdb_compactrange_helper`.
```
.................
1959     s = db->CompactRange(compact_options, &begin_slice, &end_slice);
1960   }
Closes https://github.com/facebook/rocksdb/pull/2060
Differential Revision: D4831427
Pulled By: yiwu-arbug
fbshipit-source-id: dd02037/Fix Compilation errors when using IBM Java
Summary:
PR to fix this issue -> https://github.com/facebook/rocksdb/issues/1926
Closes https://github.com/facebook/rocksdb/pull/1965
Differential Revision: D4682411
Pulled By: siying
fbshipit-source-id: a519be1/Expose DB::DeleteRange and WriteBath::DeleteRange in Java
Summary:
Added JNI wrapper from `DeleteRange` methods
Closes https://github.com/facebook/rocksdb/pull/1951
Differential Revision: D4657746
Pulled By: yiwu-arbug
fbshipit-source-id: 3fc7ab8/Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Expose DB::DeleteRange and WriteBath::DeleteRange in Java
Summary:
Added JNI wrapper from `DeleteRange` methods
Closes https://github.com/facebook/rocksdb/pull/1951
Differential Revision: D4657746
Pulled By: yiwu-arbug
fbshipit-source-id: 3fc7ab8/"
rocksdb,"Expose DB::DeleteRange and WriteBath::DeleteRange in Java
Summary:
Added JNI wrapper from `DeleteRange` methods
Closes https://github.com/facebook/rocksdb/pull/1951
Differential Revision: D4657746
Pulled By: yiwu-arbug
fbshipit-source-id: 3fc7ab8/Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Expose DB::DeleteRange and WriteBath::DeleteRange in Java
Summary:
Added JNI wrapper from `DeleteRange` methods
Closes https://github.com/facebook/rocksdb/pull/1951
Differential Revision: D4657746
Pulled By: yiwu-arbug
fbshipit-source-id: 3fc7ab8/Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Expose DB::DeleteRange and WriteBath::DeleteRange in Java
Summary:
Added JNI wrapper from `DeleteRange` methods
Closes https://github.com/facebook/rocksdb/pull/1951
Differential Revision: D4657746
Pulled By: yiwu-arbug
fbshipit-source-id: 3fc7ab8/"
rocksdb,"Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Fixed various memory leaks and Java 8 JNI Compatibility
Summary:
I have manually audited the entire RocksJava code base.
Sorry for the large pull-request, I have broken it down into many small atomic commits though.
My initial intention was to fix the warnings that appear when running RocksJava on Java 8 with `-Xcheck:jni`, for example when running `make jtest` you would see many errors similar to:
```
WARNING in native method: JNI call made without checking exceptions when required to from CallObjectMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallVoidMethod
WARNING in native method: JNI call made without checking exceptions when required to from CallStaticVoidMethod
...
```
A few of those warnings still remain, however they seem to come directly from the JVM and are not directly related to RocksJava; I am in contact with the OpenJDK hostpot-dev mailing list about these - http://mail.openjdk.java.net/pipermail/hotspot-dev/2017-February/025981.html.
As a result of fixing these, I realised we were not r
Closes https://github.com/facebook/rocksdb/pull/1890
Differential Revision: D4591758
Pulled By: siying
fbshipit-source-id: 7f7fdf4/"
rocksdb,"Reunite checkpoint and backup core logic
Summary:
These code paths forked when checkpoint was introduced by copy/pasting the core backup logic. Over time they diverged and bug fixes were sometimes applied to one but not the other (like fix to include all relevant WALs for 2PC), or it required extra effort to fix both (like fix to forge CURRENT file). This diff reunites the code paths by extracting the core logic into a function, CreateCustomCheckpoint(), that is customizable via callbacks to implement both checkpoint and backup.
Related changes:
- flush_before_backup is now forcibly enabled when 2PC is enabled
- Extracted CheckpointImpl class definition into a header file. This is so the function, CreateCustomCheckpoint(), can be called by internal rocksdb code but not exposed to users.
- Implemented more functions in DummyDB/DummyLogFile (in backupable_db_test.cc) that are used by CreateCustomCheckpoint().
Closes https://github.com/facebook/rocksdb/pull/1932
Differential Revision: D4622986
Pulled By: ajkr
fbshipit-source-id: 157723884236ee3999a682673b64f7457a7a0d87/backup garbage collect shared_checksum tmp files
Summary:
previously we only cleaned up .tmp files under ""shared/"" and ""private/"" directories in case the previous backup failed. we need to do the same for ""shared_checksum/""; otherwise, the subsequent backup will fail if it tries to backup at least one of the same files.
Closes https://github.com/facebook/rocksdb/pull/2062
Differential Revision: D4805599
Pulled By: ajkr
fbshipit-source-id: eaa6088/"
rocksdb,"Fix shared lock upgrades
Summary:
Upgrading a shared lock was silently succeeding because the actual locking code was skipped. This is because if the keys are tracked, it is assumed that they are already locked and do not require locking. Fix this by recording in tracked keys whether the key was locked exclusively or not.
Note that lock downgrades are impossible, which is the behaviour we expect.
This fixes facebook/mysql-5.6#587.
Closes https://github.com/facebook/rocksdb/pull/2122
Differential Revision: D4861489
Pulled By: IslamAbdelRahman
fbshipit-source-id: 58c7ebe7af098bf01b9774b666d3e9867747d8fd/"
rocksdb,"Fix shared lock upgrades
Summary:
Upgrading a shared lock was silently succeeding because the actual locking code was skipped. This is because if the keys are tracked, it is assumed that they are already locked and do not require locking. Fix this by recording in tracked keys whether the key was locked exclusively or not.
Note that lock downgrades are impossible, which is the behaviour we expect.
This fixes facebook/mysql-5.6#587.
Closes https://github.com/facebook/rocksdb/pull/2122
Differential Revision: D4861489
Pulled By: IslamAbdelRahman
fbshipit-source-id: 58c7ebe7af098bf01b9774b666d3e9867747d8fd/"
rocksdb,"Blob storage pr
Summary:
The final pull request for Blob Storage.
Closes https://github.com/facebook/rocksdb/pull/2269
Differential Revision: D5033189
Pulled By: yiwu-arbug
fbshipit-source-id: 6356b683ccd58cbf38a1dc55e2ea400feecd5d06/"
rocksdb,"Add macros to include file name and line number during Logging
Summary:
current logging
```
2017/03/14-14:20:30.393432 7fedde9f5700 (Original Log Time 2017/03/14-14:20:30.393414) [default] Level summary: base level 1 max bytes base 268435456 files[1 0 0 0 0 0 0] max score 0.25
2017/03/14-14:20:30.393438 7fedde9f5700 [JOB 2] Try to delete WAL files size 61417909, prev total WAL file size 73820858, number of live WAL files 2.
2017/03/14-14:20:30.393464 7fedde9f5700 [DEBUG] [JOB 2] Delete /dev/shm/old_logging//MANIFEST-000001 type=3 #1 -- OK
2017/03/14-14:20:30.393472 7fedde9f5700 [DEBUG] [JOB 2] Delete /dev/shm/old_logging//000003.log type=0 #3 -- OK
2017/03/14-14:20:31.427103 7fedd49f1700 [default] New memtable created with log file: #9. Immutable memtables: 0.
2017/03/14-14:20:31.427179 7fedde9f5700 [JOB 3] Syncing log #6
2017/03/14-14:20:31.427190 7fedde9f5700 (Original Log Time 2017/03/14-14:20:31.427170) Calling FlushMemTableToOutputFile with column family [default], flush slots available 1, compaction slots allowed 1, compaction slots scheduled 1
2017/03/14-14:20:31.
Closes https://github.com/facebook/rocksdb/pull/1990
Differential Revision: D4708695
Pulled By: IslamAbdelRahman
fbshipit-source-id: cb8968f/"
rocksdb,"update IterKey that can get user key and internal key explicitly
Summary:
to void future bug that caused by the mix of userkey/internalkey
Closes https://github.com/facebook/rocksdb/pull/2084
Differential Revision: D4825889
Pulled By: lightmark
fbshipit-source-id: 28411db/"
rocksdb,"Object lifetime in cache
Summary:
Any non-raw-data dependent object must be destructed before the table
closes. There was a bug of not doing that for filter object. This patch
fixes the bug and adds a unit test to prevent such bugs in future.
Closes https://github.com/facebook/rocksdb/pull/2246
Differential Revision: D5001318
Pulled By: maysamyabandeh
fbshipit-source-id: 6d8772e58765485868094b92964da82ef9730b6d/Fix segmentation fault caused by #1961
Summary:
Fixes #1961 which causes a segfault when filter_policy is nullptr and both
pin_l0_filter_and_index_blocks_in_cache/cache_index_and_filter_blocks
are set.
Closes https://github.com/facebook/rocksdb/pull/2029
Differential Revision: D4764862
Pulled By: maysamyabandeh
fbshipit-source-id: 05bd695/Add macros to include file name and line number during Logging
Summary:
current logging
```
2017/03/14-14:20:30.393432 7fedde9f5700 (Original Log Time 2017/03/14-14:20:30.393414) [default] Level summary: base level 1 max bytes base 268435456 files[1 0 0 0 0 0 0] max score 0.25
2017/03/14-14:20:30.393438 7fedde9f5700 [JOB 2] Try to delete WAL files size 61417909, prev total WAL file size 73820858, number of live WAL files 2.
2017/03/14-14:20:30.393464 7fedde9f5700 [DEBUG] [JOB 2] Delete /dev/shm/old_logging//MANIFEST-000001 type=3 #1 -- OK
2017/03/14-14:20:30.393472 7fedde9f5700 [DEBUG] [JOB 2] Delete /dev/shm/old_logging//000003.log type=0 #3 -- OK
2017/03/14-14:20:31.427103 7fedd49f1700 [default] New memtable created with log file: #9. Immutable memtables: 0.
2017/03/14-14:20:31.427179 7fedde9f5700 [JOB 3] Syncing log #6
2017/03/14-14:20:31.427190 7fedde9f5700 (Original Log Time 2017/03/14-14:20:31.427170) Calling FlushMemTableToOutputFile with column family [default], flush slots available 1, compaction slots allowed 1, compaction slots scheduled 1
2017/03/14-14:20:31.
Closes https://github.com/facebook/rocksdb/pull/1990
Differential Revision: D4708695
Pulled By: IslamAbdelRahman
fbshipit-source-id: cb8968f/"
rocksdb,"update IterKey that can get user key and internal key explicitly
Summary:
to void future bug that caused by the mix of userkey/internalkey
Closes https://github.com/facebook/rocksdb/pull/2084
Differential Revision: D4825889
Pulled By: lightmark
fbshipit-source-id: 28411db/"
rocksdb,"update IterKey that can get user key and internal key explicitly
Summary:
to void future bug that caused by the mix of userkey/internalkey
Closes https://github.com/facebook/rocksdb/pull/2084
Differential Revision: D4825889
Pulled By: lightmark
fbshipit-source-id: 28411db/"
rocksdb,"unbiase readamp bitmap
Summary:
Consider BlockReadAmpBitmap with bytes_per_bit = 32. Suppose bytes [a, b) were used, while bytes [a-32, a)
and [b+1, b+33) weren't used; more formally, the union of ranges passed to BlockReadAmpBitmap::Mark() contains [a, b) and doesn't intersect with [a-32, a) and [b+1, b+33). Then bits [floor(a/32), ceil(b/32)] will be set, and so the number of useful bytes will be estimated as (ceil(b/32) - floor(a/32)) * 32, which is on average equal to b-a+31.
An extreme example: if we use 1 byte from each block, it'll be counted as 32 bytes from each block.
It's easy to remove this bias by slightly changing the semantics of the bitmap. Currently each bit represents a byte range [i*32, (i+1)*32).
This diff makes each bit represent a single byte: i*32 + X, where X is a random number in [0, 31] generated when bitmap is created. So, e.g., if you read a single byte at random, with probability 31/32 it won't be counted at all, and with probability 1/32 it will be counted as 32 bytes; so, on average it's counted as 1 byte.
*But there is one exception: the last bit will always set with the old way.*
(*) - assuming read_amp_bytes_per_bit = 32.
Closes https://github.com/facebook/rocksdb/pull/2259
Differential Revision: D5035652
Pulled By: lightmark
fbshipit-source-id: bd98b1b9b49fbe61f9e3781d07f624e3cbd92356/Move memtable related files into memtable directory
Summary:
Move memtable related files into memtable directory.
Closes https://github.com/facebook/rocksdb/pull/2087
Differential Revision: D4829242
Pulled By: yiwu-arbug
fbshipit-source-id: ca70ab6/"
rocksdb,"Object lifetime in cache
Summary:
Any non-raw-data dependent object must be destructed before the table
closes. There was a bug of not doing that for filter object. This patch
fixes the bug and adds a unit test to prevent such bugs in future.
Closes https://github.com/facebook/rocksdb/pull/2246
Differential Revision: D5001318
Pulled By: maysamyabandeh
fbshipit-source-id: 6d8772e58765485868094b92964da82ef9730b6d/avoid ASSERT_EQ(false, ...);
Summary:
lately it fails on travis due to a compiler bug (see https://github.com/google/googletest/issues/322#issuecomment-125645145). interestingly it seems to affect occurrences of `ASSERT_EQ(false, ...);` but not `ASSERT_EQ(true, ...);`.
Closes https://github.com/facebook/rocksdb/pull/1958
Differential Revision: D4680742
Pulled By: ajkr
fbshipit-source-id: 291fe41/"
rocksdb,"Blob storage helper methods
Summary:
Split out interfaces needed for blob storage from #1560, including
* CompactionEventListener and OnFlushBegin listener interfaces.
* Blob filename support.
Closes https://github.com/facebook/rocksdb/pull/2169
Differential Revision: D4905463
Pulled By: yiwu-arbug
fbshipit-source-id: 564e73448f1b7a367e5e46216a521e57ea9011b5/"
rocksdb,"Blob storage pr
Summary:
The final pull request for Blob Storage.
Closes https://github.com/facebook/rocksdb/pull/2269
Differential Revision: D5033189
Pulled By: yiwu-arbug
fbshipit-source-id: 6356b683ccd58cbf38a1dc55e2ea400feecd5d06/Add bulk create/drop column family API
Summary:
Adding DB::CreateColumnFamilie() and DB::DropColumnFamilies() to bulk create/drop column families. This is to address the problem creating/dropping 1k column families takes minutes. The bottleneck is we persist options files for every single column family create/drop, and it parses the persisted options file for verification, which take a lot CPU time.
The new APIs simply create/drop column families individually, and persist options file once at the end. This improves create 1k column families to within ~0.1s. Further improvement can be merge manifest write to one IO.
Closes https://github.com/facebook/rocksdb/pull/2248
Differential Revision: D5001578
Pulled By: yiwu-arbug
fbshipit-source-id: d4e00bda671451e0b314c13e12ad194b1704aa03/Max open files mutable
Summary:
Makes max_open_files db option dynamically set-able by SetDBOptions. During the call of SetDBOptions we call SetCapacity on the table cache, which is a LRUCache.
Closes https://github.com/facebook/rocksdb/pull/2185
Differential Revision: D4979189
Pulled By: yiwu-arbug
fbshipit-source-id: ca7e8dc5e3619c79434f579be4847c0f7e56afda/CMake: more MinGW fixes
Summary:
siying this is a resubmission of #2081 with the 4th commit fixed. From that commit message:
> Note that the previous use of quotes in PLATFORM_{CC,CXX}FLAGS was
incorrect and caused GCC to produce the incorrect define:
>
>  #define ROCKSDB_JEMALLOC -DJEMALLOC_NO_DEMANGLE 1
>
> This was the cause of the Linux build failure on the previous version
of this change.
I've tested this locally, and the Linux build succeeds now.
Closes https://github.com/facebook/rocksdb/pull/2097
Differential Revision: D4839964
Pulled By: siying
fbshipit-source-id: cc51322/Revert ""[rocksdb][PR] CMake: more MinGW fixes""
fbshipit-source-id: 43b4529/CMake: more MinGW fixes
Summary:
See individual commits.
yuslepukhin siying
Closes https://github.com/facebook/rocksdb/pull/2081
Differential Revision: D4824639
Pulled By: IslamAbdelRahman
fbshipit-source-id: 2fc2b00/Refactor WriteImpl (pipeline write part 1)
Summary:
Refactor WriteImpl() so when I plug-in the pipeline write code (which is
an alternative approach for WriteThread), some of the logic can be
reuse. I split out the following methods from WriteImpl():
* PreprocessWrite()
* HandleWALFull() (previous MaybeFlushColumnFamilies())
* HandleWriteBufferFull()
* WriteToWAL()
Also adding a constructor to WriteThread::Writer, and move WriteContext into db_impl.h.
No real logic change in this patch.
Closes https://github.com/facebook/rocksdb/pull/2042
Differential Revision: D4781014
Pulled By: yiwu-arbug
fbshipit-source-id: d45ca18/Option to fail a request as incomplete when skipping too many internal keys
Summary:
Operations like Seek/Next/Prev sometimes take too long to complete when there are many internal keys to be skipped. Adding an option, max_skippable_internal_keys -- which could be used to set a threshold for the maximum number of keys that can be skipped, will help to address these cases where it is much better to fail a request (as incomplete) than to wait for a considerable time for the request to complete.
This feature -- to fail an iterator seek request as incomplete, is disabled by default when max_skippable_internal_keys = 0. It is enabled only when max_skippable_internal_keys > 0.
This feature is based on the discussion mentioned in the PR https://github.com/facebook/rocksdb/pull/1084.
Closes https://github.com/facebook/rocksdb/pull/2000
Differential Revision: D4753223
Pulled By: sagar0
fbshipit-source-id: 1c973f7/make total_log_size_ atomic
Summary:
make total_log_size_ atomic to avoid overflow caused by data race.
Closes https://github.com/facebook/rocksdb/pull/2019
Differential Revision: D4751391
Pulled By: siying
fbshipit-source-id: fac01dd/dynamic setting of stats_dump_period_sec through SetDBOption()
Summary:
Resolved the following issue: https://github.com/facebook/rocksdb/issues/1930
Closes https://github.com/facebook/rocksdb/pull/2004
Differential Revision: D4736764
Pulled By: yiwu-arbug
fbshipit-source-id: 64fe0b7/Break stalls when no bg work is happening
Summary:
Current stall will keep sleeping even if there is no Flush/Compactions to wait for, I changed the logic to break the stall if we are not flushing or compacting
db_bench command used
```
# fillrandom
# memtable size = 10MB
# value size = 1 MB
# num = 1000
# use /dev/shm
./db_bench --benchmarks=""fillrandom,stats"" --value_size=1048576 --write_buffer_size=10485760 --num=1000 --delayed_write_rate=XXXXX  --db=""/dev/shm/new_stall"" | grep ""Cumulative stall""
```
```
Current results
# delayed_write_rate = 1000 Kb/sec
Cumulative stall: 00:00:9.031 H:M:S
# delayed_write_rate = 200 Kb/sec
Cumulative stall: 00:00:22.314 H:M:S
# delayed_write_rate = 100 Kb/sec
Cumulative stall: 00:00:42.784 H:M:S
# delayed_write_rate = 50 Kb/sec
Cumulative stall: 00:01:23.785 H:M:S
# delayed_write_rate = 25 Kb/sec
Cumulative stall: 00:02:45.702 H:M:S
```
```
New results
# delayed_write_rate = 1000 Kb/sec
Cumulative stall: 00:00:9.017 H:M:S
# delayed_write_rate = 200 Kb/sec
Cumulative stall: 00
Closes https://github.com/facebook/rocksdb/pull/1884
Differential Revision: D4585439
Pulled By: IslamAbdelRahman
fbshipit-source-id: aed2198/Add macros to include file name and line number during Logging
Summary:
current logging
```
2017/03/14-14:20:30.393432 7fedde9f5700 (Original Log Time 2017/03/14-14:20:30.393414) [default] Level summary: base level 1 max bytes base 268435456 files[1 0 0 0 0 0 0] max score 0.25
2017/03/14-14:20:30.393438 7fedde9f5700 [JOB 2] Try to delete WAL files size 61417909, prev total WAL file size 73820858, number of live WAL files 2.
2017/03/14-14:20:30.393464 7fedde9f5700 [DEBUG] [JOB 2] Delete /dev/shm/old_logging//MANIFEST-000001 type=3 #1 -- OK
2017/03/14-14:20:30.393472 7fedde9f5700 [DEBUG] [JOB 2] Delete /dev/shm/old_logging//000003.log type=0 #3 -- OK
2017/03/14-14:20:31.427103 7fedd49f1700 [default] New memtable created with log file: #9. Immutable memtables: 0.
2017/03/14-14:20:31.427179 7fedde9f5700 [JOB 3] Syncing log #6
2017/03/14-14:20:31.427190 7fedde9f5700 (Original Log Time 2017/03/14-14:20:31.427170) Calling FlushMemTableToOutputFile with column family [default], flush slots available 1, compaction slots allowed 1, compaction slots scheduled 1
2017/03/14-14:20:31.
Closes https://github.com/facebook/rocksdb/pull/1990
Differential Revision: D4708695
Pulled By: IslamAbdelRahman
fbshipit-source-id: cb8968f/fix db_sst_test flakiness
Summary:
db_sst_test had been flaky occasionally in the following way: reached_max_space_on_compaction can in very rare cases be 0. This happens when the limit on maximum allowable space set using SetMaxAllowedSpaceUsage is hit during flush for all test db sizes (1,2,4,8 and 10MB).The fix clears the error returned when the the space limit is reached during flush. This ensures that the compaction call back will always be called. The runtime is increased slightly because the 1MB loop writes more data and hits the limit during multiple flushes until compaction is scheduled.
Closes https://github.com/facebook/rocksdb/pull/1861
Differential Revision: D4557396
Pulled By: lgalanis
fbshipit-source-id: ff778d1/Set logs as getting flushed before releasing lock, race condition fix
Summary:
Relating to #1903:
In MaybeFlushColumnFamilies() we want to modify the 'getting_flushed' flag before releasing the db mutex when SwitchMemtable() is called.
The following 2 actions need to be atomic in MaybeFlushColumnFamilies()
- getting_flushed is false on oldest log
- we determine that all CFs can be flushed to successfully release oldest log
- we set getting_flushed = true on the oldest log.
-------
- getting_flushed is false on oldest log
- we determine that all CFs can NOT be flushed to successfully release oldest log
- we set unable_to_flush_oldest_log_ = true on the oldest log.
#### In the 2pc case:
T1 enters function but is unable to flush all CFs to release log
T1 sets unable_to_flush_oldest_log_ = true
T1 begins flushing all CFs possible
T2 enters function but is unable to flush all CFs to release log
T2 sees unable_to_flush_oldes_log_ has been set so exits
T3 enters function and will be able to flush all CFs to release oldest log
T3 sets getting_flushed = true on oldes
Closes https://github.com/facebook/rocksdb/pull/1909
Differential Revision: D4646235
Pulled By: reidHoruff
fbshipit-source-id: c8d0447/Get unique_ptr to use delete[] for char[] in DumpMallocStats
Summary:
Avoid mismatched free() / delete / delete [] in DumpMallocStats
Closes https://github.com/facebook/rocksdb/pull/1927
Differential Revision: D4622045
Pulled By: siying
fbshipit-source-id: 1131b30/Fix interference between max_total_wal_size and db_write_buffer_size checks
Summary:
This is a trivial fix for OOMs we've seen a few days ago in logdevice.
RocksDB get into the following state:
(1) Write throughput is too high for flushes to keep up. Compactions are out of the picture - automatic compactions are disabled, and for manual compactions we don't care that much if they fall behind. We write to many CFs, with only a few L0 sst files in each, so compactions are not needed most of the time.
(2) total_log_size_ is consistently greater than GetMaxTotalWalSize(). It doesn't get smaller since flushes are falling ever further behind.
(3) Total size of memtables is way above db_write_buffer_size and keeps growing. But the write_buffer_manager_->ShouldFlush() is not checked because (2) prevents it (for no good reason, afaict; this is what this commit fixes).
(4) Every call to WriteImpl() hits the MaybeFlushColumnFamilies() path. This keeps flushing the memtables one by one in order of increasing log file number.
(5) No write stalling trigger is hit. We rely on max_write_buffer_number
Closes https://github.com/facebook/rocksdb/pull/1893
Differential Revision: D4593590
Pulled By: yiwu-arbug
fbshipit-source-id: af79c5f/Remove timeout_hint_us from WriteOptions
Summary:
The option has been deprecated for two years and has no effect. Removing.
Closes https://github.com/facebook/rocksdb/pull/1866
Differential Revision: D4555203
Pulled By: yiwu-arbug
fbshipit-source-id: c48f627/Fail IngestExternalFile when bg_error_ exists
Summary:
Fail IngestExternalFile() when bg_error_ exists
Closes https://github.com/facebook/rocksdb/pull/1881
Differential Revision: D4580621
Pulled By: IslamAbdelRahman
fbshipit-source-id: 1194913/Make DBImpl::has_unpersisted_data_ atomic
Summary:
Seems to me `has_unpersisted_data_` is read from read thread and write
from write thread concurrently without synchronization. Making it an
atomic.
I update the logic not because seeing any problem with it, but it just
feel confusing.
Closes https://github.com/facebook/rocksdb/pull/1869
Differential Revision: D4555837
Pulled By: yiwu-arbug
fbshipit-source-id: eff2ab8/"
rocksdb,"fix readampbitmap tests
Summary:
fix test failure of ReadAmpBitmap and ReadAmpBitmapLiveInCacheAfterDBClose.
test ReadAmpBitmapLiveInCacheAfterDBClose individually and make check
Closes https://github.com/facebook/rocksdb/pull/2271
Differential Revision: D5038133
Pulled By: lightmark
fbshipit-source-id: 803cd6f45ccfdd14a9d9473c8af311033e164be8/unbiase readamp bitmap
Summary:
Consider BlockReadAmpBitmap with bytes_per_bit = 32. Suppose bytes [a, b) were used, while bytes [a-32, a)
and [b+1, b+33) weren't used; more formally, the union of ranges passed to BlockReadAmpBitmap::Mark() contains [a, b) and doesn't intersect with [a-32, a) and [b+1, b+33). Then bits [floor(a/32), ceil(b/32)] will be set, and so the number of useful bytes will be estimated as (ceil(b/32) - floor(a/32)) * 32, which is on average equal to b-a+31.
An extreme example: if we use 1 byte from each block, it'll be counted as 32 bytes from each block.
It's easy to remove this bias by slightly changing the semantics of the bitmap. Currently each bit represents a byte range [i*32, (i+1)*32).
This diff makes each bit represent a single byte: i*32 + X, where X is a random number in [0, 31] generated when bitmap is created. So, e.g., if you read a single byte at random, with probability 31/32 it won't be counted at all, and with probability 1/32 it will be counted as 32 bytes; so, on average it's counted as 1 byte.
*But there is one exception: the last bit will always set with the old way.*
(*) - assuming read_amp_bytes_per_bit = 32.
Closes https://github.com/facebook/rocksdb/pull/2259
Differential Revision: D5035652
Pulled By: lightmark
fbshipit-source-id: bd98b1b9b49fbe61f9e3781d07f624e3cbd92356/"
rocksdb,"Fix some bugs in MockEnv
Summary:
Fixing some bugs in MockEnv so it be actually used.
Closes https://github.com/facebook/rocksdb/pull/1914
Differential Revision: D4609923
Pulled By: maysamyabandeh
fbshipit-source-id: ca25735/Fix a bug in tests in options operator=
Summary:
Note: Using the default operator= is an unsafe approach for Options since it destructs shared_ptr in
the same order of their creation, in contrast to destructors which
destructs them in the opposite order of creation. One particular problme is
that the cache destructor might invoke callback functions that use Option
members such as statistics. To work around this problem, we manually call
destructor of table_facotry which eventually clears the block cache.
Closes https://github.com/facebook/rocksdb/pull/1950
Differential Revision: D4655473
Pulled By: maysamyabandeh
fbshipit-source-id: 6c4bbff/Make db_wal_test slightly faster
Summary:
Avoid to run db_wal_test in all the DB test options, and some small changes.
Closes https://github.com/facebook/rocksdb/pull/1921
Differential Revision: D4622054
Pulled By: siying
fbshipit-source-id: 890fd64/"
rocksdb,"support PopSavePoint for WriteBatch
Summary:
Try to fix https://github.com/facebook/rocksdb/issues/1969
Closes https://github.com/facebook/rocksdb/pull/2170
Differential Revision: D4907333
Pulled By: yiwu-arbug
fbshipit-source-id: 417b420ff668e6c2fd0dad42a94c57385012edc5/"
rocksdb,"Fix compilation for GCC-5
Summary:
Fixes this issue https://github.com/facebook/rocksdb/issues/2108
Closes https://github.com/facebook/rocksdb/pull/2109
Differential Revision: D4851965
Pulled By: yiwu-arbug
fbshipit-source-id: 6ee807b/Refactor compaction picker code
Summary:
1. Move universal compaction picker to separate files compaction_picker_universal.cc and compaction_picker_universal.h.
2. Rename some functions to make the code easier to understand.
3. Move leveled compaction picking code to a dedicated class, so that we we don't need to pass some common variable around when calling functions. It also allowed us to break down LevelCompactionPicker::PickCompaction() to smaller functions.
Closes https://github.com/facebook/rocksdb/pull/2100
Differential Revision: D4845948
Pulled By: siying
fbshipit-source-id: efa0ab4/Add macros to include file name and line number during Logging
Summary:
current logging
```
2017/03/14-14:20:30.393432 7fedde9f5700 (Original Log Time 2017/03/14-14:20:30.393414) [default] Level summary: base level 1 max bytes base 268435456 files[1 0 0 0 0 0 0] max score 0.25
2017/03/14-14:20:30.393438 7fedde9f5700 [JOB 2] Try to delete WAL files size 61417909, prev total WAL file size 73820858, number of live WAL files 2.
2017/03/14-14:20:30.393464 7fedde9f5700 [DEBUG] [JOB 2] Delete /dev/shm/old_logging//MANIFEST-000001 type=3 #1 -- OK
2017/03/14-14:20:30.393472 7fedde9f5700 [DEBUG] [JOB 2] Delete /dev/shm/old_logging//000003.log type=0 #3 -- OK
2017/03/14-14:20:31.427103 7fedd49f1700 [default] New memtable created with log file: #9. Immutable memtables: 0.
2017/03/14-14:20:31.427179 7fedde9f5700 [JOB 3] Syncing log #6
2017/03/14-14:20:31.427190 7fedde9f5700 (Original Log Time 2017/03/14-14:20:31.427170) Calling FlushMemTableToOutputFile with column family [default], flush slots available 1, compaction slots allowed 1, compaction slots scheduled 1
2017/03/14-14:20:31.
Closes https://github.com/facebook/rocksdb/pull/1990
Differential Revision: D4708695
Pulled By: IslamAbdelRahman
fbshipit-source-id: cb8968f/"
rocksdb,"set compaction_iterator earliest_snapshot to max if no snapshot
Summary:
It is a potential bug that will be triggered if we ingest files before inserting the first key into an empty db.
0 is a special value reserved to indicate the concept of non-existence. But not good for seqno in this case because 0 is a valid seqno for ingestion(bulk loading)
Closes https://github.com/facebook/rocksdb/pull/2183
Differential Revision: D4919827
Pulled By: lightmark
fbshipit-source-id: 237eea40f88bd6487b66806109d90065dc02c362/"
rocksdb,"Option to fail a request as incomplete when skipping too many internal keys
Summary:
Operations like Seek/Next/Prev sometimes take too long to complete when there are many internal keys to be skipped. Adding an option, max_skippable_internal_keys -- which could be used to set a threshold for the maximum number of keys that can be skipped, will help to address these cases where it is much better to fail a request (as incomplete) than to wait for a considerable time for the request to complete.
This feature -- to fail an iterator seek request as incomplete, is disabled by default when max_skippable_internal_keys = 0. It is enabled only when max_skippable_internal_keys > 0.
This feature is based on the discussion mentioned in the PR https://github.com/facebook/rocksdb/pull/1084.
Closes https://github.com/facebook/rocksdb/pull/2000
Differential Revision: D4753223
Pulled By: sagar0
fbshipit-source-id: 1c973f7/Add macros to include file name and line number during Logging
Summary:
current logging
```
2017/03/14-14:20:30.393432 7fedde9f5700 (Original Log Time 2017/03/14-14:20:30.393414) [default] Level summary: base level 1 max bytes base 268435456 files[1 0 0 0 0 0 0] max score 0.25
2017/03/14-14:20:30.393438 7fedde9f5700 [JOB 2] Try to delete WAL files size 61417909, prev total WAL file size 73820858, number of live WAL files 2.
2017/03/14-14:20:30.393464 7fedde9f5700 [DEBUG] [JOB 2] Delete /dev/shm/old_logging//MANIFEST-000001 type=3 #1 -- OK
2017/03/14-14:20:30.393472 7fedde9f5700 [DEBUG] [JOB 2] Delete /dev/shm/old_logging//000003.log type=0 #3 -- OK
2017/03/14-14:20:31.427103 7fedd49f1700 [default] New memtable created with log file: #9. Immutable memtables: 0.
2017/03/14-14:20:31.427179 7fedde9f5700 [JOB 3] Syncing log #6
2017/03/14-14:20:31.427190 7fedde9f5700 (Original Log Time 2017/03/14-14:20:31.427170) Calling FlushMemTableToOutputFile with column family [default], flush slots available 1, compaction slots allowed 1, compaction slots scheduled 1
2017/03/14-14:20:31.
Closes https://github.com/facebook/rocksdb/pull/1990
Differential Revision: D4708695
Pulled By: IslamAbdelRahman
fbshipit-source-id: cb8968f/"
rocksdb,"Fix some bugs in MockEnv
Summary:
Fixing some bugs in MockEnv so it be actually used.
Closes https://github.com/facebook/rocksdb/pull/1914
Differential Revision: D4609923
Pulled By: maysamyabandeh
fbshipit-source-id: ca25735/"
rocksdb,"Fix Windows Build broken by a recent commit
Summary: Closes https://github.com/facebook/rocksdb/pull/2032
Differential Revision: D4766260
Pulled By: siying
fbshipit-source-id: 415daa4/Fix clang compile error - [-Werror,-Wunused-lambda-capture]
Summary:
Errors where:
db/version_set.cc:1535:20: error: lambda capture 'this' is not used [-Werror,-Wunused-lambda-capture]
[this](const Fsize& f1, const Fsize& f2) -> bool {
^
db/version_set.cc:1541:20: error: lambda capture 'this' is not used [-Werror,-Wunused-lambda-capture]
[this](const Fsize& f1, const Fsize& f2) -> bool {
^
db/db_test.cc:2983:27: error: lambda capture 'kNumPutsBeforeWaitForFlush' is not required to be captured for this use [-Werror,-Wunused-lambda-capture]
auto gen_l0_kb = [this, kNumPutsBeforeWaitForFlush](int size) {
^
Closes https://github.com/facebook/rocksdb/pull/1972
Differential Revision: D4685991
Pulled By: siying
fbshipit-source-id: 9125379/avoid ASSERT_EQ(false, ...);
Summary:
lately it fails on travis due to a compiler bug (see https://github.com/google/googletest/issues/322#issuecomment-125645145). interestingly it seems to affect occurrences of `ASSERT_EQ(false, ...);` but not `ASSERT_EQ(true, ...);`.
Closes https://github.com/facebook/rocksdb/pull/1958
Differential Revision: D4680742
Pulled By: ajkr
fbshipit-source-id: 291fe41/fix rate limiter test flakiness
Summary:
fix when elapsed time spans non-integral number of intervals since the rate limiter may still be drained during a partial interval.
Closes https://github.com/facebook/rocksdb/pull/1948
Differential Revision: D4651304
Pulled By: ajkr
fbshipit-source-id: b1f9e70/Statistic for how often rate limiter is drained
Summary:
This is the metric I plan to use for adaptive rate limiting. The statistics are updated only if the rate limiter is drained by flush or compaction. I believe (but am not certain) that this is the normal case.
The Statistics object is passed in RateLimiter::Request() to avoid requiring changes to client code, which would've been necessary if we passed it in the RateLimiter constructor.
Closes https://github.com/facebook/rocksdb/pull/1946
Differential Revision: D4646489
Pulled By: ajkr
fbshipit-source-id: d8e0161/Remove timeout_hint_us from WriteOptions
Summary:
The option has been deprecated for two years and has no effect. Removing.
Closes https://github.com/facebook/rocksdb/pull/1866
Differential Revision: D4555203
Pulled By: yiwu-arbug
fbshipit-source-id: c48f627/"
rocksdb,"Set lower-bound on dynamic level sizes
Summary:
Changed dynamic leveling to stop setting the base level's size bound below `max_bytes_for_level_base`.
Behavior for config where `max_bytes_for_level_base == level0_file_num_compaction_trigger * write_buffer_size` and same amount of data in L0 and base-level:
- Before #2027, compaction scoring would favor base-level due to dividing by size smaller than `max_bytes_for_level_base`.
- After #2027, L0 and Lbase get equal scores. The disadvantage is L0 is often compacted before reaching the num files trigger since `write_buffer_size` can be bigger than the dynamically chosen base-level size. This increases write-amp.
- After this diff, L0 and Lbase still get equal scores. Now it takes `level0_file_num_compaction_trigger` files of size `write_buffer_size` to trigger L0 compaction by size, fixing the write-amp problem above.
Closes https://github.com/facebook/rocksdb/pull/2123
Differential Revision: D4861570
Pulled By: ajkr
fbshipit-source-id: 467ddef56ed1f647c14d86bb018bcb044c39b964/Max open files mutable
Summary:
Makes max_open_files db option dynamically set-able by SetDBOptions. During the call of SetDBOptions we call SetCapacity on the table cache, which is a LRUCache.
Closes https://github.com/facebook/rocksdb/pull/2185
Differential Revision: D4979189
Pulled By: yiwu-arbug
fbshipit-source-id: ca7e8dc5e3619c79434f579be4847c0f7e56afda/Change L0 compaction score using level size
Summary:
The goal is to avoid the problem of small number of L0 files triggering compaction to base level (which increased write-amp), while still allowing L0 compaction-by-size (so intra-L0 compactions cause score to increase).
Closes https://github.com/facebook/rocksdb/pull/2172
Differential Revision: D4908552
Pulled By: ajkr
fbshipit-source-id: 4b170142b2b368e24bd7948b2a6f24c69fabf73d/Fix clang compile error - [-Werror,-Wunused-lambda-capture]
Summary:
Errors where:
db/version_set.cc:1535:20: error: lambda capture 'this' is not used [-Werror,-Wunused-lambda-capture]
[this](const Fsize& f1, const Fsize& f2) -> bool {
^
db/version_set.cc:1541:20: error: lambda capture 'this' is not used [-Werror,-Wunused-lambda-capture]
[this](const Fsize& f1, const Fsize& f2) -> bool {
^
db/db_test.cc:2983:27: error: lambda capture 'kNumPutsBeforeWaitForFlush' is not required to be captured for this use [-Werror,-Wunused-lambda-capture]
auto gen_l0_kb = [this, kNumPutsBeforeWaitForFlush](int size) {
^
Closes https://github.com/facebook/rocksdb/pull/1972
Differential Revision: D4685991
Pulled By: siying
fbshipit-source-id: 9125379/Add macros to include file name and line number during Logging
Summary:
current logging
```
2017/03/14-14:20:30.393432 7fedde9f5700 (Original Log Time 2017/03/14-14:20:30.393414) [default] Level summary: base level 1 max bytes base 268435456 files[1 0 0 0 0 0 0] max score 0.25
2017/03/14-14:20:30.393438 7fedde9f5700 [JOB 2] Try to delete WAL files size 61417909, prev total WAL file size 73820858, number of live WAL files 2.
2017/03/14-14:20:30.393464 7fedde9f5700 [DEBUG] [JOB 2] Delete /dev/shm/old_logging//MANIFEST-000001 type=3 #1 -- OK
2017/03/14-14:20:30.393472 7fedde9f5700 [DEBUG] [JOB 2] Delete /dev/shm/old_logging//000003.log type=0 #3 -- OK
2017/03/14-14:20:31.427103 7fedd49f1700 [default] New memtable created with log file: #9. Immutable memtables: 0.
2017/03/14-14:20:31.427179 7fedde9f5700 [JOB 3] Syncing log #6
2017/03/14-14:20:31.427190 7fedde9f5700 (Original Log Time 2017/03/14-14:20:31.427170) Calling FlushMemTableToOutputFile with column family [default], flush slots available 1, compaction slots allowed 1, compaction slots scheduled 1
2017/03/14-14:20:31.
Closes https://github.com/facebook/rocksdb/pull/1990
Differential Revision: D4708695
Pulled By: IslamAbdelRahman
fbshipit-source-id: cb8968f/avoid direct io in rocksdb_lite
Summary:
fix lite bugs
disable direct io in lite mode
Closes https://github.com/facebook/rocksdb/pull/1870
Differential Revision: D4559866
Pulled By: yiwu-arbug
fbshipit-source-id: 3761c51/"
rocksdb,"support PopSavePoint for WriteBatch
Summary:
Try to fix https://github.com/facebook/rocksdb/issues/1969
Closes https://github.com/facebook/rocksdb/pull/2170
Differential Revision: D4907333
Pulled By: yiwu-arbug
fbshipit-source-id: 417b420ff668e6c2fd0dad42a94c57385012edc5/Fix build with MinGW
Summary:
There still are many warnings (most of them about invalid printf format
for long long), but it builds if FAIL_ON_WARNINGS is disabled.
Closes https://github.com/facebook/rocksdb/pull/2052
Differential Revision: D4807355
Pulled By: siying
fbshipit-source-id: ef03786/"
rocksdb,"support PopSavePoint for WriteBatch
Summary:
Try to fix https://github.com/facebook/rocksdb/issues/1969
Closes https://github.com/facebook/rocksdb/pull/2170
Differential Revision: D4907333
Pulled By: yiwu-arbug
fbshipit-source-id: 417b420ff668e6c2fd0dad42a94c57385012edc5/"
rocksdb,"Fix random access alignment
Summary:
This fixes an issue when the most recent readers assume that alignment is always set even if direct io is off.
Also adjust slightly appveyor script to run db_basic_test cases concurrently.
Closes https://github.com/facebook/rocksdb/pull/1959
Differential Revision: D4671972
Pulled By: IslamAbdelRahman
fbshipit-source-id: 1886620/"
rocksdb,"Replace dynamic_cast<>
Summary:
Replace dynamic_cast<> so that users can choose to build with RTTI off, so that they can save several bytes per object, and get tiny more memory available.
Some nontrivial changes:
1. Add Comparator::GetRootComparator() to get around the internal comparator hack
2. Add the two experiemental functions to DB
3. Add TableFactory::GetOptionString() to avoid unnecessary casting to get the option string
4. Since 3 is done, move the parsing option functions for table factory to table factory files too, to be symmetric.
Closes https://github.com/facebook/rocksdb/pull/2645
Differential Revision: D5502723
Pulled By: siying
fbshipit-source-id: fd13cec5601cf68a554d87bfcf056f2ffa5fbf7c/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Allow ignoring unknown options when loading options from a file
Summary:
Added a flag, `ignore_unknown_options`, to skip unknown options when loading an options file (using `LoadLatestOptions`/`LoadOptionsFromFile`) or while verifying options (using `CheckOptionsCompatibility`). This will help in downgrading the db to an older version.
Also added `--ignore_unknown_options` flag to ldb
**Example Use case:**
In MyRocks, if copying from newer version to older version, it is often impossible to start because of new RocksDB options that don't exist in older version, even though data format is compatible.
MyRocks uses these load and verify functions in [ha_rocksdb.cc::check_rocksdb_options_compatibility](https://github.com/facebook/mysql-5.6/blob/e004fd9f416821d043ccc8ad4a345c33ac9953f0/storage/rocksdb/ha_rocksdb.cc#L3348-L3401).
**Test Plan:**
Updated the unit tests.
`make check`
ldb:
$ ./ldb --db=/tmp/test_db --create_if_missing put a1 b1
OK
Now edit /tmp/test_db/<OPTIONS-file> and add an unknown option.
Try loading the options now, and it fails:
$ ./ldb --db=/tmp/test_db --try_load_options get a1
Failed: Invalid argument: Unrecognized option DBOptions:: abcd
Passes with the new --ignore_unknown_options flag
$ ./ldb --db=/tmp/test_db --try_load_options --ignore_unknown_options get a1
b1
Closes https://github.com/facebook/rocksdb/pull/2423
Differential Revision: D5212091
Pulled By: sagar0
fbshipit-source-id: 2ec17636feb47dc0351b53a77e5f15ef7cbf2ca7/"
rocksdb,"Dump Blob DB options to info log
Summary:
* Dump blob db options to info log
* Remove BlobDBOptionsImpl to disallow dynamic cast *BlobDBOptions into *BlobDBOptionsImpl. Move options there to be constants or into BlobDBOptions. The dynamic cast is broken after #2645
* Change some of the default options
* Remove blob_db_options.min_blob_size, which is unimplemented. Will implement it soon.
Closes https://github.com/facebook/rocksdb/pull/2671
Differential Revision: D5529912
Pulled By: yiwu-arbug
fbshipit-source-id: dcd58ca981db5bcc7f123b65a0d6f6ae0dc703c7/Replace dynamic_cast<>
Summary:
Replace dynamic_cast<> so that users can choose to build with RTTI off, so that they can save several bytes per object, and get tiny more memory available.
Some nontrivial changes:
1. Add Comparator::GetRootComparator() to get around the internal comparator hack
2. Add the two experiemental functions to DB
3. Add TableFactory::GetOptionString() to avoid unnecessary casting to get the option string
4. Since 3 is done, move the parsing option functions for table factory to table factory files too, to be symmetric.
Closes https://github.com/facebook/rocksdb/pull/2645
Differential Revision: D5502723
Pulled By: siying
fbshipit-source-id: fd13cec5601cf68a554d87bfcf056f2ffa5fbf7c/fix db_bench argument type
Summary:
it should be a bool
Closes https://github.com/facebook/rocksdb/pull/2653
Differential Revision: D5506148
Pulled By: ajkr
fbshipit-source-id: f142f0f3aa8b678c68adef12e5ac6e1e163306f3/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Enable write rate limit for updaterandom benchmark
Summary:
We have FLAGS_benchmark_write_rate_limit to limit write rate in
db_bench, but it was not in use for updaterandom benchmark.
Closes https://github.com/facebook/rocksdb/pull/2578
Differential Revision: D5420328
Pulled By: yiwu-arbug
fbshipit-source-id: 5fa48c2b88f2f2dc83d615cb9c40c472bc916835/Fixes db_bench with blob db
Summary:
* Create info log before db open to make blob db able to log to LOG file.
* Properly destroy blob db.
Closes https://github.com/facebook/rocksdb/pull/2567
Differential Revision: D5400034
Pulled By: yiwu-arbug
fbshipit-source-id: a49cfaf4b5c67d42d4cbb872bd5a9441828c17ce/db_bench_tool: fix buffer size
Summary:
Found by gcc warning:
x86_64-pc-linux-gnu-g++ --version
x86_64-pc-linux-gnu-g++ (GCC) 7.1.1 20170710
tools/db_bench_tool.cc: In member function 'void rocksdb::Benchmark::RandomWithVerify(rocksdb::ThreadState*)':
tools/db_bench_tool.cc:4430:8: error: '%lu' directive output may be truncated writing between 1 and 19 bytes into a region of size between 0 and 66 [-Werror=format-truncation=]
void RandomWithVerify(ThreadState* thread) {
^~~~~~~~~~~~~~~~
tools/db_bench_tool.cc:4430:8: note: directive argument in the range [0, 9223372036854775807]
tools/db_bench_tool.cc:4492:13: note: 'snprintf' output between 37 and 128 bytes into a destination of size 100
snprintf(msg, sizeof(msg),
~~~~~~~~^~~~~~~~~~~~~~~~~~
""( get:%"" PRIu64 "" put:%"" PRIu64 "" del:%"" PRIu64 "" total:%"" \
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
PRIu64 "" found:%"" PRIu64 "")"",
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gets_done, puts_done, deletes_done, readwrites_, found);
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cc1plus: all warnings being treated as errors
Makefile:1707: recipe for target 'tools/db_bench_tool.o' failed
Closes https://github.com/facebook/rocksdb/pull/2558
Differential Revision: D5398703
Pulled By: siying
fbshipit-source-id: 6ffa552bbd8b59cfc2c36289f86ff9b9acca8ca6/Add max_background_jobs to db_bench
Summary:
As titled. Also fixed an off-by-one error causing us to add one less range deletion than the user specified.
Closes https://github.com/facebook/rocksdb/pull/2544
Differential Revision: D5383451
Pulled By: ajkr
fbshipit-source-id: cbd5890c33f09bbb5c0c1f4bb952a1add32336e0/FIFO Compaction with TTL
Summary:
Introducing FIFO compactions with TTL.
FIFO compaction is based on size only which makes it tricky to enable in production as use cases can have organic growth. A user requested an option to drop files based on the time of their creation instead of the total size.
To address that request:
- Added a new TTL option to FIFO compaction options.
- Updated FIFO compaction score to take TTL into consideration.
- Added a new table property, creation_time, to keep track of when the SST file is created.
- Creation_time is set as below:
- On Flush: Set to the time of flush.
- On Compaction: Set to the max creation_time of all the files involved in the compaction.
- On Repair and Recovery: Set to the time of repair/recovery.
- Old files created prior to this code change will have a creation_time of 0.
- FIFO compaction with TTL is enabled when ttl > 0. All files older than ttl will be deleted during compaction. i.e. `if (file.creation_time < (current_time - ttl)) then delete(file)`. This will enable cases where you might want to delete all files older than, say, 1 day.
- FIFO compaction will fall back to the prior way of deleting files based on size if:
- the creation_time of all files involved in compaction is 0.
- the total size (of all SST files combined) does not drop below `compaction_options_fifo.max_table_files_size` even if the files older than ttl are deleted.
This feature is not supported if max_open_files != -1 or with table formats other than Block-based.
**Test Plan:**
Added tests.
**Benchmark results:**
Base: FIFO with max size: 100MB ::
```
svemuri@dev15905 ~/rocksdb (fifo-compaction) $ TEST_TMPDIR=/dev/shm ./db_bench --benchmarks=readwhilewriting --num=5000000 --threads=16 --compaction_style=2 --fifo_compaction_max_table_files_size_mb=100
readwhilewriting :       1.924 micros/op 519858 ops/sec;   13.6 MB/s (1176277 of 5000000 found)
```
With TTL (a low one for testing) ::
```
svemuri@dev15905 ~/rocksdb (fifo-compaction) $ TEST_TMPDIR=/dev/shm ./db_bench --benchmarks=readwhilewriting --num=5000000 --threads=16 --compaction_style=2 --fifo_compaction_max_table_files_size_mb=100 --fifo_compaction_ttl=20
readwhilewriting :       1.902 micros/op 525817 ops/sec;   13.7 MB/s (1185057 of 5000000 found)
```
Example Log lines:
```
2017/06/26-15:17:24.609249 7fd5a45ff700 (Original Log Time 2017/06/26-15:17:24.609177) [db/compaction_picker.cc:1471] [default] FIFO compaction: picking file 40 with creation time 1498515423 for deletion
2017/06/26-15:17:24.609255 7fd5a45ff700 (Original Log Time 2017/06/26-15:17:24.609234) [db/db_impl_compaction_flush.cc:1541] [default] Deleted 1 files
...
2017/06/26-15:17:25.553185 7fd5a61a5800 [DEBUG] [db/db_impl_files.cc:309] [JOB 0] Delete /dev/shm/dbbench/000040.sst type=2 #40 -- OK
2017/06/26-15:17:25.553205 7fd5a61a5800 EVENT_LOG_v1 {""time_micros"": 1498515445553199, ""job"": 0, ""event"": ""table_file_deletion"", ""file_number"": 40}
```
SST Files remaining in the dbbench dir, after db_bench execution completed:
```
svemuri@dev15905 ~/rocksdb (fifo-compaction)  $ ls -l /dev/shm//dbbench/*.sst
-rw-r--r--. 1 svemuri users 30749887 Jun 26 15:17 /dev/shm//dbbench/000042.sst
-rw-r--r--. 1 svemuri users 30768779 Jun 26 15:17 /dev/shm//dbbench/000044.sst
-rw-r--r--. 1 svemuri users 30757481 Jun 26 15:17 /dev/shm//dbbench/000046.sst
```
Closes https://github.com/facebook/rocksdb/pull/2480
Differential Revision: D5305116
Pulled By: sagar0
fbshipit-source-id: 3e5cfcf5dd07ed2211b5b37492eb235b45139174/using ThreadLocalPtr to hide ROCKSDB_SUPPORT_THREAD_LOCAL from public
Summary:
 headers
https://github.com/facebook/rocksdb/pull/2199 should not reference RocksDB-specific macros (like ROCKSDB_SUPPORT_THREAD_LOCAL in this case) to public headers, `iostats_context.h` and `perf_context.h`. We shouldn't do that because users have to provide these compiler flags when building their binary with RocksDB.
We should hide the thread local global variable inside our implementation and just expose a function api to retrieve these variables. It may break some users for now but good for long term.
make check -j64
Closes https://github.com/facebook/rocksdb/pull/2380
Differential Revision: D5177896
Pulled By: lightmark
fbshipit-source-id: 6fcdfac57f2e2dcfe60992b7385c5403f6dcb390/fix regression test
Summary:
fix regression test by not reporting stats when building db
Closes https://github.com/facebook/rocksdb/pull/2390
Differential Revision: D5159909
Pulled By: lightmark
fbshipit-source-id: c3f4b9deb9c6799ff84207fd341c529144f8158d/change regression rebuild to one level
Summary:
abandon fillseqdeterministic
test locally
Closes https://github.com/facebook/rocksdb/pull/2290
Differential Revision: D5151867
Pulled By: lightmark
fbshipit-source-id: 4c8a24cc937212ffb5ceb9bfaf7288eb8726d0c1/Fix db_bench build break with blob db
Summary:
Lite build does not recognize FLAGS_use_blob_db. Fixing it.
Closes https://github.com/facebook/rocksdb/pull/2372
Reviewed By: anirbanr-fb
Differential Revision: D5130773
Pulled By: yiwu-arbug
fbshipit-source-id: 43131d9d0be5811f2129af562be72cca26369cb3/"
rocksdb,"Replace dynamic_cast<>
Summary:
Replace dynamic_cast<> so that users can choose to build with RTTI off, so that they can save several bytes per object, and get tiny more memory available.
Some nontrivial changes:
1. Add Comparator::GetRootComparator() to get around the internal comparator hack
2. Add the two experiemental functions to DB
3. Add TableFactory::GetOptionString() to avoid unnecessary casting to get the option string
4. Since 3 is done, move the parsing option functions for table factory to table factory files too, to be symmetric.
Closes https://github.com/facebook/rocksdb/pull/2645
Differential Revision: D5502723
Pulled By: siying
fbshipit-source-id: fd13cec5601cf68a554d87bfcf056f2ffa5fbf7c/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Allow ignoring unknown options when loading options from a file
Summary:
Added a flag, `ignore_unknown_options`, to skip unknown options when loading an options file (using `LoadLatestOptions`/`LoadOptionsFromFile`) or while verifying options (using `CheckOptionsCompatibility`). This will help in downgrading the db to an older version.
Also added `--ignore_unknown_options` flag to ldb
**Example Use case:**
In MyRocks, if copying from newer version to older version, it is often impossible to start because of new RocksDB options that don't exist in older version, even though data format is compatible.
MyRocks uses these load and verify functions in [ha_rocksdb.cc::check_rocksdb_options_compatibility](https://github.com/facebook/mysql-5.6/blob/e004fd9f416821d043ccc8ad4a345c33ac9953f0/storage/rocksdb/ha_rocksdb.cc#L3348-L3401).
**Test Plan:**
Updated the unit tests.
`make check`
ldb:
$ ./ldb --db=/tmp/test_db --create_if_missing put a1 b1
OK
Now edit /tmp/test_db/<OPTIONS-file> and add an unknown option.
Try loading the options now, and it fails:
$ ./ldb --db=/tmp/test_db --try_load_options get a1
Failed: Invalid argument: Unrecognized option DBOptions:: abcd
Passes with the new --ignore_unknown_options flag
$ ./ldb --db=/tmp/test_db --try_load_options --ignore_unknown_options get a1
b1
Closes https://github.com/facebook/rocksdb/pull/2423
Differential Revision: D5212091
Pulled By: sagar0
fbshipit-source-id: 2ec17636feb47dc0351b53a77e5f15ef7cbf2ca7/"
rocksdb,"fix tsan crash data race
Summary:
rand_ has data race risk
TEST_TMPDIR=\/dev\/shm\/rocksdb OPT=-g COMPILE_WITH_TSAN=1 CRASH_TEST_KILL_ODD=1887 make J=1 crash_test
Closes https://github.com/facebook/rocksdb/pull/2368
Differential Revision: D5127424
Pulled By: lightmark
fbshipit-source-id: b7f4d1430a5769b57da9f99037106749264b2ced/Fix release build on Linux
Summary:
Release builds are failing on Linux with the error:
```
tools/db_stress.cc: In function int main(int, char**):
tools/db_stress.cc:2365:12: error: rocksdb::SyncPoint has not been declared
rocksdb::SyncPoint::GetInstance()->SetCallBack(
^
tools/db_stress.cc:2370:12: error: rocksdb::SyncPoint has not been declared
rocksdb::SyncPoint::GetInstance()->SetCallBack(
^
tools/db_stress.cc:2375:12: error: rocksdb::SyncPoint has not been declared
rocksdb::SyncPoint::GetInstance()->EnableProcessing();
^
make[1]: *** [tools/db_stress.o] Error 1
make[1]: Leaving directory `/data/sandcastle/boxes/trunk-git-rocksdb-public'
make: *** [release] Error 2
```
Closes https://github.com/facebook/rocksdb/pull/2355
Differential Revision: D5113552
Pulled By: sagar0
fbshipit-source-id: 351df707277787da5633ba4a40e52edc7c895dc4/"
rocksdb,"Support prefetch last 512KB with direct I/O in block based file reader
Summary:
Right now, if direct I/O is enabled, prefetching the last 512KB cannot be applied, except compaction inputs or readahead is enabled for iterators. This can create a lot of I/O for HDD cases. To solve the problem, the 512KB is prefetched in block based table if direct I/O is enabled. The prefetched buffer is passed in totegher with random access file reader, so that we try to read from the buffer before reading from the file. This can be extended in the future to support flexible user iterator readahead too.
Closes https://github.com/facebook/rocksdb/pull/2708
Differential Revision: D5593091
Pulled By: siying
fbshipit-source-id: ee36ff6d8af11c312a2622272b21957a7b5c81e7/add VerifyChecksum() to db.h
Summary:
We need a tool to check any sst file corruption in the db.
It will check all the sst files in current version and read all the blocks (data, meta, index) with checksum verification. If any verification fails, the function will return non-OK status.
Closes https://github.com/facebook/rocksdb/pull/2498
Differential Revision: D5324269
Pulled By: lightmark
fbshipit-source-id: 6f8a272008b722402a772acfc804524c9d1a483b/Replace dynamic_cast<>
Summary:
Replace dynamic_cast<> so that users can choose to build with RTTI off, so that they can save several bytes per object, and get tiny more memory available.
Some nontrivial changes:
1. Add Comparator::GetRootComparator() to get around the internal comparator hack
2. Add the two experiemental functions to DB
3. Add TableFactory::GetOptionString() to avoid unnecessary casting to get the option string
4. Since 3 is done, move the parsing option functions for table factory to table factory files too, to be symmetric.
Closes https://github.com/facebook/rocksdb/pull/2645
Differential Revision: D5502723
Pulled By: siying
fbshipit-source-id: fd13cec5601cf68a554d87bfcf056f2ffa5fbf7c/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Improve Status message for block checksum mismatches
Summary:
We've got some DBs where iterators return Status with message ""Corruption: block checksum mismatch"" all the time. That's not very informative. It would be much easier to investigate if the error message contained the file name - then we would know e.g. how old the corrupted file is, which would be very useful for finding the root cause. This PR adds file name, offset and other stuff to some block corruption-related status messages.
It doesn't improve all the error messages, just a few that were easy to improve. I'm mostly interested in ""block checksum mismatch"" and ""Bad table magic number"" since they're the only corruption errors that I've ever seen in the wild.
Closes https://github.com/facebook/rocksdb/pull/2507
Differential Revision: D5345702
Pulled By: al13n321
fbshipit-source-id: fc8023d43f1935ad927cef1b9c55481ab3cb1339/"
rocksdb,"Replace dynamic_cast<>
Summary:
Replace dynamic_cast<> so that users can choose to build with RTTI off, so that they can save several bytes per object, and get tiny more memory available.
Some nontrivial changes:
1. Add Comparator::GetRootComparator() to get around the internal comparator hack
2. Add the two experiemental functions to DB
3. Add TableFactory::GetOptionString() to avoid unnecessary casting to get the option string
4. Since 3 is done, move the parsing option functions for table factory to table factory files too, to be symmetric.
Closes https://github.com/facebook/rocksdb/pull/2645
Differential Revision: D5502723
Pulled By: siying
fbshipit-source-id: fd13cec5601cf68a554d87bfcf056f2ffa5fbf7c/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"Windows.h macro call fix
Summary:
- moved the max call for numeric limits into paranthesis so that max wont be called as macro when including <Windows.h>
Closes https://github.com/facebook/rocksdb/pull/2709
Differential Revision: D5600773
Pulled By: yiwu-arbug
fbshipit-source-id: fd28b6f7c10ddce21bad4030f2db06f965bb08da/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Fix GetCurrentTime() initialization for valgrind
Summary:
Valgrind had false positive complaints about the initialization pattern for `GetCurrentTime()`'s argument in #2480. We can instead have the client initialize the time variable before calling `GetCurrentTime()`, and have `GetCurrentTime()` promise to only overwrite it in success case.
Closes https://github.com/facebook/rocksdb/pull/2526
Differential Revision: D5358689
Pulled By: ajkr
fbshipit-source-id: 857b189f24c19196f6bb299216f3e23e7bc4be42/Encryption at rest support
Summary:
This PR adds support for encrypting data stored by RocksDB when written to disk.
It adds an `EncryptedEnv` override of the `Env` class with matching overrides for sequential&random access files.
The encryption itself is done through a configurable `EncryptionProvider`. This class creates is asked to create `BlockAccessCipherStream` for a file. This is where the actual encryption/decryption is being done.
Currently there is a Counter mode implementation of `BlockAccessCipherStream` with a `ROT13` block cipher (NOTE the `ROT13` is for demo purposes only!!).
The Counter operation mode uses an initial counter & random initialization vector (IV).
Both are created randomly for each file and stored in a 4K (default size) block that is prefixed to that file. The `EncryptedEnv` implementation is such that clients of the `Env` class do not see this prefix (nor data, nor in filesize).
The largest part of the prefix block is also encrypted, and there is room left for implementation specific settings/values/keys in there.
To test the encryption, the `DBTestBase` class has been extended to consider a new environment variable called `ENCRYPTED_ENV`. If set, the test will setup a encrypted instance of the `Env` class to use for all tests.
Typically you would run it like this:
```
ENCRYPTED_ENV=1 make check_some
```
There is also an added test that checks that some data inserted into the database is or is not ""visible"" on disk. With `ENCRYPTED_ENV` active it must not find plain text strings, with `ENCRYPTED_ENV` unset, it must find the plain text strings.
Closes https://github.com/facebook/rocksdb/pull/2424
Differential Revision: D5322178
Pulled By: sdwilsh
fbshipit-source-id: 253b0a9c2c498cc98f580df7f2623cbf7678a27f/Implement ReopenWritibaleFile on Windows and other fixes
Summary:
Make default impl return NoSupported so the db_blob
tests exist in a meaningful manner.
Replace std::thread to port::Thread
Closes https://github.com/facebook/rocksdb/pull/2465
Differential Revision: D5275563
Pulled By: yiwu-arbug
fbshipit-source-id: cedf1a18a2c05e20d768c1308b3f3224dbd70ab6/Allow SstFileWriter to use the rate limiter
Summary:
The default IO priority of WritableFiles is IO_TOTAL, meaning that
they will bypass the rate limiter if it's passed in the options.
This change allows to pass an io priority in construction, so that by
setting IO_LOW or IO_HIGH the rate limit will be honored.
It also fixes a minor bug: SstFileWriter's copy and move constructor
are not disabled and incorrect, as any copy/move will result in a
double free. Switching to unique_ptr makes the object correctly
movable and non-copyable as expected.
Also fix minor style inconsistencies.
Closes https://github.com/facebook/rocksdb/pull/2335
Differential Revision: D5113260
Pulled By: sagar0
fbshipit-source-id: e084236e7ff0b50a56cbeceaa9fedd5e210bf9f8/Fixed some spelling mistakes
Summary: Closes https://github.com/facebook/rocksdb/pull/2314
Differential Revision: D5079601
Pulled By: sagar0
fbshipit-source-id: ae5696fd735718f544435c64c3179c49b8c04349/"
rocksdb,"Replace deprecated RocksDB#addFile with RocksDB#ingestExternalFile
Summary:
Previously the Java implementation of `RocksDB#addFile` was both incomplete and not inline with the C++ API.
Rather than fix it, as I see that `rocksdb::DB::AddFile` is now deprecated in favour of `rocksdb::DB::IngestExternalFile`, I have removed the old broken implementation and implemented `RocksDB#ingestExternalFile`.
Closes https://github.com/facebook/rocksdb/issues/2261
Closes https://github.com/facebook/rocksdb/pull/2291
Differential Revision: D5061264
Pulled By: sagar0
fbshipit-source-id: 85df0899fa1b1fc3535175cac4f52353511d4104/"
rocksdb,"Fix warnings while generating RocksJava documentation
Summary:
There are a couple of warnings while building RocksJava, coming from Javadoc generation.
```
Generating target/apidocs/org/rocksdb/RocksDB.html...
src/main/java/org/rocksdb/RocksDB.java:2139: warning: no throws for org.rocksdb.RocksDBException
public void ingestExternalFile(final List<String> filePathList,
^
src/main/java/org/rocksdb/RocksDB.java:2162: warning: no throws for org.rocksdb.RocksDBException
public void ingestExternalFile(final ColumnFamilyHandle columnFamilyHandle,
^
```
Closes https://github.com/facebook/rocksdb/pull/2396
Differential Revision: D5178388
Pulled By: sagar0
fbshipit-source-id: a0ab6696d6de78d089a9a860a559f64cc320019e/Replace deprecated RocksDB#addFile with RocksDB#ingestExternalFile
Summary:
Previously the Java implementation of `RocksDB#addFile` was both incomplete and not inline with the C++ API.
Rather than fix it, as I see that `rocksdb::DB::AddFile` is now deprecated in favour of `rocksdb::DB::IngestExternalFile`, I have removed the old broken implementation and implemented `RocksDB#ingestExternalFile`.
Closes https://github.com/facebook/rocksdb/issues/2261
Closes https://github.com/facebook/rocksdb/pull/2291
Differential Revision: D5061264
Pulled By: sagar0
fbshipit-source-id: 85df0899fa1b1fc3535175cac4f52353511d4104/"
rocksdb,"fixed typo
Summary:
fixed typo
Closes https://github.com/facebook/rocksdb/pull/2376
Differential Revision: D5183630
Pulled By: ajkr
fbshipit-source-id: 133cfd0445959e70aa2cd1a12151bf3c0c5c3ac5/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/remove unnecessary fadvise
Summary:
We has to remove this line because previously it is only called when use_os_buffer = false. But now we have direct io to replace it.
Closes https://github.com/facebook/rocksdb/pull/2573
Differential Revision: D5412824
Pulled By: yiwu-arbug
fbshipit-source-id: 81f3f0cdf94566bfc09ef2ff123e40cddbe36b36/Improve the error message for I/O related errors.
Summary:
Force people to write something other than file name while returning status for IOError.
Closes https://github.com/facebook/rocksdb/pull/2493
Differential Revision: D5321309
Pulled By: siying
fbshipit-source-id: 38bcf6c19e80831cd3e300a047e975cbb131d822/Fix crash in PosixWritableFile::Close() when fstat() fails
Summary:
We had a crash in this code: `fstat()` failed; `file_stats` contained garbage, in particular `file_stats.st_blksize == 6`; the expression `file_stats.st_blocks / (file_stats.st_blksize / 512)` divided by zero.
Closes https://github.com/facebook/rocksdb/pull/2420
Differential Revision: D5216110
Pulled By: al13n321
fbshipit-source-id: 6d8fc5e7c4f98c1139e68c7829ebdbac68b0fce0/Fix clang errors by asserting the precondition
Summary:
USE_CLANG=1 make -j32 analyze
The two errors would disappear after the assertion.
Closes https://github.com/facebook/rocksdb/pull/2416
Differential Revision: D5193526
Pulled By: maysamyabandeh
fbshipit-source-id: 16a21f18f68023f862764dd3ab9e00ca60b0eefa/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"Replace dynamic_cast<>
Summary:
Replace dynamic_cast<> so that users can choose to build with RTTI off, so that they can save several bytes per object, and get tiny more memory available.
Some nontrivial changes:
1. Add Comparator::GetRootComparator() to get around the internal comparator hack
2. Add the two experiemental functions to DB
3. Add TableFactory::GetOptionString() to avoid unnecessary casting to get the option string
4. Since 3 is done, move the parsing option functions for table factory to table factory files too, to be symmetric.
Closes https://github.com/facebook/rocksdb/pull/2645
Differential Revision: D5502723
Pulled By: siying
fbshipit-source-id: fd13cec5601cf68a554d87bfcf056f2ffa5fbf7c/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Fix GetCurrentTime() initialization for valgrind
Summary:
Valgrind had false positive complaints about the initialization pattern for `GetCurrentTime()`'s argument in #2480. We can instead have the client initialize the time variable before calling `GetCurrentTime()`, and have `GetCurrentTime()` promise to only overwrite it in success case.
Closes https://github.com/facebook/rocksdb/pull/2526
Differential Revision: D5358689
Pulled By: ajkr
fbshipit-source-id: 857b189f24c19196f6bb299216f3e23e7bc4be42/GNU C library for struct tm has 2 additional fields.
Summary:
initialize 2 additional fields tm_gmtoff and tm_zone,
otherwise under strict warnings for initialization, we get errors
in myrocks.
Closes https://github.com/facebook/rocksdb/pull/2439
Differential Revision: D5229013
Pulled By: yiwu-arbug
fbshipit-source-id: 9fc1615a1919656f36064791706ed41e10e9db84/Fix mock_env.cc uninitialized variable
Summary:
Mingw is complaining about uninitialized variable in mock_env.cc. e.g. https://travis-ci.org/facebook/rocksdb/jobs/240132276
The fix is to initialize the variable.
Closes https://github.com/facebook/rocksdb/pull/2428
Differential Revision: D5211306
Pulled By: yiwu-arbug
fbshipit-source-id: ee02bf0327dcea8590a2aa087f0176fecaf8621c/fix travis error with init time in mockenv
Summary:
/home/travis/build/facebook/rocksdb/env/mock_env.cc: In member function virtual void rocksdb::{anonymous}::TestMemLogger::Logv(const char*, va_list):
/home/travis/build/facebook/rocksdb/env/mock_env.cc:391:53: error: t.tm::tm_year may be used uninitialized in this function [-Werror=maybe-uninitialized]
static_cast<int>(now_tv.tv_usec));
Closes https://github.com/facebook/rocksdb/pull/2418
Differential Revision: D5193597
Pulled By: maysamyabandeh
fbshipit-source-id: 8801a3ef27f33eb419d534f7de747702cdf504a0/"
rocksdb,"Replace dynamic_cast<>
Summary:
Replace dynamic_cast<> so that users can choose to build with RTTI off, so that they can save several bytes per object, and get tiny more memory available.
Some nontrivial changes:
1. Add Comparator::GetRootComparator() to get around the internal comparator hack
2. Add the two experiemental functions to DB
3. Add TableFactory::GetOptionString() to avoid unnecessary casting to get the option string
4. Since 3 is done, move the parsing option functions for table factory to table factory files too, to be symmetric.
Closes https://github.com/facebook/rocksdb/pull/2645
Differential Revision: D5502723
Pulled By: siying
fbshipit-source-id: fd13cec5601cf68a554d87bfcf056f2ffa5fbf7c/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Downgrade option sanitiy check level for prefix_extractor
Summary:
With c7004840d2f4ad5fc1bdce042902b822492f3a0e, it's safe to open a DB with different prefix extractor. So it's safe to skip prefix extractor check.
Closes https://github.com/facebook/rocksdb/pull/2474
Differential Revision: D5294700
Pulled By: siying
fbshipit-source-id: eeb500da795eecb29b8c9c56a14cfd4afda12ecc/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/CodeMod: Prefer ADD_FAILURE() over EXPECT_TRUE(false), et cetera
Summary:
CodeMod: Prefer `ADD_FAILURE()` over `EXPECT_TRUE(false)`, et cetera.
The tautologically-conditioned and tautologically-contradicted boolean expectations/assertions have better alternatives: unconditional passes and failures.
Reviewed By: Orvid
Differential Revision:
D5432398
Tags: codemod, codemod-opensource
fbshipit-source-id: d16b447e8696a6feaa94b41199f5052226ef6914/Fix GetCurrentTime() initialization for valgrind
Summary:
Valgrind had false positive complaints about the initialization pattern for `GetCurrentTime()`'s argument in #2480. We can instead have the client initialize the time variable before calling `GetCurrentTime()`, and have `GetCurrentTime()` promise to only overwrite it in success case.
Closes https://github.com/facebook/rocksdb/pull/2526
Differential Revision: D5358689
Pulled By: ajkr
fbshipit-source-id: 857b189f24c19196f6bb299216f3e23e7bc4be42/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/CodeMod: Prefer ADD_FAILURE() over EXPECT_TRUE(false), et cetera
Summary:
CodeMod: Prefer `ADD_FAILURE()` over `EXPECT_TRUE(false)`, et cetera.
The tautologically-conditioned and tautologically-contradicted boolean expectations/assertions have better alternatives: unconditional passes and failures.
Reviewed By: Orvid
Differential Revision:
D5432398
Tags: codemod, codemod-opensource
fbshipit-source-id: d16b447e8696a6feaa94b41199f5052226ef6914/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/fixed typo
Summary:
fixed typo
Closes https://github.com/facebook/rocksdb/pull/2376
Differential Revision: D5183630
Pulled By: ajkr
fbshipit-source-id: 133cfd0445959e70aa2cd1a12151bf3c0c5c3ac5/"
rocksdb,"Replace dynamic_cast<>
Summary:
Replace dynamic_cast<> so that users can choose to build with RTTI off, so that they can save several bytes per object, and get tiny more memory available.
Some nontrivial changes:
1. Add Comparator::GetRootComparator() to get around the internal comparator hack
2. Add the two experiemental functions to DB
3. Add TableFactory::GetOptionString() to avoid unnecessary casting to get the option string
4. Since 3 is done, move the parsing option functions for table factory to table factory files too, to be symmetric.
Closes https://github.com/facebook/rocksdb/pull/2645
Differential Revision: D5502723
Pulled By: siying
fbshipit-source-id: fd13cec5601cf68a554d87bfcf056f2ffa5fbf7c/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"Fix blob DB transaction usage while GC
Summary:
While GC, blob DB use optimistic transaction to delete or replace the index entry in LSM, to guarantee correctness if there's a normal write writing to the same key. However, the previous implementation doesn't call SetSnapshot() nor use GetForUpdate() of transaction API, instead it do its own sequence number checking before beginning the transaction. A normal write can sneak in after the sequence number check and overwrite the key, and the GC will delete or relocate the old version of the key by mistake. Update the code to property use GetForUpdate() to check the existing index entry.
After the patch the sequence number store with each blob record is useless, So I'm considering remove the sequence number from blob record, in another patch.
Closes https://github.com/facebook/rocksdb/pull/2703
Differential Revision: D5589178
Pulled By: yiwu-arbug
fbshipit-source-id: 8dc960cd5f4e61b36024ba7c32d05584ce149c24/Update all blob db TTL and timestamps to uint64_t
Summary:
The current blob db implementation use mix of int32_t, uint32_t and uint64_t for TTL and expiration. Update all timestamps to uint64_t for consistency.
Closes https://github.com/facebook/rocksdb/pull/2683
Differential Revision: D5557103
Pulled By: yiwu-arbug
fbshipit-source-id: e4eab2691629a755e614e8cf1eed9c3a681d0c42/Allow concurrent writes to blob db
Summary:
I'm going with brute-force solution, just letting Put() and Write() holding a mutex before writing. May improve concurrent writing with finer granularity locking later.
Closes https://github.com/facebook/rocksdb/pull/2682
Differential Revision: D5552690
Pulled By: yiwu-arbug
fbshipit-source-id: 039abd675b5d274a7af6428198d1733cafecef4c/Blob DB garbage collection should keep keys with newer version
Summary:
Fix the bug where if blob db garbage collection revmoe keys with newer version. It shouldn't delete the key from base db when sequence number in base db is not equal to the one in blob log.
Closes https://github.com/facebook/rocksdb/pull/2678
Differential Revision: D5549752
Pulled By: yiwu-arbug
fbshipit-source-id: abb8649260963b5c389748023970fd746279d227/Dump Blob DB options to info log
Summary:
* Dump blob db options to info log
* Remove BlobDBOptionsImpl to disallow dynamic cast *BlobDBOptions into *BlobDBOptionsImpl. Move options there to be constants or into BlobDBOptions. The dynamic cast is broken after #2645
* Change some of the default options
* Remove blob_db_options.min_blob_size, which is unimplemented. Will implement it soon.
Closes https://github.com/facebook/rocksdb/pull/2671
Differential Revision: D5529912
Pulled By: yiwu-arbug
fbshipit-source-id: dcd58ca981db5bcc7f123b65a0d6f6ae0dc703c7/Blob DB TTL extractor
Summary:
Introducing blob_db::TTLExtractor to replace extract_ttl_fn. The TTL
extractor can be use to extract TTL from keys insert with Put or
WriteBatch. Change over existing extract_ttl_fn are:
* If value is changed, it will be return via std::string* (rather than Slice*). With Slice* the new value has to be part of the existing value. With std::string* the limitation is removed.
* It can optionally return TTL or expiration.
Other changes in this PR:
* replace `std::chrono::system_clock` with `Env::NowMicros` so that I can mock time in tests.
* add several TTL tests.
* other minor naming change.
Closes https://github.com/facebook/rocksdb/pull/2659
Differential Revision: D5512627
Pulled By: yiwu-arbug
fbshipit-source-id: 0dfcb00d74d060b8534c6130c808e4d5d0a54440/Fix BlobDB::Get which only get out the value offset
Summary:
Blob db use StackableDB::get which only get out the
value offset, but not the value.
Fix by making BlobDB::Get override the designated getter.
Closes https://github.com/facebook/rocksdb/pull/2553
Differential Revision: D5396823
Pulled By: yiwu-arbug
fbshipit-source-id: 5a7d1cf77ee44490f836a6537225955382296878/Make ""make analyze"" happy
Summary:
""make analyze"" is reporting some errors. It's complicated to look but it seems to me that they are all false positive. Anyway, I think cleaning them up is a good idea. Some of the changes are hacky but I don't know a better way.
Closes https://github.com/facebook/rocksdb/pull/2508
Differential Revision: D5341710
Pulled By: siying
fbshipit-source-id: 6070e430e0e41a080ef441e05e8ec827d45efab6/Implement ReopenWritibaleFile on Windows and other fixes
Summary:
Make default impl return NoSupported so the db_blob
tests exist in a meaningful manner.
Replace std::thread to port::Thread
Closes https://github.com/facebook/rocksdb/pull/2465
Differential Revision: D5275563
Pulled By: yiwu-arbug
fbshipit-source-id: cedf1a18a2c05e20d768c1308b3f3224dbd70ab6/Fix blob db compression bug
Summary:
`CompressBlock()` will return the uncompressed slice (i.e. `Slice(value_unc)`) if compression ratio is not good enough. This is undesired. We need to always assign the compressed slice to `value`.
Closes https://github.com/facebook/rocksdb/pull/2447
Differential Revision: D5244682
Pulled By: yiwu-arbug
fbshipit-source-id: 6989dd8852c9622822ba9acec9beea02007dff09/Update blob_db_test
Summary:
I'm trying to improve unit test of blob db. I'm rewriting blob db test. In this patch:
* Rewrite tests of basic put/write/delete operations.
* Add disable_background_tasks to BlobDBOptionsImpl to allow me not running any background job for basic unit tests.
* Move DestroyBlobDB out from BlobDBImpl to be a standalone function.
* Remove all garbage collection related tests. Will rewrite them in following patch.
* Disabled compression test since it is failing. Will fix in a followup patch.
Closes https://github.com/facebook/rocksdb/pull/2446
Differential Revision: D5243306
Pulled By: yiwu-arbug
fbshipit-source-id: 157c71ad3b699307cb88baa3830e9b6e74f8e939/write exact sequence number for each put in write batch
Summary:
At the beginning of write batch write, grab the latest sequence from base db and assume sequence number will increment by 1 for each put and delete, and write the exact sequence number with each put. This is assuming we are the only writer to increment sequence number (no external file ingestion, etc) and there should be no holes in the sequence number.
Also having some minor naming changes.
Closes https://github.com/facebook/rocksdb/pull/2402
Differential Revision: D5176134
Pulled By: yiwu-arbug
fbshipit-source-id: cb4712ee44478d5a2e5951213a10b72f08fe8c88/Fixing blob db sequence number handling
Summary:
Blob db rely on base db returning sequence number through write batch after DB::Write(). However after recent changes to the write path, DB::Writ()e no longer return sequence number in some cases. Fixing it by have WriteBatchInternal::InsertInto() always encode sequence number into write batch.
Stacking on #2375.
Closes https://github.com/facebook/rocksdb/pull/2385
Differential Revision: D5148358
Pulled By: yiwu-arbug
fbshipit-source-id: 8bda0aa07b9334ed03ed381548b39d167dc20c33/update blob_db_test
Summary:
Re-enable blob_db_test with some update:
* Commented out delay at the end of GC tests. Will update the logic later with sync point to properly trigger GC.
* Added some helper functions.
Also update make files to include blob_dump tool.
Closes https://github.com/facebook/rocksdb/pull/2375
Differential Revision: D5133793
Pulled By: yiwu-arbug
fbshipit-source-id: 95470b26d0c1f9592ba4b7637e027fdd263f425c/"
rocksdb,"Fix blob DB transaction usage while GC
Summary:
While GC, blob DB use optimistic transaction to delete or replace the index entry in LSM, to guarantee correctness if there's a normal write writing to the same key. However, the previous implementation doesn't call SetSnapshot() nor use GetForUpdate() of transaction API, instead it do its own sequence number checking before beginning the transaction. A normal write can sneak in after the sequence number check and overwrite the key, and the GC will delete or relocate the old version of the key by mistake. Update the code to property use GetForUpdate() to check the existing index entry.
After the patch the sequence number store with each blob record is useless, So I'm considering remove the sequence number from blob record, in another patch.
Closes https://github.com/facebook/rocksdb/pull/2703
Differential Revision: D5589178
Pulled By: yiwu-arbug
fbshipit-source-id: 8dc960cd5f4e61b36024ba7c32d05584ce149c24/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Simple blob file dumper
Summary:
A simple blob file dumper.
Closes https://github.com/facebook/rocksdb/pull/2242
Differential Revision: D5097553
Pulled By: yiwu-arbug
fbshipit-source-id: c6e00d949fcd3658f9f68da9352f06339fac418d/"
rocksdb,"Fix blob DB transaction usage while GC
Summary:
While GC, blob DB use optimistic transaction to delete or replace the index entry in LSM, to guarantee correctness if there's a normal write writing to the same key. However, the previous implementation doesn't call SetSnapshot() nor use GetForUpdate() of transaction API, instead it do its own sequence number checking before beginning the transaction. A normal write can sneak in after the sequence number check and overwrite the key, and the GC will delete or relocate the old version of the key by mistake. Update the code to property use GetForUpdate() to check the existing index entry.
After the patch the sequence number store with each blob record is useless, So I'm considering remove the sequence number from blob record, in another patch.
Closes https://github.com/facebook/rocksdb/pull/2703
Differential Revision: D5589178
Pulled By: yiwu-arbug
fbshipit-source-id: 8dc960cd5f4e61b36024ba7c32d05584ce149c24/Avoid blob db call Sync() while writing
Summary:
The FsyncFiles background job call Fsync() periodically for blob files. However it can access WritableFileWriter concurrently with a Put() or Write(). And WritableFileWriter does not support concurrent access. It will lead to WritableFileWriter buffer being flush with same content twice, and blob file end up corrupted. Fixing by simply let FsyncFiles hold write_mutex_.
Closes https://github.com/facebook/rocksdb/pull/2685
Differential Revision: D5561908
Pulled By: yiwu-arbug
fbshipit-source-id: f0bb5bcab0e05694e053b8c49eab43640721e872/Update all blob db TTL and timestamps to uint64_t
Summary:
The current blob db implementation use mix of int32_t, uint32_t and uint64_t for TTL and expiration. Update all timestamps to uint64_t for consistency.
Closes https://github.com/facebook/rocksdb/pull/2683
Differential Revision: D5557103
Pulled By: yiwu-arbug
fbshipit-source-id: e4eab2691629a755e614e8cf1eed9c3a681d0c42/Allow concurrent writes to blob db
Summary:
I'm going with brute-force solution, just letting Put() and Write() holding a mutex before writing. May improve concurrent writing with finer granularity locking later.
Closes https://github.com/facebook/rocksdb/pull/2682
Differential Revision: D5552690
Pulled By: yiwu-arbug
fbshipit-source-id: 039abd675b5d274a7af6428198d1733cafecef4c/Blob DB garbage collection should keep keys with newer version
Summary:
Fix the bug where if blob db garbage collection revmoe keys with newer version. It shouldn't delete the key from base db when sequence number in base db is not equal to the one in blob log.
Closes https://github.com/facebook/rocksdb/pull/2678
Differential Revision: D5549752
Pulled By: yiwu-arbug
fbshipit-source-id: abb8649260963b5c389748023970fd746279d227/Dump Blob DB options to info log
Summary:
* Dump blob db options to info log
* Remove BlobDBOptionsImpl to disallow dynamic cast *BlobDBOptions into *BlobDBOptionsImpl. Move options there to be constants or into BlobDBOptions. The dynamic cast is broken after #2645
* Change some of the default options
* Remove blob_db_options.min_blob_size, which is unimplemented. Will implement it soon.
Closes https://github.com/facebook/rocksdb/pull/2671
Differential Revision: D5529912
Pulled By: yiwu-arbug
fbshipit-source-id: dcd58ca981db5bcc7f123b65a0d6f6ae0dc703c7/Replace dynamic_cast<>
Summary:
Replace dynamic_cast<> so that users can choose to build with RTTI off, so that they can save several bytes per object, and get tiny more memory available.
Some nontrivial changes:
1. Add Comparator::GetRootComparator() to get around the internal comparator hack
2. Add the two experiemental functions to DB
3. Add TableFactory::GetOptionString() to avoid unnecessary casting to get the option string
4. Since 3 is done, move the parsing option functions for table factory to table factory files too, to be symmetric.
Closes https://github.com/facebook/rocksdb/pull/2645
Differential Revision: D5502723
Pulled By: siying
fbshipit-source-id: fd13cec5601cf68a554d87bfcf056f2ffa5fbf7c/Blob DB TTL extractor
Summary:
Introducing blob_db::TTLExtractor to replace extract_ttl_fn. The TTL
extractor can be use to extract TTL from keys insert with Put or
WriteBatch. Change over existing extract_ttl_fn are:
* If value is changed, it will be return via std::string* (rather than Slice*). With Slice* the new value has to be part of the existing value. With std::string* the limitation is removed.
* It can optionally return TTL or expiration.
Other changes in this PR:
* replace `std::chrono::system_clock` with `Env::NowMicros` so that I can mock time in tests.
* add several TTL tests.
* other minor naming change.
Closes https://github.com/facebook/rocksdb/pull/2659
Differential Revision: D5512627
Pulled By: yiwu-arbug
fbshipit-source-id: 0dfcb00d74d060b8534c6130c808e4d5d0a54440/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Reduce blob db noisy logging
Summary:
Remove some of the per-key logging by blob db to reduce noise.
Closes https://github.com/facebook/rocksdb/pull/2587
Differential Revision: D5429115
Pulled By: yiwu-arbug
fbshipit-source-id: b89328282fb8b3c64923ce48738c16017ce7feaf/Update blob db to use ROCKS_LOG_* macro
Summary:
Update blob db to use the newer ROCKS_LOG_* macro.
Closes https://github.com/facebook/rocksdb/pull/2574
Differential Revision: D5414526
Pulled By: yiwu-arbug
fbshipit-source-id: e428753aa5917e8b435cead2db26df586e5d1def/Fix BlobDB::Get which only get out the value offset
Summary:
Blob db use StackableDB::get which only get out the
value offset, but not the value.
Fix by making BlobDB::Get override the designated getter.
Closes https://github.com/facebook/rocksdb/pull/2553
Differential Revision: D5396823
Pulled By: yiwu-arbug
fbshipit-source-id: 5a7d1cf77ee44490f836a6537225955382296878/Make ""make analyze"" happy
Summary:
""make analyze"" is reporting some errors. It's complicated to look but it seems to me that they are all false positive. Anyway, I think cleaning them up is a good idea. Some of the changes are hacky but I don't know a better way.
Closes https://github.com/facebook/rocksdb/pull/2508
Differential Revision: D5341710
Pulled By: siying
fbshipit-source-id: 6070e430e0e41a080ef441e05e8ec827d45efab6/Fix blob db compression bug
Summary:
`CompressBlock()` will return the uncompressed slice (i.e. `Slice(value_unc)`) if compression ratio is not good enough. This is undesired. We need to always assign the compressed slice to `value`.
Closes https://github.com/facebook/rocksdb/pull/2447
Differential Revision: D5244682
Pulled By: yiwu-arbug
fbshipit-source-id: 6989dd8852c9622822ba9acec9beea02007dff09/Update blob_db_test
Summary:
I'm trying to improve unit test of blob db. I'm rewriting blob db test. In this patch:
* Rewrite tests of basic put/write/delete operations.
* Add disable_background_tasks to BlobDBOptionsImpl to allow me not running any background job for basic unit tests.
* Move DestroyBlobDB out from BlobDBImpl to be a standalone function.
* Remove all garbage collection related tests. Will rewrite them in following patch.
* Disabled compression test since it is failing. Will fix in a followup patch.
Closes https://github.com/facebook/rocksdb/pull/2446
Differential Revision: D5243306
Pulled By: yiwu-arbug
fbshipit-source-id: 157c71ad3b699307cb88baa3830e9b6e74f8e939/write exact sequence number for each put in write batch
Summary:
At the beginning of write batch write, grab the latest sequence from base db and assume sequence number will increment by 1 for each put and delete, and write the exact sequence number with each put. This is assuming we are the only writer to increment sequence number (no external file ingestion, etc) and there should be no holes in the sequence number.
Also having some minor naming changes.
Closes https://github.com/facebook/rocksdb/pull/2402
Differential Revision: D5176134
Pulled By: yiwu-arbug
fbshipit-source-id: cb4712ee44478d5a2e5951213a10b72f08fe8c88/Fix clang errors by asserting the precondition
Summary:
USE_CLANG=1 make -j32 analyze
The two errors would disappear after the assertion.
Closes https://github.com/facebook/rocksdb/pull/2416
Differential Revision: D5193526
Pulled By: maysamyabandeh
fbshipit-source-id: 16a21f18f68023f862764dd3ab9e00ca60b0eefa/Fixing blob db sequence number handling
Summary:
Blob db rely on base db returning sequence number through write batch after DB::Write(). However after recent changes to the write path, DB::Writ()e no longer return sequence number in some cases. Fixing it by have WriteBatchInternal::InsertInto() always encode sequence number into write batch.
Stacking on #2375.
Closes https://github.com/facebook/rocksdb/pull/2385
Differential Revision: D5148358
Pulled By: yiwu-arbug
fbshipit-source-id: 8bda0aa07b9334ed03ed381548b39d167dc20c33/"
rocksdb,"Improve Status message for block checksum mismatches
Summary:
We've got some DBs where iterators return Status with message ""Corruption: block checksum mismatch"" all the time. That's not very informative. It would be much easier to investigate if the error message contained the file name - then we would know e.g. how old the corrupted file is, which would be very useful for finding the root cause. This PR adds file name, offset and other stuff to some block corruption-related status messages.
It doesn't improve all the error messages, just a few that were easy to improve. I'm mostly interested in ""block checksum mismatch"" and ""Bad table magic number"" since they're the only corruption errors that I've ever seen in the wild.
Closes https://github.com/facebook/rocksdb/pull/2507
Differential Revision: D5345702
Pulled By: al13n321
fbshipit-source-id: fc8023d43f1935ad927cef1b9c55481ab3cb1339/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Gcc 7 ignored quantifiers
Summary:
The casting seemed to cause a problem.
I think this might increase it to unsigned long.
Closes https://github.com/facebook/rocksdb/pull/2562
Differential Revision: D5406842
Pulled By: siying
fbshipit-source-id: 736adef31448229a58a1a48bdbe77792f36736e8/Fix clang error in PartitionedFilterBlockBuilder
Summary: Closes https://github.com/facebook/rocksdb/pull/2536
Differential Revision: D5371271
Pulled By: maysamyabandeh
fbshipit-source-id: f1355ac658a79c9982a24986f0925c9e24fc39d5/FIFO Compaction with TTL
Summary:
Introducing FIFO compactions with TTL.
FIFO compaction is based on size only which makes it tricky to enable in production as use cases can have organic growth. A user requested an option to drop files based on the time of their creation instead of the total size.
To address that request:
- Added a new TTL option to FIFO compaction options.
- Updated FIFO compaction score to take TTL into consideration.
- Added a new table property, creation_time, to keep track of when the SST file is created.
- Creation_time is set as below:
- On Flush: Set to the time of flush.
- On Compaction: Set to the max creation_time of all the files involved in the compaction.
- On Repair and Recovery: Set to the time of repair/recovery.
- Old files created prior to this code change will have a creation_time of 0.
- FIFO compaction with TTL is enabled when ttl > 0. All files older than ttl will be deleted during compaction. i.e. `if (file.creation_time < (current_time - ttl)) then delete(file)`. This will enable cases where you might want to delete all files older than, say, 1 day.
- FIFO compaction will fall back to the prior way of deleting files based on size if:
- the creation_time of all files involved in compaction is 0.
- the total size (of all SST files combined) does not drop below `compaction_options_fifo.max_table_files_size` even if the files older than ttl are deleted.
This feature is not supported if max_open_files != -1 or with table formats other than Block-based.
**Test Plan:**
Added tests.
**Benchmark results:**
Base: FIFO with max size: 100MB ::
```
svemuri@dev15905 ~/rocksdb (fifo-compaction) $ TEST_TMPDIR=/dev/shm ./db_bench --benchmarks=readwhilewriting --num=5000000 --threads=16 --compaction_style=2 --fifo_compaction_max_table_files_size_mb=100
readwhilewriting :       1.924 micros/op 519858 ops/sec;   13.6 MB/s (1176277 of 5000000 found)
```
With TTL (a low one for testing) ::
```
svemuri@dev15905 ~/rocksdb (fifo-compaction) $ TEST_TMPDIR=/dev/shm ./db_bench --benchmarks=readwhilewriting --num=5000000 --threads=16 --compaction_style=2 --fifo_compaction_max_table_files_size_mb=100 --fifo_compaction_ttl=20
readwhilewriting :       1.902 micros/op 525817 ops/sec;   13.7 MB/s (1185057 of 5000000 found)
```
Example Log lines:
```
2017/06/26-15:17:24.609249 7fd5a45ff700 (Original Log Time 2017/06/26-15:17:24.609177) [db/compaction_picker.cc:1471] [default] FIFO compaction: picking file 40 with creation time 1498515423 for deletion
2017/06/26-15:17:24.609255 7fd5a45ff700 (Original Log Time 2017/06/26-15:17:24.609234) [db/db_impl_compaction_flush.cc:1541] [default] Deleted 1 files
...
2017/06/26-15:17:25.553185 7fd5a61a5800 [DEBUG] [db/db_impl_files.cc:309] [JOB 0] Delete /dev/shm/dbbench/000040.sst type=2 #40 -- OK
2017/06/26-15:17:25.553205 7fd5a61a5800 EVENT_LOG_v1 {""time_micros"": 1498515445553199, ""job"": 0, ""event"": ""table_file_deletion"", ""file_number"": 40}
```
SST Files remaining in the dbbench dir, after db_bench execution completed:
```
svemuri@dev15905 ~/rocksdb (fifo-compaction)  $ ls -l /dev/shm//dbbench/*.sst
-rw-r--r--. 1 svemuri users 30749887 Jun 26 15:17 /dev/shm//dbbench/000042.sst
-rw-r--r--. 1 svemuri users 30768779 Jun 26 15:17 /dev/shm//dbbench/000044.sst
-rw-r--r--. 1 svemuri users 30757481 Jun 26 15:17 /dev/shm//dbbench/000046.sst
```
Closes https://github.com/facebook/rocksdb/pull/2480
Differential Revision: D5305116
Pulled By: sagar0
fbshipit-source-id: 3e5cfcf5dd07ed2211b5b37492eb235b45139174/Unit Tests for sync, range sync and file close failures
Summary: Closes https://github.com/facebook/rocksdb/pull/2454
Differential Revision: D5255320
Pulled By: siying
fbshipit-source-id: 0080830fa8eb5da6de25e17ba68aee91018c7913/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Improve Status message for block checksum mismatches
Summary:
We've got some DBs where iterators return Status with message ""Corruption: block checksum mismatch"" all the time. That's not very informative. It would be much easier to investigate if the error message contained the file name - then we would know e.g. how old the corrupted file is, which would be very useful for finding the root cause. This PR adds file name, offset and other stuff to some block corruption-related status messages.
It doesn't improve all the error messages, just a few that were easy to improve. I'm mostly interested in ""block checksum mismatch"" and ""Bad table magic number"" since they're the only corruption errors that I've ever seen in the wild.
Closes https://github.com/facebook/rocksdb/pull/2507
Differential Revision: D5345702
Pulled By: al13n321
fbshipit-source-id: fc8023d43f1935ad927cef1b9c55481ab3cb1339/Fixed some spelling mistakes
Summary: Closes https://github.com/facebook/rocksdb/pull/2314
Differential Revision: D5079601
Pulled By: sagar0
fbshipit-source-id: ae5696fd735718f544435c64c3179c49b8c04349/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/CodeMod: Prefer ADD_FAILURE() over EXPECT_TRUE(false), et cetera
Summary:
CodeMod: Prefer `ADD_FAILURE()` over `EXPECT_TRUE(false)`, et cetera.
The tautologically-conditioned and tautologically-contradicted boolean expectations/assertions have better alternatives: unconditional passes and failures.
Reviewed By: Orvid
Differential Revision:
D5432398
Tags: codemod, codemod-opensource
fbshipit-source-id: d16b447e8696a6feaa94b41199f5052226ef6914/"
rocksdb,"Support prefetch last 512KB with direct I/O in block based file reader
Summary:
Right now, if direct I/O is enabled, prefetching the last 512KB cannot be applied, except compaction inputs or readahead is enabled for iterators. This can create a lot of I/O for HDD cases. To solve the problem, the 512KB is prefetched in block based table if direct I/O is enabled. The prefetched buffer is passed in totegher with random access file reader, so that we try to read from the buffer before reading from the file. This can be extended in the future to support flexible user iterator readahead too.
Closes https://github.com/facebook/rocksdb/pull/2708
Differential Revision: D5593091
Pulled By: siying
fbshipit-source-id: ee36ff6d8af11c312a2622272b21957a7b5c81e7/add VerifyChecksum() to db.h
Summary:
We need a tool to check any sst file corruption in the db.
It will check all the sst files in current version and read all the blocks (data, meta, index) with checksum verification. If any verification fails, the function will return non-OK status.
Closes https://github.com/facebook/rocksdb/pull/2498
Differential Revision: D5324269
Pulled By: lightmark
fbshipit-source-id: 6f8a272008b722402a772acfc804524c9d1a483b/fix asan/valgrind for TableCache cleanup
Summary:
Breaking commit: d12691b86fb788f0ee7180db626c4ea2445fa976
In the above commit, I moved the `TableCache` cleanup logic from `Version` destructor into `PurgeObsoleteFiles`. I missed cleaning up `TableCache` entries for the current `Version` during DB destruction.
This PR adds that logic to `VersionSet` destructor. One unfortunate side effect is now we're potentially deleting `TableReader`s after `column_family_set_.reset()`, which means we can't call `BlockBasedTableReader::Close` a second time as the block cache might already be destroyed.
Closes https://github.com/facebook/rocksdb/pull/2662
Differential Revision: D5515108
Pulled By: ajkr
fbshipit-source-id: 2cb820e19aa813e0d258d17f76b2d7b6b7ee0b18/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/fixed typo
Summary:
fixed typo
Closes https://github.com/facebook/rocksdb/pull/2312
Differential Revision: D5079631
Pulled By: sagar0
fbshipit-source-id: e4c8d1d89b244ee69e9dea1dd013227cc5241026/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"Support prefetch last 512KB with direct I/O in block based file reader
Summary:
Right now, if direct I/O is enabled, prefetching the last 512KB cannot be applied, except compaction inputs or readahead is enabled for iterators. This can create a lot of I/O for HDD cases. To solve the problem, the 512KB is prefetched in block based table if direct I/O is enabled. The prefetched buffer is passed in totegher with random access file reader, so that we try to read from the buffer before reading from the file. This can be extended in the future to support flexible user iterator readahead too.
Closes https://github.com/facebook/rocksdb/pull/2708
Differential Revision: D5593091
Pulled By: siying
fbshipit-source-id: ee36ff6d8af11c312a2622272b21957a7b5c81e7/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Fix interaction between CompactionFilter::Decision::kRemoveAndSkipUnt
Summary:
Fixes the following scenario:
1. Set prefix extractor. Enable bloom filters, with `whole_key_filtering = false`. Use compaction filter that sometimes returns `kRemoveAndSkipUntil`.
2. Do a compaction.
3. Compaction creates an iterator with `total_order_seek = false`, calls `SeekToFirst()` on it, then repeatedly calls `Next()`.
4. At some point compaction filter returns `kRemoveAndSkipUntil`.
5. Compaction calls `Seek(skip_until)` on the iterator. The key that it seeks to happens to have prefix that doesn't match the bloom filter. Since `total_order_seek = false`, iterator becomes invalid, and compaction thinks that it has reached the end. The rest of the compaction input is silently discarded.
The fix is to make compaction iterator use `total_order_seek = true`.
The implementation for PlainTable is quite awkward. I've made `kRemoveAndSkipUntil` officially incompatible with PlainTable. If you try to use them together, compaction will fail, and DB will enter read-only mode (`bg_error_`). That's not a very graceful way to communicate a misconfiguration, but the alternatives don't seem worth the implementation time and complexity. To be able to check in advance that `kRemoveAndSkipUntil` is not going to be used with PlainTable, we'd need to extend the interface of either `CompactionFilter` or `InternalIterator`. It seems unlikely that anyone will ever want to use `kRemoveAndSkipUntil` with PlainTable: PlainTable probably has very few users, and `kRemoveAndSkipUntil` has only one user so far: us (logdevice).
Closes https://github.com/facebook/rocksdb/pull/2349
Differential Revision: D5110388
Pulled By: lightmark
fbshipit-source-id: ec29101a99d9dcd97db33923b87f72bce56cc17a/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Fix interaction between CompactionFilter::Decision::kRemoveAndSkipUnt
Summary:
Fixes the following scenario:
1. Set prefix extractor. Enable bloom filters, with `whole_key_filtering = false`. Use compaction filter that sometimes returns `kRemoveAndSkipUntil`.
2. Do a compaction.
3. Compaction creates an iterator with `total_order_seek = false`, calls `SeekToFirst()` on it, then repeatedly calls `Next()`.
4. At some point compaction filter returns `kRemoveAndSkipUntil`.
5. Compaction calls `Seek(skip_until)` on the iterator. The key that it seeks to happens to have prefix that doesn't match the bloom filter. Since `total_order_seek = false`, iterator becomes invalid, and compaction thinks that it has reached the end. The rest of the compaction input is silently discarded.
The fix is to make compaction iterator use `total_order_seek = true`.
The implementation for PlainTable is quite awkward. I've made `kRemoveAndSkipUntil` officially incompatible with PlainTable. If you try to use them together, compaction will fail, and DB will enter read-only mode (`bg_error_`). That's not a very graceful way to communicate a misconfiguration, but the alternatives don't seem worth the implementation time and complexity. To be able to check in advance that `kRemoveAndSkipUntil` is not going to be used with PlainTable, we'd need to extend the interface of either `CompactionFilter` or `InternalIterator`. It seems unlikely that anyone will ever want to use `kRemoveAndSkipUntil` with PlainTable: PlainTable probably has very few users, and `kRemoveAndSkipUntil` has only one user so far: us (logdevice).
Closes https://github.com/facebook/rocksdb/pull/2349
Differential Revision: D5110388
Pulled By: lightmark
fbshipit-source-id: ec29101a99d9dcd97db33923b87f72bce56cc17a/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"Support prefetch last 512KB with direct I/O in block based file reader
Summary:
Right now, if direct I/O is enabled, prefetching the last 512KB cannot be applied, except compaction inputs or readahead is enabled for iterators. This can create a lot of I/O for HDD cases. To solve the problem, the 512KB is prefetched in block based table if direct I/O is enabled. The prefetched buffer is passed in totegher with random access file reader, so that we try to read from the buffer before reading from the file. This can be extended in the future to support flexible user iterator readahead too.
Closes https://github.com/facebook/rocksdb/pull/2708
Differential Revision: D5593091
Pulled By: siying
fbshipit-source-id: ee36ff6d8af11c312a2622272b21957a7b5c81e7/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Gcc 7 ignored quantifiers
Summary:
The casting seemed to cause a problem.
I think this might increase it to unsigned long.
Closes https://github.com/facebook/rocksdb/pull/2562
Differential Revision: D5406842
Pulled By: siying
fbshipit-source-id: 736adef31448229a58a1a48bdbe77792f36736e8/fix asan and valgrind leak report in test
Summary: Closes https://github.com/facebook/rocksdb/pull/2537
Differential Revision: D5371433
Pulled By: maysamyabandeh
fbshipit-source-id: 90d3e8bb1a8576f48b1ddf1bdbba5512b5986ba0/Fix clang error in PartitionedFilterBlockBuilder
Summary: Closes https://github.com/facebook/rocksdb/pull/2536
Differential Revision: D5371271
Pulled By: maysamyabandeh
fbshipit-source-id: f1355ac658a79c9982a24986f0925c9e24fc39d5/"
rocksdb,"Replace dynamic_cast<>
Summary:
Replace dynamic_cast<> so that users can choose to build with RTTI off, so that they can save several bytes per object, and get tiny more memory available.
Some nontrivial changes:
1. Add Comparator::GetRootComparator() to get around the internal comparator hack
2. Add the two experiemental functions to DB
3. Add TableFactory::GetOptionString() to avoid unnecessary casting to get the option string
4. Since 3 is done, move the parsing option functions for table factory to table factory files too, to be symmetric.
Closes https://github.com/facebook/rocksdb/pull/2645
Differential Revision: D5502723
Pulled By: siying
fbshipit-source-id: fd13cec5601cf68a554d87bfcf056f2ffa5fbf7c/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/using ThreadLocalPtr to hide ROCKSDB_SUPPORT_THREAD_LOCAL from public
Summary:
 headers
https://github.com/facebook/rocksdb/pull/2199 should not reference RocksDB-specific macros (like ROCKSDB_SUPPORT_THREAD_LOCAL in this case) to public headers, `iostats_context.h` and `perf_context.h`. We shouldn't do that because users have to provide these compiler flags when building their binary with RocksDB.
We should hide the thread local global variable inside our implementation and just expose a function api to retrieve these variables. It may break some users for now but good for long term.
make check -j64
Closes https://github.com/facebook/rocksdb/pull/2380
Differential Revision: D5177896
Pulled By: lightmark
fbshipit-source-id: 6fcdfac57f2e2dcfe60992b7385c5403f6dcb390/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"Replace dynamic_cast<>
Summary:
Replace dynamic_cast<> so that users can choose to build with RTTI off, so that they can save several bytes per object, and get tiny more memory available.
Some nontrivial changes:
1. Add Comparator::GetRootComparator() to get around the internal comparator hack
2. Add the two experiemental functions to DB
3. Add TableFactory::GetOptionString() to avoid unnecessary casting to get the option string
4. Since 3 is done, move the parsing option functions for table factory to table factory files too, to be symmetric.
Closes https://github.com/facebook/rocksdb/pull/2645
Differential Revision: D5502723
Pulled By: siying
fbshipit-source-id: fd13cec5601cf68a554d87bfcf056f2ffa5fbf7c/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Support ingest_behind for IngestExternalFile
Summary:
First cut for early review; there are few conceptual points to answer and some code structure issues.
For conceptual points -
- restriction-wise, we're going to disallow ingest_behind if (use_seqno_zero_out=true || disable_auto_compaction=false), the user is responsible to properly open and close DB with required params
- we wanted to ingest into reserved bottom most level. Should we fail fast if bottom level isn't empty, or should we attempt to ingest if file fits there key-ranges-wise?
- Modifying AssignLevelForIngestedFile seems the place we we'd handle that.
On code structure - going to refactor GenerateAndAddExternalFile call in the test class to allow passing instance of IngestionOptions, that's just going to incur lots of changes at callsites.
Closes https://github.com/facebook/rocksdb/pull/2144
Differential Revision: D4873732
Pulled By: lightmark
fbshipit-source-id: 81cb698106b68ef8797f564453651d50900e153a/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"add VerifyChecksum() to db.h
Summary:
We need a tool to check any sst file corruption in the db.
It will check all the sst files in current version and read all the blocks (data, meta, index) with checksum verification. If any verification fails, the function will return non-OK status.
Closes https://github.com/facebook/rocksdb/pull/2498
Differential Revision: D5324269
Pulled By: lightmark
fbshipit-source-id: 6f8a272008b722402a772acfc804524c9d1a483b/Try to repair db with wal_dir option, avoid leak some WAL files
Summary:
We should search wal_dir in Repairer::FindFiles function, and avoid use
LogFileNmae(dbname, number) to get WAL file's name, which will get a wrong
WAL filename. as following:
```
[WARN] [/home/liuchang/Workspace/rocksdb/db/repair.cc:310] Log #3: ignoring conversion error: IO error: While opening a file for sequentially reading: /tmp/rocksdbtest-1000/repair_test/000003.log: No such file or directory
```
I have added a new test case to repair_test.cc, which try to repair db with all WAL options.
Signed-off-by: Chang Liu <liuchang0812@gmail.com>
Closes https://github.com/facebook/rocksdb/pull/2692
Differential Revision: D5575888
Pulled By: ajkr
fbshipit-source-id: 5b93e9f85cddc01663ccecd87631fa723ac466a3/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Fix Data Race Between CreateColumnFamily() and GetAggregatedIntProperty()
Summary:
CreateColumnFamily() releases DB mutex after adding column family to the set and install super version (to write option file), so if users call GetAggregatedIntProperty() in the middle, then super version will be null and the process will crash. Fix it by skipping those column families without super version installed.
Maybe we should also fix the problem of releasing the lock when reading option file, but it is more risky. so I'm doing a quick and safer fix and we can investigate it later.
Closes https://github.com/facebook/rocksdb/pull/2475
Differential Revision: D5298053
Pulled By: siying
fbshipit-source-id: 4b3c8f91c60400b163fcc6cda8a0c77723be0ef6/fixed typo
Summary:
fixed typo
Closes https://github.com/facebook/rocksdb/pull/2376
Differential Revision: D5183630
Pulled By: ajkr
fbshipit-source-id: 133cfd0445959e70aa2cd1a12151bf3c0c5c3ac5/db: avoid `#include`ing malloc and jemalloc simultaneously
Summary:
This fixes a compilation failure on Linux when the system libc is not
glibc. jemalloc's configure script incorrectly assumes that glibc is
always used on Linux systems, producing glibc-style signatures; when
the system libc is e.g. musl, the following error is observed:
```
[  0%] Building CXX object CMakeFiles/rocksdb.dir/db/db_impl.cc.o
In file included from /go/src/github.com/cockroachdb/cockroach/c-deps/rocksdb.src/table/block.h:19:0,
from /go/src/github.com/cockroachdb/cockroach/c-deps/rocksdb.src/db/db_impl.cc:77:
/x-tools/x86_64-unknown-linux-musl/x86_64-unknown-linux-musl/sysroot/usr/include/malloc.h:19:8: error: declaration of 'size_t malloc_usable_size(void*)' has a different exception specifier
size_t malloc_usable_size(void *);
^~~~~~~~~~~~~~~~~~
In file included from /go/src/github.com/cockroachdb/cockroach/c-deps/rocksdb.src/db/db_impl.cc:20:0:
/go/native/x86_64-unknown-linux-musl/jemalloc/include/jemalloc/jemalloc.h:78:33: note: from previous declaration 'size_t malloc_usable_size(void*) throw ()'
#  define je_malloc_usable_size malloc_usable_size
^
/go/native/x86_64-unknown-linux-musl/jemalloc/include/jemalloc/jemalloc.h:239:41: note: in expansion of macro 'je_malloc_usable_size'
JEMALLOC_EXPORT size_t JEMALLOC_NOTHROW je_malloc_usable_size(
^~~~~~~~~~~~~~~~~~~~~
CMakeFiles/rocksdb.dir/build.make:350: recipe for target 'CMakeFiles/rocksdb.dir/db/db_impl.cc.o' failed
```
This works around the issue by rearranging the sources such that
jemalloc's headers are never in the same scope as the system's malloc
header. The jemalloc issue has been reported as well, see:
https://github.com/jemalloc/jemalloc/issues/778.
cc tschottdorf
Closes https://github.com/facebook/rocksdb/pull/2188
Differential Revision: D5163048
Pulled By: siying
fbshipit-source-id: c553125458892def175c1be5682b0330d80b2a0d/New WriteImpl to pipeline WAL/memtable write
Summary:
PipelineWriteImpl is an alternative approach to WriteImpl. In WriteImpl, only one thread is allow to write at the same time. This thread will do both WAL and memtable writes for all write threads in the write group. Pending writers wait in queue until the current writer finishes. In the pipeline write approach, two queue is maintained: one WAL writer queue and one memtable writer queue. All writers (regardless of whether they need to write WAL) will still need to first join the WAL writer queue, and after the house keeping work and WAL writing, they will need to join memtable writer queue if needed. The benefit of this approach is that
1. Writers without memtable writes (e.g. the prepare phase of two phase commit) can exit write thread once WAL write is finish. They don't need to wait for memtable writes in case of group commit.
2. Pending writers only need to wait for previous WAL writer finish to be able to join the write thread, instead of wait also for previous memtable writes.
Merging #2056 and #2058 into this PR.
Closes https://github.com/facebook/rocksdb/pull/2286
Differential Revision: D5054606
Pulled By: yiwu-arbug
fbshipit-source-id: ee5b11efd19d3e39d6b7210937b11cefdd4d1c8d/Support ingest_behind for IngestExternalFile
Summary:
First cut for early review; there are few conceptual points to answer and some code structure issues.
For conceptual points -
- restriction-wise, we're going to disallow ingest_behind if (use_seqno_zero_out=true || disable_auto_compaction=false), the user is responsible to properly open and close DB with required params
- we wanted to ingest into reserved bottom most level. Should we fail fast if bottom level isn't empty, or should we attempt to ingest if file fits there key-ranges-wise?
- Modifying AssignLevelForIngestedFile seems the place we we'd handle that.
On code structure - going to refactor GenerateAndAddExternalFile call in the test class to allow passing instance of IngestionOptions, that's just going to incur lots of changes at callsites.
Closes https://github.com/facebook/rocksdb/pull/2144
Differential Revision: D4873732
Pulled By: lightmark
fbshipit-source-id: 81cb698106b68ef8797f564453651d50900e153a/"
rocksdb,"Support prefetch last 512KB with direct I/O in block based file reader
Summary:
Right now, if direct I/O is enabled, prefetching the last 512KB cannot be applied, except compaction inputs or readahead is enabled for iterators. This can create a lot of I/O for HDD cases. To solve the problem, the 512KB is prefetched in block based table if direct I/O is enabled. The prefetched buffer is passed in totegher with random access file reader, so that we try to read from the buffer before reading from the file. This can be extended in the future to support flexible user iterator readahead too.
Closes https://github.com/facebook/rocksdb/pull/2708
Differential Revision: D5593091
Pulled By: siying
fbshipit-source-id: ee36ff6d8af11c312a2622272b21957a7b5c81e7/Fix LITE unit tests
Summary: Closes https://github.com/facebook/rocksdb/pull/2649
Differential Revision: D5505778
Pulled By: siying
fbshipit-source-id: 7e935603ede3d958ea087ed6b8cfc4121e8797bc/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Encryption at rest support
Summary:
This PR adds support for encrypting data stored by RocksDB when written to disk.
It adds an `EncryptedEnv` override of the `Env` class with matching overrides for sequential&random access files.
The encryption itself is done through a configurable `EncryptionProvider`. This class creates is asked to create `BlockAccessCipherStream` for a file. This is where the actual encryption/decryption is being done.
Currently there is a Counter mode implementation of `BlockAccessCipherStream` with a `ROT13` block cipher (NOTE the `ROT13` is for demo purposes only!!).
The Counter operation mode uses an initial counter & random initialization vector (IV).
Both are created randomly for each file and stored in a 4K (default size) block that is prefixed to that file. The `EncryptedEnv` implementation is such that clients of the `Env` class do not see this prefix (nor data, nor in filesize).
The largest part of the prefix block is also encrypted, and there is room left for implementation specific settings/values/keys in there.
To test the encryption, the `DBTestBase` class has been extended to consider a new environment variable called `ENCRYPTED_ENV`. If set, the test will setup a encrypted instance of the `Env` class to use for all tests.
Typically you would run it like this:
```
ENCRYPTED_ENV=1 make check_some
```
There is also an added test that checks that some data inserted into the database is or is not ""visible"" on disk. With `ENCRYPTED_ENV` active it must not find plain text strings, with `ENCRYPTED_ENV` unset, it must find the plain text strings.
Closes https://github.com/facebook/rocksdb/pull/2424
Differential Revision: D5322178
Pulled By: sdwilsh
fbshipit-source-id: 253b0a9c2c498cc98f580df7f2623cbf7678a27f/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Support ingest_behind for IngestExternalFile
Summary:
First cut for early review; there are few conceptual points to answer and some code structure issues.
For conceptual points -
- restriction-wise, we're going to disallow ingest_behind if (use_seqno_zero_out=true || disable_auto_compaction=false), the user is responsible to properly open and close DB with required params
- we wanted to ingest into reserved bottom most level. Should we fail fast if bottom level isn't empty, or should we attempt to ingest if file fits there key-ranges-wise?
- Modifying AssignLevelForIngestedFile seems the place we we'd handle that.
On code structure - going to refactor GenerateAndAddExternalFile call in the test class to allow passing instance of IngestionOptions, that's just going to incur lots of changes at callsites.
Closes https://github.com/facebook/rocksdb/pull/2144
Differential Revision: D4873732
Pulled By: lightmark
fbshipit-source-id: 81cb698106b68ef8797f564453651d50900e153a/"
rocksdb,"Fix LITE unit tests
Summary: Closes https://github.com/facebook/rocksdb/pull/2649
Differential Revision: D5505778
Pulled By: siying
fbshipit-source-id: 7e935603ede3d958ea087ed6b8cfc4121e8797bc/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Encryption at rest support
Summary:
This PR adds support for encrypting data stored by RocksDB when written to disk.
It adds an `EncryptedEnv` override of the `Env` class with matching overrides for sequential&random access files.
The encryption itself is done through a configurable `EncryptionProvider`. This class creates is asked to create `BlockAccessCipherStream` for a file. This is where the actual encryption/decryption is being done.
Currently there is a Counter mode implementation of `BlockAccessCipherStream` with a `ROT13` block cipher (NOTE the `ROT13` is for demo purposes only!!).
The Counter operation mode uses an initial counter & random initialization vector (IV).
Both are created randomly for each file and stored in a 4K (default size) block that is prefixed to that file. The `EncryptedEnv` implementation is such that clients of the `Env` class do not see this prefix (nor data, nor in filesize).
The largest part of the prefix block is also encrypted, and there is room left for implementation specific settings/values/keys in there.
To test the encryption, the `DBTestBase` class has been extended to consider a new environment variable called `ENCRYPTED_ENV`. If set, the test will setup a encrypted instance of the `Env` class to use for all tests.
Typically you would run it like this:
```
ENCRYPTED_ENV=1 make check_some
```
There is also an added test that checks that some data inserted into the database is or is not ""visible"" on disk. With `ENCRYPTED_ENV` active it must not find plain text strings, with `ENCRYPTED_ENV` unset, it must find the plain text strings.
Closes https://github.com/facebook/rocksdb/pull/2424
Differential Revision: D5322178
Pulled By: sdwilsh
fbshipit-source-id: 253b0a9c2c498cc98f580df7f2623cbf7678a27f/Fixing blob db sequence number handling
Summary:
Blob db rely on base db returning sequence number through write batch after DB::Write(). However after recent changes to the write path, DB::Writ()e no longer return sequence number in some cases. Fixing it by have WriteBatchInternal::InsertInto() always encode sequence number into write batch.
Stacking on #2375.
Closes https://github.com/facebook/rocksdb/pull/2385
Differential Revision: D5148358
Pulled By: yiwu-arbug
fbshipit-source-id: 8bda0aa07b9334ed03ed381548b39d167dc20c33/"
rocksdb,"expose set_skip_stats_update_on_db_open to C bindings
Summary:
It would be super helpful to not have to recompile rocksdb to get this performance tweak for mechanical disks.
I have signed the CLA.
Closes https://github.com/facebook/rocksdb/pull/2718
Differential Revision: D5606994
Pulled By: yiwu-arbug
fbshipit-source-id: c05e92bad0d03bd38211af1e1ced0d0d1e02f634/Add column families related functions (C API)
Summary:
(#2564)
Closes https://github.com/facebook/rocksdb/pull/2669
Differential Revision: D5594151
Pulled By: yiwu-arbug
fbshipit-source-id: 67ae9446342f3323d6ecad8e811f4158da194270/Write batch for `TransactionDB` in C API
Summary: Closes https://github.com/facebook/rocksdb/pull/2655
Differential Revision: D5600858
Pulled By: yiwu-arbug
fbshipit-source-id: cf52f9104e348438bf168dc6bf7af3837faf12ef/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/add Transactions and Checkpoint to C API
Summary:
I've added functions to the C API to support Transactions as requested in #1637 and to support Checkpoint.
I have also added the corresponding tests to c_test.c
For now, the following is omitted:
1. Optimistic Transactions
2. The column family variation of functions
Closes https://github.com/facebook/rocksdb/pull/2236
Differential Revision: D4989510
Pulled By: yiwu-arbug
fbshipit-source-id: 518cb39f76d5e9ec9690d633fcdc014b98958071/C API: support pinnable get
Summary: Closes https://github.com/facebook/rocksdb/pull/2254
Differential Revision: D5053590
Pulled By: yiwu-arbug
fbshipit-source-id: 2f365a031b3a2947b4fba21d26d4f8f52af9b9f0/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/FIFO Compaction with TTL
Summary:
Introducing FIFO compactions with TTL.
FIFO compaction is based on size only which makes it tricky to enable in production as use cases can have organic growth. A user requested an option to drop files based on the time of their creation instead of the total size.
To address that request:
- Added a new TTL option to FIFO compaction options.
- Updated FIFO compaction score to take TTL into consideration.
- Added a new table property, creation_time, to keep track of when the SST file is created.
- Creation_time is set as below:
- On Flush: Set to the time of flush.
- On Compaction: Set to the max creation_time of all the files involved in the compaction.
- On Repair and Recovery: Set to the time of repair/recovery.
- Old files created prior to this code change will have a creation_time of 0.
- FIFO compaction with TTL is enabled when ttl > 0. All files older than ttl will be deleted during compaction. i.e. `if (file.creation_time < (current_time - ttl)) then delete(file)`. This will enable cases where you might want to delete all files older than, say, 1 day.
- FIFO compaction will fall back to the prior way of deleting files based on size if:
- the creation_time of all files involved in compaction is 0.
- the total size (of all SST files combined) does not drop below `compaction_options_fifo.max_table_files_size` even if the files older than ttl are deleted.
This feature is not supported if max_open_files != -1 or with table formats other than Block-based.
**Test Plan:**
Added tests.
**Benchmark results:**
Base: FIFO with max size: 100MB ::
```
svemuri@dev15905 ~/rocksdb (fifo-compaction) $ TEST_TMPDIR=/dev/shm ./db_bench --benchmarks=readwhilewriting --num=5000000 --threads=16 --compaction_style=2 --fifo_compaction_max_table_files_size_mb=100
readwhilewriting :       1.924 micros/op 519858 ops/sec;   13.6 MB/s (1176277 of 5000000 found)
```
With TTL (a low one for testing) ::
```
svemuri@dev15905 ~/rocksdb (fifo-compaction) $ TEST_TMPDIR=/dev/shm ./db_bench --benchmarks=readwhilewriting --num=5000000 --threads=16 --compaction_style=2 --fifo_compaction_max_table_files_size_mb=100 --fifo_compaction_ttl=20
readwhilewriting :       1.902 micros/op 525817 ops/sec;   13.7 MB/s (1185057 of 5000000 found)
```
Example Log lines:
```
2017/06/26-15:17:24.609249 7fd5a45ff700 (Original Log Time 2017/06/26-15:17:24.609177) [db/compaction_picker.cc:1471] [default] FIFO compaction: picking file 40 with creation time 1498515423 for deletion
2017/06/26-15:17:24.609255 7fd5a45ff700 (Original Log Time 2017/06/26-15:17:24.609234) [db/db_impl_compaction_flush.cc:1541] [default] Deleted 1 files
...
2017/06/26-15:17:25.553185 7fd5a61a5800 [DEBUG] [db/db_impl_files.cc:309] [JOB 0] Delete /dev/shm/dbbench/000040.sst type=2 #40 -- OK
2017/06/26-15:17:25.553205 7fd5a61a5800 EVENT_LOG_v1 {""time_micros"": 1498515445553199, ""job"": 0, ""event"": ""table_file_deletion"", ""file_number"": 40}
```
SST Files remaining in the dbbench dir, after db_bench execution completed:
```
svemuri@dev15905 ~/rocksdb (fifo-compaction)  $ ls -l /dev/shm//dbbench/*.sst
-rw-r--r--. 1 svemuri users 30749887 Jun 26 15:17 /dev/shm//dbbench/000042.sst
-rw-r--r--. 1 svemuri users 30768779 Jun 26 15:17 /dev/shm//dbbench/000044.sst
-rw-r--r--. 1 svemuri users 30757481 Jun 26 15:17 /dev/shm//dbbench/000046.sst
```
Closes https://github.com/facebook/rocksdb/pull/2480
Differential Revision: D5305116
Pulled By: sagar0
fbshipit-source-id: 3e5cfcf5dd07ed2211b5b37492eb235b45139174/Fix bug that flush doesn't respond to fsync result
Summary:
With a regression bug was introduced two years ago, by https://github.com/facebook/rocksdb/commit/6e9fbeb27c38329f33ae541302c44c8db8374f8c , we fail to check return status of fsync call. This can cause we miss the information from the file system and can potentially cause corrupted data which we could have been detected.
Closes https://github.com/facebook/rocksdb/pull/2495
Reviewed By: ajkr
Differential Revision: D5321949
Pulled By: siying
fbshipit-source-id: c68117914bb40700198fc37d0e4c63163a8a1031/"
rocksdb,"Fix caching of compaction picker's next index
Summary:
The previous implementation of caching `file_size` index made no sense. It only remembered the original span of locked files starting from beginning of `file_size`. We should remember the index after all compactions that have been considered but rejected. This will reduce the work we do while holding the db mutex.
Closes https://github.com/facebook/rocksdb/pull/2624
Differential Revision: D5468152
Pulled By: ajkr
fbshipit-source-id: ab92a4bffe76f9f174d861bb5812b974d1013400/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/overlapping endpoint fixes in level compaction picker
Summary:
This diff addresses two problems. Both problems cause us to miss scheduling desirable compactions. One side effect is compaction picking can spam logs, as there's no delay after failed attempts to pick compactions.
1. If a compaction pulled in a locked input-level file due to user-key overlap, we would not consider picking another file from the same input level.
2. If a compaction pulled in a locked output-level file due to user-key overlap, we would not consider picking any other compaction on any level.
The code changes are dependent, which is why I solved both problems in a single diff.
- Moved input-level `ExpandInputsToCleanCut` into the loop inside `PickFileToCompact`. This gives two benefits: (1) if it fails, we will try the next-largest file on the same input level; (2) we get the fully-expanded input-level key-range with which we can check for pending compactions in output level.
- Added another call to `ExpandInputsToCleanCut` inside `PickFileToCompact`'s to check for compaction conflicts in output level.
- Deleted call to `IsRangeInCompaction` in `PickFileToCompact`, as `ExpandInputsToCleanCut` also correctly handles the case where original output-level files (i.e., ones not pulled in due to user-key overlap) are pending compaction.
Closes https://github.com/facebook/rocksdb/pull/2615
Differential Revision: D5454643
Pulled By: ajkr
fbshipit-source-id: ea3fb5477d83e97148951af3fd4558d2039e9872/delete ExpandInputsToCleanCut failure log
Summary:
I decided not even to keep it as an INFO-level log as it is too normal for compactions to be skipped due to locked input files. Removing logging here makes us consistent with how we treat locked files that weren't pulled in due to overlap.
We may want some error handling on line 422, which should never happen when called by `LevelCompactionBuilder::PickCompaction`, as `SetupInitialFiles` skips compactions where overlap causes the output level to pull in locked files.
Closes https://github.com/facebook/rocksdb/pull/2617
Differential Revision: D5458502
Pulled By: ajkr
fbshipit-source-id: c2e5f867c0a77c1812ce4242ab3e085b3eee0bae/FIFO Compaction with TTL
Summary:
Introducing FIFO compactions with TTL.
FIFO compaction is based on size only which makes it tricky to enable in production as use cases can have organic growth. A user requested an option to drop files based on the time of their creation instead of the total size.
To address that request:
- Added a new TTL option to FIFO compaction options.
- Updated FIFO compaction score to take TTL into consideration.
- Added a new table property, creation_time, to keep track of when the SST file is created.
- Creation_time is set as below:
- On Flush: Set to the time of flush.
- On Compaction: Set to the max creation_time of all the files involved in the compaction.
- On Repair and Recovery: Set to the time of repair/recovery.
- Old files created prior to this code change will have a creation_time of 0.
- FIFO compaction with TTL is enabled when ttl > 0. All files older than ttl will be deleted during compaction. i.e. `if (file.creation_time < (current_time - ttl)) then delete(file)`. This will enable cases where you might want to delete all files older than, say, 1 day.
- FIFO compaction will fall back to the prior way of deleting files based on size if:
- the creation_time of all files involved in compaction is 0.
- the total size (of all SST files combined) does not drop below `compaction_options_fifo.max_table_files_size` even if the files older than ttl are deleted.
This feature is not supported if max_open_files != -1 or with table formats other than Block-based.
**Test Plan:**
Added tests.
**Benchmark results:**
Base: FIFO with max size: 100MB ::
```
svemuri@dev15905 ~/rocksdb (fifo-compaction) $ TEST_TMPDIR=/dev/shm ./db_bench --benchmarks=readwhilewriting --num=5000000 --threads=16 --compaction_style=2 --fifo_compaction_max_table_files_size_mb=100
readwhilewriting :       1.924 micros/op 519858 ops/sec;   13.6 MB/s (1176277 of 5000000 found)
```
With TTL (a low one for testing) ::
```
svemuri@dev15905 ~/rocksdb (fifo-compaction) $ TEST_TMPDIR=/dev/shm ./db_bench --benchmarks=readwhilewriting --num=5000000 --threads=16 --compaction_style=2 --fifo_compaction_max_table_files_size_mb=100 --fifo_compaction_ttl=20
readwhilewriting :       1.902 micros/op 525817 ops/sec;   13.7 MB/s (1185057 of 5000000 found)
```
Example Log lines:
```
2017/06/26-15:17:24.609249 7fd5a45ff700 (Original Log Time 2017/06/26-15:17:24.609177) [db/compaction_picker.cc:1471] [default] FIFO compaction: picking file 40 with creation time 1498515423 for deletion
2017/06/26-15:17:24.609255 7fd5a45ff700 (Original Log Time 2017/06/26-15:17:24.609234) [db/db_impl_compaction_flush.cc:1541] [default] Deleted 1 files
...
2017/06/26-15:17:25.553185 7fd5a61a5800 [DEBUG] [db/db_impl_files.cc:309] [JOB 0] Delete /dev/shm/dbbench/000040.sst type=2 #40 -- OK
2017/06/26-15:17:25.553205 7fd5a61a5800 EVENT_LOG_v1 {""time_micros"": 1498515445553199, ""job"": 0, ""event"": ""table_file_deletion"", ""file_number"": 40}
```
SST Files remaining in the dbbench dir, after db_bench execution completed:
```
svemuri@dev15905 ~/rocksdb (fifo-compaction)  $ ls -l /dev/shm//dbbench/*.sst
-rw-r--r--. 1 svemuri users 30749887 Jun 26 15:17 /dev/shm//dbbench/000042.sst
-rw-r--r--. 1 svemuri users 30768779 Jun 26 15:17 /dev/shm//dbbench/000044.sst
-rw-r--r--. 1 svemuri users 30757481 Jun 26 15:17 /dev/shm//dbbench/000046.sst
```
Closes https://github.com/facebook/rocksdb/pull/2480
Differential Revision: D5305116
Pulled By: sagar0
fbshipit-source-id: 3e5cfcf5dd07ed2211b5b37492eb235b45139174/Support ingest_behind for IngestExternalFile
Summary:
First cut for early review; there are few conceptual points to answer and some code structure issues.
For conceptual points -
- restriction-wise, we're going to disallow ingest_behind if (use_seqno_zero_out=true || disable_auto_compaction=false), the user is responsible to properly open and close DB with required params
- we wanted to ingest into reserved bottom most level. Should we fail fast if bottom level isn't empty, or should we attempt to ingest if file fits there key-ranges-wise?
- Modifying AssignLevelForIngestedFile seems the place we we'd handle that.
On code structure - going to refactor GenerateAndAddExternalFile call in the test class to allow passing instance of IngestionOptions, that's just going to incur lots of changes at callsites.
Closes https://github.com/facebook/rocksdb/pull/2144
Differential Revision: D4873732
Pulled By: lightmark
fbshipit-source-id: 81cb698106b68ef8797f564453651d50900e153a/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Fix column family seconds_up accounting
Summary:
`cf_stats_snapshot_.seconds_up` appears to be never updated, unlike `db_stats_snapshot_.seconds_up`, which is updated here: https://github.com/facebook/rocksdb/blob/master/db/internal_stats.cc#L883
This leads to wrong information in the log, for example:
```
** Compaction Stats [default] **
....
Uptime(secs): 85591.2 total, 85591.2 interval
```
Even though DB's interval is correctly logged as 60 seconds:
```
** DB Stats **
Uptime(secs): 85591.2 total, 637.8 interval
```
Closes https://github.com/facebook/rocksdb/pull/2338
Differential Revision: D5114131
Pulled By: sagar0
fbshipit-source-id: 85243a38213236ccbb601a7f7aaa8865eaa8083c/Fix rocksdb.estimate-num-keys DB property underflow
Summary:
rocksdb.estimate-num-keys is compute from `estimate_num_keys - 2 * estimate_num_deletes`. If  `2 * estimate_num_deletes > estimate_num_keys` it will underflow. Fixing it.
Closes https://github.com/facebook/rocksdb/pull/2348
Differential Revision: D5109272
Pulled By: yiwu-arbug
fbshipit-source-id: e1bfb91346a59b7282a282b615002507e9d7c246/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Fix interaction between CompactionFilter::Decision::kRemoveAndSkipUnt
Summary:
Fixes the following scenario:
1. Set prefix extractor. Enable bloom filters, with `whole_key_filtering = false`. Use compaction filter that sometimes returns `kRemoveAndSkipUntil`.
2. Do a compaction.
3. Compaction creates an iterator with `total_order_seek = false`, calls `SeekToFirst()` on it, then repeatedly calls `Next()`.
4. At some point compaction filter returns `kRemoveAndSkipUntil`.
5. Compaction calls `Seek(skip_until)` on the iterator. The key that it seeks to happens to have prefix that doesn't match the bloom filter. Since `total_order_seek = false`, iterator becomes invalid, and compaction thinks that it has reached the end. The rest of the compaction input is silently discarded.
The fix is to make compaction iterator use `total_order_seek = true`.
The implementation for PlainTable is quite awkward. I've made `kRemoveAndSkipUntil` officially incompatible with PlainTable. If you try to use them together, compaction will fail, and DB will enter read-only mode (`bg_error_`). That's not a very graceful way to communicate a misconfiguration, but the alternatives don't seem worth the implementation time and complexity. To be able to check in advance that `kRemoveAndSkipUntil` is not going to be used with PlainTable, we'd need to extend the interface of either `CompactionFilter` or `InternalIterator`. It seems unlikely that anyone will ever want to use `kRemoveAndSkipUntil` with PlainTable: PlainTable probably has very few users, and `kRemoveAndSkipUntil` has only one user so far: us (logdevice).
Closes https://github.com/facebook/rocksdb/pull/2349
Differential Revision: D5110388
Pulled By: lightmark
fbshipit-source-id: ec29101a99d9dcd97db33923b87f72bce56cc17a/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/using ThreadLocalPtr to hide ROCKSDB_SUPPORT_THREAD_LOCAL from public
Summary:
 headers
https://github.com/facebook/rocksdb/pull/2199 should not reference RocksDB-specific macros (like ROCKSDB_SUPPORT_THREAD_LOCAL in this case) to public headers, `iostats_context.h` and `perf_context.h`. We shouldn't do that because users have to provide these compiler flags when building their binary with RocksDB.
We should hide the thread local global variable inside our implementation and just expose a function api to retrieve these variables. It may break some users for now but good for long term.
make check -j64
Closes https://github.com/facebook/rocksdb/pull/2380
Differential Revision: D5177896
Pulled By: lightmark
fbshipit-source-id: 6fcdfac57f2e2dcfe60992b7385c5403f6dcb390/Fix rocksdb.estimate-num-keys DB property underflow
Summary:
rocksdb.estimate-num-keys is compute from `estimate_num_keys - 2 * estimate_num_deletes`. If  `2 * estimate_num_deletes > estimate_num_keys` it will underflow. Fixing it.
Closes https://github.com/facebook/rocksdb/pull/2348
Differential Revision: D5109272
Pulled By: yiwu-arbug
fbshipit-source-id: e1bfb91346a59b7282a282b615002507e9d7c246/"
rocksdb,"add VerifyChecksum() to db.h
Summary:
We need a tool to check any sst file corruption in the db.
It will check all the sst files in current version and read all the blocks (data, meta, index) with checksum verification. If any verification fails, the function will return non-OK status.
Closes https://github.com/facebook/rocksdb/pull/2498
Differential Revision: D5324269
Pulled By: lightmark
fbshipit-source-id: 6f8a272008b722402a772acfc804524c9d1a483b/Fix FIFO Compaction with TTL tests
Summary:
- FIFOCompactionWithTTLTest was flaky when run in parallel earlier, and hence it was disabled. Fixed it now.
- Also, faking sleep now instead of really sleeping to make tests more realistic by using TTLs like 1 hour and 1 day.
Closes https://github.com/facebook/rocksdb/pull/2650
Differential Revision: D5506038
Pulled By: sagar0
fbshipit-source-id: deb429a527f045e3e2c5138b547c3e8ac8586aa2/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/FIFO Compaction with TTL
Summary:
Introducing FIFO compactions with TTL.
FIFO compaction is based on size only which makes it tricky to enable in production as use cases can have organic growth. A user requested an option to drop files based on the time of their creation instead of the total size.
To address that request:
- Added a new TTL option to FIFO compaction options.
- Updated FIFO compaction score to take TTL into consideration.
- Added a new table property, creation_time, to keep track of when the SST file is created.
- Creation_time is set as below:
- On Flush: Set to the time of flush.
- On Compaction: Set to the max creation_time of all the files involved in the compaction.
- On Repair and Recovery: Set to the time of repair/recovery.
- Old files created prior to this code change will have a creation_time of 0.
- FIFO compaction with TTL is enabled when ttl > 0. All files older than ttl will be deleted during compaction. i.e. `if (file.creation_time < (current_time - ttl)) then delete(file)`. This will enable cases where you might want to delete all files older than, say, 1 day.
- FIFO compaction will fall back to the prior way of deleting files based on size if:
- the creation_time of all files involved in compaction is 0.
- the total size (of all SST files combined) does not drop below `compaction_options_fifo.max_table_files_size` even if the files older than ttl are deleted.
This feature is not supported if max_open_files != -1 or with table formats other than Block-based.
**Test Plan:**
Added tests.
**Benchmark results:**
Base: FIFO with max size: 100MB ::
```
svemuri@dev15905 ~/rocksdb (fifo-compaction) $ TEST_TMPDIR=/dev/shm ./db_bench --benchmarks=readwhilewriting --num=5000000 --threads=16 --compaction_style=2 --fifo_compaction_max_table_files_size_mb=100
readwhilewriting :       1.924 micros/op 519858 ops/sec;   13.6 MB/s (1176277 of 5000000 found)
```
With TTL (a low one for testing) ::
```
svemuri@dev15905 ~/rocksdb (fifo-compaction) $ TEST_TMPDIR=/dev/shm ./db_bench --benchmarks=readwhilewriting --num=5000000 --threads=16 --compaction_style=2 --fifo_compaction_max_table_files_size_mb=100 --fifo_compaction_ttl=20
readwhilewriting :       1.902 micros/op 525817 ops/sec;   13.7 MB/s (1185057 of 5000000 found)
```
Example Log lines:
```
2017/06/26-15:17:24.609249 7fd5a45ff700 (Original Log Time 2017/06/26-15:17:24.609177) [db/compaction_picker.cc:1471] [default] FIFO compaction: picking file 40 with creation time 1498515423 for deletion
2017/06/26-15:17:24.609255 7fd5a45ff700 (Original Log Time 2017/06/26-15:17:24.609234) [db/db_impl_compaction_flush.cc:1541] [default] Deleted 1 files
...
2017/06/26-15:17:25.553185 7fd5a61a5800 [DEBUG] [db/db_impl_files.cc:309] [JOB 0] Delete /dev/shm/dbbench/000040.sst type=2 #40 -- OK
2017/06/26-15:17:25.553205 7fd5a61a5800 EVENT_LOG_v1 {""time_micros"": 1498515445553199, ""job"": 0, ""event"": ""table_file_deletion"", ""file_number"": 40}
```
SST Files remaining in the dbbench dir, after db_bench execution completed:
```
svemuri@dev15905 ~/rocksdb (fifo-compaction)  $ ls -l /dev/shm//dbbench/*.sst
-rw-r--r--. 1 svemuri users 30749887 Jun 26 15:17 /dev/shm//dbbench/000042.sst
-rw-r--r--. 1 svemuri users 30768779 Jun 26 15:17 /dev/shm//dbbench/000044.sst
-rw-r--r--. 1 svemuri users 30757481 Jun 26 15:17 /dev/shm//dbbench/000046.sst
```
Closes https://github.com/facebook/rocksdb/pull/2480
Differential Revision: D5305116
Pulled By: sagar0
fbshipit-source-id: 3e5cfcf5dd07ed2211b5b37492eb235b45139174/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Encryption at rest support
Summary:
This PR adds support for encrypting data stored by RocksDB when written to disk.
It adds an `EncryptedEnv` override of the `Env` class with matching overrides for sequential&random access files.
The encryption itself is done through a configurable `EncryptionProvider`. This class creates is asked to create `BlockAccessCipherStream` for a file. This is where the actual encryption/decryption is being done.
Currently there is a Counter mode implementation of `BlockAccessCipherStream` with a `ROT13` block cipher (NOTE the `ROT13` is for demo purposes only!!).
The Counter operation mode uses an initial counter & random initialization vector (IV).
Both are created randomly for each file and stored in a 4K (default size) block that is prefixed to that file. The `EncryptedEnv` implementation is such that clients of the `Env` class do not see this prefix (nor data, nor in filesize).
The largest part of the prefix block is also encrypted, and there is room left for implementation specific settings/values/keys in there.
To test the encryption, the `DBTestBase` class has been extended to consider a new environment variable called `ENCRYPTED_ENV`. If set, the test will setup a encrypted instance of the `Env` class to use for all tests.
Typically you would run it like this:
```
ENCRYPTED_ENV=1 make check_some
```
There is also an added test that checks that some data inserted into the database is or is not ""visible"" on disk. With `ENCRYPTED_ENV` active it must not find plain text strings, with `ENCRYPTED_ENV` unset, it must find the plain text strings.
Closes https://github.com/facebook/rocksdb/pull/2424
Differential Revision: D5322178
Pulled By: sdwilsh
fbshipit-source-id: 253b0a9c2c498cc98f580df7f2623cbf7678a27f/Introduce OnBackgroundError callback
Summary:
Some users want to prevent rocksdb from entering read-only mode in certain error cases. This diff gives them a callback, `OnBackgroundError`, that they can use to achieve it.
- call `OnBackgroundError` every time we consider setting `bg_error_`. Use its result to assign `bg_error_` but not to change the function's return status.
- classified calls using `BackgroundErrorReason` to give the callback some info about where the error happened
- renamed `ParanoidCheck` to something more specific so we can provide a clear `BackgroundErrorReason`
- unit tests for the most common cases: flush or compaction errors
Closes https://github.com/facebook/rocksdb/pull/2477
Differential Revision: D5300190
Pulled By: ajkr
fbshipit-source-id: a0ea4564249719b83428e3f4c6ca2c49e366e9b3/"
rocksdb,"fix asan/valgrind for TableCache cleanup
Summary:
Breaking commit: d12691b86fb788f0ee7180db626c4ea2445fa976
In the above commit, I moved the `TableCache` cleanup logic from `Version` destructor into `PurgeObsoleteFiles`. I missed cleaning up `TableCache` entries for the current `Version` during DB destruction.
This PR adds that logic to `VersionSet` destructor. One unfortunate side effect is now we're potentially deleting `TableReader`s after `column_family_set_.reset()`, which means we can't call `BlockBasedTableReader::Close` a second time as the block cache might already be destroyed.
Closes https://github.com/facebook/rocksdb/pull/2662
Differential Revision: D5515108
Pulled By: ajkr
fbshipit-source-id: 2cb820e19aa813e0d258d17f76b2d7b6b7ee0b18/comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/Improve Status message for block checksum mismatches
Summary:
We've got some DBs where iterators return Status with message ""Corruption: block checksum mismatch"" all the time. That's not very informative. It would be much easier to investigate if the error message contained the file name - then we would know e.g. how old the corrupted file is, which would be very useful for finding the root cause. This PR adds file name, offset and other stuff to some block corruption-related status messages.
It doesn't improve all the error messages, just a few that were easy to improve. I'm mostly interested in ""block checksum mismatch"" and ""Bad table magic number"" since they're the only corruption errors that I've ever seen in the wild.
Closes https://github.com/facebook/rocksdb/pull/2507
Differential Revision: D5345702
Pulled By: al13n321
fbshipit-source-id: fc8023d43f1935ad927cef1b9c55481ab3cb1339/FIFO Compaction with TTL
Summary:
Introducing FIFO compactions with TTL.
FIFO compaction is based on size only which makes it tricky to enable in production as use cases can have organic growth. A user requested an option to drop files based on the time of their creation instead of the total size.
To address that request:
- Added a new TTL option to FIFO compaction options.
- Updated FIFO compaction score to take TTL into consideration.
- Added a new table property, creation_time, to keep track of when the SST file is created.
- Creation_time is set as below:
- On Flush: Set to the time of flush.
- On Compaction: Set to the max creation_time of all the files involved in the compaction.
- On Repair and Recovery: Set to the time of repair/recovery.
- Old files created prior to this code change will have a creation_time of 0.
- FIFO compaction with TTL is enabled when ttl > 0. All files older than ttl will be deleted during compaction. i.e. `if (file.creation_time < (current_time - ttl)) then delete(file)`. This will enable cases where you might want to delete all files older than, say, 1 day.
- FIFO compaction will fall back to the prior way of deleting files based on size if:
- the creation_time of all files involved in compaction is 0.
- the total size (of all SST files combined) does not drop below `compaction_options_fifo.max_table_files_size` even if the files older than ttl are deleted.
This feature is not supported if max_open_files != -1 or with table formats other than Block-based.
**Test Plan:**
Added tests.
**Benchmark results:**
Base: FIFO with max size: 100MB ::
```
svemuri@dev15905 ~/rocksdb (fifo-compaction) $ TEST_TMPDIR=/dev/shm ./db_bench --benchmarks=readwhilewriting --num=5000000 --threads=16 --compaction_style=2 --fifo_compaction_max_table_files_size_mb=100
readwhilewriting :       1.924 micros/op 519858 ops/sec;   13.6 MB/s (1176277 of 5000000 found)
```
With TTL (a low one for testing) ::
```
svemuri@dev15905 ~/rocksdb (fifo-compaction) $ TEST_TMPDIR=/dev/shm ./db_bench --benchmarks=readwhilewriting --num=5000000 --threads=16 --compaction_style=2 --fifo_compaction_max_table_files_size_mb=100 --fifo_compaction_ttl=20
readwhilewriting :       1.902 micros/op 525817 ops/sec;   13.7 MB/s (1185057 of 5000000 found)
```
Example Log lines:
```
2017/06/26-15:17:24.609249 7fd5a45ff700 (Original Log Time 2017/06/26-15:17:24.609177) [db/compaction_picker.cc:1471] [default] FIFO compaction: picking file 40 with creation time 1498515423 for deletion
2017/06/26-15:17:24.609255 7fd5a45ff700 (Original Log Time 2017/06/26-15:17:24.609234) [db/db_impl_compaction_flush.cc:1541] [default] Deleted 1 files
...
2017/06/26-15:17:25.553185 7fd5a61a5800 [DEBUG] [db/db_impl_files.cc:309] [JOB 0] Delete /dev/shm/dbbench/000040.sst type=2 #40 -- OK
2017/06/26-15:17:25.553205 7fd5a61a5800 EVENT_LOG_v1 {""time_micros"": 1498515445553199, ""job"": 0, ""event"": ""table_file_deletion"", ""file_number"": 40}
```
SST Files remaining in the dbbench dir, after db_bench execution completed:
```
svemuri@dev15905 ~/rocksdb (fifo-compaction)  $ ls -l /dev/shm//dbbench/*.sst
-rw-r--r--. 1 svemuri users 30749887 Jun 26 15:17 /dev/shm//dbbench/000042.sst
-rw-r--r--. 1 svemuri users 30768779 Jun 26 15:17 /dev/shm//dbbench/000044.sst
-rw-r--r--. 1 svemuri users 30757481 Jun 26 15:17 /dev/shm//dbbench/000046.sst
```
Closes https://github.com/facebook/rocksdb/pull/2480
Differential Revision: D5305116
Pulled By: sagar0
fbshipit-source-id: 3e5cfcf5dd07ed2211b5b37492eb235b45139174/Fix Data Race Between CreateColumnFamily() and GetAggregatedIntProperty()
Summary:
CreateColumnFamily() releases DB mutex after adding column family to the set and install super version (to write option file), so if users call GetAggregatedIntProperty() in the middle, then super version will be null and the process will crash. Fix it by skipping those column families without super version installed.
Maybe we should also fix the problem of releasing the lock when reading option file, but it is more risky. so I'm doing a quick and safer fix and we can investigate it later.
Closes https://github.com/facebook/rocksdb/pull/2475
Differential Revision: D5298053
Pulled By: siying
fbshipit-source-id: 4b3c8f91c60400b163fcc6cda8a0c77723be0ef6/Fix Clang release build broken by 5582123dee8426a5191dfd5e846cea8c676c793c
Summary:
5582123dee8426a5191dfd5e846cea8c676c793c broken CLANG release build because of an unexpected change. Fix it.
Closes https://github.com/facebook/rocksdb/pull/2443
Differential Revision: D5236297
Pulled By: siying
fbshipit-source-id: 1b410adf13ded149c53e8235e9ea9f3130fb5403/Fix interaction between CompactionFilter::Decision::kRemoveAndSkipUnt
Summary:
Fixes the following scenario:
1. Set prefix extractor. Enable bloom filters, with `whole_key_filtering = false`. Use compaction filter that sometimes returns `kRemoveAndSkipUntil`.
2. Do a compaction.
3. Compaction creates an iterator with `total_order_seek = false`, calls `SeekToFirst()` on it, then repeatedly calls `Next()`.
4. At some point compaction filter returns `kRemoveAndSkipUntil`.
5. Compaction calls `Seek(skip_until)` on the iterator. The key that it seeks to happens to have prefix that doesn't match the bloom filter. Since `total_order_seek = false`, iterator becomes invalid, and compaction thinks that it has reached the end. The rest of the compaction input is silently discarded.
The fix is to make compaction iterator use `total_order_seek = true`.
The implementation for PlainTable is quite awkward. I've made `kRemoveAndSkipUntil` officially incompatible with PlainTable. If you try to use them together, compaction will fail, and DB will enter read-only mode (`bg_error_`). That's not a very graceful way to communicate a misconfiguration, but the alternatives don't seem worth the implementation time and complexity. To be able to check in advance that `kRemoveAndSkipUntil` is not going to be used with PlainTable, we'd need to extend the interface of either `CompactionFilter` or `InternalIterator`. It seems unlikely that anyone will ever want to use `kRemoveAndSkipUntil` with PlainTable: PlainTable probably has very few users, and `kRemoveAndSkipUntil` has only one user so far: us (logdevice).
Closes https://github.com/facebook/rocksdb/pull/2349
Differential Revision: D5110388
Pulled By: lightmark
fbshipit-source-id: ec29101a99d9dcd97db33923b87f72bce56cc17a/Fix TSAN: avoid arena mode with range deletions
Summary:
The range deletion meta-block iterators weren't getting cleaned up properly since they don't support arena allocation. I didn't implement arena support since, in the general case, each iterator is used only once and separately from all other iterators, so there should be no benefit to data locality.
Anyways, this diff fixes up #2370 by treating range deletion iterators as non-arena-allocated.
Closes https://github.com/facebook/rocksdb/pull/2399
Differential Revision: D5171119
Pulled By: ajkr
fbshipit-source-id: bef6f5c4c5905a124f4993945aed4bd86e2807d8/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/CodeMod: Prefer ADD_FAILURE() over EXPECT_TRUE(false), et cetera
Summary:
CodeMod: Prefer `ADD_FAILURE()` over `EXPECT_TRUE(false)`, et cetera.
The tautologically-conditioned and tautologically-contradicted boolean expectations/assertions have better alternatives: unconditional passes and failures.
Reviewed By: Orvid
Differential Revision:
D5432398
Tags: codemod, codemod-opensource
fbshipit-source-id: d16b447e8696a6feaa94b41199f5052226ef6914/"
rocksdb,"comment out unused parameters
Summary: This uses `clang-tidy` to comment out unused parameters (in functions, methods and lambdas) in fbcode. Cases that the tool failed to handle are fixed manually.
Reviewed By: igorsugak
Differential Revision: D5454343
fbshipit-source-id: 5dee339b4334e25e963891b519a5aa81fbf627b2/"
rocksdb,"Fix c_test ASAN failure
Summary:
Fix c_test missing deletion of write batch pointer.
Closes https://github.com/facebook/rocksdb/pull/2725
Differential Revision: D5613866
Pulled By: yiwu-arbug
fbshipit-source-id: bf3f59a6812178577c9c25bae558ef36414a1f51/Add column families related functions (C API)
Summary:
(#2564)
Closes https://github.com/facebook/rocksdb/pull/2669
Differential Revision: D5594151
Pulled By: yiwu-arbug
fbshipit-source-id: 67ae9446342f3323d6ecad8e811f4158da194270/Write batch for `TransactionDB` in C API
Summary: Closes https://github.com/facebook/rocksdb/pull/2655
Differential Revision: D5600858
Pulled By: yiwu-arbug
fbshipit-source-id: cf52f9104e348438bf168dc6bf7af3837faf12ef/add Transactions and Checkpoint to C API
Summary:
I've added functions to the C API to support Transactions as requested in #1637 and to support Checkpoint.
I have also added the corresponding tests to c_test.c
For now, the following is omitted:
1. Optimistic Transactions
2. The column family variation of functions
Closes https://github.com/facebook/rocksdb/pull/2236
Differential Revision: D4989510
Pulled By: yiwu-arbug
fbshipit-source-id: 518cb39f76d5e9ec9690d633fcdc014b98958071/C API: support pinnable get
Summary: Closes https://github.com/facebook/rocksdb/pull/2254
Differential Revision: D5053590
Pulled By: yiwu-arbug
fbshipit-source-id: 2f365a031b3a2947b4fba21d26d4f8f52af9b9f0/"
rocksdb,"Replace dynamic_cast<>
Summary:
Replace dynamic_cast<> so that users can choose to build with RTTI off, so that they can save several bytes per object, and get tiny more memory available.
Some nontrivial changes:
1. Add Comparator::GetRootComparator() to get around the internal comparator hack
2. Add the two experiemental functions to DB
3. Add TableFactory::GetOptionString() to avoid unnecessary casting to get the option string
4. Since 3 is done, move the parsing option functions for table factory to table factory files too, to be symmetric.
Closes https://github.com/facebook/rocksdb/pull/2645
Differential Revision: D5502723
Pulled By: siying
fbshipit-source-id: fd13cec5601cf68a554d87bfcf056f2ffa5fbf7c/"
rocksdb,"Implement ReopenWritibaleFile on Windows and other fixes
Summary:
Make default impl return NoSupported so the db_blob
tests exist in a meaningful manner.
Replace std::thread to port::Thread
Closes https://github.com/facebook/rocksdb/pull/2465
Differential Revision: D5275563
Pulled By: yiwu-arbug
fbshipit-source-id: cedf1a18a2c05e20d768c1308b3f3224dbd70ab6/Fix mingw compilation with -DNDEBUG
Summary:
This was exposed by a48a62d, which made NDEBUG the default for cmake
builds.
Closes https://github.com/facebook/rocksdb/pull/2315
Differential Revision: D5079583
Pulled By: sagar0
fbshipit-source-id: c614e96a40df016a834a62b6236852265e7ee4db/"
rocksdb,"Allow upgrades from nullptr to some merge operator
Summary:
Currently, RocksDB does not allow reopening a preexisting DB with no merge operator defined, with a merge operator defined. This means that if a DB ever want to add a merge operator, there's no way to do so currently.
Fix this by adding a new verification type `kByNameAllowFromNull` which will allow old values to be nullptr, and new values to be non-nullptr.
Closes https://github.com/facebook/rocksdb/pull/2958
Differential Revision: D5961131
Pulled By: lth
fbshipit-source-id: 06179bebd0d90db3d43690b5eb7345e2d5bab1eb/"
rocksdb,"Enable MSVC W4 with a few exceptions. Fix warnings and bugs
Summary: Closes https://github.com/facebook/rocksdb/pull/3018
Differential Revision: D6079011
Pulled By: yiwu-arbug
fbshipit-source-id: 988a721e7e7617967859dba71d660fc69f4dff57/rate limit auto-tuning
Summary:
Dynamic adjustment of rate limit according to demand for background I/O. It increases by a factor when limiter is drained too frequently, and decreases by the same factor when limiter is not drained frequently enough. The parameters for this behavior are fixed in `GenericRateLimiter::Tune`. Other changes:
- make rate limiter's `Env*` configurable for testing
- track num drain intervals in RateLimiter so we don't have to rely on stats, which may be shared across different DB instances from the ones that share the RateLimiter.
Closes https://github.com/facebook/rocksdb/pull/2899
Differential Revision: D5858704
Pulled By: ajkr
fbshipit-source-id: cc2bac30f85e7f6fd63655d0a6732ef9ed7403b1/"
rocksdb,"Enable MSVC W4 with a few exceptions. Fix warnings and bugs
Summary: Closes https://github.com/facebook/rocksdb/pull/3018
Differential Revision: D6079011
Pulled By: yiwu-arbug
fbshipit-source-id: 988a721e7e7617967859dba71d660fc69f4dff57/ldb dump can print histogram of value size
Summary:
Make ""ldb dump --count_only"" print histogram of value size. Also, fix a bug that ""ldb dump --path=<db_path>"" doesn't work.
Closes https://github.com/facebook/rocksdb/pull/2944
Differential Revision: D5954527
Pulled By: siying
fbshipit-source-id: c620a444ec544258b8d113f5f663c375dd53d6be/"
rocksdb,"db_stress snapshot compatibility with reopens
Summary:
- Release all snapshots before crashing and reopening the DB. Without this, we may attempt to release snapshots from an old DB using a new DB. That tripped an assertion.
- Release multiple snapshots in the same operation if needed. Without this, we would sometimes leak snapshots.
Closes https://github.com/facebook/rocksdb/pull/3098
Differential Revision: D6194923
Pulled By: ajkr
fbshipit-source-id: b9c89bcca7ebcbb6c7802c616f9d1175a005aadf/support disabling checksum in block-based table
Summary:
store a zero as the checksum when disabled since it's easier to keep block trailer a fixed length.
Closes https://github.com/facebook/rocksdb/pull/2781
Differential Revision: D5694702
Pulled By: ajkr
fbshipit-source-id: 69cea9da415778ba2b600dfd9d0dfc8cb5188ecd/fix db_stress uint64_t to int32 cast
Summary:
Clang complain about an cast from uint64_t to int32 in db_stress. Fixing it.
Closes https://github.com/facebook/rocksdb/pull/2755
Differential Revision: D5655947
Pulled By: yiwu-arbug
fbshipit-source-id: cfac10e796e0adfef4727090b50975b0d6e2c9be/minor improvements to db_stress
Summary:
fix some things that made this command hard to use from CLI:
- use default values for `target_file_size_base` and `max_bytes_for_level_base`. previously we were using small values for these but default value of `write_buffer_size`, which led to enormous number of L1 files.
- failure message for `value_size_mult` too big. previously there was just an assert, so in non-debug mode it'd overrun the value buffer and crash mysteriously.
- only print verification success if there's no failure. before it'd print both in the failure case.
- support `memtable_prefix_bloom_size_ratio`
- support `num_bottom_pri_threads` (universal compaction)
Closes https://github.com/facebook/rocksdb/pull/2741
Differential Revision: D5629495
Pulled By: ajkr
fbshipit-source-id: ddad97d6d4ba0884e7c0f933b0a359712514fc1d/db_stress rolling active window
Summary:
Support a window of `active_width` keys that rolls through `[0, max_key)` over the duration of the test. Operations only affect keys inside the window. This gives us the ability to detect L0->L0 deletion bug (#2722).
Closes https://github.com/facebook/rocksdb/pull/2739
Differential Revision: D5628555
Pulled By: ajkr
fbshipit-source-id: 9cb2d8f4ab1a7c73f7797b8e19f7094970ea8749/"
rocksdb,"Enable MSVC W4 with a few exceptions. Fix warnings and bugs
Summary: Closes https://github.com/facebook/rocksdb/pull/3018
Differential Revision: D6079011
Pulled By: yiwu-arbug
fbshipit-source-id: 988a721e7e7617967859dba71d660fc69f4dff57/Fix naming in InternalKey
Summary:
- Switched all instances of SetMinPossibleForUserKey and SetMaxPossibleForUserKey in accordance to InternalKeyComparator's comparison logic
Closes https://github.com/facebook/rocksdb/pull/2868
Differential Revision: D5804152
Pulled By: axxufb
fbshipit-source-id: 80be35e04f2e8abc35cc64abe1fecb03af24e183/"
rocksdb,"util: Fix coverity issues
Summary:
util/concurrent_arena.h:
CID 1396145 (#1 of 1): Uninitialized pointer field (UNINIT_CTOR)
2. uninit_member: Non-static class member free_begin_ is not initialized in this constructor nor in any functions that it calls.
94    Shard() : allocated_and_unused_(0) {}
util/dynamic_bloom.cc:
1. Condition hash_func == NULL, taking true branch.
CID 1322821 (#1 of 1): Uninitialized pointer field (UNINIT_CTOR)
3. uninit_member: Non-static class member data_ is not initialized in this constructor nor in any functions that it calls.
47      hash_func_(hash_func == nullptr ? &BloomHash : hash_func) {}
48
util/file_reader_writer.h:
204 private:
205  AlignedBuffer buffer_;
member_not_init_in_gen_ctor: The compiler-generated constructor for this class does not initialize buffer_offset_.
206  uint64_t buffer_offset_;
CID 1418246 (#1 of 1): Uninitialized scalar field (UNINIT_CTOR)
member_not_init_in_gen_ctor: The compiler-generated constructor for this class does not initialize buffer_len_.
207  size_t buffer_len_;
208};
util/thread_local.cc:
341#endif
CID 1322795 (#1 of 1): Uninitialized scalar field (UNINIT_CTOR)
3. uninit_member: Non-static class member pthread_key_ is not initialized in this constructor nor in any functions that it calls.
342}
40struct ThreadData {
2. uninit_member: Non-static class member next is not initialized in this constructor nor in any functions that it calls.
CID 1400668 (#1 of 1): Uninitialized pointer field (UNINIT_CTOR)
4. uninit_member: Non-static class member prev is not initialized in this constructor nor in any functions that it calls.
41  explicit ThreadData(ThreadLocalPtr::StaticMeta* _inst) : entries(), inst(_inst) {}
42  std::vector<Entry> entries;
1. member_decl: Class member declaration for next.
43  ThreadData* next;
3. member_decl: Class member declaration for prev.
44  ThreadData* prev;
45  ThreadLocalPtr::StaticMeta* inst;
46};
Closes https://github.com/facebook/rocksdb/pull/3123
Differential Revision: D6233566
Pulled By: sagar0
fbshipit-source-id: aa2068790ea69787a0035c0db39d59b0c25108db/Enable MSVC W4 with a few exceptions. Fix warnings and bugs
Summary: Closes https://github.com/facebook/rocksdb/pull/3018
Differential Revision: D6079011
Pulled By: yiwu-arbug
fbshipit-source-id: 988a721e7e7617967859dba71d660fc69f4dff57/"
rocksdb,"Make bytes_per_sync and wal_bytes_per_sync mutable
Summary:
SUMMARY
Moves the bytes_per_sync and wal_bytes_per_sync options from immutableoptions to mutable options. Also if wal_bytes_per_sync is changed, the wal file and memtables are flushed.
TEST PLAN
ran make check
all passed
Two new tests SetBytesPerSync, SetWalBytesPerSync check that after issuing setoptions with a new value for the var, the db options have the new value.
Closes https://github.com/facebook/rocksdb/pull/2893
Reviewed By: yiwu-arbug
Differential Revision: D5845814
Pulled By: TheRushingWookie
fbshipit-source-id: 93b52d779ce623691b546679dcd984a06d2ad1bd/Repair DBs with trailing slash in name
Summary:
Problem:
- `DB::SanitizeOptions` strips trailing slash from `wal_dir` but not `dbname`
- We check whether `wal_dir` and `dbname` refer to the same directory using string equality: https://github.com/facebook/rocksdb/blob/master/db/repair.cc#L258
- Providing `dbname` with trailing slash causes default `wal_dir` to be misidentified as a separate directory.
- Then the repair tries to add all SST files to the `VersionEdit` twice (once for `dbname` dir, once for `wal_dir`) and fails with coredump.
Solution:
- Add a new `Env` function, `AreFilesSame`, which uses device and inode number to check whether files are the same. It's currently only implemented in `PosixEnv`.
- Migrate repair to use `AreFilesSame` to check whether `dbname` and `wal_dir` are same. If unsupported, falls back to string comparison.
Closes https://github.com/facebook/rocksdb/pull/2827
Differential Revision: D5761349
Pulled By: ajkr
fbshipit-source-id: c839d548678b742af1166d60b09abd94e5476238/"
rocksdb,"Added support for differential snapshots
Summary:
The motivation for this PR is to add to RocksDB support for differential (incremental) snapshots, as snapshot of the DB changes between two points in time (one can think of it as diff between to sequence numbers, or the diff D which can be thought of as an SST file or just set of KVs that can be applied to sequence number S1 to get the database to the state at sequence number S2).
This feature would be useful for various distributed storages layers built on top of RocksDB, as it should help reduce resources (time and network bandwidth) needed to recover and rebuilt DB instances as replicas in the context of distributed storages.
From the API standpoint that would like client app requesting iterator between (start seqnum) and current DB state, and reading the ""diff"".
This is a very draft PR for initial review in the discussion on the approach, i'm going to rework some parts and keep updating the PR.
For now, what's done here according to initial discussions:
Preserving deletes:
- We want to be able to optionally preserve recent deletes for some defined period of time, so that if a delete came in recently and might need to be included in the next incremental snapshot it would't get dropped by a compaction. This is done by adding new param to Options (preserve deletes flag) and new variable to DB Impl where we keep track of the sequence number after which we don't want to drop tombstones, even if they are otherwise eligible for deletion.
- I also added a new API call for clients to be able to advance this cutoff seqnum after which we drop deletes; i assume it's more flexible to let clients control this, since otherwise we'd need to keep some kind of timestamp < -- > seqnum mapping inside the DB, which sounds messy and painful to support. Clients could make use of it by periodically calling GetLatestSequenceNumber(), noting the timestamp, doing some calculation and figuring out by how much we need to advance the cutoff seqnum.
- Compaction codepath in compaction_iterator.cc has been modified to avoid dropping tombstones with seqnum > cutoff seqnum.
Iterator changes:
- couple params added to ReadOptions, to optionally allow client to request internal keys instead of user keys (so that client can get the latest value of a key, be it delete marker or a put), as well as min timestamp and min seqnum.
TableCache changes:
- I modified table_cache code to be able to quickly exclude SST files from iterators heep if creation_time on the file is less then iter_start_ts as passed in ReadOptions. That would help a lot in some DB settings (like reading very recent data only or using FIFO compactions), but not so much for universal compaction with more or less long iterator time span.
What's left:
- Still looking at how to best plug that inside DBIter codepath. So far it seems that FindNextUserKeyInternal only parses values as UserKeys, and iter->key() call generally returns user key. Can we add new API to DBIter as internal_key(), and modify this internal method to optionally set saved_key_ to point to the full internal key? I don't need to store actual seqnum there, but I do need to store type.
Closes https://github.com/facebook/rocksdb/pull/2999
Differential Revision: D6175602
Pulled By: mikhail-antonov
fbshipit-source-id: c779a6696ee2d574d86c69cec866a3ae095aa900/Add DB::Properties::kEstimateOldestKeyTime
Summary:
With FIFO compaction we would like to get the oldest data time for monitoring. The problem is we don't have timestamp for each key in the DB. As an approximation, we expose the earliest of sst file ""creation_time"" property.
My plan is to override the property with a more accurate value with blob db, where we actually have timestamp.
Closes https://github.com/facebook/rocksdb/pull/2842
Differential Revision: D5770600
Pulled By: yiwu-arbug
fbshipit-source-id: 03833c8f10bbfbee62f8ea5c0d03c0cafb5d853a/"
rocksdb,"Added CompactionFilterFactory support to RocksJava
Summary:
This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support.
Closes https://github.com/facebook/rocksdb/pull/1241
Differential Revision: D6012778
Pulled By: sagar0
fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/"
rocksdb,"collecting kValue type tombstone
Summary:
In our testing cluster, we found large amount tombstone has been promoted to kValue type from kMerge after reaching the top level of compaction. Since we used to only collecting tombstone in merge operator, those tombstones can never be collected.
This PR addresses the issue by adding a GC step in compaction filter, which is only for kValue type records. Since those record already reached the top of compaction (no earlier data exists) we can safely remove them in compaction filter without worrying old data appears.
This PR also removes an old optimization in cassandra merge operator for single merge operands.  We need to do GC even on a single operand, so the optimation does not make sense anymore.
Closes https://github.com/facebook/rocksdb/pull/2855
Reviewed By: sagar0
Differential Revision: D5806445
Pulled By: wpc
fbshipit-source-id: 6eb25629d4ce917eb5e8b489f64a6aa78c7d270b/"
rocksdb,"Add iterator's SeekForPrev functionality to the java-api
Summary:
As discussed in #2742 , this pull-requests brings the iterator's [SeekForPrev()](https://github.com/facebook/rocksdb/wiki/SeekForPrev) functionality to the java-api. It affects all locations in the code where previously only Seek() was supported.
All code changes are essentially a copy & paste of the already existing implementations for Seek().
**Please Note**: the changes to the C++ code were applied without fully understanding its effect, so please take a closer look. However, since Seek() and SeekForPrev() provide exactly the same signature, I do not expect any mistake here.
The java-tests are extended by new tests for the additional functionality.
Compilation (`make rocksdbjavastatic`) and test (`java/make test`) run without errors.
Closes https://github.com/facebook/rocksdb/pull/2747
Differential Revision: D5721011
Pulled By: sagar0
fbshipit-source-id: c1f951cddc321592c70dd2d32bc04892f3f119f8/"
rocksdb,"Added CompactionFilterFactory support to RocksJava
Summary:
This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support.
Closes https://github.com/facebook/rocksdb/pull/1241
Differential Revision: D6012778
Pulled By: sagar0
fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/"
rocksdb,"Added CompactionFilterFactory support to RocksJava
Summary:
This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support.
Closes https://github.com/facebook/rocksdb/pull/1241
Differential Revision: D6012778
Pulled By: sagar0
fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/"
rocksdb,"Added CompactionFilterFactory support to RocksJava
Summary:
This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support.
Closes https://github.com/facebook/rocksdb/pull/1241
Differential Revision: D6012778
Pulled By: sagar0
fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/"
rocksdb,"Added CompactionFilterFactory support to RocksJava
Summary:
This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support.
Closes https://github.com/facebook/rocksdb/pull/1241
Differential Revision: D6012778
Pulled By: sagar0
fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/"
rocksdb,"Added CompactionFilterFactory support to RocksJava
Summary:
This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support.
Closes https://github.com/facebook/rocksdb/pull/1241
Differential Revision: D6012778
Pulled By: sagar0
fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/"
rocksdb,"Added CompactionFilterFactory support to RocksJava
Summary:
This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support.
Closes https://github.com/facebook/rocksdb/pull/1241
Differential Revision: D6012778
Pulled By: sagar0
fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/Provide byte[] version of SstFileWriter.merge to reduce GC Stall
Summary:
In Java API, `SstFileWriter.put/merge/delete` takes `Slice` type of key and value, which is a Java wrapper object around C++ Slice object.  The Slice object inherited [ `finalize`](https://github.com/facebook/rocksdb/blob/3c327ac2d0fd50bbd82fe1f1af5de909dad769e6/java/src/main/java/org/rocksdb/AbstractNativeReference.java#L69) method, which [added huge overhead](https://softwareengineering.stackexchange.com/questions/288715/is-overriding-object-finalize-really-bad/288753#288753) to JVM while creating new SstFile.
To address this issue, this PR overload the merge method to take Java byte array instead of the Slice object, and added unit test for it.
We also benchmark these two different merge function, where we could see GC Stall reduced from 50%  to 1%, and the throughput increased from 50MB to 200MB.
Closes https://github.com/facebook/rocksdb/pull/2746
Reviewed By: sagar0
Differential Revision: D5653145
Pulled By: scv119
fbshipit-source-id: b55ea58554b573d0b1c6f6170f8d9223811bc4f5/"
rocksdb,"Add iterator's SeekForPrev functionality to the java-api
Summary:
As discussed in #2742 , this pull-requests brings the iterator's [SeekForPrev()](https://github.com/facebook/rocksdb/wiki/SeekForPrev) functionality to the java-api. It affects all locations in the code where previously only Seek() was supported.
All code changes are essentially a copy & paste of the already existing implementations for Seek().
**Please Note**: the changes to the C++ code were applied without fully understanding its effect, so please take a closer look. However, since Seek() and SeekForPrev() provide exactly the same signature, I do not expect any mistake here.
The java-tests are extended by new tests for the additional functionality.
Compilation (`make rocksdbjavastatic`) and test (`java/make test`) run without errors.
Closes https://github.com/facebook/rocksdb/pull/2747
Differential Revision: D5721011
Pulled By: sagar0
fbshipit-source-id: c1f951cddc321592c70dd2d32bc04892f3f119f8/"
rocksdb,"Added CompactionFilterFactory support to RocksJava
Summary:
This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support.
Closes https://github.com/facebook/rocksdb/pull/1241
Differential Revision: D6012778
Pulled By: sagar0
fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/"
rocksdb,"Added CompactionFilterFactory support to RocksJava
Summary:
This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support.
Closes https://github.com/facebook/rocksdb/pull/1241
Differential Revision: D6012778
Pulled By: sagar0
fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/"
rocksdb,"Added CompactionFilterFactory support to RocksJava
Summary:
This PR also includes some cleanup, bugfixes and refactoring of the Java API. However these are really pre-cursors on the road to CompactionFilterFactory support.
Closes https://github.com/facebook/rocksdb/pull/1241
Differential Revision: D6012778
Pulled By: sagar0
fbshipit-source-id: 0774465940ee99001a78906e4fed4ef57068ad5c/"
rocksdb,"Fix unused var warnings in Release mode
Summary:
MSVC does not support unused attribute at this time. A separate assignment line fixes the issue probably by being counted as usage for MSVC and it no longer complains about unused var.
Closes https://github.com/facebook/rocksdb/pull/3048
Differential Revision: D6126272
Pulled By: maysamyabandeh
fbshipit-source-id: 4907865db45fd75a39a15725c0695aaa17509c1f/"
rocksdb,"Fix CLANG Analyze
Summary:
clang analyze shows warnings after we upgrade the CLANG version. Fix them.
Closes https://github.com/facebook/rocksdb/pull/2839
Differential Revision: D5769060
Pulled By: siying
fbshipit-source-id: 3f8e4df715590d8984f6564b608fa08cfdfa5f14/fix backup engine when latest backup corrupt
Summary:
Backup engine is intentionally openable even when some backups are corrupt. Previously the engine could write new backups as long as the most recent backup wasn't corrupt. This PR makes the backup engine able to create new backups even when the most recent one is corrupt.
We now maintain two ID instance variables:
- `latest_backup_id_` is used when creating backup to choose the new ID
- `latest_valid_backup_id_` is used when restoring latest backup since we want most recent valid one
Closes https://github.com/facebook/rocksdb/pull/2804
Differential Revision: D5734148
Pulled By: ajkr
fbshipit-source-id: db440707b31df2c7b084188aa5f6368449e10bcf/"
rocksdb,"fix deletion-triggered compaction in table builder
Summary:
It was broken when `NotifyCollectTableCollectorsOnFinish` was introduced. That function called `Finish` on each of the `TablePropertiesCollector`s, and `CompactOnDeletionCollector::Finish()` was resetting all its internal state. Then, when we checked whether compaction is necessary, the flag had already been cleared.
Fixed above issue by avoiding resetting internal state during `Finish()`. Multiple calls to `Finish()` are allowed, but callers cannot invoke `AddUserKey()` on the collector after any finishes.
Closes https://github.com/facebook/rocksdb/pull/2936
Differential Revision: D5918659
Pulled By: ajkr
fbshipit-source-id: 4f05e9d80e50ee762ba1e611d8d22620029dca6b/"
rocksdb,"Enable MSVC W4 with a few exceptions. Fix warnings and bugs
Summary: Closes https://github.com/facebook/rocksdb/pull/3018
Differential Revision: D6079011
Pulled By: yiwu-arbug
fbshipit-source-id: 988a721e7e7617967859dba71d660fc69f4dff57/"
rocksdb,"Fix unused var warnings in Release mode
Summary:
MSVC does not support unused attribute at this time. A separate assignment line fixes the issue probably by being counted as usage for MSVC and it no longer complains about unused var.
Closes https://github.com/facebook/rocksdb/pull/3048
Differential Revision: D6126272
Pulled By: maysamyabandeh
fbshipit-source-id: 4907865db45fd75a39a15725c0695aaa17509c1f/"
rocksdb,"collecting kValue type tombstone
Summary:
In our testing cluster, we found large amount tombstone has been promoted to kValue type from kMerge after reaching the top level of compaction. Since we used to only collecting tombstone in merge operator, those tombstones can never be collected.
This PR addresses the issue by adding a GC step in compaction filter, which is only for kValue type records. Since those record already reached the top of compaction (no earlier data exists) we can safely remove them in compaction filter without worrying old data appears.
This PR also removes an old optimization in cassandra merge operator for single merge operands.  We need to do GC even on a single operand, so the optimation does not make sense anymore.
Closes https://github.com/facebook/rocksdb/pull/2855
Reviewed By: sagar0
Differential Revision: D5806445
Pulled By: wpc
fbshipit-source-id: 6eb25629d4ce917eb5e8b489f64a6aa78c7d270b/"
rocksdb,"collecting kValue type tombstone
Summary:
In our testing cluster, we found large amount tombstone has been promoted to kValue type from kMerge after reaching the top level of compaction. Since we used to only collecting tombstone in merge operator, those tombstones can never be collected.
This PR addresses the issue by adding a GC step in compaction filter, which is only for kValue type records. Since those record already reached the top of compaction (no earlier data exists) we can safely remove them in compaction filter without worrying old data appears.
This PR also removes an old optimization in cassandra merge operator for single merge operands.  We need to do GC even on a single operand, so the optimation does not make sense anymore.
Closes https://github.com/facebook/rocksdb/pull/2855
Reviewed By: sagar0
Differential Revision: D5806445
Pulled By: wpc
fbshipit-source-id: 6eb25629d4ce917eb5e8b489f64a6aa78c7d270b/"
rocksdb,"Fix crashes, address test issues and adjust windows test script
Summary:
Add per-exe execution capability
Add fix parsing of groups/tests
Add timer test exclusion
Fix unit tests
Ifdef threadpool specific tests that do not pass on Vista threadpool.
Remove spurious outout from prefix_test so test case listing works
properly.
Fix not using standard test directories results in file creation errors
in sst_dump_test.
BlobDb fixes:
In C++ end() iterators can not be dereferenced. They are not valid.
When deleting blob_db_ set it to nullptr before any other code executes.
Not fixed:. On Windows you can not delete a file while it is open.
[ RUN      ] BlobDBTest.ReadWhileGC
d:\dev\rocksdb\rocksdb\utilities\blob_db\blob_db_test.cc(75): error: DestroyBlobDB(dbname_, options, bdb_options)
IO error: Failed to delete: d:/mnt/db\testrocksdb-17444/blob_db_test/blob_dir/000001.blob: Permission denied
d:\dev\rocksdb\rocksdb\utilities\blob_db\blob_db_test.cc(75): error: DestroyBlobDB(dbname_, options, bdb_options)
IO error: Failed to delete: d:/mnt/db\testrocksdb-17444/blob_db_test/blob_dir/000001.blob: Permission denied
write_batch
Should not call front() if there is a chance the container is empty
Closes https://github.com/facebook/rocksdb/pull/3152
Differential Revision: D6293274
Pulled By: sagar0
fbshipit-source-id: 318c3717c22087fae13b18715dffb24565dbd956/Blob DB: Fix race condition between flush and write
Summary:
A race condition will happen when:
* a user thread writes a value, but it hits the write stop condition because there are too many un-flushed memtables, while holding blob_db_impl.write_mutex_.
* Flush is triggered and call flush begin listener and try to acquire blob_db_impl.write_mutex_.
Fixing it.
Closes https://github.com/facebook/rocksdb/pull/3149
Differential Revision: D6279805
Pulled By: yiwu-arbug
fbshipit-source-id: 0e3c58afb78795ebe3360a2c69e05651e3908c40/Blob DB: use compression in file header instead of global options
Summary:
To fix the issue of failing to decompress existing value after reopen DB with a different compression settings.
Closes https://github.com/facebook/rocksdb/pull/3142
Differential Revision: D6267260
Pulled By: yiwu-arbug
fbshipit-source-id: c7cf7f3e33b0cd25520abf4771cdf9180cc02a5f/Fix PinnableSlice move assignment
Summary:
After move assignment, we need to re-initialized the moved PinnableSlice.
Also update blob_db_impl.cc to not reuse the moved PinnableSlice since it is supposed to be in an undefined state after move.
Closes https://github.com/facebook/rocksdb/pull/3127
Differential Revision: D6238585
Pulled By: yiwu-arbug
fbshipit-source-id: bd99f2e37406c4f7de160c7dee6a2e8126bc224e/Blob DB: Add compaction filter to remove expired blob index entries
Summary:
After adding expiration to blob index in #3066, we are now able to add a compaction filter to cleanup expired blob index entries.
Closes https://github.com/facebook/rocksdb/pull/3090
Differential Revision: D6183812
Pulled By: yiwu-arbug
fbshipit-source-id: 9cb03267a9702975290e758c9c176a2c03530b83/Blob DB: fix snapshot handling
Summary:
Blob db will keep blob file if data in the file is visible to an active snapshot. Before this patch it checks whether there is an active snapshot has sequence number greater than the earliest sequence in the file. This is problematic since we take snapshot on every read, if it keep having reads, old blob files will not be cleanup. Change to check if there is an active snapshot falls in the range of [earliest_sequence, obsolete_sequence) where obsolete sequence is
1. if data is relocated to another file by garbage collection, it is the latest sequence at the time garbage collection finish
2. otherwise, it is the latest sequence of the file
Closes https://github.com/facebook/rocksdb/pull/3087
Differential Revision: D6182519
Pulled By: yiwu-arbug
fbshipit-source-id: cdf4c35281f782eb2a9ad6a87b6727bbdff27a45/Blob DB: option to enable garbage collection
Summary:
Add an option to enable/disable auto garbage collection, where we keep counting how many keys have been evicted by either deletion or compaction and decide whether to garbage collect a blob file.
Default disable auto garbage collection for now since the whole logic is not fully tested and we plan to make major change to it.
Closes https://github.com/facebook/rocksdb/pull/3117
Differential Revision: D6224756
Pulled By: yiwu-arbug
fbshipit-source-id: cdf53bdccec96a4580a2b3a342110ad9e8864dfe/Blob DB: Fix flaky BlobDBTest::GCExpiredKeyWhileOverwriting test
Summary:
The test intent to wait until key being overwritten until proceed with garbage collection. It failed to wait for `PutUntil` finally finish. Fixing it.
Closes https://github.com/facebook/rocksdb/pull/3116
Differential Revision: D6222833
Pulled By: yiwu-arbug
fbshipit-source-id: fa9b57a772b92a66cf250b44e7975c43f62f45c5/Blob DB: cleanup unused options
Summary:
* cleanup num_concurrent_simple_blobs. We don't do concurrent writes (by taking write_mutex_) so it doesn't make sense to have multiple non TTL files open. We can revisit later when we want to improve writes.
* cleanup eviction callback. we don't have plan to use it now.
* rename s/open_simple_blob_files_/open_non_ttl_file_/ and s/open_blob_files_/open_ttl_files_/ to avoid confusion.
Closes https://github.com/facebook/rocksdb/pull/3088
Differential Revision: D6182598
Pulled By: yiwu-arbug
fbshipit-source-id: 99e6f5e01fa66d31309cdb06ce48502464bac6ad/Blob DB: update blob file format
Summary:
Changing blob file format and some code cleanup around the change. The change with blob log format are:
* Remove timestamp field in blob file header, blob file footer and blob records. The field is not being use and often confuse with expiration field.
* Blob file header now come with column family id, which always equal to default column family id. It leaves room for future support of column family.
* Compression field in blob file header now is a standalone byte (instead of compact encode with flags field)
* Blob file footer now come with its own crc.
* Key length now being uint64_t instead of uint32_t
* Blob CRC now checksum both key and value (instead of value only).
* Some reordering of the fields.
The list of cleanups:
* Better inline comments in blob_log_format.h
* rename ttlrange_t and snrange_t to ExpirationRange and SequenceRange respectively.
* simplify blob_db::Reader
* Move crc checking logic to inside blob_log_format.cc
Closes https://github.com/facebook/rocksdb/pull/3081
Differential Revision: D6171304
Pulled By: yiwu-arbug
fbshipit-source-id: e4373e0d39264441b7e2fbd0caba93ddd99ea2af/Blob DB: Inline small values in base DB
Summary:
Adding the `min_blob_size` option to allow storing small values in base db (in LSM tree) together with the key. The goal is to improve performance for small values, while taking advantage of blob db's low write amplification for large values.
Also adding expiration timestamp to blob index. It will be useful to evict stale blob indexes in base db by adding a compaction filter. I'll work on the compaction filter in future patches.
See blob_index.h for the new blob index format. There are 4 cases when writing a new key:
* small value w/o TTL: put in base db as normal value (i.e. ValueType::kTypeValue)
* small value w/ TTL: put (type, expiration, value) to base db.
* large value w/o TTL: write value to blob log and put (type, file, offset, size, compression) to base db.
* large value w/TTL: write value to blob log and put (type, expiration, file, offset, size, compression) to base db.
Closes https://github.com/facebook/rocksdb/pull/3066
Differential Revision: D6142115
Pulled By: yiwu-arbug
fbshipit-source-id: 9526e76e19f0839310a3f5f2a43772a4ad182cd0/Return write error on reaching blob dir size limit
Summary:
I found that we continue accepting writes even when the blob db goes beyond the configured blob directory size limit. Now, we return an error for writes on reaching `blob_dir_size` limit and if `is_fifo` is set to false. (We cannot just drop any file when `is_fifo` is true.)
Deleting the oldest file when `is_fifo` is true will be handled in a later PR.
Closes https://github.com/facebook/rocksdb/pull/3060
Differential Revision: D6136156
Pulled By: sagar0
fbshipit-source-id: 2f11cb3f2eedfa94524fbfa2613dd64bfad7a23c/Fix unused var warnings in Release mode
Summary:
MSVC does not support unused attribute at this time. A separate assignment line fixes the issue probably by being counted as usage for MSVC and it no longer complains about unused var.
Closes https://github.com/facebook/rocksdb/pull/3048
Differential Revision: D6126272
Pulled By: maysamyabandeh
fbshipit-source-id: 4907865db45fd75a39a15725c0695aaa17509c1f/Blob DB: Store blob index as kTypeBlobIndex in base db
Summary:
Blob db insert blob index to base db as kTypeBlobIndex type, to tell apart values written by plain rocksdb or blob db. This is to make it possible to migrate from existing rocksdb to blob db.
Also with the patch blob db garbage collection get away from OptimisticTransaction. Instead it use a custom write callback to achieve similar behavior as OptimisticTransaction. This is because we need to pass the is_blob_index flag to DBImpl::Get but OptimisticTransaction don't support it.
Closes https://github.com/facebook/rocksdb/pull/3000
Differential Revision: D6050044
Pulled By: yiwu-arbug
fbshipit-source-id: 61dc72ab9977625e75f78cd968e7d8a3976e3632/Blob DB: not writing sequence number as blob record footer
Summary:
Previously each time we write a blob we write blog_record_header + key + value + blob_record_footer to blob log. The footer only contains a sequence and a crc for the sequence number. The sequence number was used in garbage collection to verify the value is recent. After #2703 we moved to use optimistic transaction and no longer use sequence number from the footer. Remove the footer altogether.
There's another usage of sequence number and we are keeping it: Each blob log file keep track of sequence number range of keys in it, and use it to check if it is reference by a snapshot, before being deleted.
Closes https://github.com/facebook/rocksdb/pull/3005
Differential Revision: D6057585
Pulled By: yiwu-arbug
fbshipit-source-id: d6da53c457a316e9723f359a1b47facfc3ffe090/Make it explicit blob db doesn't support CF
Summary:
Blob db doesn't currently support column families. Return NotSupported status explicitly.
Closes https://github.com/facebook/rocksdb/pull/2825
Differential Revision: D5757438
Pulled By: yiwu-arbug
fbshipit-source-id: 44de9408fd032c98e8ae337d4db4ed37169bd9fa/make blob file close synchronous
Summary:
Fixing flaky blob_db_test.
To close a blob file, blob db used to add a CloseSeqWrite job to the background thread to close it. Changing file close to be synchronous in order to simplify logic, and fix flaky blob_db_test.
Closes https://github.com/facebook/rocksdb/pull/2787
Differential Revision: D5699387
Pulled By: yiwu-arbug
fbshipit-source-id: dd07a945cd435cd3808fce7ee4ea57817409474a/Blob db create a snapshot before every read
Summary:
If GC kicks in between
* A Get() reads index entry from base db.
* The Get() read from a blob file
The GC can delete the corresponding blob file, making the key not found. Fortunately we have existing logic to avoid deleting a blob file if it is referenced by a snapshot. So the fix is to explicitly create a snapshot before reading index entry from base db.
Closes https://github.com/facebook/rocksdb/pull/2754
Differential Revision: D5655956
Pulled By: yiwu-arbug
fbshipit-source-id: e4ccbc51331362542e7343175bbcbdea5830f544/GC the oldest file when out of space
Summary:
When out of space, blob db should GC the oldest file. The current implementation GC the newest one instead. Fixing it.
Closes https://github.com/facebook/rocksdb/pull/2757
Differential Revision: D5657611
Pulled By: yiwu-arbug
fbshipit-source-id: 56c30a4c52e6ab04551dda8c5c46006d4070b28d/Fix blob db crash during calculating write amp
Summary:
On initial call to BlobDBImpl::WaStats() `all_periods_write_` would be empty, so it will crash when we call pop_front() at line 1627. Apparently it is mean to pop only when `all_periods_write_.size() > kWriteAmplificationStatsPeriods`.
The whole write amp calculation doesn't seems to be correct and it is not being exposed. Will work on it later.
Test Plan
Change kWriteAmplificationStatsPeriodMillisecs to 1000 (1 second) and run db_bench --use_blob_db for 5 minutes.
Closes https://github.com/facebook/rocksdb/pull/2751
Differential Revision: D5648269
Pulled By: yiwu-arbug
fbshipit-source-id: b843d9a09bb5f9e1b713d101ec7b87e54b5115a4/"
rocksdb,"TableProperty::oldest_key_time defaults to 0
Summary:
We don't propagate TableProperty::oldest_key_time on compaction and just write the default value to SST files. It is more natural to default the value to 0.
Also revert db_sst_test back to before #2842.
Closes https://github.com/facebook/rocksdb/pull/3079
Differential Revision: D6165702
Pulled By: yiwu-arbug
fbshipit-source-id: ca3ce5928d96ae79a5beb12bb7d8c640a71478a0/Add DB::Properties::kEstimateOldestKeyTime
Summary:
With FIFO compaction we would like to get the oldest data time for monitoring. The problem is we don't have timestamp for each key in the DB. As an approximation, we expose the earliest of sst file ""creation_time"" property.
My plan is to override the property with a more accurate value with blob db, where we actually have timestamp.
Closes https://github.com/facebook/rocksdb/pull/2842
Differential Revision: D5770600
Pulled By: yiwu-arbug
fbshipit-source-id: 03833c8f10bbfbee62f8ea5c0d03c0cafb5d853a/support disabling checksum in block-based table
Summary:
store a zero as the checksum when disabled since it's easier to keep block trailer a fixed length.
Closes https://github.com/facebook/rocksdb/pull/2781
Differential Revision: D5694702
Pulled By: ajkr
fbshipit-source-id: 69cea9da415778ba2b600dfd9d0dfc8cb5188ecd/"
rocksdb,"Fix for when block.cache_handle is nullptr
Summary:
When using with compressed cache it is possible that the status is ok but the block is not actually added to the block cache. The patch takes this case into account.
Closes https://github.com/facebook/rocksdb/pull/2945
Differential Revision: D5937613
Pulled By: maysamyabandeh
fbshipit-source-id: 5428cf1115e5046b3d01ab78d26cb181122af4c6/prevent nullptr dereference in table reader error case
Summary:
A user encountered segfault on the call to `CacheDependencies()`, probably because `NewIndexIterator()` failed before populating `*index_entry`. Let's avoid the call in that case.
Closes https://github.com/facebook/rocksdb/pull/2939
Differential Revision: D5928611
Pulled By: ajkr
fbshipit-source-id: 484be453dbb00e5e160e9c6a1bc933df7d80f574/fix clang bug in block-based table reader
Summary:
This is the warning that clang considers a bug and has been causing it to fail:
```
table/block_based_table_reader.cc:240:27: warning: Potential leak of memory pointed to by 'block.value'
for (; biter.Valid(); biter.Next()) {
^~~~~
```
Actually clang just doesn't have enough knowledge to statically determine it's safe. We can teach it using an assert.
Closes https://github.com/facebook/rocksdb/pull/2779
Differential Revision: D5691225
Pulled By: ajkr
fbshipit-source-id: 3f0d545bf44636953b30ee5243c63239e8f16d8e/Preload l0 index partitions
Summary:
This fixes the existing logic for pinning l0 index partitions. The patch preloads the partitions into block cache and pin them if they belong to level 0 and pin_l0 is set.
The drawback is that it does many small IOs when preloading all the partitions into the cache is direct io is enabled. Working for a solution for that.
Closes https://github.com/facebook/rocksdb/pull/2661
Differential Revision: D5554010
Pulled By: maysamyabandeh
fbshipit-source-id: 1e6f32a3524d71355c77d4138516dcfb601ca7b2/"
rocksdb,"Allow upgrades from nullptr to some merge operator
Summary:
Currently, RocksDB does not allow reopening a preexisting DB with no merge operator defined, with a merge operator defined. This means that if a DB ever want to add a merge operator, there's no way to do so currently.
Fix this by adding a new verification type `kByNameAllowFromNull` which will allow old values to be nullptr, and new values to be non-nullptr.
Closes https://github.com/facebook/rocksdb/pull/2958
Differential Revision: D5961131
Pulled By: lth
fbshipit-source-id: 06179bebd0d90db3d43690b5eb7345e2d5bab1eb/"
rocksdb,"Preload l0 index partitions
Summary:
This fixes the existing logic for pinning l0 index partitions. The patch preloads the partitions into block cache and pin them if they belong to level 0 and pin_l0 is set.
The drawback is that it does many small IOs when preloading all the partitions into the cache is direct io is enabled. Working for a solution for that.
Closes https://github.com/facebook/rocksdb/pull/2661
Differential Revision: D5554010
Pulled By: maysamyabandeh
fbshipit-source-id: 1e6f32a3524d71355c77d4138516dcfb601ca7b2/"
rocksdb,"Added support for differential snapshots
Summary:
The motivation for this PR is to add to RocksDB support for differential (incremental) snapshots, as snapshot of the DB changes between two points in time (one can think of it as diff between to sequence numbers, or the diff D which can be thought of as an SST file or just set of KVs that can be applied to sequence number S1 to get the database to the state at sequence number S2).
This feature would be useful for various distributed storages layers built on top of RocksDB, as it should help reduce resources (time and network bandwidth) needed to recover and rebuilt DB instances as replicas in the context of distributed storages.
From the API standpoint that would like client app requesting iterator between (start seqnum) and current DB state, and reading the ""diff"".
This is a very draft PR for initial review in the discussion on the approach, i'm going to rework some parts and keep updating the PR.
For now, what's done here according to initial discussions:
Preserving deletes:
- We want to be able to optionally preserve recent deletes for some defined period of time, so that if a delete came in recently and might need to be included in the next incremental snapshot it would't get dropped by a compaction. This is done by adding new param to Options (preserve deletes flag) and new variable to DB Impl where we keep track of the sequence number after which we don't want to drop tombstones, even if they are otherwise eligible for deletion.
- I also added a new API call for clients to be able to advance this cutoff seqnum after which we drop deletes; i assume it's more flexible to let clients control this, since otherwise we'd need to keep some kind of timestamp < -- > seqnum mapping inside the DB, which sounds messy and painful to support. Clients could make use of it by periodically calling GetLatestSequenceNumber(), noting the timestamp, doing some calculation and figuring out by how much we need to advance the cutoff seqnum.
- Compaction codepath in compaction_iterator.cc has been modified to avoid dropping tombstones with seqnum > cutoff seqnum.
Iterator changes:
- couple params added to ReadOptions, to optionally allow client to request internal keys instead of user keys (so that client can get the latest value of a key, be it delete marker or a put), as well as min timestamp and min seqnum.
TableCache changes:
- I modified table_cache code to be able to quickly exclude SST files from iterators heep if creation_time on the file is less then iter_start_ts as passed in ReadOptions. That would help a lot in some DB settings (like reading very recent data only or using FIFO compactions), but not so much for universal compaction with more or less long iterator time span.
What's left:
- Still looking at how to best plug that inside DBIter codepath. So far it seems that FindNextUserKeyInternal only parses values as UserKeys, and iter->key() call generally returns user key. Can we add new API to DBIter as internal_key(), and modify this internal method to optionally set saved_key_ to point to the full internal key? I don't need to store actual seqnum there, but I do need to store type.
Closes https://github.com/facebook/rocksdb/pull/2999
Differential Revision: D6175602
Pulled By: mikhail-antonov
fbshipit-source-id: c779a6696ee2d574d86c69cec866a3ae095aa900/WritePrepared Txn: Compaction/Flush
Summary:
Update Compaction/Flush to support WritePreparedTxnDB: Add SnapshotChecker which is a proxy to query WritePreparedTxnDB::IsInSnapshot. Pass SnapshotChecker to DBImpl on WritePreparedTxnDB open. CompactionIterator use it to check if a key has been committed and if it is visible to a snapshot. In CompactionIterator:
* check if key has been committed. If not, output uncommitted keys AS-IS.
* use SnapshotChecker to check if key is visible to a snapshot when in need.
* do not output key with seq = 0 if the key is not committed.
Closes https://github.com/facebook/rocksdb/pull/2926
Differential Revision: D5902907
Pulled By: yiwu-arbug
fbshipit-source-id: 945e037fdf0aa652dc5ba0ad879461040baa0320/"
rocksdb,"Blob DB: fix snapshot handling
Summary:
Blob db will keep blob file if data in the file is visible to an active snapshot. Before this patch it checks whether there is an active snapshot has sequence number greater than the earliest sequence in the file. This is problematic since we take snapshot on every read, if it keep having reads, old blob files will not be cleanup. Change to check if there is an active snapshot falls in the range of [earliest_sequence, obsolete_sequence) where obsolete sequence is
1. if data is relocated to another file by garbage collection, it is the latest sequence at the time garbage collection finish
2. otherwise, it is the latest sequence of the file
Closes https://github.com/facebook/rocksdb/pull/3087
Differential Revision: D6182519
Pulled By: yiwu-arbug
fbshipit-source-id: cdf4c35281f782eb2a9ad6a87b6727bbdff27a45/Added support for differential snapshots
Summary:
The motivation for this PR is to add to RocksDB support for differential (incremental) snapshots, as snapshot of the DB changes between two points in time (one can think of it as diff between to sequence numbers, or the diff D which can be thought of as an SST file or just set of KVs that can be applied to sequence number S1 to get the database to the state at sequence number S2).
This feature would be useful for various distributed storages layers built on top of RocksDB, as it should help reduce resources (time and network bandwidth) needed to recover and rebuilt DB instances as replicas in the context of distributed storages.
From the API standpoint that would like client app requesting iterator between (start seqnum) and current DB state, and reading the ""diff"".
This is a very draft PR for initial review in the discussion on the approach, i'm going to rework some parts and keep updating the PR.
For now, what's done here according to initial discussions:
Preserving deletes:
- We want to be able to optionally preserve recent deletes for some defined period of time, so that if a delete came in recently and might need to be included in the next incremental snapshot it would't get dropped by a compaction. This is done by adding new param to Options (preserve deletes flag) and new variable to DB Impl where we keep track of the sequence number after which we don't want to drop tombstones, even if they are otherwise eligible for deletion.
- I also added a new API call for clients to be able to advance this cutoff seqnum after which we drop deletes; i assume it's more flexible to let clients control this, since otherwise we'd need to keep some kind of timestamp < -- > seqnum mapping inside the DB, which sounds messy and painful to support. Clients could make use of it by periodically calling GetLatestSequenceNumber(), noting the timestamp, doing some calculation and figuring out by how much we need to advance the cutoff seqnum.
- Compaction codepath in compaction_iterator.cc has been modified to avoid dropping tombstones with seqnum > cutoff seqnum.
Iterator changes:
- couple params added to ReadOptions, to optionally allow client to request internal keys instead of user keys (so that client can get the latest value of a key, be it delete marker or a put), as well as min timestamp and min seqnum.
TableCache changes:
- I modified table_cache code to be able to quickly exclude SST files from iterators heep if creation_time on the file is less then iter_start_ts as passed in ReadOptions. That would help a lot in some DB settings (like reading very recent data only or using FIFO compactions), but not so much for universal compaction with more or less long iterator time span.
What's left:
- Still looking at how to best plug that inside DBIter codepath. So far it seems that FindNextUserKeyInternal only parses values as UserKeys, and iter->key() call generally returns user key. Can we add new API to DBIter as internal_key(), and modify this internal method to optionally set saved_key_ to point to the full internal key? I don't need to store actual seqnum there, but I do need to store type.
Closes https://github.com/facebook/rocksdb/pull/2999
Differential Revision: D6175602
Pulled By: mikhail-antonov
fbshipit-source-id: c779a6696ee2d574d86c69cec866a3ae095aa900/fix tracking oldest snapshot for bottom-level compaction
Summary:
The assertion was caught by `MySQLStyleTransactionTest/MySQLStyleTransactionTest.TransactionStressTest/5` when run in a loop. The caller doesn't track whether the released snapshot is oldest, so let this function handle that case.
Closes https://github.com/facebook/rocksdb/pull/3080
Differential Revision: D6185257
Pulled By: ajkr
fbshipit-source-id: 4b3015c11db5d31e46521a00af568546ef4558cd/Blob DB: Inline small values in base DB
Summary:
Adding the `min_blob_size` option to allow storing small values in base db (in LSM tree) together with the key. The goal is to improve performance for small values, while taking advantage of blob db's low write amplification for large values.
Also adding expiration timestamp to blob index. It will be useful to evict stale blob indexes in base db by adding a compaction filter. I'll work on the compaction filter in future patches.
See blob_index.h for the new blob index format. There are 4 cases when writing a new key:
* small value w/o TTL: put in base db as normal value (i.e. ValueType::kTypeValue)
* small value w/ TTL: put (type, expiration, value) to base db.
* large value w/o TTL: write value to blob log and put (type, file, offset, size, compression) to base db.
* large value w/TTL: write value to blob log and put (type, expiration, file, offset, size, compression) to base db.
Closes https://github.com/facebook/rocksdb/pull/3066
Differential Revision: D6142115
Pulled By: yiwu-arbug
fbshipit-source-id: 9526e76e19f0839310a3f5f2a43772a4ad182cd0/single-file bottom-level compaction when snapshot released
Summary:
When snapshots are held for a long time, files may reach the bottom level containing overwritten/deleted keys. We previously had no mechanism to trigger compaction on such files. This particularly impacted DBs that write to different parts of the keyspace over time, as such files would never be naturally compacted due to second-last level files moving down. This PR introduces a mechanism for bottommost files to be recompacted upon releasing all snapshots that prevent them from dropping their deleted/overwritten keys.
- Changed `CompactionPicker` to compact files in `BottommostFilesMarkedForCompaction()`. These are the last choice when picking. Each file will be compacted alone and output to the same level in which it originated. The goal of this type of compaction is to rewrite the data excluding deleted/overwritten keys.
- Changed `ReleaseSnapshot()` to recompute the bottom files marked for compaction when the oldest existing snapshot changes, and schedule a compaction if needed. We cache the value that oldest existing snapshot needs to exceed in order for another file to be marked in `bottommost_files_mark_threshold_`, which allows us to avoid recomputing marked files for most snapshot releases.
- Changed `VersionStorageInfo` to track the list of bottommost files, which is recomputed every time the version changes by `UpdateBottommostFiles()`. The list of marked bottommost files is first computed in `ComputeBottommostFilesMarkedForCompaction()` when the version changes, but may also be recomputed when `ReleaseSnapshot()` is called.
- Extracted core logic of `Compaction::IsBottommostLevel()` into `VersionStorageInfo::RangeMightExistAfterSortedRun()` since logic to check whether a file is bottommost is now necessary outside of compaction.
Closes https://github.com/facebook/rocksdb/pull/3009
Differential Revision: D6062044
Pulled By: ajkr
fbshipit-source-id: 123d201cf140715a7d5928e8b3cb4f9cd9f7ad21/Enable MSVC W4 with a few exceptions. Fix warnings and bugs
Summary: Closes https://github.com/facebook/rocksdb/pull/3018
Differential Revision: D6079011
Pulled By: yiwu-arbug
fbshipit-source-id: 988a721e7e7617967859dba71d660fc69f4dff57/WritePrepared Txn: Disable GC during recovery
Summary:
Disables GC during recovery of a WritePrepared txn db to avoid GCing uncommitted key values.
Closes https://github.com/facebook/rocksdb/pull/2980
Differential Revision: D6000191
Pulled By: maysamyabandeh
fbshipit-source-id: fc4d522c643d24ebf043f811fe4ecd0dd0294675/Blob DB: Store blob index as kTypeBlobIndex in base db
Summary:
Blob db insert blob index to base db as kTypeBlobIndex type, to tell apart values written by plain rocksdb or blob db. This is to make it possible to migrate from existing rocksdb to blob db.
Also with the patch blob db garbage collection get away from OptimisticTransaction. Instead it use a custom write callback to achieve similar behavior as OptimisticTransaction. This is because we need to pass the is_blob_index flag to DBImpl::Get but OptimisticTransaction don't support it.
Closes https://github.com/facebook/rocksdb/pull/3000
Differential Revision: D6050044
Pulled By: yiwu-arbug
fbshipit-source-id: 61dc72ab9977625e75f78cd968e7d8a3976e3632/fix DBImpl::NewInternalIterator super-version leak on failure
Summary:
Close #2955
Closes https://github.com/facebook/rocksdb/pull/2960
Differential Revision: D5962872
Pulled By: yiwu-arbug
fbshipit-source-id: a6472d5c015bea3dc476c572ff5a5c90259e6059/WritePrepared Txn: Iterator
Summary:
On iterator create, take a snapshot, create a ReadCallback and pass the ReadCallback to the underlying DBIter to check if key is committed.
Closes https://github.com/facebook/rocksdb/pull/2981
Differential Revision: D6001471
Pulled By: yiwu-arbug
fbshipit-source-id: 3565c4cdaf25370ba47008b0e0cb65b31dfe79fe/Add ValueType::kTypeBlobIndex
Summary:
Add kTypeBlobIndex value type, which will be used by blob db only, to insert a (key, blob_offset) KV pair. The purpose is to
1. Make it possible to open existing rocksdb instance as blob db. Existing value will be of kTypeIndex type, while value inserted by blob db will be of kTypeBlobIndex.
2. Make rocksdb able to detect if the db contains value written by blob db, if so return error.
3. Make it possible to have blob db optionally store value in SST file (with kTypeValue type) or as a blob value (with kTypeBlobIndex type).
The root db (DBImpl) basically pretended kTypeBlobIndex are normal value on write. On Get if is_blob is provided, return whether the value read is of kTypeBlobIndex type, or return Status::NotSupported() status if is_blob is not provided. On scan allow_blob flag is pass and if the flag is true, return wether the value is of kTypeBlobIndex type via iter->IsBlob().
Changes on blob db side will be in a separate patch.
Closes https://github.com/facebook/rocksdb/pull/2886
Differential Revision: D5838431
Pulled By: yiwu-arbug
fbshipit-source-id: 3c5306c62bc13bb11abc03422ec5cbcea1203cca/Make bytes_per_sync and wal_bytes_per_sync mutable
Summary:
SUMMARY
Moves the bytes_per_sync and wal_bytes_per_sync options from immutableoptions to mutable options. Also if wal_bytes_per_sync is changed, the wal file and memtables are flushed.
TEST PLAN
ran make check
all passed
Two new tests SetBytesPerSync, SetWalBytesPerSync check that after issuing setoptions with a new value for the var, the db options have the new value.
Closes https://github.com/facebook/rocksdb/pull/2893
Reviewed By: yiwu-arbug
Differential Revision: D5845814
Pulled By: TheRushingWookie
fbshipit-source-id: 93b52d779ce623691b546679dcd984a06d2ad1bd/Fix Get does not return super version on error
Summary:
This is caught when I was testing #2886.
Closes https://github.com/facebook/rocksdb/pull/2907
Differential Revision: D5863153
Pulled By: yiwu-arbug
fbshipit-source-id: 8c54759ba1a0dc101f24ab50423e35731300612d/Fix naming in InternalKey
Summary:
- Switched all instances of SetMinPossibleForUserKey and SetMaxPossibleForUserKey in accordance to InternalKeyComparator's comparison logic
Closes https://github.com/facebook/rocksdb/pull/2868
Differential Revision: D5804152
Pulled By: axxufb
fbshipit-source-id: 80be35e04f2e8abc35cc64abe1fecb03af24e183/Fix CLANG Analyze
Summary:
clang analyze shows warnings after we upgrade the CLANG version. Fix them.
Closes https://github.com/facebook/rocksdb/pull/2839
Differential Revision: D5769060
Pulled By: siying
fbshipit-source-id: 3f8e4df715590d8984f6564b608fa08cfdfa5f14/Fix DropColumnFamily data race
Summary:
It should hold db mutex while accessing max_total_in_memory_state_.
Closes https://github.com/facebook/rocksdb/pull/2784
Differential Revision: D5696536
Pulled By: yiwu-arbug
fbshipit-source-id: 45430634d7fe11909b38e42e5f169f618681c4ee/"
rocksdb,"fix lite build
Summary:
* make `checksum_type_string_map` available for lite
* comment out `FilesPerLevel` in lite mode.
* travis and legocastle lite build also build `all` target and run tests
Closes https://github.com/facebook/rocksdb/pull/3015
Differential Revision: D6069822
Pulled By: yiwu-arbug
fbshipit-source-id: 9fe92ac220e711e9e6ed4e921bd25ef4314796a0/Allow DB reopen with reduced options.num_levels
Summary:
Allow user to reduce number of levels in LSM by issue a full CompactRange() and put the result in a lower level, and then reopen DB with reduced options.num_levels. Previous this will fail on reopen on when recovery replaying the previous MANIFEST and found a historical file was on a higher level than the new options.num_levels. The workaround was after CompactRange(), reopen the DB with old num_levels, which will create a new MANIFEST, and then reopen the DB again with new num_levels.
This patch relax the check of levels during recovery. It allows DB to open if there was a historical file on level > options.num_levels, but was also deleted.
Closes https://github.com/facebook/rocksdb/pull/2740
Differential Revision: D5629354
Pulled By: yiwu-arbug
fbshipit-source-id: 545903f6b36b6083e8cbaf777176aef2f488021d/"
rocksdb,"Added support for differential snapshots
Summary:
The motivation for this PR is to add to RocksDB support for differential (incremental) snapshots, as snapshot of the DB changes between two points in time (one can think of it as diff between to sequence numbers, or the diff D which can be thought of as an SST file or just set of KVs that can be applied to sequence number S1 to get the database to the state at sequence number S2).
This feature would be useful for various distributed storages layers built on top of RocksDB, as it should help reduce resources (time and network bandwidth) needed to recover and rebuilt DB instances as replicas in the context of distributed storages.
From the API standpoint that would like client app requesting iterator between (start seqnum) and current DB state, and reading the ""diff"".
This is a very draft PR for initial review in the discussion on the approach, i'm going to rework some parts and keep updating the PR.
For now, what's done here according to initial discussions:
Preserving deletes:
- We want to be able to optionally preserve recent deletes for some defined period of time, so that if a delete came in recently and might need to be included in the next incremental snapshot it would't get dropped by a compaction. This is done by adding new param to Options (preserve deletes flag) and new variable to DB Impl where we keep track of the sequence number after which we don't want to drop tombstones, even if they are otherwise eligible for deletion.
- I also added a new API call for clients to be able to advance this cutoff seqnum after which we drop deletes; i assume it's more flexible to let clients control this, since otherwise we'd need to keep some kind of timestamp < -- > seqnum mapping inside the DB, which sounds messy and painful to support. Clients could make use of it by periodically calling GetLatestSequenceNumber(), noting the timestamp, doing some calculation and figuring out by how much we need to advance the cutoff seqnum.
- Compaction codepath in compaction_iterator.cc has been modified to avoid dropping tombstones with seqnum > cutoff seqnum.
Iterator changes:
- couple params added to ReadOptions, to optionally allow client to request internal keys instead of user keys (so that client can get the latest value of a key, be it delete marker or a put), as well as min timestamp and min seqnum.
TableCache changes:
- I modified table_cache code to be able to quickly exclude SST files from iterators heep if creation_time on the file is less then iter_start_ts as passed in ReadOptions. That would help a lot in some DB settings (like reading very recent data only or using FIFO compactions), but not so much for universal compaction with more or less long iterator time span.
What's left:
- Still looking at how to best plug that inside DBIter codepath. So far it seems that FindNextUserKeyInternal only parses values as UserKeys, and iter->key() call generally returns user key. Can we add new API to DBIter as internal_key(), and modify this internal method to optionally set saved_key_ to point to the full internal key? I don't need to store actual seqnum there, but I do need to store type.
Closes https://github.com/facebook/rocksdb/pull/2999
Differential Revision: D6175602
Pulled By: mikhail-antonov
fbshipit-source-id: c779a6696ee2d574d86c69cec866a3ae095aa900/Fix build on OpenBSD
Summary:
A few simple changes to allow RocksDB to be built on OpenBSD. Let me know if any further changes are needed.
Closes https://github.com/facebook/rocksdb/pull/3061
Differential Revision: D6138800
Pulled By: ajkr
fbshipit-source-id: a13a17b5dc051e6518bd56a8c5efd1d24dd81b0c/Enable MSVC W4 with a few exceptions. Fix warnings and bugs
Summary: Closes https://github.com/facebook/rocksdb/pull/3018
Differential Revision: D6079011
Pulled By: yiwu-arbug
fbshipit-source-id: 988a721e7e7617967859dba71d660fc69f4dff57/"
rocksdb,"Make bytes_per_sync and wal_bytes_per_sync mutable
Summary:
SUMMARY
Moves the bytes_per_sync and wal_bytes_per_sync options from immutableoptions to mutable options. Also if wal_bytes_per_sync is changed, the wal file and memtables are flushed.
TEST PLAN
ran make check
all passed
Two new tests SetBytesPerSync, SetWalBytesPerSync check that after issuing setoptions with a new value for the var, the db options have the new value.
Closes https://github.com/facebook/rocksdb/pull/2893
Reviewed By: yiwu-arbug
Differential Revision: D5845814
Pulled By: TheRushingWookie
fbshipit-source-id: 93b52d779ce623691b546679dcd984a06d2ad1bd/Added save points for transactions C API
Summary:
Added possibility to set save points in transactions and then rollback to them
Closes https://github.com/facebook/rocksdb/pull/2876
Differential Revision: D5825829
Pulled By: yiwu-arbug
fbshipit-source-id: 62168992340bbcddecdaea3baa2a678475d1429d/Additions for `OptimisticTransactionDB` in C API
Summary:
Added some bindings for `OptimisticTransactionDB` in C API
Closes https://github.com/facebook/rocksdb/pull/2823
Differential Revision: D5820672
Pulled By: yiwu-arbug
fbshipit-source-id: 7efd17f619cc0741feddd2050b8fc856f9288350/Improved transactions support in C API
Summary:
Solves #2632
Added OptimisticTransactionDB to the C API.
Added missing merge operations to Transaction.
Added missing get_for_update operation to transaction
If required I will create tests for this another day.
Closes https://github.com/facebook/rocksdb/pull/2633
Differential Revision: D5600906
Pulled By: yiwu-arbug
fbshipit-source-id: da23e4484433d8f59d471f778ff2ae210e3fe4eb/"
rocksdb,"Add DB::Properties::kEstimateOldestKeyTime
Summary:
With FIFO compaction we would like to get the oldest data time for monitoring. The problem is we don't have timestamp for each key in the DB. As an approximation, we expose the earliest of sst file ""creation_time"" property.
My plan is to override the property with a more accurate value with blob db, where we actually have timestamp.
Closes https://github.com/facebook/rocksdb/pull/2842
Differential Revision: D5770600
Pulled By: yiwu-arbug
fbshipit-source-id: 03833c8f10bbfbee62f8ea5c0d03c0cafb5d853a/WritePrepared Txn: Compaction/Flush
Summary:
Update Compaction/Flush to support WritePreparedTxnDB: Add SnapshotChecker which is a proxy to query WritePreparedTxnDB::IsInSnapshot. Pass SnapshotChecker to DBImpl on WritePreparedTxnDB open. CompactionIterator use it to check if a key has been committed and if it is visible to a snapshot. In CompactionIterator:
* check if key has been committed. If not, output uncommitted keys AS-IS.
* use SnapshotChecker to check if key is visible to a snapshot when in need.
* do not output key with seq = 0 if the key is not committed.
Closes https://github.com/facebook/rocksdb/pull/2926
Differential Revision: D5902907
Pulled By: yiwu-arbug
fbshipit-source-id: 945e037fdf0aa652dc5ba0ad879461040baa0320/"
rocksdb,"single-file bottom-level compaction when snapshot released
Summary:
When snapshots are held for a long time, files may reach the bottom level containing overwritten/deleted keys. We previously had no mechanism to trigger compaction on such files. This particularly impacted DBs that write to different parts of the keyspace over time, as such files would never be naturally compacted due to second-last level files moving down. This PR introduces a mechanism for bottommost files to be recompacted upon releasing all snapshots that prevent them from dropping their deleted/overwritten keys.
- Changed `CompactionPicker` to compact files in `BottommostFilesMarkedForCompaction()`. These are the last choice when picking. Each file will be compacted alone and output to the same level in which it originated. The goal of this type of compaction is to rewrite the data excluding deleted/overwritten keys.
- Changed `ReleaseSnapshot()` to recompute the bottom files marked for compaction when the oldest existing snapshot changes, and schedule a compaction if needed. We cache the value that oldest existing snapshot needs to exceed in order for another file to be marked in `bottommost_files_mark_threshold_`, which allows us to avoid recomputing marked files for most snapshot releases.
- Changed `VersionStorageInfo` to track the list of bottommost files, which is recomputed every time the version changes by `UpdateBottommostFiles()`. The list of marked bottommost files is first computed in `ComputeBottommostFilesMarkedForCompaction()` when the version changes, but may also be recomputed when `ReleaseSnapshot()` is called.
- Extracted core logic of `Compaction::IsBottommostLevel()` into `VersionStorageInfo::RangeMightExistAfterSortedRun()` since logic to check whether a file is bottommost is now necessary outside of compaction.
Closes https://github.com/facebook/rocksdb/pull/3009
Differential Revision: D6062044
Pulled By: ajkr
fbshipit-source-id: 123d201cf140715a7d5928e8b3cb4f9cd9f7ad21/Add DB::Properties::kEstimateOldestKeyTime
Summary:
With FIFO compaction we would like to get the oldest data time for monitoring. The problem is we don't have timestamp for each key in the DB. As an approximation, we expose the earliest of sst file ""creation_time"" property.
My plan is to override the property with a more accurate value with blob db, where we actually have timestamp.
Closes https://github.com/facebook/rocksdb/pull/2842
Differential Revision: D5770600
Pulled By: yiwu-arbug
fbshipit-source-id: 03833c8f10bbfbee62f8ea5c0d03c0cafb5d853a/compaction picker to use max_bytes_for_level_multiplier_additional
Summary:
Hi,
As part of some optimization, we're using multiple DB locations (tmpfs and spindle) to store data and configured max_bytes_for_level_multiplier_additional. But, max_bytes_for_level_multiplier_additional is not used to compute the actual size for the level while picking the DB location. So, even if DB location does not have space, RocksDB mistakenly puts the level at that location.
Can someone pls. verify the fix? Let me know any other changes required.
Thanks,
Jay
Closes https://github.com/facebook/rocksdb/pull/2704
Differential Revision: D5992515
Pulled By: ajkr
fbshipit-source-id: cbbc6c0e0a7dbdca91c72e0f37b218c4cec57e28/Use L1 size as estimate for L0 size in LevelCompactionBuilder::GetPathID
Summary:
Fix for [2461](https://github.com/facebook/rocksdb/issues/2461).
Problem: When using multiple db_paths setting with RocksDB, RocksDB incorrectly calculates the size of L1 in LevelCompactionBuilder::GetPathId.
max_bytes_for_level_base is used as L0 size and L1 size is calculated as (L0 size * max_bytes_for_level_multiplier). However, L1 size should be max_bytes_for_level_base.
Solution: Use max_bytes_for_level_base as L1 size. Also, use L1 size as the estimated size of L0.
Closes https://github.com/facebook/rocksdb/pull/2903
Differential Revision: D5885442
Pulled By: maysamyabandeh
fbshipit-source-id: 036da1c9298d173b9b80479cc6661ee4b7a951f6/fix hanging after CompactFiles with L0 overlap
Summary:
Bug report: https://www.facebook.com/groups/rocksdb.dev/permalink/1389452781153232/
Non-empty `level0_compactions_in_progress_` was aborting `CompactFiles` after incrementing `bg_compaction_scheduled_`, and in that case we never decremented it. This blocked future compactions and prevented DB close as we wait for scheduled compactions to finish/abort during close.
I eliminated `CompactFiles`'s dependency on `level0_compactions_in_progress_`. Since it takes a contiguous span of L0 files -- through the last L0 file if any L1+ files are included -- it's fine to run in parallel with other compactions involving L0. We make the same assumption in intra-L0 compaction.
Closes https://github.com/facebook/rocksdb/pull/2849
Differential Revision: D5780440
Pulled By: ajkr
fbshipit-source-id: 15b15d3faf5a699aed4b82a58352d4a7bb23e027/fix CompactFiles inclusion of older L0 files
Summary:
if we're moving any L0 files down, we need to include older L0 files since they may contain older versions of the keys being moved down.
Closes https://github.com/facebook/rocksdb/pull/2845
Differential Revision: D5773800
Pulled By: ajkr
fbshipit-source-id: 9f0770a8eaaeea4c87df2e7a2a1d65bf9d7f4f7e/"
rocksdb,"TableProperty::oldest_key_time defaults to 0
Summary:
We don't propagate TableProperty::oldest_key_time on compaction and just write the default value to SST files. It is more natural to default the value to 0.
Also revert db_sst_test back to before #2842.
Closes https://github.com/facebook/rocksdb/pull/3079
Differential Revision: D6165702
Pulled By: yiwu-arbug
fbshipit-source-id: ca3ce5928d96ae79a5beb12bb7d8c640a71478a0/Add DB::Properties::kEstimateOldestKeyTime
Summary:
With FIFO compaction we would like to get the oldest data time for monitoring. The problem is we don't have timestamp for each key in the DB. As an approximation, we expose the earliest of sst file ""creation_time"" property.
My plan is to override the property with a more accurate value with blob db, where we actually have timestamp.
Closes https://github.com/facebook/rocksdb/pull/2842
Differential Revision: D5770600
Pulled By: yiwu-arbug
fbshipit-source-id: 03833c8f10bbfbee62f8ea5c0d03c0cafb5d853a/"
rocksdb,"Add DB::Properties::kEstimateOldestKeyTime
Summary:
With FIFO compaction we would like to get the oldest data time for monitoring. The problem is we don't have timestamp for each key in the DB. As an approximation, we expose the earliest of sst file ""creation_time"" property.
My plan is to override the property with a more accurate value with blob db, where we actually have timestamp.
Closes https://github.com/facebook/rocksdb/pull/2842
Differential Revision: D5770600
Pulled By: yiwu-arbug
fbshipit-source-id: 03833c8f10bbfbee62f8ea5c0d03c0cafb5d853a/"
rocksdb,"fix duplicate definition of GetEntryType()
Summary:
It's also defined in db/dbformat.cc per 7fe3b32896ecbb21d67ec52fccb713cb9bc6a644
Closes https://github.com/facebook/rocksdb/pull/3111
Differential Revision: D6219140
Pulled By: ajkr
fbshipit-source-id: 0f2b14e41457334a4665c6b7e3f42f1a060a0f35/"
rocksdb,"Enable MSVC W4 with a few exceptions. Fix warnings and bugs
Summary: Closes https://github.com/facebook/rocksdb/pull/3018
Differential Revision: D6079011
Pulled By: yiwu-arbug
fbshipit-source-id: 988a721e7e7617967859dba71d660fc69f4dff57/"
rocksdb,"WritePrepared Txn: Iterator
Summary:
On iterator create, take a snapshot, create a ReadCallback and pass the ReadCallback to the underlying DBIter to check if key is committed.
Closes https://github.com/facebook/rocksdb/pull/2981
Differential Revision: D6001471
Pulled By: yiwu-arbug
fbshipit-source-id: 3565c4cdaf25370ba47008b0e0cb65b31dfe79fe/"
rocksdb,"Add DB::Properties::kEstimateOldestKeyTime
Summary:
With FIFO compaction we would like to get the oldest data time for monitoring. The problem is we don't have timestamp for each key in the DB. As an approximation, we expose the earliest of sst file ""creation_time"" property.
My plan is to override the property with a more accurate value with blob db, where we actually have timestamp.
Closes https://github.com/facebook/rocksdb/pull/2842
Differential Revision: D5770600
Pulled By: yiwu-arbug
fbshipit-source-id: 03833c8f10bbfbee62f8ea5c0d03c0cafb5d853a/"
rocksdb,"dynamically change current memtable size
Summary:
Previously setting `write_buffer_size` with `SetOptions` would only apply to new memtables. An internal user wanted it to take effect immediately, instead of at an arbitrary future point, to prevent OOM.
This PR makes the memtable's size mutable, and makes `SetOptions()` mutate it. There is one case when we preserve the old behavior, which is when memtable prefix bloom filter is enabled and the user is increasing the memtable's capacity. That's because the prefix bloom filter's size is fixed and wouldn't work as well on a larger memtable.
Closes https://github.com/facebook/rocksdb/pull/3119
Differential Revision: D6228304
Pulled By: ajkr
fbshipit-source-id: e44bd9d10a5f8c9d8c464bf7436070bb3eafdfc9/Added support for differential snapshots
Summary:
The motivation for this PR is to add to RocksDB support for differential (incremental) snapshots, as snapshot of the DB changes between two points in time (one can think of it as diff between to sequence numbers, or the diff D which can be thought of as an SST file or just set of KVs that can be applied to sequence number S1 to get the database to the state at sequence number S2).
This feature would be useful for various distributed storages layers built on top of RocksDB, as it should help reduce resources (time and network bandwidth) needed to recover and rebuilt DB instances as replicas in the context of distributed storages.
From the API standpoint that would like client app requesting iterator between (start seqnum) and current DB state, and reading the ""diff"".
This is a very draft PR for initial review in the discussion on the approach, i'm going to rework some parts and keep updating the PR.
For now, what's done here according to initial discussions:
Preserving deletes:
- We want to be able to optionally preserve recent deletes for some defined period of time, so that if a delete came in recently and might need to be included in the next incremental snapshot it would't get dropped by a compaction. This is done by adding new param to Options (preserve deletes flag) and new variable to DB Impl where we keep track of the sequence number after which we don't want to drop tombstones, even if they are otherwise eligible for deletion.
- I also added a new API call for clients to be able to advance this cutoff seqnum after which we drop deletes; i assume it's more flexible to let clients control this, since otherwise we'd need to keep some kind of timestamp < -- > seqnum mapping inside the DB, which sounds messy and painful to support. Clients could make use of it by periodically calling GetLatestSequenceNumber(), noting the timestamp, doing some calculation and figuring out by how much we need to advance the cutoff seqnum.
- Compaction codepath in compaction_iterator.cc has been modified to avoid dropping tombstones with seqnum > cutoff seqnum.
Iterator changes:
- couple params added to ReadOptions, to optionally allow client to request internal keys instead of user keys (so that client can get the latest value of a key, be it delete marker or a put), as well as min timestamp and min seqnum.
TableCache changes:
- I modified table_cache code to be able to quickly exclude SST files from iterators heep if creation_time on the file is less then iter_start_ts as passed in ReadOptions. That would help a lot in some DB settings (like reading very recent data only or using FIFO compactions), but not so much for universal compaction with more or less long iterator time span.
What's left:
- Still looking at how to best plug that inside DBIter codepath. So far it seems that FindNextUserKeyInternal only parses values as UserKeys, and iter->key() call generally returns user key. Can we add new API to DBIter as internal_key(), and modify this internal method to optionally set saved_key_ to point to the full internal key? I don't need to store actual seqnum there, but I do need to store type.
Closes https://github.com/facebook/rocksdb/pull/2999
Differential Revision: D6175602
Pulled By: mikhail-antonov
fbshipit-source-id: c779a6696ee2d574d86c69cec866a3ae095aa900/Return Status::InvalidArgument if user request sync write while disabling WAL
Summary:
write_options.sync = true and write_options.disableWAL is incompatible. When WAL is disabled, we are not able to persist the write immediately. Return an error in this case to avoid misuse of the options.
Closes https://github.com/facebook/rocksdb/pull/3086
Differential Revision: D6176822
Pulled By: yiwu-arbug
fbshipit-source-id: 1eb10028c14fe7d7c13c8bc12c0ef659f75aa071/Exclude DBTest.DynamicFIFOCompactionOptions test under RocksDB Lite
Summary:
This test shouldn't be enabled under the lite version; and this fixes the failing contrun test due to #3006.
Closes https://github.com/facebook/rocksdb/pull/3056
Differential Revision: D6114681
Pulled By: sagar0
fbshipit-source-id: dc5243549ae6b1353cec7edb820c771d95f66dda/Fix false removal of tombstone issue in FIFO and kCompactionStyleNone
Summary:
Similar to the bug fixed by https://github.com/facebook/rocksdb/pull/2726, FIFO with compaction and kCompactionStyleNone during user customized CompactFiles() with output level to be 0 can suffer from the same problem. Fix it by leveraging the bottommost_level_ flag.
Closes https://github.com/facebook/rocksdb/pull/2735
Differential Revision: D5626906
Pulled By: siying
fbshipit-source-id: 2b148d0461c61dbd986d74655e384419ae442158/"
rocksdb,"single-file bottom-level compaction when snapshot released
Summary:
When snapshots are held for a long time, files may reach the bottom level containing overwritten/deleted keys. We previously had no mechanism to trigger compaction on such files. This particularly impacted DBs that write to different parts of the keyspace over time, as such files would never be naturally compacted due to second-last level files moving down. This PR introduces a mechanism for bottommost files to be recompacted upon releasing all snapshots that prevent them from dropping their deleted/overwritten keys.
- Changed `CompactionPicker` to compact files in `BottommostFilesMarkedForCompaction()`. These are the last choice when picking. Each file will be compacted alone and output to the same level in which it originated. The goal of this type of compaction is to rewrite the data excluding deleted/overwritten keys.
- Changed `ReleaseSnapshot()` to recompute the bottom files marked for compaction when the oldest existing snapshot changes, and schedule a compaction if needed. We cache the value that oldest existing snapshot needs to exceed in order for another file to be marked in `bottommost_files_mark_threshold_`, which allows us to avoid recomputing marked files for most snapshot releases.
- Changed `VersionStorageInfo` to track the list of bottommost files, which is recomputed every time the version changes by `UpdateBottommostFiles()`. The list of marked bottommost files is first computed in `ComputeBottommostFilesMarkedForCompaction()` when the version changes, but may also be recomputed when `ReleaseSnapshot()` is called.
- Extracted core logic of `Compaction::IsBottommostLevel()` into `VersionStorageInfo::RangeMightExistAfterSortedRun()` since logic to check whether a file is bottommost is now necessary outside of compaction.
Closes https://github.com/facebook/rocksdb/pull/3009
Differential Revision: D6062044
Pulled By: ajkr
fbshipit-source-id: 123d201cf140715a7d5928e8b3cb4f9cd9f7ad21/Fix unused var warnings in Release mode
Summary:
MSVC does not support unused attribute at this time. A separate assignment line fixes the issue probably by being counted as usage for MSVC and it no longer complains about unused var.
Closes https://github.com/facebook/rocksdb/pull/3048
Differential Revision: D6126272
Pulled By: maysamyabandeh
fbshipit-source-id: 4907865db45fd75a39a15725c0695aaa17509c1f/fix file numbers after repair
Summary:
The file numbers assigned post-repair were sometimes smaller than older files' numbers due to `LogAndApply` saving the wrong next file number in the manifest.
- Mark the highest file seen during repair as used before `LogAndApply` so the correct next file number will be stored.
- Renamed `MarkFileNumberUsedDuringRecovery` to `MarkFileNumberUsed` since now it's used during repair in addition to during recovery
- Added `TEST_Current_Next_FileNo` to expose the next file number for the unit test.
Closes https://github.com/facebook/rocksdb/pull/2988
Differential Revision: D6018083
Pulled By: ajkr
fbshipit-source-id: 3f25cbf74439cb8f16dd12af90b67f9f9f75e718/Add ValueType::kTypeBlobIndex
Summary:
Add kTypeBlobIndex value type, which will be used by blob db only, to insert a (key, blob_offset) KV pair. The purpose is to
1. Make it possible to open existing rocksdb instance as blob db. Existing value will be of kTypeIndex type, while value inserted by blob db will be of kTypeBlobIndex.
2. Make rocksdb able to detect if the db contains value written by blob db, if so return error.
3. Make it possible to have blob db optionally store value in SST file (with kTypeValue type) or as a blob value (with kTypeBlobIndex type).
The root db (DBImpl) basically pretended kTypeBlobIndex are normal value on write. On Get if is_blob is provided, return whether the value read is of kTypeBlobIndex type, or return Status::NotSupported() status if is_blob is not provided. On scan allow_blob flag is pass and if the flag is true, return wether the value is of kTypeBlobIndex type via iter->IsBlob().
Changes on blob db side will be in a separate patch.
Closes https://github.com/facebook/rocksdb/pull/2886
Differential Revision: D5838431
Pulled By: yiwu-arbug
fbshipit-source-id: 3c5306c62bc13bb11abc03422ec5cbcea1203cca/Fix naming in InternalKey
Summary:
- Switched all instances of SetMinPossibleForUserKey and SetMaxPossibleForUserKey in accordance to InternalKeyComparator's comparison logic
Closes https://github.com/facebook/rocksdb/pull/2868
Differential Revision: D5804152
Pulled By: axxufb
fbshipit-source-id: 80be35e04f2e8abc35cc64abe1fecb03af24e183/Allow DB reopen with reduced options.num_levels
Summary:
Allow user to reduce number of levels in LSM by issue a full CompactRange() and put the result in a lower level, and then reopen DB with reduced options.num_levels. Previous this will fail on reopen on when recovery replaying the previous MANIFEST and found a historical file was on a higher level than the new options.num_levels. The workaround was after CompactRange(), reopen the DB with old num_levels, which will create a new MANIFEST, and then reopen the DB again with new num_levels.
This patch relax the check of levels during recovery. It allows DB to open if there was a historical file on level > options.num_levels, but was also deleted.
Closes https://github.com/facebook/rocksdb/pull/2740
Differential Revision: D5629354
Pulled By: yiwu-arbug
fbshipit-source-id: 545903f6b36b6083e8cbaf777176aef2f488021d/"
rocksdb,"Enable MSVC W4 with a few exceptions. Fix warnings and bugs
Summary: Closes https://github.com/facebook/rocksdb/pull/3018
Differential Revision: D6079011
Pulled By: yiwu-arbug
fbshipit-source-id: 988a721e7e7617967859dba71d660fc69f4dff57/"
rocksdb,"Added save points for transactions C API
Summary:
Added possibility to set save points in transactions and then rollback to them
Closes https://github.com/facebook/rocksdb/pull/2876
Differential Revision: D5825829
Pulled By: yiwu-arbug
fbshipit-source-id: 62168992340bbcddecdaea3baa2a678475d1429d/Fix use-after-free in c_tset
Summary:
Fix asan error introduce by #2823
Closes https://github.com/facebook/rocksdb/pull/2879
Differential Revision: D5828454
Pulled By: yiwu-arbug
fbshipit-source-id: 50777855667f4e7b634279a654c3bfa01a1ac729/Additions for `OptimisticTransactionDB` in C API
Summary:
Added some bindings for `OptimisticTransactionDB` in C API
Closes https://github.com/facebook/rocksdb/pull/2823
Differential Revision: D5820672
Pulled By: yiwu-arbug
fbshipit-source-id: 7efd17f619cc0741feddd2050b8fc856f9288350/"
rocksdb,"Fix unused var warnings in Release mode
Summary:
MSVC does not support unused attribute at this time. A separate assignment line fixes the issue probably by being counted as usage for MSVC and it no longer complains about unused var.
Closes https://github.com/facebook/rocksdb/pull/3048
Differential Revision: D6126272
Pulled By: maysamyabandeh
fbshipit-source-id: 4907865db45fd75a39a15725c0695aaa17509c1f/Enable MSVC W4 with a few exceptions. Fix warnings and bugs
Summary: Closes https://github.com/facebook/rocksdb/pull/3018
Differential Revision: D6079011
Pulled By: yiwu-arbug
fbshipit-source-id: 988a721e7e7617967859dba71d660fc69f4dff57/"
rocksdb,"Fix unused var warnings in Release mode
Summary:
MSVC does not support unused attribute at this time. A separate assignment line fixes the issue probably by being counted as usage for MSVC and it no longer complains about unused var.
Closes https://github.com/facebook/rocksdb/pull/3048
Differential Revision: D6126272
Pulled By: maysamyabandeh
fbshipit-source-id: 4907865db45fd75a39a15725c0695aaa17509c1f/"
rocksdb,"db_bench: sanity check CuckooTable with mmap_read option
Summary:
This is to avoid run time error. Fail the db_bench immediately if cuckoo table is used but mmap_read is not specified.
Closes https://github.com/facebook/rocksdb/pull/3420
Differential Revision: D6838284
Pulled By: siying
fbshipit-source-id: 20893fa28d40fadc31e4ff154bed02f5a1bad341/fix db_bench filluniquerandom key count assertion
Summary:
It failed every time. I guess people usually ran with assertions disabled.
Closes https://github.com/facebook/rocksdb/pull/3422
Differential Revision: D6822984
Pulled By: ajkr
fbshipit-source-id: 2e90db75618b26ac1c46ddfa9e03c095c7bf16e3/Fix db_bench write being disabled in lite build
Summary:
The macro was added by mistake in #2372
Closes https://github.com/facebook/rocksdb/pull/3343
Differential Revision: D6681356
Pulled By: yiwu-arbug
fbshipit-source-id: 4180172fb0eaef4189c07f219241e0c261c03461/Port 3 way SSE4.2 crc32c implementation from Folly
Summary:
**# Summary**
RocksDB uses SSE crc32 intrinsics to calculate the crc32 values but it does it in single way fashion (not pipelined on single CPU core). Intel's whitepaper () published an algorithm that uses 3-way pipelining for the crc32 intrinsics, then use pclmulqdq intrinsic to combine the values. Because pclmulqdq has overhead on its own, this algorithm will show perf gains on buffers larger than 216 bytes, which makes RocksDB a perfect user, since most of the buffers RocksDB call crc32c on is over 4KB. Initial db_bench show tremendous CPU gain.
This change uses the 3-way SSE algorithm by default. The old SSE algorithm is now behind a compiler tag NO_THREEWAY_CRC32C. If user compiles the code with NO_THREEWAY_CRC32C=1 then the old SSE Crc32c algorithm would be used. If the server does not have SSE4.2 at the run time the slow way (Non SSE) will be used.
**# Performance Test Results**
We ran the FillRandom and ReadRandom benchmarks in db_bench. ReadRandom is the point of interest here since it calculates the CRC32 for the in-mem buffers. We did 3 runs for each algorithm.
Before this change the CRC32 value computation takes about 11.5% of total CPU cost, and with the new 3-way algorithm it reduced to around 4.5%. The overall throughput also improved from 25.53MB/s to 27.63MB/s.
1) ReadRandom in db_bench overall metrics
PER RUN
Algorithm | run | micros/op | ops/sec |Throughput (MB/s)
3-way      |  1   | 4.143   | 241387 | 26.7
3-way      |  2   | 3.775   | 264872 | 29.3
3-way      | 3    | 4.116   | 242929 | 26.9
FastCrc32c|1  | 4.037   | 247727 | 27.4
FastCrc32c|2  | 4.648   | 215166 | 23.8
FastCrc32c|3  | 4.352   | 229799 | 25.4
AVG
Algorithm     |    Average of micros/op |   Average of ops/sec |    Average of Throughput (MB/s)
3-way           |     4.01                               |      249,729                 |      27.63
FastCrc32c  |     4.35                              |     230,897                  |      25.53
2)   Crc32c computation CPU cost (inclusive samples percentage)
PER RUN
Implementation| run | TotalSamples   |Crc32c percentage
3-way                |  1  | 4,572,250,000 | 4.37%
3-way                |  2  | 3,779,250,000| 4.62%
3-way                |  3  | 4,129,500,000| 4.48%
FastCrc32c    |  1  | 4,663,500,000| 11.24%
FastCrc32c    |  2  | 4,047,500,000| 12.34%
FastCrc32c    |  3  | 4,366,750,000| 11.68%
**# Test Plan**
make -j64 corruption_test && ./corruption_test
By default it uses 3-way SSE algorithm
NO_THREEWAY_CRC32C=1 make -j64 corruption_test && ./corruption_test
make clean && DEBUG_LEVEL=0 make -j64 db_bench
make clean && DEBUG_LEVEL=0 NO_THREEWAY_CRC32C=1 make -j64 db_bench
Closes https://github.com/facebook/rocksdb/pull/3173
Differential Revision: D6330882
Pulled By: yingsu00
fbshipit-source-id: 8ec3d89719533b63b536a736663ca6f0dd4482e9/fix gflags namespace
Summary:
I started adding gflags support for cmake on linux and got frustrated that I'd need to duplicate the build_detect_platform logic, which determines namespace based on attempting compilation. We can do it differently -- use the GFLAGS_NAMESPACE macro if available, and if not, that indicates it's an old gflags version without configurable namespace so we can simply hardcode ""google"".
Closes https://github.com/facebook/rocksdb/pull/3212
Differential Revision: D6456973
Pulled By: ajkr
fbshipit-source-id: 3e6d5bde3ca00d4496a120a7caf4687399f5d656/"
rocksdb,"Fix clang-analyzer false-positive on ldb_cmd.cc
Summary:
clang-analyzer complaint about db_ being nullptr, but it couldn't be because it checks exec_stats before proceed. Add an assert to get around the false-positive.
Test Plan
`make analyze`
Closes https://github.com/facebook/rocksdb/pull/3236
Differential Revision: D6505417
Pulled By: yiwu-arbug
fbshipit-source-id: e5b65764ea994dd9e4bab3e697b97dc70dc22cab/ldb to allow db with --try_load_options and without an options file
Summary:
This is to fix tools/check_format_compatible.sh. The tool try to open
old versions of rocksdb with the provided options file. When options
file is missing (e.g. rocksdb 2.2), it should still proceed with default
options.
Closes https://github.com/facebook/rocksdb/pull/3232
Differential Revision: D6503955
Pulled By: yiwu-arbug
fbshipit-source-id: e44cfcce7ddc7d12cf83466ed3f3fe7624aa78b8/improve ldb CLI option support
Summary:
- Made CLI arguments take precedence over options file when both are provided. Note some of the CLI args are not settable via options file, like `--compression_max_dict_bytes`, so it's necessary to allow both ways of providing options simultaneously.
- Changed `PrepareOptionsForOpenDB` to update the proper `ColumnFamilyOptions` if one exists for the user's `--column_family_name` argument. I supported this only in the base class, `LDBCommand`, so it works for the general arguments. Will defer adding support for subcommand-specific arguments.
- Made the command fail if `--try_load_options` is provided and loading options file returns NotFound. I found the previous behavior of silently continuing confusing.
Closes https://github.com/facebook/rocksdb/pull/3144
Differential Revision: D6270544
Pulled By: ajkr
fbshipit-source-id: 7c2eac9f9b38720523d74466fb9e78db53561367/tools: Fix coverity issues
Summary:
tools/ldb_cmd.cc:
```
310  ignore_unknown_options_ = IsFlagPresent(flags, ARG_IGNORE_UNKNOWN_OPTIONS);
CID 1322798 (#1 of 1): Uninitialized pointer field (UNINIT_CTOR)
5. uninit_member: Non-static class member db_ttl_ is not initialized in this constructor nor in any functions that it calls.
311}
```
Closes https://github.com/facebook/rocksdb/pull/3122
Differential Revision: D6428576
Pulled By: sagar0
fbshipit-source-id: d77f04dd201f7f1d9f59ef88a215ee7ad7b934e9/"
rocksdb,"Compilation fixes for powerpc build, -Wparentheses-equality error and missing header guards
Summary:
This pull request contains miscellaneous compilation fixes.
Thanks,
Chinmay
Closes https://github.com/facebook/rocksdb/pull/3462
Differential Revision: D6941424
Pulled By: sagar0
fbshipit-source-id: fe9c26507bf131221f2466740204bff40a15614a/db_stress: skip snapshot check if cf is dropped
Summary:
We added a new verification that ensures a value that snapshot reads when is released is the same as when it was created. This test however fails when the cf is dropped in between. The patch skips the tests if that was the case.
Closes https://github.com/facebook/rocksdb/pull/3279
Differential Revision: D6581584
Pulled By: maysamyabandeh
fbshipit-source-id: afe37d371c0f91818d2e279b3949b810e112e8eb/fix gflags namespace
Summary:
I started adding gflags support for cmake on linux and got frustrated that I'd need to duplicate the build_detect_platform logic, which determines namespace based on attempting compilation. We can do it differently -- use the GFLAGS_NAMESPACE macro if available, and if not, that indicates it's an old gflags version without configurable namespace so we can simply hardcode ""google"".
Closes https://github.com/facebook/rocksdb/pull/3212
Differential Revision: D6456973
Pulled By: ajkr
fbshipit-source-id: 3e6d5bde3ca00d4496a120a7caf4687399f5d656/"
rocksdb,"fix gflags namespace
Summary:
I started adding gflags support for cmake on linux and got frustrated that I'd need to duplicate the build_detect_platform logic, which determines namespace based on attempting compilation. We can do it differently -- use the GFLAGS_NAMESPACE macro if available, and if not, that indicates it's an old gflags version without configurable namespace so we can simply hardcode ""google"".
Closes https://github.com/facebook/rocksdb/pull/3212
Differential Revision: D6456973
Pulled By: ajkr
fbshipit-source-id: 3e6d5bde3ca00d4496a120a7caf4687399f5d656/"
rocksdb,"Add a Close() method to DB to return status when closing a db
Summary:
Currently, the only way to close an open DB is to destroy the DB
object. There is no way for the caller to know the status. In one
instance, the destructor encountered an error due to failure to
close a log file on HDFS. In order to prevent silent failures, we add
DB::Close() that calls CloseImpl() which must be implemented by its
descendants.
The main failure point in the destructor is closing the log file. This
patch also adds a Close() entry point to Logger in order to get status.
When DBOptions::info_log is allocated and owned by the DBImpl, it is
explicitly closed by DBImpl::CloseImpl().
Closes https://github.com/facebook/rocksdb/pull/3348
Differential Revision: D6698158
Pulled By: anand1976
fbshipit-source-id: 9468e2892553eb09c4c41b8723f590c0dbd8ab7d/"
rocksdb,"Handle error return from WriteBuffer()
Summary:
There are a couple of places where we swallow any error from
WriteBuffer() - in SwitchMemtable() and DBImpl::CloseImpl(). Propagate
the error up in those cases rather than ignoring it.
Closes https://github.com/facebook/rocksdb/pull/3404
Differential Revision: D6879954
Pulled By: anand1976
fbshipit-source-id: 2ef88b554be5286b0a8bad7384ba17a105395bdb/Fix WriteBatch rep_ format for RangeDeletion records
Summary:
This is a small amount of general cleanup I made while experimenting with https://github.com/facebook/rocksdb/issues/3391.
Closes https://github.com/facebook/rocksdb/pull/3392
Differential Revision: D6788365
Pulled By: yiwu-arbug
fbshipit-source-id: 2716e5aabd5424a4dfdaa954361a62c8eb721ae2/Add a Close() method to DB to return status when closing a db
Summary:
Currently, the only way to close an open DB is to destroy the DB
object. There is no way for the caller to know the status. In one
instance, the destructor encountered an error due to failure to
close a log file on HDFS. In order to prevent silent failures, we add
DB::Close() that calls CloseImpl() which must be implemented by its
descendants.
The main failure point in the destructor is closing the log file. This
patch also adds a Close() entry point to Logger in order to get status.
When DBOptions::info_log is allocated and owned by the DBImpl, it is
explicitly closed by DBImpl::CloseImpl().
Closes https://github.com/facebook/rocksdb/pull/3348
Differential Revision: D6698158
Pulled By: anand1976
fbshipit-source-id: 9468e2892553eb09c4c41b8723f590c0dbd8ab7d/WritePrepared Txn: fix bug with Rollback seq
Summary:
The sequence number was not properly advanced after a rollback marker. The patch extends the existing unit tests to detect the bug and also fixes it.
Closes https://github.com/facebook/rocksdb/pull/3157
Differential Revision: D6304291
Pulled By: maysamyabandeh
fbshipit-source-id: 1b519c44a5371b802da49c9e32bd00087a8da401/"
rocksdb,"Add a ticker stat for number of keys skipped during iteration
Summary:
This diff adds a new ticker stat, NUMBER_ITER_SKIP, to count the
number of internal keys skipped during iteration. Keys can be skipped
due to deletes, or lower sequence number, or higher sequence number
than the one requested.
Also, fix the issue when StatisticsData is naturally aligned on cacheline boundary,
padding becomes a zero size array, which the Windows compiler doesn't
like. So add a cacheline worth of padding in that case to keep it happy.
We cannot conditionally add padding as gcc doesn't allow using sizeof
in preprocessor directives.
Closes https://github.com/facebook/rocksdb/pull/3177
Differential Revision: D6353897
Pulled By: anand1976
fbshipit-source-id: 441d5a09af9c4e22e7355242dfc0c7b27aa0a6c2/"
rocksdb,"Java: Add copy constructors for various option classes
Summary:
Add Java-side copy constructors for:
- Options
- DBOptions
- ColumnFamilyOptions
- WriteOptions
along with unit tests to assert the copy worked.
NOTE: Unit tests are failing in travis but it looks like a global timeout issue. These tests pass.
Closes https://github.com/facebook/rocksdb/pull/3450
Differential Revision: D6874425
Pulled By: sagar0
fbshipit-source-id: 5bde68ea5b5225e071faea2628bf8bbf10bd65ab/"
rocksdb,"Java: Add copy constructors for various option classes
Summary:
Add Java-side copy constructors for:
- Options
- DBOptions
- ColumnFamilyOptions
- WriteOptions
along with unit tests to assert the copy worked.
NOTE: Unit tests are failing in travis but it looks like a global timeout issue. These tests pass.
Closes https://github.com/facebook/rocksdb/pull/3450
Differential Revision: D6874425
Pulled By: sagar0
fbshipit-source-id: 5bde68ea5b5225e071faea2628bf8bbf10bd65ab/"
rocksdb,"Java: Add copy constructors for various option classes
Summary:
Add Java-side copy constructors for:
- Options
- DBOptions
- ColumnFamilyOptions
- WriteOptions
along with unit tests to assert the copy worked.
NOTE: Unit tests are failing in travis but it looks like a global timeout issue. These tests pass.
Closes https://github.com/facebook/rocksdb/pull/3450
Differential Revision: D6874425
Pulled By: sagar0
fbshipit-source-id: 5bde68ea5b5225e071faea2628bf8bbf10bd65ab/"
rocksdb,"Java: Add copy constructors for various option classes
Summary:
Add Java-side copy constructors for:
- Options
- DBOptions
- ColumnFamilyOptions
- WriteOptions
along with unit tests to assert the copy worked.
NOTE: Unit tests are failing in travis but it looks like a global timeout issue. These tests pass.
Closes https://github.com/facebook/rocksdb/pull/3450
Differential Revision: D6874425
Pulled By: sagar0
fbshipit-source-id: 5bde68ea5b5225e071faea2628bf8bbf10bd65ab/"
rocksdb,"Java: Add copy constructors for various option classes
Summary:
Add Java-side copy constructors for:
- Options
- DBOptions
- ColumnFamilyOptions
- WriteOptions
along with unit tests to assert the copy worked.
NOTE: Unit tests are failing in travis but it looks like a global timeout issue. These tests pass.
Closes https://github.com/facebook/rocksdb/pull/3450
Differential Revision: D6874425
Pulled By: sagar0
fbshipit-source-id: 5bde68ea5b5225e071faea2628bf8bbf10bd65ab/"
rocksdb,"Suppress valgrind ""unimplemented functionality"" error
Summary:
Add ROCKSDB_VALGRIND_RUN macro and suppress false-positive ""unimplemented functionality"" throw by valgrind for steam hints.
Another approach would be add a valgrind suppress file. Valgrind is suppose to print the suppression when given ""--gen-suppressions=all"" param, which is suppose to be the content for the suppression file. But it doesn't print.
Closes https://github.com/facebook/rocksdb/pull/3174
Differential Revision: D6338786
Pulled By: yiwu-arbug
fbshipit-source-id: 3559efa5f3b92d40d09ad6ac82bc7b59f86c75aa/"
rocksdb,"Add a Close() method to DB to return status when closing a db
Summary:
Currently, the only way to close an open DB is to destroy the DB
object. There is no way for the caller to know the status. In one
instance, the destructor encountered an error due to failure to
close a log file on HDFS. In order to prevent silent failures, we add
DB::Close() that calls CloseImpl() which must be implemented by its
descendants.
The main failure point in the destructor is closing the log file. This
patch also adds a Close() entry point to Logger in order to get status.
When DBOptions::info_log is allocated and owned by the DBImpl, it is
explicitly closed by DBImpl::CloseImpl().
Closes https://github.com/facebook/rocksdb/pull/3348
Differential Revision: D6698158
Pulled By: anand1976
fbshipit-source-id: 9468e2892553eb09c4c41b8723f590c0dbd8ab7d/"
rocksdb,"fix gflags namespace
Summary:
I started adding gflags support for cmake on linux and got frustrated that I'd need to duplicate the build_detect_platform logic, which determines namespace based on attempting compilation. We can do it differently -- use the GFLAGS_NAMESPACE macro if available, and if not, that indicates it's an old gflags version without configurable namespace so we can simply hardcode ""google"".
Closes https://github.com/facebook/rocksdb/pull/3212
Differential Revision: D6456973
Pulled By: ajkr
fbshipit-source-id: 3e6d5bde3ca00d4496a120a7caf4687399f5d656/"
rocksdb,"Suppress lint in old files
Summary: Grandfather in super old lint issues to make a clean slate for moving forward that allows us to have stronger enforcement on new issues.
Reviewed By: yiwu-arbug
Differential Revision: D6821806
fbshipit-source-id: 22797d31ec58e9eb0255d3b66fedfcfcb0dc127c/"
rocksdb,"WritePrepared Txn: fix bug with Rollback seq
Summary:
The sequence number was not properly advanced after a rollback marker. The patch extends the existing unit tests to detect the bug and also fixes it.
Closes https://github.com/facebook/rocksdb/pull/3157
Differential Revision: D6304291
Pulled By: maysamyabandeh
fbshipit-source-id: 1b519c44a5371b802da49c9e32bd00087a8da401/"
rocksdb,"Suppress lint in old files
Summary: Grandfather in super old lint issues to make a clean slate for moving forward that allows us to have stronger enforcement on new issues.
Reviewed By: yiwu-arbug
Differential Revision: D6821806
fbshipit-source-id: 22797d31ec58e9eb0255d3b66fedfcfcb0dc127c/"
rocksdb,"Blob DB: miscellaneous changes
Summary:
* Expose garbage collection related options
* Minor logging and counter name update
* Remove unused constants.
Closes https://github.com/facebook/rocksdb/pull/3451
Differential Revision: D6867077
Pulled By: yiwu-arbug
fbshipit-source-id: 6c3272a9c9d78b125a0bd6b2e56d00d087cdd6c8/Blob DB: fix crash when DB full but no candidate file to evict
Summary:
When blob_files is empty, std::min_element will return blobfiles.end(), which cannot be dereference. Fixing it.
Closes https://github.com/facebook/rocksdb/pull/3387
Differential Revision: D6764927
Pulled By: yiwu-arbug
fbshipit-source-id: 86f78700132be95760d35ac63480dfd3a8bbe17a/Blob DB: avoid having a separate read of checksum
Summary:
Previously on a blob db read, we are making a read of the blob value, and then make another read to get CRC checksum. I'm combining the two read into one.
readrandom db_bench with 1G database with base db size of 13M, value size 1k:
`./db_bench --db=/home/yiwu/tmp/db_bench --use_blob_db --value_size=1024 --num=1000000 --benchmarks=readrandom --use_existing_db --cache_size=32000000`
master: throughput 234MB/s, get micros p50 5.984 p95 9.998 p99 20.817 p100 787
this PR: throughput 261MB/s, get micros p50 5.157 p95 9.928 p99 20.724 p100 190
Closes https://github.com/facebook/rocksdb/pull/3301
Differential Revision: D6615950
Pulled By: yiwu-arbug
fbshipit-source-id: 052410c6d8539ec0cc305d53793bbc8f3616baa3/BlobDB: dump blob db options on open
Summary:
We dump blob db options on blob db open, but it was removed by mistake in #3246. Adding it back.
Closes https://github.com/facebook/rocksdb/pull/3298
Differential Revision: D6607177
Pulled By: yiwu-arbug
fbshipit-source-id: 2a4aacbfa52fd8f1878dc9e1fbb95fe48faf80c0/BlobDB: update blob_db_options.bytes_per_sync behavior
Summary:
Previously, if blob_db_options.bytes_per_sync, there is a background job to call fsync() for every bytes_per_sync bytes written to a blob file. With the change we simply pass bytes_per_sync as env_options_ to blob files so that sync_file_range() will be used instead.
Closes https://github.com/facebook/rocksdb/pull/3297
Differential Revision: D6606994
Pulled By: yiwu-arbug
fbshipit-source-id: 452424be52e32ba92f5ea603b564e9b88929af47/BlobDB: Remove the need to get sequence number per write
Summary:
Previously we store sequence number range of each blob files, and use the sequence number range to check if the file can be possibly visible by a snapshot. But it adds complexity to the code, since the sequence number is only available after a write. (The current implementation get sequence number by calling GetLatestSequenceNumber(), which is wrong.) With the patch, we are not storing sequence number range, and check if snapshot_sequence < obsolete_sequence to decide if the file is visible by a snapshot (previously we check if first_sequence <= snapshot_sequence < obsolete_sequence).
Closes https://github.com/facebook/rocksdb/pull/3274
Differential Revision: D6571497
Pulled By: yiwu-arbug
fbshipit-source-id: ca06479dc1fcd8782f6525b62b7762cd47d61909/BlobDB: refactor DB open logic
Summary:
Refactor BlobDB open logic. List of changes:
Major:
* On reopen, mark blob files found as immutable, do not use them for writing new keys.
* Not to scan the whole file to find file footer. Instead just seek to the end of the file and try to read footer.
Minor:
* Move most of the real logic from blob_db.cc to blob_db_impl.cc.
* Not to hold shared_ptr of event listeners in global maps in blob_db.cc
* Some changes to BlobFile interface.
* Improve logging and error handling.
Closes https://github.com/facebook/rocksdb/pull/3246
Differential Revision: D6526147
Pulled By: yiwu-arbug
fbshipit-source-id: 9dc4cdd63359a2f9b696af817086949da8d06952/utilities: Fix coverity issues in blob_db and col_buf_decoder
Summary:
utilities/blob_db/blob_db_impl.cc
265                    : bdb_options_.blob_dir;
3. uninit_member: Non-static class member env_ is not initialized in this constructor nor in any functions that it calls.
5. uninit_member: Non-static class member ttl_extractor_ is not initialized in this constructor nor in any functions that it calls.
7. uninit_member: Non-static class member open_p1_done_ is not initialized in this constructor nor in any functions that it calls.
CID 1418245 (#1 of 1): Uninitialized pointer field (UNINIT_CTOR)
9. uninit_member: Non-static class member debug_level_ is not initialized in this constructor nor in any functions that it calls.
266}
4. past_the_end: Function end creates an iterator.
CID 1418258 (#1 of 1): Using invalid iterator (INVALIDATE_ITERATOR)
5. deref_iterator: Dereferencing iterator file_nums.end() though it is already past the end of its container.
utilities/col_buf_decoder.h:
nullable_(nullable),
2. uninit_member: Non-static class member remain_runs_ is not initialized in this constructor nor in any functions that it calls.
4. uninit_member: Non-static class member run_val_ is not initialized in this constructor nor in any functions that it calls.
CID 1396134 (#1 of 1): Uninitialized scalar field (UNINIT_CTOR)
6. uninit_member: Non-static class member last_val_ is not initialized in this constructor nor in any functions that it calls.
46        big_endian_(big_endian) {}
Closes https://github.com/facebook/rocksdb/pull/3134
Differential Revision: D6340607
Pulled By: sagar0
fbshipit-source-id: 25c52566e2ff979fe6c7abb0f40c27fc16597054/Blob DB: Add statistics
Summary:
Adding a list of blob db counters.
Also remove WaStats() which doesn't expose the stats and can be substitute by (BLOB_DB_BYTES_WRITTEN / BLOB_DB_BLOB_FILE_BYTES_WRITTEN).
Closes https://github.com/facebook/rocksdb/pull/3193
Differential Revision: D6394216
Pulled By: yiwu-arbug
fbshipit-source-id: 017508c8ff3fcd7ea7403c64d0f9834b24816803/Blob DB: Fix GC handling for inlined blob
Summary:
Garbage collection checks if the offset in blob index matches the offset of the blob value in the file. If it is a mismatch, the value is the current version. However it failed to check if the blob index is an inlined type, which don't even have an offset. Fixing it.
Closes https://github.com/facebook/rocksdb/pull/3194
Differential Revision: D6394270
Pulled By: yiwu-arbug
fbshipit-source-id: 7c2b9d795f1116f55f4d728086980f9b6e88ea78/Blob DB: not using PinnableSlice move assignment
Summary:
The current implementation of PinnableSlice move assignment have an issue #3163. We are moving away from it instead of try to get the move assignment right, since it is too tricky.
Closes https://github.com/facebook/rocksdb/pull/3164
Differential Revision: D6319201
Pulled By: yiwu-arbug
fbshipit-source-id: 8f3279021f3710da4a4caa14fd238ed2df902c48/"
rocksdb,"fix gflags namespace
Summary:
I started adding gflags support for cmake on linux and got frustrated that I'd need to duplicate the build_detect_platform logic, which determines namespace based on attempting compilation. We can do it differently -- use the GFLAGS_NAMESPACE macro if available, and if not, that indicates it's an old gflags version without configurable namespace so we can simply hardcode ""google"".
Closes https://github.com/facebook/rocksdb/pull/3212
Differential Revision: D6456973
Pulled By: ajkr
fbshipit-source-id: 3e6d5bde3ca00d4496a120a7caf4687399f5d656/"
rocksdb,"NUMBER_BLOCK_COMPRESSED, etc, shouldn't be treated as timer counter
Summary:
NUMBER_BLOCK_DECOMPRESSED and NUMBER_BLOCK_COMPRESSED are not reported unless the stats level contain detailed timers, which is wrong. They are normal counters. Fix it.
Closes https://github.com/facebook/rocksdb/pull/3263
Differential Revision: D6552519
Pulled By: siying
fbshipit-source-id: 40899ccea7b2856bb39752616657c0bfd432f6f9/table: Fix coverity issues
Summary:
table/block.cc:
420  }
CID 1396127 (#1 of 1): Uninitialized scalar field (UNINIT_CTOR)
7. uninit_member: Non-static class member restart_offset_ is not initialized in this constructor nor in any functions that it calls.
421}
table/block_based_table_builder.cc:
CID 1418259 (#1 of 1): Uninitialized scalar field (UNINIT_CTOR)
7. uninit_member: Non-static class member compressed_cache_key_prefix_size is not initialized in this constructor nor in any functions that it calls.
table/block_based_table_reader.h:
3. uninit_member: Non-static class member index_type is not initialized in this constructor nor in any functions that it calls.
CID 1396147 (#1 of 1): Uninitialized scalar field (UNINIT_CTOR)
5. uninit_member: Non-static class member hash_index_allow_collision is not initialized in this constructor nor in any functions that it calls.
413        global_seqno(kDisableGlobalSequenceNumber) {}
414
table/cuckoo_table_reader.cc:
55  if (hash_funs == user_props.end()) {
56    status_ = Status::Corruption(""Number of hash functions not found"");
5. uninit_member: Non-static class member is_last_level_ is not initialized in this constructor nor in any functions that it calls.
7. uninit_member: Non-static class member identity_as_first_hash_ is not initialized in this constructor nor in any functions that it calls.
9. uninit_member: Non-static class member use_module_hash_ is not initialized in this constructor nor in any functions that it calls.
11. uninit_member: Non-static class member num_hash_func_ is not initialized in this constructor nor in any functions that it calls.
13. uninit_member: Non-static class member key_length_ is not initialized in this constructor nor in any functions that it calls.
15. uninit_member: Non-static class member user_key_length_ is not initialized in this constructor nor in any functions that it calls.
17. uninit_member: Non-static class member value_length_ is not initialized in this constructor nor in any functions that it calls.
19. uninit_member: Non-static class member bucket_length_ is not initialized in this constructor nor in any functions that it calls.
21. uninit_member: Non-static class member cuckoo_block_size_ is not initialized in this constructor nor in any functions that it calls.
23. uninit_member: Non-static class member cuckoo_block_bytes_minus_one_ is not initialized in this constructor nor in any functions that it calls.
CID 1322785 (#2 of 2): Uninitialized scalar field (UNINIT_CTOR)
25. uninit_member: Non-static class member table_size_ is not initialized in this constructor nor in any functions that it calls.
57    return;
table/plain_table_index.h:
2. uninit_member: Non-static class member index_size_ is not initialized in this constructor nor in any functions that it calls.
CID 1322801 (#1 of 1): Uninitialized scalar field (UNINIT_CTOR)
4. uninit_member: Non-static class member sub_index_size_ is not initialized in this constructor nor in any functions that it calls.
128        huge_page_tlb_size_(huge_page_tlb_size) {}
129
Closes https://github.com/facebook/rocksdb/pull/3113
Differential Revision: D6505719
Pulled By: yiwu-arbug
fbshipit-source-id: 38f44d8f9dfefb4c2e25d83b8df25a5201c75618/Revert ""No need for Restart Interval for meta blocks""
Summary:
See [issue 3169](https://github.com/facebook/rocksdb/issues/3169) for more information
This reverts commit 593d3de37171d99a761ce2ab34ffa12654acd055.
Closes https://github.com/facebook/rocksdb/pull/3188
Differential Revision: D6379271
Pulled By: miasantreble
fbshipit-source-id: 88f9ed67ba52237ad9b6f7251db83672b62d7537/Fix calculating filter partition target size
Summary:
block_size_deviation is in percentage while the partition size is in bytes. The current code fails to take that into account resulting into very large target size for filter partitions.
Closes https://github.com/facebook/rocksdb/pull/3187
Differential Revision: D6376069
Pulled By: maysamyabandeh
fbshipit-source-id: 276546fc68f50e0da32c462abb46f6cf676db9b2/"
rocksdb,"Suppress lint in old files
Summary: Grandfather in super old lint issues to make a clean slate for moving forward that allows us to have stronger enforcement on new issues.
Reviewed By: yiwu-arbug
Differential Revision: D6821806
fbshipit-source-id: 22797d31ec58e9eb0255d3b66fedfcfcb0dc127c/"
rocksdb,"Fix memory issue introduced by 2f1a3a4d748ea92c282a1302b1523adc6d67ce81
Summary: Closes https://github.com/facebook/rocksdb/pull/3256
Differential Revision: D6541714
Pulled By: siying
fbshipit-source-id: 40efd89b68587a9d58cfe6f4eebd771c2d9f1542/convert null terminator in ascii dump
Summary:
The ASCII output is almost always useless to me as the first '\0' byte in the key or value causes it to stop printing. Since all characters are already surrounded by spaces, ""\ 0"" (how we display a backslash followed by a zero) and ""\0"" (how this PR displays a null terminator) are distinguishable. My assumption is the value of seeing all the bytes outweighs the value of the alignment we had before, where we always had one character followed by one space.
Closes https://github.com/facebook/rocksdb/pull/3203
Differential Revision: D6428651
Pulled By: ajkr
fbshipit-source-id: aafc978a51e9ea029cfe3e763e2bb0e1751b9ccf/"
rocksdb,"table: Fix coverity issues
Summary:
table/block.cc:
420  }
CID 1396127 (#1 of 1): Uninitialized scalar field (UNINIT_CTOR)
7. uninit_member: Non-static class member restart_offset_ is not initialized in this constructor nor in any functions that it calls.
421}
table/block_based_table_builder.cc:
CID 1418259 (#1 of 1): Uninitialized scalar field (UNINIT_CTOR)
7. uninit_member: Non-static class member compressed_cache_key_prefix_size is not initialized in this constructor nor in any functions that it calls.
table/block_based_table_reader.h:
3. uninit_member: Non-static class member index_type is not initialized in this constructor nor in any functions that it calls.
CID 1396147 (#1 of 1): Uninitialized scalar field (UNINIT_CTOR)
5. uninit_member: Non-static class member hash_index_allow_collision is not initialized in this constructor nor in any functions that it calls.
413        global_seqno(kDisableGlobalSequenceNumber) {}
414
table/cuckoo_table_reader.cc:
55  if (hash_funs == user_props.end()) {
56    status_ = Status::Corruption(""Number of hash functions not found"");
5. uninit_member: Non-static class member is_last_level_ is not initialized in this constructor nor in any functions that it calls.
7. uninit_member: Non-static class member identity_as_first_hash_ is not initialized in this constructor nor in any functions that it calls.
9. uninit_member: Non-static class member use_module_hash_ is not initialized in this constructor nor in any functions that it calls.
11. uninit_member: Non-static class member num_hash_func_ is not initialized in this constructor nor in any functions that it calls.
13. uninit_member: Non-static class member key_length_ is not initialized in this constructor nor in any functions that it calls.
15. uninit_member: Non-static class member user_key_length_ is not initialized in this constructor nor in any functions that it calls.
17. uninit_member: Non-static class member value_length_ is not initialized in this constructor nor in any functions that it calls.
19. uninit_member: Non-static class member bucket_length_ is not initialized in this constructor nor in any functions that it calls.
21. uninit_member: Non-static class member cuckoo_block_size_ is not initialized in this constructor nor in any functions that it calls.
23. uninit_member: Non-static class member cuckoo_block_bytes_minus_one_ is not initialized in this constructor nor in any functions that it calls.
CID 1322785 (#2 of 2): Uninitialized scalar field (UNINIT_CTOR)
25. uninit_member: Non-static class member table_size_ is not initialized in this constructor nor in any functions that it calls.
57    return;
table/plain_table_index.h:
2. uninit_member: Non-static class member index_size_ is not initialized in this constructor nor in any functions that it calls.
CID 1322801 (#1 of 1): Uninitialized scalar field (UNINIT_CTOR)
4. uninit_member: Non-static class member sub_index_size_ is not initialized in this constructor nor in any functions that it calls.
128        huge_page_tlb_size_(huge_page_tlb_size) {}
129
Closes https://github.com/facebook/rocksdb/pull/3113
Differential Revision: D6505719
Pulled By: yiwu-arbug
fbshipit-source-id: 38f44d8f9dfefb4c2e25d83b8df25a5201c75618/"
rocksdb,"Change size_t cast in table_test
Summary:
Fixes this build error on master (macOS):
```
table/table_test.cc:972:27: error: implicit conversion loses integer precision: 'size_t' (aka 'unsigned long') to
'unsigned int' [-Werror,-Wshorten-64-to-32]
```
Closes https://github.com/facebook/rocksdb/pull/3434
Reviewed By: maysamyabandeh
Differential Revision: D6840354
Pulled By: gfosco
fbshipit-source-id: fffac6aefbbdd134ce1299453c5590aa855a5fc8/Split HarnessTest_Randomized to avoid timeout
Summary:
Split HarnessTest_Randomized to two tests
Closes https://github.com/facebook/rocksdb/pull/3424
Differential Revision: D6826006
Pulled By: maysamyabandeh
fbshipit-source-id: 59c9a11c7da092206effce6e4fa3792f9c66bef2/Fix multiple build failures
Summary:
* Fix DBTest.CompactRangeWithEmptyBottomLevel lite build failure
* Fix DBTest.AutomaticConflictsWithManualCompaction failure introduce by #3366
* Fix BlockBasedTableTest::IndexUncompressed should be disabled if snappy is disabled
* Fix ASAN failure with DBBasicTest::DBClose test
Closes https://github.com/facebook/rocksdb/pull/3373
Differential Revision: D6732313
Pulled By: yiwu-arbug
fbshipit-source-id: 1eb9b9d9a8d795f56188fa9770db9353f6fdedc5/"
rocksdb,"WritePrepared Txn: Support merge operator
Summary:
CompactionIterator invoke MergeHelper::MergeUntil() to do partial merge between snapshot boundaries. Previously it only depend on sequence number to tell snapshot boundary, but we also need to make use of snapshot_checker to verify visibility of the merge operands to the snapshots. For example, say there is a snapshot with seq = 2 but only can see data with seq <= 1. There are three merges, each with seq = 1, 2, 3. A correct compaction output would be (1),(2+3). Without taking snapshot_checker into account when generating merge result, compaction will generate output (1+2),(3).
By filtering uncommitted keys with read callback, the read path already take care of merges well and don't need additional updates.
Closes https://github.com/facebook/rocksdb/pull/3475
Differential Revision: D6926087
Pulled By: yiwu-arbug
fbshipit-source-id: 8f539d6f897cfe29b6dc27a8992f68c2a629d40a/WritePrepared Txn: update compaction_iterator_test and db_iterator_test
Summary:
Update compaction_iterator_test with write-prepared transaction DB related tests. Transaction related tests are group in CompactionIteratorWithSnapshotCheckerTest. The existing test are duplicated to make them also test with dummy SnapshotChecker that will say every key is visible to every snapshot (this is okay, we still compare sequence number to verify visibility). Merge related tests are disabled and will be revisit in another PR.
Existing db_iterator_tests are also duplicated to test with dummy read_callback that will say every key is committed.
Closes https://github.com/facebook/rocksdb/pull/3466
Differential Revision: D6909253
Pulled By: yiwu-arbug
fbshipit-source-id: 2ae4656b843a55e2e9ff8beecf21f2832f96cd25/"
rocksdb,"log flush reason for better debugging experience
Summary:
It's always a mystery from the logs why flush was triggered -- user triggered it manually, WriteBufferManager triggered it,  logs were full, write buffer was full, etc.
This PR logs Flush reason whenever a flush is scheduled.
Closes https://github.com/facebook/rocksdb/pull/3401
Differential Revision: D6788142
Pulled By: miasantreble
fbshipit-source-id: a867e54d493c06adf5172bd36a180fb3faae3511/Handle error return from WriteBuffer()
Summary:
There are a couple of places where we swallow any error from
WriteBuffer() - in SwitchMemtable() and DBImpl::CloseImpl(). Propagate
the error up in those cases rather than ignoring it.
Closes https://github.com/facebook/rocksdb/pull/3404
Differential Revision: D6879954
Pulled By: anand1976
fbshipit-source-id: 2ef88b554be5286b0a8bad7384ba17a105395bdb/DB::DumpSupportInfo should log all supported compression types
Summary:
DB::DumpSupportInfo should log all supported compression types.
Closes #3146
Closes https://github.com/facebook/rocksdb/pull/3396
Differential Revision: D6777019
Pulled By: yiwu-arbug
fbshipit-source-id: 5b17f1ffb2d71224e52f7d9c045434746c789fb0/fix live WALs purged while file deletions disabled
Summary:
When calling `DisableFileDeletions` followed by `GetSortedWalFiles`, we guarantee the files returned by the latter call won't be deleted until after file deletions are re-enabled. However, `GetSortedWalFiles` didn't omit files already planned for deletion via `PurgeObsoleteFiles`, so the guarantee could be broken.
We fix it by making `GetSortedWalFiles` wait for the number of pending purges to hit zero if file deletions are disabled. This condition is eventually met since `PurgeObsoleteFiles` is guaranteed to be called for the existing pending purges, and new purges cannot be scheduled while file deletions are disabled. Once the condition is met, `GetSortedWalFiles` simply returns the content of DB and archive directories, which nobody can delete (except for deletion scheduler, for which I plan to fix this bug later) until deletions are re-enabled.
Closes https://github.com/facebook/rocksdb/pull/3341
Differential Revision: D6681131
Pulled By: ajkr
fbshipit-source-id: 90b1e2f2362ea9ef715623841c0826611a817634/Add a Close() method to DB to return status when closing a db
Summary:
Currently, the only way to close an open DB is to destroy the DB
object. There is no way for the caller to know the status. In one
instance, the destructor encountered an error due to failure to
close a log file on HDFS. In order to prevent silent failures, we add
DB::Close() that calls CloseImpl() which must be implemented by its
descendants.
The main failure point in the destructor is closing the log file. This
patch also adds a Close() entry point to Logger in order to get status.
When DBOptions::info_log is allocated and owned by the DBImpl, it is
explicitly closed by DBImpl::CloseImpl().
Closes https://github.com/facebook/rocksdb/pull/3348
Differential Revision: D6698158
Pulled By: anand1976
fbshipit-source-id: 9468e2892553eb09c4c41b8723f590c0dbd8ab7d/Fix memleak when DB::DeleteFile()
Summary:
Because the corresponding read_first_record_cache_ item wasn't
erased, memory leaked.
Closes https://github.com/facebook/rocksdb/pull/1712
Differential Revision: D4363654
Pulled By: ajkr
fbshipit-source-id: 7da1adcfc8c380e4ffe05b8769fc2221ad17a225/WritePrepared Txn: Return NotSupported on iterator refresh
Summary:
A proper implementation of Iterator::Refresh() for WritePreparedTxnDB would require release and acquire another snapshot. Since MyRocks don't make use of Iterator::Refresh(), we just simply mark it as not supported.
Closes https://github.com/facebook/rocksdb/pull/3290
Differential Revision: D6599931
Pulled By: yiwu-arbug
fbshipit-source-id: 4e1632d967316431424f6e458254ecf9a97567cf/BlobDB: Remove the need to get sequence number per write
Summary:
Previously we store sequence number range of each blob files, and use the sequence number range to check if the file can be possibly visible by a snapshot. But it adds complexity to the code, since the sequence number is only available after a write. (The current implementation get sequence number by calling GetLatestSequenceNumber(), which is wrong.) With the patch, we are not storing sequence number range, and check if snapshot_sequence < obsolete_sequence to decide if the file is visible by a snapshot (previously we check if first_sequence <= snapshot_sequence < obsolete_sequence).
Closes https://github.com/facebook/rocksdb/pull/3274
Differential Revision: D6571497
Pulled By: yiwu-arbug
fbshipit-source-id: ca06479dc1fcd8782f6525b62b7762cd47d61909/Preserve overlapping file endpoint invariant
Summary:
Fix for #2833.
- In `DeleteFilesInRange`, use `GetCleanInputsWithinInterval` instead of `GetOverlappingInputs` to make sure we get a clean cut set of files to delete.
- In `GetCleanInputsWithinInterval`, support nullptr as `begin_key` or `end_key`.
- In `GetOverlappingInputsRangeBinarySearch`, move the assertion for non-empty range away from `ExtendFileRangeWithinInterval`, which should be allowed to return an empty range (via `end_index < begin_index`).
Closes https://github.com/facebook/rocksdb/pull/2843
Differential Revision: D5772387
Pulled By: ajkr
fbshipit-source-id: e554e8461823c6be82b21a9262a2da02b3957881/"
rocksdb,"fix DBTest2.ReadAmpBitmapLiveInCacheAfterDBClose file ID support check
Summary:
Updated the test case to handle tmpfs mounted at directories different from ""/dev/shm/"".
Closes https://github.com/facebook/rocksdb/pull/3440
Differential Revision: D6848213
Pulled By: ajkr
fbshipit-source-id: 465e9dbf0921d0930161f732db6b3766bb030589/fix live WALs purged while file deletions disabled
Summary:
When calling `DisableFileDeletions` followed by `GetSortedWalFiles`, we guarantee the files returned by the latter call won't be deleted until after file deletions are re-enabled. However, `GetSortedWalFiles` didn't omit files already planned for deletion via `PurgeObsoleteFiles`, so the guarantee could be broken.
We fix it by making `GetSortedWalFiles` wait for the number of pending purges to hit zero if file deletions are disabled. This condition is eventually met since `PurgeObsoleteFiles` is guaranteed to be called for the existing pending purges, and new purges cannot be scheduled while file deletions are disabled. Once the condition is met, `GetSortedWalFiles` simply returns the content of DB and archive directories, which nobody can delete (except for deletion scheduler, for which I plan to fix this bug later) until deletions are re-enabled.
Closes https://github.com/facebook/rocksdb/pull/3341
Differential Revision: D6681131
Pulled By: ajkr
fbshipit-source-id: 90b1e2f2362ea9ef715623841c0826611a817634/"
rocksdb,"Fix multiple build failures
Summary:
* Fix DBTest.CompactRangeWithEmptyBottomLevel lite build failure
* Fix DBTest.AutomaticConflictsWithManualCompaction failure introduce by #3366
* Fix BlockBasedTableTest::IndexUncompressed should be disabled if snappy is disabled
* Fix ASAN failure with DBBasicTest::DBClose test
Closes https://github.com/facebook/rocksdb/pull/3373
Differential Revision: D6732313
Pulled By: yiwu-arbug
fbshipit-source-id: 1eb9b9d9a8d795f56188fa9770db9353f6fdedc5/fix release order in validateNumberOfEntries
Summary:
ScopedArenaIterator should be defined after range_del_agg so that it destructs the assigned iterator, which depends on range_del_agg, before it range_del_agg is already destructed.
Closes https://github.com/facebook/rocksdb/pull/3281
Differential Revision: D6592332
Pulled By: maysamyabandeh
fbshipit-source-id: 89a15d8ed13d0fc856b0c47dce3d91778738dbac/"
rocksdb,"WritePrepared Txn: Support merge operator
Summary:
CompactionIterator invoke MergeHelper::MergeUntil() to do partial merge between snapshot boundaries. Previously it only depend on sequence number to tell snapshot boundary, but we also need to make use of snapshot_checker to verify visibility of the merge operands to the snapshots. For example, say there is a snapshot with seq = 2 but only can see data with seq <= 1. There are three merges, each with seq = 1, 2, 3. A correct compaction output would be (1),(2+3). Without taking snapshot_checker into account when generating merge result, compaction will generate output (1+2),(3).
By filtering uncommitted keys with read callback, the read path already take care of merges well and don't need additional updates.
Closes https://github.com/facebook/rocksdb/pull/3475
Differential Revision: D6926087
Pulled By: yiwu-arbug
fbshipit-source-id: 8f539d6f897cfe29b6dc27a8992f68c2a629d40a/"
rocksdb,"Explictly fail writes if key or value is not smaller than 4GB
Summary:
Right now, users will encounter unexpected bahavior if they use key or value larger than 4GB. We should explicitly fail the queriers.
Closes https://github.com/facebook/rocksdb/pull/3484
Differential Revision: D6953895
Pulled By: siying
fbshipit-source-id: b60491e1af064fc5d52971956661f6c18ceac24f/Fix DBTest::SoftLimit TSAN failure
Summary:
Fix data race found by TSAN around WriteStallListener: https://gist.github.com/yiwu-arbug/027d2448b903648f2f0f40b05258d80f
Closes https://github.com/facebook/rocksdb/pull/3384
Differential Revision: D6762167
Pulled By: yiwu-arbug
fbshipit-source-id: cd3a5c9f806de390bd1af6077ea6dbbc8bcaec09/fix DBTest.AutomaticConflictsWithManualCompaction
Summary:
After af92d4ad112f192693f6017f24f9ae1b00e1f053, only exclusive manual compaction can have conflict. dc360df81ec48e56a5d9cee4adb7f11ef0ca82ac updated the conflict-checking test case accordingly. But we missed the point that exclusive manual compaction can only conflict with automatic compactions scheduled after it, since it waits on pending automatic compactions before it begins running.
This PR updates the test case to ensure the automatic compactions are scheduled after the manual compaction starts but before it finishes, thus ensuring a conflict. I also cleaned up the test case to use less space as I saw it cause out-of-space error on travis.
Closes https://github.com/facebook/rocksdb/pull/3375
Differential Revision: D6735162
Pulled By: ajkr
fbshipit-source-id: 020530a4e150a4786792dce7cec5d66b420cb884/Fix multiple build failures
Summary:
* Fix DBTest.CompactRangeWithEmptyBottomLevel lite build failure
* Fix DBTest.AutomaticConflictsWithManualCompaction failure introduce by #3366
* Fix BlockBasedTableTest::IndexUncompressed should be disabled if snappy is disabled
* Fix ASAN failure with DBBasicTest::DBClose test
Closes https://github.com/facebook/rocksdb/pull/3373
Differential Revision: D6732313
Pulled By: yiwu-arbug
fbshipit-source-id: 1eb9b9d9a8d795f56188fa9770db9353f6fdedc5/Add a Close() method to DB to return status when closing a db
Summary:
Currently, the only way to close an open DB is to destroy the DB
object. There is no way for the caller to know the status. In one
instance, the destructor encountered an error due to failure to
close a log file on HDFS. In order to prevent silent failures, we add
DB::Close() that calls CloseImpl() which must be implemented by its
descendants.
The main failure point in the destructor is closing the log file. This
patch also adds a Close() entry point to Logger in order to get status.
When DBOptions::info_log is allocated and owned by the DBImpl, it is
explicitly closed by DBImpl::CloseImpl().
Closes https://github.com/facebook/rocksdb/pull/3348
Differential Revision: D6698158
Pulled By: anand1976
fbshipit-source-id: 9468e2892553eb09c4c41b8723f590c0dbd8ab7d/replace DBTest.HugeNumbersOfLevel with a more targeted test case
Summary:
This test often causes out-of-space error when run on travis. We don't want such stress tests in our unit test suite.
The bug in #596, which this test intends to expose, can be repro'd as long as the bottommost level(s) are empty when CompactRange is called. I rewrote the test to cover this simple case without writing a lot of data.
Closes https://github.com/facebook/rocksdb/pull/3362
Differential Revision: D6710417
Pulled By: ajkr
fbshipit-source-id: 9a1ec85e738c813ac2fee29f1d5302065ecb54c5/fix ThreadStatus for bottom-pri compaction threads
Summary:
added `ThreadType::BOTTOM_PRIORITY` which is used in the `ThreadStatus` object to indicate the thread is used for bottom-pri compactions. Previously there was a bug where we mislabeled such threads as `ThreadType::LOW_PRIORITY`.
Closes https://github.com/facebook/rocksdb/pull/3270
Differential Revision: D6559428
Pulled By: ajkr
fbshipit-source-id: 96b1a50a9c19492b1a5fd1b77cf7061a6f9f1d1c/exclude DynamicUniversalCompactionOptions from ROCKSDB_LITE
Summary:
since [SetOptions](https://github.com/facebook/rocksdb/blob/master/db/db_impl.cc#L494) is not supported in ROCKSDB_LITE
Right now unit test under lite is broken
Closes https://github.com/facebook/rocksdb/pull/3253
Differential Revision: D6539428
Pulled By: miasantreble
fbshipit-source-id: 13172b8ecbd75682330726498ea198969bc3e637/"
rocksdb,"Incorrect Universal Compaction reason
Summary:
While writing tests for dynamic Universal Compaction options, I found that the compaction reasons we set for size-ratio based and sorted-run based universal compactions are swapped with each other. Fixed it.
Closes https://github.com/facebook/rocksdb/pull/3412
Differential Revision: D6820540
Pulled By: sagar0
fbshipit-source-id: 270a188968ba25b2c96a8339904416c4c87ff5b3/"
rocksdb,"Fix coverity issues version, write_batch
Summary:
db/version_builder.cc:
117        base_vstorage_->InternalComparator();
CID 1351713 (#1 of 1): Uninitialized pointer field (UNINIT_CTOR)
2. uninit_member: Non-static class member field level_zero_cmp_.internal_comparator is not initialized in this constructor nor in any functions that it calls.
db/version_edit.h:
145  FdWithKeyRange()
146      : fd(),
147        smallest_key(),
148        largest_key() {
CID 1418254 (#1 of 1): Uninitialized pointer field (UNINIT_CTOR)
2. uninit_member: Non-static class member file_metadata is not initialized in this constructor nor in any functions that it calls.
149  }
db/version_set.cc:
120    }
CID 1322789 (#1 of 1): Uninitialized pointer field (UNINIT_CTOR)
4. uninit_member: Non-static class member curr_file_level_ is not initialized in this constructor nor in any functions that it calls.
121  }
db/write_batch.cc:
939    assert(cf_mems_);
CID 1419862 (#1 of 1): Uninitialized scalar field (UNINIT_CTOR)
3. uninit_member: Non-static class member rebuilding_trx_seq_ is not initialized in this constructor nor in any functions that it calls.
940  }
Closes https://github.com/facebook/rocksdb/pull/3092
Differential Revision: D6505666
Pulled By: yiwu-arbug
fbshipit-source-id: fd2c68948a0280772691a419d72ac7e190951d86/Preserve overlapping file endpoint invariant
Summary:
Fix for #2833.
- In `DeleteFilesInRange`, use `GetCleanInputsWithinInterval` instead of `GetOverlappingInputs` to make sure we get a clean cut set of files to delete.
- In `GetCleanInputsWithinInterval`, support nullptr as `begin_key` or `end_key`.
- In `GetOverlappingInputsRangeBinarySearch`, move the assertion for non-empty range away from `ExtendFileRangeWithinInterval`, which should be allowed to return an empty range (via `end_index < begin_index`).
Closes https://github.com/facebook/rocksdb/pull/2843
Differential Revision: D5772387
Pulled By: ajkr
fbshipit-source-id: e554e8461823c6be82b21a9262a2da02b3957881/"
rocksdb,"Disable onboard cache for compaction output
Summary:
FILE_FLAG_WRITE_THROUGH is for disabling device on-board cache in windows API, which should be disabled if user doesn't need system cache.
There was a perf issue related with this, we found during memtable flush, the high percentile latency jumps significantly. During profiling, we found those high latency (P99.9) read requests got queue-jumped by write requests from memtable flush and takes 80ms or even more time to wait, even when SSD overall IO throughput is relatively low.
After enabling FILE_FLAG_WRITE_THROUGH, we rerun the test found high percentile latency drops a lot without observable impact on writes.
Scenario 1: 40MB/s + 40MB/s  R/W compaction throughput
Original | FILE_FLAG_WRITE_THROUGH | Percentage reduction
---------------------------------------------------------------
P99.9 | 56.897 ms | 35.593 ms | -37.4%
P99 | 3.905 ms | 3.896 ms | -2.8%
Scenario 2:  14MB/s + 14MB/s R/W compaction throughput, cohosted with 100+ other rocksdb instances have manually triggered memtable flush operations (memtable is tiny), creating a lot of randomized the small file writes operations during test.
Original | FILE_FLAG_WRITE_THROUGH | Percentage reduction
---------------------------------------------------------------
P99.9 | 86.227   ms | 50.436 ms | -41.5%
P99 | 8.415   ms | 3.356 ms | -60.1%
Closes https://github.com/facebook/rocksdb/pull/3225
Differential Revision: D6624174
Pulled By: miasantreble
fbshipit-source-id: 321b86aee9d74470840c70e5d0d4fa9880660a91/"
rocksdb,"MaxFileSizeForLevel: adjust max_file_size for dynamic level compaction
Summary:
`MutableCFOptions::RefreshDerivedOptions` always assume base level is L1, which is not true when `level_compaction_dynamic_level_bytes=true` and Level based compaction is used.
This PR fixes this by recomputing `max_file_size` at query time (in `MaxFileSizeForLevel`)
Fixes https://github.com/facebook/rocksdb/issues/3229
In master:
```
Level Files Size(MB)
--------------------
0       14      846
1        0        0
2        0        0
3        0        0
4        0        0
5       15      366
6       11      481
Cumulative compaction: 3.83 GB write, 2.27 GB read
```
In branch:
```
Level Files Size(MB)
--------------------
0        9      544
1        0        0
2        0        0
3        0        0
4        0        0
5        0        0
6      445      935
Cumulative compaction: 2.91 GB write, 1.46 GB read
```
db_bench command used:
```
./db_bench --benchmarks=""fillrandom,deleterandom,fillrandom,levelstats,stats"" --statistics -deletes=5000 -db=tmp -compression_type=none --num=20000 -value_size=100000 -level_compaction_dynamic_level_bytes=true -target_file_size_base=2097152 -target_file_size_multiplier=2
```
Closes https://github.com/facebook/rocksdb/pull/3755
Differential Revision: D7721381
Pulled By: miasantreble
fbshipit-source-id: 39afb8503190bac3b466adf9bbf2a9b3655789f8/remove prefixscanrandom from db_bench help
Summary:
fix issue reported in https://github.com/facebook/rocksdb/issues/3757
Closes https://github.com/facebook/rocksdb/pull/3784
Differential Revision: D7794107
Pulled By: miasantreble
fbshipit-source-id: 43535074fcb82adb5656bcb916284b2dfc5cbb64/Support lowering CPU priority of background threads
Summary:
Background activities like compaction can negatively affect
latency of higher-priority tasks like request processing. To avoid this,
rocksdb already lowers the IO priority of background threads on Linux
systems. While this takes care of typical IO-bound systems, it does not
help much when CPU (temporarily) becomes the bottleneck. This is
especially likely when using more expensive compression settings.
This patch adds an API to allow for lowering the CPU priority of
background threads, modeled on the IO priority API. Benchmarks (see
below) show significant latency and throughput improvements when CPU
bound. As a result, workloads with some CPU usage bursts should benefit
from lower latencies at a given utilization, or should be able to push
utilization higher at a given request latency target.
A useful side effect is that compaction CPU usage is now easily visible
in common tools, allowing for an easier estimation of the contribution
of compaction vs. request processing threads.
As with IO priority, the implementation is limited to Linux, degrading
to a no-op on other systems.
Closes https://github.com/facebook/rocksdb/pull/3763
Differential Revision: D7740096
Pulled By: gwicke
fbshipit-source-id: e5d32373e8dc403a7b0c2227023f9ce4f22b413c/db_bench fillXXXdeterministic should respect compression type
Summary:
db_bench fillXXXdeterministic should respect compression type when calling CompactFiles().
Closes https://github.com/facebook/rocksdb/pull/3731
Differential Revision: D7647761
Pulled By: yiwu-arbug
fbshipit-source-id: 15e12429e0dd93ece2231b015f2e26c2d94781e6/fix memory leak in two_level_iterator
Summary:
this PR fixes a few failed contbuild:
1. ASAN memory leak in Block::NewIterator (table/block.cc:429). the proper destruction of first_level_iter_ and second_level_iter_ of two_level_iterator.cc is missing from the code after the refactoring in https://github.com/facebook/rocksdb/pull/3406
2. various unused param errors introduced by https://github.com/facebook/rocksdb/pull/3662
3. updated comment for `ForceReleaseCachedEntry` to emphasize the use of `force_erase` flag.
Closes https://github.com/facebook/rocksdb/pull/3718
Reviewed By: maysamyabandeh
Differential Revision: D7621192
Pulled By: miasantreble
fbshipit-source-id: 476c94264083a0730ded957c29de7807e4f5b146/Align SST file data blocks to avoid spanning multiple pages
Summary:
Provide a block_align option in BlockBasedTableOptions to allow
alignment of SST file data blocks. This will avoid higher
IOPS/throughput load due to < 4KB data blocks spanning 2 4KB pages.
When this option is set to true, the block alignment is set to lower of
block size and 4KB.
Closes https://github.com/facebook/rocksdb/pull/3502
Differential Revision: D7400897
Pulled By: anand1976
fbshipit-source-id: 04cc3bd144e88e3431a4f97604e63ad7a0f06d44/Blob DB: Improve FIFO eviction
Summary:
Improving blob db FIFO eviction with the following changes,
* Change blob_dir_size to max_db_size. Take into account SST file size when computing DB size.
* FIFO now only take into account live sst files and live blob files. It is normal for disk usage to go over max_db_size because there are obsolete sst files and blob files pending deletion.
* FIFO eviction now also evict TTL blob files that's still open. It doesn't evict non-TTL blob files.
* If FIFO is triggered, it will pass an expiration and the current sequence number to compaction filter. Compaction filter will then filter inlined keys to evict those with an earlier expiration and smaller sequence number. So call LSM FIFO.
* Compaction filter also filter those blob indexes where corresponding blob file is gone.
* Add an event listener to listen compaction/flush event and update sst file size.
* Implement DB::Close() to make sure base db, as well as event listener and compaction filter, destruct before blob db.
* More blob db statistics around FIFO.
* Fix some locking issue when accessing a blob file.
Closes https://github.com/facebook/rocksdb/pull/3556
Differential Revision: D7139328
Pulled By: yiwu-arbug
fbshipit-source-id: ea5edb07b33dfceacb2682f4789bea61de28bbfa/Added bytes XOR merge operator
Summary:
Closes https://github.com/facebook/rocksdb/pull/575
I fixed the merge conflicts etc.
Closes https://github.com/facebook/rocksdb/pull/3065
Differential Revision: D7128233
Pulled By: sagar0
fbshipit-source-id: 2c23a48c9f0432c290b0cd16a12fb691bb37820c/"
rocksdb,"fix handling of empty string as checkpoint directory
Summary:
- made `CreateCheckpoint` properly return `InvalidArgument` when called with an empty directory. Previously it triggered an assertion failure due to a bug in the logic.
- made `ldb` set empty `checkpoint_dir` if that's what the user specifies, so that we can use it to properly test `CreateCheckpoint` in the future.
Differential Revision: D6874562
fbshipit-source-id: dcc1bd41768261d9338987fa7711444289707ed7/"
rocksdb,"Fix db_stress memory leak ASAN error
Summary:
In case `--expected_values_path` is unset, we allocate a buffer internally to hold the expected DB state. This PR makes sure it is freed.
Closes https://github.com/facebook/rocksdb/pull/3804
Differential Revision: D7874694
Pulled By: ajkr
fbshipit-source-id: a8f7655e009507c4e639ceebfc3525d69c856e3b/Adjust pread/pwrite to return Status
Summary:
Returning bytes_read causes the caller to call GetLastError()
to report failure but the lasterror may be overwritten by then
so we lose the error code.
Fix up CMake file to include xpress source code only when needed.
Fix warning for the uninitialized var.
Closes https://github.com/facebook/rocksdb/pull/3795
Differential Revision: D7832935
Pulled By: anand1976
fbshipit-source-id: 4be21affb9b85d361b96244f4ef459f492b7cb2b/Second attempt at db_stress crash-recovery verification
Summary:
- Original commit: a4fb1f8c049ee9d61a9da8cf23b64d2c7d36a33f
- Revert commit (we reverted as a quick fix to get crash tests passing): 6afe22db2e667799d8c903db61750d676bffe152
This PR includes the contents of the original commit plus two bug fixes, which are:
- In whitebox crash test, only set `--expected_values_path` for `db_stress` runs in the first half of the crash test's duration. In the second half, a fresh DB is created for each `db_stress` run, so we cannot maintain expected state across `db_stress` runs.
- Made `Exists()` return true for `UNKNOWN_SENTINEL` values. I previously had an assert in `Exists()` that value was not `UNKNOWN_SENTINEL`. But it is possible for post-crash-recovery expected values to be `UNKNOWN_SENTINEL` (i.e., if the crash happens in the middle of an update), in which case this assertion would be tripped. The effect of returning true in this case is there may be cases where a `SingleDelete` deletes no data. But if we had returned false, the effect would be calling `SingleDelete` on a key with multiple older versions, which is not supported.
Closes https://github.com/facebook/rocksdb/pull/3793
Differential Revision: D7811671
Pulled By: ajkr
fbshipit-source-id: 67e0295bfb1695ff9674837f2e05bb29c50efc30/revert db_stress crash-recovery verification
Summary:
crash-recovery verification is failing in the whitebox testing, which may or may not be a valid correctness issue -- need more time to investigate. In the meantime, reverting so we don't mask other failures.
Closes https://github.com/facebook/rocksdb/pull/3786
Differential Revision: D7794516
Pulled By: ajkr
fbshipit-source-id: 28ccdfdb9ec9b3b0fb08c15cbf9d2e282201ff33/Allow options file in db_stress and db_crashtest
Summary:
- When options file is provided to db_stress, take supported options from the file instead of from flags
- Call `BuildOptionsTable` after `Open` so it can use `options_` once it has been populated either from flags or from file
- Allow options filename to be passed via `db_crashtest.py`
Closes https://github.com/facebook/rocksdb/pull/3768
Differential Revision: D7755331
Pulled By: ajkr
fbshipit-source-id: 5205cc5deb0d74d677b9832174153812bab9a60a/Add crash-recovery correctness check to db_stress
Summary:
Previously, our `db_stress` tool held the expected state of the DB in-memory, so after crash-recovery, there was no way to verify data correctness. This PR adds an option, `--expected_values_file`, which specifies a file holding the expected values.
In black-box testing, the `db_stress` process can be killed arbitrarily, so updates to the `--expected_values_file` must be atomic. We achieve this by `mmap`ing the file and relying on `std::atomic<uint32_t>` for atomicity. Actually this doesn't provide a total guarantee on what we want as `std::atomic<uint32_t>` could, in theory, be translated into multiple stores surrounded by a mutex. We can verify our assumption by looking at `std::atomic::is_always_lock_free`.
For the `mmap`'d file, we didn't have an existing way to expose its contents as a raw memory buffer. This PR adds it in the `Env::NewMemoryMappedFileBuffer` function, and `MemoryMappedFileBuffer` class.
`db_crashtest.py` is updated to use an expected values file for black-box testing. On the first iteration (when the DB is created), an empty file is provided as `db_stress` will populate it when it runs. On subsequent iterations, that same filename is provided so `db_stress` can check the data is as expected on startup.
Closes https://github.com/facebook/rocksdb/pull/3629
Differential Revision: D7463144
Pulled By: ajkr
fbshipit-source-id: c8f3e82c93e045a90055e2468316be155633bd8b/fix compilation error: implicit conversion loses integer precision
Summary:
Fix compilation error with clang:
> tools/db_stress.cc:2598:21: error: implicit conversion loses integer precision: 'gflags::uint64' (aka 'unsigned long') to 'uint32_t' (aka 'unsigned int') [-Werror,-Wshorten-64-to-32]
Random rand(FLAGS_seed);
~~~~ ^~~~~~~~~~
Closes https://github.com/facebook/rocksdb/pull/3746
Differential Revision: D7703209
Pulled By: miasantreble
fbshipit-source-id: 18c56a5138a2f308e4213594bc82e8e64bc21570/Improve db_stress with transactions
Summary:
db_stress was already capable running transactions by setting use_txn. Running it under stress showed a couple of problems fixed in this patch.
- The uncommitted transaction must be either rolled back or commit after recovery.
- Current implementation of WritePrepared transaction cannot handle cf drop before crash. Clarified that in the comments and added safety checks. When running with use_txn, clear_column_family_one_in must be set to 0.
Closes https://github.com/facebook/rocksdb/pull/3733
Differential Revision: D7654419
Pulled By: maysamyabandeh
fbshipit-source-id: a024bad80a9dc99677398c00d29ff17d4436b7f3/use delete[] to dealloc an array
Summary:
fix a bug in `db_stress` where an int array was incorrectly deallocated using delete instead of delete[]
Closes https://github.com/facebook/rocksdb/pull/3725
Differential Revision: D7634749
Pulled By: miasantreble
fbshipit-source-id: 489b776f5f4c03de1824edac5495787ec19cc910/fix memory leak in two_level_iterator
Summary:
this PR fixes a few failed contbuild:
1. ASAN memory leak in Block::NewIterator (table/block.cc:429). the proper destruction of first_level_iter_ and second_level_iter_ of two_level_iterator.cc is missing from the code after the refactoring in https://github.com/facebook/rocksdb/pull/3406
2. various unused param errors introduced by https://github.com/facebook/rocksdb/pull/3662
3. updated comment for `ForceReleaseCachedEntry` to emphasize the use of `force_erase` flag.
Closes https://github.com/facebook/rocksdb/pull/3718
Reviewed By: maysamyabandeh
Differential Revision: D7621192
Pulled By: miasantreble
fbshipit-source-id: 476c94264083a0730ded957c29de7807e4f5b146/Implemented Knuth shuffle to construct permutation for selecting no_o
Summary:
verwrite_keys. Also changed each no_overwrite_key set to an unordered set, otherwise Knuth shuffle only gets you 2x time improvement, because insertion (and subsequent internal sorting) into an ordered set is the bottleneck.
With this change, each iteration of permutation construction and prefix selection takes around 40 secs, as opposed to 360 secs previously. However, this still means that with the default 10 CF per blackbox test case, the test is going to time out given the default interval of 200 secs.
Also, there is currently an assertion error affecting all blackbox tests in db_crashtest.py; this assertion error will be fixed in a future PR.
Closes https://github.com/facebook/rocksdb/pull/3699
Differential Revision: D7624616
Pulled By: amytai
fbshipit-source-id: ea64fbe83407ff96c1c0ecabbc6c830576939393/Fix some typos in comments and docs.
Summary: Closes https://github.com/facebook/rocksdb/pull/3568
Differential Revision: D7170953
Pulled By: siying
fbshipit-source-id: 9cfb8dd88b7266da920c0e0c1e10fb2c5af0641c/Fix a leak in prepared_section_completed_
Summary:
The zeroed entries were not removed from prepared_section_completed_ map. This patch adds a unit test to show the problem and fixes that by refactoring the code. The new code is more efficient since i) it uses two separate mutex to avoid contention between commit and prepare threads, ii) it uses a sorted vector for maintaining uniq log entires with prepare which avoids a very large heap with many duplicate entries.
Closes https://github.com/facebook/rocksdb/pull/3545
Differential Revision: D7106071
Pulled By: maysamyabandeh
fbshipit-source-id: b3ae17cb6cd37ef10b6b35e0086c15c758768a48/"
rocksdb,"Clock cache should check if deleter is nullptr before calling it
Summary:
Clock cache should check if deleter is nullptr before calling it.
Closes https://github.com/facebook/rocksdb/pull/3677
Differential Revision: D7493602
Pulled By: yiwu-arbug
fbshipit-source-id: 4f94b188d2baf2cbc7c0d5da30fea1215a683de4/"
rocksdb,"Use nullptr instead of NULL / 0 more consistently.
Summary: Closes https://github.com/facebook/rocksdb/pull/3569
Differential Revision: D7170968
Pulled By: yiwu-arbug
fbshipit-source-id: 308a6b7dd358a04fd9a7de3d927bfd8abd57d348/"
rocksdb,"Disallow compactions if there isn't enough free space
Summary:
This diff handles cases where compaction causes an ENOSPC error.
This does not handle corner cases where another background job is started while compaction is running, and the other background job triggers ENOSPC, although we do allow the user to provision for these background jobs with SstFileManager::SetCompactionBufferSize.
It also does not handle the case where compaction has finished and some other background job independently triggers ENOSPC.
Usage: Functionality is inside SstFileManager. In particular, users should set SstFileManager::SetMaxAllowedSpaceUsage, which is the reference highwatermark for determining whether to cancel compactions.
Closes https://github.com/facebook/rocksdb/pull/3449
Differential Revision: D7016941
Pulled By: amytai
fbshipit-source-id: 8965ab8dd8b00972e771637a41b4e6c645450445/"
rocksdb,"Unbreak MemTableRep API change
Summary:
The MemTableRep API was broken by this commit: 813719e9525f647aaebf19ca3d4bb6f1c63e2648
This patch reverts the changes and instead adds InsertKey (and etc.) overloads to extend the MemTableRep API without breaking the existing classes that inherit from it.
Closes https://github.com/facebook/rocksdb/pull/3513
Differential Revision: D7004134
Pulled By: maysamyabandeh
fbshipit-source-id: e568d91fe1e17dd76c0c1f6c7dd51a18633b1c4f/"
rocksdb,"Unbreak MemTableRep API change
Summary:
The MemTableRep API was broken by this commit: 813719e9525f647aaebf19ca3d4bb6f1c63e2648
This patch reverts the changes and instead adds InsertKey (and etc.) overloads to extend the MemTableRep API without breaking the existing classes that inherit from it.
Closes https://github.com/facebook/rocksdb/pull/3513
Differential Revision: D7004134
Pulled By: maysamyabandeh
fbshipit-source-id: e568d91fe1e17dd76c0c1f6c7dd51a18633b1c4f/"
rocksdb,"Unbreak MemTableRep API change
Summary:
The MemTableRep API was broken by this commit: 813719e9525f647aaebf19ca3d4bb6f1c63e2648
This patch reverts the changes and instead adds InsertKey (and etc.) overloads to extend the MemTableRep API without breaking the existing classes that inherit from it.
Closes https://github.com/facebook/rocksdb/pull/3513
Differential Revision: D7004134
Pulled By: maysamyabandeh
fbshipit-source-id: e568d91fe1e17dd76c0c1f6c7dd51a18633b1c4f/"
rocksdb,"Unbreak MemTableRep API change
Summary:
The MemTableRep API was broken by this commit: 813719e9525f647aaebf19ca3d4bb6f1c63e2648
This patch reverts the changes and instead adds InsertKey (and etc.) overloads to extend the MemTableRep API without breaking the existing classes that inherit from it.
Closes https://github.com/facebook/rocksdb/pull/3513
Differential Revision: D7004134
Pulled By: maysamyabandeh
fbshipit-source-id: e568d91fe1e17dd76c0c1f6c7dd51a18633b1c4f/"
rocksdb,"Second attempt at db_stress crash-recovery verification
Summary:
- Original commit: a4fb1f8c049ee9d61a9da8cf23b64d2c7d36a33f
- Revert commit (we reverted as a quick fix to get crash tests passing): 6afe22db2e667799d8c903db61750d676bffe152
This PR includes the contents of the original commit plus two bug fixes, which are:
- In whitebox crash test, only set `--expected_values_path` for `db_stress` runs in the first half of the crash test's duration. In the second half, a fresh DB is created for each `db_stress` run, so we cannot maintain expected state across `db_stress` runs.
- Made `Exists()` return true for `UNKNOWN_SENTINEL` values. I previously had an assert in `Exists()` that value was not `UNKNOWN_SENTINEL`. But it is possible for post-crash-recovery expected values to be `UNKNOWN_SENTINEL` (i.e., if the crash happens in the middle of an update), in which case this assertion would be tripped. The effect of returning true in this case is there may be cases where a `SingleDelete` deletes no data. But if we had returned false, the effect would be calling `SingleDelete` on a key with multiple older versions, which is not supported.
Closes https://github.com/facebook/rocksdb/pull/3793
Differential Revision: D7811671
Pulled By: ajkr
fbshipit-source-id: 67e0295bfb1695ff9674837f2e05bb29c50efc30/revert db_stress crash-recovery verification
Summary:
crash-recovery verification is failing in the whitebox testing, which may or may not be a valid correctness issue -- need more time to investigate. In the meantime, reverting so we don't mask other failures.
Closes https://github.com/facebook/rocksdb/pull/3786
Differential Revision: D7794516
Pulled By: ajkr
fbshipit-source-id: 28ccdfdb9ec9b3b0fb08c15cbf9d2e282201ff33/Add crash-recovery correctness check to db_stress
Summary:
Previously, our `db_stress` tool held the expected state of the DB in-memory, so after crash-recovery, there was no way to verify data correctness. This PR adds an option, `--expected_values_file`, which specifies a file holding the expected values.
In black-box testing, the `db_stress` process can be killed arbitrarily, so updates to the `--expected_values_file` must be atomic. We achieve this by `mmap`ing the file and relying on `std::atomic<uint32_t>` for atomicity. Actually this doesn't provide a total guarantee on what we want as `std::atomic<uint32_t>` could, in theory, be translated into multiple stores surrounded by a mutex. We can verify our assumption by looking at `std::atomic::is_always_lock_free`.
For the `mmap`'d file, we didn't have an existing way to expose its contents as a raw memory buffer. This PR adds it in the `Env::NewMemoryMappedFileBuffer` function, and `MemoryMappedFileBuffer` class.
`db_crashtest.py` is updated to use an expected values file for black-box testing. On the first iteration (when the DB is created), an empty file is provided as `db_stress` will populate it when it runs. On subsequent iterations, that same filename is provided so `db_stress` can check the data is as expected on startup.
Closes https://github.com/facebook/rocksdb/pull/3629
Differential Revision: D7463144
Pulled By: ajkr
fbshipit-source-id: c8f3e82c93e045a90055e2468316be155633bd8b/Support lowering CPU priority of background threads
Summary:
Background activities like compaction can negatively affect
latency of higher-priority tasks like request processing. To avoid this,
rocksdb already lowers the IO priority of background threads on Linux
systems. While this takes care of typical IO-bound systems, it does not
help much when CPU (temporarily) becomes the bottleneck. This is
especially likely when using more expensive compression settings.
This patch adds an API to allow for lowering the CPU priority of
background threads, modeled on the IO priority API. Benchmarks (see
below) show significant latency and throughput improvements when CPU
bound. As a result, workloads with some CPU usage bursts should benefit
from lower latencies at a given utilization, or should be able to push
utilization higher at a given request latency target.
A useful side effect is that compaction CPU usage is now easily visible
in common tools, allowing for an easier estimation of the contribution
of compaction vs. request processing threads.
As with IO priority, the implementation is limited to Linux, degrading
to a no-op on other systems.
Closes https://github.com/facebook/rocksdb/pull/3763
Differential Revision: D7740096
Pulled By: gwicke
fbshipit-source-id: e5d32373e8dc403a7b0c2227023f9ce4f22b413c/Fix some typos in comments and docs.
Summary: Closes https://github.com/facebook/rocksdb/pull/3568
Differential Revision: D7170953
Pulled By: siying
fbshipit-source-id: 9cfb8dd88b7266da920c0e0c1e10fb2c5af0641c/Use nullptr instead of NULL / 0 more consistently.
Summary: Closes https://github.com/facebook/rocksdb/pull/3569
Differential Revision: D7170968
Pulled By: yiwu-arbug
fbshipit-source-id: 308a6b7dd358a04fd9a7de3d927bfd8abd57d348/Windows cumulative patch
Summary:
This patch addressed several issues.
Portability including db_test std::thread -> port::Thread Cc: @
and %z to ROCKSDB portable macro. Cc: maysamyabandeh
Implement Env::AreFilesSame
Make the implementation of file unique number more robust
Get rid of C-runtime and go directly to Windows API when dealing
with file primitives.
Implement GetSectorSize() and aling unbuffered read on the value if
available.
Adjust Windows Logger for the new interface, implement CloseImpl() Cc: anand1976
Fix test running script issue where $status var was of incorrect scope
so the failures were swallowed and not reported.
DestroyDB() creates a logger and opens a LOG file in the directory
being cleaned up. This holds a lock on the folder and the cleanup is
prevented. This fails one of the checkpoin tests. We observe the same in production.
We close the log file in this change.
Fix DBTest2.ReadAmpBitmapLiveInCacheAfterDBClose failure where the test
attempts to open a directory with NewRandomAccessFile which does not
work on Windows.
Fix DBTest.SoftLimit as it is dependent on thread timing. CC: yiwu-arbug
Closes https://github.com/facebook/rocksdb/pull/3552
Differential Revision: D7156304
Pulled By: siying
fbshipit-source-id: 43db0a757f1dfceffeb2b7988043156639173f5b/Fix the Logger::Close() and DBImpl::Close() design pattern
Summary:
The recent Logger::Close() and DBImpl::Close() implementation rely on
calling the CloseImpl() virtual function from the destructor, which will
not work. Refactor the implementation to have a private close helper
function in derived classes that can be called by both CloseImpl() and
the destructor.
Closes https://github.com/facebook/rocksdb/pull/3528
Reviewed By: gfosco
Differential Revision: D7049303
Pulled By: anand1976
fbshipit-source-id: 76a64cbf403209216dfe4864ecf96b5d7f3db9f4/"
rocksdb,"Fix clang build failure with -Wgnu-redeclared-enum
Summary:
In include/rocksdb/db.h, enum EntryType is redeclared even though
original declaration in types.h in included.
Closes https://github.com/facebook/rocksdb/pull/3766
Differential Revision: D7765504
Pulled By: anand1976
fbshipit-source-id: 622a8ecb306993915be1b9dd5cdd79dbc6a4ea05/Add block cache related DB properties
Summary:
Add DB properties ""rocksdb.block-cache-capacity"", ""rocksdb.block-cache-usage"", ""rocksdb.block-cache-pinned-usage"" to show block cache usage.
Closes https://github.com/facebook/rocksdb/pull/3734
Differential Revision: D7657180
Pulled By: yiwu-arbug
fbshipit-source-id: dd34a019d5878dab539c51ee82669e97b2b745fd/Fix some typos in comments and docs.
Summary: Closes https://github.com/facebook/rocksdb/pull/3568
Differential Revision: D7170953
Pulled By: siying
fbshipit-source-id: 9cfb8dd88b7266da920c0e0c1e10fb2c5af0641c/Fix API name in a comment in db.h
Summary:
... so that people are not confused.
Closes https://github.com/facebook/rocksdb/pull/3580
Differential Revision: D7187175
Pulled By: sagar0
fbshipit-source-id: bce70093d52e38cd24c9432fd708885d7c2c013e/Add ""rocksdb.live-sst-files-size"" DB property
Summary:
Add ""rocksdb.live-sst-files-size"" DB property which only include files of latest version. Existing ""rocksdb.total-sst-files-size"" include files from all versions and thus include files that's obsolete but not yet deleted. I'm going to use this new property to cap blob db sst + blob files size.
Closes https://github.com/facebook/rocksdb/pull/3548
Differential Revision: D7116939
Pulled By: yiwu-arbug
fbshipit-source-id: c6a52e45ce0f24ef78708156e1a923c1dd6bc79a/Fix the Logger::Close() and DBImpl::Close() design pattern
Summary:
The recent Logger::Close() and DBImpl::Close() implementation rely on
calling the CloseImpl() virtual function from the destructor, which will
not work. Refactor the implementation to have a private close helper
function in derived classes that can be called by both CloseImpl() and
the destructor.
Closes https://github.com/facebook/rocksdb/pull/3528
Reviewed By: gfosco
Differential Revision: D7049303
Pulled By: anand1976
fbshipit-source-id: 76a64cbf403209216dfe4864ecf96b5d7f3db9f4/"
rocksdb,"Fix some typos in comments and docs.
Summary: Closes https://github.com/facebook/rocksdb/pull/3568
Differential Revision: D7170953
Pulled By: siying
fbshipit-source-id: 9cfb8dd88b7266da920c0e0c1e10fb2c5af0641c/"
rocksdb,"Fixed small typos
Summary: Closes https://github.com/facebook/rocksdb/pull/3667
Differential Revision: D7470060
Pulled By: miasantreble
fbshipit-source-id: 8e8545cda38f0805f35ccdb8841666a2d7a965f5/"
rocksdb,"Support StringAppendOperator(delimiter_char) constructor in java-api
Summary:
Fixes #3336
Closes https://github.com/facebook/rocksdb/pull/3337
Differential Revision: D7196585
Pulled By: sagar0
fbshipit-source-id: a854f3fc906862ecba685b31946e4ef7c0b421c5/"
rocksdb,"Second attempt at db_stress crash-recovery verification
Summary:
- Original commit: a4fb1f8c049ee9d61a9da8cf23b64d2c7d36a33f
- Revert commit (we reverted as a quick fix to get crash tests passing): 6afe22db2e667799d8c903db61750d676bffe152
This PR includes the contents of the original commit plus two bug fixes, which are:
- In whitebox crash test, only set `--expected_values_path` for `db_stress` runs in the first half of the crash test's duration. In the second half, a fresh DB is created for each `db_stress` run, so we cannot maintain expected state across `db_stress` runs.
- Made `Exists()` return true for `UNKNOWN_SENTINEL` values. I previously had an assert in `Exists()` that value was not `UNKNOWN_SENTINEL`. But it is possible for post-crash-recovery expected values to be `UNKNOWN_SENTINEL` (i.e., if the crash happens in the middle of an update), in which case this assertion would be tripped. The effect of returning true in this case is there may be cases where a `SingleDelete` deletes no data. But if we had returned false, the effect would be calling `SingleDelete` on a key with multiple older versions, which is not supported.
Closes https://github.com/facebook/rocksdb/pull/3793
Differential Revision: D7811671
Pulled By: ajkr
fbshipit-source-id: 67e0295bfb1695ff9674837f2e05bb29c50efc30/revert db_stress crash-recovery verification
Summary:
crash-recovery verification is failing in the whitebox testing, which may or may not be a valid correctness issue -- need more time to investigate. In the meantime, reverting so we don't mask other failures.
Closes https://github.com/facebook/rocksdb/pull/3786
Differential Revision: D7794516
Pulled By: ajkr
fbshipit-source-id: 28ccdfdb9ec9b3b0fb08c15cbf9d2e282201ff33/Add crash-recovery correctness check to db_stress
Summary:
Previously, our `db_stress` tool held the expected state of the DB in-memory, so after crash-recovery, there was no way to verify data correctness. This PR adds an option, `--expected_values_file`, which specifies a file holding the expected values.
In black-box testing, the `db_stress` process can be killed arbitrarily, so updates to the `--expected_values_file` must be atomic. We achieve this by `mmap`ing the file and relying on `std::atomic<uint32_t>` for atomicity. Actually this doesn't provide a total guarantee on what we want as `std::atomic<uint32_t>` could, in theory, be translated into multiple stores surrounded by a mutex. We can verify our assumption by looking at `std::atomic::is_always_lock_free`.
For the `mmap`'d file, we didn't have an existing way to expose its contents as a raw memory buffer. This PR adds it in the `Env::NewMemoryMappedFileBuffer` function, and `MemoryMappedFileBuffer` class.
`db_crashtest.py` is updated to use an expected values file for black-box testing. On the first iteration (when the DB is created), an empty file is provided as `db_stress` will populate it when it runs. On subsequent iterations, that same filename is provided so `db_stress` can check the data is as expected on startup.
Closes https://github.com/facebook/rocksdb/pull/3629
Differential Revision: D7463144
Pulled By: ajkr
fbshipit-source-id: c8f3e82c93e045a90055e2468316be155633bd8b/fix memory leak in two_level_iterator
Summary:
this PR fixes a few failed contbuild:
1. ASAN memory leak in Block::NewIterator (table/block.cc:429). the proper destruction of first_level_iter_ and second_level_iter_ of two_level_iterator.cc is missing from the code after the refactoring in https://github.com/facebook/rocksdb/pull/3406
2. various unused param errors introduced by https://github.com/facebook/rocksdb/pull/3662
3. updated comment for `ForceReleaseCachedEntry` to emphasize the use of `force_erase` flag.
Closes https://github.com/facebook/rocksdb/pull/3718
Reviewed By: maysamyabandeh
Differential Revision: D7621192
Pulled By: miasantreble
fbshipit-source-id: 476c94264083a0730ded957c29de7807e4f5b146/"
rocksdb,"Disallow compactions if there isn't enough free space
Summary:
This diff handles cases where compaction causes an ENOSPC error.
This does not handle corner cases where another background job is started while compaction is running, and the other background job triggers ENOSPC, although we do allow the user to provision for these background jobs with SstFileManager::SetCompactionBufferSize.
It also does not handle the case where compaction has finished and some other background job independently triggers ENOSPC.
Usage: Functionality is inside SstFileManager. In particular, users should set SstFileManager::SetMaxAllowedSpaceUsage, which is the reference highwatermark for determining whether to cancel compactions.
Closes https://github.com/facebook/rocksdb/pull/3449
Differential Revision: D7016941
Pulled By: amytai
fbshipit-source-id: 8965ab8dd8b00972e771637a41b4e6c645450445/Fix the Logger::Close() and DBImpl::Close() design pattern
Summary:
The recent Logger::Close() and DBImpl::Close() implementation rely on
calling the CloseImpl() virtual function from the destructor, which will
not work. Refactor the implementation to have a private close helper
function in derived classes that can be called by both CloseImpl() and
the destructor.
Closes https://github.com/facebook/rocksdb/pull/3528
Reviewed By: gfosco
Differential Revision: D7049303
Pulled By: anand1976
fbshipit-source-id: 76a64cbf403209216dfe4864ecf96b5d7f3db9f4/"
rocksdb,"Use nullptr instead of NULL / 0 more consistently.
Summary: Closes https://github.com/facebook/rocksdb/pull/3569
Differential Revision: D7170968
Pulled By: yiwu-arbug
fbshipit-source-id: 308a6b7dd358a04fd9a7de3d927bfd8abd57d348/uint64_t and size_t changes to compile for iOS
Summary:
In attempting to build a static lib for use in iOS, I ran in to lots of type errors between uint64_t and size_t.  This PR contains the changes I made to get `TARGET_OS=IOS make static_lib` to succeed while also getting Xcode to build successfully with the resulting `librocksdb.a` library imported.
This also compiles for me on macOS and tests fine, but I'm really not sure if I made the correct decisions about where to `static_cast` and where to change types.
Also up for discussion: is iOS worth supporting?  Getting the static lib is just part one, we aren't providing any bridging headers or wrappers like the ObjectiveRocks project, it won't be a great experience.
Closes https://github.com/facebook/rocksdb/pull/3503
Differential Revision: D7106457
Pulled By: gfosco
fbshipit-source-id: 82ac2073de7e1f09b91f6b4faea91d18bd311f8e/"
rocksdb,"Fix some typos in comments and docs.
Summary: Closes https://github.com/facebook/rocksdb/pull/3568
Differential Revision: D7170953
Pulled By: siying
fbshipit-source-id: 9cfb8dd88b7266da920c0e0c1e10fb2c5af0641c/"
rocksdb,"fix memory leak in two_level_iterator
Summary:
this PR fixes a few failed contbuild:
1. ASAN memory leak in Block::NewIterator (table/block.cc:429). the proper destruction of first_level_iter_ and second_level_iter_ of two_level_iterator.cc is missing from the code after the refactoring in https://github.com/facebook/rocksdb/pull/3406
2. various unused param errors introduced by https://github.com/facebook/rocksdb/pull/3662
3. updated comment for `ForceReleaseCachedEntry` to emphasize the use of `force_erase` flag.
Closes https://github.com/facebook/rocksdb/pull/3718
Reviewed By: maysamyabandeh
Differential Revision: D7621192
Pulled By: miasantreble
fbshipit-source-id: 476c94264083a0730ded957c29de7807e4f5b146/"
rocksdb,"fix memory leak in two_level_iterator
Summary:
this PR fixes a few failed contbuild:
1. ASAN memory leak in Block::NewIterator (table/block.cc:429). the proper destruction of first_level_iter_ and second_level_iter_ of two_level_iterator.cc is missing from the code after the refactoring in https://github.com/facebook/rocksdb/pull/3406
2. various unused param errors introduced by https://github.com/facebook/rocksdb/pull/3662
3. updated comment for `ForceReleaseCachedEntry` to emphasize the use of `force_erase` flag.
Closes https://github.com/facebook/rocksdb/pull/3718
Reviewed By: maysamyabandeh
Differential Revision: D7621192
Pulled By: miasantreble
fbshipit-source-id: 476c94264083a0730ded957c29de7807e4f5b146/"
rocksdb,"Avoid directory renames in BackupEngine
Summary:
We used to name private directories like ""1.tmp"" while BackupEngine populated them, and then rename without the "".tmp"" suffix (i.e., rename ""1.tmp"" to ""1"") after all files were copied. On glusterfs, directory renames like this require operations across many hosts, and partial failures have caused operational problems.
Fortunately we don't need to rename private directories. We already have a meta-file that uses the tempfile-rename pattern to commit a backup atomically after all its files have been successfully copied. So we can copy private files directly to their final location, so now there's no directory rename.
Closes https://github.com/facebook/rocksdb/pull/3749
Differential Revision: D7705610
Pulled By: ajkr
fbshipit-source-id: fd724a28dd2bf993ce323a5f2cb7e7d6980cc346/fix memory leak in two_level_iterator
Summary:
this PR fixes a few failed contbuild:
1. ASAN memory leak in Block::NewIterator (table/block.cc:429). the proper destruction of first_level_iter_ and second_level_iter_ of two_level_iterator.cc is missing from the code after the refactoring in https://github.com/facebook/rocksdb/pull/3406
2. various unused param errors introduced by https://github.com/facebook/rocksdb/pull/3662
3. updated comment for `ForceReleaseCachedEntry` to emphasize the use of `force_erase` flag.
Closes https://github.com/facebook/rocksdb/pull/3718
Reviewed By: maysamyabandeh
Differential Revision: D7621192
Pulled By: miasantreble
fbshipit-source-id: 476c94264083a0730ded957c29de7807e4f5b146/Disallow compactions if there isn't enough free space
Summary:
This diff handles cases where compaction causes an ENOSPC error.
This does not handle corner cases where another background job is started while compaction is running, and the other background job triggers ENOSPC, although we do allow the user to provision for these background jobs with SstFileManager::SetCompactionBufferSize.
It also does not handle the case where compaction has finished and some other background job independently triggers ENOSPC.
Usage: Functionality is inside SstFileManager. In particular, users should set SstFileManager::SetMaxAllowedSpaceUsage, which is the reference highwatermark for determining whether to cancel compactions.
Closes https://github.com/facebook/rocksdb/pull/3449
Differential Revision: D7016941
Pulled By: amytai
fbshipit-source-id: 8965ab8dd8b00972e771637a41b4e6c645450445/BackupEngine gluster-friendly file naming convention
Summary:
Use the rsync tempfile naming convention in our `BackupEngine`. The temp file follows the format, `.<filename>.<suffix>`, which is later renamed to `<filename>`. We fix `tmp` as the `<suffix>` as we don't need to use random bytes for now. The benefit is gluster treats this tempfile naming convention specially and applies hashing only to `<filename>`, so the file won't need to be linked or moved when it's renamed. Our gluster team suggested this will make things operationally easier.
Closes https://github.com/facebook/rocksdb/pull/3463
Differential Revision: D6893333
Pulled By: ajkr
fbshipit-source-id: fd7622978f4b2487fce33cde40dd3124f16bcaa8/"
rocksdb,"WritePrepared Txn: enable rollback in stress test
Summary:
Rollback was disabled in stress test since there was a concurrency issue in WritePrepared rollback algorithm. The issue is fixed by caching the column family handles in WritePrepared to skip getting them from the db when needed for rollback.
Tested by running transaction stress test under tsan.
Closes https://github.com/facebook/rocksdb/pull/3785
Differential Revision: D7793727
Pulled By: maysamyabandeh
fbshipit-source-id: d81ab6fda0e53186ca69944cfe0712ce4869451e/WritePrepared Txn: rollback_merge_operands hack
Summary:
This is a hack as temporary fix of MyRocks with rollbacking  the merge operands. The way MyRocks uses merge operands is without protection of locks, which violates the assumption behind the rollback algorithm. They are ok with not being rolled back as it would just create a gap in the autoincrement column. The hack add an option to disable the rollback of merge operands by default and only enables it to let the unit test pass.
Closes https://github.com/facebook/rocksdb/pull/3711
Differential Revision: D7597177
Pulled By: maysamyabandeh
fbshipit-source-id: 544be0f666c7e7abb7f651ec8b23124e05056728/WritePrepared Txn: fix smallest_prep atomicity issue
Summary:
We introduced smallest_prep optimization in this commit b225de7e10f02be6d00e96b9fb86dfef880babdf, which enables storing the smallest uncommitted sequence number along with the snapshot. This enables the readers that read from the snapshot to skip further checks and safely assumed the data is committed if its sequence number is less than smallest uncommitted when the snapshot was taken. The problem was that smallest uncommitted and the snapshot must be taken atomically, and the lack of atomicity had led to readers using a smallest uncommitted after the snapshot was taken and hence mistakenly skipping some data.
This patch fixes the problem by i) separating the process of removing of prepare entries from the AddCommitted function, ii) removing the prepare entires AFTER the committed sequence number is published, iii) getting smallest uncommitted (from the prepare list) BEFORE taking a snapshot. This guarantees that the smallest uncommitted that is accompanied with a snapshot is less than or equal of such number if it was obtained atomically.
Tested by running MySQLStyleTransactionTest/MySQLStyleTransactionTest.TransactionStressTest that was failing sporadically.
Closes https://github.com/facebook/rocksdb/pull/3703
Differential Revision: D7581934
Pulled By: maysamyabandeh
fbshipit-source-id: dc9d6f4fb477eba75d4d5927326905b548a96a32/WritePrepared Txn: smallest_prepare optimization
Summary:
The is an optimization to reduce lookup in the CommitCache when querying IsInSnapshot. The optimization takes the smallest uncommitted data at the time that the snapshot was taken and if the sequence number of the read data is lower than that number it assumes the data as committed.
To implement this optimization two changes are required: i) The AddPrepared function must be called sequentially to avoid out of order insertion in the PrepareHeap (otherwise the top of the heap does not indicate the smallest prepare in future too), ii) non-2PC transactions also call AddPrepared if they do not commit in one step.
Closes https://github.com/facebook/rocksdb/pull/3649
Differential Revision: D7388630
Pulled By: maysamyabandeh
fbshipit-source-id: b79506238c17467d590763582960d4d90181c600/WritePrepared Txn: AddPrepared for all sub-batches
Summary:
Currently AddPrepared is performed only on the first sub-batch if there are duplicate keys in the write batch. This could cause a problem if the transaction takes too long to commit and the seq number of the first sub-patch moved to old_prepared_ but not the seq of the later ones. The patch fixes this by calling AddPrepared for all sub-patches.
Closes https://github.com/facebook/rocksdb/pull/3651
Differential Revision: D7388635
Pulled By: maysamyabandeh
fbshipit-source-id: 0ccd80c150d9bc42fe955e49ddb9d7ca353067b4/WritePrepared Txn: fix race condition on publishing seq
Summary:
This commit fixes a race condition on calling SetLastPublishedSequence. The function must be called only from the 2nd write queue when two_write_queues is enabled. However there was a bug that would also call it from the main write queue if CommitTimeWriteBatch is provided to the commit request and yet use_only_the_last_commit_time_batch_for_recovery optimization is not enabled. To fix that we penalize the commit request in such cases by doing an additional write solely to publish the seq number from the 2nd queue.
Closes https://github.com/facebook/rocksdb/pull/3641
Differential Revision: D7361508
Pulled By: maysamyabandeh
fbshipit-source-id: bf8f7a27e5cccf5425dccbce25eb0032e8e5a4d7/WritePrepared Txn: fix non-emptied PreparedHeap bug
Summary:
Under a certain sequence of accessing PreparedHeap, there was a bug that would not successfully empty the heap. This would result in performance issues when the heap content is moved to old_prepared_ after max_evicted_seq_ advances the orphan prepared sequence numbers. The patch fixed the bug and add more unit tests. It also does more logging when the unlikely scenarios are faced
Closes https://github.com/facebook/rocksdb/pull/3526
Differential Revision: D7038486
Pulled By: maysamyabandeh
fbshipit-source-id: f1e40bea558f67b03d2a29131fcb8734c65fce97/"
rocksdb,"Support StringAppendOperator(delimiter_char) constructor in java-api
Summary:
Fixes #3336
Closes https://github.com/facebook/rocksdb/pull/3337
Differential Revision: D7196585
Pulled By: sagar0
fbshipit-source-id: a854f3fc906862ecba685b31946e4ef7c0b421c5/"
rocksdb,"Fix formatting in log message
Summary:
Add missing space.
Closes https://github.com/facebook/rocksdb/pull/3826
Differential Revision: D7956059
Pulled By: miasantreble
fbshipit-source-id: 3aeba76385f8726399a3086c46de710636a31191/BlobDB: Fix BlobDBImpl::GCFileAndUpdateLSM issues
Summary:
* Fix BlobDBImpl::GCFileAndUpdateLSM doesn't close the new file, and the new file will not be able to be garbage collected later.
* Fix BlobDBImpl::GCFileAndUpdateLSM doesn't copy over metadata from old file to new file.
Closes https://github.com/facebook/rocksdb/pull/3639
Differential Revision: D7355092
Pulled By: yiwu-arbug
fbshipit-source-id: 4fa3594ac5ce376bed1af04a545c532cfc0088c4/Blob DB: Improve FIFO eviction
Summary:
Improving blob db FIFO eviction with the following changes,
* Change blob_dir_size to max_db_size. Take into account SST file size when computing DB size.
* FIFO now only take into account live sst files and live blob files. It is normal for disk usage to go over max_db_size because there are obsolete sst files and blob files pending deletion.
* FIFO eviction now also evict TTL blob files that's still open. It doesn't evict non-TTL blob files.
* If FIFO is triggered, it will pass an expiration and the current sequence number to compaction filter. Compaction filter will then filter inlined keys to evict those with an earlier expiration and smaller sequence number. So call LSM FIFO.
* Compaction filter also filter those blob indexes where corresponding blob file is gone.
* Add an event listener to listen compaction/flush event and update sst file size.
* Implement DB::Close() to make sure base db, as well as event listener and compaction filter, destruct before blob db.
* More blob db statistics around FIFO.
* Fix some locking issue when accessing a blob file.
Closes https://github.com/facebook/rocksdb/pull/3556
Differential Revision: D7139328
Pulled By: yiwu-arbug
fbshipit-source-id: ea5edb07b33dfceacb2682f4789bea61de28bbfa/Blob DB: remove existing garbage collection implementation
Summary:
Red diff to remove existing implementation of garbage collection. The current approach is reference counting kind of approach and require a lot of effort to get the size counter right on compaction and deletion. I'm going to go with a simple mark-sweep kind of approach and will send another PR for that.
CompactionEventListener was added solely for blob db and it adds complexity and overhead to compaction iterator. Removing it as well.
Closes https://github.com/facebook/rocksdb/pull/3551
Differential Revision: D7130190
Pulled By: yiwu-arbug
fbshipit-source-id: c3a375ad2639a3f6ed179df6eda602372cc5b8df/"
rocksdb,"Align SST file data blocks to avoid spanning multiple pages
Summary:
Provide a block_align option in BlockBasedTableOptions to allow
alignment of SST file data blocks. This will avoid higher
IOPS/throughput load due to < 4KB data blocks spanning 2 4KB pages.
When this option is set to true, the block alignment is set to lower of
block size and 4KB.
Closes https://github.com/facebook/rocksdb/pull/3502
Differential Revision: D7400897
Pulled By: anand1976
fbshipit-source-id: 04cc3bd144e88e3431a4f97604e63ad7a0f06d44/Several small ""fixes""
Summary:
- removed a few unneeded variables
- fused some variable declarations and their assignments
- fixed right-trimming code in string_util.cc to not underflow
- simplifed an assertion
- move non-nullptr check assertion before dereferencing of that pointer
- pass an std::string function parameter by const reference instead of by value (avoiding potential copy)
Closes https://github.com/facebook/rocksdb/pull/3507
Differential Revision: D7004679
Pulled By: sagar0
fbshipit-source-id: 52944952d9b56dfcac3bea3cd7878e315bb563c4/"
rocksdb,"fix memory leak in two_level_iterator
Summary:
this PR fixes a few failed contbuild:
1. ASAN memory leak in Block::NewIterator (table/block.cc:429). the proper destruction of first_level_iter_ and second_level_iter_ of two_level_iterator.cc is missing from the code after the refactoring in https://github.com/facebook/rocksdb/pull/3406
2. various unused param errors introduced by https://github.com/facebook/rocksdb/pull/3662
3. updated comment for `ForceReleaseCachedEntry` to emphasize the use of `force_erase` flag.
Closes https://github.com/facebook/rocksdb/pull/3718
Reviewed By: maysamyabandeh
Differential Revision: D7621192
Pulled By: miasantreble
fbshipit-source-id: 476c94264083a0730ded957c29de7807e4f5b146/"
rocksdb,"Fix the bloom filter skipping empty prefixes
Summary:
bc0da4b5125ac4f43c88879522013814355338e7 optimized bloom filters by skipping duplicate entires when the whole key and prefixes are both added to the bloom. It however used empty string as the initial value of the last entry added to the bloom. This is incorrect since empty key/prefix are valid entires by themselves. This patch fixes that.
Closes https://github.com/facebook/rocksdb/pull/3776
Differential Revision: D7778803
Pulled By: maysamyabandeh
fbshipit-source-id: d5a065daebee17f9403cac51e9d5626aac87bfbc/Skip duplicate bloom keys when whole_key and prefix are mixed
Summary:
Currently we rely on FilterBitsBuilder to skip the duplicate keys. It does that by comparing that hash of the key to the hash of the last added entry. This logic breaks however when we have whole_key_filtering mixed with prefix blooms as their addition to FilterBitsBuilder will be interleaved. The patch fixes that by comparing the last whole key and last prefix with the whole key and prefix of the new key respectively and skip the call to FilterBitsBuilder if it is a duplicate.
Closes https://github.com/facebook/rocksdb/pull/3764
Differential Revision: D7744413
Pulled By: maysamyabandeh
fbshipit-source-id: 15df73bbbafdfd754d4e1f42ea07f47b03bc5eb8/"
rocksdb,"avoid double delete on dummy record insertion failure
Summary:
When the dummy record insertion fails, there is no need to explicitly delete the block as it will be registered for cleanup regardless.
Closes https://github.com/facebook/rocksdb/pull/3688
Differential Revision: D7537741
Pulled By: miasantreble
fbshipit-source-id: fcd3a3d3d382ee8e2c7ced0a4980e683d93a16d6/Remove block-based table assertion for non-empty filter block
Summary:
7a6353bd1c516fe3f7118248c77035697c5ac247 prevents empty filter blocks from being written for SST files containing range deletions only. However the assertion this PR removes is still a problem as we could be reading from a DB generated by a RocksDB build without the 7a6353bd1c516fe3f7118248c77035697c5ac247 patch. So remove the assertion. We already don't do this check when `cache_index_and_filter_blocks=false`, so it should be safe.
Closes https://github.com/facebook/rocksdb/pull/3773
Differential Revision: D7769964
Pulled By: ajkr
fbshipit-source-id: 7285762446f2cd2ccf16efd7a988a106fbb0d8d3/fix memory leak in two_level_iterator
Summary:
this PR fixes a few failed contbuild:
1. ASAN memory leak in Block::NewIterator (table/block.cc:429). the proper destruction of first_level_iter_ and second_level_iter_ of two_level_iterator.cc is missing from the code after the refactoring in https://github.com/facebook/rocksdb/pull/3406
2. various unused param errors introduced by https://github.com/facebook/rocksdb/pull/3662
3. updated comment for `ForceReleaseCachedEntry` to emphasize the use of `force_erase` flag.
Closes https://github.com/facebook/rocksdb/pull/3718
Reviewed By: maysamyabandeh
Differential Revision: D7621192
Pulled By: miasantreble
fbshipit-source-id: 476c94264083a0730ded957c29de7807e4f5b146/uint64_t and size_t changes to compile for iOS
Summary:
In attempting to build a static lib for use in iOS, I ran in to lots of type errors between uint64_t and size_t.  This PR contains the changes I made to get `TARGET_OS=IOS make static_lib` to succeed while also getting Xcode to build successfully with the resulting `librocksdb.a` library imported.
This also compiles for me on macOS and tests fine, but I'm really not sure if I made the correct decisions about where to `static_cast` and where to change types.
Also up for discussion: is iOS worth supporting?  Getting the static lib is just part one, we aren't providing any bridging headers or wrappers like the ObjectiveRocks project, it won't be a great experience.
Closes https://github.com/facebook/rocksdb/pull/3503
Differential Revision: D7106457
Pulled By: gfosco
fbshipit-source-id: 82ac2073de7e1f09b91f6b4faea91d18bd311f8e/Customized BlockBasedTableIterator and LevelIterator
Summary:
Use a customzied BlockBasedTableIterator and LevelIterator to replace current implementations leveraging two-level-iterator. Hope the customized logic will make code easier to understand. As a side effect, BlockBasedTableIterator reduces the allocation for the data block iterator object, and avoid the virtual function call to it, because we can directly reference BlockIter, a final class. Similarly, LevelIterator reduces virtual function call to the dummy iterator iterating the file metadata. It also enabled further optimization.
The upper bound check is also moved from index block to data block. This implementation fits this iterator better. After the change, forwared iterator is slightly optimized to ensure we trim those iterators.
The two-level-iterator now is only used by partitioned index, so it is simplified.
Closes https://github.com/facebook/rocksdb/pull/3406
Differential Revision: D6809041
Pulled By: siying
fbshipit-source-id: 7da3b9b1d3c8e9d9405302c15920af1fcaf50ffa/"
rocksdb,"Several small ""fixes""
Summary:
- removed a few unneeded variables
- fused some variable declarations and their assignments
- fixed right-trimming code in string_util.cc to not underflow
- simplifed an assertion
- move non-nullptr check assertion before dereferencing of that pointer
- pass an std::string function parameter by const reference instead of by value (avoiding potential copy)
Closes https://github.com/facebook/rocksdb/pull/3507
Differential Revision: D7004679
Pulled By: sagar0
fbshipit-source-id: 52944952d9b56dfcac3bea3cd7878e315bb563c4/"
rocksdb,"Fix the memory leak with pinned partitioned filters
Summary:
The existing unit test did not set the level so the check for pinned partitioned filter/index being properly released from the block cache was not properly exercised as they only take effect in level 0. As a result a memory leak in pinned partitioned filters was hidden. The patch fix the test as well as the bug.
Closes https://github.com/facebook/rocksdb/pull/3692
Differential Revision: D7559763
Pulled By: maysamyabandeh
fbshipit-source-id: 55eff274945838af983c764a7d71e8daff092e4a/Align SST file data blocks to avoid spanning multiple pages
Summary:
Provide a block_align option in BlockBasedTableOptions to allow
alignment of SST file data blocks. This will avoid higher
IOPS/throughput load due to < 4KB data blocks spanning 2 4KB pages.
When this option is set to true, the block alignment is set to lower of
block size and 4KB.
Closes https://github.com/facebook/rocksdb/pull/3502
Differential Revision: D7400897
Pulled By: anand1976
fbshipit-source-id: 04cc3bd144e88e3431a4f97604e63ad7a0f06d44/"
rocksdb,"Fix a leak in FilterBlockBuilder when adding prefix
Summary:
Our valgrind continuous test found an interesting leak which got introduced in #3614. We were adding the prefix key before saving the previous prefix start offset, due to which previous prefix offset is always incorrect. Fixed it by saving the the previous sate before adding the key.
Closes https://github.com/facebook/rocksdb/pull/3660
Differential Revision: D7418698
Pulled By: sagar0
fbshipit-source-id: 9933685f943cf2547ed5c553f490035a2fa785cf/Several small ""fixes""
Summary:
- removed a few unneeded variables
- fused some variable declarations and their assignments
- fixed right-trimming code in string_util.cc to not underflow
- simplifed an assertion
- move non-nullptr check assertion before dereferencing of that pointer
- pass an std::string function parameter by const reference instead of by value (avoiding potential copy)
Closes https://github.com/facebook/rocksdb/pull/3507
Differential Revision: D7004679
Pulled By: sagar0
fbshipit-source-id: 52944952d9b56dfcac3bea3cd7878e315bb563c4/"
rocksdb,"Blob DB: remove existing garbage collection implementation
Summary:
Red diff to remove existing implementation of garbage collection. The current approach is reference counting kind of approach and require a lot of effort to get the size counter right on compaction and deletion. I'm going to go with a simple mark-sweep kind of approach and will send another PR for that.
CompactionEventListener was added solely for blob db and it adds complexity and overhead to compaction iterator. Removing it as well.
Closes https://github.com/facebook/rocksdb/pull/3551
Differential Revision: D7130190
Pulled By: yiwu-arbug
fbshipit-source-id: c3a375ad2639a3f6ed179df6eda602372cc5b8df/"
rocksdb,"Skip deleted WALs during recovery
Summary:
This patch record min log number to keep to the manifest while flushing SST files to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic.
Before the commit, for 2PC case, we determined which log number to keep in FindObsoleteFiles(). We looked at the earliest logs with outstanding prepare entries, or prepare entries whose respective commit or abort are in memtable. With the commit, the same calculation is done while we apply the SST flush. Just before installing the flush file, we precompute the earliest log file to keep after the flush finishes using the same logic (but skipping the memtables just flushed), record this information to the manifest entry for this new flushed SST file. This pre-computed value is also remembered in memory, and will later be used to determine whether a log file can be deleted. This value is unlikely to change until next flush because the commit entry will stay in memtable. (In WritePrepared, we could have removed the older log files as soon as all prepared entries are committed. It's not yet done anyway. Even if we do it, the only thing we loss with this new approach is earlier log deletion between two flushes, which does not guarantee to happen anyway because the obsolete file clean-up function is only executed after flush or compaction)
This min log number to keep is stored in the manifest using the safely-ignore customized field of AddFile entry, in order to guarantee that the DB generated using newer release can be opened by previous releases no older than 4.2.
Closes https://github.com/facebook/rocksdb/pull/3765
Differential Revision: D7747618
Pulled By: siying
fbshipit-source-id: d00c92105b4f83852e9754a1b70d6b64cb590729/WritePrepared Txn: smallest_prepare optimization
Summary:
The is an optimization to reduce lookup in the CommitCache when querying IsInSnapshot. The optimization takes the smallest uncommitted data at the time that the snapshot was taken and if the sequence number of the read data is lower than that number it assumes the data as committed.
To implement this optimization two changes are required: i) The AddPrepared function must be called sequentially to avoid out of order insertion in the PrepareHeap (otherwise the top of the heap does not indicate the smallest prepare in future too), ii) non-2PC transactions also call AddPrepared if they do not commit in one step.
Closes https://github.com/facebook/rocksdb/pull/3649
Differential Revision: D7388630
Pulled By: maysamyabandeh
fbshipit-source-id: b79506238c17467d590763582960d4d90181c600/Fix race condition causing double deletion of ssts
Summary:
Possible interleaved execution of background compaction thread calling `FindObsoleteFiles (no full scan) / PurgeObsoleteFiles` and user thread calling `FindObsoleteFiles (full scan) / PurgeObsoleteFiles` can lead to race condition on which RocksDB attempts to delete a file twice. The second attempt will fail and return `IO error`. This may occur to other files,  but this PR targets sst.
Also add a unit test to verify that this PR fixes the issue.
The newly added unit test `obsolete_files_test` has a test case for this scenario, implemented in `ObsoleteFilesTest#RaceForObsoleteFileDeletion`. `TestSyncPoint`s are used to coordinate the interleaving the `user_thread` and background compaction thread. They execute as follows
```
timeline              user_thread                background_compaction thread
t1   |                                          FindObsoleteFiles(full_scan=false)
t2   |     FindObsoleteFiles(full_scan=true)
t3   |                                          PurgeObsoleteFiles
t4   |     PurgeObsoleteFiles
V
```
When `user_thread` invokes `FindObsoleteFiles` with full scan, it collects ALL files in RocksDB directory, including the ones that background compaction thread have collected in its job context. Then `user_thread` will see an IO error when trying to delete these files in `PurgeObsoleteFiles` because background compaction thread has already deleted the file in `PurgeObsoleteFiles`.
To fix this, we make RocksDB remember which (SST) files have been found by threads after calling `FindObsoleteFiles` (see `DBImpl#files_grabbed_for_purge_`). Therefore, when another thread calls `FindObsoleteFiles` with full scan, it will not collect such files.
ajkr could you take a look and comment? Thanks!
Closes https://github.com/facebook/rocksdb/pull/3638
Differential Revision: D7384372
Pulled By: riversand963
fbshipit-source-id: 01489516d60012e722ee65a80e1449e589ce26d3/Fix race condition via concurrent FlushWAL
Summary:
Currently log_writer->AddRecord in WriteImpl is protected from concurrent calls via FlushWAL only if two_write_queues_ option is set. The patch fixes the problem by i) skip log_writer->AddRecord in FlushWAL if manual_wal_flush is not set, ii) protects log_writer->AddRecord in WriteImpl via log_write_mutex_ if manual_wal_flush_ is set but two_write_queues_ is not.
Fixes #3599
Closes https://github.com/facebook/rocksdb/pull/3656
Differential Revision: D7405608
Pulled By: maysamyabandeh
fbshipit-source-id: d6cc265051c77ae49c7c6df4f427350baaf46934/WritePrepared Txn: AddPrepared for all sub-batches
Summary:
Currently AddPrepared is performed only on the first sub-batch if there are duplicate keys in the write batch. This could cause a problem if the transaction takes too long to commit and the seq number of the first sub-patch moved to old_prepared_ but not the seq of the later ones. The patch fixes this by calling AddPrepared for all sub-patches.
Closes https://github.com/facebook/rocksdb/pull/3651
Differential Revision: D7388635
Pulled By: maysamyabandeh
fbshipit-source-id: 0ccd80c150d9bc42fe955e49ddb9d7ca353067b4/FlushReason improvement
Summary:
Right now flush reason ""SuperVersion Change"" covers a few different scenarios which is a bit vague. For example, the following db_bench job should trigger ""Write Buffer Full""
> $ TEST_TMPDIR=/dev/shm ./db_bench -benchmarks=fillrandom -write_buffer_size=1048576 -target_file_size_base=1048576 -max_bytes_for_level_base=4194304
$ grep 'flush_reason' /dev/shm/dbbench/LOG
...
2018/03/06-17:30:42.543638 7f2773b99700 EVENT_LOG_v1 {""time_micros"": 1520386242543634, ""job"": 192, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7006, ""num_deletes"": 0, ""memory_usage"": 1018024, ""flush_reason"": ""SuperVersion Change""}
2018/03/06-17:30:42.569541 7f2773b99700 EVENT_LOG_v1 {""time_micros"": 1520386242569536, ""job"": 193, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7006, ""num_deletes"": 0, ""memory_usage"": 1018104, ""flush_reason"": ""SuperVersion Change""}
2018/03/06-17:30:42.596396 7f2773b99700 EVENT_LOG_v1 {""time_micros"": 1520386242596392, ""job"": 194, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7008, ""num_deletes"": 0, ""memory_usage"": 1018048, ""flush_reason"": ""SuperVersion Change""}
2018/03/06-17:30:42.622444 7f2773b99700 EVENT_LOG_v1 {""time_micros"": 1520386242622440, ""job"": 195, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7006, ""num_deletes"": 0, ""memory_usage"": 1018104, ""flush_reason"": ""SuperVersion Change""}
With the fix:
> 2018/03/19-14:40:02.341451 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602341444, ""job"": 98, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7009, ""num_deletes"": 0, ""memory_usage"": 1018008, ""flush_reason"": ""Write Buffer Full""}
2018/03/19-14:40:02.379655 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602379642, ""job"": 100, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7006, ""num_deletes"": 0, ""memory_usage"": 1018016, ""flush_reason"": ""Write Buffer Full""}
2018/03/19-14:40:02.418479 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602418474, ""job"": 101, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7009, ""num_deletes"": 0, ""memory_usage"": 1018104, ""flush_reason"": ""Write Buffer Full""}
2018/03/19-14:40:02.455084 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602455079, ""job"": 102, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7009, ""num_deletes"": 0, ""memory_usage"": 1018048, ""flush_reason"": ""Write Buffer Full""}
2018/03/19-14:40:02.492293 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602492288, ""job"": 104, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7007, ""num_deletes"": 0, ""memory_usage"": 1018056, ""flush_reason"": ""Write Buffer Full""}
2018/03/19-14:40:02.528720 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602528715, ""job"": 105, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7006, ""num_deletes"": 0, ""memory_usage"": 1018104, ""flush_reason"": ""Write Buffer Full""}
2018/03/19-14:40:02.566255 7f11dc257700 EVENT_LOG_v1 {""time_micros"": 1521495602566238, ""job"": 107, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7009, ""num_deletes"": 0, ""memory_usage"": 1018112, ""flush_reason"": ""Write Buffer Full""}
Closes https://github.com/facebook/rocksdb/pull/3627
Differential Revision: D7328772
Pulled By: miasantreble
fbshipit-source-id: 67c94065fbdd36930f09930aad0aaa6d2c152bb8/Disallow compactions if there isn't enough free space
Summary:
This diff handles cases where compaction causes an ENOSPC error.
This does not handle corner cases where another background job is started while compaction is running, and the other background job triggers ENOSPC, although we do allow the user to provision for these background jobs with SstFileManager::SetCompactionBufferSize.
It also does not handle the case where compaction has finished and some other background job independently triggers ENOSPC.
Usage: Functionality is inside SstFileManager. In particular, users should set SstFileManager::SetMaxAllowedSpaceUsage, which is the reference highwatermark for determining whether to cancel compactions.
Closes https://github.com/facebook/rocksdb/pull/3449
Differential Revision: D7016941
Pulled By: amytai
fbshipit-source-id: 8965ab8dd8b00972e771637a41b4e6c645450445/Windows cumulative patch
Summary:
This patch addressed several issues.
Portability including db_test std::thread -> port::Thread Cc: @
and %z to ROCKSDB portable macro. Cc: maysamyabandeh
Implement Env::AreFilesSame
Make the implementation of file unique number more robust
Get rid of C-runtime and go directly to Windows API when dealing
with file primitives.
Implement GetSectorSize() and aling unbuffered read on the value if
available.
Adjust Windows Logger for the new interface, implement CloseImpl() Cc: anand1976
Fix test running script issue where $status var was of incorrect scope
so the failures were swallowed and not reported.
DestroyDB() creates a logger and opens a LOG file in the directory
being cleaned up. This holds a lock on the folder and the cleanup is
prevented. This fails one of the checkpoin tests. We observe the same in production.
We close the log file in this change.
Fix DBTest2.ReadAmpBitmapLiveInCacheAfterDBClose failure where the test
attempts to open a directory with NewRandomAccessFile which does not
work on Windows.
Fix DBTest.SoftLimit as it is dependent on thread timing. CC: yiwu-arbug
Closes https://github.com/facebook/rocksdb/pull/3552
Differential Revision: D7156304
Pulled By: siying
fbshipit-source-id: 43db0a757f1dfceffeb2b7988043156639173f5b/Fix the Logger::Close() and DBImpl::Close() design pattern
Summary:
The recent Logger::Close() and DBImpl::Close() implementation rely on
calling the CloseImpl() virtual function from the destructor, which will
not work. Refactor the implementation to have a private close helper
function in derived classes that can be called by both CloseImpl() and
the destructor.
Closes https://github.com/facebook/rocksdb/pull/3528
Reviewed By: gfosco
Differential Revision: D7049303
Pulled By: anand1976
fbshipit-source-id: 76a64cbf403209216dfe4864ecf96b5d7f3db9f4/Add delay before flush in CompactRange to avoid write stalling
Summary:
- Refactored logic for checking write stall condition to a helper function: `GetWriteStallConditionAndCause`. Now it is decoupled from the logic for updating WriteController / stats in `RecalculateWriteStallConditions`, so we can reuse it for predicting whether write stall will occur.
- Updated `CompactRange` to first check whether the one additional immutable memtable / L0 file would cause stalling before it flushes. If so, it waits until that is no longer true.
- Updated `bg_cv_` to be signaled on `SetOptions` calls. The stall conditions `CompactRange` cares about can change when (1) flush finishes, (2) compaction finishes, or (3) options dynamically change. The cv was already signaled for (1) and (2) but not yet for (3).
Closes https://github.com/facebook/rocksdb/pull/3381
Differential Revision: D6754983
Pulled By: ajkr
fbshipit-source-id: 5613e03f1524df7192dc6ae885d40fd8f091d972/"
rocksdb,"Windows cumulative patch
Summary:
This patch addressed several issues.
Portability including db_test std::thread -> port::Thread Cc: @
and %z to ROCKSDB portable macro. Cc: maysamyabandeh
Implement Env::AreFilesSame
Make the implementation of file unique number more robust
Get rid of C-runtime and go directly to Windows API when dealing
with file primitives.
Implement GetSectorSize() and aling unbuffered read on the value if
available.
Adjust Windows Logger for the new interface, implement CloseImpl() Cc: anand1976
Fix test running script issue where $status var was of incorrect scope
so the failures were swallowed and not reported.
DestroyDB() creates a logger and opens a LOG file in the directory
being cleaned up. This holds a lock on the folder and the cleanup is
prevented. This fails one of the checkpoin tests. We observe the same in production.
We close the log file in this change.
Fix DBTest2.ReadAmpBitmapLiveInCacheAfterDBClose failure where the test
attempts to open a directory with NewRandomAccessFile which does not
work on Windows.
Fix DBTest.SoftLimit as it is dependent on thread timing. CC: yiwu-arbug
Closes https://github.com/facebook/rocksdb/pull/3552
Differential Revision: D7156304
Pulled By: siying
fbshipit-source-id: 43db0a757f1dfceffeb2b7988043156639173f5b/"
rocksdb,"Skip deleted WALs during recovery
Summary:
This patch record min log number to keep to the manifest while flushing SST files to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic.
Before the commit, for 2PC case, we determined which log number to keep in FindObsoleteFiles(). We looked at the earliest logs with outstanding prepare entries, or prepare entries whose respective commit or abort are in memtable. With the commit, the same calculation is done while we apply the SST flush. Just before installing the flush file, we precompute the earliest log file to keep after the flush finishes using the same logic (but skipping the memtables just flushed), record this information to the manifest entry for this new flushed SST file. This pre-computed value is also remembered in memory, and will later be used to determine whether a log file can be deleted. This value is unlikely to change until next flush because the commit entry will stay in memtable. (In WritePrepared, we could have removed the older log files as soon as all prepared entries are committed. It's not yet done anyway. Even if we do it, the only thing we loss with this new approach is earlier log deletion between two flushes, which does not guarantee to happen anyway because the obsolete file clean-up function is only executed after flush or compaction)
This min log number to keep is stored in the manifest using the safely-ignore customized field of AddFile entry, in order to guarantee that the DB generated using newer release can be opened by previous releases no older than 4.2.
Closes https://github.com/facebook/rocksdb/pull/3765
Differential Revision: D7747618
Pulled By: siying
fbshipit-source-id: d00c92105b4f83852e9754a1b70d6b64cb590729/Revert ""Skip deleted WALs during recovery""
Summary:
This reverts commit 73f21a7b2177aeb82b9f518222e2b9ea8fbb7c4f.
It breaks compatibility. When created a DB using a build with this new change, opening the DB and reading the data will fail with this error:
""Corruption: Can't access /000000.sst: IO error: while stat a file for size: /tmp/xxxx/000000.sst: No such file or directory""
This is because the dummy AddFile4 entry generated by the new code will be treated as a real entry by an older build. The older build will think there is a real file with number 0, but there isn't such a file.
Closes https://github.com/facebook/rocksdb/pull/3762
Differential Revision: D7730035
Pulled By: siying
fbshipit-source-id: f2051859eff20ef1837575ecb1e1bb96b3751e77/fix memory leak in two_level_iterator
Summary:
this PR fixes a few failed contbuild:
1. ASAN memory leak in Block::NewIterator (table/block.cc:429). the proper destruction of first_level_iter_ and second_level_iter_ of two_level_iterator.cc is missing from the code after the refactoring in https://github.com/facebook/rocksdb/pull/3406
2. various unused param errors introduced by https://github.com/facebook/rocksdb/pull/3662
3. updated comment for `ForceReleaseCachedEntry` to emphasize the use of `force_erase` flag.
Closes https://github.com/facebook/rocksdb/pull/3718
Reviewed By: maysamyabandeh
Differential Revision: D7621192
Pulled By: miasantreble
fbshipit-source-id: 476c94264083a0730ded957c29de7807e4f5b146/Skip deleted WALs during recovery
Summary:
This patch record the deleted WAL numbers in the manifest to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic.
Closes https://github.com/facebook/rocksdb/pull/3488
Differential Revision: D6967893
Pulled By: maysamyabandeh
fbshipit-source-id: 13119feb155a08ab6d4909f437c7a750480dc8a1/"
rocksdb,"WritePrepared Txn: enable TryAgain for duplicates at the end of the batch
Summary:
The WriteBatch::Iterate will try with a larger sequence number if the memtable reports a duplicate. This status is specified with TryAgain status. So far the assumption was that the last entry in the batch will never return TryAgain, which is correct when WAL is created via WritePrepared since it always appends a batch separator if a natural one does not exist. However when reading a WAL generated by WriteCommitted this batch separator might  not exist. Although WritePrepared is not supposed to be able to read the WAL generated by WriteCommitted we should avoid confusing scenarios in which the behavior becomes unpredictable. The path fixes that by allowing TryAgain even for the last entry of the write batch.
Closes https://github.com/facebook/rocksdb/pull/3747
Differential Revision: D7708391
Pulled By: maysamyabandeh
fbshipit-source-id: bfaddaa9b14a4cdaff6977f6f63c789a6ab1ee0d/Optionally create DuplicateDetector
Summary:
Address issue https://github.com/facebook/rocksdb/issues/3579
Closes https://github.com/facebook/rocksdb/pull/3589
Differential Revision: D7221161
Pulled By: yiwu-arbug
fbshipit-source-id: bd875ab0aa0e414dfa98b1bf036ba9b4ed351361/Fix some typos in comments and docs.
Summary: Closes https://github.com/facebook/rocksdb/pull/3568
Differential Revision: D7170953
Pulled By: siying
fbshipit-source-id: 9cfb8dd88b7266da920c0e0c1e10fb2c5af0641c/WritePrepared Txn: Fix bug with duplicate keys during recovery
Summary:
Fix the following bugs:
- During recovery a duplicate key was inserted twice into the write batch of the recovery transaction,
once when the memtable returns false (because it was duplicates) and once for the 2nd attempt. This would result into different SubBatch count measured when the recovered transactions is committing.
- If a cf is flushed during recovery the memtable is not available to assist in detecting the duplicate key. This could result into not advancing the sequence number when iterating over duplicate keys of a flushed cf and hence inserting the next key with the wrong sequence number.
- SubBacthCounter would reset the comparator to default comparator after the first duplicate key. The 2nd duplicate key hence would have gone through a wrong comparator and not being detected.
Closes https://github.com/facebook/rocksdb/pull/3562
Differential Revision: D7149440
Pulled By: maysamyabandeh
fbshipit-source-id: 91ec317b165f363f5d11ff8b8c47c81cebb8ed77/Fix 2 more unused reference errors VS2017
Summary:
As in #3425
Closes https://github.com/facebook/rocksdb/pull/3497
Differential Revision: D6979588
Pulled By: gfosco
fbshipit-source-id: e9fb32d04ad45575dfe9de1d79348d158e474197/"
rocksdb,"Fix GitHub issue #3716: gcc-8 warnings
Summary:
Fix the following gcc-8 warnings:
- conflicting C language linkage declaration [-Werror]
- writing to an object with no trivial copy-assignment [-Werror=class-memaccess]
- array subscript -1 is below array bounds [-Werror=array-bounds]
Solves https://github.com/facebook/rocksdb/issues/3716
Closes https://github.com/facebook/rocksdb/pull/3736
Differential Revision: D7684161
Pulled By: yiwu-arbug
fbshipit-source-id: 47c0423d26b74add251f1d3595211eee1e41e54a/Use nullptr instead of NULL / 0 more consistently.
Summary: Closes https://github.com/facebook/rocksdb/pull/3569
Differential Revision: D7170968
Pulled By: yiwu-arbug
fbshipit-source-id: 308a6b7dd358a04fd9a7de3d927bfd8abd57d348/"
rocksdb,"Fix formatting in log message
Summary:
Add missing space.
Closes https://github.com/facebook/rocksdb/pull/3826
Differential Revision: D7956059
Pulled By: miasantreble
fbshipit-source-id: 3aeba76385f8726399a3086c46de710636a31191/MaxFileSizeForLevel: adjust max_file_size for dynamic level compaction
Summary:
`MutableCFOptions::RefreshDerivedOptions` always assume base level is L1, which is not true when `level_compaction_dynamic_level_bytes=true` and Level based compaction is used.
This PR fixes this by recomputing `max_file_size` at query time (in `MaxFileSizeForLevel`)
Fixes https://github.com/facebook/rocksdb/issues/3229
In master:
```
Level Files Size(MB)
--------------------
0       14      846
1        0        0
2        0        0
3        0        0
4        0        0
5       15      366
6       11      481
Cumulative compaction: 3.83 GB write, 2.27 GB read
```
In branch:
```
Level Files Size(MB)
--------------------
0        9      544
1        0        0
2        0        0
3        0        0
4        0        0
5        0        0
6      445      935
Cumulative compaction: 2.91 GB write, 1.46 GB read
```
db_bench command used:
```
./db_bench --benchmarks=""fillrandom,deleterandom,fillrandom,levelstats,stats"" --statistics -deletes=5000 -db=tmp -compression_type=none --num=20000 -value_size=100000 -level_compaction_dynamic_level_bytes=true -target_file_size_base=2097152 -target_file_size_multiplier=2
```
Closes https://github.com/facebook/rocksdb/pull/3755
Differential Revision: D7721381
Pulled By: miasantreble
fbshipit-source-id: 39afb8503190bac3b466adf9bbf2a9b3655789f8/fix intra-L0 FIFO for uncompressed use case
Summary:
- inflate the argument passed as `max_compact_bytes_per_del_file` by a bit (10%). The intent of this argument is prevent L0 files from being intra-L0 compacted multiple times. Without compression, some intra-L0 compactions exceed this limit (and thus aren't executed), even though none of their files have gone through intra-L0 before.
- fix `FindIntraL0Compaction` as it was rejecting some valid intra-L0 compactions. In particular, `compact_bytes_per_del_file` is the work-per-deleted-file for the span [0, span_len), whereas `new_compact_bytes_per_del_file` is the work-per-deleted-file for the span [0, span_len+1). The former is more correct for checking whether we've found an eligible span.
Closes https://github.com/facebook/rocksdb/pull/3684
Differential Revision: D7530396
Pulled By: ajkr
fbshipit-source-id: cad4f50902bdc428ac9ff6fffb13eb288648d85e/Ttl-triggered and snapshot-release-triggered compactions should not be manual compactions
Summary:
Ttl-triggered and snapshot-release-triggered compactions should not be considered as manual compactions. This is a bug.
Closes https://github.com/facebook/rocksdb/pull/3678
Differential Revision: D7498151
Pulled By: sagar0
fbshipit-source-id: a2d5bed05268a4dc93d54ea97a9ae44b366df15d/Level Compaction with TTL
Summary:
Level Compaction with TTL.
As of today, a file could exist in the LSM tree without going through the compaction process for a really long time if there are no updates to the data in the file's key range. For example, in certain use cases, the keys are not actually ""deleted""; instead they are just set to empty values. There might not be any more writes to this ""deleted"" key range, and if so, such data could remain in the LSM for a really long time resulting in wasted space.
Introducing a TTL could solve this problem. Files (and, in turn, data) older than TTL will be scheduled for compaction when there is no other background work. This will make the data go through the regular compaction process and get rid of old unwanted data.
This also has the (good) side-effect of all the data in the non-bottommost level being newer than ttl, and all data in the bottommost level older than ttl. It could lead to more writes while reducing space.
This functionality can be controlled by the newly introduced column family option -- ttl.
TODO for later:
- Make ttl mutable
- Extend TTL to Universal compaction as well? (TTL is already supported in FIFO)
- Maybe deprecate CompactionOptionsFIFO.ttl in favor of this new ttl option.
Closes https://github.com/facebook/rocksdb/pull/3591
Differential Revision: D7275442
Pulled By: sagar0
fbshipit-source-id: dcba484717341200d419b0953dafcdf9eb2f0267/uint64_t and size_t changes to compile for iOS
Summary:
In attempting to build a static lib for use in iOS, I ran in to lots of type errors between uint64_t and size_t.  This PR contains the changes I made to get `TARGET_OS=IOS make static_lib` to succeed while also getting Xcode to build successfully with the resulting `librocksdb.a` library imported.
This also compiles for me on macOS and tests fine, but I'm really not sure if I made the correct decisions about where to `static_cast` and where to change types.
Also up for discussion: is iOS worth supporting?  Getting the static lib is just part one, we aren't providing any bridging headers or wrappers like the ObjectiveRocks project, it won't be a great experience.
Closes https://github.com/facebook/rocksdb/pull/3503
Differential Revision: D7106457
Pulled By: gfosco
fbshipit-source-id: 82ac2073de7e1f09b91f6b4faea91d18bd311f8e/"
rocksdb,"Add block cache related DB properties
Summary:
Add DB properties ""rocksdb.block-cache-capacity"", ""rocksdb.block-cache-usage"", ""rocksdb.block-cache-pinned-usage"" to show block cache usage.
Closes https://github.com/facebook/rocksdb/pull/3734
Differential Revision: D7657180
Pulled By: yiwu-arbug
fbshipit-source-id: dd34a019d5878dab539c51ee82669e97b2b745fd/Add ""rocksdb.live-sst-files-size"" DB property
Summary:
Add ""rocksdb.live-sst-files-size"" DB property which only include files of latest version. Existing ""rocksdb.total-sst-files-size"" include files from all versions and thus include files that's obsolete but not yet deleted. I'm going to use this new property to cap blob db sst + blob files size.
Closes https://github.com/facebook/rocksdb/pull/3548
Differential Revision: D7116939
Pulled By: yiwu-arbug
fbshipit-source-id: c6a52e45ce0f24ef78708156e1a923c1dd6bc79a/"
rocksdb,"Skip deleted WALs during recovery
Summary:
This patch record min log number to keep to the manifest while flushing SST files to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic.
Before the commit, for 2PC case, we determined which log number to keep in FindObsoleteFiles(). We looked at the earliest logs with outstanding prepare entries, or prepare entries whose respective commit or abort are in memtable. With the commit, the same calculation is done while we apply the SST flush. Just before installing the flush file, we precompute the earliest log file to keep after the flush finishes using the same logic (but skipping the memtables just flushed), record this information to the manifest entry for this new flushed SST file. This pre-computed value is also remembered in memory, and will later be used to determine whether a log file can be deleted. This value is unlikely to change until next flush because the commit entry will stay in memtable. (In WritePrepared, we could have removed the older log files as soon as all prepared entries are committed. It's not yet done anyway. Even if we do it, the only thing we loss with this new approach is earlier log deletion between two flushes, which does not guarantee to happen anyway because the obsolete file clean-up function is only executed after flush or compaction)
This min log number to keep is stored in the manifest using the safely-ignore customized field of AddFile entry, in order to guarantee that the DB generated using newer release can be opened by previous releases no older than 4.2.
Closes https://github.com/facebook/rocksdb/pull/3765
Differential Revision: D7747618
Pulled By: siying
fbshipit-source-id: d00c92105b4f83852e9754a1b70d6b64cb590729/Add block cache related DB properties
Summary:
Add DB properties ""rocksdb.block-cache-capacity"", ""rocksdb.block-cache-usage"", ""rocksdb.block-cache-pinned-usage"" to show block cache usage.
Closes https://github.com/facebook/rocksdb/pull/3734
Differential Revision: D7657180
Pulled By: yiwu-arbug
fbshipit-source-id: dd34a019d5878dab539c51ee82669e97b2b745fd/Add ""rocksdb.live-sst-files-size"" DB property
Summary:
Add ""rocksdb.live-sst-files-size"" DB property which only include files of latest version. Existing ""rocksdb.total-sst-files-size"" include files from all versions and thus include files that's obsolete but not yet deleted. I'm going to use this new property to cap blob db sst + blob files size.
Closes https://github.com/facebook/rocksdb/pull/3548
Differential Revision: D7116939
Pulled By: yiwu-arbug
fbshipit-source-id: c6a52e45ce0f24ef78708156e1a923c1dd6bc79a/"
rocksdb,"Skip deleted WALs during recovery
Summary:
This patch record min log number to keep to the manifest while flushing SST files to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic.
Before the commit, for 2PC case, we determined which log number to keep in FindObsoleteFiles(). We looked at the earliest logs with outstanding prepare entries, or prepare entries whose respective commit or abort are in memtable. With the commit, the same calculation is done while we apply the SST flush. Just before installing the flush file, we precompute the earliest log file to keep after the flush finishes using the same logic (but skipping the memtables just flushed), record this information to the manifest entry for this new flushed SST file. This pre-computed value is also remembered in memory, and will later be used to determine whether a log file can be deleted. This value is unlikely to change until next flush because the commit entry will stay in memtable. (In WritePrepared, we could have removed the older log files as soon as all prepared entries are committed. It's not yet done anyway. Even if we do it, the only thing we loss with this new approach is earlier log deletion between two flushes, which does not guarantee to happen anyway because the obsolete file clean-up function is only executed after flush or compaction)
This min log number to keep is stored in the manifest using the safely-ignore customized field of AddFile entry, in order to guarantee that the DB generated using newer release can be opened by previous releases no older than 4.2.
Closes https://github.com/facebook/rocksdb/pull/3765
Differential Revision: D7747618
Pulled By: siying
fbshipit-source-id: d00c92105b4f83852e9754a1b70d6b64cb590729/Revert ""Skip deleted WALs during recovery""
Summary:
This reverts commit 73f21a7b2177aeb82b9f518222e2b9ea8fbb7c4f.
It breaks compatibility. When created a DB using a build with this new change, opening the DB and reading the data will fail with this error:
""Corruption: Can't access /000000.sst: IO error: while stat a file for size: /tmp/xxxx/000000.sst: No such file or directory""
This is because the dummy AddFile4 entry generated by the new code will be treated as a real entry by an older build. The older build will think there is a real file with number 0, but there isn't such a file.
Closes https://github.com/facebook/rocksdb/pull/3762
Differential Revision: D7730035
Pulled By: siying
fbshipit-source-id: f2051859eff20ef1837575ecb1e1bb96b3751e77/Skip deleted WALs during recovery
Summary:
This patch record the deleted WAL numbers in the manifest to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic.
Closes https://github.com/facebook/rocksdb/pull/3488
Differential Revision: D6967893
Pulled By: maysamyabandeh
fbshipit-source-id: 13119feb155a08ab6d4909f437c7a750480dc8a1/"
rocksdb,"Several small ""fixes""
Summary:
- removed a few unneeded variables
- fused some variable declarations and their assignments
- fixed right-trimming code in string_util.cc to not underflow
- simplifed an assertion
- move non-nullptr check assertion before dereferencing of that pointer
- pass an std::string function parameter by const reference instead of by value (avoiding potential copy)
Closes https://github.com/facebook/rocksdb/pull/3507
Differential Revision: D7004679
Pulled By: sagar0
fbshipit-source-id: 52944952d9b56dfcac3bea3cd7878e315bb563c4/"
rocksdb,"fix wrong length in snprintf
Summary: Closes https://github.com/facebook/rocksdb/pull/3622
Differential Revision: D7307689
Pulled By: ajkr
fbshipit-source-id: b8f52effc63fea06c2058b39c60944c2c1f814b4/Use nullptr instead of NULL / 0 more consistently.
Summary: Closes https://github.com/facebook/rocksdb/pull/3569
Differential Revision: D7170968
Pulled By: yiwu-arbug
fbshipit-source-id: 308a6b7dd358a04fd9a7de3d927bfd8abd57d348/"
rocksdb,"Add block cache related DB properties
Summary:
Add DB properties ""rocksdb.block-cache-capacity"", ""rocksdb.block-cache-usage"", ""rocksdb.block-cache-pinned-usage"" to show block cache usage.
Closes https://github.com/facebook/rocksdb/pull/3734
Differential Revision: D7657180
Pulled By: yiwu-arbug
fbshipit-source-id: dd34a019d5878dab539c51ee82669e97b2b745fd/fix behavior does not match name for ""IsFileDeletionsEnabled""
Summary:
for PR https://github.com/facebook/rocksdb/pull/3598
I deleted the original repo for some reason. Sorry for the inconvenience.
Closes https://github.com/facebook/rocksdb/pull/3612
Differential Revision: D7291671
Pulled By: ajkr
fbshipit-source-id: 918490ba86b13fe450d232af436cbe259d847c64/Add ""rocksdb.live-sst-files-size"" DB property
Summary:
Add ""rocksdb.live-sst-files-size"" DB property which only include files of latest version. Existing ""rocksdb.total-sst-files-size"" include files from all versions and thus include files that's obsolete but not yet deleted. I'm going to use this new property to cap blob db sst + blob files size.
Closes https://github.com/facebook/rocksdb/pull/3548
Differential Revision: D7116939
Pulled By: yiwu-arbug
fbshipit-source-id: c6a52e45ce0f24ef78708156e1a923c1dd6bc79a/"
rocksdb,"Fix race condition via concurrent FlushWAL
Summary:
Currently log_writer->AddRecord in WriteImpl is protected from concurrent calls via FlushWAL only if two_write_queues_ option is set. The patch fixes the problem by i) skip log_writer->AddRecord in FlushWAL if manual_wal_flush is not set, ii) protects log_writer->AddRecord in WriteImpl via log_write_mutex_ if manual_wal_flush_ is set but two_write_queues_ is not.
Fixes #3599
Closes https://github.com/facebook/rocksdb/pull/3656
Differential Revision: D7405608
Pulled By: maysamyabandeh
fbshipit-source-id: d6cc265051c77ae49c7c6df4f427350baaf46934/Windows cumulative patch
Summary:
This patch addressed several issues.
Portability including db_test std::thread -> port::Thread Cc: @
and %z to ROCKSDB portable macro. Cc: maysamyabandeh
Implement Env::AreFilesSame
Make the implementation of file unique number more robust
Get rid of C-runtime and go directly to Windows API when dealing
with file primitives.
Implement GetSectorSize() and aling unbuffered read on the value if
available.
Adjust Windows Logger for the new interface, implement CloseImpl() Cc: anand1976
Fix test running script issue where $status var was of incorrect scope
so the failures were swallowed and not reported.
DestroyDB() creates a logger and opens a LOG file in the directory
being cleaned up. This holds a lock on the folder and the cleanup is
prevented. This fails one of the checkpoin tests. We observe the same in production.
We close the log file in this change.
Fix DBTest2.ReadAmpBitmapLiveInCacheAfterDBClose failure where the test
attempts to open a directory with NewRandomAccessFile which does not
work on Windows.
Fix DBTest.SoftLimit as it is dependent on thread timing. CC: yiwu-arbug
Closes https://github.com/facebook/rocksdb/pull/3552
Differential Revision: D7156304
Pulled By: siying
fbshipit-source-id: 43db0a757f1dfceffeb2b7988043156639173f5b/Fix deadlock in ColumnFamilyData::InstallSuperVersion()
Summary:
Deadlock: a memtable flush holds DB::mutex_ and calls ThreadLocalPtr::Scrape(), which locks ThreadLocalPtr mutex; meanwhile, a thread exit handler locks ThreadLocalPtr mutex and calls SuperVersionUnrefHandle, which tries to lock DB::mutex_.
This deadlock is hit all the time on our workload. It blocks our release.
In general, the problem is that ThreadLocalPtr takes an arbitrary callback and calls it while holding a lock on a global mutex. The same global mutex is (at least in some cases) locked by almost all ThreadLocalPtr methods, on any instance of ThreadLocalPtr. So, there'll be a deadlock if the callback tries to do anything to any instance of ThreadLocalPtr, or waits for another thread to do so.
So, probably the only safe way to use ThreadLocalPtr callbacks is to do only do simple and lock-free things in them.
This PR fixes the deadlock by making sure that local_sv_ never holds the last reference to a SuperVersion, and therefore SuperVersionUnrefHandle never has to do any nontrivial cleanup.
I also searched for other uses of ThreadLocalPtr to see if they may have similar bugs. There's only one other use, in transaction_lock_mgr.cc, and it looks fine.
Closes https://github.com/facebook/rocksdb/pull/3510
Reviewed By: sagar0
Differential Revision: D7005346
Pulled By: al13n321
fbshipit-source-id: 37575591b84f07a891d6659e87e784660fde815f/"
rocksdb,"fix some text in comments.
Summary:
1. Remove redundant text.
2. Make terminology consistent across all comments and doc of RocksDB. Also do
our best to conform to conventions. Specifically, use 'callback' instead of
'call-back' [wikipedia](https://en.wikipedia.org/wiki/Callback_(computer_programming)).
Closes https://github.com/facebook/rocksdb/pull/3693
Differential Revision: D7560396
Pulled By: riversand963
fbshipit-source-id: ba8c251c487f4e7d1872a1a8dc680f9e35a6ffb8/"
rocksdb,"Skip deleted WALs during recovery
Summary:
This patch record min log number to keep to the manifest while flushing SST files to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic.
Before the commit, for 2PC case, we determined which log number to keep in FindObsoleteFiles(). We looked at the earliest logs with outstanding prepare entries, or prepare entries whose respective commit or abort are in memtable. With the commit, the same calculation is done while we apply the SST flush. Just before installing the flush file, we precompute the earliest log file to keep after the flush finishes using the same logic (but skipping the memtables just flushed), record this information to the manifest entry for this new flushed SST file. This pre-computed value is also remembered in memory, and will later be used to determine whether a log file can be deleted. This value is unlikely to change until next flush because the commit entry will stay in memtable. (In WritePrepared, we could have removed the older log files as soon as all prepared entries are committed. It's not yet done anyway. Even if we do it, the only thing we loss with this new approach is earlier log deletion between two flushes, which does not guarantee to happen anyway because the obsolete file clean-up function is only executed after flush or compaction)
This min log number to keep is stored in the manifest using the safely-ignore customized field of AddFile entry, in order to guarantee that the DB generated using newer release can be opened by previous releases no older than 4.2.
Closes https://github.com/facebook/rocksdb/pull/3765
Differential Revision: D7747618
Pulled By: siying
fbshipit-source-id: d00c92105b4f83852e9754a1b70d6b64cb590729/Revert ""Skip deleted WALs during recovery""
Summary:
This reverts commit 73f21a7b2177aeb82b9f518222e2b9ea8fbb7c4f.
It breaks compatibility. When created a DB using a build with this new change, opening the DB and reading the data will fail with this error:
""Corruption: Can't access /000000.sst: IO error: while stat a file for size: /tmp/xxxx/000000.sst: No such file or directory""
This is because the dummy AddFile4 entry generated by the new code will be treated as a real entry by an older build. The older build will think there is a real file with number 0, but there isn't such a file.
Closes https://github.com/facebook/rocksdb/pull/3762
Differential Revision: D7730035
Pulled By: siying
fbshipit-source-id: f2051859eff20ef1837575ecb1e1bb96b3751e77/fix data race
Summary:
Fix a TSAN failure in `DBRangeDelTest.ValidLevelSubcompactionBoundaries`:
https://gist.github.com/miasantreble/712e04b4de2ff7f193c98b1acf07e899
Closes https://github.com/facebook/rocksdb/pull/3691
Differential Revision: D7541400
Pulled By: miasantreble
fbshipit-source-id: b0b4538980bce7febd0385e61d6e046580bcaefb/Level Compaction with TTL
Summary:
Level Compaction with TTL.
As of today, a file could exist in the LSM tree without going through the compaction process for a really long time if there are no updates to the data in the file's key range. For example, in certain use cases, the keys are not actually ""deleted""; instead they are just set to empty values. There might not be any more writes to this ""deleted"" key range, and if so, such data could remain in the LSM for a really long time resulting in wasted space.
Introducing a TTL could solve this problem. Files (and, in turn, data) older than TTL will be scheduled for compaction when there is no other background work. This will make the data go through the regular compaction process and get rid of old unwanted data.
This also has the (good) side-effect of all the data in the non-bottommost level being newer than ttl, and all data in the bottommost level older than ttl. It could lead to more writes while reducing space.
This functionality can be controlled by the newly introduced column family option -- ttl.
TODO for later:
- Make ttl mutable
- Extend TTL to Universal compaction as well? (TTL is already supported in FIFO)
- Maybe deprecate CompactionOptionsFIFO.ttl in favor of this new ttl option.
Closes https://github.com/facebook/rocksdb/pull/3591
Differential Revision: D7275442
Pulled By: sagar0
fbshipit-source-id: dcba484717341200d419b0953dafcdf9eb2f0267/Skip deleted WALs during recovery
Summary:
This patch record the deleted WAL numbers in the manifest to ignore them and any WAL older than them during recovery. This is to avoid scenarios when we have a gap between the WAL files are fed to the recovery procedure. The gap could happen by for example out-of-order WAL deletion. Such gap could cause problems in 2PC recovery where the prepared and commit entry are placed into two separate WAL and gap in the WALs could result into not processing the WAL with the commit entry and hence breaking the 2PC recovery logic.
Closes https://github.com/facebook/rocksdb/pull/3488
Differential Revision: D6967893
Pulled By: maysamyabandeh
fbshipit-source-id: 13119feb155a08ab6d4909f437c7a750480dc8a1/Optimize overlap checking for external file ingestion
Summary:
If there are a lot of overlapped files in L0, creating a merging iterator for
all files in L0 to check overlap can be very slow because we need to read and
seek all files in L0. However, in that case, the ingested file is likely to
overlap with some files in L0, so if we check those files one by one, we can stop
once we encounter overlap.
Ref: https://github.com/facebook/rocksdb/issues/3540
Closes https://github.com/facebook/rocksdb/pull/3564
Differential Revision: D7196784
Pulled By: anand1976
fbshipit-source-id: 8700c1e903bd515d0fa7005b6ce9b3a3d9db2d67/Use nullptr instead of NULL / 0 more consistently.
Summary: Closes https://github.com/facebook/rocksdb/pull/3569
Differential Revision: D7170968
Pulled By: yiwu-arbug
fbshipit-source-id: 308a6b7dd358a04fd9a7de3d927bfd8abd57d348/Add ""rocksdb.live-sst-files-size"" DB property
Summary:
Add ""rocksdb.live-sst-files-size"" DB property which only include files of latest version. Existing ""rocksdb.total-sst-files-size"" include files from all versions and thus include files that's obsolete but not yet deleted. I'm going to use this new property to cap blob db sst + blob files size.
Closes https://github.com/facebook/rocksdb/pull/3548
Differential Revision: D7116939
Pulled By: yiwu-arbug
fbshipit-source-id: c6a52e45ce0f24ef78708156e1a923c1dd6bc79a/Customized BlockBasedTableIterator and LevelIterator
Summary:
Use a customzied BlockBasedTableIterator and LevelIterator to replace current implementations leveraging two-level-iterator. Hope the customized logic will make code easier to understand. As a side effect, BlockBasedTableIterator reduces the allocation for the data block iterator object, and avoid the virtual function call to it, because we can directly reference BlockIter, a final class. Similarly, LevelIterator reduces virtual function call to the dummy iterator iterating the file metadata. It also enabled further optimization.
The upper bound check is also moved from index block to data block. This implementation fits this iterator better. After the change, forwared iterator is slightly optimized to ensure we trim those iterators.
The two-level-iterator now is only used by partitioned index, so it is simplified.
Closes https://github.com/facebook/rocksdb/pull/3406
Differential Revision: D6809041
Pulled By: siying
fbshipit-source-id: 7da3b9b1d3c8e9d9405302c15920af1fcaf50ffa/"
rocksdb,"fix memory leak in two_level_iterator
Summary:
this PR fixes a few failed contbuild:
1. ASAN memory leak in Block::NewIterator (table/block.cc:429). the proper destruction of first_level_iter_ and second_level_iter_ of two_level_iterator.cc is missing from the code after the refactoring in https://github.com/facebook/rocksdb/pull/3406
2. various unused param errors introduced by https://github.com/facebook/rocksdb/pull/3662
3. updated comment for `ForceReleaseCachedEntry` to emphasize the use of `force_erase` flag.
Closes https://github.com/facebook/rocksdb/pull/3718
Reviewed By: maysamyabandeh
Differential Revision: D7621192
Pulled By: miasantreble
fbshipit-source-id: 476c94264083a0730ded957c29de7807e4f5b146/"
rocksdb,"Adjust pread/pwrite to return Status
Summary:
Returning bytes_read causes the caller to call GetLastError()
to report failure but the lasterror may be overwritten by then
so we lose the error code.
Fix up CMake file to include xpress source code only when needed.
Fix warning for the uninitialized var.
Closes https://github.com/facebook/rocksdb/pull/3795
Differential Revision: D7832935
Pulled By: anand1976
fbshipit-source-id: 4be21affb9b85d361b96244f4ef459f492b7cb2b/Windows cumulative patch
Summary:
This patch addressed several issues.
Portability including db_test std::thread -> port::Thread Cc: @
and %z to ROCKSDB portable macro. Cc: maysamyabandeh
Implement Env::AreFilesSame
Make the implementation of file unique number more robust
Get rid of C-runtime and go directly to Windows API when dealing
with file primitives.
Implement GetSectorSize() and aling unbuffered read on the value if
available.
Adjust Windows Logger for the new interface, implement CloseImpl() Cc: anand1976
Fix test running script issue where $status var was of incorrect scope
so the failures were swallowed and not reported.
DestroyDB() creates a logger and opens a LOG file in the directory
being cleaned up. This holds a lock on the folder and the cleanup is
prevented. This fails one of the checkpoin tests. We observe the same in production.
We close the log file in this change.
Fix DBTest2.ReadAmpBitmapLiveInCacheAfterDBClose failure where the test
attempts to open a directory with NewRandomAccessFile which does not
work on Windows.
Fix DBTest.SoftLimit as it is dependent on thread timing. CC: yiwu-arbug
Closes https://github.com/facebook/rocksdb/pull/3552
Differential Revision: D7156304
Pulled By: siying
fbshipit-source-id: 43db0a757f1dfceffeb2b7988043156639173f5b/"
rocksdb,"Windows JNI build fixes (#4015)
Summary:
Fixing compilation, unsatisfied link exceptions (updated list of files that needs to be linked) and warnings for Windows build.
```C++
//MSVC 2015 does not support dynamic arrays like:
rocksdb::Slice key_parts[jkey_parts_len];
//I have converted to:
std::vector<rocksdb::Slice> key_parts;
```
Also reusing `free_key_parts` that does the same as `free_key_value_parts` that was removed.
Java elapsedTime unit test increase of sleep to 2 ms. Otherwise it was failing.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4015
Differential Revision: D8558215
Pulled By: sagar0
fbshipit-source-id: d3c34f846343f9218424da2402a2bd367bbd0aa2/zLinux build error with gcc and IBM Java headers (#4013)
Summary:
`SetByteArrayRegion` does not have const source buffer thus compilation error. I have made that same as in other JNI files (const_cast). It was missing for new transaction functionality added recently.
Closes https://github.com/facebook/rocksdb/pull/4013
Differential Revision: D8493290
Pulled By: sagar0
fbshipit-source-id: 14afedf365b111121bd11e68a8d546a1cae68b26/Crash on Windows, because of shared_ptr reinterpret cast (#3999)
Summary:
For more details see #3998
Closes https://github.com/facebook/rocksdb/pull/3999
Differential Revision: D8458905
Pulled By: sagar0
fbshipit-source-id: d6e09182933253a08eaf81ac7cfe50ed3b6576c5/"
rocksdb,"check if data size exceeds java array vm limit when it is copied in jni (#3850)
Summary:
to address issue #3849
Closes https://github.com/facebook/rocksdb/pull/3850
Differential Revision: D8695487
Pulled By: sagar0
fbshipit-source-id: 04baeb2127663934ed1321fe6d9a9ec23c86e16b/"
rocksdb,"check if data size exceeds java array vm limit when it is copied in jni (#3850)
Summary:
to address issue #3849
Closes https://github.com/facebook/rocksdb/pull/3850
Differential Revision: D8695487
Pulled By: sagar0
fbshipit-source-id: 04baeb2127663934ed1321fe6d9a9ec23c86e16b/"
rocksdb,"Support range deletion tombstones in IngestExternalFile SSTs (#3778)
Summary:
Fixes #3391.
This change adds a `DeleteRange` method to `SstFileWriter` and adds
support for ingesting SSTs with range deletion tombstones. This is
important for applications that need to atomically ingest SSTs while
clearing out any existing keys in a given key range.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/3778
Differential Revision: D8821836
Pulled By: anand1976
fbshipit-source-id: ca7786c1947ff129afa703dab011d524c7883844/Allow storing metadata with backups for Java API (#4111)
Summary:
Exposes BackupEngine::CreateNewBackupWithMetadata and BackupInfo metadata to the Java API.
Full disclaimer, I'm not familiar with JNI stuff, so I might have forgotten something (hopefully no memory leaks!). I also tried to find contributing guidelines but didn't see any, but I hope the PR style is consistent with the rest of the code base.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4111
Differential Revision: D8811180
Pulled By: ajkr
fbshipit-source-id: e38b3e396c7574328c2a1a0e55acc8d092b6a569/"
rocksdb,"option for timing measurement of non-blocking ops during compaction (#4029)
Summary:
For example calling CompactionFilter is always timed and gives the user no way to disable.
This PR will disable the timer if `Statistics::stats_level_` (which is part of DBOptions) is `kExceptDetailedTimers`
Closes https://github.com/facebook/rocksdb/pull/4029
Differential Revision: D8583670
Pulled By: miasantreble
fbshipit-source-id: 913be9fe433ae0c06e88193b59d41920a532307f/"
rocksdb,"Pending output file number should be released after bulkload failure (#4145)
Summary:
If bulkload fails for an input error, the pending output file number wasn't released. This bug can cause all future files with larger number than the current number won't be deleted, even they are compacted. This commit fixes the bug.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4145
Differential Revision: D8877900
Pulled By: siying
fbshipit-source-id: 080be92a23d43305ca1e13fe1c06eb4cd0b01466/Support range deletion tombstones in IngestExternalFile SSTs (#3778)
Summary:
Fixes #3391.
This change adds a `DeleteRange` method to `SstFileWriter` and adds
support for ingesting SSTs with range deletion tombstones. This is
important for applications that need to atomically ingest SSTs while
clearing out any existing keys in a given key range.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/3778
Differential Revision: D8821836
Pulled By: anand1976
fbshipit-source-id: ca7786c1947ff129afa703dab011d524c7883844/Reduce execution time of a test. (#4127)
Summary:
Reduce the number of key ranges in `ExternalSSTFileTest.OverlappingRanges` so
that the test completes in shorter time to avoid timeouts.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4127
Differential Revision: D8827851
Pulled By: riversand963
fbshipit-source-id: a16387b0cc92a7c872b1c50f0cfbadc463afc9db/Fix ExternalSSTFileTest::OverlappingRanges test on Solaris Sparc (#4012)
Summary:
Fix of #4011
Closes https://github.com/facebook/rocksdb/pull/4012
Differential Revision: D8499173
Pulled By: sagar0
fbshipit-source-id: cbb2b90c544ed364a3640ea65835d577b2dbc5df/"
rocksdb,"Add GCC 8 to Travis (#3433)
Summary:
- Avoid `strdup` to use jemalloc on Windows
- Use `size_t` for consistency
- Add GCC 8 to Travis
- Add CMAKE_BUILD_TYPE=Release to Travis
Pull Request resolved: https://github.com/facebook/rocksdb/pull/3433
Differential Revision: D6837948
Pulled By: sagar0
fbshipit-source-id: b8543c3a4da9cd07ee9a33f9f4623188e233261f/"
rocksdb,"Pin top-level index on partitioned index/filter blocks (#4037)
Summary:
Top-level index in partitioned index/filter blocks are small and could be pinned in memory. So far we use that by cache_index_and_filter_blocks to false. This however make it difficult to keep account of the total memory usage. This patch introduces pin_top_level_index_and_filter which in combination with cache_index_and_filter_blocks=true keeps the top-level index in cache and yet pinned them to avoid cache misses and also cache lookup overhead.
Closes https://github.com/facebook/rocksdb/pull/4037
Differential Revision: D8596218
Pulled By: maysamyabandeh
fbshipit-source-id: 3a5f7f9ca6b4b525b03ff6bd82354881ae974ad2/"
rocksdb,"Catchup with posix features
Summary:
Catch up with Posix features
NewWritableRWFile must fail when file does not exists
Implement Env::Truncate()
Adjust Env options optimization functions
Implement MemoryMappedBuffer on Windows.
Closes https://github.com/facebook/rocksdb/pull/3857
Differential Revision: D8053610
Pulled By: ajkr
fbshipit-source-id: ccd0d46c29648a9f6f496873bc1c9d6c5547487e/"
rocksdb,"Suppress clang analyzer error (#4299)
Summary:
Suppress multiple clang-analyzer error. All of them are clang false-positive.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4299
Differential Revision: D9430740
Pulled By: yiwu-arbug
fbshipit-source-id: fbdd575bdc214d124826d61d35a117995c509279/"
rocksdb,"WriteBufferManager JNI fixes (#4579)
Summary:
1. `WriteBufferManager` should have a reference alive in Java side through `Options`/`DBOptions` otherwise, if it's GC'ed at java side, native side can seg fault.
2. native method `setWriteBufferManager()` in `DBOptions.java` doesn't have it's jni method invocation in rocksdbjni which is added in this PR
3. `DBOptionsTest.java` is referencing object of `Options`. Instead it should be testing against `DBOptions`. Seems like a copy paste error.
4. Add a getter for WriteBufferManager.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4579
Differential Revision: D10561150
Pulled By: sagar0
fbshipit-source-id: 139a15c7f051a9f77b4200215b88267b48fbc487/"
rocksdb,"WriteBufferManager JNI fixes (#4579)
Summary:
1. `WriteBufferManager` should have a reference alive in Java side through `Options`/`DBOptions` otherwise, if it's GC'ed at java side, native side can seg fault.
2. native method `setWriteBufferManager()` in `DBOptions.java` doesn't have it's jni method invocation in rocksdbjni which is added in this PR
3. `DBOptionsTest.java` is referencing object of `Options`. Instead it should be testing against `DBOptions`. Seems like a copy paste error.
4. Add a getter for WriteBufferManager.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4579
Differential Revision: D10561150
Pulled By: sagar0
fbshipit-source-id: 139a15c7f051a9f77b4200215b88267b48fbc487/"
rocksdb,"Small issues (#4564)
Summary:
Couple of very minor improvements (typos in comments, full qualification of class name, reordering members of a struct to make it smaller)
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4564
Differential Revision: D10510183
Pulled By: maysamyabandeh
fbshipit-source-id: c7ddf9bfbf2db08cd31896c3fd93789d3fa68c8b/Support pragma once in all header files and cleanup some warnings (#4339)
Summary:
As you know, almost all compilers support ""pragma once"" keyword instead of using include guards. To be keep consistency between header files, all header files are edited.
Besides this, try to fix some warnings about loss of data.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4339
Differential Revision: D9654990
Pulled By: ajkr
fbshipit-source-id: c2cf3d2d03a599847684bed81378c401920ca848/"
rocksdb,"Drop unnecessary deletion markers during compaction (issue - 3842) (#4289)
Summary:
This PR fixes issue 3842. We drop deletion markers iff
1. We are the bottom most level AND
2. All other occurrences of the key are in the same snapshot range as the delete
I've also enhanced db_stress_test to add an option that does a full compare of the keys. This is done by a single thread (thread # 0). For tests I've run (so far)
make check -j64
db_stress
db_stress  --acquire_snapshot_one_in=1000 --ops_per_thread=100000 /* to verify that new code doesnt break existing tests */
./db_stress --compare_full_db_state_snapshot=true --acquire_snapshot_one_in=1000 --ops_per_thread=100000 /* to verify new test code */
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4289
Differential Revision: D9491165
Pulled By: shrikanthshankar
fbshipit-source-id: ce144834f31736c189aaca81bed356ba990331e2/Add path to WritableFileWriter. (#4039)
Summary:
We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise it's hard to tell what has been going on.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4039
Differential Revision: D8670178
Pulled By: riversand963
fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/"
rocksdb,"Try to fix ExternalSSTFileTest.IngestNonExistingFile flakines (#4625)
Summary:
ExternalSSTFileTest.IngestNonExistingFile occasionally fail for number of SST files after manual compaction doesn't go down as expected. Although I don't find a reason how this can happen, adding an extra waiting to make sure obsolete file purging has finished before we check the files doesn't hurt.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4625
Differential Revision: D12910586
Pulled By: siying
fbshipit-source-id: 2a5ddec6908c99cf3bcc78431c6f93151c2cab59/"
rocksdb,"WriteBatch::Iterate wrongly returns Status::Corruption (#4478)
Summary:
Wrong I overwrite `WriteBatch::Handler::Continue` to return _false_ at some point, I always get the `Status::Corruption` error.
I don't think this check is used correctly here: The counter in `found` cannot reflect all entries in the WriteBatch when we exit the loop early.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4478
Differential Revision: D10317416
Pulled By: yiwu-arbug
fbshipit-source-id: cccae3382805035f9b3239b66682b5fcbba6bb61/"
rocksdb,"Support pragma once in all header files and cleanup some warnings (#4339)
Summary:
As you know, almost all compilers support ""pragma once"" keyword instead of using include guards. To be keep consistency between header files, all header files are edited.
Besides this, try to fix some warnings about loss of data.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4339
Differential Revision: D9654990
Pulled By: ajkr
fbshipit-source-id: c2cf3d2d03a599847684bed81378c401920ca848/Add path to WritableFileWriter. (#4039)
Summary:
We want to sample the file I/O issued by RocksDB and report the function calls. This requires us to include the file paths otherwise it's hard to tell what has been going on.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4039
Differential Revision: D8670178
Pulled By: riversand963
fbshipit-source-id: 97ee806d1c583a2983e28e213ee764dc6ac28f7a/"
rocksdb,"Use only ""local"" range tombstones during Get (#4449)
Summary:
Previously, range tombstones were accumulated from every level, which
was necessary if a range tombstone in a higher level covered a key in a lower
level. However, RangeDelAggregator::AddTombstones's complexity is based on
the number of tombstones that are currently stored in it, which is wasteful in
the Get case, where we only need to know the highest sequence number of range
tombstones that cover the key from higher levels, and compute the highest covering
sequence number at the current level. This change introduces this optimization, and
removes the use of RangeDelAggregator from the Get path.
In the benchmark results, the following command was used to initialize the database:
```
./db_bench -db=/dev/shm/5k-rts -use_existing_db=false -benchmarks=filluniquerandom -write_buffer_size=1048576 -compression_type=lz4 -target_file_size_base=1048576 -max_bytes_for_level_base=4194304 -value_size=112 -key_size=16 -block_size=4096 -level_compaction_dynamic_level_bytes=true -num=5000000 -max_background_jobs=12 -benchmark_write_rate_limit=20971520 -range_tombstone_width=100 -writes_per_range_tombstone=100 -max_num_range_tombstones=50000 -bloom_bits=8
```
...and the following command was used to measure read throughput:
```
./db_bench -db=/dev/shm/5k-rts/ -use_existing_db=true -benchmarks=readrandom -disable_auto_compactions=true -num=5000000 -reads=100000 -threads=32
```
The filluniquerandom command was only run once, and the resulting database was used
to measure read performance before and after the PR. Both binaries were compiled with
`DEBUG_LEVEL=0`.
Readrandom results before PR:
```
readrandom   :       4.544 micros/op 220090 ops/sec;   16.9 MB/s (63103 of 100000 found)
```
Readrandom results after PR:
```
readrandom   :      11.147 micros/op 89707 ops/sec;    6.9 MB/s (63103 of 100000 found)
```
So it's actually slower right now, but this PR paves the way for future optimizations (see #4493).
----
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4449
Differential Revision: D10370575
Pulled By: abhimadan
fbshipit-source-id: 9a2e152be1ef36969055c0e9eb4beb0d96c11f4d/Fix user comparator receiving internal key (#4575)
Summary:
There was a bug that the user comparator would receive the internal key instead of the user key. The bug was due to RangeMightExistAfterSortedRun expecting user key but receiving internal key when called in GenerateBottommostFiles. The patch augment an existing unit test to reproduce the bug and fixes it.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4575
Differential Revision: D10500434
Pulled By: maysamyabandeh
fbshipit-source-id: 858346d2fd102cce9e20516d77338c112bdfe366/Properly determine a truncated CompactRange stop key (#4496)
Summary:
When a CompactRange() call for a level is truncated before the end key
is reached, because it exceeds max_compaction_bytes, we need to properly
set the compaction_end parameter to indicate the stop key. The next
CompactRange will use that as the begin key. We set it to the smallest
key of the next file in the level after expanding inputs to get a clean
cut.
Previously, we were setting it before expanding inputs. So we could end
up recompacting some files. In a pathological case, where a single key
has many entries spanning all the files in the level (possibly due to
merge operands without a partial merge operator, thus resulting in
compaction output identical to the input), this would result in
an endless loop over the same set of files.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4496
Differential Revision: D10395026
Pulled By: anand1976
fbshipit-source-id: f0c2f89fee29b4b3be53b6467b53abba8e9146a9/"
rocksdb,"Support pragma once in all header files and cleanup some warnings (#4339)
Summary:
As you know, almost all compilers support ""pragma once"" keyword instead of using include guards. To be keep consistency between header files, all header files are edited.
Besides this, try to fix some warnings about loss of data.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4339
Differential Revision: D9654990
Pulled By: ajkr
fbshipit-source-id: c2cf3d2d03a599847684bed81378c401920ca848/"
rocksdb,"Promote CompactionFilter* accessors to ColumnFamilyOptionsInterface (#3461)
Summary:
When adding CompactionFilter and CompactionFilterFactory settings to the Java layer, ColumnFamilyOptions was modified directly instead of ColumnFamilyOptionsInterface. This meant that the old-stye Options monolith was left behind.
This patch fixes that, by:
- promoting the CompactionFilter + CompactionFilterFactory setters from ColumnFamilyOptions -> ColumnFamilyOptionsInterface
- adding getters in ColumnFamilyOptionsInterface
- implementing setters in Options
- implementing getters in both ColumnFamilyOptions and Options
- adding testcases
- reusing a test CompactionFilterFactory by moving it to a common location
Pull Request resolved: https://github.com/facebook/rocksdb/pull/3461
Differential Revision: D13278788
Pulled By: sagar0
fbshipit-source-id: 72602c6eb97dc80734e718abb5e2e9958d3c753b/"
rocksdb,"BaseDeltaIterator: always check valid() before accessing key() (#4702)
Summary:
Current implementation of `current_over_upper_bound_` fails to take into consideration that keys might be invalid in either base iterator or delta iterator. Calling key() in such scenario will lead to assertion failure and runtime errors.
This PR addresses the bug by adding check for valid keys before calling `IsOverUpperBound()`, also added test coverage for iterate_upper_bound usage in BaseDeltaIterator
Also recommit https://github.com/facebook/rocksdb/pull/4656 (It was reverted earlier due to bugs)
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4702
Differential Revision: D13146643
Pulled By: miasantreble
fbshipit-source-id: 6d136929da12d0f2e2a5cea474a8038ec5cdf1d0/apply ReadOptions.iterate_upper_bound to transaction iterator (#4656)
Summary:
Currently transaction iterator does not apply `ReadOptions.iterate_upper_bound` when iterating. This PR attempts to fix the problem by having `BaseDeltaIterator` enforcing the upper bound check when iterator state is changed.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4656
Differential Revision: D13039257
Pulled By: miasantreble
fbshipit-source-id: 909eb9f6b4597a4d80418fb139f32ec82c6ec1d1/"
rocksdb,"Fix swallowing of exception in Java RocksDB when loading native library (#4728)
Summary:
This PR fixes #4721. When an exception is caught and thrown as a different exception, then the original exception should be  inserted as a cause of the new exception. This bug in RocksDB was swallowing the underlying exception from `NativeLibraryLoader` and throwing the following exception
```
...
Caused by: java.lang.RuntimeException: Unable to load the RocksDB shared libraryjava.nio.channels.ClosedByInterruptException
at org.rocksdb.RocksDB.loadLibrary(RocksDB.java:67)
at org.rocksdb.RocksDB.<clinit>(RocksDB.java:35)
... 73 more
```
The fix is simple and self-explanatory.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4728
Differential Revision: D13418371
Pulled By: sagar0
fbshipit-source-id: d76c25af2a83a0f8ba62cc8d7b721bfddc85fdf1/Fix issues with RocksJava dropColumnFamily (#4770)
Summary:
Closes https://github.com/facebook/rocksdb/issues/4409
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4770
Differential Revision: D13416802
Pulled By: ajkr
fbshipit-source-id: 8a351e9b80dc9eeb6073467fbc67cd2f544917b0/Expose underlying Read/Write APIs for avoiding unnecessary memory copy (#2303)
Summary:
adamretter
As you already mentioned at #1247 .
Pull Request resolved: https://github.com/facebook/rocksdb/pull/2303
Differential Revision: D10209001
Pulled By: sagar0
fbshipit-source-id: bcbce004112c2edeaff116968d79c6f90aab4b6c/"
rocksdb,"Fix typos in comments (#4819)
Summary:
Fix some typos in comments.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4819
Differential Revision: D13548543
Pulled By: siying
fbshipit-source-id: ca2e128fa47bef32892fc3627a7541fd9e2d5c3f/"
rocksdb,"Promote CompactionFilter* accessors to ColumnFamilyOptionsInterface (#3461)
Summary:
When adding CompactionFilter and CompactionFilterFactory settings to the Java layer, ColumnFamilyOptions was modified directly instead of ColumnFamilyOptionsInterface. This meant that the old-stye Options monolith was left behind.
This patch fixes that, by:
- promoting the CompactionFilter + CompactionFilterFactory setters from ColumnFamilyOptions -> ColumnFamilyOptionsInterface
- adding getters in ColumnFamilyOptionsInterface
- implementing setters in Options
- implementing getters in both ColumnFamilyOptions and Options
- adding testcases
- reusing a test CompactionFilterFactory by moving it to a common location
Pull Request resolved: https://github.com/facebook/rocksdb/pull/3461
Differential Revision: D13278788
Pulled By: sagar0
fbshipit-source-id: 72602c6eb97dc80734e718abb5e2e9958d3c753b/"
rocksdb,"Promote CompactionFilter* accessors to ColumnFamilyOptionsInterface (#3461)
Summary:
When adding CompactionFilter and CompactionFilterFactory settings to the Java layer, ColumnFamilyOptions was modified directly instead of ColumnFamilyOptionsInterface. This meant that the old-stye Options monolith was left behind.
This patch fixes that, by:
- promoting the CompactionFilter + CompactionFilterFactory setters from ColumnFamilyOptions -> ColumnFamilyOptionsInterface
- adding getters in ColumnFamilyOptionsInterface
- implementing setters in Options
- implementing getters in both ColumnFamilyOptions and Options
- adding testcases
- reusing a test CompactionFilterFactory by moving it to a common location
Pull Request resolved: https://github.com/facebook/rocksdb/pull/3461
Differential Revision: D13278788
Pulled By: sagar0
fbshipit-source-id: 72602c6eb97dc80734e718abb5e2e9958d3c753b/"
rocksdb,"WritePrepared: fix issue with snapshot released during compaction (#4858)
Summary:
Compaction iterator keep a copy of list of live snapshots at the beginning of compaction, and then query snapshot checker to verify if values of a sequence number is visible to these snapshots. However when the snapshot is released in the middle of compaction, the snapshot checker implementation (i.e. WritePreparedSnapshotChecker) may remove info with the snapshot and may report incorrect result, which lead to values being compacted out when it shouldn't. This patch conservatively keep the values if snapshot checker determines that the snapshots is released.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4858
Differential Revision: D13617146
Pulled By: maysamyabandeh
fbshipit-source-id: cf18a94f6f61a94bcff73c280f117b224af5fbc3/"
rocksdb,"Deprecate CompactionFilter::IgnoreSnapshots() = false (#4954)
Summary:
We found that the behavior of CompactionFilter::IgnoreSnapshots() = false isn't
what we have expected. We thought that snapshot will always be preserved.
However, we just realized that, if no snapshot is created while compaction
starts, and a snapshot is created after that, the data seen from the snapshot
can successfully be dropped by the compaction. This creates a strange behavior
to the feature, which is hard to explain. Like what is documented in code
comment, this feature is not very useful with snapshot anyway. The decision
is to deprecate the feature.
We keep the function to avoid to break users code. However, we will fail
compactions if false is returned.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4954
Differential Revision: D13981900
Pulled By: siying
fbshipit-source-id: 2db8c2c3865acd86a28dca625945d1481b1d1e36/BaseDeltaIterator: always check valid() before accessing key() (#4702)
Summary:
Current implementation of `current_over_upper_bound_` fails to take into consideration that keys might be invalid in either base iterator or delta iterator. Calling key() in such scenario will lead to assertion failure and runtime errors.
This PR addresses the bug by adding check for valid keys before calling `IsOverUpperBound()`, also added test coverage for iterate_upper_bound usage in BaseDeltaIterator
Also recommit https://github.com/facebook/rocksdb/pull/4656 (It was reverted earlier due to bugs)
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4702
Differential Revision: D13146643
Pulled By: miasantreble
fbshipit-source-id: 6d136929da12d0f2e2a5cea474a8038ec5cdf1d0/apply ReadOptions.iterate_upper_bound to transaction iterator (#4656)
Summary:
Currently transaction iterator does not apply `ReadOptions.iterate_upper_bound` when iterating. This PR attempts to fix the problem by having `BaseDeltaIterator` enforcing the upper bound check when iterator state is changed.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4656
Differential Revision: D13039257
Pulled By: miasantreble
fbshipit-source-id: 909eb9f6b4597a4d80418fb139f32ec82c6ec1d1/"
rocksdb,"Move some RocksObject into try-with-resources in Test (#5037)
Summary:
Fix #5008
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5037
Differential Revision: D14302474
Pulled By: riversand963
fbshipit-source-id: dcd9dda5d4d6d459315692f355499a39e546d518/"
rocksdb,"Document the interaction between disableWAL and BackupEngine (#5071)
Summary:
BackupEngine relies on write-ahead logs to back up the memtable. Disabling write-ahead logs
can result in backups failing to preserve unflushed keys. This PR updates the documentation to specify this behavior, and suggest always flushing the memtable when write-ahead logs are disabled.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5071
Differential Revision: D14524124
Pulled By: miasantreble
fbshipit-source-id: 635f855f8a42ad60273b5efd226139b511e3e5d5/"
rocksdb,"Document the interaction between disableWAL and BackupEngine (#5071)
Summary:
BackupEngine relies on write-ahead logs to back up the memtable. Disabling write-ahead logs
can result in backups failing to preserve unflushed keys. This PR updates the documentation to specify this behavior, and suggest always flushing the memtable when write-ahead logs are disabled.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5071
Differential Revision: D14524124
Pulled By: miasantreble
fbshipit-source-id: 635f855f8a42ad60273b5efd226139b511e3e5d5/"
rocksdb,"Optionally wait on bytes_per_sync to smooth I/O (#5183)
Summary:
The existing implementation does not guarantee bytes reach disk every `bytes_per_sync` when writing SST files, or every `wal_bytes_per_sync` when writing WALs. This can cause confusing behavior for users who enable this feature to avoid large syncs during flush and compaction, but then end up hitting them anyways.
My understanding of the existing behavior is we used `sync_file_range` with `SYNC_FILE_RANGE_WRITE` to submit ranges for async writeback, such that we could continue processing the next range of bytes while that I/O is happening. I believe we can preserve that benefit while also limiting how far the processing can get ahead of the I/O, which prevents huge syncs from happening when the file finishes.
Consider this `sync_file_range` usage: `sync_file_range(fd_, 0, static_cast<off_t>(offset + nbytes), SYNC_FILE_RANGE_WAIT_BEFORE | SYNC_FILE_RANGE_WRITE)`. Expanding the range to start at 0 and adding the `SYNC_FILE_RANGE_WAIT_BEFORE` flag causes any pending writeback (like from a previous call to `sync_file_range`) to finish before it proceeds to submit the latest `nbytes` for writeback. The latest `nbytes` are still written back asynchronously, unless processing exceeds I/O speed, in which case the following `sync_file_range` will need to wait on it.
There is a second change in this PR to use `fdatasync` when `sync_file_range` is unavailable (determined statically) or has some known problem with the underlying filesystem (determined dynamically).
The above two changes only apply when the user enables a new option, `strict_bytes_per_sync`.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5183
Differential Revision: D14953553
Pulled By: siying
fbshipit-source-id: 445c3862e019fb7b470f9c7f314fc231b62706e9/Fix db_stress for custom env (#5122)
Summary:
Fix some hdfs-related code so that it can compile and run 'db_stress'
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5122
Differential Revision: D14675495
Pulled By: riversand963
fbshipit-source-id: cac280479efcf5451982558947eac1732e8bc45a/Support for single-primary, multi-secondary instances (#4899)
Summary:
This PR allows RocksDB to run in single-primary, multi-secondary process mode.
The writer is a regular RocksDB (e.g. an `DBImpl`) instance playing the role of a primary.
Multiple `DBImplSecondary` processes (secondaries) share the same set of SST files, MANIFEST, WAL files with the primary. Secondaries tail the MANIFEST of the primary and apply updates to their own in-memory state of the file system, e.g. `VersionStorageInfo`.
This PR has several components:
1. (Originally in #4745). Add a `PathNotFound` subcode to `IOError` to denote the failure when a secondary tries to open a file which has been deleted by the primary.
2. (Similar to #4602). Add `FragmentBufferedReader` to handle partially-read, trailing record at the end of a log from where future read can continue.
3. (Originally in #4710 and #4820). Add implementation of the secondary, i.e. `DBImplSecondary`.
3.1 Tail the primary's MANIFEST during recovery.
3.2 Tail the primary's MANIFEST during normal processing by calling `ReadAndApply`.
3.3 Tailing WAL will be in a future PR.
4. Add an example in 'examples/multi_processes_example.cc' to demonstrate the usage of secondary RocksDB instance in a multi-process setting. Instructions to run the example can be found at the beginning of the source code.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4899
Differential Revision: D14510945
Pulled By: riversand963
fbshipit-source-id: 4ac1c5693e6012ad23f7b4b42d3c374fecbe8886/"
rocksdb,"Consolidate hash function used for non-persistent data in a new function (#5155)
Summary:
Create new function NPHash64() and GetSliceNPHash64(), which are currently
implemented using murmurhash.
Replace the current direct call of murmurhash() to use the new functions
if the hash results are not used in on-disk format.
This will make it easier to try out or switch to alternative functions
in the uses where data format compatibility doesn't need to be considered.
This part shouldn't have any performance impact.
Also, the sharded cache hash function is changed to the new format, because
it falls into this categoery. It doesn't show visible performance impact
in db_bench results. CPU showed by perf is increased from about 0.2% to 0.4%
in an extreme benchmark setting (4KB blocks, no-compression, everything
cached in block cache). We've known that the current hash function used,
our own Hash() has serious hash quality problem. It can generate a lots of
conflicts with similar input. In this use case, it means extra lock contention
for reads from the same file. This slight CPU regression is worthy to me
to counter the potential bad performance with hot keys. And hopefully this
will get further improved in the future with a better hash function.
cache_test's condition is relaxed a little bit to. The new hash is slightly
more skewed in this use case, but I manually checked the data and see
the hash results are still in a reasonable range.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5155
Differential Revision: D14834821
Pulled By: siying
fbshipit-source-id: ec9a2c0a2f8ae4b54d08b13a5c2e9cc97aa80cb5/"
rocksdb,"Optionally wait on bytes_per_sync to smooth I/O (#5183)
Summary:
The existing implementation does not guarantee bytes reach disk every `bytes_per_sync` when writing SST files, or every `wal_bytes_per_sync` when writing WALs. This can cause confusing behavior for users who enable this feature to avoid large syncs during flush and compaction, but then end up hitting them anyways.
My understanding of the existing behavior is we used `sync_file_range` with `SYNC_FILE_RANGE_WRITE` to submit ranges for async writeback, such that we could continue processing the next range of bytes while that I/O is happening. I believe we can preserve that benefit while also limiting how far the processing can get ahead of the I/O, which prevents huge syncs from happening when the file finishes.
Consider this `sync_file_range` usage: `sync_file_range(fd_, 0, static_cast<off_t>(offset + nbytes), SYNC_FILE_RANGE_WAIT_BEFORE | SYNC_FILE_RANGE_WRITE)`. Expanding the range to start at 0 and adding the `SYNC_FILE_RANGE_WAIT_BEFORE` flag causes any pending writeback (like from a previous call to `sync_file_range`) to finish before it proceeds to submit the latest `nbytes` for writeback. The latest `nbytes` are still written back asynchronously, unless processing exceeds I/O speed, in which case the following `sync_file_range` will need to wait on it.
There is a second change in this PR to use `fdatasync` when `sync_file_range` is unavailable (determined statically) or has some known problem with the underlying filesystem (determined dynamically).
The above two changes only apply when the user enables a new option, `strict_bytes_per_sync`.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5183
Differential Revision: D14953553
Pulled By: siying
fbshipit-source-id: 445c3862e019fb7b470f9c7f314fc231b62706e9/"
rocksdb,"Atomic ingest (#4895)
Summary:
Make file ingestion atomic.
as title.
Ingesting external SST files into multiple column families should be atomic. If
a crash occurs and db reopens, either all column families have successfully
ingested the files before the crash, or non of the ingestions have any effect
on the state of the db.
Also add unit tests for atomic ingestion.
Note that the unit test here does not cover the case of incomplete atomic group
in the MANIFEST, which is covered in VersionSetTest already.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/4895
Differential Revision: D13718245
Pulled By: riversand963
fbshipit-source-id: 7df97cc483af73ad44dd6993008f99b083852198/"
rocksdb,"refactor SavePoints (#5192)
Summary:
Savepoints are assumed to be used in a stack-wise fashion (only
the top element should be used), so they were stored by `WriteBatch`
in a member variable `save_points` using an std::stack.
Conceptually this is fine, but the implementation had a few issues:
- the `save_points_` instance variable was a plain pointer to a heap-
allocated `SavePoints` struct. The destructor of `WriteBatch` simply
deletes this pointer. However, the copy constructor of WriteBatch
just copied that pointer, meaning that copying a WriteBatch with
active savepoints will very likely have crashed before. Now a proper
copy of the savepoints is made in the copy constructor, and not just
a copy of the pointer
- `save_points_` was an std::stack, which defaults to `std::deque` for
the underlying container. A deque is a bit over the top here, as we
only need access to the most recent savepoint (i.e. stack.top()) but
never any elements at the front. std::deque is rather expensive to
initialize in common environments. For example, the STL implementation
shipped with GNU g++ will perform a heap allocation of more than 500
bytes to create an empty deque object. Although the `save_points_`
container is created lazily by RocksDB, moving from a deque to a plain
`std::vector` is much more memory-efficient. So `save_points_` is now
a vector.
- `save_points_` was changed from a plain pointer to an `std::unique_ptr`,
making ownership more explicit.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5192
Differential Revision: D15024074
Pulled By: maysamyabandeh
fbshipit-source-id: 5b128786d3789cde94e46465c9e91badd07a25d7/"
rocksdb,"Refresh snapshot list during long compactions (2nd attempt) (#5278)
Summary:
Part of compaction cpu goes to processing snapshot list, the larger the list the bigger the overhead. Although the lifetime of most of the snapshots is much shorter than the lifetime of compactions, the compaction conservatively operates on the list of snapshots that it initially obtained. This patch allows the snapshot list to be updated via a callback if the compaction is taking long. This should let the compaction to continue more efficiently with much smaller snapshot list.
For simplicity, to avoid the feature is disabled in two cases: i) When more than one sub-compaction are sharing the same snapshot list, ii) when Range Delete is used in which the range delete aggregator has its own copy of snapshot list.
This fixes the reverted https://github.com/facebook/rocksdb/pull/5099 issue with range deletes.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5278
Differential Revision: D15203291
Pulled By: maysamyabandeh
fbshipit-source-id: fa645611e606aa222c7ce53176dc5bb6f259c258/Revert snap_refresh_nanos feature (#5269)
Summary:
Our daily stress tests are failing after this feature. Reverting temporarily until we figure the reason for test failures.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5269
Differential Revision: D15151285
Pulled By: maysamyabandeh
fbshipit-source-id: e4002b99690a97df30d4b4b58bf0f61e9591bc6e/Add rocksdb_property_int_cf (#5268)
Summary:
Adds the missing `rocksdb_property_int_cf` function to the C API to let consuming libraries avoid parsing strings.
Fixes https://github.com/facebook/rocksdb/issues/5249
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5268
Differential Revision: D15149461
Pulled By: maysamyabandeh
fbshipit-source-id: e9fe5f1ad7c64066d921dba8473507269b51d331/"
rocksdb,"Optionally wait on bytes_per_sync to smooth I/O (#5183)
Summary:
The existing implementation does not guarantee bytes reach disk every `bytes_per_sync` when writing SST files, or every `wal_bytes_per_sync` when writing WALs. This can cause confusing behavior for users who enable this feature to avoid large syncs during flush and compaction, but then end up hitting them anyways.
My understanding of the existing behavior is we used `sync_file_range` with `SYNC_FILE_RANGE_WRITE` to submit ranges for async writeback, such that we could continue processing the next range of bytes while that I/O is happening. I believe we can preserve that benefit while also limiting how far the processing can get ahead of the I/O, which prevents huge syncs from happening when the file finishes.
Consider this `sync_file_range` usage: `sync_file_range(fd_, 0, static_cast<off_t>(offset + nbytes), SYNC_FILE_RANGE_WAIT_BEFORE | SYNC_FILE_RANGE_WRITE)`. Expanding the range to start at 0 and adding the `SYNC_FILE_RANGE_WAIT_BEFORE` flag causes any pending writeback (like from a previous call to `sync_file_range`) to finish before it proceeds to submit the latest `nbytes` for writeback. The latest `nbytes` are still written back asynchronously, unless processing exceeds I/O speed, in which case the following `sync_file_range` will need to wait on it.
There is a second change in this PR to use `fdatasync` when `sync_file_range` is unavailable (determined statically) or has some known problem with the underlying filesystem (determined dynamically).
The above two changes only apply when the user enables a new option, `strict_bytes_per_sync`.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5183
Differential Revision: D14953553
Pulled By: siying
fbshipit-source-id: 445c3862e019fb7b470f9c7f314fc231b62706e9/"
rocksdb,"simplify include directive involving inttypes (#5402)
Summary:
When using `PRIu64` type of printf specifier, current code base does the following:
```
#ifndef __STDC_FORMAT_MACROS
#define __STDC_FORMAT_MACROS
#endif
#include <inttypes.h>
```
However, this can be simplified to
```
#include <cinttypes>
```
as long as flag `-std=c++11` is used.
This should solve issues like https://github.com/facebook/rocksdb/issues/5159
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5402
Differential Revision: D15701195
Pulled By: miasantreble
fbshipit-source-id: 6dac0a05f52aadb55e9728038599d3d2e4b59d03/"
rocksdb,"WritePrepared: fix Get without snapshot (#5664)
Summary:
if read_options.snapshot is not set, ::Get will take the last sequence number after taking a super-version and uses that as the sequence number. Theoretically max_eviceted_seq_ could advance this sequence number. This could lead ::IsInSnapshot that will be invoked by the ReadCallback to notice the absence of the snapshot. In this case, the ReadCallback should have passed a non-value to snap_released so that it could be set by the ::IsInSnapshot. The patch does that, and adds a unit test to verify it.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5664
Differential Revision: D16614033
Pulled By: maysamyabandeh
fbshipit-source-id: 06fb3fd4aacd75806ed1a1acec7961f5d02486f2/Add an option to put first key of each sst block in the index (#5289)
Summary:
The first key is used to defer reading the data block until this file gets to the top of merging iterator's heap. For short range scans, most files never make it to the top of the heap, so this change can reduce read amplification by a lot sometimes.
Consider the following workload. There are a few data streams (we'll be calling them ""logs""), each stream consisting of a sequence of blobs (we'll be calling them ""records""). Each record is identified by log ID and a sequence number within the log. RocksDB key is concatenation of log ID and sequence number (big endian). Reads are mostly relatively short range scans, each within a single log. Writes are mostly sequential for each log, but writes to different logs are randomly interleaved. Compactions are disabled; instead, when we accumulate a few tens of sst files, we create a new column family and start writing to it.
So, a typical sst file consists of a few ranges of blocks, each range corresponding to one log ID (we use FlushBlockPolicy to cut blocks at log boundaries). A typical read would go like this. First, iterator Seek() reads one block from each sst file. Then a series of Next()s move through one sst file (since writes to each log are mostly sequential) until the subiterator reaches the end of this log in this sst file; then Next() switches to the next sst file and reads sequentially from that, and so on. Often a range scan will only return records from a small number of blocks in small number of sst files; in this case, the cost of initial Seek() reading one block from each file may be bigger than the cost of reading the actually useful blocks.
Neither iterate_upper_bound nor bloom filters can prevent reading one block from each file in Seek(). But this PR can: if the index contains first key from each block, we don't have to read the block until this block actually makes it to the top of merging iterator's heap, so for short range scans we won't read any blocks from most of the sst files.
This PR does the deferred block loading inside value() call. This is not ideal: there's no good way to report an IO error from inside value(). As discussed with siying offline, it would probably be better to change InternalIterator's interface to explicitly fetch deferred value and get status. I'll do it in a separate PR.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5289
Differential Revision: D15256423
Pulled By: al13n321
fbshipit-source-id: 750e4c39ce88e8d41662f701cf6275d9388ba46a/"
rocksdb,"Java: Make the generics of the Options interfaces more strict (#5461)
Summary:
Make the generics of the Options interfaces more strict so they are usable in a Kotlin Multiplatform expect/actual typealias implementation without causing a Violation of Finite Bound Restriction.
This fix would enable the creation of a generic Kotlin multiplatform library by just typealiasing the JVM implementation to the current Java implementation.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5461
Differential Revision: D15903288
Pulled By: sagar0
fbshipit-source-id: 75e83fdf5d2fcede40744a17e767563d6a4b0696/"
rocksdb,"simplify include directive involving inttypes (#5402)
Summary:
When using `PRIu64` type of printf specifier, current code base does the following:
```
#ifndef __STDC_FORMAT_MACROS
#define __STDC_FORMAT_MACROS
#endif
#include <inttypes.h>
```
However, this can be simplified to
```
#include <cinttypes>
```
as long as flag `-std=c++11` is used.
This should solve issues like https://github.com/facebook/rocksdb/issues/5159
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5402
Differential Revision: D15701195
Pulled By: miasantreble
fbshipit-source-id: 6dac0a05f52aadb55e9728038599d3d2e4b59d03/"
rocksdb,"Provide an option so that SST ingestion won't fall back to copy after hard linking fails (#5333)
Summary:
RocksDB always tries to perform a hard link operation on the external SST file to ingest. This operation can fail if the external SST resides on a different device/FS, or the underlying FS does not support hard link. Currently RocksDB assumes that if the link fails, the user is willing to perform file copy, which is not true according to the post. This commit provides an option named  'failed_move_fall_back_to_copy' for users to choose which behavior they want.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5333
Differential Revision: D15457597
Pulled By: HaoyuHuang
fbshipit-source-id: f3626e13f845db4f7ed970a53ec8a2b1f0d62214/"
rocksdb,"Avoid user key copying for Get/Put/Write with user-timestamp (#5502)
Summary:
In previous https://github.com/facebook/rocksdb/issues/5079, we added user-specified timestamp to `DB::Get()` and `DB::Put()`. Limitation is that these two functions may cause extra memory allocation and key copy. The reason is that `WriteBatch` does not allocate extra memory for timestamps because it is not aware of timestamp size, and we did not provide an API to assign/update timestamp of each key within a `WriteBatch`.
We address these issues in this PR by doing the following.
1. Add a `timestamp_size_` to `WriteBatch` so that `WriteBatch` can take timestamps into account when calling `WriteBatch::Put`, `WriteBatch::Delete`, etc.
2. Add APIs `WriteBatch::AssignTimestamp` and `WriteBatch::AssignTimestamps` so that application can assign/update timestamps for each key in a `WriteBatch`.
3. Avoid key copy in `GetImpl` by adding new constructor to `LookupKey`.
Test plan (on devserver):
```
$make clean && COMPILE_WITH_ASAN=1 make -j32 all
$./db_basic_test --gtest_filter=Timestamp/DBBasicTestWithTimestampWithParam.PutAndGet/*
$make check
```
If the API extension looks good, I will add more unit tests.
Some simple benchmark using db_bench.
```
$rm -rf /dev/shm/dbbench/* && TEST_TMPDIR=/dev/shm ./db_bench -benchmarks=fillseq,readrandom -num=1000000
$rm -rf /dev/shm/dbbench/* && TEST_TMPDIR=/dev/shm ./db_bench -benchmarks=fillrandom -num=1000000 -disable_wal=true
```
Master is at a78503bd6c80a3c4137df1962a972fe406b4d90b.
```
|        | readrandom | fillrandom |
| master | 15.53 MB/s | 25.97 MB/s |
| PR5502 | 16.70 MB/s | 25.80 MB/s |
```
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5502
Differential Revision: D16340894
Pulled By: riversand963
fbshipit-source-id: 51132cf792be07d1efc3ac33f5768c4ee2608bb8/"
rocksdb,"Fix memorty leak in `rocksdb_wal_iter_get_batch` function (#5515)
Summary:
`wal_batch.writeBatchPtr.release()` gives up the ownership of the original `WriteBatch`, but there is no new owner, which causes memory leak.
The patch is simple. Removing `release()` prevent ownership change. `std::move` is for speed.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5515
Differential Revision: D16264281
Pulled By: riversand963
fbshipit-source-id: 51c556b7a1c977325c3aa24acb636303847151fa/"
rocksdb,"Add new persistent 64-bit hash (#5984)
Summary:
For upcoming new SST filter implementations, we will use a new
64-bit hash function (XXH3 preview, slightly modified). This change
updates hash.{h,cc} for that change, adds unit tests, and out-of-lines
the implementations to keep hash.h as clean/small as possible.
In developing the unit tests, I discovered that the XXH3 preview always
returns zero for the empty string. Zero is problematic for some
algorithms (including an upcoming SST filter implementation) if it
occurs more often than at the ""natural"" rate, so it should not be
returned from trivial values using trivial seeds. I modified our fork
of XXH3 to return a modest hash of the seed for the empty string.
With hash function details out-of-lines in hash.h, it makes sense to
enable XXH_INLINE_ALL, so that direct calls to XXH64/XXH32/XXH3p
are inlined. To fix array-bounds warnings on some inline calls, I
injected some casts to uintptr_t in xxhash.cc. (Issue reported to Yann.)
Revised: Reverted using XXH_INLINE_ALL for now.  Some Facebook
checks are unhappy about #include on xxhash.cc file. I would
fix that by rename to xxhash_cc.h, but to best preserve history I want
to do that in a separate commit (PR) from the uintptr casts.
Also updated filter_bench for this change, improving the performance
predictability of dry run hashing and adding support for 64-bit hash
(for upcoming new SST filter implementations, minor dead code in the
tool for now).
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5984
Differential Revision: D18246567
Pulled By: pdillinger
fbshipit-source-id: 6162fbf6381d63c8cc611dd7ec70e1ddc883fbb8/Update xxhash.cc to allow combined compilation (#5969)
Summary:
To fix unity_test
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5969
Test Plan: make unity_test
Differential Revision: D18140426
Pulled By: pdillinger
fbshipit-source-id: d5516e6d665f57e3706b9f9b965b0c458e58ccef/Misc hashing updates / upgrades (#5909)
Summary:
- Updated our included xxhash implementation to version 0.7.2 (== the latest dev version as of 2019-10-09).
- Using XXH_NAMESPACE (like other fb projects) to avoid potential name collisions.
- Added fastrange64, and unit tests for it and fastrange32. These are faster alternatives to hash % range.
- Use preview version of XXH3 instead of MurmurHash64A for NPHash64
-- Had to update cache_test to increase probability of passing for any given hash function.
- Use fastrange64 instead of % with uses of NPHash64
-- Had to fix WritePreparedTransactionTest.CommitOfDelayedPrepared to avoid deadlock apparently caused by new hash collision.
- Set default seed for NPHash64 because specifying a seed rarely makes sense for it.
- Removed unnecessary include xxhash.h in a popular .h file
- Rename preview version of XXH3 to XXH3p for clarity and to ease backward compatibility in case final version of XXH3 is integrated.
Relying on existing unit tests for NPHash64-related changes. Each new implementation of fastrange64 passed unit tests when manipulating my local build to select it. I haven't done any integration performance tests, but I consider the improved performance of the pieces being swapped in to be well established.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5909
Differential Revision: D18125196
Pulled By: pdillinger
fbshipit-source-id: f6bf83d49d20cbb2549926adf454fd035f0ecc0d/"
rocksdb,"Add new persistent 64-bit hash (#5984)
Summary:
For upcoming new SST filter implementations, we will use a new
64-bit hash function (XXH3 preview, slightly modified). This change
updates hash.{h,cc} for that change, adds unit tests, and out-of-lines
the implementations to keep hash.h as clean/small as possible.
In developing the unit tests, I discovered that the XXH3 preview always
returns zero for the empty string. Zero is problematic for some
algorithms (including an upcoming SST filter implementation) if it
occurs more often than at the ""natural"" rate, so it should not be
returned from trivial values using trivial seeds. I modified our fork
of XXH3 to return a modest hash of the seed for the empty string.
With hash function details out-of-lines in hash.h, it makes sense to
enable XXH_INLINE_ALL, so that direct calls to XXH64/XXH32/XXH3p
are inlined. To fix array-bounds warnings on some inline calls, I
injected some casts to uintptr_t in xxhash.cc. (Issue reported to Yann.)
Revised: Reverted using XXH_INLINE_ALL for now.  Some Facebook
checks are unhappy about #include on xxhash.cc file. I would
fix that by rename to xxhash_cc.h, but to best preserve history I want
to do that in a separate commit (PR) from the uintptr casts.
Also updated filter_bench for this change, improving the performance
predictability of dry run hashing and adding support for 64-bit hash
(for upcoming new SST filter implementations, minor dead code in the
tool for now).
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5984
Differential Revision: D18246567
Pulled By: pdillinger
fbshipit-source-id: 6162fbf6381d63c8cc611dd7ec70e1ddc883fbb8/Misc hashing updates / upgrades (#5909)
Summary:
- Updated our included xxhash implementation to version 0.7.2 (== the latest dev version as of 2019-10-09).
- Using XXH_NAMESPACE (like other fb projects) to avoid potential name collisions.
- Added fastrange64, and unit tests for it and fastrange32. These are faster alternatives to hash % range.
- Use preview version of XXH3 instead of MurmurHash64A for NPHash64
-- Had to update cache_test to increase probability of passing for any given hash function.
- Use fastrange64 instead of % with uses of NPHash64
-- Had to fix WritePreparedTransactionTest.CommitOfDelayedPrepared to avoid deadlock apparently caused by new hash collision.
- Set default seed for NPHash64 because specifying a seed rarely makes sense for it.
- Removed unnecessary include xxhash.h in a popular .h file
- Rename preview version of XXH3 to XXH3p for clarity and to ease backward compatibility in case final version of XXH3 is integrated.
Relying on existing unit tests for NPHash64-related changes. Each new implementation of fastrange64 passed unit tests when manipulating my local build to select it. I haven't done any integration performance tests, but I consider the improved performance of the pieces being swapped in to be well established.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5909
Differential Revision: D18125196
Pulled By: pdillinger
fbshipit-source-id: f6bf83d49d20cbb2549926adf454fd035f0ecc0d/Faster new DynamicBloom implementation (for memtable) (#5762)
Summary:
Since DynamicBloom is now only used in-memory, we're free to
change it without schema compatibility issues. The new implementation
is drawn from (with manifest permission)
https://github.com/pdillinger/wormhashing/blob/303542a767437f56d8b66cea6ebecaac0e6a61e9/bloom_simulation_tests/foo.cc#L613
This has several speed advantages over the prior implementation:
* Uses fastrange instead of %
* Minimum logic to determine first (and all) probed memory addresses
* (Major) Two probes per 64-bit memory fetch/write.
* Very fast and effective (murmur-like) hash expansion/re-mixing. (At
least on recent CPUs, integer multiplication is very cheap.)
While a Bloom filter with 512-bit cache locality has about a 1.15x FP
rate penalty (e.g. 0.84% to 0.97%), further restricting to two probes
per 64 bits incurs an additional 1.12x FP rate penalty (e.g. 0.97% to
1.09%). Nevertheless, the unit tests show no ""mediocre"" FP rate samples,
unlike the old implementation with more erratic FP rates.
Especially for the memtable, we expect speed to outweigh somewhat higher
FP rates. For example, a negative table query would have to be 1000x
slower than a BF query to justify doubling BF query time to shave 10% off
FP rate (working assumption around 1% FP rate). While that seems likely
for SSTs, my data suggests a speed factor of roughly 50x for the memtable
(vs. BF; ~1.5% lower write throughput when enabling memtable Bloom
filter, after this change).  Thus, it's probably not worth even 5% more
time in the Bloom filter to shave off 1/10th of the Bloom FP rate, or 0.1%
in absolute terms, and it's probably at least 20% slower to recoup that
much FP rate from this new implementation. Because of this, we do not see
a need for a 'locality' option that affects the MemTable Bloom filter
and have decoupled the MemTable Bloom filter from Options::bloom_locality.
Note that just 3% more memory to the Bloom filter (10.3 bits per key vs.
just 10) is able to make up for the ~12% FP rate drop in the new
implementation:
[] # Nearly ""ideal"" FP-wise but reasonably fast cache-local implementation
[~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_WORM64_FROM32_any.out 10000000 6 10 $RANDOM 100000000
./foo_gcc_IMPL_CACHE_WORM64_FROM32_any.out time: 3.29372 sampled_fp_rate: 0.00985956 ...
[] # Close match to this new implementation
[~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out 10000000 6 10.3 $RANDOM 100000000
./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out time: 2.10072 sampled_fp_rate: 0.00985655 ...
[] # Old locality=1 implementation
[~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_ROCKSDB_DYNAMIC_any.out 10000000 6 10 $RANDOM 100000000
./foo_gcc_IMPL_CACHE_ROCKSDB_DYNAMIC_any.out time: 3.95472 sampled_fp_rate: 0.00988943 ...
Also note the dramatic speed improvement vs. alternatives.
--
Performance unit test: DynamicBloomTest.concurrent_with_perf is updated
to report more precise timing data. (Measure running time of each
thread, not just longest running thread, etc.) Results averaged over
various sizes enabled with --enable_perf and 20 runs each; old dynamic
bloom refers to locality=1, the faster of the old:
old dynamic bloom, avg add latency = 65.6468
new dynamic bloom, avg add latency = 44.3809
old dynamic bloom, avg query latency = 50.6485
new dynamic bloom, avg query latency = 43.2186
old avg parallel add latency = 41.678
new avg parallel add latency = 24.5238
old avg parallel hit latency = 14.6322
new avg parallel hit latency = 12.3939
old avg parallel miss latency = 16.7289
new avg parallel miss latency = 12.2134
Tested on a dedicated 64-bit production machine at Facebook. Significant
improvement all around.
Despite now using std::atomic<uint64_t>, quick before-and-after test on
a 32-bit machine (Intel Atom N270, released 2008) shows no regression in
performance, in some cases modest improvement.
--
Performance integration test (synthetic): with DEBUG_LEVEL=0, used
TEST_TMPDIR=/dev/shm ./db_bench --benchmarks=fillrandom,readmissing,readrandom,stats --num=2000000
and optionally with -memtable_whole_key_filtering -memtable_bloom_size_ratio=0.01
300 runs each configuration.
Write throughput change by enabling memtable bloom:
Old locality=0: -3.06%
Old locality=1: -2.37%
New:            -1.50%
conclusion -> seems to substantially close the gap
Readmissing throughput change by enabling memtable bloom:
Old locality=0: +34.47%
Old locality=1: +34.80%
New:            +33.25%
conclusion -> maybe a small new penalty from FP rate
Readrandom throughput change by enabling memtable bloom:
Old locality=0: +31.54%
Old locality=1: +31.13%
New:            +30.60%
conclusion -> maybe also from FP rate (after memtable flush)
--
Another conclusion we can draw from this new implementation is that the
existing 32-bit hash function is not inherently crippling the Bloom
filter speed or accuracy, below about 5 million keys. For speed, the
implementation is essentially the same whether starting with 32-bits or
64-bits of hash; it just determines whether the first multiplication
after fastrange is a pseudorandom expansion or needed re-mix. Note that
this multiplication can occur while memory is fetching.
For accuracy, in a standard configuration, you need about 5 million
keys before you have about a 1.1x FP penalty due to using a
32-bit hash vs. 64-bit:
[~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out $((5 * 1000 * 1000 * 10)) 6 10 $RANDOM 100000000
./foo_gcc_IMPL_CACHE_MUL64_BLOCK_FROM32_any.out time: 2.52069 sampled_fp_rate: 0.0118267 ...
[~/wormhashing/bloom_simulation_tests] ./foo_gcc_IMPL_CACHE_MUL64_BLOCK_any.out $((5 * 1000 * 1000 * 10)) 6 10 $RANDOM 100000000
./foo_gcc_IMPL_CACHE_MUL64_BLOCK_any.out time: 2.43871 sampled_fp_rate: 0.0109059
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5762
Differential Revision: D17214194
Pulled By: pdillinger
fbshipit-source-id: ad9da031772e985fd6b62a0e1db8e81892520595/"
rocksdb,"Apply formatter on recent 45 commits. (#5827)
Summary:
Some recent commits might not have passed through the formatter. I formatted recent 45 commits. The script hangs for more commits so I stopped there.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5827
Test Plan: Run all existing tests.
Differential Revision: D17483727
fbshipit-source-id: af23113ee63015d8a43d89a3bc2c1056189afe8f/"
rocksdb,"Misc hashing updates / upgrades (#5909)
Summary:
- Updated our included xxhash implementation to version 0.7.2 (== the latest dev version as of 2019-10-09).
- Using XXH_NAMESPACE (like other fb projects) to avoid potential name collisions.
- Added fastrange64, and unit tests for it and fastrange32. These are faster alternatives to hash % range.
- Use preview version of XXH3 instead of MurmurHash64A for NPHash64
-- Had to update cache_test to increase probability of passing for any given hash function.
- Use fastrange64 instead of % with uses of NPHash64
-- Had to fix WritePreparedTransactionTest.CommitOfDelayedPrepared to avoid deadlock apparently caused by new hash collision.
- Set default seed for NPHash64 because specifying a seed rarely makes sense for it.
- Removed unnecessary include xxhash.h in a popular .h file
- Rename preview version of XXH3 to XXH3p for clarity and to ease backward compatibility in case final version of XXH3 is integrated.
Relying on existing unit tests for NPHash64-related changes. Each new implementation of fastrange64 passed unit tests when manipulating my local build to select it. I haven't done any integration performance tests, but I consider the improved performance of the pieces being swapped in to be well established.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5909
Differential Revision: D18125196
Pulled By: pdillinger
fbshipit-source-id: f6bf83d49d20cbb2549926adf454fd035f0ecc0d/"
rocksdb,"Fix a bug in file ingestion (#5760)
Summary:
Before this PR, when the number of column families involved in a file ingestion exceeds 2, a bug in the looping logic prevents correct file number being assigned to each ingestion job.
Also skip deleting non-existing hard links during cleanup-after-failure.
Test plan (devserver)
```
$COMPILE_WITH_ASAN=1 make all
$./external_sst_file_test --gtest_filter=ExternalSSTFileTest/ExternalSSTFileTest.IngestFilesIntoMultipleColumnFamilies_*/*
$makke check
```
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5760
Differential Revision: D17142982
Pulled By: riversand963
fbshipit-source-id: 06c1847a4e7a402647bcf28d124e70f2a0f9daf6/Fix IngestExternalFile overlapping check (#5649)
Summary:
Previously, the end key of a range deletion tombstone was considered exclusive for the purposes of deletion, but considered inclusive when checking if two SSTables overlap. For example, an SSTable with a range deletion tombstone [a, b) would be considered overlapping with an SSTable with a range deletion tombstone [b, c). This commit fixes this check.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5649
Differential Revision: D16808765
Pulled By: anand1976
fbshipit-source-id: 5c7ad1c027e4f778d35070e5dae1b8e6037e0d68/"
rocksdb,"Refactor trimming logic for immutable memtables (#5022)
Summary:
MyRocks currently sets `max_write_buffer_number_to_maintain` in order to maintain enough history for transaction conflict checking. The effectiveness of this approach depends on the size of memtables. When memtables are small, it may not keep enough history; when memtables are large, this may consume too much memory.
We are proposing a new way to configure memtable list history: by limiting the memory usage of immutable memtables. The new option is `max_write_buffer_size_to_maintain` and it will take precedence over the old `max_write_buffer_number_to_maintain` if they are both set to non-zero values. The new option accounts for the total memory usage of flushed immutable memtables and mutable memtable. When the total usage exceeds the limit, RocksDB may start dropping immutable memtables (which is also called trimming history), starting from the oldest one.
The semantics of the old option actually works both as an upper bound and lower bound. History trimming will start if number of immutable memtables exceeds the limit, but it will never go below (limit-1) due to history trimming.
In order the mimic the behavior with the new option, history trimming will stop if dropping the next immutable memtable causes the total memory usage go below the size limit. For example, assuming the size limit is set to 64MB, and there are 3 immutable memtables with sizes of 20, 30, 30. Although the total memory usage is 80MB > 64MB, dropping the oldest memtable will reduce the memory usage to 60MB < 64MB, so in this case no memtable will be dropped.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5022
Differential Revision: D14394062
Pulled By: miasantreble
fbshipit-source-id: 60457a509c6af89d0993f988c9b5c2aa9e45f5c5/"
rocksdb,"Refactor trimming logic for immutable memtables (#5022)
Summary:
MyRocks currently sets `max_write_buffer_number_to_maintain` in order to maintain enough history for transaction conflict checking. The effectiveness of this approach depends on the size of memtables. When memtables are small, it may not keep enough history; when memtables are large, this may consume too much memory.
We are proposing a new way to configure memtable list history: by limiting the memory usage of immutable memtables. The new option is `max_write_buffer_size_to_maintain` and it will take precedence over the old `max_write_buffer_number_to_maintain` if they are both set to non-zero values. The new option accounts for the total memory usage of flushed immutable memtables and mutable memtable. When the total usage exceeds the limit, RocksDB may start dropping immutable memtables (which is also called trimming history), starting from the oldest one.
The semantics of the old option actually works both as an upper bound and lower bound. History trimming will start if number of immutable memtables exceeds the limit, but it will never go below (limit-1) due to history trimming.
In order the mimic the behavior with the new option, history trimming will stop if dropping the next immutable memtable causes the total memory usage go below the size limit. For example, assuming the size limit is set to 64MB, and there are 3 immutable memtables with sizes of 20, 30, 30. Although the total memory usage is 80MB > 64MB, dropping the oldest memtable will reduce the memory usage to 60MB < 64MB, so in this case no memtable will be dropped.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5022
Differential Revision: D14394062
Pulled By: miasantreble
fbshipit-source-id: 60457a509c6af89d0993f988c9b5c2aa9e45f5c5/"
rocksdb,"Fix block cache ID uniqueness for Windows builds (#5844)
Summary:
Since we do not evict a file's blocks from block cache before that file
is deleted, we require a file's cache ID prefix is both unique and
non-reusable. However, the Windows functionality we were relying on only
guaranteed uniqueness. That meant a newly created file could be assigned
the same cache ID prefix as a deleted file. If the newly created file
had block offsets matching the deleted file, full cache keys could be
exactly the same, resulting in obsolete data blocks returned from cache
when trying to read from the new file.
We noticed this when running on FAT32 where compaction was writing out
of order keys due to reading obsolete blocks from its input files. The
functionality is documented as behaving the same on NTFS, although I
wasn't able to repro it there.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5844
Test Plan:
we had a reliable repro of out-of-order keys on FAT32 that
was fixed by this change
Differential Revision: D17752442
fbshipit-source-id: 95d983f9196cf415f269e19293b97341edbf7e00/"
rocksdb,"Improve RocksJava Comparator (#6252)
Summary:
This is a redesign of the API for RocksJava comparators with the aim of improving performance. It also simplifies the class hierarchy.
**NOTE**: This breaks backwards compatibility for existing 3rd party Comparators implemented in Java... so we need to consider carefully which release branches this goes into.
Previously when implementing a comparator in Java the developer had a choice of subclassing either `DirectComparator` or `Comparator` which would use direct and non-direct byte-buffers resepectively (via `DirectSlice` and `Slice`).
In this redesign there we have eliminated the overhead of using the Java Slice classes, and just use `ByteBuffer`s. The `ComparatorOptions` supplied when constructing a Comparator allow you to choose between direct and non-direct byte buffers by setting `useDirect`.
In addition, the `ComparatorOptions` now allow you to choose whether a ByteBuffer is reused over multiple comparator calls, by setting `maxReusedBufferSize > 0`. When buffers are reused, ComparatorOptions provides a choice of mutex type by setting `useAdaptiveMutex`.
---
[JMH benchmarks previously indicated](https://github.com/facebook/rocksdb/pull/6241#issue-356398306) that the difference between C++ and Java for implementing a comparator was ~7x slowdown in Java.
With these changes, when reusing buffers and guarding access to them via mutexes the slowdown is approximately the same. However, these changes offer a new facility to not reuse mutextes, which reduces the slowdown to ~5.5x in Java. We also offer a `thread_local` mechanism for reusing buffers, which reduces slowdown to ~5.2x in Java (closes https://github.com/facebook/rocksdb/pull/4425).
These changes also form a good base for further optimisation work such as further JNI lookup caching, and JNI critical.
---
These numbers were captured without jemalloc. With jemalloc, the performance improves for all tests, and the Java slowdown reduces to between 4.8x and 5.x.
```
ComparatorBenchmarks.put                                                native_bytewise  thrpt   25  124483.795  2032.443  ops/s
ComparatorBenchmarks.put                                        native_reverse_bytewise  thrpt   25  114414.536  3486.156  ops/s
ComparatorBenchmarks.put              java_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   17228.250  1288.546  ops/s
ComparatorBenchmarks.put          java_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   16035.865  1248.099  ops/s
ComparatorBenchmarks.put                java_bytewise_non-direct_reused-64_thread-local  thrpt   25   21571.500   871.521  ops/s
ComparatorBenchmarks.put                  java_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   23613.773  8465.660  ops/s
ComparatorBenchmarks.put              java_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   16768.172  5618.489  ops/s
ComparatorBenchmarks.put                    java_bytewise_direct_reused-64_thread-local  thrpt   25   23921.164  8734.742  ops/s
ComparatorBenchmarks.put                              java_bytewise_non-direct_no-reuse  thrpt   25   17899.684   839.679  ops/s
ComparatorBenchmarks.put                                  java_bytewise_direct_no-reuse  thrpt   25   22148.316  1215.527  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   11311.126   820.602  ops/s
ComparatorBenchmarks.put  java_reverse_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   11421.311   807.210  ops/s
ComparatorBenchmarks.put        java_reverse_bytewise_non-direct_reused-64_thread-local  thrpt   25   11554.005   960.556  ops/s
ComparatorBenchmarks.put          java_reverse_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   22960.523  1673.421  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   18293.317  1434.601  ops/s
ComparatorBenchmarks.put            java_reverse_bytewise_direct_reused-64_thread-local  thrpt   25   24479.361  2157.306  ops/s
ComparatorBenchmarks.put                      java_reverse_bytewise_non-direct_no-reuse  thrpt   25    7942.286   626.170  ops/s
ComparatorBenchmarks.put                          java_reverse_bytewise_direct_no-reuse  thrpt   25   11781.955  1019.843  ops/s
```
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6252
Differential Revision: D19331064
Pulled By: pdillinger
fbshipit-source-id: 1f3b794e6a14162b2c3ffb943e8c0e64a0c03738/"
rocksdb,"Improve RocksJava Comparator (#6252)
Summary:
This is a redesign of the API for RocksJava comparators with the aim of improving performance. It also simplifies the class hierarchy.
**NOTE**: This breaks backwards compatibility for existing 3rd party Comparators implemented in Java... so we need to consider carefully which release branches this goes into.
Previously when implementing a comparator in Java the developer had a choice of subclassing either `DirectComparator` or `Comparator` which would use direct and non-direct byte-buffers resepectively (via `DirectSlice` and `Slice`).
In this redesign there we have eliminated the overhead of using the Java Slice classes, and just use `ByteBuffer`s. The `ComparatorOptions` supplied when constructing a Comparator allow you to choose between direct and non-direct byte buffers by setting `useDirect`.
In addition, the `ComparatorOptions` now allow you to choose whether a ByteBuffer is reused over multiple comparator calls, by setting `maxReusedBufferSize > 0`. When buffers are reused, ComparatorOptions provides a choice of mutex type by setting `useAdaptiveMutex`.
---
[JMH benchmarks previously indicated](https://github.com/facebook/rocksdb/pull/6241#issue-356398306) that the difference between C++ and Java for implementing a comparator was ~7x slowdown in Java.
With these changes, when reusing buffers and guarding access to them via mutexes the slowdown is approximately the same. However, these changes offer a new facility to not reuse mutextes, which reduces the slowdown to ~5.5x in Java. We also offer a `thread_local` mechanism for reusing buffers, which reduces slowdown to ~5.2x in Java (closes https://github.com/facebook/rocksdb/pull/4425).
These changes also form a good base for further optimisation work such as further JNI lookup caching, and JNI critical.
---
These numbers were captured without jemalloc. With jemalloc, the performance improves for all tests, and the Java slowdown reduces to between 4.8x and 5.x.
```
ComparatorBenchmarks.put                                                native_bytewise  thrpt   25  124483.795  2032.443  ops/s
ComparatorBenchmarks.put                                        native_reverse_bytewise  thrpt   25  114414.536  3486.156  ops/s
ComparatorBenchmarks.put              java_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   17228.250  1288.546  ops/s
ComparatorBenchmarks.put          java_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   16035.865  1248.099  ops/s
ComparatorBenchmarks.put                java_bytewise_non-direct_reused-64_thread-local  thrpt   25   21571.500   871.521  ops/s
ComparatorBenchmarks.put                  java_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   23613.773  8465.660  ops/s
ComparatorBenchmarks.put              java_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   16768.172  5618.489  ops/s
ComparatorBenchmarks.put                    java_bytewise_direct_reused-64_thread-local  thrpt   25   23921.164  8734.742  ops/s
ComparatorBenchmarks.put                              java_bytewise_non-direct_no-reuse  thrpt   25   17899.684   839.679  ops/s
ComparatorBenchmarks.put                                  java_bytewise_direct_no-reuse  thrpt   25   22148.316  1215.527  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   11311.126   820.602  ops/s
ComparatorBenchmarks.put  java_reverse_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   11421.311   807.210  ops/s
ComparatorBenchmarks.put        java_reverse_bytewise_non-direct_reused-64_thread-local  thrpt   25   11554.005   960.556  ops/s
ComparatorBenchmarks.put          java_reverse_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   22960.523  1673.421  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   18293.317  1434.601  ops/s
ComparatorBenchmarks.put            java_reverse_bytewise_direct_reused-64_thread-local  thrpt   25   24479.361  2157.306  ops/s
ComparatorBenchmarks.put                      java_reverse_bytewise_non-direct_no-reuse  thrpt   25    7942.286   626.170  ops/s
ComparatorBenchmarks.put                          java_reverse_bytewise_direct_no-reuse  thrpt   25   11781.955  1019.843  ops/s
```
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6252
Differential Revision: D19331064
Pulled By: pdillinger
fbshipit-source-id: 1f3b794e6a14162b2c3ffb943e8c0e64a0c03738/"
rocksdb,"Improve RocksJava Comparator (#6252)
Summary:
This is a redesign of the API for RocksJava comparators with the aim of improving performance. It also simplifies the class hierarchy.
**NOTE**: This breaks backwards compatibility for existing 3rd party Comparators implemented in Java... so we need to consider carefully which release branches this goes into.
Previously when implementing a comparator in Java the developer had a choice of subclassing either `DirectComparator` or `Comparator` which would use direct and non-direct byte-buffers resepectively (via `DirectSlice` and `Slice`).
In this redesign there we have eliminated the overhead of using the Java Slice classes, and just use `ByteBuffer`s. The `ComparatorOptions` supplied when constructing a Comparator allow you to choose between direct and non-direct byte buffers by setting `useDirect`.
In addition, the `ComparatorOptions` now allow you to choose whether a ByteBuffer is reused over multiple comparator calls, by setting `maxReusedBufferSize > 0`. When buffers are reused, ComparatorOptions provides a choice of mutex type by setting `useAdaptiveMutex`.
---
[JMH benchmarks previously indicated](https://github.com/facebook/rocksdb/pull/6241#issue-356398306) that the difference between C++ and Java for implementing a comparator was ~7x slowdown in Java.
With these changes, when reusing buffers and guarding access to them via mutexes the slowdown is approximately the same. However, these changes offer a new facility to not reuse mutextes, which reduces the slowdown to ~5.5x in Java. We also offer a `thread_local` mechanism for reusing buffers, which reduces slowdown to ~5.2x in Java (closes https://github.com/facebook/rocksdb/pull/4425).
These changes also form a good base for further optimisation work such as further JNI lookup caching, and JNI critical.
---
These numbers were captured without jemalloc. With jemalloc, the performance improves for all tests, and the Java slowdown reduces to between 4.8x and 5.x.
```
ComparatorBenchmarks.put                                                native_bytewise  thrpt   25  124483.795  2032.443  ops/s
ComparatorBenchmarks.put                                        native_reverse_bytewise  thrpt   25  114414.536  3486.156  ops/s
ComparatorBenchmarks.put              java_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   17228.250  1288.546  ops/s
ComparatorBenchmarks.put          java_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   16035.865  1248.099  ops/s
ComparatorBenchmarks.put                java_bytewise_non-direct_reused-64_thread-local  thrpt   25   21571.500   871.521  ops/s
ComparatorBenchmarks.put                  java_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   23613.773  8465.660  ops/s
ComparatorBenchmarks.put              java_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   16768.172  5618.489  ops/s
ComparatorBenchmarks.put                    java_bytewise_direct_reused-64_thread-local  thrpt   25   23921.164  8734.742  ops/s
ComparatorBenchmarks.put                              java_bytewise_non-direct_no-reuse  thrpt   25   17899.684   839.679  ops/s
ComparatorBenchmarks.put                                  java_bytewise_direct_no-reuse  thrpt   25   22148.316  1215.527  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   11311.126   820.602  ops/s
ComparatorBenchmarks.put  java_reverse_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   11421.311   807.210  ops/s
ComparatorBenchmarks.put        java_reverse_bytewise_non-direct_reused-64_thread-local  thrpt   25   11554.005   960.556  ops/s
ComparatorBenchmarks.put          java_reverse_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   22960.523  1673.421  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   18293.317  1434.601  ops/s
ComparatorBenchmarks.put            java_reverse_bytewise_direct_reused-64_thread-local  thrpt   25   24479.361  2157.306  ops/s
ComparatorBenchmarks.put                      java_reverse_bytewise_non-direct_no-reuse  thrpt   25    7942.286   626.170  ops/s
ComparatorBenchmarks.put                          java_reverse_bytewise_direct_no-reuse  thrpt   25   11781.955  1019.843  ops/s
```
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6252
Differential Revision: D19331064
Pulled By: pdillinger
fbshipit-source-id: 1f3b794e6a14162b2c3ffb943e8c0e64a0c03738/"
rocksdb,"Improve RocksJava Comparator (#6252)
Summary:
This is a redesign of the API for RocksJava comparators with the aim of improving performance. It also simplifies the class hierarchy.
**NOTE**: This breaks backwards compatibility for existing 3rd party Comparators implemented in Java... so we need to consider carefully which release branches this goes into.
Previously when implementing a comparator in Java the developer had a choice of subclassing either `DirectComparator` or `Comparator` which would use direct and non-direct byte-buffers resepectively (via `DirectSlice` and `Slice`).
In this redesign there we have eliminated the overhead of using the Java Slice classes, and just use `ByteBuffer`s. The `ComparatorOptions` supplied when constructing a Comparator allow you to choose between direct and non-direct byte buffers by setting `useDirect`.
In addition, the `ComparatorOptions` now allow you to choose whether a ByteBuffer is reused over multiple comparator calls, by setting `maxReusedBufferSize > 0`. When buffers are reused, ComparatorOptions provides a choice of mutex type by setting `useAdaptiveMutex`.
---
[JMH benchmarks previously indicated](https://github.com/facebook/rocksdb/pull/6241#issue-356398306) that the difference between C++ and Java for implementing a comparator was ~7x slowdown in Java.
With these changes, when reusing buffers and guarding access to them via mutexes the slowdown is approximately the same. However, these changes offer a new facility to not reuse mutextes, which reduces the slowdown to ~5.5x in Java. We also offer a `thread_local` mechanism for reusing buffers, which reduces slowdown to ~5.2x in Java (closes https://github.com/facebook/rocksdb/pull/4425).
These changes also form a good base for further optimisation work such as further JNI lookup caching, and JNI critical.
---
These numbers were captured without jemalloc. With jemalloc, the performance improves for all tests, and the Java slowdown reduces to between 4.8x and 5.x.
```
ComparatorBenchmarks.put                                                native_bytewise  thrpt   25  124483.795  2032.443  ops/s
ComparatorBenchmarks.put                                        native_reverse_bytewise  thrpt   25  114414.536  3486.156  ops/s
ComparatorBenchmarks.put              java_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   17228.250  1288.546  ops/s
ComparatorBenchmarks.put          java_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   16035.865  1248.099  ops/s
ComparatorBenchmarks.put                java_bytewise_non-direct_reused-64_thread-local  thrpt   25   21571.500   871.521  ops/s
ComparatorBenchmarks.put                  java_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   23613.773  8465.660  ops/s
ComparatorBenchmarks.put              java_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   16768.172  5618.489  ops/s
ComparatorBenchmarks.put                    java_bytewise_direct_reused-64_thread-local  thrpt   25   23921.164  8734.742  ops/s
ComparatorBenchmarks.put                              java_bytewise_non-direct_no-reuse  thrpt   25   17899.684   839.679  ops/s
ComparatorBenchmarks.put                                  java_bytewise_direct_no-reuse  thrpt   25   22148.316  1215.527  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   11311.126   820.602  ops/s
ComparatorBenchmarks.put  java_reverse_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   11421.311   807.210  ops/s
ComparatorBenchmarks.put        java_reverse_bytewise_non-direct_reused-64_thread-local  thrpt   25   11554.005   960.556  ops/s
ComparatorBenchmarks.put          java_reverse_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   22960.523  1673.421  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   18293.317  1434.601  ops/s
ComparatorBenchmarks.put            java_reverse_bytewise_direct_reused-64_thread-local  thrpt   25   24479.361  2157.306  ops/s
ComparatorBenchmarks.put                      java_reverse_bytewise_non-direct_no-reuse  thrpt   25    7942.286   626.170  ops/s
ComparatorBenchmarks.put                          java_reverse_bytewise_direct_no-reuse  thrpt   25   11781.955  1019.843  ops/s
```
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6252
Differential Revision: D19331064
Pulled By: pdillinger
fbshipit-source-id: 1f3b794e6a14162b2c3ffb943e8c0e64a0c03738/"
rocksdb,"Improve RocksJava Comparator (#6252)
Summary:
This is a redesign of the API for RocksJava comparators with the aim of improving performance. It also simplifies the class hierarchy.
**NOTE**: This breaks backwards compatibility for existing 3rd party Comparators implemented in Java... so we need to consider carefully which release branches this goes into.
Previously when implementing a comparator in Java the developer had a choice of subclassing either `DirectComparator` or `Comparator` which would use direct and non-direct byte-buffers resepectively (via `DirectSlice` and `Slice`).
In this redesign there we have eliminated the overhead of using the Java Slice classes, and just use `ByteBuffer`s. The `ComparatorOptions` supplied when constructing a Comparator allow you to choose between direct and non-direct byte buffers by setting `useDirect`.
In addition, the `ComparatorOptions` now allow you to choose whether a ByteBuffer is reused over multiple comparator calls, by setting `maxReusedBufferSize > 0`. When buffers are reused, ComparatorOptions provides a choice of mutex type by setting `useAdaptiveMutex`.
---
[JMH benchmarks previously indicated](https://github.com/facebook/rocksdb/pull/6241#issue-356398306) that the difference between C++ and Java for implementing a comparator was ~7x slowdown in Java.
With these changes, when reusing buffers and guarding access to them via mutexes the slowdown is approximately the same. However, these changes offer a new facility to not reuse mutextes, which reduces the slowdown to ~5.5x in Java. We also offer a `thread_local` mechanism for reusing buffers, which reduces slowdown to ~5.2x in Java (closes https://github.com/facebook/rocksdb/pull/4425).
These changes also form a good base for further optimisation work such as further JNI lookup caching, and JNI critical.
---
These numbers were captured without jemalloc. With jemalloc, the performance improves for all tests, and the Java slowdown reduces to between 4.8x and 5.x.
```
ComparatorBenchmarks.put                                                native_bytewise  thrpt   25  124483.795  2032.443  ops/s
ComparatorBenchmarks.put                                        native_reverse_bytewise  thrpt   25  114414.536  3486.156  ops/s
ComparatorBenchmarks.put              java_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   17228.250  1288.546  ops/s
ComparatorBenchmarks.put          java_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   16035.865  1248.099  ops/s
ComparatorBenchmarks.put                java_bytewise_non-direct_reused-64_thread-local  thrpt   25   21571.500   871.521  ops/s
ComparatorBenchmarks.put                  java_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   23613.773  8465.660  ops/s
ComparatorBenchmarks.put              java_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   16768.172  5618.489  ops/s
ComparatorBenchmarks.put                    java_bytewise_direct_reused-64_thread-local  thrpt   25   23921.164  8734.742  ops/s
ComparatorBenchmarks.put                              java_bytewise_non-direct_no-reuse  thrpt   25   17899.684   839.679  ops/s
ComparatorBenchmarks.put                                  java_bytewise_direct_no-reuse  thrpt   25   22148.316  1215.527  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   11311.126   820.602  ops/s
ComparatorBenchmarks.put  java_reverse_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   11421.311   807.210  ops/s
ComparatorBenchmarks.put        java_reverse_bytewise_non-direct_reused-64_thread-local  thrpt   25   11554.005   960.556  ops/s
ComparatorBenchmarks.put          java_reverse_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   22960.523  1673.421  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   18293.317  1434.601  ops/s
ComparatorBenchmarks.put            java_reverse_bytewise_direct_reused-64_thread-local  thrpt   25   24479.361  2157.306  ops/s
ComparatorBenchmarks.put                      java_reverse_bytewise_non-direct_no-reuse  thrpt   25    7942.286   626.170  ops/s
ComparatorBenchmarks.put                          java_reverse_bytewise_direct_no-reuse  thrpt   25   11781.955  1019.843  ops/s
```
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6252
Differential Revision: D19331064
Pulled By: pdillinger
fbshipit-source-id: 1f3b794e6a14162b2c3ffb943e8c0e64a0c03738/"
rocksdb,"Improve RocksJava Comparator (#6252)
Summary:
This is a redesign of the API for RocksJava comparators with the aim of improving performance. It also simplifies the class hierarchy.
**NOTE**: This breaks backwards compatibility for existing 3rd party Comparators implemented in Java... so we need to consider carefully which release branches this goes into.
Previously when implementing a comparator in Java the developer had a choice of subclassing either `DirectComparator` or `Comparator` which would use direct and non-direct byte-buffers resepectively (via `DirectSlice` and `Slice`).
In this redesign there we have eliminated the overhead of using the Java Slice classes, and just use `ByteBuffer`s. The `ComparatorOptions` supplied when constructing a Comparator allow you to choose between direct and non-direct byte buffers by setting `useDirect`.
In addition, the `ComparatorOptions` now allow you to choose whether a ByteBuffer is reused over multiple comparator calls, by setting `maxReusedBufferSize > 0`. When buffers are reused, ComparatorOptions provides a choice of mutex type by setting `useAdaptiveMutex`.
---
[JMH benchmarks previously indicated](https://github.com/facebook/rocksdb/pull/6241#issue-356398306) that the difference between C++ and Java for implementing a comparator was ~7x slowdown in Java.
With these changes, when reusing buffers and guarding access to them via mutexes the slowdown is approximately the same. However, these changes offer a new facility to not reuse mutextes, which reduces the slowdown to ~5.5x in Java. We also offer a `thread_local` mechanism for reusing buffers, which reduces slowdown to ~5.2x in Java (closes https://github.com/facebook/rocksdb/pull/4425).
These changes also form a good base for further optimisation work such as further JNI lookup caching, and JNI critical.
---
These numbers were captured without jemalloc. With jemalloc, the performance improves for all tests, and the Java slowdown reduces to between 4.8x and 5.x.
```
ComparatorBenchmarks.put                                                native_bytewise  thrpt   25  124483.795  2032.443  ops/s
ComparatorBenchmarks.put                                        native_reverse_bytewise  thrpt   25  114414.536  3486.156  ops/s
ComparatorBenchmarks.put              java_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   17228.250  1288.546  ops/s
ComparatorBenchmarks.put          java_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   16035.865  1248.099  ops/s
ComparatorBenchmarks.put                java_bytewise_non-direct_reused-64_thread-local  thrpt   25   21571.500   871.521  ops/s
ComparatorBenchmarks.put                  java_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   23613.773  8465.660  ops/s
ComparatorBenchmarks.put              java_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   16768.172  5618.489  ops/s
ComparatorBenchmarks.put                    java_bytewise_direct_reused-64_thread-local  thrpt   25   23921.164  8734.742  ops/s
ComparatorBenchmarks.put                              java_bytewise_non-direct_no-reuse  thrpt   25   17899.684   839.679  ops/s
ComparatorBenchmarks.put                                  java_bytewise_direct_no-reuse  thrpt   25   22148.316  1215.527  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   11311.126   820.602  ops/s
ComparatorBenchmarks.put  java_reverse_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   11421.311   807.210  ops/s
ComparatorBenchmarks.put        java_reverse_bytewise_non-direct_reused-64_thread-local  thrpt   25   11554.005   960.556  ops/s
ComparatorBenchmarks.put          java_reverse_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   22960.523  1673.421  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   18293.317  1434.601  ops/s
ComparatorBenchmarks.put            java_reverse_bytewise_direct_reused-64_thread-local  thrpt   25   24479.361  2157.306  ops/s
ComparatorBenchmarks.put                      java_reverse_bytewise_non-direct_no-reuse  thrpt   25    7942.286   626.170  ops/s
ComparatorBenchmarks.put                          java_reverse_bytewise_direct_no-reuse  thrpt   25   11781.955  1019.843  ops/s
```
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6252
Differential Revision: D19331064
Pulled By: pdillinger
fbshipit-source-id: 1f3b794e6a14162b2c3ffb943e8c0e64a0c03738/"
rocksdb,"fix typo (#6099)
Summary:
fix a typo in struct ReadOptions
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6099
Differential Revision: D18729618
fbshipit-source-id: 850a9df71f7c0abebea17feab77b8d5874e8ba0a/"
rocksdb,"Improve RocksJava Comparator (#6252)
Summary:
This is a redesign of the API for RocksJava comparators with the aim of improving performance. It also simplifies the class hierarchy.
**NOTE**: This breaks backwards compatibility for existing 3rd party Comparators implemented in Java... so we need to consider carefully which release branches this goes into.
Previously when implementing a comparator in Java the developer had a choice of subclassing either `DirectComparator` or `Comparator` which would use direct and non-direct byte-buffers resepectively (via `DirectSlice` and `Slice`).
In this redesign there we have eliminated the overhead of using the Java Slice classes, and just use `ByteBuffer`s. The `ComparatorOptions` supplied when constructing a Comparator allow you to choose between direct and non-direct byte buffers by setting `useDirect`.
In addition, the `ComparatorOptions` now allow you to choose whether a ByteBuffer is reused over multiple comparator calls, by setting `maxReusedBufferSize > 0`. When buffers are reused, ComparatorOptions provides a choice of mutex type by setting `useAdaptiveMutex`.
---
[JMH benchmarks previously indicated](https://github.com/facebook/rocksdb/pull/6241#issue-356398306) that the difference between C++ and Java for implementing a comparator was ~7x slowdown in Java.
With these changes, when reusing buffers and guarding access to them via mutexes the slowdown is approximately the same. However, these changes offer a new facility to not reuse mutextes, which reduces the slowdown to ~5.5x in Java. We also offer a `thread_local` mechanism for reusing buffers, which reduces slowdown to ~5.2x in Java (closes https://github.com/facebook/rocksdb/pull/4425).
These changes also form a good base for further optimisation work such as further JNI lookup caching, and JNI critical.
---
These numbers were captured without jemalloc. With jemalloc, the performance improves for all tests, and the Java slowdown reduces to between 4.8x and 5.x.
```
ComparatorBenchmarks.put                                                native_bytewise  thrpt   25  124483.795  2032.443  ops/s
ComparatorBenchmarks.put                                        native_reverse_bytewise  thrpt   25  114414.536  3486.156  ops/s
ComparatorBenchmarks.put              java_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   17228.250  1288.546  ops/s
ComparatorBenchmarks.put          java_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   16035.865  1248.099  ops/s
ComparatorBenchmarks.put                java_bytewise_non-direct_reused-64_thread-local  thrpt   25   21571.500   871.521  ops/s
ComparatorBenchmarks.put                  java_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   23613.773  8465.660  ops/s
ComparatorBenchmarks.put              java_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   16768.172  5618.489  ops/s
ComparatorBenchmarks.put                    java_bytewise_direct_reused-64_thread-local  thrpt   25   23921.164  8734.742  ops/s
ComparatorBenchmarks.put                              java_bytewise_non-direct_no-reuse  thrpt   25   17899.684   839.679  ops/s
ComparatorBenchmarks.put                                  java_bytewise_direct_no-reuse  thrpt   25   22148.316  1215.527  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   11311.126   820.602  ops/s
ComparatorBenchmarks.put  java_reverse_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   11421.311   807.210  ops/s
ComparatorBenchmarks.put        java_reverse_bytewise_non-direct_reused-64_thread-local  thrpt   25   11554.005   960.556  ops/s
ComparatorBenchmarks.put          java_reverse_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   22960.523  1673.421  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   18293.317  1434.601  ops/s
ComparatorBenchmarks.put            java_reverse_bytewise_direct_reused-64_thread-local  thrpt   25   24479.361  2157.306  ops/s
ComparatorBenchmarks.put                      java_reverse_bytewise_non-direct_no-reuse  thrpt   25    7942.286   626.170  ops/s
ComparatorBenchmarks.put                          java_reverse_bytewise_direct_no-reuse  thrpt   25   11781.955  1019.843  ops/s
```
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6252
Differential Revision: D19331064
Pulled By: pdillinger
fbshipit-source-id: 1f3b794e6a14162b2c3ffb943e8c0e64a0c03738/"
rocksdb,"Allow fractional bits/key in BloomFilterPolicy (#6092)
Summary:
There's no technological impediment to allowing the Bloom
filter bits/key to be non-integer (fractional/decimal) values, and it
provides finer control over the memory vs. accuracy trade-off. This is
especially handy in using the format_version=5 Bloom filter in place
of the old one, because bits_per_key=9.55 provides the same accuracy as
the old bits_per_key=10.
This change not only requires refining the logic for choosing the best
num_probes for a given bits/key setting, it revealed a flaw in that logic.
As bits/key gets higher, the best num_probes for a cache-local Bloom
filter is closer to bpk / 2 than to bpk * 0.69, the best choice for a
standard Bloom filter. For example, at 16 bits per key, the best
num_probes is 9 (FP rate = 0.0843%) not 11 (FP rate = 0.0884%).
This change fixes and refines that logic (for the format_version=5
Bloom filter only, just in case) based on empirical tests to find
accuracy inflection points between each num_probes.
Although bits_per_key is now specified as a double, the new Bloom
filter converts/rounds this to ""millibits / key"" for predictable/precise
internal computations. Just in case of unforeseen compatibility
issues, we round to the nearest whole number bits / key for the
legacy Bloom filter, so as not to unlock new behaviors for it.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6092
Test Plan: unit tests included
Differential Revision: D18711313
Pulled By: pdillinger
fbshipit-source-id: 1aa73295f152a995328cb846ef9157ae8a05522a/"
rocksdb,"Improve RocksJava Comparator (#6252)
Summary:
This is a redesign of the API for RocksJava comparators with the aim of improving performance. It also simplifies the class hierarchy.
**NOTE**: This breaks backwards compatibility for existing 3rd party Comparators implemented in Java... so we need to consider carefully which release branches this goes into.
Previously when implementing a comparator in Java the developer had a choice of subclassing either `DirectComparator` or `Comparator` which would use direct and non-direct byte-buffers resepectively (via `DirectSlice` and `Slice`).
In this redesign there we have eliminated the overhead of using the Java Slice classes, and just use `ByteBuffer`s. The `ComparatorOptions` supplied when constructing a Comparator allow you to choose between direct and non-direct byte buffers by setting `useDirect`.
In addition, the `ComparatorOptions` now allow you to choose whether a ByteBuffer is reused over multiple comparator calls, by setting `maxReusedBufferSize > 0`. When buffers are reused, ComparatorOptions provides a choice of mutex type by setting `useAdaptiveMutex`.
---
[JMH benchmarks previously indicated](https://github.com/facebook/rocksdb/pull/6241#issue-356398306) that the difference between C++ and Java for implementing a comparator was ~7x slowdown in Java.
With these changes, when reusing buffers and guarding access to them via mutexes the slowdown is approximately the same. However, these changes offer a new facility to not reuse mutextes, which reduces the slowdown to ~5.5x in Java. We also offer a `thread_local` mechanism for reusing buffers, which reduces slowdown to ~5.2x in Java (closes https://github.com/facebook/rocksdb/pull/4425).
These changes also form a good base for further optimisation work such as further JNI lookup caching, and JNI critical.
---
These numbers were captured without jemalloc. With jemalloc, the performance improves for all tests, and the Java slowdown reduces to between 4.8x and 5.x.
```
ComparatorBenchmarks.put                                                native_bytewise  thrpt   25  124483.795  2032.443  ops/s
ComparatorBenchmarks.put                                        native_reverse_bytewise  thrpt   25  114414.536  3486.156  ops/s
ComparatorBenchmarks.put              java_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   17228.250  1288.546  ops/s
ComparatorBenchmarks.put          java_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   16035.865  1248.099  ops/s
ComparatorBenchmarks.put                java_bytewise_non-direct_reused-64_thread-local  thrpt   25   21571.500   871.521  ops/s
ComparatorBenchmarks.put                  java_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   23613.773  8465.660  ops/s
ComparatorBenchmarks.put              java_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   16768.172  5618.489  ops/s
ComparatorBenchmarks.put                    java_bytewise_direct_reused-64_thread-local  thrpt   25   23921.164  8734.742  ops/s
ComparatorBenchmarks.put                              java_bytewise_non-direct_no-reuse  thrpt   25   17899.684   839.679  ops/s
ComparatorBenchmarks.put                                  java_bytewise_direct_no-reuse  thrpt   25   22148.316  1215.527  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   11311.126   820.602  ops/s
ComparatorBenchmarks.put  java_reverse_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   11421.311   807.210  ops/s
ComparatorBenchmarks.put        java_reverse_bytewise_non-direct_reused-64_thread-local  thrpt   25   11554.005   960.556  ops/s
ComparatorBenchmarks.put          java_reverse_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   22960.523  1673.421  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   18293.317  1434.601  ops/s
ComparatorBenchmarks.put            java_reverse_bytewise_direct_reused-64_thread-local  thrpt   25   24479.361  2157.306  ops/s
ComparatorBenchmarks.put                      java_reverse_bytewise_non-direct_no-reuse  thrpt   25    7942.286   626.170  ops/s
ComparatorBenchmarks.put                          java_reverse_bytewise_direct_no-reuse  thrpt   25   11781.955  1019.843  ops/s
```
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6252
Differential Revision: D19331064
Pulled By: pdillinger
fbshipit-source-id: 1f3b794e6a14162b2c3ffb943e8c0e64a0c03738/"
rocksdb,"Improve RocksJava Comparator (#6252)
Summary:
This is a redesign of the API for RocksJava comparators with the aim of improving performance. It also simplifies the class hierarchy.
**NOTE**: This breaks backwards compatibility for existing 3rd party Comparators implemented in Java... so we need to consider carefully which release branches this goes into.
Previously when implementing a comparator in Java the developer had a choice of subclassing either `DirectComparator` or `Comparator` which would use direct and non-direct byte-buffers resepectively (via `DirectSlice` and `Slice`).
In this redesign there we have eliminated the overhead of using the Java Slice classes, and just use `ByteBuffer`s. The `ComparatorOptions` supplied when constructing a Comparator allow you to choose between direct and non-direct byte buffers by setting `useDirect`.
In addition, the `ComparatorOptions` now allow you to choose whether a ByteBuffer is reused over multiple comparator calls, by setting `maxReusedBufferSize > 0`. When buffers are reused, ComparatorOptions provides a choice of mutex type by setting `useAdaptiveMutex`.
---
[JMH benchmarks previously indicated](https://github.com/facebook/rocksdb/pull/6241#issue-356398306) that the difference between C++ and Java for implementing a comparator was ~7x slowdown in Java.
With these changes, when reusing buffers and guarding access to them via mutexes the slowdown is approximately the same. However, these changes offer a new facility to not reuse mutextes, which reduces the slowdown to ~5.5x in Java. We also offer a `thread_local` mechanism for reusing buffers, which reduces slowdown to ~5.2x in Java (closes https://github.com/facebook/rocksdb/pull/4425).
These changes also form a good base for further optimisation work such as further JNI lookup caching, and JNI critical.
---
These numbers were captured without jemalloc. With jemalloc, the performance improves for all tests, and the Java slowdown reduces to between 4.8x and 5.x.
```
ComparatorBenchmarks.put                                                native_bytewise  thrpt   25  124483.795  2032.443  ops/s
ComparatorBenchmarks.put                                        native_reverse_bytewise  thrpt   25  114414.536  3486.156  ops/s
ComparatorBenchmarks.put              java_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   17228.250  1288.546  ops/s
ComparatorBenchmarks.put          java_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   16035.865  1248.099  ops/s
ComparatorBenchmarks.put                java_bytewise_non-direct_reused-64_thread-local  thrpt   25   21571.500   871.521  ops/s
ComparatorBenchmarks.put                  java_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   23613.773  8465.660  ops/s
ComparatorBenchmarks.put              java_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   16768.172  5618.489  ops/s
ComparatorBenchmarks.put                    java_bytewise_direct_reused-64_thread-local  thrpt   25   23921.164  8734.742  ops/s
ComparatorBenchmarks.put                              java_bytewise_non-direct_no-reuse  thrpt   25   17899.684   839.679  ops/s
ComparatorBenchmarks.put                                  java_bytewise_direct_no-reuse  thrpt   25   22148.316  1215.527  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   11311.126   820.602  ops/s
ComparatorBenchmarks.put  java_reverse_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   11421.311   807.210  ops/s
ComparatorBenchmarks.put        java_reverse_bytewise_non-direct_reused-64_thread-local  thrpt   25   11554.005   960.556  ops/s
ComparatorBenchmarks.put          java_reverse_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   22960.523  1673.421  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   18293.317  1434.601  ops/s
ComparatorBenchmarks.put            java_reverse_bytewise_direct_reused-64_thread-local  thrpt   25   24479.361  2157.306  ops/s
ComparatorBenchmarks.put                      java_reverse_bytewise_non-direct_no-reuse  thrpt   25    7942.286   626.170  ops/s
ComparatorBenchmarks.put                          java_reverse_bytewise_direct_no-reuse  thrpt   25   11781.955  1019.843  ops/s
```
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6252
Differential Revision: D19331064
Pulled By: pdillinger
fbshipit-source-id: 1f3b794e6a14162b2c3ffb943e8c0e64a0c03738/"
rocksdb,"Improve RocksJava Comparator (#6252)
Summary:
This is a redesign of the API for RocksJava comparators with the aim of improving performance. It also simplifies the class hierarchy.
**NOTE**: This breaks backwards compatibility for existing 3rd party Comparators implemented in Java... so we need to consider carefully which release branches this goes into.
Previously when implementing a comparator in Java the developer had a choice of subclassing either `DirectComparator` or `Comparator` which would use direct and non-direct byte-buffers resepectively (via `DirectSlice` and `Slice`).
In this redesign there we have eliminated the overhead of using the Java Slice classes, and just use `ByteBuffer`s. The `ComparatorOptions` supplied when constructing a Comparator allow you to choose between direct and non-direct byte buffers by setting `useDirect`.
In addition, the `ComparatorOptions` now allow you to choose whether a ByteBuffer is reused over multiple comparator calls, by setting `maxReusedBufferSize > 0`. When buffers are reused, ComparatorOptions provides a choice of mutex type by setting `useAdaptiveMutex`.
---
[JMH benchmarks previously indicated](https://github.com/facebook/rocksdb/pull/6241#issue-356398306) that the difference between C++ and Java for implementing a comparator was ~7x slowdown in Java.
With these changes, when reusing buffers and guarding access to them via mutexes the slowdown is approximately the same. However, these changes offer a new facility to not reuse mutextes, which reduces the slowdown to ~5.5x in Java. We also offer a `thread_local` mechanism for reusing buffers, which reduces slowdown to ~5.2x in Java (closes https://github.com/facebook/rocksdb/pull/4425).
These changes also form a good base for further optimisation work such as further JNI lookup caching, and JNI critical.
---
These numbers were captured without jemalloc. With jemalloc, the performance improves for all tests, and the Java slowdown reduces to between 4.8x and 5.x.
```
ComparatorBenchmarks.put                                                native_bytewise  thrpt   25  124483.795  2032.443  ops/s
ComparatorBenchmarks.put                                        native_reverse_bytewise  thrpt   25  114414.536  3486.156  ops/s
ComparatorBenchmarks.put              java_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   17228.250  1288.546  ops/s
ComparatorBenchmarks.put          java_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   16035.865  1248.099  ops/s
ComparatorBenchmarks.put                java_bytewise_non-direct_reused-64_thread-local  thrpt   25   21571.500   871.521  ops/s
ComparatorBenchmarks.put                  java_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   23613.773  8465.660  ops/s
ComparatorBenchmarks.put              java_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   16768.172  5618.489  ops/s
ComparatorBenchmarks.put                    java_bytewise_direct_reused-64_thread-local  thrpt   25   23921.164  8734.742  ops/s
ComparatorBenchmarks.put                              java_bytewise_non-direct_no-reuse  thrpt   25   17899.684   839.679  ops/s
ComparatorBenchmarks.put                                  java_bytewise_direct_no-reuse  thrpt   25   22148.316  1215.527  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   11311.126   820.602  ops/s
ComparatorBenchmarks.put  java_reverse_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   11421.311   807.210  ops/s
ComparatorBenchmarks.put        java_reverse_bytewise_non-direct_reused-64_thread-local  thrpt   25   11554.005   960.556  ops/s
ComparatorBenchmarks.put          java_reverse_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   22960.523  1673.421  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   18293.317  1434.601  ops/s
ComparatorBenchmarks.put            java_reverse_bytewise_direct_reused-64_thread-local  thrpt   25   24479.361  2157.306  ops/s
ComparatorBenchmarks.put                      java_reverse_bytewise_non-direct_no-reuse  thrpt   25    7942.286   626.170  ops/s
ComparatorBenchmarks.put                          java_reverse_bytewise_direct_no-reuse  thrpt   25   11781.955  1019.843  ops/s
```
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6252
Differential Revision: D19331064
Pulled By: pdillinger
fbshipit-source-id: 1f3b794e6a14162b2c3ffb943e8c0e64a0c03738/"
rocksdb,"Improve RocksJava Comparator (#6252)
Summary:
This is a redesign of the API for RocksJava comparators with the aim of improving performance. It also simplifies the class hierarchy.
**NOTE**: This breaks backwards compatibility for existing 3rd party Comparators implemented in Java... so we need to consider carefully which release branches this goes into.
Previously when implementing a comparator in Java the developer had a choice of subclassing either `DirectComparator` or `Comparator` which would use direct and non-direct byte-buffers resepectively (via `DirectSlice` and `Slice`).
In this redesign there we have eliminated the overhead of using the Java Slice classes, and just use `ByteBuffer`s. The `ComparatorOptions` supplied when constructing a Comparator allow you to choose between direct and non-direct byte buffers by setting `useDirect`.
In addition, the `ComparatorOptions` now allow you to choose whether a ByteBuffer is reused over multiple comparator calls, by setting `maxReusedBufferSize > 0`. When buffers are reused, ComparatorOptions provides a choice of mutex type by setting `useAdaptiveMutex`.
---
[JMH benchmarks previously indicated](https://github.com/facebook/rocksdb/pull/6241#issue-356398306) that the difference between C++ and Java for implementing a comparator was ~7x slowdown in Java.
With these changes, when reusing buffers and guarding access to them via mutexes the slowdown is approximately the same. However, these changes offer a new facility to not reuse mutextes, which reduces the slowdown to ~5.5x in Java. We also offer a `thread_local` mechanism for reusing buffers, which reduces slowdown to ~5.2x in Java (closes https://github.com/facebook/rocksdb/pull/4425).
These changes also form a good base for further optimisation work such as further JNI lookup caching, and JNI critical.
---
These numbers were captured without jemalloc. With jemalloc, the performance improves for all tests, and the Java slowdown reduces to between 4.8x and 5.x.
```
ComparatorBenchmarks.put                                                native_bytewise  thrpt   25  124483.795  2032.443  ops/s
ComparatorBenchmarks.put                                        native_reverse_bytewise  thrpt   25  114414.536  3486.156  ops/s
ComparatorBenchmarks.put              java_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   17228.250  1288.546  ops/s
ComparatorBenchmarks.put          java_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   16035.865  1248.099  ops/s
ComparatorBenchmarks.put                java_bytewise_non-direct_reused-64_thread-local  thrpt   25   21571.500   871.521  ops/s
ComparatorBenchmarks.put                  java_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   23613.773  8465.660  ops/s
ComparatorBenchmarks.put              java_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   16768.172  5618.489  ops/s
ComparatorBenchmarks.put                    java_bytewise_direct_reused-64_thread-local  thrpt   25   23921.164  8734.742  ops/s
ComparatorBenchmarks.put                              java_bytewise_non-direct_no-reuse  thrpt   25   17899.684   839.679  ops/s
ComparatorBenchmarks.put                                  java_bytewise_direct_no-reuse  thrpt   25   22148.316  1215.527  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   11311.126   820.602  ops/s
ComparatorBenchmarks.put  java_reverse_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   11421.311   807.210  ops/s
ComparatorBenchmarks.put        java_reverse_bytewise_non-direct_reused-64_thread-local  thrpt   25   11554.005   960.556  ops/s
ComparatorBenchmarks.put          java_reverse_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   22960.523  1673.421  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   18293.317  1434.601  ops/s
ComparatorBenchmarks.put            java_reverse_bytewise_direct_reused-64_thread-local  thrpt   25   24479.361  2157.306  ops/s
ComparatorBenchmarks.put                      java_reverse_bytewise_non-direct_no-reuse  thrpt   25    7942.286   626.170  ops/s
ComparatorBenchmarks.put                          java_reverse_bytewise_direct_no-reuse  thrpt   25   11781.955  1019.843  ops/s
```
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6252
Differential Revision: D19331064
Pulled By: pdillinger
fbshipit-source-id: 1f3b794e6a14162b2c3ffb943e8c0e64a0c03738/"
rocksdb,"Improve RocksJava Comparator (#6252)
Summary:
This is a redesign of the API for RocksJava comparators with the aim of improving performance. It also simplifies the class hierarchy.
**NOTE**: This breaks backwards compatibility for existing 3rd party Comparators implemented in Java... so we need to consider carefully which release branches this goes into.
Previously when implementing a comparator in Java the developer had a choice of subclassing either `DirectComparator` or `Comparator` which would use direct and non-direct byte-buffers resepectively (via `DirectSlice` and `Slice`).
In this redesign there we have eliminated the overhead of using the Java Slice classes, and just use `ByteBuffer`s. The `ComparatorOptions` supplied when constructing a Comparator allow you to choose between direct and non-direct byte buffers by setting `useDirect`.
In addition, the `ComparatorOptions` now allow you to choose whether a ByteBuffer is reused over multiple comparator calls, by setting `maxReusedBufferSize > 0`. When buffers are reused, ComparatorOptions provides a choice of mutex type by setting `useAdaptiveMutex`.
---
[JMH benchmarks previously indicated](https://github.com/facebook/rocksdb/pull/6241#issue-356398306) that the difference between C++ and Java for implementing a comparator was ~7x slowdown in Java.
With these changes, when reusing buffers and guarding access to them via mutexes the slowdown is approximately the same. However, these changes offer a new facility to not reuse mutextes, which reduces the slowdown to ~5.5x in Java. We also offer a `thread_local` mechanism for reusing buffers, which reduces slowdown to ~5.2x in Java (closes https://github.com/facebook/rocksdb/pull/4425).
These changes also form a good base for further optimisation work such as further JNI lookup caching, and JNI critical.
---
These numbers were captured without jemalloc. With jemalloc, the performance improves for all tests, and the Java slowdown reduces to between 4.8x and 5.x.
```
ComparatorBenchmarks.put                                                native_bytewise  thrpt   25  124483.795  2032.443  ops/s
ComparatorBenchmarks.put                                        native_reverse_bytewise  thrpt   25  114414.536  3486.156  ops/s
ComparatorBenchmarks.put              java_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   17228.250  1288.546  ops/s
ComparatorBenchmarks.put          java_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   16035.865  1248.099  ops/s
ComparatorBenchmarks.put                java_bytewise_non-direct_reused-64_thread-local  thrpt   25   21571.500   871.521  ops/s
ComparatorBenchmarks.put                  java_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   23613.773  8465.660  ops/s
ComparatorBenchmarks.put              java_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   16768.172  5618.489  ops/s
ComparatorBenchmarks.put                    java_bytewise_direct_reused-64_thread-local  thrpt   25   23921.164  8734.742  ops/s
ComparatorBenchmarks.put                              java_bytewise_non-direct_no-reuse  thrpt   25   17899.684   839.679  ops/s
ComparatorBenchmarks.put                                  java_bytewise_direct_no-reuse  thrpt   25   22148.316  1215.527  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_non-direct_reused-64_adaptive-mutex  thrpt   25   11311.126   820.602  ops/s
ComparatorBenchmarks.put  java_reverse_bytewise_non-direct_reused-64_non-adaptive-mutex  thrpt   25   11421.311   807.210  ops/s
ComparatorBenchmarks.put        java_reverse_bytewise_non-direct_reused-64_thread-local  thrpt   25   11554.005   960.556  ops/s
ComparatorBenchmarks.put          java_reverse_bytewise_direct_reused-64_adaptive-mutex  thrpt   25   22960.523  1673.421  ops/s
ComparatorBenchmarks.put      java_reverse_bytewise_direct_reused-64_non-adaptive-mutex  thrpt   25   18293.317  1434.601  ops/s
ComparatorBenchmarks.put            java_reverse_bytewise_direct_reused-64_thread-local  thrpt   25   24479.361  2157.306  ops/s
ComparatorBenchmarks.put                      java_reverse_bytewise_non-direct_no-reuse  thrpt   25    7942.286   626.170  ops/s
ComparatorBenchmarks.put                          java_reverse_bytewise_direct_no-reuse  thrpt   25   11781.955  1019.843  ops/s
```
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6252
Differential Revision: D19331064
Pulled By: pdillinger
fbshipit-source-id: 1f3b794e6a14162b2c3ffb943e8c0e64a0c03738/"
rocksdb,"wait pending memtable writes on file ingestion or compact range (#6113)
Summary:
**Summary:**
This PR fixes two unordered_write related issues:
- ingestion job may skip the necessary memtable flush https://github.com/facebook/rocksdb/issues/6026
- compact range may cause memtable is flushed before pending unordered write finished
1. `CompactRange` triggers memtable flush but doesn't wait for pending-writes
2.  there are some pending writes but memtable is already flushed
3.  the memtable related WAL is removed( note that the pending-writes were recorded in that WAL).
4.  pending-writes write to newer created memtable
5. there is a restart
6. missing the previous pending-writes because WAL is removed but they aren't included in SST.
**How to solve:**
- Wait pending memtable writes before ingestion job check memtable key range
- Wait pending memtable writes before flush memtable.
**Note that: `CompactRange` calls `RangesOverlapWithMemtables` too without waiting for pending waits, but I'm not sure whether it affects the correctness.**
**Test Plan:**
make check
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6113
Differential Revision: D18895674
Pulled By: maysamyabandeh
fbshipit-source-id: da22b4476fc7e06c176020e7cc171eb78189ecaf/Fix IngestExternalFile's bug with two_write_queue (#5976)
Summary:
When two_write_queue enable, IngestExternalFile performs EnterUnbatched on both write queues. SwitchMemtable also EnterUnbatched on 2nd write queue when this option is enabled. When the call stack includes IngestExternalFile -> FlushMemTable -> SwitchMemtable, this results into a deadlock.
The implemented solution is to pass on the existing writes_stopped argument in FlushMemTable to skip EnterUnbatched in SwitchMemtable.
Fixes https://github.com/facebook/rocksdb/issues/5974
Pull Request resolved: https://github.com/facebook/rocksdb/pull/5976
Differential Revision: D18535943
Pulled By: maysamyabandeh
fbshipit-source-id: a4f9d4964c10d4a7ca06b1e0102ca2ec395512bc/"
rocksdb,"Fix a data race related to memtable trimming (#6187)
Summary:
https://github.com/facebook/rocksdb/pull/6177 introduced a data race
involving `MemTableList::InstallNewVersion` and `MemTableList::NumFlushed`.
The patch fixes this by caching whether the current version has any
memtable history (i.e. flushed memtables that are kept around for
transaction conflict checking) in an `std::atomic<bool>` member called
`current_has_history_`, similarly to how `current_memory_usage_excluding_last_`
is handled.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6187
Test Plan:
```
make clean
COMPILE_WITH_TSAN=1 make db_test -j24
./db_test
```
Differential Revision: D19084059
Pulled By: ltamasi
fbshipit-source-id: 327a5af9700fb7102baea2cc8903c085f69543b9/Do not schedule memtable trimming if there is no history (#6177)
Summary:
We have observed an increase in CPU load caused by frequent calls to
`ColumnFamilyData::InstallSuperVersion` from `DBImpl::TrimMemtableHistory`
when using `max_write_buffer_size_to_maintain` to limit the amount of
memtable history maintained for transaction conflict checking. Part of the issue
is that trimming can potentially be scheduled even if there is no memtable
history. The patch adds a check that fixes this.
See also https://github.com/facebook/rocksdb/pull/6169.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6177
Test Plan:
Compared `perf` output for
```
./db_bench -benchmarks=randomtransaction -optimistic_transaction_db=1 -statistics -stats_interval_seconds=1 -duration=90 -num=500000 --max_write_buffer_size_to_maintain=16000000 --transaction_set_snapshot=1 --threads=32
```
before and after the change. There is a significant reduction for the call chain
`rocksdb::DBImpl::TrimMemtableHistory` -> `rocksdb::ColumnFamilyData::InstallSuperVersion` ->
`rocksdb::ThreadLocalPtr::StaticMeta::Scrape` even without https://github.com/facebook/rocksdb/pull/6169.
Differential Revision: D19057445
Pulled By: ltamasi
fbshipit-source-id: dff81882d7b280e17eda7d9b072a2d4882c50f79/"
rocksdb,"Add an option to prevent DB::Open() from querying sizes of all sst files (#6353)
Summary:
When paranoid_checks is on, DBImpl::CheckConsistency() iterates over all sst files and calls Env::GetFileSize() for each of them. As far as I could understand, this is pretty arbitrary and doesn't affect correctness - if filesystem doesn't corrupt fsynced files, the file sizes will always match; if it does, it may as well corrupt contents as well as sizes, and rocksdb doesn't check contents on open.
If there are thousands of sst files, getting all their sizes takes a while. If, on top of that, Env is overridden to use some remote storage instead of local filesystem, it can be *really* slow and overload the remote storage service. This PR adds an option to not do GetFileSize(); instead it does GetChildren() for parent directory to check that all the expected sst files are at least present, but doesn't check their sizes.
We can't just disable paranoid_checks instead because paranoid_checks do a few other important things: make the DB read-only on write errors, print error messages on read errors, etc.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6353
Test Plan: ran the added sanity check unit test. Will try it out in a LogDevice test cluster where the GetFileSize() calls are causing a lot of trouble.
Differential Revision: D19656425
Pulled By: al13n321
fbshipit-source-id: c2c421b367633033760d1f56747bad206d1fbf82/Shorten certain test names to avoid infra failure (#6352)
Summary:
Unit test names, together with other components,  are used to create log files
during some internal testing. Overly long names cause infra failure due to file
names being too long.
Look for internal tests.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6352
Differential Revision: D19649307
Pulled By: riversand963
fbshipit-source-id: 6f29de096e33c0eaa87d9c8702f810eda50059e7/Fix error message (#6264)
Summary:
Fix an error message when CURRENT is not found.
Test plan (dev server)
```
make check
```
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6264
Differential Revision: D19300699
Pulled By: riversand963
fbshipit-source-id: 303fa206386a125960ecca1dbdeff07422690caf/Fix & test rocksdb_filterpolicy_create_bloom_full (#6132)
Summary:
Add overrides needed in FilterPolicy wrapper to fix
rocksdb_filterpolicy_create_bloom_full (see issue https://github.com/facebook/rocksdb/issues/6129). Re-enabled
assertion in BloomFilterPolicy::CreateFilter that was being violated.
Expanded c_test to identify Bloom filter implementations by FP counts.
(Without the fix, updated test will trigger assertion and fail otherwise
without the assertion.)
Fixes https://github.com/facebook/rocksdb/issues/6129
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6132
Test Plan: updated c_test, also run under valgrind.
Differential Revision: D18864911
Pulled By: pdillinger
fbshipit-source-id: 08e81d7b5368b08e501cd402ef5583f2650c19fa/"
rocksdb,"Fixes for g++ 4.9.2 compatibility (#6053)
Summary:
Taken from merryChris in https://github.com/facebook/rocksdb/issues/6043
Stackoverflow ref on {{}} vs. {}:
https://stackoverflow.com/questions/26947704/implicit-conversion-failure-from-initializer-list
Note to reader: .clear() does not empty out an ostringstream, but .str("""")
suffices because we don't have to worry about clearing error flags.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6053
Test Plan: make check, manual run of filter_bench
Differential Revision: D18602259
Pulled By: pdillinger
fbshipit-source-id: f6190f83b8eab4e80e7c107348839edabe727841/"
rocksdb,"Work around weird unused errors with Mingw (#6075)
Summary:
From the reset of the code, it looks this this maybe can be unconditionally given the attribute? But I couldn't test with MSVC so I defensively put under CPP.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6075
Differential Revision: D18723749
fbshipit-source-id: 45fc8732c28dd29aab1644225d68f3c6f39bd69b/"
rocksdb,"JNI direct buffer support for basic operations (#2283)
Summary:
It is very useful to support direct ByteBuffers in Java. It allows to have zero memory copy and some serializers are using that directly so one do not need to create byte[] array for it.
This change also contains some fixes for Windows JNI build.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/2283
Differential Revision: D19834971
Pulled By: pdillinger
fbshipit-source-id: 44173aa02afc9836c5498c592fd1ea95b6086e8e/"
rocksdb,"Fix spelling: commited -> committed (#6481)
Summary:
In most places in the code the variable names are spelled correctly as
COMMITTED but in a couple places not. This fixes them and ensures the
variable is always called COMMITTED everywhere.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6481
Differential Revision: D20306776
Pulled By: pdillinger
fbshipit-source-id: b6c1bfe41db559b4bc6955c530934460c07f7022/"
rocksdb,"JNI direct buffer support for basic operations (#2283)
Summary:
It is very useful to support direct ByteBuffers in Java. It allows to have zero memory copy and some serializers are using that directly so one do not need to create byte[] array for it.
This change also contains some fixes for Windows JNI build.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/2283
Differential Revision: D19834971
Pulled By: pdillinger
fbshipit-source-id: 44173aa02afc9836c5498c592fd1ea95b6086e8e/"
rocksdb,"JNI direct buffer support for basic operations (#2283)
Summary:
It is very useful to support direct ByteBuffers in Java. It allows to have zero memory copy and some serializers are using that directly so one do not need to create byte[] array for it.
This change also contains some fixes for Windows JNI build.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/2283
Differential Revision: D19834971
Pulled By: pdillinger
fbshipit-source-id: 44173aa02afc9836c5498c592fd1ea95b6086e8e/"
rocksdb,"JNI direct buffer support for basic operations (#2283)
Summary:
It is very useful to support direct ByteBuffers in Java. It allows to have zero memory copy and some serializers are using that directly so one do not need to create byte[] array for it.
This change also contains some fixes for Windows JNI build.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/2283
Differential Revision: D19834971
Pulled By: pdillinger
fbshipit-source-id: 44173aa02afc9836c5498c592fd1ea95b6086e8e/"
rocksdb,"JNI direct buffer support for basic operations (#2283)
Summary:
It is very useful to support direct ByteBuffers in Java. It allows to have zero memory copy and some serializers are using that directly so one do not need to create byte[] array for it.
This change also contains some fixes for Windows JNI build.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/2283
Differential Revision: D19834971
Pulled By: pdillinger
fbshipit-source-id: 44173aa02afc9836c5498c592fd1ea95b6086e8e/"
rocksdb,"Add Java API for rocksdb::CancelAllBackgroundWork() (#6657)
Summary:
Adding a Java API for rocksdb::CancelAllBackgroundWork() so that the user can call this (when required) before closing the DB. This is to **prevent the crashes when manual compaction is running and the user decides to close the DB**.
Calling CancelAllBackgroundWork() seems to be the recommended way to make sure that it's safe to close the DB (according to RocksDB FAQ: https://github.com/facebook/rocksdb/wiki/RocksDB-FAQ#basic-readwrite).
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6657
Reviewed By: cheng-chang
Differential Revision: D20896395
Pulled By: pdillinger
fbshipit-source-id: 8a8208c10093db09bd35db9af362211897870d96/JNI direct buffer support for basic operations (#2283)
Summary:
It is very useful to support direct ByteBuffers in Java. It allows to have zero memory copy and some serializers are using that directly so one do not need to create byte[] array for it.
This change also contains some fixes for Windows JNI build.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/2283
Differential Revision: D19834971
Pulled By: pdillinger
fbshipit-source-id: 44173aa02afc9836c5498c592fd1ea95b6086e8e/"
rocksdb,"JNI direct buffer support for basic operations (#2283)
Summary:
It is very useful to support direct ByteBuffers in Java. It allows to have zero memory copy and some serializers are using that directly so one do not need to create byte[] array for it.
This change also contains some fixes for Windows JNI build.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/2283
Differential Revision: D19834971
Pulled By: pdillinger
fbshipit-source-id: 44173aa02afc9836c5498c592fd1ea95b6086e8e/"
rocksdb,"fix assert error while db.getDefaultColumnFamily().getDescriptor() (#6006)
Summary:
Threw assert error at assert(isOwningHandle()) in ColumnFamilyHandle.getDescriptor(),
because default CF don't own a handle, due to [RocksDB.getDefaultColumnFamily()](https://github.com/facebook/rocksdb/blob/3a408eeae95614150ac930fc7f244524ed8c6f1c/java/src/main/java/org/rocksdb/RocksDB.java#L3702) called cfHandle.disOwnNativeHandle().
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6006
Differential Revision: D19031448
fbshipit-source-id: 2420c45e835bda0e552e919b1b63708472b91538/"
rocksdb,"JNI direct buffer support for basic operations (#2283)
Summary:
It is very useful to support direct ByteBuffers in Java. It allows to have zero memory copy and some serializers are using that directly so one do not need to create byte[] array for it.
This change also contains some fixes for Windows JNI build.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/2283
Differential Revision: D19834971
Pulled By: pdillinger
fbshipit-source-id: 44173aa02afc9836c5498c592fd1ea95b6086e8e/"
rocksdb,"JNI direct buffer support for basic operations (#2283)
Summary:
It is very useful to support direct ByteBuffers in Java. It allows to have zero memory copy and some serializers are using that directly so one do not need to create byte[] array for it.
This change also contains some fixes for Windows JNI build.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/2283
Differential Revision: D19834971
Pulled By: pdillinger
fbshipit-source-id: 44173aa02afc9836c5498c592fd1ea95b6086e8e/"
rocksdb,"Fix spelling: commited -> committed (#6481)
Summary:
In most places in the code the variable names are spelled correctly as
COMMITTED but in a couple places not. This fixes them and ensures the
variable is always called COMMITTED everywhere.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6481
Differential Revision: D20306776
Pulled By: pdillinger
fbshipit-source-id: b6c1bfe41db559b4bc6955c530934460c07f7022/"
rocksdb,"Replace namespace name ""rocksdb"" with ROCKSDB_NAMESPACE (#6433)
Summary:
When dynamically linking two binaries together, different builds of RocksDB from two sources might cause errors. To provide a tool for user to solve the problem, the RocksDB namespace is changed to a flag which can be overridden in build time.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6433
Test Plan: Build release, all and jtest. Try to build with ROCKSDB_NAMESPACE with another flag.
Differential Revision: D19977691
fbshipit-source-id: aa7f2d0972e1c31d75339ac48478f34f6cfcfb3e/"
rocksdb,"Replace namespace name ""rocksdb"" with ROCKSDB_NAMESPACE (#6433)
Summary:
When dynamically linking two binaries together, different builds of RocksDB from two sources might cause errors. To provide a tool for user to solve the problem, the RocksDB namespace is changed to a flag which can be overridden in build time.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6433
Test Plan: Build release, all and jtest. Try to build with ROCKSDB_NAMESPACE with another flag.
Differential Revision: D19977691
fbshipit-source-id: aa7f2d0972e1c31d75339ac48478f34f6cfcfb3e/"
rocksdb,"Fix wrong key being read on ingested file with global seqno and delta encoding (#6669)
Summary:
On reading an ingested SST file, `DataBlockIter` will replace seqno encoded in a key with global seqno. However, if the original seqno was part of the prefix used for the next key, the global seqno is by mistake used as part of the prefix to construct the next key, causing wrong result being returned. Although at this point it is only software error while data in the file is not corrupted, the issue can further cause compaction output out of order and corrupted result when the ingested SST participated in compaction. Fixing the issue by save the actual seqno and restore it before the key being used as prefix to construct next key.
The unit test is by Little-Wallace from https://github.com/facebook/rocksdb/issues/6666. Fixing https://github.com/facebook/rocksdb/issues/6666.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6669
Test Plan:
New unit test
Signed-off-by: Yi Wu <yiwu@pingcap.com>
Reviewed By: cheng-chang
Differential Revision: D20931808
Pulled By: ajkr
fbshipit-source-id: f01959c35d6a493954dca981663766c7a5a9e8ab/fix some spelling typos (#6464)
Summary:
Found from Debian's ""Lintian"" program
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6464
Differential Revision: D20162862
Pulled By: zhichao-cao
fbshipit-source-id: 06941ee2437b038b2b8045becbe9d2c6fbff3e12/Replace namespace name ""rocksdb"" with ROCKSDB_NAMESPACE (#6433)
Summary:
When dynamically linking two binaries together, different builds of RocksDB from two sources might cause errors. To provide a tool for user to solve the problem, the RocksDB namespace is changed to a flag which can be overridden in build time.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6433
Test Plan: Build release, all and jtest. Try to build with ROCKSDB_NAMESPACE with another flag.
Differential Revision: D19977691
fbshipit-source-id: aa7f2d0972e1c31d75339ac48478f34f6cfcfb3e/"
rocksdb,"Replace namespace name ""rocksdb"" with ROCKSDB_NAMESPACE (#6433)
Summary:
When dynamically linking two binaries together, different builds of RocksDB from two sources might cause errors. To provide a tool for user to solve the problem, the RocksDB namespace is changed to a flag which can be overridden in build time.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6433
Test Plan: Build release, all and jtest. Try to build with ROCKSDB_NAMESPACE with another flag.
Differential Revision: D19977691
fbshipit-source-id: aa7f2d0972e1c31d75339ac48478f34f6cfcfb3e/WriteUnPrepared: Fix assertion during recovery (#6419)
Summary:
During recovery, multiple (un)prepared batches could exist in the same WAL record due to group commit. This breaks an assertion in `MemTableInserter::MarkBeginPrepare`.
To fix, reset unprepared_batch_ to false after `MarkEndPrepare`.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6419
Differential Revision: D19896148
Pulled By: lth
fbshipit-source-id: b1a32ef88f775a0881264a18bd1a4a5b8c85eee3/"
rocksdb,"Replace namespace name ""rocksdb"" with ROCKSDB_NAMESPACE (#6433)
Summary:
When dynamically linking two binaries together, different builds of RocksDB from two sources might cause errors. To provide a tool for user to solve the problem, the RocksDB namespace is changed to a flag which can be overridden in build time.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6433
Test Plan: Build release, all and jtest. Try to build with ROCKSDB_NAMESPACE with another flag.
Differential Revision: D19977691
fbshipit-source-id: aa7f2d0972e1c31d75339ac48478f34f6cfcfb3e/"
rocksdb,"Replace namespace name ""rocksdb"" with ROCKSDB_NAMESPACE (#6433)
Summary:
When dynamically linking two binaries together, different builds of RocksDB from two sources might cause errors. To provide a tool for user to solve the problem, the RocksDB namespace is changed to a flag which can be overridden in build time.
Pull Request resolved: https://github.com/facebook/rocksdb/pull/6433
Test Plan: Build release, all and jtest. Try to build with ROCKSDB_NAMESPACE with another flag.
Differential Revision: D19977691
fbshipit-source-id: aa7f2d0972e1c31d75339ac48478f34f6cfcfb3e/"
