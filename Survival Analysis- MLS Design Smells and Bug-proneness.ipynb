{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thsis notebook presents the data processing and survival analysis to investigate the impacts of multi-language design smells on software fault-proneness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " path_root = os.getcwd()\n",
    " data_path_root = Path(path_root).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_list = ['conscrypt', 'frostwire','javacpp','jna','OpenDDS','pljava','realm-java','rocksdb'] \n",
    "\n",
    "snapshot_0 ={'conscrypt':{'commit':'10da3cb', 'date': '2008-10-21'},\n",
    "             'frostwire':{'commit':'d922745', 'date': '2015-11-03'},\n",
    "             'javacpp': {'commit':'c3248e6', 'date': '2012-04-08'},\n",
    "             'jna': {'commit':'9813273', 'date': '1998-10-01'},\n",
    "             'OpenDDS': {'commit':'3b2e748', 'date': '2005-06-10'},\n",
    "             'pljava': {'commit':'92cd3f7', 'date': '2000-01-29'},\n",
    "             'realm-java': {'commit':'b03c621', 'date': '2012-04-20'},\n",
    "             'rocksdb': {'commit':'54f1fd7', 'date': '2011-03-02'}\n",
    "            }\n",
    "\n",
    "snapshot_last ={'conscrypt':{'commit':'b1220d7', 'date': '2020-01-27 00:00:01'},\n",
    "             'frostwire':{'commit':'16aca17', 'date': '2019-11-20 00:00:01'},\n",
    "             'javacpp': {'commit':'', 'date': '2019-06-12 00:00:01'},\n",
    "             'jna': {'commit':'424fc00', 'date': '2020-02-10 00:00:01'},\n",
    "             'OpenDDS': {'commit':'e3a2193', 'date': '2020-02-04 00:00:01'},\n",
    "             'pljava': {'commit':'485cb54', 'date': '2020-01-11 00:00:01'},\n",
    "             'realm-java': {'commit':'b96e28a', 'date': '2019-11-01 00:00:01'},\n",
    "             'rocksdb': {'commit':'debc4ef', 'date': '2020-02-10 00:00:01'}\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-27 00:00:01\n"
     ]
    }
   ],
   "source": [
    "sys = 'conscrypt'\n",
    "print(snapshot_last[sys]['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_renamed_n_removed_date(rdates):\n",
    "    formatted_list = ''\n",
    "    date_list = rdates.split('/')\n",
    "    for dt in date_list:\n",
    "        if len(dt)>0:\n",
    "           formatted_list = formatted_list + dt[:19]+'/'\n",
    "    formatted_list = formatted_list[:-1]\n",
    "    return formatted_list\n",
    "\n",
    "def reformat_inducing_n_fixing_date(ind_dates):\n",
    "    formatted_list = ''\n",
    "    date_list = ind_dates.split('/')\n",
    "    for dt in date_list:\n",
    "        if len(dt)>0:\n",
    "           formatted_list = formatted_list + dt.replace('T',' ')[:19]+'/'\n",
    "    formatted_list = formatted_list[:-1]\n",
    "    return formatted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_diff_in_hours(row):\n",
    "    date1 = row.CreatedAt\n",
    "    sys = row.System\n",
    "#     print(sys)\n",
    "    date2=''\n",
    "    if str(row.InducingDates)=='nan':\n",
    "        date2=snapshot_last[sys]['date']\n",
    "    else:\n",
    "        dates2 = str(row.InducingDates).split('/')\n",
    "        date2= dates2[len(dates2)-1] # taking the date of the earliest bug\n",
    "    if len(date2)>0:  \n",
    "        date1 = datetime.datetime.strptime(date1[:19], '%Y-%m-%d %H:%M:%S')\n",
    "        date2 = datetime.datetime.strptime(date2[:19], '%Y-%m-%d %H:%M:%S')\n",
    "        date_diff = (date2 - date1)\n",
    "        days = str(date_diff).split(',')\n",
    "        day = 0\n",
    "        if len(days)>1:\n",
    "            day= int(days[0].split(' ')[0])\n",
    "            hour = int(days[1].split(':')[0])\n",
    "        else:\n",
    "            hour = int(days[0].split(':')[0]) \n",
    "        \n",
    "        diff_hour = day*24+hour\n",
    "    if diff_hour <0 :\n",
    "        print('System: {} Hour: {} Creation: {} inducing:{}'.format(row.System, diff_hour, date1, date2))\n",
    "    return diff_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "smell_list = ['ExcessiveInterlangCommunication', 'Toomuchclustring',\n",
    "       'ToomuchScattering', 'UnusedMethodDeclaration',\n",
    "       'UnusedMethodImplementation', 'UnusedParameter',\n",
    "       'AssumingSafeReturnValue', 'ExcessiveObjects', 'NotHandlingExceptions',\n",
    "       'NotCachingObjects', 'NotSecuringLibraries', 'HardCodingLibraries',\n",
    "       'NotUsingRelativePath', 'MemoryManagementMismatch',\n",
    "       'LocalReferencesAbuse']\n",
    "\n",
    "selected_columns = ['ExcessiveInterlangCommunication', 'Toomuchclustring',\n",
    "       'ToomuchScattering', 'UnusedMethodDeclaration',\n",
    "       'UnusedMethodImplementation', 'UnusedParameter',\n",
    "       'AssumingSafeReturnValue', 'ExcessiveObjects', 'NotHandlingExceptions',\n",
    "       'NotCachingObjects', 'NotSecuringLibraries', 'HardCodingLibraries',\n",
    "       'NotUsingRelativePath', 'MemoryManagementMismatch',\n",
    "       'LocalReferencesAbuse', \n",
    "       'inducingflag','Smelly','SurvivalTime','LOC','prev_fixing']\n",
    "\n",
    "selected_columns1 = ['ExcessiveInterlangCommunication', 'Toomuchclustring',\n",
    "       'UnusedMethodDeclaration',\n",
    "       'UnusedParameter',\n",
    "       'AssumingSafeReturnValue', 'NotHandlingExceptions',\n",
    "       'NotSecuringLibraries', \n",
    "       'NotUsingRelativePath', 'MemoryManagementMismatch',\n",
    "       'LocalReferencesAbuse', \n",
    "       'inducingflag','Smelly','SurvivalTime','LOC','prev_fixing']\n",
    "\n",
    "\n",
    "selected_columns2 = ['ExcessiveInterlangCommunication', \n",
    "       'UnusedParameter',\n",
    "       'AssumingSafeReturnValue', 'NotHandlingExceptions',\n",
    "       'NotSecuringLibraries', \n",
    "       'NotUsingRelativePath', 'MemoryManagementMismatch',\n",
    "       'LocalReferencesAbuse', \n",
    "       'LOC','prev_fixing']\n",
    "\n",
    "selected_columns3 = ['LOC','prev_fixing']\n",
    "# ['ToomuchScattering', 'UnusedMethodImplementation', 'ExcessiveObjects', 'NotCachingObjects', 'HardCodingLibraries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "# print(reformat_renamed_n_removed_date('/2010-05-03 12:57:15-07:00'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(reformat_inducing_n_fixing_date('2009-04-03T06:50:03Z/2009-03-04T03:28:47Z/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_name = 'OpenDDS'\n",
    "path_root = os.getcwd()\n",
    "data_path = os.path.join(data_path_root, 'data', 'survival', sys_name + '_merged2.csv')\n",
    "cleaned_data_path = os.path.join(data_path_root, 'data', 'survival','cleaned', sys_name + '_merged2_cleaned.csv')\n",
    "data_df = load_csv(data_path)\n",
    "\n",
    "data_df['System'] = sys_name\n",
    "\n",
    "#Correct Release Date\n",
    "data_df['Release'] = data_df['Release'].apply(lambda x: str(x).replace('T',' ')[:19])\n",
    "\n",
    "#Reformat Creat Date\n",
    "data_df['CreatedAt'] = data_df['CreatedAt'].apply(lambda x: str(x)[:19])\n",
    "\n",
    "#Reformat Renaming and Removed Date(s)\n",
    "data_df['RenamedAt'] = data_df['RenamedAt'].apply(lambda x: reformat_renamed_n_removed_date(str(x)))\n",
    "data_df['RemovedDate'] = data_df['RemovedDate'].apply(lambda x: reformat_renamed_n_removed_date(str(x)))\n",
    "\n",
    "#Reformat Inducing and Fixing Date(s)\n",
    "data_df['InducingDates'] = data_df['InducingDates'].apply(lambda x: reformat_inducing_n_fixing_date(str(x)))\n",
    "data_df['FixingDates'] = data_df['FixingDates'].apply(lambda x: reformat_inducing_n_fixing_date(str(x)))\n",
    "\n",
    "if sys_name == 'conscrypt':\n",
    "    data_df.loc[data_df['Version']=='conscrypt_0','Release']= '2008-10-21 00:00:00'\n",
    "\n",
    "if sys_name == 'jna':\n",
    "    data_df.loc[data_df['Version']=='jna_6','Release']= '2002-12-06 01:28:03'\n",
    "    data_df.loc[data_df['Version']=='jna_7','Release']= '2003-11-04 06:09:08'\n",
    "    data_df.loc[data_df['Version']=='jna_8','Release']= '2004-05-30 01:51:57'\n",
    "    data_df.loc[data_df['Version']=='jna_9','Release']= '2006-06-04 23:22:24'\n",
    "\n",
    "data_df['SurvivalTime'] = data_df.apply(date_diff_in_hours, axis=1)\n",
    "data_df = data_df[data_df.SurvivalTime >= 0]    \n",
    "data_df.to_csv(cleaned_data_path, index = False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['SurvivalTime'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add flags for smells\n",
    "path_root = os.getcwd()\n",
    "for sys in sys_list:   \n",
    "    data_path = os.path.join(data_path_root, 'data', 'survival', 'cleaned', sys + '_merged2_cleaned.csv')\n",
    "    data_path1 = os.path.join(data_path_root, 'data', 'survival', 'cleaned', sys + '_merged2_cleaned_time.csv')\n",
    "    data_df = load_csv(data_path)\n",
    "    for sml in smell_list:\n",
    "        col_name = 'Smelly_'+sml\n",
    "        data_df[col_name]= data_df[sml].apply(lambda x: 1 if int(x)>0 else 0)\n",
    "    data_df.to_csv(data_path1, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\C5265284\\AppData\\Local\\Continuum\\anaconda3\\envs\\conda37TF2GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3254: DtypeWarning: Columns (4,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Id_db', 'File', 'System', 'Version', 'Package', 'Release', 'Class',\n",
       "       'ExcessiveInterlangCommunication', 'Toomuchclustring',\n",
       "       'ToomuchScattering', 'UnusedMethodDeclaration',\n",
       "       'UnusedMethodImplementation', 'UnusedParameter',\n",
       "       'AssumingSafeReturnValue', 'ExcessiveObjects', 'NotHandlingExceptions',\n",
       "       'NotCachingObjects', 'NotSecuringLibraries', 'HardCodingLibraries',\n",
       "       'NotUsingRelativePath', 'MemoryManagementMismatch',\n",
       "       'LocalReferencesAbuse', 'FilePath', 'inducing', 'fixing',\n",
       "       'inducingflag', 'fixingFlag', 'Smelly', 'LOC', 'Time', 'CLOC',\n",
       "       'LOC_inducing', 'prev_inducing', 'prev_fixing', 'cum_inducing',\n",
       "       'cum_fixing', 'Message_induce', 'Message_fix', 'dev-inducing',\n",
       "       'dev-fixing', 'CreatedAt', 'RenamedFrom', 'RenamedTo', 'RenamedAt',\n",
       "       'RemovedDate', 'InducingDates', 'FixingDates', 'status', 'SurvivalTime',\n",
       "       'Smelly_ExcessiveInterlangCommunication', 'Smelly_Toomuchclustring',\n",
       "       'Smelly_ToomuchScattering', 'Smelly_UnusedMethodDeclaration',\n",
       "       'Smelly_UnusedMethodImplementation', 'Smelly_UnusedParameter',\n",
       "       'Smelly_AssumingSafeReturnValue', 'Smelly_ExcessiveObjects',\n",
       "       'Smelly_NotHandlingExceptions', 'Smelly_NotCachingObjects',\n",
       "       'Smelly_NotSecuringLibraries', 'Smelly_HardCodingLibraries',\n",
       "       'Smelly_NotUsingRelativePath', 'Smelly_MemoryManagementMismatch',\n",
       "       'Smelly_LocalReferencesAbuse'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys_name = 'OpenDDS'\n",
    "cleaned_data_path = os.path.join(data_path_root, 'data', 'survival','cleaned', sys_name + '_merged2_cleaned_time.csv')\n",
    "data_cl = load_csv(cleaned_data_path)\n",
    "data_cl.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_path = os.path.join(data_path_root, 'data', 'survival','cleaned', sys_name + '_merged2_cleaned.csv')\n",
    "data_cl = load_csv(cleaned_data_path)\n",
    "data_cl['SurvivalTime'] = data_cl.apply(date_diff_in_hours, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all smell data\n",
    "cleaned_data_path_merged = os.path.join(data_path_root, 'data', 'survival','cleaned', 'merged_cleaned_smell_data_time.csv')\n",
    "merged_df = pd.DataFrame()\n",
    "for sys_name in sys_list:\n",
    "    print('Merging smell data from:{}'.format(sys_name))\n",
    "    cleaned_data_path = os.path.join(data_path_root, 'data', 'survival','cleaned', sys_name + '_merged2_cleaned.csv')\n",
    "    data_cl = list(load_csv(cleaned_data_path))\n",
    "    rel_list =data_cl['Version']\n",
    "    data_cl['SurvivalTime'] = data_cl.apply(date_diff_in_hours, axis=1)\n",
    "    data_cl = data_cl[data_cl.SurvivalTime >= 0]\n",
    "    cleaned_data_path_time = os.path.join(data_path_root, 'data', 'survival','cleaned', sys_name + '_merged2_cleaned_time.csv')\n",
    "    data_cl.to_csv(cleaned_data_path_time, index = False)\n",
    "    merged_df = pd.concat([merged_df, data_cl])\n",
    "merged_df.to_csv(cleaned_data_path_merged, index=False)\n",
    "print('Merged data saved to: {}'.format(cleaned_data_path_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleand_file = os.path.join(data_path_root, 'data', 'survival','cleaned', 'merged_cleaned_smell_data_s_time2.csv')\n",
    "analysis_df['SurvivalTime'] = analysis_df.apply(date_diff_in_hours, axis=1)\n",
    "cleaned_data_path_merged_time = os.path.join(data_path_root, 'data', 'survival','cleaned', 'merged_cleaned_smell_data_s_time2.csv')\n",
    "analysis_df.to_csv(cleaned_data_path_merged_time,index =False)\n",
    "analysis_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = merged_df.query ('System==\\\"conscrypt\\\"')\n",
    "# analysis_df = analysis_df[analysis_df['Release']=='']\n",
    "# analysis_df = analysis_df[analysis_df['Release'].isna()]\n",
    "analysis_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis_df = merged_df\n",
    "analysis_df['SurvivalTime'] = analysis_df.apply(date_diff_in_hours, axis=1)\n",
    "cleaned_data_path_merged_time = os.path.join(data_path_root, 'data', 'survival','cleaned', 'merged_cleaned_smell_data_s_time2.csv')\n",
    "analysis_df.to_csv(cleaned_data_path_merged_time,index =False)\n",
    "analysis_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['SurvivalTime'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['SurvivalTime'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_name = 'conscrypt'\n",
    "analysis_df_sys = analysis_df.query('System==\\\"'+ sys_name+'\\\"')\n",
    "analysis_df_sys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df_sys.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df_sys= analysis_df_sys[selected_columns3]\n",
    "# analysis_df_sys= analysis_df_sys.query('inducingflag==1')\n",
    "print(analysis_df_sys.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = analysis_df_sys[selected_columns2]\n",
    "plt.figure(figsize=(16, 16))\n",
    "sb.heatmap(corr_data.corr(method='spearman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_columns = selected_columns3.extend(['inducingflag','Smelly','SurvivalTime'])\n",
    "print(selected_columns3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis_df_sys = analysis_df_sys[sa_columns] \n",
    "analysis_df_sys.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys_list = ['conscrypt', 'frostwire','javacpp','jna','OpenDDS','pljava','realm-java','rocksdb'] \n",
    "sys = 'rocksdb'\n",
    "data_path1 = os.path.join(data_path_root, 'data', 'survival', 'cleaned', sys + '_merged2_cleaned_time.csv')\n",
    "analysis_df_sys= load_csv(data_path1)\n",
    "# analysis_df_sys= analysis_df_sys.query('inducingflag==1')\n",
    "analysis_df_sys.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df_sys['SurvivalTime'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmf = KaplanMeierFitter() ## instantiate the class to create an object\n",
    "\n",
    "T = analysis_df_sys['SurvivalTime']     ## time to event\n",
    "E = analysis_df_sys['inducingflag'] \n",
    "\n",
    "groups = analysis_df_sys['Smelly']   \n",
    "i1 = (groups == 1)      ## group i1 , smelly\n",
    "i2 = (groups == 0)     ## group i2 , non-smelly\n",
    "\n",
    "\n",
    "## fit the model for smelly group\n",
    "kmf.fit(T[i1], E[i1], label='Smelly')\n",
    "a1 = kmf.plot()\n",
    "\n",
    "## fit the model for non-smelly group\n",
    "kmf.fit(T[i2], E[i2], label='Non-smelly')\n",
    "kmf.plot(ax=a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df_sys= analysis_df_[selected_columns1]\n",
    "analysis_df_sys= analysis_df_sys.query('inducingflag==1')\n",
    "\n",
    "kmf = KaplanMeierFitter() ## instantiate the class to create an object\n",
    "\n",
    "T = analysis_df_sys['SurvivalTime']     ## time to event\n",
    "E = analysis_df_sys['inducingflag'] \n",
    "\n",
    "groups = analysis_df_sys['Smelly']   \n",
    "i1 = (groups == 1)      ## group i1 , smelly\n",
    "i2 = (groups == 0)     ## group i2 , non-smelly\n",
    "\n",
    "\n",
    "## fit the model for smelly group\n",
    "kmf.fit(T[i1], E[i1], label='Smelly')\n",
    "a1 = kmf.plot()\n",
    "\n",
    "## fit the model for non-smelly group\n",
    "kmf.fit(T[i2], E[i2], label='Non-smelly')\n",
    "kmf.plot(ax=a1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df_sys= analysis_df_sys[selected_columns1]\n",
    "# analysis_df_sys= analysis_df_sys.query('inducingflag==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df_sys.head() ## have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "# Using Cox Proportional Hazards model\n",
    "cph = CoxPHFitter()   ## Instantiate the class to create a cph object\n",
    "cph.fit(analysis_df_sys, 'SurvivalTime', event_col='inducingflag',show_progress=True)   ## Fit the data to train the model\n",
    "cph.print_summary()    ## HAve a look at the significance of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decimal\n",
    "\n",
    "# create a new context for this task\n",
    "ctx = decimal.Context()\n",
    "\n",
    "# 20 digits should be enough for everyone :D\n",
    "ctx.prec = 10\n",
    "\n",
    "def float_to_str(f):\n",
    "    \"\"\"\n",
    "    Convert the given float to a string,\n",
    "    without resorting to scientific notation\n",
    "    \"\"\"\n",
    "    d1 = ctx.create_decimal(repr(f))\n",
    "    return format(d1, 'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_name = sys_list[7]\n",
    "#     path_root = os.getcwd()\n",
    "data_path = os.path.join(data_path_root, 'data', 'survival','cleaned', sys_name + '_merged2_cleaned_time.csv')\n",
    "fig_path = os.path.join(data_path_root, 'results', 'figures', sys_name + '_survival_allsmell.pdf')\n",
    "data_df = load_csv(data_path)\n",
    "\n",
    "analysis_df = data_df\n",
    "analysis_df= analysis_df[selected_columns]\n",
    "# analysis_df = analysis_df.query('inducingflag==1')\n",
    "\n",
    "kmf1 = KaplanMeierFitter() ## instantiate the class to create an object\n",
    "\n",
    "T = analysis_df['SurvivalTime']     ## time to event\n",
    "E = analysis_df['inducingflag'] \n",
    "\n",
    "groups = analysis_df['Smelly']   \n",
    "i1 = (groups == 1)      ## group i1 , smelly\n",
    "i2 = (groups == 0)     ## group i2 , non-smelly\n",
    "\n",
    "\n",
    "## fit the model for smelly group\n",
    "kmf1.fit(T[i1], E[i1], label='Smelly')\n",
    "a1 = kmf1.plot()\n",
    "\n",
    "## fit the model for non-smelly group\n",
    "kmf1.fit(T[i2], E[i2], label='Non-smelly')\n",
    "plt = kmf1.plot(ax=a1)\n",
    "\n",
    "plt.set_xlabel(\"Time (in Hours)\")\n",
    "plt.set_ylabel(\"Survival Probability\")\n",
    "\n",
    "fig= plt.get_figure()\n",
    "\n",
    "fig.savefig(fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_name = sys_list[0]\n",
    "#     path_root = os.getcwd()\n",
    "data_path = os.path.join(data_path_root, 'data', 'survival','cleaned',  sys_name + '_merged2_cleaned_time.csv')\n",
    "for sml in smell_list:\n",
    "    sml1 = smell_list[0]\n",
    "    sml2 = smell_list[1]\n",
    "    fig_path = os.path.join(data_path_root, 'results', 'figures', sys_name, sys_name + '_survival_'+ sml +'.pdf')\n",
    "    data_df = load_csv(data_path)\n",
    "    smell_type_flag1 = 'Smelly_'+ sml1\n",
    "    smell_type_flag2 = 'Smelly_'+ sml2\n",
    "\n",
    "    analysis_df = data_df\n",
    "    print(analysis_df.shape)\n",
    "    #   analysis_df= analysis_df[selected_columns]\n",
    "    # analysis_df = analysis_df.query(smell_type_flag+'==1')\n",
    "\n",
    "    print(analysis_df.shape)\n",
    "\n",
    "    kmf1 = KaplanMeierFitter() ## instantiate the class to create an object\n",
    "\n",
    "    T = analysis_df['SurvivalTime']     ## time to event\n",
    "    E = analysis_df['inducingflag'] \n",
    "\n",
    "    groups = analysis_df[smell_type_flag1]   \n",
    "    i1 = (groups == 1)      ## group i1 , smelly\n",
    "    i2 = (groups == 0)     ## group i2 , non-smelly\n",
    "\n",
    "\n",
    "    # ## fit the model for smelly group\n",
    "    kmf1.fit(T[i1], E[i1], label=sml1)\n",
    "    a1 = kmf1.plot()\n",
    "\n",
    "    groups = analysis_df[smell_type_flag2]   \n",
    "    i1 = (groups == 1)      ## group i1 , smelly\n",
    "    i2 = (groups == 0)     ## group i2 , non-smelly\n",
    "    ## fit the model for non-smelly group\n",
    "    kmf1.fit(T[i1], E[i1], label = sml2)\n",
    "    plt = kmf1.plot(ax= a1)\n",
    "\n",
    "    plt.set_xlabel(\"Time (in Hours)\")\n",
    "    plt.set_ylabel(\"Survival Probability\")\n",
    "\n",
    "    fig= plt.get_figure()\n",
    "\n",
    "    # fig.savefig(fig_path)\n",
    "    # fig.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smelly_ExcessiveInterlangCommunication : 254\n",
      "Smelly_Toomuchclustring : 67\n",
      "Smelly_ToomuchScattering : 342\n",
      "Smelly_UnusedMethodDeclaration : 123\n",
      "Smelly_UnusedMethodImplementation : 0\n",
      "Smelly_UnusedParameter : 9\n",
      "Smelly_AssumingSafeReturnValue : 0\n",
      "Smelly_ExcessiveObjects : 0\n",
      "Smelly_NotHandlingExceptions : 0\n",
      "Smelly_NotCachingObjects : 0\n",
      "Smelly_NotSecuringLibraries : 30\n",
      "Smelly_HardCodingLibraries : 7\n",
      "Smelly_NotUsingRelativePath : 0\n",
      "Smelly_MemoryManagementMismatch : 0\n",
      "Smelly_LocalReferencesAbuse : 0\n"
     ]
    }
   ],
   "source": [
    "# print(smell_list)\n",
    "sys_name = sys_list[2]\n",
    "#     path_root = os.getcwd()\n",
    "data_path = os.path.join(data_path_root, 'data', 'survival','cleaned', sys_name + '_merged2_cleaned_time.csv')\n",
    "data_path_flag = os.path.join(data_path_root, 'data', 'survival','cleaned', sys_name + '_merged2_cleaned_flag_count.csv')\n",
    "data_df = load_csv(data_path)\n",
    "sm_lst =[]\n",
    "data_count =[]\n",
    "for sm in smell_list:\n",
    "    col = 'Smelly_' + str(sm)\n",
    "    sm_lst.append(col)\n",
    "    data_count.append(data_df[col].sum())    \n",
    "    print('{} : {}'.format(col, data_df[col].sum()))\n",
    "\n",
    "count_df = pd.DataFrame(data = np.reshape(data_count,(1,15)) , columns = sm_lst)\n",
    "count_df.to_csv(data_path_flag, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smelly_ExcessiveInterlangCommunication : 287\n",
      "Smelly_Toomuchclustring : 480\n",
      "Smelly_ToomuchScattering : 798\n",
      "Smelly_UnusedMethodDeclaration : 138\n",
      "Smelly_UnusedMethodImplementation : 0\n",
      "Smelly_UnusedParameter : 1485\n",
      "Smelly_AssumingSafeReturnValue : 63\n",
      "Smelly_ExcessiveObjects : 0\n",
      "Smelly_NotHandlingExceptions : 63\n",
      "Smelly_NotCachingObjects : 0\n",
      "Smelly_NotSecuringLibraries : 68\n",
      "Smelly_HardCodingLibraries : 21\n",
      "Smelly_NotUsingRelativePath : 27\n",
      "Smelly_MemoryManagementMismatch : 28\n",
      "Smelly_LocalReferencesAbuse : 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sys_name = sys_list[7]\n",
    "#     path_root = os.getcwd()\n",
    "data_path = os.path.join(data_path_root, 'data', 'survival','cleaned',  sys_name + '_merged2_cleaned_time.csv')\n",
    "data_df = load_csv(data_path)\n",
    "data_count_path = os.path.join(data_path_root, 'data', 'survival','cleaned',  sys_name + '_merged2_cleaned_flag_count.csv')\n",
    "count_df = load_csv(data_count_path)\n",
    "\n",
    "for sml in smell_list:\n",
    "    fig_path = os.path.join(data_path_root, 'results', 'figures', sys_name, sys_name + '_survival_'+ sml +'.pdf')\n",
    "      \n",
    "    smell_type_flag = 'Smelly_'+ sml\n",
    "   \n",
    "    smelly_count = count_df[smell_type_flag].max()\n",
    "    print('{} : {}'.format(smell_type_flag,smelly_count))\n",
    "        \n",
    "    if smelly_count > 0 :\n",
    "        analysis_df = data_df\n",
    "    #     print(analysis_df.shape)\n",
    "        #   analysis_df= analysis_df[selected_columns]\n",
    "        # analysis_df = analysis_df.query(smell_type_flag+'==1')\n",
    "\n",
    "    #     print(analysis_df.shape)\n",
    "\n",
    "        kmf1 = KaplanMeierFitter() ## instantiate the class to create an object\n",
    "\n",
    "        T = analysis_df['SurvivalTime']     ## time to event\n",
    "        E = analysis_df['inducingflag'] \n",
    "\n",
    "        groups = analysis_df[smell_type_flag]   \n",
    "        i1 = (groups == 1)      ## group i1 , smelly\n",
    "        i2 = (groups == 0)     ## group i2 , non-smelly\n",
    "\n",
    "\n",
    "        # ## fit the model for smelly group\n",
    "        kmf1.fit(T[i1], E[i1], label= 'Smelly')\n",
    "        a1 = kmf1.plot()\n",
    "\n",
    "        kmf1.fit(T[i2], E[i2], label = 'Non-smelly')\n",
    "        plt = kmf1.plot(ax= a1)\n",
    "\n",
    "        plt.set_xlabel(\"Time (in Hours)\")\n",
    "        plt.set_ylabel(\"Survival Probability\")\n",
    "\n",
    "        fig= plt.get_figure()\n",
    "\n",
    "        fig.savefig(fig_path)\n",
    "        fig.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols = ['ExcessiveInterlangCommunication', 'Toomuchclustring',\n",
    "       'ToomuchScattering', 'UnusedMethodDeclaration',\n",
    "       'UnusedMethodImplementation', 'UnusedParameter',\n",
    "       'AssumingSafeReturnValue', 'ExcessiveObjects', 'NotHandlingExceptions',\n",
    "       'NotCachingObjects', 'NotSecuringLibraries', 'HardCodingLibraries',\n",
    "       'NotUsingRelativePath', 'MemoryManagementMismatch',\n",
    "       'LocalReferencesAbuse', \n",
    "       'inducingflag', 'Smelly', 'LOC', \n",
    "       'prev_fixing', 'SurvivalTime'\n",
    "       ]\n",
    "\n",
    "smell_flags = ['Smelly_ExcessiveInterlangCommunication', 'Smelly_Toomuchclustring',\n",
    "       'Smelly_ToomuchScattering', 'Smelly_UnusedMethodDeclaration',\n",
    "       'Smelly_UnusedMethodImplementation', 'Smelly_UnusedParameter',\n",
    "       'Smelly_AssumingSafeReturnValue', 'Smelly_ExcessiveObjects',\n",
    "       'Smelly_NotHandlingExceptions', 'Smelly_NotCachingObjects',\n",
    "       'Smelly_NotSecuringLibraries', 'Smelly_HardCodingLibraries',\n",
    "       'Smelly_NotUsingRelativePath', 'Smelly_MemoryManagementMismatch',\n",
    "       'Smelly_LocalReferencesAbuse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_name = sys_list[0]\n",
    "#     path_root = os.getcwd()\n",
    "data_path = os.path.join(data_path_root, 'data', 'survival','cleaned', sys_name + '_merged2_cleaned_time.csv')\n",
    "data_path_exp = os.path.join(data_path_root, 'data', 'survival','cleaned', sys_name + '_merged2_cleaned_time_filtered.csv')\n",
    "fig_path = os.path.join(data_path_root, 'results', 'figures', sys_name + '_survival_allsmell_new.pdf')\n",
    "data_df = load_csv(data_path)\n",
    "\n",
    "analysis_df = data_df\n",
    "analysis_df= analysis_df[data_cols]\n",
    "analysis_df.to_csv(data_path_exp, index = False)\n",
    "# analysis_df = analysis_df.query('inducingflag==1')\n",
    "\n",
    "kmf1 = KaplanMeierFitter() ## instantiate the class to create an object\n",
    "\n",
    "T = analysis_df['SurvivalTime']     ## time to event\n",
    "E = analysis_df['inducingflag'] \n",
    "\n",
    "groups = analysis_df['Smelly']   \n",
    "i1 = (groups == 1)      ## group i1 , smelly\n",
    "i2 = (groups == 0)     ## group i2 , non-smelly\n",
    "\n",
    "\n",
    "## fit the model for smelly group\n",
    "kmf1.fit(T[i1], E[i1], label='Smelly')\n",
    "a1 = kmf1.plot()\n",
    "\n",
    "## fit the model for non-smelly group\n",
    "kmf1.fit(T[i2], E[i2], label='Non-smelly')\n",
    "plt = kmf1.plot(ax=a1)\n",
    "\n",
    "plt.set_xlabel(\"Time (in Hours)\")\n",
    "plt.set_ylabel(\"Survival Probability\")\n",
    "\n",
    "fig= plt.get_figure()\n",
    "\n",
    "fig.savefig(fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16, 16))\n",
    "sb.heatmap(data_df[selected_columns].corr(method='spearman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys_list = ['rocksdb', 'pljava', 'realm-java', 'jpype', 'javacpp', 'zstd-jni', 'java-smt','vlc-android', 'conscrypt'] #'vlc-android', , 'conscrypt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_name = 'conscrypt'\n",
    "path_root = os.getcwd()\n",
    "data_path = os.path.join(data_path_root, 'data', 'survival', sys_name + '_merged2.csv')\n",
    "data = load_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_inducing_commits(rcommit):\n",
    "    formatted_list = ''\n",
    "    commit_list = rcommit.split('/')\n",
    "    for c in commit_list:\n",
    "        if len(c)>0:\n",
    "           formatted_list = formatted_list + c[:7]+'/'\n",
    "    formatted_list = formatted_list[:-1]\n",
    "    return formatted_list\n",
    "\n",
    "def reformat_inducing_n_fixing_date(ind_dates):\n",
    "    formatted_list = ''\n",
    "    date_list = ind_dates.split('/')\n",
    "    for dt in date_list:\n",
    "        if len(dt)>0:\n",
    "           formatted_list = formatted_list + dt.replace('T',' ')[:19]+'/'\n",
    "    formatted_list = formatted_list[:-1]\n",
    "    return formatted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bug data cleaning\n",
    "sys_name = 'conscrypt'\n",
    "data_path = os.path.join(data_path_root, 'data', 'survival','bug-data', sys_name + '_bug.csv')\n",
    "data_df = load_csv(data_path)\n",
    "data_df['Project'] = sys_name\n",
    "data_df=data_df.drop(0)\n",
    "data_df=data_df.reindex()\n",
    "\n",
    "\n",
    "#Correct Fixing commit\n",
    "data_df['BugFixing'] = data_df['BugFixing'].apply(lambda x: str(x)[:7])\n",
    "\n",
    "\n",
    "#Reformat Fixing Dates\n",
    "data_df['FixingDates'] = data_df['FixingDates'].apply(lambda x: str(x)[:19])\n",
    "\n",
    "\n",
    "#Reformat inducing Commits\n",
    "data_df['BugInducing'] = data_df['BugInducing'].apply(lambda x: reformat_inducing_commits(str(x)))\n",
    "\n",
    "#Reformat inducing Commits\n",
    "data_df['InducingDate'] = data_df['InducingDate'].apply(lambda x: reformat_inducing_n_fixing_date(str(x)))\n",
    "\n",
    "data_df.head(50)\n",
    "\n",
    "\n",
    "# #Reformat Renaming and Removed Date(s)\n",
    "# data_df['RenamedAt'] = data_df['RenamedAt'].apply(lambda x: reformat_renamed_n_removed_date(str(x)))\n",
    "# data_df['RemovedDate'] = data_df['RemovedDate'].apply(lambda x: reformat_renamed_n_removed_date(str(x)))\n",
    "\n",
    "# #Reformat Inducing and Fixing Date(s)\n",
    "# data_df['InducingDates'] = data_df['InducingDates'].apply(lambda x: reformat_inducing_n_fixing_date(str(x)))\n",
    "# data_df['FixingDates'] = data_df['FixingDates'].apply(lambda x: reformat_inducing_n_fixing_date(str(x)))\n",
    "\n",
    "# # condi = data_df.query('Version == \\'conscrypt_0\\' & Release == \\'nan\\'')\n",
    "# # print(condi.shape)\n",
    "\n",
    "# # Updating snapshot date for snapshot_0\n",
    "# data_df.loc[data_df['Version']=='conscrypt_0','Release']= '2008-10-21 00:00:00'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['InducingDate'][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
